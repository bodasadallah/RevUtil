{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the dataset, noting that it is artificially created and might contain noise, including misinformation and outofcontext images. It suggests that the authors should provide more analysis on the dataset quality and the amount of noise it might have. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset quality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of noise in the artificially created dataset, specifically mentioning the potential for misinformation and outofcontext images in the \"pristine\" set of tweets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the dataset quality and noise, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential noise in the artificially created dataset, specifically mentioning the possibility of misinformation and outofcontext images in the \"pristine\" set of tweets. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the dataset might contain such noise. Without additional evidence or justification, the claim remains 3, as the authors may need to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, noting that it is artificially created and might contain noise, including misinformation and outofcontext images. The reviewer suggests that the authors should provide more analysis on the dataset quality and the amount of noise it might have. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to consider the quality of their dataset. However, the comment could be more helpful if it provided specific guidance on how to analyze the dataset or suggested alternative approaches to address the noise. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap, such as suggesting additional analysis or experiments. Without concrete guidance on how to improve the paper, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a gap in the paper by noting that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, it does not specify which part of the paper this issue is related to, such as a specific section or analysis. This lack of grounding makes it difficult for the authors to pinpoint where the issue lies and how to address it. Additionally, the comment does not provide specific guidance on how to improve the analysis or what aspects of the algorithm\"s convergence should be explored. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. This is a valuable observation as it highlights an area where the paper could be strengthened by providing a more indepth analysis of the algorithm\"s theoretical underpinnings. However, the comment does not offer specific suggestions or guidance on how the authors might address this gap, such as suggesting additional analysis or experiments. While it provides a clear direction for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" choice of operators, specifically the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min, which correspond to union and intersection. The comment implies that the authors should have considered these alternatives and provides a reason for not doing so. However, it does not explicitly instruct the authors to include or discuss these operators in their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider these operators. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" choice of operators and suggesting that they might have considered alternatives like the or operator or elementwise max, which correspond to union and intersection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" choice of operators, specifically the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min, which correspond to union and intersection. The comment implies that the authors should have considered these alternatives and provides a reason for not doing so. However, it does not offer any specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed explanation or evidence makes the claim 3, as the authors are left to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors may have overlooked certain operators, namely the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min, which correspond to union and intersection. The comment provides a clear rationale for why these alternatives might have been better options, but it does not offer specific guidance on how the authors should incorporate or discuss these operators in their draft. While the feedback is 3 in pointing out a potential oversight, it lacks detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this selection might affect the underestimation of performances. While the comment implies that the authors should provide a justification for this choice, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to explain their reasoning for selecting only 10 answers. However, the comment lacks concrete guidance on how to address this issue or what specific aspects of the selection process might impact performance estimation. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the issue needs to be addressed. While the comment is specific in its inquiry about the selection process and its potential impact on performance estimation, the absence of explicit grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. However, it does not provide any specific reasoning, examples, or references to support the claim that this selection could lead to underestimation. Without additional context or justification, the reviewer\"s concern remains speculative and lacks verifiability. Therefore, the comment is classified as \"1\" as it does not provide sufficient evidence or reasoning to support the claim.", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. While it identifies a potential issue with the methodology, it does not provide any suggestions or guidance on how to address this concern. The comment lacks actionable advice or detailed feedback, making it 3 as it highlights a potential area for improvement but does not offer a clear path forward for the authors. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the reported duration includes time spent by the user waiting for the model to generate a response. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify the purpose of the average duration. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and the specific areas that require attention. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the reported duration includes time spent by the user waiting for the model to generate a response. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. While it provides some specificity by asking about the purpose and inclusion of waiting time, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the reported duration includes time spent by the user waiting for the model to generate a response. This comment is 3 as it raises a valid point about the lack of clarity in the presentation of data in Table 1. However, it does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of explanation for the average duration reported in Table 1. It questions the purpose of this metric and asks whether it includes waiting time for the model to generate a response. This feedback is helpful as it highlights a potential area of confusion or lack of clarity in the paper. However, the comment could be more helpful if it provided suggestions on how the authors might clarify this point or include additional context in the table. Overall, the comment is 3, as it identifies a specific issue that needs attention but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the wording used in the paper, specifically the phrase \"on par or better,\" which might be misleading due to cognitive biases among NLP researchers. However, the comment does not provide explicit guidance on how the authors should correct the wording or what specific changes should be made. The action is implicit, as the authors need to infer that they should revise the wording to avoid ambiguity. While the comment is 3, it lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"on par or better\" at line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the wording, suggesting that it might be misleading due to cognitive biases among NLP researchers. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the phrase \"on par or better\" might be misleading due to cognitive biases among NLP researchers. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording used in the paper, specifically the phrase \"on par or better,\" which might be misleading due to cognitive biases among NLP researchers. The comment suggests that this wording could be corrected to avoid ambiguity, but it does not provide specific guidance on how to revise the wording or what changes should be made. While the feedback highlights a potential area for improvement, it lacks detailed suggestions or examples, making it 3. The authors would need to infer the need for revision and potentially seek further clarification to fully address the comment. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these interpretations or what changes might be necessary. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the results in Table 3 are discussed, making it difficult for the authors to identify the relevant section. Additionally, the comment is not specific because it does not provide detailed guidance on how to interpret the results or what actions should be taken. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any suggestions or guidance on how the authors might address these interpretations or what changes could be made to improve the clarity or robustness of the results. Without actionable feedback or specific suggestions, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any explicit or implicit suggestions on how to address this issue, such as recommending a consistent formatting approach or providing guidance on why the inconsistency is problematic. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistency in the presentation of data, noting that some items have spaces between accuracy and standard deviation while others do not, which affects the visual appeal and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any specific examples, reasoning, or references to support why this inconsistency is problematic or how it impacts the overall quality of the paper. Without additional context or justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of data in Table 2 and Table 3, noting inconsistencies in the formatting of accuracy and standard deviation values. This observation is clear and actionable, as it points out a potential issue with the visual appeal and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting approach or explaining why the inconsistency is problematic. While the feedback is 3 in identifying a problem, it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been explored in various NLP and imagetext models. It acknowledges that the related work section summarizes these efforts and notes that the paper\"s novelty lies in applying similar ideas to videotext models. However, the comment does not provide explicit guidance on how the authors can address this issue or what specific aspects of their work could be improved to enhance its novelty. The action is implicit and vague, as it does not specify how the authors can demonstrate the novelty of their work or what additional contributions they could make. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, such as a particular section, table, or figure. It also lacks specificity, as it does not detail what aspects of the paper are lacking novelty or how the authors can address this issue. The comment provides a general overview of the related work but does not offer specific guidance or suggestions for improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks novelty, as adversarial attacks on text have been explored in various NLP and imagetext models. It acknowledges that the related work section summarizes these efforts and notes that the paper\"s novelty lies in applying similar ideas to videotext models. However, the comment does not provide specific examples or detailed reasoning to support the claim that the work lacks novelty. It lacks detailed justification or references to specific works that could be discussed to substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, specifically noting that adversarial attacks on text have been explored in various NLP and imagetext models. It acknowledges that the related work section summarizes these efforts and suggests that the paper\"s novelty lies in applying similar ideas to videotext models. However, the comment does not provide specific guidance or suggestions on how the authors can address this issue or enhance the novelty of their work. It lacks actionable feedback, making it difficult for the authors to improve their draft based on this comment alone. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the explanations for lexical features and sentencelevel features in Section 3.2 are somewhat intertwined and confusing. It provides a clear action for improvement: organizing the section with separate paragraphs for each type of feature. This action is concrete and specific, as it clearly indicates how the authors should restructure the section to enhance clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the organization of the section by suggesting separate paragraphs for lexical and sentencelevel features. This level of detail helps the authors understand exactly what needs to be done to enhance the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are somewhat intertwined and confusing, implying that the section could be more coherently organized. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without detailed reasoning or examples, the claim is 3, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of explanations in Section 3.2, noting that the features are somewhat intertwined and confusing. It provides a clear suggestion for improvement by recommending a more coherent organization of the section with separate paragraphs for lexical and sentencelevel features. This feedback is actionable and constructive, as it directly addresses a potential weakness in the paper and offers a concrete solution for the authors to consider. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the clarity of the explanations. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the amount of space dedicated to the assumptions section and experimental results, suggesting that it might be excessive. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors need to infer that they should consider reducing the space dedicated to these sections or reorganizing the paper to make it more concise. The comment is vague and lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"assumptions\" section and the \"experimental results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue as being excessive in space, which provides a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a subjective opinion about the usefulness of the information presented in the assumptions section and the experimental results. It suggests that the amount of space dedicated to these sections is excessive. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the excessive space dedicated to the assumptions section and experimental results. While it acknowledges the value of fleshing out the assumptions, it suggests that the amount of space allocated to these sections might be excessive, which could be a concern for the authors. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing alternative ways to present the information or suggesting a more concise approach. Without actionable advice or detailed feedback, the comment is 3 as it highlights a potential area for improvement but does not provide a comprehensive solution. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and points out that the paper does not adequately describe this comparison, instead emphasizing soft vs. hard word sense disambiguation. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, it does not provide explicit instructions on how to implement these suggestions, such as which specific baselines to include or how to compare the models. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the comparison between the proposed models and models that consider different senses but not sememes, suggesting that the MST baseline might be an example. However, it does not specify which part of the paper this comparison is intended to address, making it difficult for the authors to pinpoint the exact section. While the comment is specific in its suggestion to include more baselines, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison between the proposed models and models that consider different senses but not sememes, suggesting that the MST baseline might be an example. It also points out that the paper does not adequately describe this comparison, instead emphasizing soft vs. hard word sense disambiguation. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, it lacks specific examples or references to support the claim that the MST baseline is an example of a model considering different senses but not sememes. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and points out that the paper does not adequately describe this comparison, instead emphasizing soft vs. hard word sense disambiguation. The comment implies that including more baselines based on related work would strengthen the paper. However, the feedback lacks specific guidance on which baselines to include or how to compare the models effectively. While it provides a direction for improvement, the comment could be more helpful with additional details or suggestions on how to address the issue comprehensively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific suggestions or actions that the authors can take to clarify or improve their methodology. As a result, the authors are left without a clear understanding of what steps to take to resolve this ambiguity. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. Without knowing the context or location of the discussion, the authors cannot confidently identify the section that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the ambiguity in the selection process. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any specific reasoning, examples, or references to support why this is unclear. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential ambiguity in the selection process of frame similarity factors and attributes similarity factors, which could hinder the clarity and reproducibility of the research. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific instructions for the authors to address certain aspects of their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. The comment also questions why the term \"latent in verbs\" is not mentioned. These instructions are explicit and provide clear guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment does not explicitly mention which part of the paper these instructions refer to, making it weakly grounded. The instructions are specific in detailing what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. While the instructions are clear, the absence of justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on areas where the authors could improve their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B), which are important aspects of the paper. Additionally, it suggests using consistent terminology for the model in Tables 1 and 2, which is a practical and helpful suggestion. The comment also questions why the term \"latent in verbs\" is not mentioned, prompting the authors to consider this aspect. Overall, the feedback is clear, concise, and provides actionable guidance, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggesting an alternative phrasing. The comment is explicit in pointing out the error and providing a clear alternative, allowing the authors to directly address the issue. However, it does not provide detailed guidance on how to implement the suggested change or what specific aspects of the sentence need to be revised. While the action is explicit, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a factual error in the description of the GRU model and suggests an alternative phrasing that aligns with the information presented in Figure 2. This provides clear guidance on what needs to be corrected or clarified in the paper.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests an alternative phrasing. While the comment provides a specific example and suggests a correction, it lacks detailed reasoning or references to support the claim. The authors would need to infer the validity of the claim based on the provided information, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggests an alternative phrasing. This feedback is clear and actionable, providing the authors with a specific point of improvement. However, the comment could be more helpful if it offered additional guidance on how to revise the sentence or suggested alternative phrasing that aligns with the information in Figure 2. Despite this, the comment is 4 as it directs the authors to a specific area for improvement and encourages them to refine their writing."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the baseline models used in the paper. First, it points out that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. This suggests that the authors should include this comparison to provide a more comprehensive evaluation of their models. Second, the comment notes that the authors do not compare their models to other domain adaptation methods, such as those mentioned in Section 8. This implies that the authors should include these comparisons to strengthen their analysis. The review point also suggests that the authors should clarify the statement on line 277, which is vague and lacks specificity. While the comment identifies two areas for improvement, it does not provide explicit guidance on how to address these issues, such as suggesting specific comparisons or clarifications. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the baseline models used in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issues with the baseline models, such as the lack of comparison to Campos et al. (2020) and other domain adaptation methods. This provides clear guidance on what needs to be addressed. However, the comment does not specify what needs to be addressed in terms of comparisons or clarifications, making it somewhat specific. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests that the authors should compare their models to Campos et al. (2020) and other domain adaptation methods. The comment provides specific examples of missing comparisons, such as the work cited in Section 8. However, it lacks detailed reasoning or references to support the claim that these comparisons are necessary or would significantly improve the paper. The suggestion to clarify the statement on line 277 is also vague and does not provide specific guidance on how to do so. Therefore, the comment is 4, as it provides some justification but lacks depth and specificity in its claims.", "helpfulness_rationale": "The review comment identifies two key weaknesses in the paper: the lack of comparison to specific baseline models, particularly Campos et al. (2020), and the absence of comparisons with other domain adaptation methods. It also suggests a minor correction in the text on line 277. While the comment highlights important areas for improvement, it does not provide detailed guidance on how to address these issues or suggest specific comparisons or clarifications. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable suggestions, which could be expanded to enhance its usefulness."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the lack of description regarding the societal biases of the knowledge bases used in the paper. It questions whether the knowledge bases are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. The action is implicit and vague, as it does not specify how the authors should verify or address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, it does not specify which part of the paper discusses the knowledge bases or where the issue is addressed. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in that it highlights a potential issue with the knowledge bases, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. While it identifies a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. The comment could be more helpful if it offered concrete suggestions or examples of how to mitigate the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the lack of strong baselines in Table 3, specifically mentioning the baselines in 1. It requests the authors to justify their choice of baselines. While the comment implies that the authors should include more baselines, it does not provide explicit guidance on how to do so or what specific baselines should be added. The action is implicit and somewhat vague, as the authors need to infer that they should add more baselines and justify their selection. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to justify the reason for the absence of strong baselines, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of strong baselines in Table 3 and requests justification for their absence. While the comment identifies a potential issue with the baselines, it does not provide specific examples or references to support the claim that the baselines are weak. The request for justification is clear, but the lack of detailed reasoning or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment identifies a specific issue with the baselines in Table 3, noting that they are weak and suggests that the authors should include more baselines, referencing a specific paper 1. This feedback is clear and actionable, as it provides a direct request for improvement and a specific reference to support the claim. However, it could be more helpful if it offered additional guidance on how to select or justify the baselines. Overall, the comment is 4 as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the paper\"s reliance on supplemental space, suggesting that the paper is not truly independent due to references to supplemental figures and model comparisons. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should consider making the paper more selfcontained, but it lacks concrete guidance on how to achieve this. As a result, the authors are left without a clear understanding of what steps to take to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of the paper relying on supplemental space, specifically mentioning references to supplemental figures and model comparisons. However, it does not specify which part of the paper these references are located in, making it weakly grounded. The comment is specific in identifying the problem with the paper\"s reliance on supplemental space, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space, making it not truly independent, and provides specific references to the supplemental figures and model comparisons that support this claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the full extent of the issue based on the provided references, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reliance on supplemental space, noting that the paper is not truly independent due to references to supplemental figures and model comparisons. This feedback is clear and actionable, as it highlights a critical aspect of the paper\"s structure and suggests that the authors should consider making the paper more selfcontained. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to make the paper more independent, such as integrating key information into the main text or providing a more detailed explanation of the supplemental content. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or what changes could be made to their draft. The action is implicit, as the authors would need to infer that they should consider the redundancy of concept map extraction and potentially integrate it into the summarization process. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment addresses the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It provides a rationale for this claim, explaining that many systems already build similar knowledge graphs and generate summaries accordingly. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its reasoning about the redundancy of concept map extraction, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. The comment provides a rationale for this claim, explaining that many systems already build similar knowledge graphs and generate summaries accordingly. However, it lacks specific examples or references to support the claim that concept map extraction becomes increasingly difficult to distinguish with a growing number of nodes. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to substantiate the reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It provides a rationale for this claim, explaining that many systems already build similar knowledge graphs and generate summaries accordingly. However, the comment does not offer specific suggestions or guidance on how the authors might address this concern or what changes could be made to their draft. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer that they should consider the redundancy of concept map extraction and potentially integrate it into the summarization process, but the comment does not provide detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should provide more details about the traits of the experts involved in the annotation process and justify why expert annotation is necessary, beyond its commercial value. It also asks for clarification on whether the experts are linguistic or domain experts, and whether the annotation process differs from what nonexperts would do. This feedback is explicit and provides clear guidance on what needs to be addressed, making it 5. The authors know exactly what information is required to improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions about the traits of the experts, the justification for expert annotation, and the differences between expert and nonexpert annotation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the expertise of the annotators and the justification for expert annotation, which are relevant to the paper\"s methodology. However, it does not provide specific examples or references to support these claims. The questions are logical and require the authors to clarify their methodology, but without additional context or evidence, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the need for more detailed information about the experts involved in the annotation process. It questions the justification for expert annotation beyond its commercial value, asking for clarification on the experts\" expertise (linguistic or domain) and whether the annotation process differs from what nonexperts would do. This feedback is clear and constructive, guiding the authors to enhance the transparency and rigor of their methodology. By addressing these points, the authors can significantly improve the clarity and depth of their paper, making the comment highly valuable for their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with lines 102106, stating that the term \"such distribution\" is misleading because it does not align with the discussion in the preceding text. However, the comment does not provide any explicit guidance or suggestions on how the authors should revise or clarify this section. The action is implicit, as the authors would need to infer that they need to address the misleading nature of the term. Additionally, the comment lacks concrete details on how to make the discussion clearer, leaving the authors without a clear path to improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 102106, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a misleading issue with the term \"such distribution\" and suggests that it does not align with the preceding discussion. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the term \"such distribution\" does not align with the preceding discussion. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the term is misleading or how to address it. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with lines 102106, noting that the term \"such distribution\" is misleading because it does not align with the preceding discussion. This feedback is clear and actionable, as it directs the authors to a particular section of the paper that needs clarification. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of the discussion. Despite this, the comment offers valuable guidance for the authors to enhance the accuracy and coherence of their paper, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would benefit from including examples of the system applied to actual texts, as opposed to other components or models. While the comment implies that this would be helpful, it does not explicitly instruct the authors to add such examples or specify how to do so. The action is implicit and somewhat vague, as the authors are left to infer that adding examples would improve the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, which implies a specific part of the paper where such examples would be beneficial. However, it does not explicitly mention which section or part of the paper this would apply to, making it weakly grounded. The comment is specific in its suggestion to include examples, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact area where the examples should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from including examples of the system on actual texts, which implies that the current draft lacks such examples. However, the comment does not provide any specific reasoning or evidence to support why this would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains 3, as the authors are left to infer the value of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from including examples of the system applied to actual texts, which could enhance the understanding and impact of the work. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what kind of examples would be most effective. While it offers a general direction for improvement, the feedback is somewhat vague and could be more helpful if it included specific suggestions or examples. Therefore, the comment is rated as 3, as it provides a clear idea of what could be improved but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper. It asks whether the CS is used for evaluation purposes and also for augmenting the training material. The comment implies that the authors should clarify how the CS is used and what data split is employed. However, it does not provide explicit instructions or detailed guidance on how to address these questions or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and the specific areas to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not specify which part of the paper discusses the CS or where these questions should be addressed. The authors may need to infer that the questions relate to the methodology or experimental setup sections, but this is not explicitly stated. The comment is specific in its questions but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not provide any evidence, reasoning, or references to support these questions or claims. The questions are based on the authors\" understanding, but without further clarification or justification, they remain speculative. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. While the comment identifies an area that needs clarification, it does not provide specific guidance or suggestions on how to address these questions or improve the draft. The feedback is 3 as it points out a potential area of confusion for the authors, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion in section 5.2 is abstract and lacks clarity, making it difficult for the authors to understand why the new model is better than MH. It suggests providing examples of spurious structures to clarify the discussion. However, the comment does not explicitly instruct the authors to provide these examples or how to incorporate them into the discussion. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies a lack of clarity in the discussion regarding the abstract nature of the insights and suggests providing examples of spurious structures to clarify the comparison between the new model and MH. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstract nature of the discussion in section 5.2 and suggests providing examples of spurious structures to clarify the comparison between the new model and MH. However, the comment does not offer any specific reasoning, examples, or references to support why the discussion is abstract or how the suggested examples would clarify the comparison. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, namely the abstract nature of the discussion in section 5.2, which makes it difficult for the authors to understand why the new model is better than MH. The comment suggests providing examples of spurious structures to clarify the discussion, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate these examples into the discussion. Despite this, the feedback is 4 as it directs the authors towards a concrete improvement that could enhance the clarity and understanding of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F1. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F1. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. Additionally, the comment does not provide specific details on what aspects of the comparison should be highlighted, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F1. However, it lacks detailed reasoning or examples to support why this comparison is necessary or how it would be beneficial. The comment does not provide specific references or logical reasoning to justify the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F1. While it provides a potential improvement to the methodology, it lacks detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The comment is 3 as it identifies a potential area for improvement, but it does not offer comprehensive feedback or actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a clear and explicit action that provides specific guidance on what needs to be included in the paper. The authors know exactly what information is missing and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: stating the maximum number of tasks done by any annotator. This provides the authors with a clear understanding of the issue and how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a factual suggestion that requires no further verification or reasoning. It is a direct request for clarification or additional information, which does not involve making claims or opinions. Therefore, this comment is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by asking the authors to include the maximum number of tasks done by any annotator. This is a clear and actionable piece of feedback that directly addresses a potential gap in the paper. By providing this information, the authors can enhance the transparency and completeness of their work. The comment is concise and directly actionable, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions how the experiments relate to the underlying research question and the specific hypothesis tested. However, the comment does not provide any explicit or implicit suggestions on how the authors might improve the clarity or coherence of the presentation of their results. Without specific guidance on what aspects need clarification or how to better integrate the different pieces of the puzzle, the authors are left without actionable steps to address the feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions how the experiments relate to the underlying research question and the specific hypothesis tested. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it challenging for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its critique of the clarity of the results, it is 1 because it does not provide explicit references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the clarity of the empirical results and analyses presented in the paper, questioning how they relate to the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while it contains many empirical results and analyses, it lacks clarity in explaining how these results relate to the underlying research question and the specific hypothesis being tested. The comment highlights a gap in the paper\"s ability to present a coherent and comprehensive picture of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or coherence of their presentation. Without actionable advice or examples of how to address the issue, the authors may find it challenging to make meaningful improvements to their draft. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of numerical results in the paper, specifically questioning how the proposed method can be applied to popular algorithms and how its performance compares to existing DP algorithms. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include numerical results and conduct comparisons with existing algorithms. However, the action is implicit and somewhat vague, as it does not specify which algorithms to use or how to perform the comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and questions the application of the proposed method to popular algorithms, specifically comparing its performance with existing DP algorithms. However, it does not specify which algorithms are considered \"popular\" or provide any details on how the comparison should be conducted. The comment is 1 as it does not mention specific sections or parts of the paper that need attention. It is also not specific because it lacks details on the algorithms or the comparison process. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks numerical results and questions how the proposed method can be applied to popular algorithms and compared with existing DP algorithms. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and the absence of comparisons with existing DP algorithms. This feedback is valuable as it highlights a critical area where the authors can enhance the paper by providing empirical evidence and demonstrating the practical applicability of their method. However, the comment could be more helpful if it suggested specific algorithms or methods for comparison or provided guidance on how to conduct these comparisons. Despite this, the feedback is 3 as it directs the authors to an important aspect of their work that needs further development. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not drawn formally enough to be considered more than motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. The comment provides explicit guidance on what needs to be done, namely, to formalize the connection or clarify the language. This level of detail makes the action clear and concrete, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection in the paper is not drawn formally enough, implying that it is considered motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. However, the comment does not specify which part of the paper discusses the probabilistic connection, making it weakly grounded. It is specific in suggesting that the authors should formalize the connection or clarify the language, but without a clear reference to the section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection in the paper is not drawn formally enough, making it appear as motivational rather than substantiated. The comment suggests that the authors should either formalize this connection or adjust the language to clarify it. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or examples, the claim is 3, as it provides a general direction but lacks the necessary depth for full understanding and implementation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the probabilistic connection is not drawn formally enough, making it appear as motivational rather than substantiated. The comment suggests that the authors should either formalize this connection or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the rigor and clarity of their work. By recommending concrete steps, the comment empowers the authors to address the identified weakness and improve the overall quality of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is explicit and provides a clear action for the authors to take, which is to include empirical evidence to substantiate the claim. The comment is specific in its suggestion and offers a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not specify which part of the paper discusses the third contribution or the Column Subset Selection problem, making it weakly grounded. It is specific in its suggestion to include empirical evidence, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include empirical evidence to substantiate their claim. By doing so, the authors can strengthen the validity of their contribution and provide a more comprehensive evaluation of their algorithm. However, the comment could be more helpful if it offered specific guidance on how to conduct or present the empirical evidence. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those supported on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or what changes could be made to improve the scheme. The action is implicit and vague, leaving the authors without a clear understanding of how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the applicability of the robust training scheme to practical datasets, particularly those supported on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper discusses the robust training scheme or the datasets used. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the issue is being addressed. While the comment is specific about the concern regarding scalability, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those supported on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those supported on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. This feedback highlights a potential limitation of the proposed method and provides a specific area for the authors to consider. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what changes could be made to improve the scheme. While it identifies a potential weakness, it does not offer actionable steps or insights to enhance the paper. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. While it prompts the authors to consider the relevance of their dataset choice, it does not explicitly instruct them to provide additional justification or evidence for their dataset selection. The action is implicit, as the authors need to infer that they should address the sufficiency of the dataset and provide more context on the style shifts being studied. However, the comment lacks concrete guidance on how to determine the sufficiency of the dataset or what specific evidence to include. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. While the comment is specific in its questioning of the dataset choice, it lacks grounding as it does not provide explicit references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. While the comment raises a valid concern about the dataset choice, it does not provide specific examples, references, or detailed reasoning to support the claim that the dataset is insufficient. The authors are left to infer the need for more detailed justification or evidence, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of a 4year period for studying style shifts, questioning whether the chosen timeframe is adequate to capture the relevant changes. It also asks for clarification on the types of style shifts that occur within this timeframe, which is crucial for understanding what the model is capturing. While the comment identifies a potential weakness in the dataset choice, it does not provide specific suggestions or guidance on how to address this issue. The feedback is 3 as it prompts the authors to consider the limitations of their dataset and the need for more detailed justification or evidence. However, it could be more helpful if it offered actionable advice or suggestions for improving the dataset or analysis. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the experiments in the paper, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to address the lack of explanation for the selfcomparisons or to include comparisons with SketchRNN. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the issue of only reporting selfcomparisons and the lack of explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. However, the comment does not specify which part of the experiments section this issue is discussed, making it weakly grounded. The comment is specific in detailing the issue of selfcomparisons and the suggestion to include comparisons with SketchRNN, which provides clear guidance for the authors. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only reports selfcomparisons and lacks explanation for this choice, which adds to the poor motivation problem. It suggests that comparisons with SketchRNN could be performed. However, the comment does not provide specific examples or references to support the claim about the lack of explanation or the suggestion to include comparisons with SketchRNN. This makes the claim 3, as it lacks detailed reasoning or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the experiments section of the paper, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. This observation highlights a potential weakness in the paper\"s motivation and experimental design. The comment also suggests that comparisons with SketchRNN could be performed, which provides a concrete direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to address the lack of explanation or how to incorporate comparisons with SketchRNN effectively. Overall, the comment is 4 as it points out a critical issue and offers a specific suggestion for improvement, but it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency to understand. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the results need clarification. The comment implies that the authors should consider making the results more accessible to a broader audience, but it lacks concrete suggestions or actionable steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It makes a general observation about the results being based on \"standard\" techniques and requiring a degree of technical competency, but it does not provide specific guidance or examples related to any particular section or aspect of the paper. Therefore, the comment is 1 and does not specify what needs to be addressed, making it unspecific. This aligns with a score of 1 and Not Specific.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not obvious a priori and require a fair degree of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as it is based on subjective interpretation and lacks concrete examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that they are based on \"standard\" techniques but are not immediately obvious or accessible to a broader audience. This suggests that the results may require additional explanation or context to be fully understood. However, the comment does not provide specific guidance on how the authors might address this issue or what aspects of the results need clarification. While it highlights a potential area for improvement, the feedback lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that don\"t. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion in their draft. The comment is specific in its recommendation, detailing exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates the frozen model and those that don\"t, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that do not. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this distinction is important or how it would improve the paper. Without additional context or justification, the claim is 3, as it is based on a logical suggestion but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors make a distinction between hard prompt work updates the frozen model and those that do not. This feedback is actionable and directly addresses a potential area for clarification or enhancement in the paper. By suggesting a clear categorization, the comment offers a concrete and constructive way for the authors to improve their draft. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the conclusion that the direct model is clearly the better of the two, given the significant difference in the amount of data used for training the text disambiguation model and the endtoend system. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to strengthen their conclusions. The comment implies that the authors should consider the impact of data quantity on model performance, but it lacks concrete suggestions or actionable steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly the better of the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the data discrepancy and its impact on the conclusion, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly the better of the two, given the significant difference in the amount of data used for training the text disambiguation model and the endtoend system. The comment suggests that this difference, which is only a few percentage points, brings into question the validity of the conclusion. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to fully substantiate the concern, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly the better of the two, given that the difference in data usage is only a few percentage points. This feedback highlights a potential issue with the experimental setup and its impact on the conclusions drawn. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or strengthen their analysis. Without actionable advice, the comment is 3, as it identifies a potential weakness but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, specifically regarding the recovery of updated parameters from projected gradients. While the comment identifies these areas, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide a clearer motivation for GaRare and a more detailed explanation of the algorithmic process. This lack of explicit action makes the comment 3, as it provides a general direction but lacks specific steps for improvement.", "grounding_specificity_rationale": "The comment addresses the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. However, it does not specify which part of the paper discusses GaRare or the algorithmic process, making it weakly grounded. The comment is specific in detailing the issues that need to be addressed, such as the motivation for GaRare and the need for a more detailed algorithmic presentation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clear motivation for GaRare and does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes the claim 3, as the authors would need to provide additional information to address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that require attention, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any explicit or implicit suggestions on how the authors should address this gap or incorporate these works into their draft. Without specific guidance on what needs to be done, the authors are left without a clear path to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields\" and \"Continuous Conditional Neural Fields,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a missing link to similar work that has a similar structure to the CRF and ability to perform exact inference, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this claim is important or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the related work section by pointing out the absence of references to similar works on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and ability to perform exact inference, which is relevant to the paper\"s topic. However, the comment does not provide any suggestions or guidance on how the authors might address this gap or incorporate these works into their draft. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear indication of a missing element but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should try to explain why the Wavelet Packet Analysis (WPA) works, particularly with np.ones input, and what the model predicts in this scenario. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into the workings of WPA to enhance the paper and spark future research directions. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should try to explain why WPA works, particularly with np.ones input, and what the model predicts in this scenario. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into the workings of WPA to enhance the paper and spark future research directions. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. It is specific in suggesting the need for a deeper explanation of WPA\"s functionality, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the functionality of WPA, specifically with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works and why it might not be effective with certain inputs. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is 3 as it points out a potential area for improvement but does not provide sufficient evidence or guidance for the authors to act upon. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by questioning the functionality of WPA, particularly with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well as WPA. It highlights that the authors spend considerable time demonstrating WPA\"s improvement in test performance but fail to provide insights into how WPA works, which is crucial for sparking future research directions. This feedback is valuable as it prompts the authors to delve deeper into the mechanisms of WPA and its effectiveness, offering a clear direction for enhancing the paper. However, the comment could be more helpful if it provided specific suggestions or guidance on how to explore the functionality of WPA. Overall, the comment is 4, as it highlights an important area for improvement and encourages the authors to consider future research directions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" While it suggests that the authors should provide more clarification, it does not explicitly instruct them to do so or offer specific guidance on how to clarify the similarity. The action is implicit, as the authors need to infer that they should clarify the relationship between their method and the cited work. However, the comment lacks concrete details on what aspects of the method need clarification, making it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the similarity between the method part and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in that it highlights a potential issue with the method\"s novelty or distinctiveness compared to existing work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This is a subjective claim, as it expresses an opinion about the similarity of the method to existing work. However, the comment lacks specific evidence or reasoning to support this claim, making it difficult for the authors to understand the basis of the concern. Without further explanation or examples, the claim is not verifiable. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity of the method part to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This feedback is 3 as it identifies a potential issue with the novelty or distinctiveness of the method. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or clarify the relationship between their method and the cited work. Without actionable advice or detailed examples, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the paper by pointing out that while two important parameters/thresholds are mentioned in the end of Section 2, the experimental section (Section 3) does not discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is explicit and provides a clear action for the authors to take, which is to address this gap by including a discussion of parameter settings and their impact on performance in the experimental section. The comment is specific and concrete, as it directly instructs the authors on what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 2 and the experimental section (Sec. 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of discussion on how the two important parameters/thresholds are set and how sensitive the performance is with respect to these parameters. This provides a clear direction for the authors to improve their draft. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a gap in the paper by pointing out that while two important parameters/thresholds are mentioned in the end of Section 2, the experimental section (Section 3) does not discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is clear and provides a logical reasoning for why the experimental section lacks this information. However, it does not provide specific examples or references to support the claim, which could enhance the verifiability. Therefore, the comment is 4, as it is wellsupported but lacks some depth in terms of examples or references.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that while two important parameters/thresholds are mentioned in the end of Section 2, the experimental section (Section 3) does not discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is clear and actionable, as it directs the authors to address this gap by including a discussion of parameter settings and their impact on performance in the experimental section. By providing a specific and constructive suggestion, the comment empowers the authors to improve the completeness and clarity of their draft. Therefore, the comment is 5, as it offers detailed guidance on how to enhance the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the approach. The comment lacks concrete guidance on what specific aspects of the model or task need to be revised or adjusted to mitigate this potential weakness. As a result, the authors are left without a clear understanding of how to proceed with the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors cannot confidently determine which aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its critique of the approach but lacks detailed suggestions on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it provides a subjective opinion but lacks sufficient justification.", "helpfulness_rationale": "The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how to address this concern or improve the approach. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should take a cautious approach regarding the contribution until the promised dataset is publicly available. However, it does not provide any specific guidance or actions on how the authors should proceed with this cautious approach. The comment lacks explicit instructions or concrete steps for the authors to take, making it difficult for them to understand what actions are needed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the promised dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, taking a cautious approach regarding the contribution until the dataset is publicly available. This provides clear guidance on how the authors should proceed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting a cautious approach should be taken. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. Without additional context or evidence, the claim remains speculative and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the availability of a promised dataset, which is essential for the contribution of the paper. It suggests a cautious approach should be taken until the dataset is publicly accessible, highlighting a potential limitation that could affect the reproducibility and impact of the work. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they should take to ensure the dataset is made available in the future. While it raises an important concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 3, as it identifies a significant issue but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the authors\" claim of achieving stateoftheart results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to substantiate their claim. The feedback lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"challenging scene text recognition tasks\" and \"stateoftheart results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the authors\" claim regarding the performance of their method, suggesting that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim of achieving stateoftheart results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the assertion that the performance is primarily due to the first step. Without this additional information, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks. It questions the persuasiveness of this claim, suggesting that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or substantiate their claim. While it raises a valid concern, the feedback lacks actionable advice, making it 3. The authors would need to conduct additional experiments or provide more detailed evidence to address the reviewer\"s concern. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for this observation. While the comment suggests that the authors should consider why the performance deteriorates when CBN is applied to layer 2 in addition to layers 3 and 4, it does not provide explicit guidance on how to address this issue or what actions the authors should take. The action is implicit, as the authors need to infer that they should investigate and explain the performance difference. However, the comment lacks concrete details on how to approach this investigation, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, and it questions why this approach might deteriorate performance compared to applying CBN to layers 4 and 3 only. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance compared to applying it to layers 4 and 3 only. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It highlights a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 leads to a performance deterioration compared to applying it to layers 4 and 3 only. This observation is intriguing and prompts the authors to investigate and understand the underlying reasons for this phenomenon. However, the comment lacks detailed guidance or suggestions on how the authors might approach this investigation or what specific aspects of the model or training process could be contributing to the performance difference. While it identifies a potential area for improvement, the feedback is somewhat limited in its depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not provide any explicit or implicit suggestions on how the authors might address this issue. The comment lacks guidance on what specific changes or clarifications are needed to resolve the confusion. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not specify which part of the paper this issue is related to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the confusion arises. Additionally, the comment does not provide specific guidance on how to address this issue, making it 2. Therefore, this comment aligns with the label 2.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand why the call is confusing or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the implicit call to the Witness oracle, which could be confusing for readers. However, the comment lacks specific guidance or suggestions on how the authors might address this confusion. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it points out a problem but does not provide sufficient assistance for the authors to address it effectively."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions the authors\" claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes are needed in the draft. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the authors\" claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. It implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment does not specify which part of the paper discusses the proposed method or headpose handling, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of headpose handling, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the authors\" claim that their proposed method cannot handle headpose, suggesting that a previous work (e.g., Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors\" method is indeed limited in this regard. Without further elaboration or evidence, the claim remains 3, as it is based on an inference rather than a direct assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific guidance or suggestions on how to address this issue or improve the draft. It does not provide actionable steps or detailed reasoning to help the authors enhance their work. As a result, the comment is 2, as it identifies a potential weakness but does not offer substantial feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel or simple patterns by Gu et al. (2019). However, the comment does not explicitly instruct the authors to address this similarity or provide specific guidance on how to improve their draft based on this observation. While the authors might infer that they should discuss or differentiate their spurious features from existing backdoor triggers, the lack of explicit action or detailed guidance makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples of how these triggers have been used in previous work. This allows the authors to understand what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel or simple patterns by Gu et al. (2019). This claim is supported by logical reasoning and references to specific examples, making it 4. The authors can understand the basis of the claim and how it relates to their work, allowing them to address it effectively. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant similarity between the spurious features discussed in Section 3.1 and 3.2 and backdoor triggers, which are artificial patterns that appear only a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel or simple patterns by Gu et al. (2019). This observation is valuable as it highlights a potential issue with the novelty or distinctiveness of the spurious features discussed in the paper. However, the comment could be more helpful if it provided specific guidance on how the authors might address this similarity or differentiate their work from existing studies. While it offers a starting point for discussion, it lacks detailed suggestions or actionable advice, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a structural optimization component that has been emphasized multiple times, but it points out that the optimization algorithm is directly derived from previous works. This feedback suggests that the authors should clarify the novelty and contribution of their optimization approach. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the algorithm need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their optimization algorithm. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the structural optimization component of the paper, which is a specific part of the work. However, it does not explicitly mention which section or part of the paper this optimization is discussed in, making it weakly grounded. The comment is specific in identifying that the optimization algorithm is directly from previous works, which reduces the contribution. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the optimization algorithm is directly from previous works, which reduces the contribution. However, the comment does not provide specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it difficult to verify the claim and understand the basis of the criticism. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the structural optimization component of the paper, noting that it is directly derived from previous works. This observation raises concerns about the novelty and contribution of the optimization approach. While the comment highlights a specific area that needs clarification, it does not provide detailed guidance on how to address this issue or suggest specific improvements. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue regarding the related work section, specifically mentioning the importance of discussing modular networks for Visual Question Answering (VQA). It points out that the current introduction does not adequately address this aspect, suggesting that the authors should include it. However, the comment does not provide explicit guidance on how to incorporate this information or what specific examples or references should be included. The action is implicit, as the authors need to infer that they should add a discussion of modular networks for VQA, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to mention related work on modular networks for VQA, such as A, to provide context and relevance to the introduction. This provides the authors with a clear understanding of what needs to be addressed in the related work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not adequately address related work on modular networks for Visual Question Answering (VQA). It suggests that including this information is crucial for the introduction to paint an accurate picture of the field. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the claim is 3, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the related work section by pointing out the absence of discussion on modular networks for Visual Question Answering (VQA). This is a significant oversight, as it could mislead readers into thinking that no one uses modular architectures in this field. By highlighting this omission, the comment provides the authors with a clear and actionable suggestion to enhance the introduction and related work sections. However, the comment could be more helpful if it offered specific examples or references to include in the discussion of modular networks for VQA. Overall, the feedback is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the authors\" discussion by noting that they primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. While the comment identifies a specific area where the authors could improve their discussion, it does not provide explicit guidance on how to address this gap or what specific aspects of the contrast should be included. The action is implicit, as the authors need to infer that they should expand their discussion to include these methods. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and the lack of contrast with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the contrast between the authors\" method and other computationally efficient subspace clustering methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not adequately contrast their method with other computationally efficient subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the authors\" discussion by pointing out that they primarily focus on SSC without adequately contrasting their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is 3 as it highlights an area where the authors could enhance their discussion and provide a more comprehensive comparison of their method with existing approaches. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this gap, such as suggesting additional references or a detailed comparison of the methods. Overall, the comment offers a clear direction for improvement, but it could be more impactful with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or RL is not used. This feedback is explicit and provides a clear action for the authors to take: they should include the missing cases in the tables to accurately represent the ablation study. The comment is specific and concrete, giving the authors a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance drop and the missing cases in the tables, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without the dependency tree, and that the two tables do not list the cases where either dependency tree or reinforcement learning is not used. This claim is 3 as it highlights a specific issue in the ablation experiment results, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to refer to the tables to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or reinforcement learning is not used. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By including the missing cases in the tables, the authors can accurately represent the ablation study and enhance the clarity of their results. The comment is 4 as it offers a clear direction for improvement, though it could be more comprehensive if it suggested additional ways to present the data or discuss the implications of the findings. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It highlights that the results are presented only on the CIFAR10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment does not provide explicit guidance on how the authors should expand their experiments or what specific datasets or model types they should consider. While the action is implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely that they are limited to the CIFAR10 dataset and do not consider other datasets from federated learning benchmarks. The comment provides specific examples of relevant datasets and suggests considering additional works for details on different datasets and model types. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments section is a main weakness of the paper, as the results are presented only on the CIFAR10 dataset and do not consider other datasets from federated learning benchmarks. The comment suggests considering datasets from the LEAF benchmark and recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to infer the need for a more comprehensive evaluation based on the provided information, which limits the verifiability of the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It points out that the results are presented only on the CIFAR10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is 4 as it provides clear guidance on how the authors can enhance the comprehensiveness of their experimental evaluation, which is crucial for addressing the main weakness of the paper. However, it could be more helpful if it included specific suggestions on which datasets or model types to consider, making it fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should use another dataset for the ablation study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the claim made in the paper regarding the improvement of proposed modules in accuracy and completeness, referencing a table. However, it does not specify which part of the paper the claim is made or which table is being referred to, making it weakly grounded. The comment is specific in questioning the validity of the claim and suggesting an alternative dataset for the ablation study, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using a different dataset, it does not provide specific reasoning or examples to support why this alternative dataset would be beneficial. The suggestion is somewhat vague and lacks detailed justification, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2, as it provides some basis for consideration but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D, to provide a more comprehensive evaluation. This feedback is 3 as it identifies a potential area for improvement in the experimental setup and encourages the authors to consider using additional datasets for a more robust analysis. However, the comment could be more helpful if it provided specific guidance on how to implement the suggestion or why the additional datasets would be beneficial. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their methodology. The feedback is somewhat vague and lacks concrete suggestions, making it challenging for the authors to understand how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not specify which part of the paper discusses the methodology or the results, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and the difficulty in interpreting the results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It also notes that previous work has considered multiple vulnerabilities simultaneously, which the authors have not addressed. The comment suggests that the results are difficult to interpret, implying a lack of clarity in the findings. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to provide more detailed reasoning or evidence to address these concerns effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It also notes that previous work has considered multiple vulnerabilities simultaneously, which the authors have not addressed. The comment suggests that the results are difficult to interpret, implying a lack of clarity in the findings. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The feedback provides a clear direction for the authors to consider alternative approaches or to expand their methodology to include multiple vulnerabilities. While it could be more detailed, the comment offers valuable insights that could guide the authors in improving their study. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also points out that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it does not explicitly instruct the authors to provide these details or suggest specific ways to improve the explanations. The action is implicit and somewhat vague, as the authors are left to infer that they should add these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the need for more details in the definition of the resistance distance and the explanations for Algorithm 1, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also suggests that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it lacks specific examples or references to support the claim that more details are necessary. The feedback is 3 as it provides a general suggestion but does not offer detailed reasoning or evidence to justify the need for more details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies areas where the paper could be improved, specifically mentioning the need for more details in the definition of the resistance distance and additional explanations for Algorithm 1. While it acknowledges that the writing is generally good, it provides specific suggestions for enhancing clarity and comprehensibility. This feedback is 4 as it offers actionable insights for the authors to improve their draft, but it could be more comprehensive if it included additional suggestions or examples of how to provide these details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment implies that the authors should consider including such results, it does not explicitly instruct them to do so or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should include quantitative results on testing images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the shape model invariance study, specifically questioning the sufficiency of evaluation on training images. However, it does not specify which part of the paper this study is located in, making it weakly grounded. The comment is specific in its request for quantitative results on testing images, which would enhance the evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment does not contain a subjective claim or opinion, it poses a logical question that could be addressed with additional information or justification. However, without further context or explanation, the claim is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the point.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the evaluation for the shape model invariance study. It questions whether the current evaluation, which focuses on transformations of training images, fully supports the claim. The comment suggests that additional quantitative results on testing images might be necessary to strengthen the study. This feedback is 3 as it identifies a potential gap in the evaluation and prompts the authors to consider expanding their analysis. However, it could be more helpful if it provided specific guidance on how to conduct the additional testing or what kind of results would be expected. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment implies that this related work should be discussed and compared against to provide a better understanding of the stateoftheart. However, it does not explicitly instruct the authors to include or discuss this work in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this omission. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should discuss and compare their work against this related paper to provide a better understanding of the stateoftheart. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment suggests that this related work should be discussed and compared against to provide a better understanding of the stateoftheart. However, the comment lacks specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is 3, as it provides a basis for improvement but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the related work section by pointing out the omission of a relevant paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. This paper deals with hypergraph data and tensors, which are pertinent to the authors\" work. By suggesting that the authors discuss and compare their approach against this related work, the comment provides a clear direction for improving the paper. It highlights the importance of situating the authors\" contribution within the existing literature, thereby enhancing the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it provided specific guidance on how to discuss or compare the works, such as suggesting specific aspects of the related work that should be addressed. Overall, the comment is 4 as it identifies a crucial area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two main concerns regarding the computational cost and scalability of the optimal transport distance calculation. It questions whether the method scales on normal machines with a few cores and asks for clarification on how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. While the comment identifies specific areas for clarification and potential improvement, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer how to respond to the questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational cost and scalability of the optimal transport distance calculation, specifically questioning whether the method scales on normal machines with a few cores. It also asks for clarification on how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. However, the comment does not specify which part of the paper discusses the optimal transport distance calculation or where the authors can find more information about the Sinkhorn method. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issues with scalability and the computation of exact optimal transport, but without explicit grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the scalability of the optimal transport distance calculation on normal machines with a few cores and the method used to compute the exact optimal transport from the doubly stochastic matrix produced by the Sinkhorn method. While the comment highlights potential issues with the method\"s scalability and computational cost, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed explanation or evidence makes it difficult for the authors to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises important questions about the scalability and computational cost of the optimal transport distance calculation, which is a critical aspect of the paper. It points out that while the method is claimed to be efficient on a 36core machine, it is unclear how it scales on normal machines with a few cores. Additionally, the comment questions how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. These questions are valuable for the authors to address, as they highlight potential limitations and areas for clarification in the paper. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting alternative methods or providing additional details on the computation process. Overall, the comment is 3 as it identifies key areas for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models in the image domain (CNNs). However, the comment does not provide explicit guidance on how to conduct this exploration or what specific steps the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. The comment implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models in the image domain (CNNs), which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models in the image domain (CNNs). However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the parameters are limited to ViT. Without additional evidence or justification, the claim remains 3, as it lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models in the image domain (CNNs). This feedback is 3 as it points out a potential limitation in the scope of the study and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what additional experiments might be necessary. Overall, the comment offers a valuable insight but lacks detailed actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis. It suggests that the significance of the paper is poor due to this lack of clarity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need clarification. The action is implicit, as the authors would need to infer that they should elaborate on the practical applications of tensor networks in machine learning. The comment is vague and lacks concrete details on how to improve the paper, making it 3.", "grounding_specificity_rationale": "The comment addresses the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis, questioning the clarity of this aspect. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in identifying the issue with the clarity of the paper, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the significance of the paper is poor because it does not clearly explain how tensor networks are useful for machine learning algorithms or analysis. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as it is based on a logical argument but lacks sufficient substantiation.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the utility of tensor networks in representing the PMF of discrete variables for machine learning algorithms or analysis. It suggests that the significance of the paper is poor due to this lack of clarity. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the paper\"s clarity. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable value, as it lacks detailed advice or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the extent to which the observations generalize to fewshot learners beyond Prototypical Networks is not evaluated. This observation suggests that the paper\"s contributions may be limited in terms of understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability of their observations. The action is implicit and vague, as it leaves the authors without a clear understanding of how to proceed with the evaluation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the generalizability of observations to fewshot learners beyond Prototypical Networks, which is a clear and specific concern. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in detailing the issue, as it highlights the limitation in evaluating the generalizability of the observations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the extent to which the observations generalize to fewshot learners beyond Prototypical Networks is not evaluated, which may limit the scope of the submission\u2019s contributions. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that the extent to which the observations generalize to fewshot learners beyond Prototypical Networks is not evaluated. This observation is important as it may limit the scope of the paper\"s contributions in understanding the properties of episodic training. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or expand their analysis to include fewshot learners. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it points out a relevant limitation but does not offer constructive feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what changes should be made to the paper. The action is implicit and vague, leaving the authors without a clear understanding of how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue, it lacks grounding as it does not provide explicit references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide specific guidance or suggestions on how to address this issue or what changes should be made to the paper. While it identifies a potential problem, it lacks actionable advice, making it 3. The authors would need to infer the need for further clarification or discussion, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the abstract effectively explains the proposed idea but does not provide details on how the idea was evaluated or what the outcome was. It also mentions minor language issues. While the comment identifies a gap in the abstract\"s content, it does not explicitly instruct the authors to include details about the evaluation process or the outcome. The suggestion to address minor language issues is vague and lacks specific guidance. Therefore, the comment is 3, as it highlights an area for improvement but does not provide clear instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding how the proposed idea was evaluated and what the outcome was, as well as mentioning minor language issues. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks details on how it was evaluated and what the outcome was. It also mentions minor language issues. However, the comment does not provide any specific examples or references to support the claim about the lack of detail in the evaluation process or the outcome. The mention of minor language issues is vague and lacks specific examples or references. Therefore, the claim is 1 due to the lack of supporting evidence or justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the abstract, noting that while it effectively explains the proposed idea, it lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include additional information that would enhance the comprehensiveness of the abstract. However, the comment could be more helpful if it provided specific examples or suggestions for how to include this information. Overall, the comment is 4 as it highlights a clear area for improvement and provides a basis for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a confusion regarding the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for the target domain \tau is unlabeled, which is inconsistent with the original MFDA paper (Yue et al., 2021a). The comment suggests that the authors should clarify the use of unlabeled data in source domains during training, as it is unclear whether this is consistent with the original paper. While the comment identifies a specific issue and suggests a clarification, it does not provide explicit instructions on how to address the confusion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potentially make revisions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the MFDA setting, particularly the confusion regarding the notation for the target domain \tau and the use of unlabeled data in source domains during training. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the consistency of the description of the MFDA setting with the original paper (Yue et al., 2021a). It highlights a specific discrepancy regarding the notation for the target domain \tau and the use of unlabeled data in source domains during training. The comment suggests that the authors should clarify this aspect to align with the original paper, which is a logical and verifiable claim. However, the comment could be strengthened by providing more detailed reasoning or examples to support the claim. Overall, the comment is 4, as it provides a clear basis for the authors to address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue in the description of the MFDA setting within the Method Section, particularly concerning the notation for the target domain \tau and the use of unlabeled data in source domains during training. It highlights a discrepancy with the original MFDA paper (Yue et al., 2021a), which is a crucial point for clarity and consistency. The comment is 4 as it points out a potential confusion that could affect the understanding of the method. However, it could be more helpful if it provided suggestions on how to clarify the description or address the inconsistency, making it actionable for the authors. Overall, the feedback is valuable and directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that epochwise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the progress of algorithms after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of the algorithms should be examined. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis, especially for finite sum settings, could provide insights into the behavior of optimization algorithms. It provides specific examples, such as investigating the effects of batch size and different sampling strategies on the progress of algorithms after each full pass of the data. This guidance is clear and specific, as it outlines potential areas for further analysis and comparison between deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be applied to, making it weakly grounded. Despite this, the specific suggestions for analysis and comparison provide clear guidance for the authors. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis, especially for finite sum settings, could provide insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the progress of algorithms after each full pass of the data. This claim is 3 as it provides a logical reasoning for why such analysis could be beneficial, but it lacks specific examples or references to support the claim fully. The suggestion to use this analysis for comparative studies between deterministic and stochastic methods is also clear but could benefit from more detailed examples or references. Overall, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence.", "helpfulness_rationale": "The review comment suggests that epochwise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the progress of algorithms after each full pass of the data. This could help with comparative analysis between deterministic and stochastic methods. While the comment provides a clear direction for potential improvements, it lacks specific guidance on how the authors should conduct this analysis or what aspects of the algorithms should be examined. The feedback is 3 as it identifies a potential area for further exploration but does not provide detailed instructions or examples to fully enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the authors\" claim about the immense workload but disagrees with the assessment of the paper\"s contribution as incremental. It suggests that the paper is essentially a combination of GraphRAG and GraphCare 1 and points out that many key baselines were not cited. The comment also notes that essential RAG algorithms for EHR, such as MedRetriever 2, and commonly used GraphRAG algorithms like KGRAG 3, should have been introduced. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific sections to revise or how to incorporate the missing information. While the action is somewhat implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" claim about the immense workload and the incremental contribution of the article, referencing GraphRAG and GraphCare 1. It also specifies the issue of missing key baselines and suggests the inclusion of essential RAG algorithms for EHR, such as MedRetriever 2, and commonly used GraphRAG algorithms like KGRAG 3. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" contribution is incremental and suggests that the paper is essentially a combination of GraphRAG and GraphCare 1. It also points out that many key baselines were not cited and recommends including essential RAG algorithms for EHR, such as MedRetriever 2, and commonly used GraphRAG algorithms like KGRAG 3. The claim about the incremental contribution is 3 as it provides a basis for comparison with existing work, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include specific algorithms is clear and actionable, making the comment 4. Therefore, the label is 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the authors\" work, highlighting the immense workload and the incremental contribution of the article. It suggests that the paper is essentially a combination of GraphRAG and GraphCare 1, which implies that the novelty of the work is limited. Additionally, the comment points out that many key baselines were not cited, and it recommends including essential RAG algorithms for EHR, such as MedRetriever 2, and commonly used GraphRAG algorithms like KGRAG 3. This feedback is 4 as it offers specific suggestions for improvement, such as expanding the literature review and including additional baselines. However, it could be more helpful if it provided more detailed guidance on how to address these issues or suggested specific sections of the paper that need revision. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the issue. It questions the annotators\" consideration of local regulations and their impact on zeroshot crosscountry classification. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the distinction between the two types of speech. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Paper Summary,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. The comment is specific in detailing what needs to be addressed, including the need for clearer differentiation and clarification regarding the impact of local regulations on annotations and classification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the distinction between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. It also questions the role of local regulations in the annotations and their impact on zeroshot crosscountry classification. However, the comment lacks specific examples or references to support the claim that the distinction is difficult to make or that local regulations are not adequately considered. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the differentiation between derogatory and exclusionary extreme speech, which is a crucial aspect of the paper. It provides an example from the sample data file to illustrate the confusion, making the feedback more concrete and actionable for the authors. However, the comment could be more helpful if it offered suggestions on how to improve the distinction or clarify the role of local regulations in the annotations. Despite this, the feedback is 4 as it directs the authors to an area that needs attention and provides a clear example to guide their revision efforts."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should make the paper mathematically correct, but it acknowledges that this might make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment provides some guidance, it does not explicitly instruct the authors on how to make the paper mathematically correct or how to introduce the notation L_l. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" which indicates a figure in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the paper, such as making the content mathematically correct and introducing the notation L_l beforehand. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the mathematical correctness of the paper and suggests that the notation L_l should be introduced beforehand. However, the comment lacks specific examples or references to support these claims. Without detailed reasoning or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical correctness of the paper and suggests that the notation L_l should be introduced before its use. While it acknowledges that making the paper mathematically correct might complicate other equations, it provides a clear direction for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to achieve mathematical correctness or introduced the notation L_l. Overall, the feedback is 3 as it points out an area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, noting that the baseline and timeaware models show similar performance. It suggests that the proposed method might be more effective under different timestep scenarios. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same, suggesting that the method might be more effective under different scenarios. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, based on the observation that Figure 5 shows similar performance between the baseline and timeaware models. While the comment identifies a potential issue, it does not provide specific examples, detailed reasoning, or references to support the claim that the effectiveness of the proposed methods is questionable under these conditions. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as evidenced by the similar performance shown in Figure 5. The comment suggests that the proposed method might be more effective under different timestep scenarios, which is a relevant point for consideration. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments or analyses could be conducted to strengthen the evaluation. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the mechanisms and guarantees of disentanglement. However, the comment does not specify exactly how this should be done, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to disentangled latent vectors. However, the comment does not specify which part of the paper discusses disentanglement or how it is realized. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of disentanglement, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is 3 as it points out a specific area where the paper could be clearer, but it lacks detailed examples or references to support the claim. The authors would need to infer the need for more explanation, which could be improved with additional details or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation regarding disentanglement. However, the comment could be more helpful if it provided specific examples or suggestions for how to address this issue. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the objective equation. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed objective equation requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S, and it highlights the lack of discussion regarding the effect on the number of parameters compared to prior work, such as AlignFlow. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed objective equation requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S, and it notes that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth to fully substantiate the authors\" concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. It highlights a lack of discussion regarding the effect on the number of parameters compared to prior work, such as AlignFlow. This feedback is clear and actionable, as it directs the authors to address the optimization process and provide a detailed comparison with existing methods. However, the comment could be more helpful if it suggested specific ways to improve the discussion or provide additional context. Overall, the comment is 4, as it offers valuable insights and guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between Eq. 4 and Eq. 3, specifically whether the u^l in Eq. 3 tending to be 1 implies an improvement in the designed solutions. It also notes that the improvement in Table 5 is marginal on some datasets, such as OfficeHome, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the relationship between Eq. 4 and Eq. 3, specifically whether the u^l in Eq. 3 tending to be 1 implies an improvement in the designed solutions. It also notes that the improvement of the designed solutions in Table 5 is not significant on some datasets, such as OfficeHome, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not specify which part of the paper these equations are located in, making it difficult for the authors to pinpoint the exact issue. While the comment provides some specificity by mentioning the equations and the datasets, it lacks full grounding as it does not explicitly mention the sections or tables where these equations are discussed. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the relationship between Eq. 4 and Eq. 3, specifically whether the u^l in Eq. 3 tending to be 1 implies an improvement in the designed solutions. It also notes that the improvement of the designed solutions in Table 5 is marginal on some datasets, such as OfficeHome, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not provide any specific reasoning or evidence to support the claim that the improvement is marginal or that the relationship between the equations is as suggested. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim, rendering it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the relationship between Eq. 4 and Eq. 3, specifically whether the u^l in Eq. 3 tending to be 1 implies an improvement in the designed solutions. It also notes that the improvement of the designed solutions in Table 5 is marginal on some datasets, such as OfficeHome, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This feedback highlights a potential issue with the significance of the improvement, which could be a valuable point for the authors to consider. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, it does not provide actionable steps or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not \"Whtypes\"/transformable. However, it does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary. The comment lacks concrete guidance on how to improve the generalization of the model or what specific modifications could be made to the template mapping. As a result, the authors are left without a clear understanding of how to apply the feedback to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the question answering process, specifically mentioning the template mapping and its potential impact on generalization to questions that are not \"Whtypes\"/transformable. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the question answering process might cause poor generalization to questions that are not \"Whtypes\"/transformable due to the template mapping. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not \"Whtypes\"/transformable. This feedback is 3 as it highlights a specific area that could be improved, but it lacks detailed guidance or suggestions on how to address this issue. The authors are left without a clear understanding of what changes might be necessary to enhance the generalization of their model. While the comment points out a potential weakness, it does not provide actionable steps or examples to improve the question answering process. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that comparing the model\"s performance only on pretrained synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by showing performance on realworld datasets with different losses. While the comment implies that the authors should include results from finetuning on realworld datasets, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this. The action is implicit and somewhat vague, as the authors are left to infer that they need to include additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of comparing model performance only on pretrained synthetic data, which is an important aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to demonstrate the importance of the proposed three projection errors by providing performance on realworld datasets with different losses. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that comparing the model\"s performance only on pretrained synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors by showing performance on realworld datasets with different losses. While the comment provides a logical argument for why the suggested approach is more comprehensive, it lacks specific examples or references to support the claim. The reasoning is clear, but the absence of detailed evidence or examples makes it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the model\"s performance, specifically that it is limited to pretrained synthetic data. It suggests that demonstrating the importance of the proposed three projection errors by showing performance on realworld datasets with different losses would be a more comprehensive approach. This feedback is clear and actionable, providing a specific direction for the authors to improve their evaluation methodology. However, it could be more helpful if it included suggestions on how to conduct these additional experiments or what specific metrics to use. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests that the authors should consider averaging over subword representations, a common practice in certain cases, and provides a specific reference to support this suggestion. This action is clear and concrete, as it directly instructs the authors on how to improve their draft by incorporating a common practice. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (L.490), allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, a common practice, and references a specific paper to support this suggestion. This provides the authors with a clear understanding of what needs to be addressed and how to do it, making the comment 5.", "verifiability_rationale": "The review point claims that it is common to average over subword representations in certain cases, providing a specific reference to support this claim. This allows the authors to understand the basis of the suggestion and potentially incorporate it into their work. However, the comment could be more robust if it included a brief explanation of why averaging is a common practice or provided additional examples. Overall, the claim is 4, as it is supported by a reference but lacks some depth in explanation.", "helpfulness_rationale": "The review comment identifies a specific detail in the paper, namely the use of the first subword token\"s embedding as the verb embedding, and suggests that averaging over subword representations is a common practice in similar cases. It provides a specific reference to support this suggestion, which could help the authors understand the context and potentially improve their approach. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or discussed the potential benefits and drawbacks of averaging. Overall, the comment is 3 as it provides a clear direction for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not provide explicit guidance on how to implement these suggestions or actions, such as specific steps or examples of how to conduct the calibration curves or discuss the differences. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC\"s ability to assess discriminant ability and suggests that it may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not specify which part of the paper discusses the model AUC or where the calibration curves or feasibility discussion should be included. This makes it weakly grounded, as the authors cannot confidently determine which sections are relevant. The comment is specific in detailing the issues and suggestions, such as conducting calibration curves and discussing differences. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the consistency of the model AUC with actual risk and suggests that calibration curves could help demonstrate this consistency. It also recommends discussing the differences between the traditional method and the proposed method. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the feedback. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the model AUC\"s ability to demonstrate consistency with actual risk, suggesting that calibration curves could be used to address this. It also recommends discussing the differences between the traditional method and the proposed method, which could provide valuable context and comparison. However, the comment lacks specific guidance on how to implement these suggestions or what specific aspects of the model AUC should be addressed. While it provides a general direction for improvement, it does not offer detailed actionable feedback that would be 5 to the authors. Therefore, the comment is 3, as it offers some insights but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues related to the paper\"s content. First, it notes that the range of ID and OOD does not change much with sparsification, as shown in Figure 4. Second, it points out that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires approximately identical means, which is crucial for DICE but not well discussed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification, as shown in Figure 4, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment lacks specific examples or references to support the claim that these conditions are crucial for DICE. Without detailed reasoning or evidence, the claim is difficult to verify, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the lack of change in the range of ID and OOD with sparsification, as shown in Figure 4, and the insufficient discussion of Lemma 2\"s requirements, particularly the need for approximately identical means for DICE. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. While the feedback highlights areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The comment is 3 as it points out specific weaknesses but does not offer comprehensive advice or detailed steps for improvement, leaving the authors with a clear direction but limited actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, including questions about the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to strengthen their experiments, include missing baselines, and discuss limitations and societal impacts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the strength and fairness of the experiments, questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. However, the comment does not specify which part of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several concerns about the strength and fairness of the experiments, specifically questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out important aspects that need attention, but it could be more comprehensive with additional suggestions or examples to guide the authors in enhancing their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the observed results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not provide explicit instructions on how the authors should address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to clarify the results and improve the presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the question about the sparsity patterns and the suggestion to clarify whether the results are specific to the sparsity detection problem or generalizable to GNNs in general. Additionally, it points out that the presentation of bits in Section 4.3 could be improved. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment lacks specific examples or references to support the claim that the sparsity patterns do almost equally well and that there is no insight provided. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the sparsity patterns observed in the paper, suggesting that they do almost equally well and that there is no insight provided to explain this phenomenon. It also points out that the presentation of bits in Section 4.3 could be improved. While the comment identifies an area that needs clarification, it does not provide specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it highlights potential areas for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two distinct points. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is somewhat explicit but could be more detailed, as it does not provide specific guidance on how to address this concern or what additional assumptions might be considered. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a concrete action that the authors can take to correct the error. However, the first part of the comment is somewhat vague and lacks detailed guidance, making the overall comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first para of Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, questioning the claim about \"significant additional assumptions\" and suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set. Additionally, it points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point contains two claims: one questioning the claim about \"significant additional assumptions\" in the first paragraph of Section 3.2, and another pointing out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. The first claim is 3 as it provides a specific example of a common assumption in machine learning, which partially supports the reviewer\"s argument. However, it lacks detailed reasoning or references to substantiate the claim fully. The second part of the comment is more verifiable as it points out a specific error in the inequality, which can be addressed with a correction. Overall, the comment is 3, as it provides some justification but lacks comprehensive evidence or references for the first claim.", "helpfulness_rationale": "The review comment provides specific feedback on two distinct issues. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, a common assumption in machine learning. This feedback is 3 as it challenges the authors to reconsider the scope of their assumptions and potentially refine their claims. However, it could be more helpful if it provided guidance on how to address this concern or what additional assumptions might be considered. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a clear and actionable suggestion that the authors can easily address by correcting the inequality. Overall, the comment is 4 as it provides specific feedback on an error and challenges a claim, but it could be more comprehensive with additional guidance on the first point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, leaving the authors to infer that it should be done in the context of the related work. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or references, the claim remains 3, as it is based on an assumption rather than a wellsupported argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a comparative analysis. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the comparison should be included. Without detailed examples or suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide explicit guidance on how to conduct this examination or what specific aspects of the performance should be analyzed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests examining the performance with different numbers of scenarios, implying that the number of scenarios used for training might influence the results. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting an area for further examination, but without clear guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the performance of the paper might be influenced by the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment lacks specific guidance on how to conduct this examination or what aspects of the performance should be analyzed. While it identifies a potential area for improvement, it does not provide actionable steps or detailed suggestions, making it 3. The authors would need to infer the necessary actions, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It also suggests considering the impact of disturbances in the training data on the model\"s performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what actions they should take to improve their draft. The feedback is vague and lacks concrete details, making it difficult for the authors to understand how to respond or incorporate the suggestions. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s performance. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the impact of disturbances, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it, specifically questioning whether disturbances in the training data might affect the model\"s performance. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or logical reasoning to substantiate the concern, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests considering the impact of disturbances in the training data on the model\"s performance, which is a valuable point for the authors to explore. However, the comment lacks depth and specificity, as it does not provide detailed guidance or suggestions on how the authors might address this issue or what experiments could be conducted to investigate it. Without actionable advice or a clear framework for improvement, the comment is 3, as it identifies an area for further consideration but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that Appendix A.2 does not illustrate the state space representation of the environment clearly. While it points out a specific area that needs improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the representation in the appendix, but without specific suggestions or examples, the action remains implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment specifically mentions \"Appendix A.2,\" providing clear grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the state space representation is not illustrated clearly, offering a clear direction for improvement. This comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation illustrated in Appendix A.2. This feedback is clear and actionable, as it directs the authors to improve the clarity of their appendix. However, the comment lacks broader context or suggestions on how to enhance the clarity, such as providing more detailed explanations or examples. While it points out a specific area for improvement, it does not offer a comprehensive guide for the authors to address the issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the restrictive nature of the bounded noise assumption in stochastic optimization literature and mentions several efforts to extend these noise conditions, citing specific works. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative assumptions or exploring the cited works. The comment lacks concrete guidance on how the authors might address the issue or incorporate the suggested references. As a result, the authors are left without clear direction on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the bounded noise assumption in stochastic optimization literature, referencing specific works that extend these noise conditions. However, it does not specify which part of the paper discusses the bounded noise assumption or how it relates to the authors\" work. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment mentions specific works, it does not provide detailed guidance on how these works could be integrated or discussed in the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the bounded noise assumption, while common, is somewhat restrictive in stochastic optimization literature. It provides references to specific works that have extended these noise conditions, such as A. Khaled and P. Richt\u00b4arik. Better theory for sgd in the nonconvex world. TMLR 2023. R. Gower, O. Sebbouh, and N. Loizou Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021. However, the comment does not offer a detailed explanation of why the bounded noise assumption is restrictive or how the cited works address this limitation. While the references are provided, the reasoning behind the claim is not fully elaborated, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the bounded noise assumption, which is a common assumption in stochastic optimization literature. It acknowledges that this assumption is somewhat restrictive and points out several efforts to extend these noise conditions, citing specific works. However, the comment does not provide actionable guidance or suggestions on how the authors might address this limitation or incorporate the suggested references into their work. While it highlights an important aspect of the literature, the lack of concrete advice limits its helpfulness to the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the motivation need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not specify which part of the paper discusses this motivation, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is specific in identifying the issue but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the overall motivation of using characteristic function regularization is not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the motivation is unclear or how to address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the motivation behind using characteristic function regularization. However, it lacks specific details or suggestions on how the authors might address this issue or what aspects of the motivation need clarification. Without actionable guidance or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It claims that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the paper or what specific aspects need to be addressed to enhance the contribution. As a result, the comment is 1, as the authors are left without a clear path forward to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of existing techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a detailed description of the techniques used and suggests that the combination of these techniques is not surprising, implying that the contribution might be incremental. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or evidence to substantiate the assertion that the combination of these techniques is not surprising or that the contribution is incremental. As a result, the claim is 1 due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by suggesting that the combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, might not be surprising. This observation implies that the contribution of the paper could be considered incremental. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address this concern or enhance the novelty of their work. While it raises a valid point about the incremental nature of the contribution, it lacks depth and guidance, making it 3. The authors would need to infer what steps to take to improve their draft, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. While it prompts the authors to clarify the term, it does not explicitly instruct them to provide a definition or explanation. The action is implicit, as the authors need to infer that they should clarify the meaning of \"100 steps\" to avoid confusion. However, the comment lacks concrete guidance on how to clarify this, such as suggesting specific examples or comparisons. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"100 steps\" in the context of the search models comparison, specifically questioning whether it refers to 100 sampled strategies. This provides a clear and precise request for clarification, enabling the authors to understand the exact issue being raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically asking whether it refers to 100 sampled strategies. This is a factual question that requires clarification but does not contain any subjective opinions or claims that need verification. The comment is essentially a request for clarification, which is a normal statement. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the meaning of \"100 steps\" in the context of search models comparison, which is crucial for understanding the methodology. By asking whether \"100 steps\" refers to 100 sampled strategies, the comment highlights a potential ambiguity in the paper that could lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify their methodology. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, suggesting that the authors should consider this in their work. However, the comment does not provide explicit guidance on how the authors should explore energy models or how they should address the similarity to the prior VAE paper. The action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, suggesting that the authors should consider this in their work. However, the comment does not specify which part of the paper discusses energy models or how the motivation and goals are similar to the prior VAE paper. This makes it difficult for the authors to identify the specific sections or parts of the paper that need attention. The comment is weakly grounded as it does not provide explicit references or sections, but it is specific in suggesting the exploration of energy models and the need to address the similarity to the prior VAE paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that energy models for image generation are less explored compared to GANs and VAEs, suggesting that exploring them further is a promising direction. It also notes that the motivation and goals of the model are similar to a prior VAE paper, implying that the authors should consider this in their work. However, the comment lacks specific examples or references to support the claim about the relative unexploredness of energy models, making it difficult for the authors to fully understand and address the feedback. The reasoning is somewhat vague, and the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, which could help the authors contextualize their work. However, the comment lacks specific guidance on how the authors should explore energy models or how they should address the similarity to the prior VAE paper. While it provides a direction for future work, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity in its recommendations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the method should be evaluated on a different benchmark, such as Atari, to assess its generalizability to other domains. It provides a clear and concrete action for the authors to take, which is to run experiments on this new benchmark. This guidance is specific and detailed, allowing the authors to understand exactly how to apply the suggestion. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain and suggests running experiments on a different benchmark, such as Atari, which is a common practice in the literature. This provides clear guidance on which part of the paper needs improvement. The comment is also specific, as it specifies the need to evaluate the method on a different benchmark to assess its generalizability and performance with discrete action spaces and highdimensional observations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on the Meta World domain, making it difficult to judge its generalizability to other domains. It suggests running experiments on a different benchmark, such as Atari, to verify the method\"s performance with discrete action spaces and highdimensional observations. This claim is 3 as it provides a logical reasoning for why the evaluation on a single domain is insufficient and suggests a specific alternative benchmark. However, it lacks detailed examples or references to support the claim fully, which could enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, noting that it is only tested on the Meta World domain. This makes it challenging to assess the generalizability of the results to other domains. The comment strongly suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This recommendation is clear and actionable, providing the authors with a specific direction to improve the robustness and applicability of their method. By addressing this issue, the authors can gain a more comprehensive understanding of their method\"s performance across various domains. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the model\"s behavior should be examined. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply the suggested action. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in or what aspects of the model\"s behavior should be examined. The comment lacks grounding as it does not provide clear guidance on which section or part of the paper needs attention. It is also specific in suggesting the inclusion of an analysis, but without detailed guidance on how to conduct it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment acknowledges the strengths of the paper, such as the presentation of the method and the quality of the experiments, but identifies a significant weakness: the lack of analysis on what the model does. This feedback is valuable as it highlights an area where the authors could enhance their work by providing a deeper analysis of the model\"s behavior. However, the comment could be more helpful if it suggested specific ways to conduct this analysis or provided examples of what kind of analysis would be beneficial. Overall, the comment is 3 as it points out a crucial aspect that needs improvement, but it lacks depth and actionable guidance, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide explicit guidance on how the authors might address these issues or what specific actions they should take to improve the modulator. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to understand how to apply it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not specify which part of the paper discusses the modulator or where the issue of scalability is addressed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific in its critique of the modulator\"s design, the absence of explicit references to the paper\"s sections or content limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the heuristic design of the modulator, suggesting that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the heuristic design of the modulator, specifically questioning its scalability and the need for tedious hyperparameter tuning for diverse training data. This feedback highlights a concern that could impact the practical applicability and robustness of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the modulator. While it points out a potential weakness, it does not provide actionable steps or detailed insights that would help the authors enhance their work. Therefore, the comment is 3, as it raises a valid concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might be impractical for less informed functions like f_R/f_P. However, it does not provide explicit guidance on how the authors should address this issue or what changes could be made to the experiments to reduce the reliance on domain knowledge. The action is implicit and vague, as it does not specify how the authors can incorporate less domain knowledge or what experiments could be modified. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"f_R and f_P\" and \"experiments performed here,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the issue of incorporating domain knowledge into the structure of the experiments, suggesting that less informed functions might require impractical amounts of data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might be impractical for less informed functions like f_R/f_P. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains 3, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments performed in the paper, specifically noting that the incorporation of domain knowledge might be impractical for less informed functions like f_R/f_P. While the comment highlights a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the experiments. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and implement the suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of imitation learning, suggesting that obtaining labeled data through optimal problemsolving is necessary. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to conduct experiments or analyze the impact of labeled data size. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment raises a concern about the necessity of obtaining labeled data for imitation learning, suggesting that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its critique, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of obtaining labeled data for imitation learning and suggests that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of imitation learning, specifically questioning the necessity of obtaining labeled data and the lack of experiments on the challenges and performance changes associated with different sizes of labeled data. While the comment highlights a gap in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential area for further exploration, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment identifies a potential issue with the paper, it does not provide explicit guidance on how the authors should address this concern or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should explore the connection between memorization and generalization bounds. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of the connection between memorization and generalization, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. The comment suggests that the paper does not adequately address this connection, implying a need for further exploration or clarification. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the paper does not connect memorization and generalization bounds. Without these elements, the claim is 3, as it provides a basis for the authors to consider but lacks sufficient depth to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment identifies a potential area for clarification or further exploration, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a gap in the paper\"s discussion, but it lacks actionable advice or detailed insights that would enable the authors to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. While the comment provides a clear action\u2014mentioning and comparing with untrained neural networks\u2014it does not specify how to implement this comparison or where in the paper this discussion should be included. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments\" and \"imaging in the recent few years,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests mentioning and comparing the current method with untrained neural networks used for solving inverse problems, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. This claim is 3 as it provides a specific example of a relevant area for comparison, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would benefit from additional context or references to fully understand the implications of this comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement in the paper, namely the discussion of outofdistribution (OOD) experiments. It suggests that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. This feedback provides a clear direction for the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it included specific guidance on how to integrate this comparison into the paper or suggested additional relevant literature. Overall, the comment offers valuable insights and actionable feedback, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should conduct additional experiments to include these network structures. However, the comment does not explicitly instruct the authors to perform these experiments or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider including these experiments. However, the comment does not specify which part of the paper these additional experiments should be conducted in or how they would enhance the paper. The lack of specific guidance makes it difficult for the authors to understand exactly what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific details on how these experiments would be conducted or what specific aspects of the paper would benefit from such experiments. The references provided are relevant but do not offer detailed guidance on how to implement the suggested changes. Therefore, the claim is 3, as it provides some justification but lacks depth and specificity.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects of the paper would benefit from such additional experiments. While it identifies a potential area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. While it highlights a potential issue with the clarity of the explanation, it does not provide explicit guidance on how the authors should address this concern or what specific aspects need clarification. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the mechanism. However, the comment lacks concrete details on how to improve the explanation, making it 3.", "grounding_specificity_rationale": "The comment questions the clarity of the explanation regarding why the proposed sample selection mechanism helps preserve the label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its critique but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the explanation regarding the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the clarity of their explanation. The feedback is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the evaluation of the results, noting that while the analysis is detailed and comprehensive, it only considers two relatively old and small models. This feedback provides a clear and explicit action for the authors to take, which is to expand the evaluation to include more recent and larger models. The comment is specific in its suggestion, guiding the authors on what additional models to consider. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results/analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the evaluation is limited to two relatively old and small models, which the authors can address by expanding their evaluation to include more recent and larger models. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results/analysis, despite being detailed and comprehensive, are limited to only two relatively old and small models. This claim is 3 as it provides a specific observation about the scope of the evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors could benefit from additional context or examples to understand the limitations more clearly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the evaluation of the results, noting that despite being detailed and comprehensive, the analysis is limited to only two relatively old and small models. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors should expand their evaluation to include more recent and larger models. By addressing this limitation, the authors can enhance the depth and comprehensiveness of their analysis, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to provide an explanation for the degradation in performance of the FBN results when additional information is included. While it prompts the authors to address this issue, it does not explicitly instruct them on how to do so. The action is implicit, as the authors need to infer that they should provide an explanation for the observed performance degradation. However, the comment lacks specific guidance on what aspects of the additional information might be causing the degradation or how to analyze it. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to provide an explanation for the degradation in performance when additional information is included, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the degradation in FBN results when additional information is included. It does not contain a subjective claim or suggestion but rather poses a question that requires the authors to provide an explanation or analysis. Since the comment is a question rather than a statement that requires verification, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results, noting that the performance degrades when additional information is included. This observation is clear and highlights a potential area for further investigation or clarification. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their results. While it points out a problem, it lacks actionable advice or insights that could help the authors enhance their work. Therefore, the comment is 3, as it identifies a weakness but does not offer substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two specific sections of the paper that are hard to read and points out a lack of clarity in the explanation of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. However, the comment does not offer explicit guidance on how the authors should improve the clarity of these sections or provide specific suggestions for revisions. The action is implicit, as the authors need to infer that they should clarify the explanations in these sections. The lack of concrete guidance makes the comment 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. This level of detail helps the authors understand exactly what needs to be clarified. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises specific questions about the clarity of explanations in the paper, particularly regarding the conversion of a stacked LSTM to a sequential LSTM and the meaning of certain variables in a figure. However, it does not provide any evidence, reasoning, or references to support why these explanations are unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis for these claims. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies specific sections of the paper that are difficult to read, particularly the first two sections, due to the lack of clear explanations of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. This feedback is 3 as it highlights areas where the authors need to improve the clarity of their explanations. However, the comment could be more helpful if it offered suggestions or guidance on how to clarify these sections. Overall, the comment provides a clear indication of areas for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the motivation behind the paper is not clear and suggests that the introduction should be revised to make the paper easier to follow. While the comment identifies a potential issue with the clarity of the motivation, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should revise the introduction to improve clarity. However, the comment lacks concrete details on what aspects of the motivation are unclear, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the motivation behind the paper is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction or the paper is unclear, leaving the authors to infer that the issue lies in the introduction. This lack of specific grounding makes it difficult for the authors to pinpoint the exact areas that need revision. Additionally, the comment does not provide specific examples or suggestions for how to improve the clarity of the motivation or the introduction. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific details or examples to support this claim. It does not provide any evidence or reasoning to justify why the motivation is unclear or how the introduction could be revised to improve clarity. Without such details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the motivation behind the paper, suggesting that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it lacks specific guidance or suggestions on how to revise the introduction or what aspects of the motivation need clarification. This makes the feedback 3, as it points out a crucial weakness but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of multiple local prompts, suggesting that while it is intuitive, the features and their positions vary across different categories. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider the variability in features and positions, but it lacks concrete instructions on how to implement this consideration. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of using multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the variability in features and positions, but the lack of grounding makes it challenging for the authors to understand where to focus their revisions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that while it is intuitive that including multiple local prompts helps, the features and their positions are not the same for different categories. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the consistency of feature representation across categories. While it points out a valid concern, the feedback could be more helpful if it provided actionable advice or examples of how to implement the suggested improvements. Therefore, the comment is 3, as it identifies a meaningful issue but does not fully guide the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might validate the alignment or what specific steps they should follow to ensure it is sufficiently validated. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or aspect of the paper is being referred to, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to validate the alignment or what steps should be taken to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments remains insufficiently validated. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, noting that it remains insufficiently validated. This feedback is clear and actionable, as it highlights a potential weakness in the methodology or experimental setup that could impact the reliability of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as proposing specific validation methods or additional experiments. Overall, the comment is 3 as it points out a critical area for improvement, but it lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the experiments are conducted on a limited number of molecules and only include indistribution testing. The reviewer suggests that the value of the method might be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the draft. The action is implicit and vague, as it leaves the authors to infer the need for additional experiments or a more comprehensive evaluation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of limited experiments on a small number of molecules and the lack of indistribution testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the limitation in the experimental setup and suggests that the value of the method might be limited if it requires individual training for each molecule. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and only provides indistribution testing. This is a factual observation about the scope of the experiments. However, the comment does not provide any reasoning, examples, or references to support why this limitation is significant or how it affects the value of the method. Without additional context or justification, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that the experiments are conducted on a limited number of molecules and only include indistribution testing. This observation is important because it highlights a potential constraint on the value of the method, suggesting that it might be limited if it requires individual training for each molecule. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve the scope of their experiments. While it points out a critical area for improvement, the feedback lacks actionable advice, making it 3. The authors would need to infer how to enhance their draft based on this comment, which limits its overall impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a specific issue with the figure, it does not provide explicit guidance on how to address the question or what changes should be made to the figure. The action is implicit, as the authors would need to infer that they need to clarify the source of the test data and the presence of a ground truth. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line in Figure 3, questioning the source of the test data and the presence of a ground truth. This provides the authors with a clear understanding of what needs to be clarified or addressed. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. This is a factual question that requires clarification but does not contain any subjective opinions or claims that need verification. The comment is a normal statement, as it seeks to understand the source of the test data and the presence of a ground truth, which is essential for the authors to address. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, questioning the source of the test data and the presence of a ground truth. This feedback is clear and actionable, as it directs the authors to clarify the figure\"s content and ensure that the data is properly grounded. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific ways to improve the figure\"s clarity. Despite this, the feedback is 4 as it highlights a critical area for improvement, allowing the authors to enhance the transparency and clarity of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the paper\"s writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide explicit guidance on what specific aspects need improvement or how the authors should address these issues. The feedback is somewhat vague, as it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment expresses concern about the paper\"s writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing or presentation are lacking makes the comment weakly grounded. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not very wellwritten, possibly hurriedly written, and difficult to read. It also mentions issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s writing quality, suggesting that it is rushed and difficult to read. It also points out problems with presentation and formatting, particularly in figures and tables, indicating areas where the paper could be improved. However, the comment lacks specific suggestions or actionable advice on how the authors might address these issues. While it highlights the need for improvement, it does not provide detailed guidance or examples, making it 3. The feedback is valuable but could be more impactful with additional suggestions or constructive feedback. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a point about the novelty of the paper\"s contribution in relation to prior work on double descent in linear regression. It suggests that the paper should better highlight the novelty of its result, particularly in anisotropic settings, where optimal regularization can remove double descent. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their work need to be emphasized. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"samplewise multiple descent\" and \"optimal regularization\" in the context of prior work on linear regression. It clearly specifies what the authors should address in relation to their contribution, which is the novelty of their result in anisotropic settings. However, the comment does not provide specific guidance on how to highlight this novelty or what aspects of the paper need to be emphasized. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper\"s main contribution is the result that optimal regularization can remove double descent even in certain anisotropic settings, given that prior work has shown samplewise multiple descent in linear regression. However, the comment does not provide specific evidence, examples, or references to support this claim. The authors are left to verify the claims independently, which makes the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper\"s contribution by pointing out that prior work has already established the theoretical basis for samplewise multiple descent in linear regression. It suggests that the paper\"s main contribution lies in demonstrating that optimal regularization can remove double descent even in certain anisotropic settings. However, the comment does not provide specific guidance on how the authors should highlight the novelty of their result or what aspects of their work need to be emphasized to address this concern. While it raises an important point about the paper\"s contribution, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what the ablation studies of MCT without the adaptive metrics entail. While the questions prompt the authors to investigate and clarify these aspects, they do not provide explicit instructions on how to address them or what specific actions should be taken. The authors are left to infer that they need to align the results and conduct ablation studies, but without detailed guidance on how to do so, the feedback remains somewhat vague. Therefore, the comment is 3, as it provides a clear direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises two questions regarding the results presented in Table 6 and Table 1, specifically questioning why the results are not aligned and what the ablation studies of MCT without adaptive metrics entail. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections being addressed. While the questions are specific in nature, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the alignment of results in Table 6 with Table 1 and the relevance of ablation studies for MCT without adaptive metrics. However, it does not provide any specific reasoning, examples, or references to support why these questions are important or how they impact the paper. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two questions regarding the alignment of results in Table 6 with Table 1 (MCTpair) and the relevance of ablation studies for MCT without adaptive metrics. While these questions highlight potential areas of concern or confusion, they do not provide specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need clarification or further investigation, but it lacks actionable advice or detailed explanations of how the authors can improve their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks in the paper are too simplistic for the bAbi task and that the final model could solve all of them. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes are needed to make the subtasks more challenging or relevant. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are too simplistic for the bAbi task and that the final model could solve all of them. However, it does not specify which part of the paper these subtasks are discussed in, making it difficult for the authors to identify the exact section or context. While the comment implies that the authors should consider making the subtasks more challenging, it lacks specificity in terms of how to achieve this or what aspects of the tasks need to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for the bAbi task and that the final model could solve all of them. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the 10 subtasks used in the bAbi task. It suggests that the final model might be able to solve all the subtasks, implying that the tasks are too simplistic. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or make the subtasks more challenging. While it points out a potential area for improvement, it does not provide actionable steps or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it highlights a concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks concrete guidance on how to revise the study or clarify its nature. As a result, the authors are left without a clear understanding of what action to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect being discussed. The comment is vague and lacks specificity, as it does not provide any details on what needs to be addressed or how the study should be revised. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the study is not an ablation study. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. This feedback is 3 as it highlights a potential misunderstanding or mischaracterization of the study\"s nature. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the study\"s classification. Without actionable advice or examples, the authors may struggle to understand the implications of this feedback and how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could potentially improve the model. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the model should be considered. The action is implicit, as the authors need to infer that they should explore the possibility of integrating AccNet into a larger predictor. While the suggestion is concrete in terms of the idea, the lack of detailed guidance on implementation makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126\" and the section \"Further Questions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential improvement by including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the model. This provides clear guidance on what needs to be addressed and how the suggestion could be implemented. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation. However, it does not provide any specific reasoning, examples, or references to support why this suggestion would be beneficial or how it could be implemented. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could potentially improve the model. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the model should be considered. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity. The authors would need to infer the exact steps to follow, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. This feedback suggests that the authors should consider expanding the evaluation to include more datasets to provide a more comprehensive assessment of the metric. However, the comment does not specify which additional datasets should be included or how this expansion would be implemented. The action is implicit and somewhat vague, as the authors need to infer that they should test the metric on more datasets to improve its robustness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"new proposed metric,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that the metric is only tested on a single dataset, highlighting a limitation that needs to be addressed. This feedback provides a clear and actionable suggestion for improvement, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset. This is a factual statement that can be verified by examining the experimental setup described in the paper. However, the comment does not provide any additional context, reasoning, or references to support the claim. While the claim is verifiable, it lacks depth and could be strengthened with more detailed explanation or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation of the new proposed metric, noting that it is only tested on a single dataset. This feedback is valuable as it highlights a potential area for improvement, suggesting that the authors should consider expanding their evaluation to include more datasets to provide a more comprehensive assessment of the metric. However, the comment lacks detailed guidance on which additional datasets to include or how this expansion would be implemented. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions for specific datasets or methods for evaluating the metric. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add these comparisons to their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not specify which part of the paper this evaluation is being discussed in, making it weakly grounded. It is specific in suggesting the inclusion of these comparisons, but without clear references to the sections or figures, the authors may find it challenging to identify the exact part of the paper to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the evaluation. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This feedback is 3 as it provides a specific direction for improvement, indicating that the evaluation could be more comprehensive by including comparisons with other relevant architectures. However, the comment lacks detailed guidance on how to implement this suggestion or what specific aspects of the evaluation should be considered. While it offers a valuable insight, the feedback could be more impactful with additional details or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It provides examples of where these definitions are missing, which helps the authors understand the specific areas that need clarification. However, the comment does not offer explicit guidance on how the authors should define these terms or notation. While the authors can infer that they need to address these issues, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific instances in the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation, which provides clear guidance on what needs to be addressed. The inclusion of references to specific papers further enhances the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined, specifically mentioning \"NE\" on L73 and the superscript notation in Eq 6, which is only defined later in the paper. The comment provides specific examples of where these definitions are missing, such as L166. However, it does not offer additional context or reasoning to fully support the claim, leaving the authors to infer the need for clarification. The comment is 3 as it provides some evidence but lacks depth and detail. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. By pointing out these inconsistencies, the comment provides the authors with clear feedback on areas that need clarification. However, the comment could be more helpful if it suggested specific ways to address these issues, such as providing definitions or examples. While the feedback is 3, it lacks depth and guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve their evaluation or select more appropriate baselines. As a result, the authors are left without a clear understanding of what steps to follow to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation\" and \"the baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly states that the evaluation is weak and that the baselines are not designed for fair classification, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific details or references to support this claim. Without additional information or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation section of the paper, specifically noting that the baselines used are not designed for fair classification. This feedback is valuable as it highlights a potential weakness in the methodology and suggests that the authors should consider using more appropriate baselines for a fairer comparison. However, the comment lacks specific guidance on how the authors might address this issue or what alternative baselines could be considered. While it points out a critical area for improvement, the lack of actionable suggestions limits its overall helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It also implies that the authors might be overstating the generality of their work, which could muddle the exposition. However, the comment does not provide explicit guidance on how to clarify the setting or address the issue of overstating generality. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to spell out the setting more clearly and the concern about overstating generality. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and precision of their writing. However, the comment could be more helpful if it offered additional guidance on how to spell out the setting or suggested specific ways to improve the exposition. Despite this, the feedback is 4 as it directs the authors towards a concrete improvement that could enhance the overall quality of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method works on these newer approaches or what its advantages are compared to them. While the comment implies that the authors should consider using more recent baselines, it does not provide explicit guidance on how to implement this change or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should compare their method with more advanced 3D CNNs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these 3D CNNs or what its advantages are compared to them. However, the comment does not specify which part of the paper discusses the choice of baselines or the experimental setup, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of using older baselines, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these newer approaches or what its advantages are compared to them. While the comment raises a valid concern about the choice of baselines, it lacks specific examples or references to support the claim that the proposed method might not be effective on more advanced 3D CNNs. The authors would need to provide more detailed reasoning or evidence to substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of baselines used in the experiments, specifically questioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these newer approaches or what its advantages are compared to them. This feedback is 3 as it points out a potential gap in the experimental evaluation and encourages the authors to consider more recent and relevant baselines. However, the comment could be more helpful if it provided specific guidance on how to conduct additional experiments or what specific comparisons would be beneficial. Overall, the comment offers a clear direction for improvement but lacks detailed suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide explicit or implicit actions for the authors to take. The comment implies that the authors should conduct more analysis, but it does not specify how to do so or what kind of analysis would be beneficial. Without concrete guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"three tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the improvements over previous works and selfimplemented baselines, noting that they are marginal and that further analysis beyond the main experiments is not sufficient. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the improvements over previous works and selfimplemented baselines, noting that they are marginal and that further analysis beyond the main experiments is not sufficient. While the comment highlights a concern, it lacks specific guidance or suggestions on how the authors might address this issue or what additional analysis could be conducted to strengthen their results. Without actionable advice or detailed feedback, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the theoretical results of the paper, specifically that the utility guarantees are only provided for Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific area for improvement and provides a clear direction for the authors to address it, it does not explicitly instruct them on how to compare the rates or what specific literature to consult. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the limitation of the theoretical result, which is the requirement for Gaussian features and noise, and suggests a comparison to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only for Gaussian features and noise, which is a strong requirement compared to previous algorithms that do not need this assumption. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the claim about the limitation of the theoretical result is logical and based on the description provided, the suggestion to compare rates lacks specific examples or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the theoretical results of the paper, noting that the utility guarantees are only provided for Gaussian features and noise. This is a significant constraint, as previous algorithms do not require this assumption. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which is a valuable piece of feedback for improving the paper. However, the comment could be more helpful if it provided specific examples of existing rates or suggested particular literature to compare against. Overall, the feedback is 4 as it highlights an important area for improvement and provides a clear direction for the authors to follow, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would have been beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on the simulated data. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects should be compared. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this comparison. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the comparison, the lack of grounding makes it difficult for the authors to understand where to apply the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for comparison that could enhance the paper\"s contribution. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. Without further elaboration, the authors may find it challenging to fully understand and implement the suggested improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. It provides specific examples of these works, such as 1, 2, 3, which implies that the authors should include these in their experimental comparisons to better demonstrate the effectiveness of their method. The comment is explicit in suggesting the addition of more baselines and provides concrete examples, making it clear how the authors should apply the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions, such as 1, 2, 3. This provides a clear indication of what additional comparisons are needed. However, the comment does not specify which part of the paper these comparisons should be made in, such as the experimental section or a specific section discussing the method. While the authors can infer that the suggestion pertains to the experimental section, the lack of explicit mention makes the comment weakly grounded. The comment is specific in detailing the need for additional comparisons, but the lack of grounding makes it only 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without detailed reasoning or examples, the claim is not 5, as it lacks the necessary evidence to be considered actionable. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, noting that the authors only compared their proposed method with two baselines. It suggests that there are other works focusing on similar questions and provides examples of such works. This feedback is clear and actionable, as it directs the authors to include additional comparisons to better demonstrate the effectiveness of their method. By recommending the inclusion of more baselines, the comment provides a concrete and constructive suggestion that can help the authors strengthen their experimental evaluation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for fewshot learning, rather than the zeroshot version and its connection to density estimation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the draft. The comment lacks actionable feedback, leaving the authors without a clear path to respond or make changes. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for fewshot learning, rather than the zeroshot version and its connection to density estimation. However, it does not specify which part of the paper this relates to, making it difficult for the authors to identify the exact section being addressed. The comment is vague and does not provide specific guidance on how to improve the draft. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the zeroshot version and its connection to density estimation are distracting to the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential distraction in the paper, specifically the inclusion of the zeroshot version and its connection to density estimation, which might be distracting to the main point of the paper. The reviewer suggests that this focus is more aesthetic than technical, implying that it could be removed or reframed to better align with the paper\"s core argument. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the draft. While it provides a general direction for improvement, it does not offer detailed feedback or actionable steps, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide explicit guidance on what specific aspects of the methodology should be included or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more details on the filtering process, but the lack of concrete instructions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"details around the filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is lacking, namely \"more information on the translation and filtering methodology,\" which is crucial for assessing the dataset quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset, suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide any specific examples, references, or logical reasoning to support the claim that the filtering process lacks detail or that the dataset quality is compromised. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper by providing more details about the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it suggested specific ways to improve the dataset or provided examples of how to enhance the methodology. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the impact of using different image sizes and variations of ResNets on the performance difference. While it suggests that the authors should provide more context or analysis regarding this aspect, the comment does not explicitly instruct the authors on how to address this issue or what specific actions they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information or analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (L170), allowing the authors to accurately identify the part being addressed. It also specifies what the authors should know, namely the impact of using different image sizes and variations of ResNets on the performance difference. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the impact of using different image sizes and variations of ResNets on the performance difference. However, it does not provide any specific reasoning, examples, or references to support why this question is important or how it might affect the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of using different image sizes and variations of ResNets on the performance difference, specifically referencing line 170. While it prompts the authors to consider this aspect, it does not provide any guidance or suggestions on how to address this question or what specific analysis might be needed. The comment is 3 as it identifies a potential area for further exploration, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While the comment implies that the authors should provide a detailed description of the algorithm, it does not specify how this detailed description should be presented or what aspects of the algorithm need to be emphasized. The action is explicit but lacks concrete guidance on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not specify which part of the paper this refers to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion to provide a detailed description of the algorithm, the absence of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While this feedback is relevant and provides a clear direction for improvement, it lacks specific guidance on how the authors might enhance the description of the algorithm. The comment is 3 as it identifies a need for more detailed explanation but does not offer detailed suggestions or examples of how to achieve this. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. However, it does not provide explicit instructions on how to implement this suggestion or what specific aspects of the runtime comparison should be included. The action is implicit, as the authors can infer that they need to add a runtime comparison, but the lack of detailed guidance makes it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to include a runtime comparison, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, this comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. This feedback is 3 as it points out a potential area for improvement by suggesting a specific experiment or analysis that could enhance the paper\"s impact. However, the comment lacks depth and does not provide detailed guidance on how to conduct the runtime comparison or what specific aspects of the comparison should be included. While it offers a clear direction for improvement, the lack of actionable advice limits its overall helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It also recommends adding a line or two to indicate that there is no solution for this, which would improve the readability and provide a clearer overall picture for the reader. The comment is explicit in suggesting what action to take, and it provides concrete details on how to implement this action by recommending the inclusion of additional information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the omission of FFNs due to the inability to obtain a linear decomposition, referencing a point mentioned in the paper. It suggests exploring existing work that offers an approximation or alternative method to compute the contribution of FFNs. However, the comment does not specify which part of the paper discusses the linear decomposition or where the suggestion to explore existing work should be placed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting what needs to be addressed, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It recommends adding a line or two to indicate that there is no solution for this, which would improve the readability and provide a clearer overall picture for the reader. While the comment provides a logical suggestion and implies the need for additional information, it lacks specific examples or references to support the claim. The authors would need to infer the relevance of this suggestion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests exploring existing work that offers an approximation or alternative method to compute the contribution of FFNs, or alternatively, indicates that no solution exists, which would improve the readability and provide a clearer overall picture for the reader. This feedback is clear and actionable, offering a constructive suggestion for improvement. However, it could be more helpful if it provided specific examples or references to existing work that could be explored. Overall, the comment is 4, as it provides valuable guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks how the number of images impacts the model performance, and second, it suggests explaining the BYOL model in the abstract. While the questions are clear and specific, they do not provide explicit instructions on how the authors should address these issues. The authors are left to infer that they need to provide more details on the impact of the number of images and explain the BYOL model in the abstract. This lack of explicit guidance makes the comment 3, as the authors can deduce the necessary actions but do not know exactly how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. However, it does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it difficult for the authors to identify the exact sections they need to address. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises two questions: how the number of images impacts model performance and whether more training images make performance worse or better. It also suggests explaining the BYOL model in the abstract. While the questions are logical and relevant to the paper, the comment lacks specific examples or references to support the claims. The authors are left to infer the relevance of these questions and the need for explanation, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two important questions regarding the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. These questions are relevant and could help the authors improve the clarity and completeness of their paper. However, the comment lacks specific guidance on how to address these issues or provide additional context. While it identifies areas for improvement, it does not offer detailed suggestions or examples, which could make it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the rationale behind the method\"s effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" However, the comment does not explicitly instruct the authors to include these explanations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the reasoning behind the method\"s effectiveness. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind the method\"s effectiveness, particularly regarding the L_pixel component. However, it does not specify which part of the paper discusses this component or the method\"s effectiveness. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a need for stronger arguments or intuitions regarding why the L_pixel losses are \"bound to help,\" but without explicit grounding, the authors may struggle to locate the relevant section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the method\"s effectiveness, particularly regarding the L_pixel component, suggesting that the authors should provide stronger arguments or intuitions for why these losses are \"bound to help.\" However, the comment does not offer any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 2, as it provides a basis for improvement but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the rationale behind the method\"s effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" This feedback is 3 as it highlights an area where the authors could enhance their explanation of the method\"s effectiveness. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the arguments or intuitions. Without such details, the authors may struggle to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models understanding of finegrained errors like technique error. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the evaluation. The comment lacks concrete guidance on what alternative metrics or methods could be considered, making it difficult for the authors to take action to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models understanding of finegrained errors like technique error. However, it does not specify which part of the paper this concern relates to, such as a particular section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the issue needs to be addressed. While the comment is specific in its critique of the metric, the absence of grounding information limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models understanding of finegrained errors like technique error. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique error. This feedback is 3 as it identifies a potential weakness in the evaluation methodology. However, the comment could be more helpful if it provided suggestions or guidance on alternative metrics or methods that could better capture the models\" understanding of finegrained errors. Without specific recommendations or examples, the authors may struggle to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It also highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench, for language generation. While the comment provides a clear action\u2014comparing the metric with others\u2014it does not offer specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a large amount of work on LLM evaluation 2\" and suggests comparing the SynTextBench metric with other metrics proposed in the literature. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear direction for comparison, asking the authors to understand under what conditions SynTextBench should be used over other metrics like MMLU or Big Bench. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there has been a large amount of work on LLM evaluation 2 and suggests comparing the SynTextBench metric with other metrics proposed in the literature. It also highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench, for language generation. However, the comment lacks specific examples or references to support the claim about the amount of work on LLM evaluation or the comparison of metrics. While the reasoning is somewhat logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench, for language generation. This feedback is valuable as it directs the authors to consider additional comparisons and provides a specific area for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4, as it identifies a significant area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing and annotations in the paper are difficult to follow. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of the writing and annotations. The comment lacks explicit instructions or concrete advice on what needs to be done to address this issue. As a result, the authors are left without a clear understanding of how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment is not specific, as it does not detail what aspects of the writing or annotations are hard to follow. Without specific examples or guidance, the authors cannot effectively address the issue. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are \"poor\" and \"hard to follow.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the writing and annotations in the paper, specifically noting that they are \"poor\" and \"hard to follow.\" However, the comment lacks specificity and actionable suggestions. It does not provide any guidance on how the authors might improve the clarity or readability of their writing or annotations. Without detailed feedback or examples, the authors may struggle to understand the nature of the problem and how to address it effectively. Therefore, the comment is 2, as it offers a general observation but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the results presented in Table 2. The first question asks why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method. The second question inquires about the discrepancy in F1 scores between the overall setting and individual types in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the results presented in the table, particularly regarding the number of SOTA performances and the discrepancy in F1 scores. This provides clear guidance on what aspects of the results require further explanation or clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the results presented in Table 2, specifically regarding the number of SOTA performances and the discrepancy in F1 scores. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\".", "helpfulness_rationale": "The review comment identifies specific areas in the results that require further explanation or clarification. It questions the number of evaluation metrics achieving SOTA performances and the discrepancy in F1 scores between the overall setting and individual types. While the comment highlights potential areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out specific weaknesses that need attention, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of including all reports. While the comment is somewhat specific in questioning the rationale, it lacks concrete suggestions on how to implement this change or what experiments might be needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion about the potential ease of including all reports, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion that including all reports would be easier. As a result, the claim is 1, as it lacks sufficient support for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. This feedback is 3 as it prompts the authors to reconsider their approach and potentially explore the impact of including all reports. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what experiments or analyses could be conducted to support their decision. While it identifies an area for improvement, the feedback could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. It notes that the current instances have a maximum of 7 variables, which raises concerns about the ability of LLMs to model problems with large instance sizes. However, the comment does not provide explicit guidance on how the authors should generate these additional instances or what specific changes need to be made to the paper. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. However, the comment does not provide any specific reasoning, examples, or references to support why this is a concern or how it impacts the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. This is a valid point, as the current instances have a maximum of 7 variables, which may limit the ability of LLMs to model problems with large instance sizes. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue, such as proposing additional experiments or modifications to the paper. While it identifies a potential area for improvement, the lack of actionable advice makes the comment 3, as it provides a clear direction for the authors to consider but lacks depth in its suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The comment lacks concrete details, making it difficult for the authors to understand exactly what actions to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and perspectives, but without clear references to the paper, the authors may struggle to identify the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment suggests that the authors should include the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a direction for the authors to enhance their work by considering additional baselines and perspectives. However, the comment lacks specific guidance on which baselines to include or how to implement these suggestions, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions should be included. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to their draft. The comment is specific in its request, detailing what should be included in the conclusion and summary. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and a summary of the paper\"s contributions should be included. However, it does not specify which part of the paper this comment is related to, such as the conclusion section or the abstract. Without this information, the authors may find it challenging to identify the exact part of the paper that needs revision. While the comment is specific in its request, the lack of grounding makes it difficult for the authors to understand which section to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions should be included. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis for this recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a brief conclusion and a summary of the paper\"s contributions should be included. This is a clear and actionable piece of feedback that provides the authors with a specific direction for improving their draft. By adding a conclusion and summary, the authors can enhance the completeness and impact of their work, making it easier for readers to understand the key takeaways. However, the comment could be more helpful if it provided additional guidance on how to write these sections effectively or included examples of what should be included. Overall, the comment is 4 as it directs the authors towards a specific improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, suggesting that the data distribution in Figure 1 might be inseparable from the network model. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or improve the experiment. The comment implies that the authors should consider the nonlinear expression ability of neural networks and how it relates to the data distribution, but it lacks concrete steps or suggestions for implementation. Therefore, the comment is not actionable, as it does not provide clear guidance on how the authors can address the issue or improve their draft.", "grounding_specificity_rationale": "The comment raises a concern about the synthetic experiment in a nonseparable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is vague and lacks specificity, as it does not provide detailed guidance on how to address the issue or what aspects of the experiment need to be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the synthetic experiment in a nonseparable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. The comment does not provide any evidence, reasoning, or references to support the claim that the data distribution is inseparable from the network model. Without additional context or justification, the authors may find it challenging to understand or address the concern raised in the comment. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the synthetic experiment in a nonseparable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. It raises a valid concern about the nonlinear expression ability of neural networks and how it relates to the data distribution. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 2, as it points out a problem but does not offer concrete solutions or directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point critiques a statement on line 134 regarding the applicability of a theorem to standard sigmoid functions, noting that it depends on the maximum slope. It suggests that the theorem, specifically Theorem 4.1, would be more useful if the authors elaborated on why this holds, particularly in the context of RNNs converging to the nearest fixed point compared to URNNs. While the comment implies that the authors should provide more detail, it does not explicitly instruct them to do so or specify how to elaborate. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the explanation in the main text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors elaborate on why the statement holds, particularly in the context of RNNs converging to the nearest fixed point compared to URNNs. This provides clear guidance on what part of the paper requires further explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques a statement on line 134 regarding the applicability of a theorem to standard sigmoid functions, noting that it depends on the maximum slope. It suggests that the theorem, specifically Theorem 4.1, would be more useful if the authors elaborated on why this holds, particularly in the context of RNNs converging to the nearest fixed point compared to URNNs. The comment provides a logical reasoning by explaining the relevance of the convergence behavior of RNNs and URNNs, which helps the authors understand the basis of the critique. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific point of confusion regarding the applicability of a theorem to standard sigmoid functions, particularly concerning the maximum slope. It suggests that the authors should elaborate on why this holds, especially in the context of RNNs converging to the nearest fixed point compared to URNNs. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to enhance the explanation in the main text. By addressing this critique, the authors can improve the clarity and depth of their paper, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should report results for multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. It acknowledges that this might be timeconsuming due to the size of the datasets but encourages the authors to carry out this exercise. The comment is explicit in its suggestion and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should report results for multiple train/test splits or folds, which is a specific and actionable suggestion. However, it does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its recommendation, as it clearly specifies the need for multiple splits to provide a more accurate illustration of the method\u2019s performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the results should be reported for multiple train/test splits or folds, which is a standard practice in many papers on Gaussian Processes. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors are encouraged to consider this suggestion, but the lack of detailed reasoning or evidence weakens the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental methodology, suggesting that the results are reported for a single heldout test set, which may not provide a comprehensive evaluation of the method\"s performance. The comment recommends using multiple train/test splits or folds, a standard practice in many papers on Gaussian Processes, to offer a more accurate illustration of the method\"s performance. While the comment does not provide specific guidance on how to implement this suggestion, it offers a clear direction for improvement. The feedback is 4 as it highlights a common practice and encourages the authors to enhance the robustness of their results, though it could be more detailed with specific examples or references. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment implies that the authors should clarify the term \"perfect,\" it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the term. However, the comment lacks concrete details on what specific clarification is needed, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment raises a valid point about the ambiguity of the term \"perfect,\" it does not provide any specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some context but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the phrase \"perfect\" in the context of the initial rationale selector. It questions the meaning of \"perfect\" and suggests that if it were perfect, no additional work would be needed. This feedback is 3 as it highlights a potential ambiguity in the writing, which could be clarified to improve the paper\"s clarity. However, the comment could be more helpful if it provided additional context or suggestions for how to clarify the term. Overall, the comment offers a clear area for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "No", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zeroshot intent classifier. While it does not explicitly instruct the authors to address these questions, it implies that they should provide more clarity on these aspects. The action is implicit, as the authors need to infer that they should clarify these points in their draft. However, the questions are specific and direct, giving the authors a clear idea of what needs to be addressed. Therefore, the comment is 3, as it provides a clear direction but lacks explicit instructions on how to implement the changes. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zeroshot intent classifier. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific and direct, as they ask for clarification on the methodology and accuracy of the system. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zeroshot intent classifier. However, it does not provide any claims or opinions that require verification. The questions are factual and descriptive, asking for clarification on specific aspects of the methodology. Therefore, the comment is classified as \"No\" because it does not contain any claims that need to be verified.", "helpfulness_rationale": "The review comment raises two specific questions about the experimental setup, particularly concerning the use of domain ontologies and the details of the zeroshot intent classifier. It asks for clarification on the number of questions created and the accuracy of the system. While the questions are direct and point to specific areas that need more detail, they do not provide actionable feedback or suggestions for improvement. The authors are left with a clear understanding of what information is missing but are not guided on how to address it. Therefore, the comment is 2, as it identifies a need for clarification but lacks depth and guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of citations to recent works on selfplay and populationplay in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which suggests that the authors should include these citations to provide a more comprehensive context. However, the comment does not explicitly instruct the authors on how to incorporate these citations or where to place them within the paper. While the action is implied, it is vague and lacks concrete guidance, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to recent works on selfplay and populationplay in the context of exploration and coordination within MARL, providing specific examples of relevant papers. This allows the authors to accurately identify the part of the paper where these citations should be included. The comment is also specific, as it clearly specifies what needs to be addressed by including these citations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks citations to recent works on selfplay and populationplay in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which supports the claim. However, the comment does not explain why these specific papers are relevant or how they relate to the paper\"s content, making it 3. The inclusion of these references would enhance the paper\"s context and relevance, but the lack of detailed reasoning or examples limits the verifiability.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of citations to recent works on selfplay and populationplay in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which are crucial for contextualizing the paper\"s contribution. By highlighting this omission, the comment offers a clear and actionable suggestion for improvement, guiding the authors to include these references. This feedback is 4 as it directs the authors to a specific area for enhancement, but it could be more comprehensive if it suggested additional areas for improvement or provided more detailed guidance on how to integrate the suggested citations. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their method with other selfsupervised learning methods that are not based on contrastive learning. This provides a clear and explicit action for the authors to take, as they can directly compare their method with relevant baselines. The comment is specific in its suggestion, guiding the authors on what kind of comparisons would be beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the authors\" method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this comparison should be made or where these methods are discussed. The authors cannot confidently determine which section or part of the paper this comment addresses, making it weakly grounded. Additionally, while the suggestion is specific in terms of the type of comparison, it lacks detail on how to implement or execute this comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the authors\" method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this comparison is necessary or how it would benefit their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the authors\" method with other selfsupervised learning methods that are not based on contrastive learning. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their work by including additional comparisons. By comparing their method with other relevant approaches, the authors can better position their work within the existing literature and demonstrate its unique contributions. This feedback is 4 as it offers a clear and constructive suggestion for improvement, though it could be further expanded to include specific examples or references. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the claim of COCOLM being parameterefficient, noting that the conclusion would apply to related works. The comment implicitly suggests that the authors should provide a more nuanced comparison and address the impact of BPE vocabulary changes on performance. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address them. The action is somewhat vague, as the authors need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCOLM being parameterefficient, implying that the conclusion would apply to related works. However, the comment does not specify which part of the paper this comparison is made or which sections discuss the performance of these models. This makes it difficult for the authors to pinpoint the exact areas that need revision. The comment is specific in its critique of the comparison but lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCOLM being parameterefficient, noting that the conclusion would apply to related works. However, the comment lacks specific examples or detailed reasoning to substantiate these claims, making it difficult for the authors to understand the basis of the critique. The absence of references or detailed explanations makes the claim 3, as it relies on the authors\" interpretation of the existing literature. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCOLM being parameterefficient, implying that the conclusion would apply to related works. This feedback provides a clear critique of the comparison and highlights the need for a more nuanced discussion of the performance of different models. However, the comment lacks specific suggestions or detailed guidance on how the authors might address these concerns, such as providing additional experimental results or clarifying the claims. While it offers valuable insights, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of meaningful baselines in the authors\" comparisons, suggesting that they should include more sophisticated baselines such as a chainofthought prompting approach. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific baselines to consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more meaningful baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue of lacking meaningful baselines and suggests a specific alternative baseline, the chainofthought prompting approach. This provides the authors with clear guidance on what needs to be addressed and how to improve their comparisons. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors limit their comparisons to simple naive baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare with a chainofthought prompting approach. However, the comment lacks specific examples or references to support the claim that the current baselines are indeed \"simple naive.\" While it provides a suggestion for improvement, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of meaningful baselines used for comparison. It suggests that the authors should include more sophisticated baselines, such as a chainofthought prompting approach, to provide a more comprehensive evaluation of their model criticism techniques. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their comparisons. By addressing this issue, the authors can strengthen the validity and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment prompts the authors to clarify their methodology, it does not provide explicit instructions or suggestions on how to address the question or improve the draft. The action is implicit, as the authors need to infer that they should clarify their methodology and discuss the generalization of their approach. However, the comment lacks concrete guidance on how to implement these suggestions, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its questioning, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the methodology of pretraining the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential area for clarification, it does not provide any specific evidence, reasoning, or references to support the claim that this is a significant issue or a gap in the paper. The authors are left to interpret the relevance of this question, making it difficult to fully understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the methodology of pretraining the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalization of this approach to scenarios where labels are not available. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to consider the implications of their methodology, but it lacks depth and actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes might be necessary. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which part of the paper these observations and decisions are discussed in, nor does it provide any specific examples or guidance on how to address this issue. The lack of grounding makes it difficult for the authors to understand which sections need revision, and the comment lacks specificity in detailing what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this observation or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some observations and design decisions might be hardware and software dependent, which could limit the generalizability of the findings. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to ensure the robustness of their work. While it identifies a potential area for improvement, it lacks actionable advice or detailed insights, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s usefulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the lack of new evaluation metrics and the need for an indepth exploration of the reasons behind the experimental results. However, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues, such as suggesting the development of new metrics or the inclusion of a detailed analysis of the experimental results. The comment lacks concrete details on how to implement these suggestions, making it 1.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the need for an indepth exploration of experimental results, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which sections or aspects of the paper are being discussed, making the comment weakly grounded. However, it is specific in detailing the issues that need to be addressed, such as the absence of new metrics and the need for a deeper analysis of experimental results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks new evaluation metrics and only uses linearly combined existing metrics. It also notes that the experimental analysis section needs an indepth exploration of the reasons behind the results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of new evaluation metrics and the need for a more indepth exploration of the reasons behind the experimental results. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that require attention, but it lacks actionable advice or detailed examples, which could help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit action that the authors should take to avoid confusion and ensure clarity in their notation. The comment provides a direct and concrete instruction, making it 5. The authors know exactly what needs to be addressed and how to implement the suggested change. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit reference to specific parts of the paper, such as L166 and L176, which allows the authors to accurately pinpoint the issue. The comment is fully grounded as it provides specific references to the sections where the notation is used. It is also specific because it clearly specifies the problem with the notation, making it easy for the authors to understand and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a factual observation that requires no further verification or reasoning to understand. The comment is clear and specific, making it verifiable. Therefore, it is classified as a comment that is 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion for the readers. By pointing out this inconsistency, the comment provides the authors with a concrete suggestion to improve the clarity and consistency of their notation. This feedback is helpful as it directly addresses a specific aspect of the paper that could hinder understanding. However, the comment could be more helpful if it suggested alternative notations or provided guidance on how to avoid such confusion in the future. Overall, the comment is 4 as it identifies a clear issue and offers a direct suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, suggesting that it may be primarily of theoretical interest and that the AMP algorithm\"s usefulness for nonGaussian problems is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the practical relevance of their work. The action is implicit and vague, as it does not specify what changes or improvements the authors should make to enhance the paper. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the practical impact of the weak recovery problem studied, suggesting that it is primarily of theoretical interest and that the AMP algorithm\"s usefulness for nonGaussian problems is unclear. However, the comment does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique of the practical impact, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and that the AMP algorithm\"s usefulness for nonGaussian problems is unclear, limiting practical impact. However, the comment does not provide specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical impact of the weak recovery problem studied, suggesting that it is primarily of theoretical interest and that the AMP algorithm may not be useful for nonGaussian problems. This feedback highlights a gap in the paper\"s discussion of the algorithm\"s realworld applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the practical relevance of their work. While it points out a concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the paper\"s focus on a reductionist problem. It suggests that the authors should clarify their claims and provide more context or citations to support their arguments. However, the comment does not explicitly instruct the authors on how to address this issue or what specific changes to make. The action is implicit, as the authors need to infer that they should clarify their claims and provide more context or citations. The action is somewhat vague, as it does not specify the exact nature of the clarification or the type of citations needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the relevance of connections to human cognition in the context of the paper, specifically questioning whether such connections are meaningful given the reductionist nature of the problem. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its critique of the authors\" claims regarding the impact of cognitively basic adaptation mechanisms and the structure of the CPR on selforganization. It suggests that the authors need to provide more context or citations to support their claims, which is a clear and specific request. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the paper, specifically questioning whether such connections are meaningful given the reductionist nature of the problem. The authors themselves state that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation that humans use. This raises a valid point about the clarity of the authors\" claims regarding the impact of cognitively basic adaptation mechanisms and the structure of the CPR on selforganization. However, the comment does not provide specific examples or references to support the claim that the authors\" claims are unclear or need more context. Without additional evidence or references, the claim is 3, as it highlights a potential area for clarification but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the relevance of connections to human cognition in the context of the paper, specifically questioning whether such connections are meaningful given the reductionist nature of the problem. The authors themselves state that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation that humans use, which raises a valid point about the clarity of their claims. The comment suggests that the authors need to clarify their claims and provide more context or citations to support their arguments. However, the feedback is somewhat limited as it does not offer specific guidance on how to address the issue or what kind of additional evidence or citations would be beneficial. While it provides a starting point for improvement, the comment could be more helpful if it offered more detailed suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment suggests that the authors should include such comparisons to prove the effectiveness of the proposed approach, but it does not offer specific guidance on how to implement this suggestion or what kind of baselines to use. Without concrete instructions or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. This makes it difficult for the authors to pinpoint where the comparison should be added or discussed. While the comment is specific about the type of comparison needed, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks comparison to simple feature acquisition baselines, which is a significant issue for proving the effectiveness of the proposed approach. However, the comment does not provide specific examples of such baselines or explain why their absence is a critical flaw. Without detailed reasoning or references to support the claim, it is difficult for the authors to understand the basis of the criticism and how to address it. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines. This omission makes it difficult for readers to assess the effectiveness of the proposed approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as which baselines to include or how to conduct the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes that clarifications are needed on how the embeddings are combined and fed into the CSCM. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the combination and feeding of embeddings. However, the action is somewhat vague as it does not specify the exact steps or methods that need clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific question about how historical observations are combined with inputs known over all time, particularly focusing on the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes the need for clarifications on how the embeddings are combined and fed into the CSCM. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what needs clarification regarding the combination and feeding of embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes the need for clarifications on how the embeddings are combined and fed into the CSCM. This feedback is 3 as it points out a specific area where clarification is needed, but it does not provide detailed reasoning or examples to support the claim. The authors would need to infer the need for clarification based on the feedback, which could be improved with more explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely how historical observations are combined with inputs known over all time, particularly concerning the differences in sequence lengths (L vs L+M). It points out that while the text mentions separate embedding and addition with positional encoding, it lacks clarity on how the embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to clarify a specific aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples to guide the authors in addressing this issue. Overall, the comment is 4, as it effectively highlights a need for clarification and improvement in the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While the comment implies that the authors should address this issue, it does not explicitly instruct them to include a discussion on the power of different architectures. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for more discussion but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not offer any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. This feedback is 3 as it identifies a potential area for improvement by prompting the authors to elaborate on the capabilities of different architectures. However, the comment lacks specificity and does not provide detailed guidance on how to address the issue or what aspects of the architectures should be discussed. The authors are left to infer that they need to expand on this topic, which limits the actionable nature of the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the methods should be evaluated across different splits of trainvaltest to obtain robust results, rather than relying on different initialisation seeds. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve the robustness of their results. The comment is specific in its recommendation, detailing exactly what needs to be done to enhance the evaluation process. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the methods should be evaluated across different splits of trainvaltest to obtain robust results, rather than relying on different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area where the suggestion should be implemented. While the comment is specific in its recommendation, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the methods should be evaluated across different splits of trainvaltest to obtain robust results, rather than relying on different initialisation seeds. This claim is 3 as it provides a logical reasoning for why evaluating across different splits would lead to more robust results. However, it lacks specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the robustness of the results by recommending that the methods be evaluated across different splits of trainvaltest, rather than relying solely on different initialisation seeds. This feedback is actionable and directly addresses a potential weakness in the evaluation process. By offering a clear and concise suggestion, the comment empowers the authors to enhance the robustness of their findings, making it 4. However, it could be more helpful if it included additional guidance on how to implement this suggestion or why this approach is beneficial. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the first two bullet points about contributions in the introduction could be combined. This is a clear and explicit action that the authors can easily understand and implement. The comment provides specific guidance on how to improve the draft by merging the contributions, which is concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the first two bullet points about contributions in the introduction could be combined. However, it does not specify which part of the introduction these bullet points are located in, making it difficult for the authors to identify the exact section to address. While the comment is specific about the action to be taken, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the first two bullet points about contributions in the introduction could be combined. This is a suggestion for improvement, but it does not contain any claims or opinions that require verification. The comment is factual and descriptive, aligning with a classification of \"No\".", "helpfulness_rationale": "The review comment suggests that the first two bullet points about contributions in the introduction could be combined. This is a specific and actionable suggestion that provides clear guidance for the authors to improve the structure and flow of their paper. By merging these points, the authors can enhance the clarity and conciseness of their introduction, making it easier for readers to understand the contributions of the work. This feedback is clear and constructive, offering a direct path for improvement, thus aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems and robustness against weak boundaries. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s ability to find closed contours. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the paper need to be improved. The action is implicit and vague, as it does not specify which parts of the paper should be revised or how the authors should incorporate the suggested references. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper targets a problem that somewhat differs from general segmentation problems, allowing the authors to identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, how much the paper can improve over existing solutions and how to demonstrate the algorithm\"s ability to find closed contours and show stronger robustness against weak boundaries. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems and robustness against weak boundaries. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s ability to find closed contours. However, the comment lacks specific examples or references to support the claim that the paper needs to address these issues. Without detailed reasoning or evidence, the claim remains 3, as it provides a general direction for improvement but lacks depth and specificity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems and robustness against weak boundaries. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s ability to find closed contours. However, the comment lacks specific guidance on how to address this issue or what aspects of the paper need to be improved. While it identifies an important area for improvement, it does not provide actionable feedback or detailed suggestions, making it 3. The authors would need to infer the need for more detailed comparisons with recent trends and how to incorporate this into their work, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited novelty of the paper, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. It mentions that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty or provide unique insights about the challenges of overcorrelation in recommender systems. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DeCorr\" and \"graph collaborative filtering,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the lack of unique insights regarding overcorrelation in recommender systems, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty, as it primarily applies existing literature, specifically DeCorr, to a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s novelty, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. While the authors acknowledge that the paper transposes DeCorr\"s insights into graph collaborative filtering, they also note that the contribution is mainly in the application rather than in providing unique insights about the challenges of overcorrelation in recommender systems. This feedback is 3 as it highlights a critical area for improvement, but it lacks depth and actionable suggestions for the authors to address the issue of limited novelty. The comment could be more helpful if it provided specific guidance on how to enhance the novelty or offer unique insights into the challenges of overcorrelation in recommender systems. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it is a key factor in performance gain compared to other modules. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the pretraining method need to be discussed. While the suggestion is clear, the lack of detailed instructions or concrete steps makes it 3. The authors know that they need to expand on the discussion of unsupervised pretraining, but they are not given specific guidance on what to include or how to improve the discussion. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining in the main paper and suggests that it is more important than other modules. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it also notes that there is no detailed discussion of unsupervised pretraining in the main paper, which could be a problem. The reviewer suggests that the unsupervised pretraining is more important than other modules compared to the ablation study in Table 5. While the claim is supported by the data in Table 4 and the comparison with Table 5, the reasoning could be more detailed to fully substantiate the claim. Therefore, the comment is 4, as it provides some justification but lacks depth in explanation or references. The label is 4.", "helpfulness_rationale": "The review comment identifies a key issue in the paper, noting that the unsupervised pretraining method is a significant factor in performance gain, as evidenced by data in Table 4. However, it points out that there is no detailed discussion of this method in the main paper, which could be a problem. The reviewer suggests that the unsupervised pretraining is more important than other modules compared to the ablation study in Table 5. This feedback is 4 as it highlights a critical gap in the paper\"s discussion and provides a clear suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to expand the discussion or what aspects of the unsupervised pretraining method should be included. Overall, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\"s gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors can implement the suggested changes or what steps they should take to ensure the accuracy of their model. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\"s gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table discussing the choice of ELM. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of accuracy and the potential drawback, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\"s gender, which could be a drawback. The comment implies that the accuracy should be calculated after using a gender detection model in the pipeline, particularly in cases where vocal traits match speaker identity. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed explanation or evidence makes the claim 3, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\"s gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, particularly in cases where vocal traits match speaker identity. This feedback highlights a potential issue with the methodology and suggests that the authors should consider the implications of using a gender detection model in their pipeline. However, the comment lacks specific guidance on how the authors might address this issue or what changes they should make to their draft. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on how to determine which $P^*$ to fix. While the comment provides some direction for improvement, it lacks explicit instructions on how to incorporate this intuition or guidance into the paper. The authors are left with a general idea of what needs to be addressed but without concrete steps on how to implement it. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on how to achieve them.", "grounding_specificity_rationale": "The comment suggests providing more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$. However, the comment does not specify which part of the paper this feedback pertains to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its suggestions, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the intuition behind the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on determining which $P^*$ to fix. While the questions are relevant and could provide valuable insights, the comment lacks specific examples or references to support these claims. The authors would need to infer the basis for these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper, such as offering more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$, which could guide the authors in enhancing the clarity and practical relevance of their work. However, the comment could be more helpful if it provided more detailed guidance or examples on how to incorporate these suggestions into the paper. Overall, the feedback is 3, as it identifies areas for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the equations. Without specific advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of different variables in equations (7) and (10), specifically asking why they are not analogous. However, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The authors are left without a clear understanding of what part of the paper needs revision or how to improve the consistency of the equations. As a result, the comment is 1, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific because it does not offer any actionable advice. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely analytical and does not offer any new information or reasoning to support the observation. Therefore, it is classified as \"No\" because it lacks a claim that needs verification.", "helpfulness_rationale": "The review comment raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. This feedback is 3 as it points out a potential inconsistency or area for clarification in the equations. However, it does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve the consistency of the equations. Without actionable advice or specific suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the applicability of the model to realworld diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in realworld scenarios. However, the comment does not specify how the authors should go about providing this evidence, such as suggesting specific datasets or methods for empirical validation. While the action is explicit in identifying the need for empirical evidence, it lacks concrete guidance on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment does not specify which part of the paper discusses the model\"s applicability or where the empirical evidence should be provided. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its suggestion to provide empirical evidence, the absence of grounding information makes it challenging for the authors to address the concern effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment lacks specific details or examples to substantiate this concern, making it difficult for the authors to understand the basis of the claim. Without additional context or references, the claim remains 3, as it lacks sufficient evidence to fully support the authors in addressing the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the model to realworld diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in realworld scenarios. This feedback is valuable as it highlights a crucial aspect of the model\"s practical relevance and encourages the authors to strengthen the paper by including empirical validation. However, the comment could be more helpful if it provided specific guidance on how to conduct this empirical evaluation or suggested potential datasets or methods for validation. Despite this, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the novelty of the paper is limited, noting that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty of the paper or what specific changes could be made to improve the contribution. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. It provides a detailed explanation of the incremental contribution, which helps the authors understand the specific areas that need attention. However, the comment does not explicitly mention a specific section, table, or figure, making it weakly grounded. It is specific in detailing the novelty and contribution of the paper, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, noting that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It lacks specific examples or references that would help the authors understand why the novelty is limited or how the decomposition part contributes to the paper. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in 10. It also highlights the incremental contribution of the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides some insight into the paper\"s contribution, it lacks detailed suggestions or actionable advice on how to enhance the novelty or address the identified limitation. The feedback is 3 as it directs the authors to consider the novelty of their work, but it could be more comprehensive with additional guidance on how to improve the paper. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should address the missing information about the input domain. However, the comment lacks concrete details on what specific information needs to be added or how to clarify the issue. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. However, it does not specify which part of the paper this issue relates to, making it difficult for the authors to pinpoint the exact section or figure where this information should be addressed. The comment is specific in its suggestion to clarify the input domain, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. This feedback highlights a potential gap in the clarity of the paper, as it leaves the authors uncertain about the scope and nature of the inputs being discussed. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as clarifying the input domain or providing additional context. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with the work mentioned in A. However, it does not provide any explicit or implicit suggestions on how the authors should address this comparison or what specific aspects of the comparison should be considered. The comment lacks concrete guidance on how to conduct the comparison or what data or analysis would be necessary. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with a work mentioned in A. However, it does not specify which part of the paper this comparison should be made or which aspects of the comparison are relevant. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to conduct the comparison or what data or analysis would be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with a work mentioned in A. However, it does not provide any specific evidence, reasoning, or references to support the claim that such a comparison is necessary or beneficial. The comment lacks detailed justification or examples to substantiate the need for this comparison, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with a work mentioned in A. However, it does not provide any suggestions or guidance on how the authors might address this comparison or what aspects of the comparison are relevant. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies issues with the presentation of the paper, specifically noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. While the comment explicitly states the issue and provides a suggestion for improvement, it does not offer concrete guidance on how to create or integrate such a figure into the paper. The action is implicit and somewhat vague, as the authors would need to infer how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue as the presentation being \"equationdriven\" and the notation being \"convoluted and hard to follow,\" and suggests that an illustrative figure would have been helpful. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is \"equationdriven\" and that the notation in chapter 3 is \"convoluted and hard to follow.\" It suggests that an illustrative figure would have been helpful. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issue or how to address it. The reasoning is somewhat vague, and the suggestion for an illustrative figure is not fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the paper, noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. This feedback is clear and actionable, providing the authors with a specific area to improve the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional suggestions or guidance on how to create or integrate such a figure. Overall, the comment is 4 as it highlights a significant area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. While the comment highlights a specific issue, it does not provide explicit guidance on how the authors should address this conflict or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to resolve the conflict. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the definition of minimal conditional dependence and the equations, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. The comment provides a clear logical reasoning by pointing out the inconsistency between the definition and the equation. However, it lacks specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It highlights a discrepancy between the theoretical expectation and the equation presented, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This feedback is clear and actionable, as it points out a specific area where the authors need to address a potential inconsistency. However, the comment could be more helpful if it provided guidance on how to resolve the conflict or what changes might be necessary. Overall, the comment is 4, as it directs the authors to a critical issue that needs to be addressed for the paper to be accurate and consistent."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, it does not provide any explicit or implicit actions for the authors to take to improve the presentation. The comment lacks guidance on how to enhance the subscripts or what specific improvements could be made. As a result, the authors are left without a clear understanding of what steps to undertake to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, and suggests that enhancing readability and aesthetic appeal would improve the presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visual presentation of data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to improve the presentation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address. However, the comment could be more helpful if it offered suggestions on how to enhance the subscripts or provided examples of improved presentation. Despite this, the comment is 4 as it directs the authors to a concrete area for improvement, allowing them to make targeted revisions to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. It also mentions that this formatting issue effectively violates the 9page paper limit, which is a significant concern. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the formatting. The authors are left without guidance on how to resolve the whitespace problem or enhance the visual presentation of the paper. Therefore, the comment is 1 as it lacks any actionable steps or guidance for the authors to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1,\" indicating a specific part of the paper being addressed. It also specifies the issue by detailing the formatting problems with equations and captions, which are directly related to the mentioned part. The comment is specific in its critique of the formatting, providing clear details on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions too close to the figures. This is presented as a violation of the 9page paper limit, which is a factual observation. However, the comment lacks specific examples or references to support the claim about the formatting issues, making it 3. The authors would need to provide more detailed evidence or examples to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. This observation is presented as a potential violation of the 9page paper limit, which is a significant concern. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the formatting of their paper. Without actionable feedback or suggestions, the authors are left without a clear path to resolve the formatting problem, making the comment unhelpful. Therefore, the comment is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should clarify this concept. The authors are left to infer that they need to address the ambiguity in the definition of local interactions, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific issue but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. This is a subjective question that requires the authors to clarify their understanding of the concept. However, the comment does not provide any evidence, reasoning, or references to support the claim that the concept is unclear. As a result, the comment is considered 1 because it lacks sufficient justification for the authors to address it. Therefore, the label is 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. This is a pertinent point that could help the authors clarify their understanding of the concept, which is crucial for the coherence and accuracy of their paper. However, the comment does not provide any suggestions or guidance on how the authors might address this ambiguity. While it identifies an area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the paper\"s claim of better results in the Molecule generation experiment (Table 3) and the observation that adding the proposed constrained method yields lower validity and diversity. However, it does not provide explicit or implicit actions for the authors to take. The comment suggests that the authors should reevaluate their results and consider the impact of the constrained method on validity and diversity. While the authors can infer that they need to address this issue, the comment lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Molecule generation experiment (Table.3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue: the paper claims better results, but the addition of the proposed constrained method yields lower validity and diversity. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim of better results in the Molecule generation experiment (Table 3) is contradicted by the observation that adding the proposed constrained method yields lower validity and diversity. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the paper\"s claim of better results in the Molecule generation experiment and the observation that adding the proposed constrained method yields lower validity and diversity. This feedback highlights a potential issue with the paper\"s claims and suggests that the authors need to reevaluate their results and consider the impact of the constrained method on validity and diversity. While the comment points out a specific area of concern, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it directs the authors to a critical area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete guidance on how to update the archetypes. The comment is vague and lacks actionable steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the update mechanism of archetype positions after initialisation, providing a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, asking for clarification rather than making an opinion or suggestion. Therefore, it is classified as \"No\"", "helpfulness_rationale": "The review comment raises a specific question about the update mechanism of archetype positions in Algorithm 2, which is a crucial aspect of the paper. It highlights a potential area of confusion for the authors, as the update process is not clearly explained. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it offer any additional insights or improvements. While it identifies a potential area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several areas where additional information is missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are explicit and provide clear guidance on what information needs to be included to improve the paper. The authors can directly apply these actions to enhance the completeness and clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for additional information in the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what information is missing and what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the completeness of the empirical study, including the need for recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are logical and provide clear guidance on what information is missing, making the claim 3. However, the comment could be more robust if it included specific examples or references to support the need for these details. Overall, the comment is 4, as it provides a clear basis for improvement but lacks some depth in terms of evidence or examples.", "helpfulness_rationale": "The review comment identifies several important areas where additional information is missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are clear and actionable, providing the authors with specific guidance on what information needs to be included to enhance the completeness and clarity of their draft. The feedback is 4 as it offers detailed and constructive suggestions that would significantly improve the paper, though it could be further expanded to include additional recommendations or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant risk of methods exploiting relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, mentioning that AU6 can occur in both expressions of pain and happiness, and that this cooccurrence differs in datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The comment explicitly suggests a concrete action for the authors to take, which is to perform crossdataset experiments to address the issue of datasetspecific variations in relationships between action units. This provides clear guidance on how the authors can improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"action units\" and \"datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue of varying relationships between action units across different datasets, providing clear guidance on how to test the generalization of the work through crossdataset experiments. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units can lead to different cooccurrences across datasets, such as AU6 in pain and happiness, which vary in datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. While the claim is supported by the observation of different cooccurrences in Figure 1, the reasoning could be more detailed, and the suggestion for crossdataset experiments is logical but could benefit from further elaboration or examples. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the variability of these relationships across different datasets. It provides a concrete example, noting that AU6 can occur in both expressions of pain and happiness, and that this cooccurrence differs significantly between datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, which is a valuable and actionable suggestion for the authors. By pointing out this issue and offering a specific direction for improvement, the comment is 4, as it provides clear guidance on how the authors can enhance their research. However, it could be more comprehensive if it included additional suggestions or elaborated on the implications of this variability."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional detail would be beneficial, it does not explicitly instruct the authors to provide this description or specify how it should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the description of the Starcraft environment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this description should be included in or how it should be integrated. The comment is 1 as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also not specific because it does not detail what aspects of the Starcraft environment description are missing or how it should be expanded. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, the comment does not provide any specific reasoning or evidence to support why this additional description would be beneficial or how it would enhance the paper. Without detailed justification or examples, the claim lacks sufficient support, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While this feedback provides a specific area for improvement, it lacks depth and actionable guidance. The authors are left to infer that additional detail would be beneficial, but the comment does not specify what aspects of the Starcraft environment description are missing or how it should be expanded. This limits the comment\"s helpfulness, as it does not offer a clear path for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern regarding the timeconsuming nature of the training process due to the pixellevel shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a highorder factor graph with four types of factors. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to improve the efficiency of the training process or how to compare the processing efficiency with existing work. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the training process due to the pixellevel shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a highorder factor graph with four types of factors. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the timeconsuming nature of the training process due to the pixellevel shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a highorder factor graph with four types of factors. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the training process is timeconsuming or that the parsing model is complex. Without these elements, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the training process due to the pixellevel shape model and the independent training on all font images and characters. It also highlights the complexity of the parsing model as a highorder factor graph with four types of factors. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the efficiency of their training process. Without actionable advice or detailed feedback, the authors may find it challenging to incorporate these points into their draft. Therefore, the comment is 2, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors combine two existing techniques without innovation and questions the use of an old and simple domain adaptation method. It implies that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not provide explicit guidance on which specific methods to use or how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the need for improvement and the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of two existing techniques and questions the use of an old and simple domain adaptation method. It provides specific guidance on considering more recent and effective domain adaptation methods to improve performance. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors combine two existing techniques without innovation and questions the use of an old and simple domain adaptation method. It suggests considering more recent and effective methods to improve performance. However, the comment lacks specific examples or references to support the claim about the novelty of the combination or the effectiveness of the proposed methods. Without detailed evidence or references, the claim is difficult to verify, making it 2. The authors would need to provide more context or evidence to fully understand the basis of the critique.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the authors combine two existing techniques without introducing significant innovation. It questions the use of an old and simple domain adaptation method, implying that more recent and effective methods could enhance the performance of the framework. The comment provides a clear direction for improvement by suggesting the authors consider adopting more advanced domain adaptation techniques. However, it could be more helpful if it offered specific examples of recent methods or guidance on how to implement the suggested improvements. Overall, the comment is 4 as it highlights an area for enhancement and provides a clear direction for the authors to follow, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors can address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to enhance the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not specify which part of the paper is challenging to follow or provide any details on what aspects of the motivation are unclear. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide any suggestions or guidance on how to improve the motivation or address the concern about being an incremental engineering paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is difficult to follow and suggests it might be an incremental engineering paper. However, it does not provide any specific evidence, reasoning, or references to support these claims. Without detailed justification or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: difficulty in following the motivation and the perception of it being an incremental engineering paper. However, it lacks specific details or actionable suggestions on how the authors can address these concerns. While it highlights areas for improvement, the feedback is somewhat vague and does not provide clear guidance on what changes might be necessary. This makes the comment 3, as it offers a general direction for improvement but lacks depth and specificity. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial. It also mentions that the authors note a specific scenario where their method underperforms, suggesting that the weighting might have helped. However, the comment does not provide explicit guidance on how to conduct the ablation study or what specific aspects to focus on. While the suggestion is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, which is a specific aspect of the paper. It mentions that the authors note a specific scenario where their method underperforms, suggesting that the weighting might have helped remedy this issue. However, the comment does not explicitly mention which part of the paper discusses the weighting method or the specific scenario where the method underperforms. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. The comment is specific in its suggestion but weakly grounded as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an ablation study on the weighting method of the crossentropy loss, noting that the authors mention a specific scenario where their method underperforms, such as \"the game has repetitive background sounds.\" This observation implies that the weighting method might have helped remedy the issue. However, the comment lacks detailed reasoning or examples to fully support the claim. It does not provide specific references or detailed explanations of why the weighting method could have improved the results in the mentioned scenario. As a result, the claim is 3, as it is based on a logical inference but lacks sufficient evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, noting that the authors mention a specific scenario where their method underperforms, such as \"the game has repetitive background sounds.\" This observation implies that the weighting method might have helped remedy the issue. However, the comment does not provide detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it identifies a potential area for improvement, it lacks depth and actionable suggestions, making it 3. The authors would gain some insight into the need for further analysis but would require additional guidance to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a critical weakness in the paper, stating that it lacks novelty and is incremental in nature. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit suggestions on how the authors might address these issues or improve the paper. The authors are left without guidance on how to enhance the novelty or significance of their work, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper discusses the dataset or the approach, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific in its critique of the methodology, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, criticizing the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentioning another synthetic benchmark paper based on a single question template. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable suggestions or insights on how the authors might address these issues or improve the novelty of their work. Without specific guidance or suggestions, the authors are left without a clear path forward, making the comment 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not provide specific guidance on how to demonstrate the importance of these assumptions or what kind of examples would be effective. The action is implicit, as the authors need to infer that they should provide detailed explanations and examples to support their claim. While the comment is 3, it lacks concrete details on how to implement the suggested action, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for detailed explanations and examples, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis for this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. This feedback is actionable as it provides a clear direction for the authors to enhance their paper by offering detailed explanations and examples to support their claims. However, the comment could be more helpful if it included specific examples or guidance on how to demonstrate the importance of these assumptions. Overall, the comment is 4 as it directs the authors towards a crucial aspect of their work that needs further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern regarding the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet18, and mentions the accuracy is around 70%. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to improve the implementation. While the authors might infer that they need to optimize their implementation, the lack of explicit instructions or detailed suggestions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ImageNet\" and provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet18, as well as the accuracy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the performance issues with the implementation, including the time taken and accuracy, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, providing specific details such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and an accuracy of around 70%. This claim is supported by specific numerical data, making it 4. However, the comment could be strengthened by providing more context or comparison to other implementations, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the accuracy of around 70%. This feedback is clear and actionable, as it highlights a critical performance bottleneck that the authors need to address. By pointing out these specific issues, the comment guides the authors to improve the efficiency and accuracy of their implementation, which is essential for the paper\"s overall quality and impact. Therefore, the comment is 5, as it provides detailed and constructive feedback that empowers the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, it does not provide explicit or implicit actions for the authors to take, such as conducting experiments or providing detailed reasoning. The comment lacks concrete guidance on how the authors might address this question or incorporate it into their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide explicit references to sections, tables, or figures. While it is specific in its suggestion about the potential benefits of labeled data, the lack of grounding makes it challenging for the authors to understand the context and relevance of the comment. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, the comment does not provide any specific reasoning, examples, or references to support the claim that labeled data could be beneficial. Without detailed justification or evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. It provides a brief rationale by mentioning that labeled data has exact labels, which might be useful for consistency training in graph anomaly detection. However, the comment lacks depth and does not offer specific guidance or suggestions on how the authors might explore this idea or incorporate it into their work. While it identifies a potential area for improvement, it does not provide actionable steps or detailed reasoning, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental part needs to be reorganized and further improved. It highlights that the current experimental content in the main text does not effectively showcase the superiority of the method. The comment implies that the authors should reorganize the experimental section to better highlight the method\"s advantages. However, it does not provide specific guidance on how to reorganize the content or what aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental part needs to be reorganized and further improved, indicating that the authors should reorganize the experimental section to better highlight the method\"s superiority. However, the comment does not specify which part of the paper the experimental section is located in, making it weakly grounded. It also lacks specificity in detailing what aspects of the experimental content need to be improved to showcase the method\"s superiority. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental part needs to be reorganized and further improved, indicating that the current content in the main text does not effectively highlight the superiority of the method. However, the comment lacks specific details or examples of how the experimental content could be reorganized or improved to better showcase the method\"s advantages. Without concrete suggestions or references, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a need for reorganization and improvement in the experimental part of the paper. It points out that the current content in the main text does not effectively highlight the superiority of the method, suggesting that the experimental section should be restructured to better showcase this advantage. However, the comment lacks specific guidance on how to reorganize the content or what aspects should be emphasized. While it provides a clear direction for improvement, the lack of detailed suggestions or examples makes it 3. The authors would need to infer the exact steps to take, which limits the comment\"s impact. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time, and it recommends publishing the code. However, the comment does not provide explicit guidance on how the authors should address this question or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its inquiry about the training time, the lack of grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time and recommends publishing the code. However, the comment does not provide any evidence, reasoning, or references to support the claim that the training time is reasonable or that the code should be published. Without specific justification or examples, the claim is 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time and recommends publishing the code. However, the comment lacks specific guidance or actionable advice on how the authors might address this question or improve their draft. While it identifies an area for clarification, it does not provide detailed suggestions or insights that would be helpful for the authors to enhance their work. Therefore, the comment is 2, as it offers limited value in terms of actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. It does not provide explicit instructions on how to address these points, such as suggesting specific sections or types of descriptions to include. The comment is somewhat vague, as it implies that the authors should consider these aspects but does not offer concrete guidance on how to do so. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is vague and does not provide detailed guidance on what needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the clarity of the paper regarding the concept of Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It asks for clarification on why entropy is not a good measure of the spreading of teacher predictions, specifically referencing line 115 and line 113. However, the comment does not provide any evidence, reasoning, or references to support these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the concept of Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It questions why entropy is not a good measure of the spreading of teacher predictions, particularly referencing lines 113 and 115. While the comment highlights a potential gap in the paper\"s explanation, it does not provide specific suggestions or guidance on how to address this issue. The feedback is 3 as it points out a need for clarification, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline\"s performance and the claim made in the abstract. It points out that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the draft. The action is implicit, as the authors need to infer that they should clarify the discrepancy in the human baseline\"s performance and the abstract\"s claim. The action is somewhat vague, as it does not specify how to address the issue or what changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the human baseline, specifically mentioning that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This provides a clear reference point for the authors to understand which part of the paper is being discussed. However, the comment does not specify what needs to be addressed in this part, such as how to improve the human baseline or clarify the discrepancy in the abstract. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also points out that the abstract mentions a human baseline achieving a certain performance level, which is misleading given the discrepancy in recording lengths. However, the comment lacks specific examples or references to support the claim about the human baseline\"s performance. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline in the paper, noting that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also points out a potential misleading claim in the abstract regarding the human baseline\"s performance. While the comment highlights a valid concern, it does not provide specific guidance on how the authors might address this issue or what changes could be made to improve the human baseline or the abstract\"s claim. The feedback is 3 as it identifies a weakness but lacks actionable suggestions for improvement, leaving the authors with limited direction for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the strong assumptions made for the termination states of instructions, particularly in the general case where manual labeling of large datasets is expensive. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the draft to improve it. The comment identifies a potential weakness but lacks actionable guidance, leaving the authors without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, noting that it is strong and expensive to label data manually in the general case. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the nature of the issue, the lack of grounding makes it challenging for the authors to fully understand and address the concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is strong and expensive to label data manually in the general case. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumptions made for the termination states of instructions, specifically noting that it is expensive to label data manually in the general case. This feedback highlights a limitation in the assumptions and suggests that the authors should consider the practical implications of this expense. However, the comment lacks specific guidance on how the authors might address this issue or what changes could be made to the draft to improve its relevance or applicability. While it points out a potential weakness, it does not provide actionable advice or suggestions for improvement, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is explicit and provides a clear action for the authors to take: they should consider incorporating these methods as baselines in their experiments. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a gap in the related work by noting that while other methods for training NMT models beyond MLE are discussed, none of them are used as baselines. This provides a clear and specific direction for the authors to improve their draft by including these methods as baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section discusses other methods for training NMT models beyond MLE but does not include any of these methods as baselines. This claim is 3 as it highlights a gap in the related work section, but it lacks specific examples or references to support the claim. The authors would need to infer that the omission of these methods as baselines is a significant oversight. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the related work section by noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is clear and actionable, as it provides a specific suggestion for improvement: the authors should consider incorporating these methods as baselines in their experiments. By doing so, the authors can provide a more comprehensive comparison and better contextualize their work. This feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it suggested specific methods or baselines to include. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the term \"efficient proxy\" used in the paper. It suggests that the authors might be referring to a particular proxy or a family of efficient proxies, but the paper does not provide a clear definition or context. While the comment implies that the authors need to clarify this term, it does not explicitly instruct them to do so or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is discussed, making it difficult for the authors to pinpoint the exact location. Additionally, the comment does not provide specific guidance on how to clarify the term or address the potential ambiguity. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left to interpret the ambiguity themselves, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the clarity of the term \"efficient proxy\" used in the paper. It points out that the term could be interpreted in two ways: as a particular efficient proxy or as a family of efficient proxies. The comment suggests that the authors might be referring to a particular proxy, but the paper does not provide a proxy called \"Efficient Proxy,\" which implies that the authors are discussing a family of proxies. This feedback highlights a potential ambiguity in the terminology used, which could lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as clarifying the term or providing additional context. As a result, the comment is 3, as it identifies a potential area for improvement but lacks actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses an opinion about the model\"s simplicity, suggesting that it is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the model\"s simplicity, suggesting that it is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. Without this context, the authors cannot accurately identify where the issue lies, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the model\"s simplicity need to be addressed. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the model being overly simple, suggesting it is both a feature and a bug. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the model being overly simple, suggesting it is both a feature and a bug. However, it lacks specific details or actionable suggestions on how the authors might address this issue. The comment does not provide guidance on potential improvements or alternative approaches to enhance the model\"s complexity or relevance. As a result, the feedback is vague and does not offer substantial value to the authors in terms of actionable advice or constructive suggestions. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the work\"s narrow focus on a specific task and language might limit its broader impact. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might broaden the scope or impact of their work. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section being discussed. It is also not specific because it does not detail what aspects of the narrow task or specific language might limit the broader impact. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively. Therefore, this comment is rated as 1.", "verifiability_rationale": "The review point claims that the work\"s narrow focus on a specific task and language might limit its broader impact. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without supporting evidence, the authors may find it challenging to understand or address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the work, noting that its narrow focus on a specific task and language might limit its broader impact. While this observation is insightful, it lacks actionable guidance or suggestions on how the authors might address this limitation. The comment does not provide specific advice on expanding the scope or impact of the work, leaving the authors with limited direction for improvement. Therefore, the comment is 3, as it highlights an important consideration but does not offer detailed guidance for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of runtimes in the experiments to aid readers in applying the method. While the comment provides explicit guidance on what should be included, it lacks specific details on how to integrate this information into the main paper or experiments. The authors know that they need to add this information but are not given precise instructions on where to place it or how to present it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of runtimes in the experiments to aid readers in applying the method. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to know exactly where to apply the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should mention the negligible computational cost of CHR in the main paper to motivate the method and include runtime examples in the experiments. This claim is 3 as it provides a logical suggestion for improving the paper\"s clarity and motivation. However, it lacks specific examples or references to support the claim, making it 3. The authors would benefit from additional details or references to strengthen the claim.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by mentioning the negligible computational cost of CHR and suggesting the inclusion of runtime examples in the experiments. This feedback is actionable and offers concrete guidance on how the authors can enhance the motivation and clarity of their work. However, the comment could be more helpful if it provided more detailed examples or suggestions on how to present the runtime data effectively. Overall, the feedback is 4 as it directs the authors towards important improvements that would benefit the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. The comment is explicit in its request for clarification and provides a concrete action for the authors to take, which is to elaborate on the process and its interpretation. This guidance is clear and specific, allowing the authors to understand exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the interpretation of the EEG topography plots and suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This provides a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ambiguity in interpreting Figure 3, which presents EEG topography plots for both input and output during the EEG token quantization process. The comment suggests that the authors should elucidate this procedure in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. However, the comment does not provide specific examples, detailed reasoning, or references to support why this clarification is necessary or how it would enhance the understanding of the process. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both input and output during the EEG token quantization process lead to ambiguity in interpretation. The comment suggests that the authors should elucidate this procedure in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and interpretability of their results. By addressing this suggestion, the authors can enhance the understanding of their methodology and its implications, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria used for this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detail and consider additional tasks or datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in its suggestion to provide more detail and consider additional tasks or datasets, but without clear references to specific sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not provide any specific reasoning, examples, or references to support why this choice might limit generalizability or what alternative approaches could be considered. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It questions whether the criteria for this selection are clear and whether other tasks or datasets might provide different insights. This feedback is 3 as it highlights an important aspect of the study that could impact the broader applicability of the findings. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue, such as suggesting additional tasks or datasets to consider or providing more detailed criteria for the selection process. Without such guidance, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. While it points out that the authors may be assuming the reader understands the concept of tumour growth, it does not provide explicit guidance on how to address this issue. The comment suggests that the authors should clarify the modelling process, but it does not offer specific steps or examples on how to do so. As a result, the authors are left with a vague understanding of what action to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of clarity regarding what is being modelled in the context of modelling curves, particularly in the second paragraph of the introduction. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction is unclear about what is being modelled, specifically mentioning tumour growth. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modelling curves but lacks clarity on what is being modelled, particularly in the context of tumour growth. While the comment points out a potential area for improvement, it does not provide detailed suggestions or guidance on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, making the feedback 3. It could be more helpful if it offered specific suggestions or examples of how to improve the clarity of the modelling process described in the introduction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should provide more explanation to clarify certain aspects, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically mentions the CBR contribution and asks for a discussion on the implications of minimizing different terms in Equation 3. However, the comment does not provide explicit guidance on how to improve the explanation or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide more explanation, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically mentions the CBR contribution and asks for a discussion on the implications of minimizing different terms in Equation 3. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the need for more explanation and discussion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper should provide more explanation to clarify certain aspects, particularly regarding the main contributions and the discussion of different optimization strategies. It suggests that the authors should discuss the implications of minimizing different terms in Equation 3. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the reasoning behind the suggestion. The feedback is 3 as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for more explanation in the paper, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically asks for a discussion on the implications of minimizing different terms in Equation 3, which provides a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to enhance the explanation or suggested specific areas where more detail is needed. Overall, the feedback is 3 as it highlights important aspects for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\"s proofs. This provides a clear and explicit action for the authors to take, as they can directly incorporate this definition into their draft. The comment is specific in its suggestion, detailing exactly what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\"s proofs. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it refers to the section where treewidth is discussed or used in the proofs. This makes the comment weakly grounded, as the authors need to make an educated guess to identify the relevant part. However, the comment is specific in detailing what needs to be addressed, which is the inclusion of a definition of treewidth. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\"s proofs. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to support why this definition is necessary or how it would enhance the paper. The authors would need to infer the importance of this definition based on the context of the proofs, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\"s proofs. This feedback is clear and actionable, as it provides a specific and concrete suggestion for improvement. By adding this definition, the authors can enhance the clarity and comprehensibility of their paper, making it easier for readers to understand the proofs. The comment is 4 as it directly addresses a key aspect of the paper that could improve its overall quality and accessibility. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, it does not provide explicit guidance on how to conduct this analysis or what specific steps the authors should take. The action is implicit, as the authors need to infer that they should analyze the quality of the local minima. While the comment is 3, it lacks concrete details on how to implement the suggested analysis, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of local minima, particularly the approximation ratio, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggested improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that while the paper analyzes the convergence of Algorithm 1 to permutations as local minima, it does not delve into the quality of these local minima. The comment suggests that the authors should consider analyzing the approximation ratio of these local minima under certain assumptions, which is a valuable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or examples of relevant literature. Overall, the feedback is 3 as it highlights an important aspect that could enhance the paper, but it lacks depth and detail to fully guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the paper\"s selfcontained nature and suggests that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments. While the comment identifies specific issues and requests, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take to improve the paper. The actions are implicit and somewhat vague, as the authors are left to infer how to make the paper selfcontained and reproducible. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s selfcontained nature and suggests that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments. However, the comment does not specify which sections or parts of the paper are affected by this issue, making it weakly grounded. The comment is specific in detailing the need for the supplementary material and the release of source code, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not selfcontained understandable given the NIPS format, but the supplementary material is necessary to understand large parts of the main paper and allow reproducibility. It also requests the authors to release the source code of their experiments to allow reproduction of their results. However, the comment lacks specific examples or references to support the claim about the paper\"s understandability or the necessity of the supplementary material. While the request for source code is clear, the overall claim is not welljustified, making it 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontained nature, noting that it is not understandable given the NIPS format, and that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments to allow for the reproduction of their results. This feedback is clear and actionable, providing the authors with specific areas to address and concrete steps to take. However, the comment could be more helpful if it offered additional guidance on how to make the paper more selfcontained or how to ensure reproducibility beyond simply releasing the source code. Overall, the comment is 4 as it highlights important issues and provides actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, specifically referencing a sentence in the paper. It does not provide explicit instructions or suggestions on how to address this question or improve the draft. The comment is vague and lacks concrete guidance, leaving the authors uncertain about what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any evidence, reasoning, or references to support the claim or question raised. Without additional context or justification, the authors are left without guidance on how to address the question or improve their understanding of the algorithms. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any suggestions or guidance on how to address this question or improve the draft. The comment lacks actionable feedback, leaving the authors without a clear understanding of what to do or how to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. It implies that the authors should clarify why they chose REINFORCE, potentially referencing the attention model paper they are building upon. However, the comment does not explicitly instruct the authors to include this rationale in their draft or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a rationale for their choice of algorithm. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. However, it does not specify which part of the paper this rationale should be included in, making it weakly grounded. The comment is specific in that it requests clarification on the reasoning behind the algorithm choice, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to address this feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. While the comment implies that the authors should clarify their reasoning, it lacks specific examples or detailed explanations of why REINFORCE was chosen over PPO. Without additional context or justification, the claim is 3, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to improve their draft by explaining the rationale behind their choice of the REINFORCE algorithm for training. It specifically requests clarification on why this algorithm was chosen over alternatives like PPO, which is relevant to the attention model paper the authors are building upon. This feedback is valuable as it prompts the authors to provide a detailed justification for their methodological choices, enhancing the transparency and rigor of their work. However, the comment could be more helpful if it included specific examples or guidance on how to articulate this rationale effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater depth and detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to their draft. The comment is specific in its request for additional experiments, which helps the authors understand exactly what needs to be done to strengthen their claims. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides the authors with a clear understanding of what additional experiments are required to support their claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This claim is 3 as it provides a clear direction for the authors to take, but it lacks specific examples or references to support the need for such experiments. While the suggestion is logical, the absence of detailed reasoning or examples makes it somewhat challenging for the authors to fully understand and implement the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include experimental results of excluding the mixup technique from their proposed method. This is a clear and actionable suggestion that would help demonstrate the pure contribution of the proposed method. By providing a specific direction for additional experiments, the comment offers valuable guidance to the authors, enhancing the depth and impact of their work. Therefore, the comment is 4, as it provides a clear and constructive feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide explicit guidance on what needs to be addressed or how to improve the analysis. The authors are left to infer that they should either provide a more detailed analysis or acknowledge that this aspect is not covered. This lack of explicit action or guidance makes the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the highfrequency range. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its focus on the theoretical support, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that this is an essential theoretical support. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. This feedback highlights a potential gap in the paper\"s theoretical foundation, which is crucial for understanding the merits of Fourier features. However, the comment does not provide specific guidance or suggestions on how to address this gap or improve the analysis. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to their draft. The comment lacks concrete guidance on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for details, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely factual and descriptive, lacking any opinions or assertions that could be challenged or supported. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the methodology, noting that the authors do not provide details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback is valuable as it highlights a potential gap in the clarity and completeness of the methodology section. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their draft. Without specific advice or examples, the authors may find it challenging to incorporate the necessary details. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning details like data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not explicitly instruct the authors to provide this information or clarify it in their draft. While the authors can infer that they need to include this information, the action is implicit and somewhat vague. The lack of explicit guidance on how to address this issue makes the comment 3.", "grounding_specificity_rationale": "The comment asks for clarification on the experiment setup in Section 3.3, specifically mentioning details like data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not specify which part of Section 3.3 is being referred to, making it weakly grounded. The comment is specific in its request for clarification and provides a reference, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning details like data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not contain a claim that requires verification. It is a request for clarification and additional information, which is helpful but does not involve making a claim that needs to be substantiated. Therefore, this comment is classified as \"No\".", "helpfulness_rationale": "The review comment requests clarification on the experiment setup in Section 3.3, specifically mentioning details such as data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. It lacks actionable feedback, making it unhelpful for the authors to enhance their work. Therefore, the comment is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether an error in the initial calibration steps of the algorithm might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to investigate or correct the error. The comment lacks concrete guidance on how to proceed, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" which provides full grounding as the authors can accurately identify the section being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. This feedback is 3 as it identifies a potential issue that could impact the results, prompting the authors to investigate and address it. However, the comment lacks specific guidance on how to identify or correct the error, making it incomplete. The authors would need to conduct further analysis or seek additional information to fully address the concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically focusing on common inference tasks. It asks which tasks can be computed exactly or approximately with an NPSPECHMM. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete actions or detailed feedback, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of these distributions on inference and asks about common inference tasks in discrete HMMs, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NPSPECHMM. While the question is clear and directly relates to the paper\"s focus, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks depth and does not offer any guidance or justification for the question, making it difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NPSPECHMM. This question highlights a potential gap in the paper\"s discussion of how these distributions affect inference. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. It lacks actionable feedback, leaving the authors without clear direction on how to enhance their work. Therefore, the comment is 2, as it identifies a relevant area for improvement but does not offer any constructive advice or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a deficiency in the analysis of experimental results, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to conduct a deeper analysis or provide guidance on how to address this issue. The action is implicit, as the authors can infer that they need to expand their analysis to include reasons for the poor performance. However, the lack of concrete guidance on what specific analysis to conduct makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, providing a clear indication of what needs to be addressed. This level of detail helps the authors understand exactly where the issue lies and what kind of analysis is missing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or references to support the claim. The authors could strengthen the comment by providing more detailed reasoning or examples to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the analysis of experimental results, specifically pointing out that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to expand their analysis and provide a deeper understanding of the results. By highlighting this gap, the comment encourages the authors to enhance the depth and comprehensiveness of their experimental analysis, which is crucial for a thorough evaluation of their work. Therefore, the comment is 4, as it provides a clear direction for improvement but could be further enhanced with specific suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. While the comment implies an action\u2014namely, to provide a justification for the selection of datasets\u2014it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain their dataset selection process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the dataset selection process, but without explicit grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any justification or reasoning for this choice, nor does it offer any references or examples to support the claim. Without additional context or explanation, the authors are left to infer the reasoning behind this decision, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. This question highlights a potential gap in the analysis or justification of the dataset selection process. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it points out a potential issue but does not offer concrete solutions or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the clarity of the explanation. The authors are left to infer that they need to clarify the calculation of \u03bb and provide a clearer explanation of the ELLA\"s sample efficiency in COMBO environments. This lack of explicit action and detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (Page 9, lines 310313 and Page 8, lines 281285), allowing the authors to accurately identify the parts being addressed. It also specifies what the authors need to understand, namely the process of calculating \u03bb and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. Additionally, the comment references specific papers 1, 2, and 3, which provides context and suggests further reading. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment lacks specific details or references to support these claims, making it difficult for the authors to understand the basis of the concern. The absence of detailed reasoning or examples makes the claim 3, as the authors may need to infer the basis of the concern themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment, referencing specific papers that could provide context. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the clarity of the explanation. While it identifies areas for improvement, it does not provide actionable steps or specific advice on how to enhance the paper\"s clarity or address the concerns. Therefore, the comment is 3, as it highlights important areas for clarification but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point mentions that an alternating direction method is used to solve a minmin problem but does not specify which method is being referred to. This lack of specificity makes it difficult for the authors to understand which method is being discussed and how it relates to the minmin problem. Without additional context or clarification, the authors are left without a clear action to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is being discussed or how the authors should address the issue. The comment lacks both grounding and specificity, making it difficult for the authors to understand and respond to it effectively. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point is a factual statement about the use of an alternating direction method to solve a minmin problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is brief and lacks specificity, as it only mentions that an alternating direction method is used to solve a minmin problem without specifying which method is being referred to. This lack of detail makes it difficult for the authors to understand the context or how to address the issue. The comment does not provide any actionable feedback or suggestions for improvement, leaving the authors with no guidance on how to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies specific areas of concern, it does not provide explicit guidance on how the authors should address these issues or what actions they should take to improve the algorithm. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the effectiveness of lower bound double qlearning, specifically mentioning the MsPacman environment in Figure 2 where the algorithm shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. However, the comment does not specify which part of the paper discusses these environments or the algorithm\"s performance, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to understand which part of the paper needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies potential issues with the algorithm\"s performance and convergence, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve the algorithm. The feedback is 3 as it highlights areas for improvement, but it lacks actionable advice, making it difficult for the authors to take concrete steps to enhance their work. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear understanding of how to proceed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without this context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the novelty of the paper. Therefore, the comment is 1 and lacks specificity, making it ungrounded and not specific. This aligns with category 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this claim is made or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the paper, suggesting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. It lacks actionable advice, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is 2, as it highlights a concern but does not offer constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches from below rather than above. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit, as the authors need to infer that they should clarify the performance discrepancy and provide an explanation. While the action is somewhat vague, it is clear that the authors need to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA becoming worse than vanilla DNN when lambda is small, and it questions the expected behavior. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches from below rather than above. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the performance is expected to approach from above. Without additional context or justification, the claim is difficult to verify, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It points out that the performance is worse and questions why it approaches from below rather than above, which is unexpected. This feedback is 3 as it highlights a potential area of confusion or inconsistency in the results. However, the comment lacks actionable guidance on how the authors might address this issue or what specific changes could be made to the draft to clarify the performance discrepancy. Without further suggestions or detailed explanations, the authors may find it challenging to improve their draft based on this feedback alone. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper by noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not comparing with stateoftheart systems, they have compared their results with earlier systems that have worse performance, such as Taghipour and Ng (2016). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific comparisons would be beneficial. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional comparisons and the specific areas where they should focus. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison of results with earlier research work from 2020, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by highlighting the lack of comparison with stateoftheart systems and suggesting comparisons with earlier systems like Taghipour and Ng (2016). This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not comparing with stateoftheart systems, they have compared their results with earlier systems that have worse performance, such as Taghipour and Ng (2016). However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide a clear explanation of why the comparison with earlier work is important or how it would enhance the paper\"s contribution. As a result, the claim is 3, as it is based on the authors\" explanation but lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of comparisons with earlier research work from 2020. While the authors have explained their reasons for not comparing with stateoftheart systems, the comment highlights the need for such comparisons to provide a more comprehensive evaluation of the paper\"s contributions. However, the feedback lacks specific suggestions or guidance on which earlier works should be compared or how the comparison should be structured. This limits the authors\" ability to effectively address the feedback and improve their draft. Therefore, the comment is 3, as it points out an important area for improvement but does not provide detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should elaborate on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. It implies that the current explanation is insufficient and that the authors should provide more detail to clarify this point. The action is explicit, as it directly instructs the authors to elaborate on the conditions for Hoeffding\"s inequality to hold. However, the comment lacks specific guidance on how to elaborate, such as suggesting additional details or examples. Therefore, the action is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely lines 124125. This allows the authors to accurately identify the section being discussed. The comment is also specific because it provides a clear request for elaboration on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. This guidance is detailed and specific, allowing the authors to understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should elaborate on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. The comment provides a logical reasoning by explaining that the bound holds under specific conditions, such as independent samples, and that stochastic algorithms further guarantee its validity. However, it lacks specific examples or references to support the claim, making it 3. The authors would benefit from additional details or examples to fully understand and address the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors could provide more elaboration, particularly regarding the conditions under which Hoeffding\"s bound holds. It suggests that the authors should elaborate on the role of stochastic algorithms in guaranteeing the validity of the inequality. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to elaborate, such as suggesting specific examples or detailed explanations. Overall, the comment is 4, as it directs the authors to a specific area for improvement but lacks some depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. While it implies that this addition would be beneficial, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the table would benefit from such an addition. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to incorporate the suggested approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not specify which part of Table1 would benefit from this addition or what specific issues the authors are addressing. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also specific in suggesting a particular approach, but without context, it is difficult for the authors to understand how to apply this suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not provide any justification or reasoning for why this addition would be beneficial or how it would improve the paper. Without specific examples or references, the claim lacks support and is therefore 1. The comment is purely speculative and does not offer any actionable guidance for the authors to follow.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. This feedback is 3 as it points out a potential area for improvement by suggesting a specific technique that could enhance the paper. However, the comment lacks depth and does not provide detailed reasoning or guidance on why this addition would be beneficial or how it would impact the overall contribution of the paper. The authors are left to infer the exact steps needed to incorporate this suggestion, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using fewshot examples for ChainofThought (CoT). However, it does not provide explicit guidance on how the authors should conduct or present this ablation study. The action is implicit, as the authors need to infer that they should include an ablation study to justify their prompt choice. While the comment is 3, it lacks concrete details on how to implement the suggested improvement, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using fewshot examples for ChainofThought (CoT). However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental section. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in that it identifies the need for an ablation study and suggests a potential reason for the choice of prompt, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using fewshot examples for ChainofThought (CoT). However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the paper lacks such an ablation study. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of an ablation study explaining the choice of prompt, particularly the use of fewshot examples for ChainofThought (CoT). This feedback is 3 as it highlights a potential gap in the paper\"s analysis and suggests a way to strengthen the justification for the chosen methodology. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or why this specific choice is important. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, it does not provide explicit guidance on how the authors should revise the text to address this concern. The comment implies that the authors need to clarify their use of the term, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential issue but does not provide detailed guidance on how to implement the suggested change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" recommending careful consideration of its distinction from temporal relationships. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment on page 1 points out a potential issue with the use of the term \"causal mechanisms,\" suggesting that it should be used carefully as it is distinct from a temporal relationship. This feedback is clear and identifies a specific area for improvement, but it lacks detailed guidance on how the authors might address this concern. While it provides a starting point for revision, it does not offer comprehensive suggestions or examples, making it 3. The comment is valuable in highlighting a potential area of confusion, but it could be more helpful with additional guidance on how to revise the text. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide explicit guidance on how to incorporate this discussion into the draft or what specific aspects of the results should be addressed. The action is implicit, as the authors need to infer that they should add a discussion related to the mentioned paper. While the suggestion is concrete in terms of the topic, the lack of explicit guidance on how to implement it makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. It is specific in suggesting the inclusion of a discussion related to the mentioned paper, but without clear guidance on how to integrate it into the draft. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". This feedback is 3 as it identifies a specific area for improvement by suggesting a relevant discussion that could enhance the paper\"s context and depth. However, the comment lacks detailed guidance on how to incorporate this discussion or what specific aspects of the results should be addressed. While it provides a clear direction for improvement, the lack of actionable advice limits its overall helpfulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper\"s results is unclear. It also provides a rationale for why PCA is intuitive and requests clarification on whether the assumptions are met, referencing a specific paper. While the comment identifies a potential issue with the novelty and significance of the paper, it does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve the paper. The action is implicit, as the authors need to infer that they should discuss the novelty and significance of their approach and address the assumptions of PCA. However, the comment lacks concrete details on how to do so, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce the interaction count and questions its significance, suggesting that it is incremental. It also requests clarification on whether the assumptions of PCA are met, referencing a specific paper. However, the comment does not specify which part of the paper discusses the use of PCA or the results that are unclear. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the approach, but without explicit references, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the novelty of using PCA to reduce the interaction count and the clarity of the paper\"s results. It suggests that the approach is intuitive and requests clarification on whether the assumptions of PCA are met, referencing a specific paper. However, the comment does not provide detailed reasoning or examples to support the claim that the novelty is incremental or that the significance of the results is unclear. While the reference to the paper provides some context, the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper\"s results is unclear. It provides a rationale for why PCA might be intuitive and requests clarification on whether the assumptions of PCA are met, referencing a specific paper. This feedback is 3 as it identifies a potential area for improvement in the paper\"s novelty and significance. However, it lacks detailed guidance on how the authors might address these concerns or what specific aspects of their approach need to be clarified. The comment could be more helpful if it provided more detailed suggestions or examples of how to improve the paper\"s novelty and significance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the use of fewshot RC models in the paper, suggesting that they are not stateoftheart and asking for a comparison with relation extraction/generation models in fewshot settings. While the comment identifies a potential issue with the choice of models, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit, as the authors need to infer that they should consider using more advanced models and compare their performance. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the use of fewshot RC models in the paper, suggesting that they are not stateoftheart and asking for a comparison with relation extraction/generation models in fewshot settings. However, the comment does not specify which part of the paper discusses the choice of models or where the authors should compare their performance. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its request for comparison, the absence of explicit references or sections makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of fewshot RC models in the paper, suggesting that they are not stateoftheart and asking for a comparison with relation extraction/generation models in fewshot settings. The comment provides specific references to support the claim that the models used are not stateoftheart. However, it does not offer detailed reasoning or examples to fully substantiate the claim, leaving room for the authors to seek additional evidence or clarification. Therefore, the claim is 3, as it is supported by references but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of fewshot RC models used in the paper, suggesting that they are not stateoftheart. It also raises a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment points out a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their models. The feedback is 3 as it highlights a potential weakness but lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the results in section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might extend their results to deeper networks or how they could improve the scope of their findings. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results in section 4 apply only to shallow fullyconnected ReLU networks, providing a clear understanding of the limitation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. This is a factual statement that is supported by the content of section 4, which likely discusses the limitations of the results to such networks. However, the comment does not provide additional context, examples, or references to support this claim beyond what is already present in the paper. While the claim is verifiable, it lacks depth and could be strengthened with more detailed reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results presented in section 4, noting that they apply only to shallow fullyconnected ReLU networks. This is a clear and actionable piece of feedback that highlights a potential gap in the scope of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their findings to include deeper networks. While it points out an important area for improvement, the lack of actionable advice limits its overall helpfulness. Therefore, the comment is rated as 3, as it identifies a specific issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide results for the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not specify how the authors should present these results or what aspects of the results are important to highlight. The comment implies that the authors should include results, but it lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more information about what was observed in this discussion, indicating that the authors need to provide results or detailed observations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB vs a single MCT layers for the decision head, noting that no results were shown. However, it does not provide any specific reasoning, examples, or references to support why this observation is important or how it impacts the paper. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It notes that no results were shown, which is a significant gap in the analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what results they should include. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical gap but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. While it implies that the authors should consider this aspect, it does not provide explicit guidance on how to control the number of distribution sets or what specific actions should be taken. The comment is somewhat vague, as it leaves the authors to infer the need for further exploration and experimentation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its question about the number of distribution sets, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. This feedback is 3 as it points out a potential area for further investigation or clarification. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment could be more helpful if it offered actionable advice or examples of how to control the number of distribution sets or what implications this might have. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the perplexity experiments should be conducted using transformerbased language models, which are more current and relevant to the field. While the comment provides a clear direction for improvement by specifying the type of models to use, it does not offer explicit guidance on how to implement this suggestion, such as which specific transformer models to consider or how to adapt the current methodology. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the perplexity experiments should be conducted using transformerbased language models, which are more current and relevant to the field. However, it does not specify which part of the paper the authors should address or provide detailed guidance on how to implement this suggestion. The comment is fully grounded as it mentions the type of models to use, but it is not specific in terms of which part of the paper needs revision or how to conduct the experiments. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the perplexity experiments should be conducted using transformerbased language models, which are more current and relevant to the field. This claim is 3 as it provides a logical reasoning for why transformerbased models are more appropriate, aligning with current NLP trends. However, it lacks specific examples or references to support the claim fully, which could make it partially verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the perplexity experiments, noting that they are conducted on obsolete language models that are rarely used in current NLP research. The comment suggests that the authors should consider using transformerbased language models, which are more relevant and widely adopted in the field. This feedback is clear and actionable, providing a specific direction for improvement that aligns with current trends in NLP. By recommending the use of more contemporary models, the comment helps the authors enhance the relevance and impact of their work. However, it could be more helpful if it provided specific examples of transformer models or guidance on how to adapt the methodology. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the estimation process. The comment lacks concrete guidance on what needs to be done to clarify or improve the estimation of mu. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or context. The comment is vague and does not provide specific guidance on how to address the issue of misestimation. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific reasoning, examples, or references to support why this estimation is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific guidance or suggestions on how to address this issue or improve the estimation process. The feedback is vague and lacks actionable insights, leaving the authors without a clear understanding of how to respond or enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific way to present the sensitivity of the performance to initialization by varying the distance of the initialization matrix M^0 from the groundtruth matrix M^*. It provides a clear and concrete action for the authors to take, which is to include this analysis in their draft. The comment is explicit and provides detailed guidance on how to implement the suggested action, making it 5.", "grounding_specificity_rationale": "The comment suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the groundtruth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing the proposed analysis, but the lack of explicit grounding makes it 3. Therefore, it aligns with category 3.", "verifiability_rationale": "The review point suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the groundtruth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not offer any specific examples or references to support the claim that this analysis would be beneficial or how it aligns with existing literature. The lack of detailed reasoning or evidence makes the claim 3, as it provides a logical suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of the sensitivity to initialization in the paper. It proposes a method to analyze the performance as a function of the distance of the initialization matrix from the groundtruth matrix, which could offer valuable insights into the robustness of the method. By suggesting this analysis, the comment offers a clear and actionable direction for the authors to enhance their draft. However, it could be more helpful if it included additional guidance on how to implement this analysis or why it is important. Overall, the comment is 4 as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This comment provides a specific and explicit action for the authors to consider, as they can verify whether the operation is indeed necessary. The suggestion is clear and concrete, allowing the authors to understand exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the definition of the Frobenius norm, suggesting that the absolute value operation is not needed since tensor entries are real numbers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This claim is 3 as it provides a logical reasoning based on the nature of tensor entries. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue in the definition of the Frobenius norm, specifically pointing out that the absolute value operation might be unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement. By highlighting this detail, the comment helps the authors refine their definition and ensure its accuracy. However, the comment could be more helpful if it offered additional context or guidance on why this observation is important. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that the authors can easily address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide highprobability bounds instead of only bounds in expectation. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides explicit guidance on what should be added, it lacks specific instructions on how to implement these changes, such as which ensemble methods to use or how to calculate the error bars. The action is somewhat vague, as it does not offer detailed steps or examples for the authors to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide highproprobability bounds instead of only bounds in expectation, and it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper discusses the bounds or the experiments, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only bounds in expectation are provided, suggesting that highprobability bounds would be more informative. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment lacks specific examples or references to support the claim about the absence of highprobability bounds or the effectiveness of ensemble methods. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by recommending the inclusion of highprobability bounds instead of only bounds in expectation. It also suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. These suggestions are actionable and provide clear guidance on what the authors should do to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or detailed instructions on how to implement these changes. Overall, the feedback is 4 as it offers valuable insights and actionable suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results are less impressive and recommends evaluating them from more aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. However, it does not provide explicit guidance on how to conduct this additional evaluation or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the areas where the results should be evaluated, such as actual latency on the target device, memory consumption during inference, and actual network size. This provides clear guidance for the authors to focus on specific aspects of their results. The comment is also specific, as it suggests evaluating the results from these additional perspectives to enhance their impressiveness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the results section, suggesting that the findings are less impressive and could be strengthened by evaluating them from additional aspects. It specifically mentions the importance of considering actual latency on the target device, memory consumption during inference, and actual network size. This feedback is 3 as it provides a direction for improvement, but it lacks depth and specificity. The authors are left to infer the exact steps needed to enhance their results, which limits the comment\"s impact. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of the paper, suggesting that it might be incremental and similar to a previous work. It asks for clarification on the differences between the current paper and the cited work, specifically questioning whether the novelty lies in applying a similar methodology to a new task. While the comment prompts the authors to address these points, it does not provide explicit instructions on how to do so. The action is implicit, as the authors need to infer that they should compare their work to the cited paper and clarify the novelty. However, the comment lacks concrete guidance on how to conduct this comparison or what specific aspects to focus on. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment questions the novelty of the paper by asking for clarification on how it differs from a specific previous work. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it relates to the introduction or discussion of the paper. The comment is specific in its request for clarification but lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the novelty of the paper by asking for clarification on how it differs from a specific previous work. While the comment prompts the authors to address this question, it does not provide any specific evidence, reasoning, or references to support the claim that the paper is incremental or similar to the cited work. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the paper, questioning whether it builds upon existing work or presents incremental contributions. By asking for clarification on the differences between the current paper and a specific previous work, the comment provides a clear direction for the authors to address a potential weakness in their manuscript. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to compare the two works or what aspects of novelty should be highlighted. While it prompts the authors to consider the novelty of their work, it does not offer actionable steps or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3, as it identifies an important issue but could be more comprehensive and detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or resolve this discrepancy, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment refers to \"the reported ablation studies in Table 2,\" which provides a clear reference point for the authors to understand the context of the issue. However, it does not specify which part of the table or section of the paper the ablation studies are located, making it weakly grounded. The comment is specific in questioning the results of the ablation studies, particularly the performance of the complete loss function compared to those with some terms missing. This specificity allows the authors to understand the exact issue being raised. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation is significant or how it might impact the conclusions of the study. Without additional context or justification, the claim remains 1, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the reported ablation studies, noting that the complete loss function performed worse than those with some terms missing. This observation raises a question about the results and their implications, which could be a valuable point for the authors to address. However, the comment lacks actionable suggestions or guidance on how the authors might investigate or resolve this discrepancy. While it points out a potential area for further analysis, it does not provide any specific steps or insights that would help the authors improve their draft. Therefore, the comment is 3, as it highlights a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and that the abstract should be more highlevel, omitting technical details. While the comment implies that the authors should revise the abstract to make it clearer, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the abstract to remove the technical details and make it more accessible. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and the specific statement that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the statement, suggesting that it is unclear and that the abstract should be more highlevel, omitting technical details. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and that the abstract should be more highlevel, omitting technical details. However, the comment does not provide any evidence or reasoning to support why the statement is unclear or how it should be revised. Without specific examples or references, the authors are left to interpret the claim, making it difficult to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that a particular statement is unclear and suggests that the abstract should be more highlevel, omitting technical details. This feedback is 3 as it points out a potential area for improvement in the abstract\"s clarity. However, it lacks depth and does not provide specific guidance on how to revise the abstract to address the issue. The authors are left to infer the necessary changes, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it does not explicitly instruct the authors on which modalities to include or how to present the results. The suggestion is somewhat vague, as it lacks specific guidance on which tasks or modalities to focus on. Therefore, the comment is 3, as it gives a general idea of what needs to be done but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. However, it does not specify which modalities or tasks should be included, nor does it provide guidance on how to present or analyze the results. The comment is 1 as it does not explicitly mention specific sections or parts of the paper that need improvement. It is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. However, the comment lacks specific examples or references to support the claim that expected test loss is not meaningful in languagerelated tasks. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2. The authors would need to provide more context or examples to fully understand the basis of the suggestion.", "helpfulness_rationale": "The review comment suggests that the authors should include results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it lacks specific guidance on which modalities or tasks to include, making it 3. The suggestion is clear and actionable, but it could be more comprehensive if it offered detailed examples or guidance on how to present the additional results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. While the comment identifies a specific area needing clarification, it does not provide explicit guidance on how to address this issue or what actions the authors should take to improve their draft. The action is implicit and vague, as the authors are left to infer how to enhance their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/f few training steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue, as it clearly points out the lack of consideration for how the method leverages the fewshot nature and ensures generalization. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically regarding how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. This feedback is valuable as it highlights a critical area that needs further clarification and justification. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues. While it points out a key area for improvement, the lack of detailed advice limits its impact on guiding the authors in enhancing their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their work need improvement. While it identifies a potential area for enhancement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a concern but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment critiques the straightforward and naive use of Gaussian Process (GP) in the paper, referencing the GP community\"s investigation into dynamical modeling since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not specify which part of the paper discusses the use of GP or how the authors might address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, while it points out a potential area for improvement, it does not provide specific guidance on how to make the use of GP more sophisticated or aligned with the GP community\"s practices. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is not 5, as it relies on the authors\" interpretation of the GP usage in their paper. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the straightforward and naive use of Gaussian Process (GP) in the paper, suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of Gaussian Process Dynamical Models in NIPs 2005. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for enhancement, but it lacks actionable advice or detailed examples to guide the authors in making their work more robust. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to GAN models to avoid overfitting. It provides a counterargument based on the reviewer\"s experience with highdimensional LSTMs and suggests that the baseline models might not be properly regularized. The comment implies that the authors should investigate the regularization techniques used in their models, specifically questioning whether dropout is applied to the hidden states as well. However, the comment does not explicitly instruct the authors to conduct this investigation or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the regularization techniques and potentially adjust their models accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim made in that section, suggesting that the baseline models might not be properly regularized and that the authors should investigate whether dropout is applied to the hidden states. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the regularization techniques used in the baseline models, specifically questioning whether dropout is applied to the hidden states. The reviewer provides a counterargument based on their experience with highdimensional LSTMs, suggesting that the baseline models might not be properly regularized. However, the comment lacks specific examples or references to support the claim that the baseline models are not properly regularized. While the reviewer provides a logical argument, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the supplemental section D.4, questioning the claim that smaller architectures are necessary for language models (LMs) compared to GAN models to avoid overfitting. It provides a counterargument based on the reviewer\"s experience with highdimensional LSTMs, suggesting that the baseline models might not be properly regularized. The comment also raises a specific question about whether dropout is applied to the hidden states, which is a crucial aspect of model regularization. This feedback is 4 as it highlights a potential issue with the baseline models and encourages the authors to investigate the regularization techniques used. However, it could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific experiments to conduct. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that some ablations mentioned in previous sections are difficult to find in the subsequent content, suggesting that the writing could be improved in this part. However, it does not provide explicit guidance on how the authors should improve the writing or where the ablations are located. The action is implicit and vague, as the authors are left to infer that they need to enhance the writing clarity in the mentioned sections. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are hard to locate in the following contents, implying that the authors need to improve the writing in this part. However, it does not specify which sections or parts of the paper are affected, making it weakly grounded. The comment is specific in pointing out the issue with the writing clarity, but without clear references, it is difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are hard to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the ablations are difficult to find, the authors may struggle to understand the issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some ablations mentioned in previous sections are difficult to locate in the subsequent content, suggesting that the writing could be improved in this part. However, the comment lacks specific details or suggestions on how the authors might improve the writing or where the ablations are located. This feedback is 3 as it identifies an area for improvement, but it does not provide actionable guidance or examples, leaving the authors with limited insight into how to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The actions are implicit and vague, leaving the authors without clear direction on how to improve their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given2)5)\" and \"differential privacy application,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should \"think through it more clearly\" and \"move the experimental results from the appendix to the main paper,\" providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and recommends moving experimental results from the appendix to the main paper. However, it does not provide specific reasoning or examples to support why the application is considered halfbaked or why the results should be moved. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"halfbaked\" and recommends the authors think through it more clearly. It also suggests moving the experimental results from the appendix to the main paper, which could enhance the paper\"s impact. However, the comment lacks specific guidance on how to address the \"halfbaked\" nature of the application or what specific aspects need clarification. While it provides some direction, the feedback could be more actionable and detailed to fully assist the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation. It suggests that using robotic manipulation in general might be more appropriate. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the methodology. The action is implicit, as the authors need to infer that they should provide more detail on the methodology\"s specificity. The action is vague because it lacks concrete steps on how to demonstrate the methodology\"s relevance to bimanual manipulation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion regarding the methodology\"s specificity, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, the comment lacks specific details or suggestions on how the authors could address this issue or clarify the methodology. It does not provide actionable guidance or examples to help the authors improve their draft. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient direction for the authors to act upon."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the comparability of Geffect values across different unlearning objectives and approaches, given that the study examines each objective in isolation. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the comparability of Geffect values, but it does not offer specific guidance on how to do so. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the concern regarding the comparability of Geffect values across different unlearning objectives and approaches, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, noting that the study examines each objective in isolation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential concern regarding the comparability of Geffect values across different unlearning objectives and approaches, as the study examines each objective in isolation. This feedback highlights a critical aspect that needs to be addressed to ensure the validity and comparability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as considering alternative methods for comparison or providing additional context. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. However, the comment does not offer explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly how to respond or improve their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of the UNIFORM procedure\"s advantage over other methods, specifically noting that the results are not always clear, especially in the 1shot setting. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or table. While the authors can infer that it relates to the experimental results or discussion of the UNIFORM procedure, the lack of explicit mention makes it weakly grounded. The comment is specific in identifying the need for a theory to explain the effectiveness in the 1shot setting, but the absence of grounding makes it difficult for the authors to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting. It notes that the tables show the UNIFORM method does not always offer a clear advantage. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the results are not always clear. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting. It points out that the results are not always clear, which suggests a need for further clarification or a theory to explain the effectiveness in this setting. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or improve their draft. While it highlights an important area for attention, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this concept and suggests adding it to strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it lacks specific guidance on how to conduct this exploration or what linguistic theories might be relevant. The action is explicit but somewhat vague, as it does not provide detailed steps or examples for the authors to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. This provides full grounding as the authors can accurately identify the sections where the discussion takes place. The comment is also specific, as it asks the authors to consider existing linguistic theories that could explain the concept and suggests adding this information to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this concept and suggests adding it to strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it lacks specific examples or references to support the claim that information value is a stronger predictor. The suggestion to consider existing linguistic theories is vague and does not provide detailed guidance on which theories might be relevant or how to integrate them into the paper. Therefore, the comment is 3, as it provides a general direction but lacks the necessary depth and specificity to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also prompts the authors to explore existing linguistic theories that could explain this concept and suggests adding this information to strengthen the paper. This feedback is clear and actionable, providing the authors with a specific direction to enhance their work. However, the comment could be more helpful if it offered more detailed guidance on which linguistic theories might be relevant or how to integrate this information effectively. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for not adequately commenting on the use of AutoML approaches beyond improving raw performances, specifically mentioning the extraction of hints for future network architecture design. It suggests that the authors should provide more insight into the takeaways from the found architecture. However, the comment does not explicitly instruct the authors on how to address this issue or what specific aspects to focus on. While it implies that the authors should expand on their discussion, the action remains somewhat vague and lacks concrete guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for not adequately commenting on the use of AutoML approaches beyond improving raw performances, specifically mentioning the extraction of hints for future network architecture design. However, it does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the use of AutoML, the absence of explicit references to the paper\"s sections or elements makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the authors for not adequately commenting on the use of AutoML approaches beyond improving raw performances, specifically mentioning the extraction of hints for future network architecture design. It suggests that the authors should provide more insight into the takeaways from the found architecture. However, the comment lacks specific examples or references to support the claim that the authors did not spend much time commenting on these aspects. Without detailed examples or references, the claim remains 3, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by providing more detailed commentary on the use of AutoML approaches beyond just improving raw performances. It highlights the importance of extracting hints that can be reused in the design of new network architectures, which is a valuable insight for future work. However, the comment does not provide specific suggestions or guidance on how the authors might address this aspect, such as what specific takeaways or insights should be included. While it points out a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3, as it offers a clear direction but could be more comprehensive with detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This suggests that the authors may need to ensure that all terms are defined before they are used in the paper. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting where the definition should be placed or how to clarify its usage. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the issue of defining T_a(t) before using it in Section 3.1. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly points out that the term T_a(t) is used in Section 3.1 but only defined in Section 4, highlighting a potential issue with clarity and consistency. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation about the structure and content of the paper, and it does not require any additional evidence or reasoning to be considered verifiable. The comment is clear and specific, providing a clear indication of a potential issue with the definition and usage of the term. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition and usage of the term T_a(t) in the paper. It points out that while the term is used in Section 3.1, it is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper, which could affect the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as where the definition should be placed or how to clarify its usage. While it identifies a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL\"s performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide explicit guidance on how to address this limitation or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their experiments to more complex games. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ReBeL\"s performance on more complex problem\" and \"bigger depth,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a limitation in the experimental setup, noting that the experiments were only conducted on two typical games, and suggests that the ReBeL\"s performance on more complex problems, especially those with larger depth, could be explored. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL\"s performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the experiments were limited to two typical games. This lack of substantiation makes the claim 3, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It highlights the ReBeL\"s performance on more complex problems, especially those with larger depth, which could lead to significant inputs for the value and policy functions. This feedback is 3 as it points out a potential area for improvement in the experimental design. However, it lacks specific guidance on how to address this limitation or what additional experiments could be conducted to strengthen the study. The comment provides a clear direction for improvement but could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide explicit guidance on what specific evidence or arguments are needed to establish this contribution as significant. The comment implies that the authors should provide more detailed evidence or arguments, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a need for more evidence but does not offer specific guidance on how to achieve this.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs to be addressed. The comment is specific in its critique of the contribution, but it lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. While it highlights the need for more substantial evidence to establish the significance of this contribution, it does not provide specific guidance or suggestions on how to strengthen the evidence or arguments. The comment is 3 as it points out an area for improvement, but it lacks depth and actionable advice, making it less impactful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap or what aspects of the discussion could be expanded. The comment identifies a specific area that needs attention but does not offer guidance on how to improve the draft. As a result, the authors are left without a clear direction for action, making the comment 1.", "grounding_specificity_rationale": "The comment highlights a specific gap in the paper by pointing out the lack of discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the missing discussion but lacks grounding as it does not provide clear guidance on where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. This is a critical aspect that needs to be addressed to strengthen the paper\"s theoretical foundation. However, the comment lacks specific guidance or suggestions on how the authors might approach this discussion or what aspects of the analysis could be expanded. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to follow but does not offer detailed guidance on implementation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measures for evaluating the generated VCEs, noting that the evaluation is primarily based on visual inspection. While it identifies a gap in the methodology, it does not provide explicit guidance on how to address this issue or suggest specific quantitative measures. The action is implicit, as the authors would need to infer that they should consider adding quantitative metrics to their evaluation process. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"generally lacking a quantitative measure to evaluate the generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking quantitative measures and suggests that the evaluation is primarily based on visual inspection. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, with evaluation primarily relying on visual inspection. This claim is 3 as it highlights a potential gap in the methodology but does not provide specific examples or references to support the claim. The authors would need to infer that the lack of quantitative measures could be a limitation, but the comment lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of quantitative measures for evaluating the generated VCEs. It notes that the evaluation is primarily based on visual inspection, which may not provide a comprehensive or objective assessment. This feedback is valuable as it highlights a potential gap in the methodology and suggests that the authors should consider incorporating quantitative measures to enhance the rigor and depth of their evaluation. However, the comment could be more helpful if it provided specific examples of quantitative measures that could be used or suggested alternative evaluation methods. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors claim their method performs better than baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors can address this issue or improve their method. It lacks concrete actions or detailed feedback on what specific aspects of the method or experiments need to be revised to demonstrate a more substantial improvement. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of marginal improvements over baselines and the high error range, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the performance differences between methods and the need for more significant improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" method only shows marginal improvements over baselines, mostly within the error bar range. It suggests that the performance differences between some methods are not significant. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a key issue with the authors\" claims of marginal improvements over baselines, noting that the error range is high, suggesting that the performance differences are not significant. This feedback is valuable as it highlights a potential overstatement in the authors\" claims and encourages them to reevaluate their results. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as conducting additional experiments or refining their analysis. While it points out a critical area for improvement, the lack of detailed actionable advice limits its overall impact. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It also asks for clarification on how to select representative images. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the action is not concrete or detailed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method and how to select representative images. However, it does not provide any specific reasoning, examples, or references to support why this is an issue or how it could be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. This feedback highlights a potential gap in the paper\"s methodology or experimental design, suggesting that the authors need to clarify how their new evaluation set differs from the previous one and how they ensure its diversity and representativeness. However, the comment does not provide specific guidance or suggestions on how to address these issues, leaving the authors with a general idea of what needs improvement but without concrete steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it raises a valid point about the need to clarify the connection between the term and the cited work, it does not provide explicit guidance on how the authors should address this concern. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting specific ways to clarify the relevance or providing examples of how the term might be used in the context of the cited work. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider by questioning the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it prompts the authors to consider this connection, it does not provide any specific evidence, reasoning, or references to support the claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This question prompts the authors to consider the connection between the term and the cited work, which could help them clarify their terminology and ensure consistency in their use of terms. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as suggesting specific ways to clarify the relevance or providing examples of how the term might be used in the context of the cited work. While it identifies an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this feedback identifies a potential area for improvement, it does not provide explicit guidance on how the authors should expand their experiments or what additional datasets they could consider. The action is implicit, as the authors need to infer that they should include more diverse datasets to enhance the comprehensiveness of their experiments. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments being limited to MNIST and a single realworld dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation in the experiments, indicating that the authors should consider expanding their experiments to include more diverse datasets. This provides clear guidance on what needs to be addressed to improve the comprehensiveness of the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. This feedback is 3 as it points out a potential gap in the comprehensiveness of the experiments. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the implications of this limitation. The comment could be more verifiable with additional context or examples, but it provides a clear indication of an area for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. This feedback is valuable as it highlights a potential gap in the comprehensiveness of the experiments, suggesting that the authors should consider expanding their experiments to include more diverse datasets. However, the comment lacks specific guidance on which additional datasets to consider or how to address this limitation effectively. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions or examples of additional datasets that could enhance the robustness and generalizability of the experiments. Therefore, the comment is 3, as it offers a clear insight but lacks depth and actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point questions the similarity of the proposed method to the approach in 10 and suggests that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why 10 cannot use these side information. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the proposed method. The action is implicit and vague, as it does not specify how the authors should explore or implement the suggestions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the similarity of the proposed method to the approach in 10 and suggests that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why 10 cannot use these side information. However, the comment does not specify which part of the paper discusses the proposed method or the approach in 10, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while the comment suggests an improvement, it does not provide specific guidance on how to implement it. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the similarity of the proposed method to the approach in 10 and suggests that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why 10 cannot use these side information. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the critique. Without clear justification or references, the claim is considered 2, as it provides some context but lacks depth and clarity.", "helpfulness_rationale": "The review comment questions the similarity of the proposed method to an approach in 10 and suggests that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why 10 cannot use these side information. However, the comment does not provide specific guidance or suggestions on how to address this issue or how the proposed method could be improved. It lacks depth and actionable advice, making it 2. The authors are left with a vague understanding of the issue and no clear path forward for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added. However, the comment does not provide explicit guidance on how the authors might address this issue or what changes could be made to the method to incorporate a sparsity constraint. The action is implicit and vague, as it does not specify how the authors should implement or address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proposed method, noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in detailing the problem with the lack of a sparsity constraint, which could lead to increased factors and computation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint, which could lead to an increase in the number of factors and computation as more tasks are added. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added, which is a significant concern. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate a sparsity constraint. While it highlights a potential problem, it lacks actionable advice, making it 3. The authors would need to infer how to improve their method based on this feedback, which limits the comment\"s overall impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. While the comment implies that these additions are necessary, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their evaluation to include these aspects. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is related to, such as the methodology or results sections. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the type of experiments needed, the absence of explicit references to sections or parts of the paper makes it weakly grounded. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies specific areas where the evaluation could be strengthened. However, the comment lacks depth and does not provide detailed guidance on how to conduct these additional experiments or what specific aspects of the evaluation would benefit from these additions. Without more detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, it does not provide explicit guidance on what specific aspects of the paper need further explanation or elaboration. The suggestion to give more explanations is vague and lacks concrete details on how the authors should expand on this point. As a result, the authors are left without a clear understanding of what specific sections or arguments require additional clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the issue of consistency between training and inference is discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies that the authors should provide more explanations on this consistency, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to assume that the claim is valid, which makes it difficult to fully understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the consistency between training and inference is discussed, noting that it can be easily satisfied due to the smoothness of neural models. The comment suggests that the authors should provide more explanations on this point. This feedback is 3 as it highlights a potential area for improvement by prompting the authors to elaborate on a specific aspect of their work. However, the comment lacks depth and does not provide specific guidance on how the authors might expand on this point, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment does not explicitly instruct the authors to conduct this exploration or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should test the model with larger parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment does not specify which part of the paper discusses the model\"s performance or parameters, making it weakly grounded. It is specific in questioning the claim and suggesting an additional experiment, but without clear references to the sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the claim or understand the reasoning behind it. The feedback is 3 as it provides a direction for further investigation but lacks detailed justification or evidence. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model\"s performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific guidance or suggestions on how to conduct this exploration or what experiments to perform to substantiate the claim. While it points out a potential area for further investigation, it does not provide actionable steps or detailed feedback that would help the authors address the issue effectively. Therefore, the comment is 3, as it identifies a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the regularization methods used for the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to reproduce the features of previous models. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the regularization methods used in the LN model and the GLMs, specifically noting a discrepancy in the regularization techniques. It mentions the LN model needing regularization and then applying regularization in the form of a cropped stimulus to both LN models and GLMs. The comment also references the work of Pillow et al., which did not use L1 regularization but employed a lowrank approximation for the spatial filter. This provides a clear and specific reference to the issue, allowing the authors to understand the context and the specific aspect of the paper that needs attention. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific because it details the discrepancy in regularization methods. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the authors should try to reproduce the main features of previous models to ensure a fair comparison, specifically mentioning the discrepancy in regularization methods between the LN model and the GLM. The comment provides a specific reference to the work of Pillow et al., which did not use L1 regularization but employed a lowrank approximation for the spatial filter. This reference offers a basis for comparison and suggests a way to align the models. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the regularization methods used in the LN model and the GLMs, noting a discrepancy in the techniques employed. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison, which is a valuable piece of feedback. However, the comment could be more helpful by providing specific guidance on how to reproduce the features of previous models or by suggesting alternative regularization methods that could be explored. While the feedback is 3, it could be more comprehensive and actionable to fully assist the authors in improving their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be improved by including some failure cases and related discussion. While the comment implies that this addition would enhance the paper, it does not explicitly instruct the authors to include specific examples or details about these failure cases. The action is implicit, as the authors need to infer that they should add this information, but it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment suggests including some failure cases and related discussion in the paper. However, it does not specify which part of the paper this should be included in, nor does it provide any guidance on what kind of discussion or examples would be beneficial. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment is not specific about what aspects of failure cases or discussion would be relevant, leaving the authors with a vague understanding of how to address the suggestion. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper would benefit from including some failure cases and related discussion. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how to incorporate it into their work. Therefore, the comment is considered 1, as it lacks sufficient evidence or explanation to be fully understood and actionable.", "helpfulness_rationale": "The review comment suggests that the paper would be improved by including some failure cases and related discussion. While this feedback provides a clear direction for improvement, it lacks specific details or examples, making it 3. The authors are informed about a potential area for enhancement but are not given guidance on how to implement it or what aspects of failure cases to consider. This level of feedback is useful but could be more comprehensive if it included suggestions for specific types of failure cases or discussion points. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform an ablation study to address the question. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific about the issue of the base layer GNN encoding, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests that an ablation study would be helpful. However, the comment does not provide any specific reasoning, examples, or references to support why the base layer GNN encoding is necessary or how an ablation study would address this concern. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically questioning the necessity of the base layer GNN encoding. It suggests that an ablation study would be helpful to determine the importance of this component. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific results would be expected. This makes the feedback 3, as it points out a potential weakness but does not fully address the authors\" needs for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the discussion of computational complexity, specifically regarding the counting of homomorphisms. It notes that the authors make brief statements about the efficiency of computing homomorphism counts but do not provide a detailed discussion or explicit action to address this. The comment suggests that the paper would benefit from explicitly adding upper bounds of counting and elaborating on empirical runtimes. However, it does not provide specific guidance on how to implement these suggestions, such as which parts of the paper should be expanded or what specific analyses should be conducted. While the action is somewhat vague, it is clear that the authors need to address the issue of computational complexity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue of computational complexity is discussed, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed discussion on the computational complexity of counting homomorphisms and suggests adding upper bounds and elaborating on empirical runtimes. This provides the authors with clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, noting that the paper makes brief statements about the efficiency of computing homomorphism counts but lacks a detailed discussion. The comment suggests that the paper would benefit from explicitly adding upper bounds of counting and elaborating on empirical runtimes. However, the comment does not provide specific examples or references to support the claim that the discussion is inadequate. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper by discussing the computational complexity of counting homomorphisms. It points out that the paper makes brief statements about the efficiency of computing these counts but lacks a detailed discussion or explicit action to address this gap. The comment suggests that the paper would benefit from explicitly adding upper bounds of counting and elaborating on empirical runtimes. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their work. However, it could be more helpful if it included more detailed guidance on how to implement these suggestions or provided examples of how to elaborate on the computational complexity. Overall, the comment is 4, as it offers valuable insights and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the text, noting that the first \"f\" should be \"g\" and that there is an extra \".\" in the middle of a sentence. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment explicitly points out the error and raises a question, it does not provide explicit guidance on how to correct the error or address the question. The action is implicit, as the authors would need to infer how to apply the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be corrected, such as the error in the text and the question about the convergence of networks in a baseline MCL with deep learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a specific question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues in the text, such as a potential error in the form of a sentence and a question about the convergence of networks in a baseline MCL with deep learning. While the comment points out these areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need attention, but it lacks depth and actionable advice, making it only marginally helpful for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the study, specifically the lack of analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific metrics to use. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of study of inference time, which is a specific aspect of the paper. It also suggests comparing the inference speed to previous topdown and bottomup pose estimation methods, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue that needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a study of inference time, which is a significant aspect for evaluating the practical applicability of the pose estimation method. It suggests comparing the inference speed to previous topdown and bottomup methods, implying that this comparison would provide valuable insights. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the lack of inference time study is a critical omission. While the suggestion is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the study by pointing out the absence of an analysis of inference time. It suggests that since the pose estimation method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous topdown and bottomup pose estimation methods. This feedback is valuable as it highlights a crucial aspect that could enhance the practical applicability and comprehensiveness of the research. However, the comment could be more helpful if it provided specific guidance on how to conduct the inference time analysis or suggested particular metrics for comparison. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of lowvariance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not provide explicit guidance on how to address these limitations or what specific aspects of the claim need to be discussed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim regarding evolutional dropout and internal covariate shift, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, suggesting that Batch Normalization standardizes variance and centers activation, which should be discussed explicitly. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of lowvariance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The feedback is 3 as it provides a general direction but lacks depth and specific guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the claim about evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of lowvariance units. It also points out that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it included suggestions on how to discuss these limitations or what specific aspects of the claim need to be elaborated upon. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which aspects of the contribution need more detail or how the authors should go about adding this description. The action is implicit and vague, as it does not provide concrete guidance on what specific elements of the contribution require additional explanation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this contribution is discussed in, nor does it provide any guidance on what aspects of the contribution need more detail. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any details on what kind of description is needed or how it should be added. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is necessary or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should add more description about the contribution of the paper. However, it lacks specificity and does not provide any guidance on what aspects of the contribution need more detail or how the authors should go about adding this description. The comment is vague and does not offer actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the organization of the paper by suggesting that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. It also suggests that tricks like normalization or feature scaling could be referenced in a separate section. However, the comment does not explicitly instruct the authors on how to implement these suggestions, such as where to add these sections or how to integrate the tricks. While the suggestions are clear, the lack of explicit guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the organization of the paper, such as separating the description of the main contributions and the generative/inference models, and referencing tricks like normalization or feature scaling in a separate section. However, it does not explicitly mention which sections or parts of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the scattered description of the layerwise attention mechanism and the need for separate sections for contributions and tricks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point provides suggestions for improving the organization of the paper by recommending that the main contributions, particularly the introduction of two types of attention for deep VAEs, be described in a separate section before discussing the generative and inference models. It also suggests that tricks like normalization or feature scaling could be referenced in a separate section. However, the comment lacks specific examples or detailed reasoning to support why these changes would be beneficial or how they would improve the paper. The suggestions are somewhat vague and do not provide a clear rationale for why these organizational changes are necessary or how they would enhance the clarity or impact of the paper. Therefore, the claim is 3, as it provides some guidance but lacks sufficient detail to fully substantiate the suggestions.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the organization of the paper, such as separating the description of the main contributions and the generative/inference models, and referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and actionable, offering the authors a clear path to enhance the structure and clarity of their work. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or why these changes would be beneficial. Overall, the feedback is 4, as it provides valuable insights for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include supervised baselines, particularly full annotation and selfsupervised methods, to provide a more comprehensive comparison. It implies that the authors should consider adding these baselines to their experiments, especially given the scale of the datasets used. However, the comment does not provide explicit guidance on how to implement these baselines or where to add them in the draft. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests the inclusion of supervised baselines, specifically mentioning full annotation and selfsupervised methods, in the context of experiments conducted on datasets of a certain scale. However, it does not specify which part of the paper these baselines should be included in or how they should be integrated. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting the inclusion of certain baselines, but without explicit guidance on implementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include supervised baselines, specifically mentioning full annotation and selfsupervised methods, to provide a more comprehensive comparison. The comment implies that these baselines are informative and relevant, especially given the scale of the datasets used in the experiments. However, the comment lacks specific examples or references to support the claim that these baselines are necessary or beneficial. Without detailed reasoning or evidence, the claim is 3, as it provides a logical suggestion but lacks depth and specificity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, particularly full annotation and selfsupervised methods. It provides a clear rationale for why these baselines are important, suggesting that they offer a more comprehensive comparison to fully supervised pretrained networks. This feedback is valuable as it directs the authors to consider adding these baselines to enhance the robustness and comprehensiveness of their experiments. However, the comment could be more helpful if it provided specific guidance on how to implement these baselines or where in the draft they should be discussed. Overall, the comment is 4, as it highlights a crucial area for improvement and offers a clear rationale for its suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for the authors to consider. It questions the effectiveness of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it asks why BEAR is missing from the baselines. While the comment provides some guidance, it lacks explicit instructions on how to address these points or what specific actions the authors should take. The suggestions are somewhat vague and do not offer detailed guidance on how to conduct the additional evaluations or why BEAR is missing from the baselines. Therefore, the comment is 3, as it provides some direction but lacks concrete details on how to implement the suggestions.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment does not specify which part of the paper discusses the method\"s application or evaluation on Hopper, making it weakly grounded. While it provides some specificity by questioning the method\"s effectiveness and suggesting additional evaluations, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment does not provide any specific reasoning, examples, or references to support these claims or questions. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions and suggestions for the authors to consider. It questions the method\"s effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This provides a clear direction for further experimentation and analysis. Additionally, the comment questions why BEAR is missing from the baselines, which is a relevant concern for the authors to address. However, the comment lacks depth and does not provide specific guidance on how to conduct these evaluations or why BEAR is missing from the baselines. While it offers some actionable feedback, it could be more helpful with additional details and suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a theocratical justification for why cotraining and weight averaging improve results. While the comment implies that this justification is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors need to infer that they should add this justification. However, the comment lacks concrete guidance on how to provide this justification, such as suggesting specific examples or references. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theocratical justification for why cotraining and weight averaging improve results. However, it does not specify which part of the paper this justification should be included in, making it weakly grounded. The comment is specific in its request for justification, but without clear guidance on where to include it, the authors may struggle to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theocratical justification for why cotraining and weight averaging improve results. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered 2, as it provides a general direction but lacks the necessary details for full understanding and implementation.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors provide a theocratical justification for why cotraining and weight averaging improve results. This feedback is specific and actionable, as it directs the authors to enhance the clarity and depth of their explanation regarding the effectiveness of these techniques. However, the comment could be more helpful if it provided additional guidance on how to construct this justification or included examples of how such justification might be presented. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide explicit instructions or concrete guidance on what specific aspects of the method need to be elaborated upon or how to present these details. The action is implicit and vague, as it leaves the authors to infer the exact areas that require additional explanation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific in its request for more details, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or reasoning to support why these details are important or how they would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that more details about the proposed method should be presented. It highlights the need for a clearer explanation of how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment lacks specificity and does not provide guidance on what aspects of the method should be elaborated upon or how to present these details effectively. While it points out a potential area for improvement, it does not offer actionable advice or suggestions for enhancing the clarity and depth of the paper. Therefore, the comment is 3, as it provides a general direction for improvement but lacks the depth and specificity needed for the authors to fully address the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method in detecting hallucinations in openended responses, providing a specific example to illustrate the issue. It suggests that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific improvements could be made to the method. The action is implicit and somewhat vague, as it leaves the authors to infer the need for further investigation or modification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method, noting its potential struggle to detect hallucinations in openended responses. It provides a concrete example, such as the prompt \"introduce a sports celebrity to me,\" to illustrate the challenge. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The specificity of the comment is high as it clearly identifies the problem and provides an example, guiding the authors on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, providing an example of a prompt that could lead to this issue. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without additional context or examples, the claim is not 5, and the authors may struggle to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method in detecting hallucinations in openended responses, providing a specific example to illustrate the issue. This feedback is valuable as it highlights a gap in the method\"s ability to handle certain types of prompts, which could impact the reliability of the results. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or improve the method\"s robustness. Without specific recommendations or actionable steps, the feedback is 3, as it provides insight into an area that needs attention but lacks depth in terms of constructive suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of how theoretical findings relate to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical findings\" and suggests verifying the conclusion about \"label noise and model size on MNIST and CNN.\" This provides clear guidance on which parts of the paper need attention. However, the comment lacks specificity in detailing what aspects of the findings need verification or how the authors should approach this verification. It does not provide specific examples or detailed instructions, making it somewhat specific. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the clarity of how theoretical findings relate to realworld deep learning models. It suggests verifying the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific examples or detailed reasoning to support the claim that the findings are unclear or require verification. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by questioning the clarity of how theoretical findings relate to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific guidance on how to conduct this verification or what aspects of the findings need to be clarified. While it points out an area for improvement, the feedback is somewhat vague and could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay, suggesting that the authors should expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are still close to optimal. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer that they should consider reporting cosine similarities for larger weight decay values or extend their plots to include these values. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the application of weight decay, noting that the authors might expect suboptimal cosine similarities for large weight decay parameters. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. The comment is specific in detailing the expected outcome and the observation about the plots, but it lacks grounding as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors would expect suboptimal cosine similarities for large weight decay parameters, which is a logical deduction based on the understanding of how weight decay affects model training. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors could infer the reasoning but would need additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay, suggesting that the authors might expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are still close to optimal. This feedback is 3 as it highlights a potential area for improvement in the analysis and suggests that the authors should consider reporting cosine similarities for larger weight decay values or extending their plots to include these values. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested alternative approaches. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This omission is serious, as it could lead to misinterpretations and incorrect conclusions. The comment suggests that this issue must be addressed for publication and implies that it would be straightforward to fix. However, the comment does not provide specific guidance on how to revise the sections to include this information, leaving the authors with a general idea of what needs to be done but lacking concrete steps. The action is explicit but somewhat vague, as it does not detail the exact changes required. Therefore, the comment is 4, aligning with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections of the paper where the results are not explained, specifically the title, abstract, introduction, and discussion. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the omission of the explanation regarding unsupervised random forests, and it highlights the potential consequences of this omission, such as misinterpretations and incorrect conclusions. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper does not explain that the results are for unsupervised random forests, which is a significant omission that could lead to misinterpretations. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim is 3, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a significant omission that could lead to misinterpretations and incorrect conclusions, as casual readers might misremember the findings. The comment suggests that this issue must be addressed for publication, implying that it would be straightforward to fix. However, the comment lacks specific guidance on how to revise the sections to include this information, leaving the authors with a general idea of what needs to be done but lacking concrete steps. While the feedback is clear and highlights a crucial oversight, it could be more helpful if it provided detailed suggestions on how to revise the sections to include the necessary information. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the proposed method requires significantly more computation than other methods, given that the authors describe an online version of the algorithm due to the impracticality of training multiple iterations/epochs with large models and datasets. While the comment implies that the authors should compare the computational complexity of their method with others, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors describe an online version of the algorithm, allowing the authors to accurately identify the section being addressed. It is also specific because it requests a comparison of the computational complexity of the proposed method with other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, which is a relevant concern for the authors to address. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the proposed method requires significantly more computation. Without additional context or justification, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises a pertinent question about the computational complexity of the proposed method compared to other methods, which is a crucial aspect for evaluating the efficiency and practicality of the approach. By questioning whether the proposed method requires significantly more computation, the reviewer highlights a potential area for improvement or further analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as providing a detailed comparison of computational complexity or suggesting alternative approaches. While the feedback identifies an important concern, it could be more helpful if it included actionable steps or examples to guide the authors in addressing the issue. Therefore, the comment is 3, as it points out a relevant area for improvement but does not provide comprehensive guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of significance testing to support the claims made about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT4, and suggests that the authors should conduct significance testing to substantiate their claims. However, the comment does not provide explicit guidance on how to perform the significance testing or what specific statistical methods should be used. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines of the paper (line 486) and provides examples of claims made in the draft. It specifies what needs to be addressed, namely the lack of significance testing to support the claims about the differences between various methods. This allows the authors to accurately identify the part of the paper being addressed and understand the issue clearly. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should conduct significance testing to support their claims about the differences between various methods, such as ChatGPT and GPT4. It provides specific examples, like the scores for different models, to illustrate the need for such testing. However, the comment lacks detailed reasoning or references to justify why significance testing is necessary or how it should be conducted. While the claim is 3 due to the inclusion of examples, it could be more robust with additional explanation or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper, specifically the lack of significance testing to support claims about the differences between various methods. It provides concrete examples, such as the comparison between ChatGPT and GPT4, and highlights the difficulty in determining the significance of these differences without proper testing. This feedback is 5 as it directs the authors to address a significant gap in their analysis by conducting the necessary statistical testing. The comment is clear, specific, and provides a clear path for improvement, making it 5 for the authors to enhance the rigor and validity of their claims."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. This comment is explicit in its request for additional evidence and analysis, providing a clear action for the authors to take. It specifies what kind of evidence or analysis is needed, making it concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment is specific in its request for more evidence and analysis, but without grounding, it is difficult for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or examples, the claim remains 3, as it lacks sufficient justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their analysis. However, the comment could be more helpful if it provided specific examples or guidance on what kind of evidence or analysis would be beneficial. Despite this, the comment offers a valuable direction for the authors to improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 5 is difficult to comprehend and suggests that the authors should provide more details about the two baselines presented in the figure. It also notes that the study is limited to Englishcentric datasets and suggests that the authors could extend CATER to other languages in the future. While the comment explicitly mentions the need for more details about the baselines and suggests extending the study to other languages, it does not provide specific guidance on how to add these details or extend the study. The action is somewhat vague, as the authors need to infer how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comprehensibility of Figure 5 and the need for more details about the two baselines. Additionally, it suggests extending the study to other languages, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests providing more details about the two baselines presented in the figure. It also notes that the study is limited to Englishcentric datasets and suggests extending CATER to other languages. While the comment identifies a potential issue with the comprehensibility of the figure and suggests improvements, it lacks specific examples or detailed reasoning to fully substantiate these claims. The authors would need to infer the basis for the comprehensibility issue and the need for more details, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and lacks details about the two baselines presented. It also points out that the study is limited to Englishcentric datasets and suggests extending CATER to other languages. This feedback is clear and actionable, providing the authors with specific areas for improvement. By highlighting the need for more details and suggesting future work, the comment offers valuable guidance on how to enhance the comprehensibility and scope of the study. However, it could be more helpful if it included suggestions on how to improve the comprehensibility of Figure 5 or provided examples of what additional details might be needed. Overall, the comment is 4, as it effectively directs the authors toward specific improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for improvement in the literature review, specifically mentioning that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. While the comment suggests that the paper should provide a more explicit and comparative analysis of related work, it does not provide specific guidance on what aspects of the literature review need to be improved or how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to expand the literature review to include a clearer comparison with existing work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for improvement in the literature review, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be addressed, namely, the clarity of the main contribution and the distinction from existing work, particularly in relation to GFlowNet for sequence generation. This provides clear guidance on how the authors should enhance their literature review. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and needs improvement, specifically regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact areas that need improvement. Without detailed examples or references, the claim is 3, as it provides a general direction but lacks the necessary depth to guide the authors effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of clarity in the literature review. It highlights that the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation, are not adequately addressed. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to improve the literature review. Despite this, the feedback is 4 as it directs the authors towards a crucial area for improvement, allowing them to enhance the clarity and depth of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also mentions the inclusion of morphologically rich and lowresource languages in the experiments as additional points. However, the comment does not provide explicit instructions or detailed guidance on how to implement these suggestions, such as which specific tasks or languages to include or how to analyze the results. The actions are implicit and somewhat vague, as the authors need to infer how to apply the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also mentions the inclusion of morphologically rich and lowresource languages in the experiments as additional points. However, the comment does not specify which part of the paper these suggestions relate to, such as specific sections or tables. This makes it difficult for the authors to identify the exact areas where these additions should be made. While the suggestions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich and lowresource languages in the experiments. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand the rationale behind the recommendations. Without detailed reasoning or evidence, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the experiments section by adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also suggests including morphologically rich and lowresource languages in the experiments. These suggestions are actionable and offer a clear direction for the authors to enhance their work. However, the comment could be more helpful if it provided additional guidance on how to implement these suggestions or included examples of how to conduct the additional experiments. Despite this, the feedback is 4 as it directs the authors towards specific areas for improvement, allowing them to make informed decisions about enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how node importance is used in a 1shot scenario and notes that the experimental part does not include a 1shot setting, despite related works like RALE having it. While the comment identifies a potential area for clarification and suggests that the authors should consider including a 1shot setting in their experiments, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how node importance is used in a 1shot scenario, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this question pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in that it questions the use of node importance in a 1shot setting and notes the absence of such a setting in the experiments, despite its presence in related works. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of node importance in a 1shot scenario and the absence of a 1shot setting in the experiments, despite its presence in related works like RALE. While the comment identifies a potential area for clarification, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors are left to infer the implications and potential issues, which could be addressed with more detailed explanations or references. Therefore, the comment is considered 2, as it provides some basis for understanding but lacks sufficient depth and clarity to fully support the claims.", "helpfulness_rationale": "The review comment raises a question about the use of node importance in a 1shot scenario and points out that the experimental part does not include a 1shot setting, despite related works like RALE having it. This feedback highlights a potential gap in the paper\"s exploration of different settings and suggests that the authors should consider including a 1shot setting in their experiments. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the current work might need to be adjusted. While it identifies an area for improvement, it does not provide detailed feedback or actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on what aspects of the discussion should be included or how to address the problems. The action is implicit and somewhat vague, as the authors are left to infer the exact nature of the additional discussion needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion but lacks grounding as it does not provide clear guidance on where to add the discussion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. Without additional context or references, the claim remains 3, as it lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that there should be more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these problems. This feedback is 3 as it highlights a specific aspect that could enhance the paper\"s depth and comprehensiveness. However, the comment lacks detailed guidance on what specific discussions or analyses would be beneficial, leaving the authors with a general idea but without concrete steps to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the tradeoffs between annotation effort and training performance. While the comment implies that the authors should highlight these observations, it does not provide explicit instructions on how to do so. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section, implying that the authors should highlight them. However, it does not specify which part of the experimental section contains these observations or conclusions, making it weakly grounded. The comment is specific in recommending that the authors highlight these observations to improve understanding of the tradeoffs between annotation effort and training performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the tradeoffs between annotation effort and training performance. However, the comment lacks specific examples or detailed reasoning to support why highlighting these observations would be beneficial. It does not provide any references or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations would enhance the reader\"s understanding of the tradeoffs between annotation effort and training performance. While the comment provides a clear direction for improvement, it lacks specific guidance on how to highlight the observations or examples of what might be highlighted. This makes the feedback 3, as it offers a general idea but could be more comprehensive with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. This comment is explicit in its suggestion to conduct ablation experiments, which directly informs the authors on what action to take. The action is also concrete, as it specifies the type of experiments needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. However, the comment does not specify which part of the paper contains these modifications, making it weakly grounded. It is specific in suggesting the need for ablation experiments, but without clear references, the authors may find it challenging to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. However, the comment lacks specific details or references to support the claim that these modifications are indeed necessary or beneficial. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or examples.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to strengthen their results. By providing ablation studies, the authors can demonstrate the effectiveness of the modifications and enhance the credibility of their findings. However, the comment could be more helpful if it provided specific guidance on how to design these experiments or what metrics to use. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While the first question prompts the authors to explore the relationship between model capacity and FID, it does not provide explicit guidance on how to address this. The second part acknowledges the presence of unexpected artifacts but does not offer specific suggestions or actions for the authors to take. The comment lacks explicit and concrete actions or suggestions for the authors to address these issues, making it 1.", "grounding_specificity_rationale": "The comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific about the issues, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" These questions are openended and do not contain any subjective opinions, judgments, or suggestions. They are factual inquiries that require the authors to provide their own analysis or findings. Therefore, the comment is classified as \"No\" because it does not contain a claim that needs verification.", "helpfulness_rationale": "The review comment raises two questions about the impact of the SR model\"s capacity on the FID and the unexpected artifacts introduced by the pipelining method. While these questions highlight potential areas for further investigation and clarification, they do not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it identifies areas that require attention, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the partitioning principle of Kmeans and points out that the authors claim to provide a \"proof\" but do not include it. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to fill in Appendix A and clarify the purpose of Proposition B.1, as well as provide the missing proof. This lack of explicit action makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these appendices, such as the lack of content in Appendix A and the unclear purpose of Proposition B.1. The comment requests clarification on the purpose of Proposition B.1 and points out that the authors claim to provide a \"proof\" but do not include it. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises two main issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the partitioning principle of Kmeans and points out that the authors claim to provide a \"proof\" but do not include it. The comment is 3 as it provides a logical reasoning for questioning the content and purpose of the appendices, but it lacks specific examples or references to support the claim that the appendices are missing or unclear. This makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two key issues with the paper: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the partitioning principle of Kmeans and points out that the authors claim to provide a \"proof\" but do not include it. This feedback is 3 as it highlights specific areas that need attention and raises concerns about the clarity and completeness of the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as suggesting ways to expand Appendix A or clarify the purpose of Proposition B.1. Overall, the comment offers valuable insights but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 to reassure readers that it is not a real concern. The comment implies that the authors should provide more detail or justification to address this concern, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the vulnerability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of approximations introduced in the paper, specifically mentioning \"several approximations (i iii)\" and suggesting that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110. However, the comment does not specify which part of the paper these approximations are discussed or where the vulnerability is addressed. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of approximations and vulnerability, it lacks grounding as it does not provide clear references to the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors introduce several approximations, which leaves loose ends, and suggests that the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 needs to be expanded to reassure readers. The comment provides a logical reasoning by pointing out the potential vulnerability and suggesting that it should be addressed. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 to reassure readers that it is not a real concern. This feedback is 3 as it highlights a specific area that needs clarification or expansion, providing the authors with a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to address the vulnerability or suggested specific ways to expand the discussion. Overall, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores. However, it points out that more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment implies that the authors should provide more details about the evaluation procedures to address this concern. While the action is clear and explicit, it lacks concrete guidance on how to conduct this additional analysis or what specific aspects of the evaluation procedures need to be detailed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but it highlights the need for more careful analysis, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the evaluation procedures or the \"old\" benchmarks, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the need for more detailed analysis, it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but suggests that more careful analysis is needed, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment also recommends providing more details about the evaluation procedures. However, the claim lacks specific examples or references to support the need for more careful analysis, making it 3. The authors would need to infer the reasoning behind the claim, which could be improved with additional details or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on several benchmarks, setting new SoTA scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment also recommends providing more details about the evaluation procedures. This feedback is 3 as it identifies an area for improvement and suggests a specific aspect that requires further attention. However, it could be more helpful if it provided more detailed guidance on how to conduct this additional analysis or what specific aspects of the evaluation procedures need to be detailed. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not provide explicit guidance on how to incorporate these games into the experiments or what specific aspects of the methods should be analyzed in this context. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including collaborative games in the experiments, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion relates to, such as the experimental setup or results section. This makes it weakly grounded, as the authors may need to infer the specific part of the paper being addressed. The comment is specific in that it suggests an interesting direction for future work, but the lack of explicit grounding makes it difficult for the authors to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is valuable or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. This feedback provides a clear direction for improvement by highlighting a potential area for further exploration. However, the comment lacks specific guidance on how to incorporate these games into the experiments or what aspects of the methods should be analyzed in this context. While it offers a valuable suggestion, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it identifies a potential enhancement but does not provide comprehensive instructions for implementation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, making it difficult for the authors to be convinced of the results. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks specific instructions or suggestions on what information should be included to make the experimental settings clear and convincing. Without concrete actions or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 1 to 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue as the missing experimental settings for these figures, which are crucial for the results to be convincing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, making the results difficult to be convincing. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the experimental settings are missing and how this impacts the results. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, which makes it difficult for the authors to be convinced of the results. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided specific guidance on what information should be included in the experimental settings to make them convincing. Despite this, the comment is 4 as it directs the authors to a specific area that requires improvement, allowing them to enhance the clarity and persuasiveness of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the rationale behind the work, suggesting that some parameter isolation methods are specifically tailored to leverage sparsity. However, it does not provide explicit guidance on how the proposed method avoids impeding the learning of new task knowledge. The comment implies that the authors need to clarify this aspect, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential area for clarification but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically mentioning the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this observation is made or where the authors discuss the proposed method in detail. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in that it highlights a potential issue with the rationale and suggests a clarification, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some parameter isolation methods are specifically tailored to leverage sparsity, which contradicts the authors\" suggestion that their method avoids impeding the learning of new task knowledge. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it is based on a logical deduction but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the rationale behind the work, specifically questioning how the proposed method avoids impeding the learning of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity, which contradicts the authors\" claim. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or clarify their rationale. While it points out a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear action for the authors to take, which is to integrate benchmark comparisons against stateoftheart fairness algorithms. This action is explicit and concrete, as it specifies exactly what needs to be done to enhance the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for comparisons with existing fairness algorithms and suggests integrating benchmark comparisons against stateoftheart fairness algorithms. This provides detailed guidance on what needs to be done to enhance the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not conducted comparisons with existing fairness algorithms in the experimental section. It suggests that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. However, the comment lacks specific examples or references to existing fairness algorithms, making it 3. The authors would need to infer the need for such comparisons and the importance of benchmarking to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper\"s credibility and demonstrate the effectiveness of the proposed method. By offering this constructive feedback, the comment guides the authors to improve the depth and impact of their research. However, the comment could be more helpful if it provided specific examples of existing fairness algorithms or suggested particular benchmarks to include. Overall, the feedback is 4 as it highlights a crucial area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the supervised pretraining approach based on the prediction of the homolumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to mitigate it. While the authors can infer that they should consider alternative pretraining methods or discuss the implications of this finding, the action is implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to supervised pretraining based on the prediction of the homolumo gap, which is a particular aspect of the paper. It highlights a potential issue with this approach, noting that it might lead to negative transfer, as evidenced by the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of the homolumo gap may lead to negative transfer, as evidenced by the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. This claim is 3 as it provides a specific example of a potential issue, but it lacks detailed reasoning or references to support the assertion that this is a common problem or a significant concern. The authors could benefit from further elaboration or evidence to strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the supervised pretraining approach based on the prediction of the homolumo gap, suggesting that it might lead to negative transfer. It provides a specific example of this issue by mentioning the poor performance of TransformerM on most tasks in the QM9 dataset, except for homo, lumo, and gap. This feedback is 3 as it highlights a potential area for improvement and suggests that the authors should consider alternative pretraining methods or discuss the implications of this finding. However, the comment could be more helpful if it provided additional guidance or suggestions for addressing the issue. Overall, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 8082. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and then determine how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the use of the center correlation in Figure 4 A&B despite its stated lack of insight for discriminating model defenses. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the authors\" reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 8082. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the center correlation is useful in this context. This lack of detailed explanation makes the claim 3, as the authors would need to infer the reasoning and provide their own justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the use of the center correlation in Figure 4 A&B, despite the authors\" earlier statement that it was not insightful for discriminating model defenses. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to reconsider their approach and provide a clearer explanation of why the metric was included in the figure. By identifying this inconsistency, the comment offers a constructive suggestion for improving the clarity and coherence of the paper. However, the comment could be more helpful if it provided additional context or guidance on how the authors might address this issue. Overall, the feedback is 3 as it points out a specific area that needs clarification, but it lacks depth in terms of actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors would need to infer that they should reconsider the name or provide a more nuanced description of the phenomenon. The comment is 3 because it points out a specific issue but lacks concrete details on how to implement the suggested changes. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not specify which part of the paper discusses this phenomenon, making it weakly grounded. It is specific in detailing what the issue is and why the name might be problematic, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the name \"distributional generalization\" used to describe a phenomenon, suggesting that it might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. The comment provides a logical explanation for why the name might be too strong, but it lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. This feedback is 3 as it points out a specific area for improvement and suggests a more nuanced description of the phenomenon. However, the comment could be more helpful if it provided additional context or examples to support the claim, or if it offered specific guidance on how the authors might address this issue. Overall, the comment provides a clear direction for improvement, but it could be more comprehensive and actionable to fully benefit the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not provide explicit guidance on how the authors should implement this change or any other specific actions they should take. The comment is vague and lacks concrete instructions, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not specify which part of the paper this critique refers to, such as a particular figure or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the labeling method, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. This feedback is specific and identifies a potential improvement in the clarity of the plot labeling. However, the comment does not provide any suggestions or guidance on how the authors might implement this change or what other aspects of the plot could be improved. While it offers a clear observation, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the phrase, but it lacks concrete details on what specific changes or additions are needed. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should clarify, namely the meaning of the phrase \"is sufficient\" in the context of the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide any specific examples, reasoning, or references to support the claim. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the comment and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the phrase \"is sufficient\" at lines 240 and 428. It suggests that the authors should clarify the meaning of this phrase in the context of the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. This feedback is clear and actionable, as it directs the authors to a specific area where clarification is needed. However, the comment could be more helpful if it provided additional context or examples to guide the authors in understanding the intended meaning of the phrase. Overall, the comment is 4 as it highlights a crucial point that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for nonlinear RNN models that exhibit emergent behavior. The reviewer questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. However, the comment does not offer explicit guidance on how the authors might address these questions or improve their draft. The action is implicit, as the authors need to infer that they should clarify the scientific insight and provide more detailed explanations. While the action is somewhat vague, it is clear that the authors need to address the questions raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scientific insight gained from the model and formalism compared to prior taskoptimized approaches, specifically asking for clarification on whether the model serves as a prototype approximation for nonlinear RNN models with emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for nonlinear RNN models that exhibit emergent behavior. The reviewer questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the model does not serve as a prototype approximation. This lack of substantiation makes the claim 3, as the authors would need to provide additional evidence or reasoning to address the reviewer\"s concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for nonlinear RNN models that exhibit emergent behavior. The reviewer questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. This feedback is valuable as it prompts the authors to clarify the scientific contribution and provide a more detailed explanation of the model\"s significance. However, the comment could be more helpful if it offered suggestions on how to address these questions or provide additional context. Overall, the comment is 3, as it identifies an important area for clarification and improvement, but it lacks depth and actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tradeoff between computational efficiency and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors need to infer that they should consider the implications of this tradeoff and potentially discuss it in their paper. The action is vague because it does not specify how to address the issue or what changes might be needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the tradeoff between computational efficiency and information loss when using ancestral graphs compared to DAGs, referencing a specific paper 10. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment is fully grounded as it explicitly mentions the paper 10 and the specific aspect of the method being discussed. It is also specific because it clearly specifies the issue of information loss and the tradeoff between computational efficiency and information richness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method reduces computation time by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment questions the tradeoff between computational efficiency and information loss. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the information encoded in ancestral graphs. While the logic is somewhat inferable, the absence of concrete evidence or references makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that while it reduces computation time, it does so by reducing the search space to ancestral graphs, resulting in less information compared to the richer search space of DAGs. The comment questions the tradeoff between computational efficiency and information richness, which is a relevant point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the method, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, such as the sufficient amount of training data points needed. However, it does not explicitly instruct the authors to include these results or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should add these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the paper these discussions are in, making it weakly grounded. The comment is specific in its suggestion to include additional results, but the lack of grounding makes it difficult for the authors to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could be enhanced by including sample complexitytype results for not returning NSF. This feedback is actionable, as it provides a clear direction for the authors to consider adding additional results to strengthen their theoretical analysis. However, the comment could be more helpful if it offered more detailed guidance on how to derive or incorporate these results. Overall, the comment is 4, as it provides a valuable suggestion for improvement but lacks some depth in terms of actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the discussion section could benefit from including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, it does not explicitly instruct the authors to include this discussion or provide detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion and understand the specific aspects to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one, as discussed in Section 4.2. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, the comment does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The specificity is high as it clearly specifies what needs to be addressed, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one, as discussed in Section 4.2. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, the comment lacks detailed reasoning or references to support why this discussion is necessary or how it would enhance the paper. The authors are left to infer the importance of this suggestion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by suggesting that the discussion section could benefit from including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one. It also provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. This feedback is clear and actionable, as it guides the authors to enhance the discussion section with additional context and analysis. However, the comment could be more helpful if it included more detailed guidance on how to incorporate this discussion or what specific aspects to address. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of the definitions, it does not provide explicit guidance on how the authors should address this concern or clarify the definitions. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the definitions in the paper. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. It suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment does not specify which part of the paper contains these definitions or where the confusion arises. The authors cannot confidently determine which section or table is being addressed, making the comment weakly grounded. Additionally, while it highlights a potential issue with the clarity of the definitions, it does not provide specific guidance on how to clarify them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment lacks specific examples or detailed reasoning to support the claim that the definitions are unclear or that the motivation is weak. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the clarity of definitions in Table 1, specifically questioning the distinction between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of the definitions, it does not provide specific suggestions or detailed guidance on how the authors might address this concern. The feedback is 3 as it highlights an area that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the paper\"s readability and the lack of clear intuition for how the pieces fit together, as well as the limited context provided by the experiments. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks specific guidance on how to improve the paper\"s clarity or provide more context for the experiments. Without actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concerns about the paper\"s readability and the lack of clear intuition for how the pieces fit together, as well as the limited context provided by the experiments. However, it does not specify which part of the paper is difficult to follow or lacks context. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment is somewhat specific in that it identifies the issues of clarity and context, but without explicit references to specific sections or parts of the paper, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point expresses concerns about the paper\"s readability and the lack of clear intuition for how the pieces fit together, as well as the limited context provided by the experiments. However, the comment does not provide specific examples, reasoning, or references to support these claims. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s readability, noting that it is not particularly easy to follow and lacks a clear intuition for how the pieces fit together. Additionally, the reviewer points out that the experiments have little context, which can make it difficult for readers to understand their relevance. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it lacks actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the student and refinement networks, which are trained simultaneously. It suggests that the comparison might be unfair and requests the authors to provide KID/FID metrics for their teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics to address the concern about fairness. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the request for metrics, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, the comment does not provide any justification or reasoning for why this comparison might be unfair or why the inclusion of KID/FID metrics would address this concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. This feedback is 3 as it identifies a potential issue with the experimental setup and suggests a specific metric to include, which could enhance the rigor and comparability of the results. However, the comment lacks depth and does not provide detailed guidance on how to address the fairness issue or why the inclusion of KID/FID metrics is necessary. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to implement or explore this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider regarding the scaling of the refined region vector and suggests an alternative approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment provides a specific question and suggestion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the implications and potential benefits of the alternative approach, which could be more effective with additional explanation or evidence. Therefore, the comment is considered 2, as it provides some justification but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific aspect of the paper that could be improved by questioning the scaling of the refined region vector. It suggests an alternative approach by introducing a scaling variable before the attention weight, which could potentially enhance the model\"s performance. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, leaving the authors with a clear direction but limited depth in terms of actionable feedback. While it provides a starting point for improvement, the comment could be more helpful with additional elaboration or guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the model. It lacks concrete guidance on potential solutions or actions the authors should take to mitigate this problem. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the problem, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is 3 as it highlights a potential area for improvement in the draft, specifically regarding the clarity and accuracy of goal specification. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or what specific changes could be made to improve the model\"s performance. Without actionable advice or examples, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should delve deeper into how specific models behave differently when ReGuide is applied, providing a more nuanced understanding of the conclusions. It gives an example of comparing false positive rates (FPR) between models with and without ReGuide. However, the comment does not explicitly instruct the authors to conduct this analysis or present the results in a specific way. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests a deeper investigation into how specific models behave differently when ReGuide is applied, which is a relevant aspect of the paper. However, it does not specify which part of the paper this investigation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare false positive rates (FPR) between models with and without ReGuide, providing a clear direction for the authors to follow. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide a deeper investigation into how specific models behave differently when ReGuide is applied, particularly focusing on false positive rates (FPR). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed guidance or evidence, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a specific example, such as comparing false positive rates (FPR) between models with and without ReGuide, which could enhance the nuance of the conclusions. However, the comment lacks broader guidance on how to conduct this analysis or what specific aspects to focus on, making it 3. The feedback is actionable but could be more comprehensive to fully assist the authors in enhancing their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify what aspects of the comparison need to be supplemented or what additional information would be beneficial. The comment lacks explicit guidance on how to enhance the comparison, leaving the authors uncertain about the exact actions to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment does not provide specific guidance on what aspects of the comparison should be supplemented or what additional information would be beneficial. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not provide any specific reasoning, examples, or references to support why this comparison should be supplemented. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it lacks specific guidance on what aspects of the comparison need to be supplemented or what additional information would be beneficial. The comment is vague and does not provide actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a difficulty in understanding the axes of Figure 1, but it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on how to clarify the axes or improve the figure\"s clarity. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper Figure 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it points out a lack of clarity regarding the axes of the figure, which is a clear issue that needs to be addressed. However, without specific guidance on how to improve the clarity of the axes, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point states that it is hard to understand what the axes are for Figure 1. This is a subjective observation about the clarity of the figure, but it does not provide any specific reasoning or examples to support why this is a problem. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directly points out a potential problem with the figure\"s presentation. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the axes, such as adding labels or explanations. Without such guidance, the authors may struggle to address the issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of direct runtime comparisons with existing methods, suggesting that such comparisons are necessary to demonstrate the efficiency of the proposed approach. It implies that the authors should include these comparisons to provide a more comprehensive evaluation of their method. However, the comment does not specify which existing methods should be compared or how the comparisons should be conducted, leaving the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"direct runtime comparisons,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the absence of these comparisons and the need for them to demonstrate the efficiency of the proposed approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is a valid concern as it is essential for demonstrating the efficiency of the proposed approach. However, the comment does not provide specific examples or references to existing methods that should be compared, nor does it offer detailed reasoning or evidence to support the claim. While the reasoning is logical, the lack of specific examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. This is a crucial aspect for evaluating the efficiency and practicality of the proposed approach. By highlighting this omission, the comment provides a clear and actionable suggestion for the authors to enhance their draft. However, the comment could be more helpful if it suggested specific methods for comparison or provided guidance on how to conduct these comparisons. Despite this, the feedback is 4 as it directs the authors towards an important area of improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\"s motivation. While it raises a valid concern about the focus, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors would need to infer that they should consider the differences in representation between clusters. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\"s motivation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the focus, the absence of grounding information limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\"s motivation. This is a subjective opinion or critique of the paper\"s approach. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a valid concern about the focus of the paper, questioning why the authors chose to focus on which clusters are \"best\" rather than exploring the differences in representation between them. This critique is relevant to the paper\"s motivation and could provide valuable insights for the authors to consider in their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what changes could be made to better align with the paper\"s motivation. While it identifies an important point, the feedback is somewhat limited in its actionable value, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pretraining for AMR parsing and generation. However, the comment does not explicitly instruct the authors to include these elements or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should add case studies and error studies to their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including case studies and error studies to enhance the paper\"s effectiveness, providing an example of a case study in the context of graph pretraining for AMR parsing and generation. However, it does not specify which part of the paper should be addressed or how these studies should be integrated. The authors can infer that the feedback pertains to the methodology or results sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of case studies and error studies, but the absence of detailed guidance on implementation makes it somewhat grounded and specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that including case studies and error studies would enhance the paper\"s effectiveness by providing a more convincing demonstration of the proposed components. It provides an example of a case study in the context of graph pretraining for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed reasoning or references to support the claim that these studies would be beneficial. While the suggestion is logical, the absence of specific examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including case studies and error studies would enhance the paper\"s effectiveness by providing a more convincing demonstration of the proposed components. It offers an example of a case study in the context of graph pretraining for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed guidance on how to implement these studies or what specific aspects of the proposed components should be highlighted. While it provides a valuable suggestion, the feedback could be more helpful if it included more detailed examples or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies an area for improvement but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment does not explicitly instruct the authors to address this clarification or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and its consideration of explicitness (E) and size (S). It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, suggesting that these aspects may already be considered implicit. However, the comment does not specify which part of the paper discusses the DCI framework or where the authors can find the relevant information. This makes it difficult for the authors to pinpoint the exact section or part of the paper being addressed. While the comment is specific about the issue of explicitness and size, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment lacks specific examples or references to support the claim that the DCI framework is already considered explicit or sizerelated. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for discussion but lacks the depth needed for full understanding. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the explicitness and size of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the framework. While it identifies a potential area for improvement, it does not provide actionable steps or detailed reasoning to help the authors enhance their work. Therefore, the comment is 3, as it highlights a relevant concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 and Figure 2\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, explicitness of figures, and incorrect placement of Table 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and the layout is rushed, citing specific issues such as small font sizes in Figure 1 and 2, lack of explicitness in the figures, incorrect placement of Table 2, and incorrect formatting on page 6. These claims are supported by specific examples, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims about the layout and formatting issues. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment points out these specific problems, it does not provide detailed guidance on how the authors might address these issues or suggest improvements. The feedback is 3 as it highlights areas for enhancement, but it lacks depth and actionable suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for realworld querying. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the interventions need to be evaluated for practicality and safety. The action is implicit and vague, as it leaves the authors to infer the necessary steps without clear direction. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for realworld querying. However, it does not specify which part of the paper discusses the types of interventions or where the authors should address the practicality and safety concerns. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is somewhat specific in that it highlights the importance of considering practicality and safety, but it lacks detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with label 3.", "verifiability_rationale": "The review point suggests that while the types of interventions are reasonable computationally, they need to be considered for practicality and safety in realworld querying. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 2, as it offers a suggestion but lacks the necessary depth and support for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a valid concern about the practicality and safety of the computational types of interventions included in the paper. It suggests that while the interventions are computationally reasonable, they need to be considered for their realworld applicability and safety. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern, such as additional experiments or analyses that could be conducted. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes they should consider making to their draft. Without specific suggestions or instructions, the authors are left without a clear path to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this concern or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment lacks specific details or suggestions on how the authors might address this concern or what changes could be made to their draft. Without actionable guidance or examples, the authors may find it difficult to understand the implications of this feedback or how to improve their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. While the comment identifies a specific issue and provides a clear direction for improvement, it does not explicitly instruct the authors on how to conduct this evaluation or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which consists of two major components: a generative shape model and a word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain. The reviewer suggests evaluating the proposed approach separately against baseline detection and parsing techniques to better support the claim. However, the comment does not specify which part of the paper discusses the proposed method or the evaluation of the components. This makes it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the issue of evaluating the components, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. However, the comment does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would strengthen the claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key issue with the proposed method, specifically questioning the contribution of each component to the performance gain. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation and strengthen their claims. However, the comment could be more helpful if it included suggestions on which metrics or specific aspects of the evaluation should be considered. Overall, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should discuss the rationale behind the manual disentanglement and explore alternative approaches. The lack of concrete suggestions or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of manual disentanglement, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not provide any specific reasoning, examples, or references to support the claim that manual disentanglement is a significant issue or why it is preferred over a learned approach. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically questioning the manual disentangling process and suggesting that everything could be learned instead. It raises a valid point about the rationale behind the manual disentanglement and encourages the authors to explore alternative approaches. However, the comment lacks depth and specificity, as it does not provide detailed reasoning or suggestions for how the authors might address this issue. The feedback is 3 as it prompts the authors to consider alternative approaches, but it could be more impactful with additional guidance or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the method. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying a potential area for clarification or improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might affect the method. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method\"s behavior without the Lipschitz Hessian assumption, which is a critical aspect of the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to the method. The comment lacks depth and actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer constructive feedback or suggestions for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to improve the clarity of their presentation, but without specific instructions on how to do so, the action remains implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some pieces\" and \"equation (12),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies that the presentation of these methods is vague and requires checking the original paper for understanding. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it lacks specific examples or references to support the claim. The authors are left to infer that the presentation needs improvement, but without detailed guidance or evidence, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of certain pieces of the paper, noting that some methods are using existing approaches and that their presentation is vague, requiring the authors to consult the original paper to understand them. This feedback is clear and actionable, as it highlights a potential area for improvement in the clarity and organization of the paper. However, it could be more helpful if it provided suggestions on how to improve the presentation or examples of clearer ways to present the methods. Overall, the comment is 4, as it directs the authors to address a specific issue but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on what aspects of the writing are jumbled or how the authors can improve the clarity and organization of their presentation. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not specify which part of the paper is affected by this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment lacks specificity in identifying the sections or aspects of the paper that are jumbled, and it does not provide any guidance on how to address this issue. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the writing and presentation of the paper, noting that it is \"jumbled at times.\" This is a subjective assessment and lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might improve the clarity or organization of their writing. Without concrete advice or examples, the authors are left without a clear path to address the issue, making the comment 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests a scenario where the method might be impractical due to power demand on a mobile device. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft to account for computational complexity. The action is implicit and vague, as it does not specify what needs to be done or how to implement the suggestion. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. The comment is specific in its request for comparison but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests a scenario where the method might be impractical due to power demand on a mobile device. However, the comment does not provide any evidence, reasoning, or references to support the claim about computational complexity or the potential power demand. Without specific data or examples, the authors may find it challenging to address the question or understand the implications. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests a scenario where the method might be impractical due to power demand on a mobile device. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft to account for computational complexity. While it identifies a potential area for improvement, it lacks actionable advice or detailed feedback, making it 3. The authors would need to infer how to address the computational complexity issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of realworld datasets. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might develop a distributed version of the method or what specific steps they should consider. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of realworld datasets. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental setup. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of scalability, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of realworld datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of realworld datasets. This feedback highlights a critical limitation that could impact the practical applicability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as exploring distributed versions of the method or alternative approaches. While it points out a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it raises an important issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific feedback on the vagueness of the statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at L1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it does not offer explicit or concrete actions for the authors to take. The feedback is 3 as it directs the authors to clarify the vague statement and reconsider the reinforcement learningagent analogy, but it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific parts of the paper, such as lines 15, 1618, and later sections (229 to 253). It provides detailed feedback on the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. The comment is fully grounded as it explicitly mentions specific sections of the paper, and it is specific because it provides detailed feedback on the vagueness of a statement and the relevance of the reinforcement learningagent analogy. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point contains claims that are partially verifiable. The first part of the comment suggests that certain RNNs work well for specific natural language reasoning tasks, referencing the literature on natural language inference and providing a link to a leaderboard. This provides some support for the claim, but it could be more detailed with specific examples or references. The second part critiques the reinforcement learningagent analogy, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. This critique is 3 as it provides a logical argument for why the analogy might be outofplace, but it lacks specific examples or references to support the claim fully. Overall, the comment is 4, as it provides some justification but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment provides specific feedback on the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it lacks detailed guidance on how the authors might address these issues or what specific changes should be made. The feedback is 3 as it directs the authors to clarify the vague statement and reconsider the reinforcement learningagent analogy, but it does not provide comprehensive suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: first, it notes that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not discuss this observation further. Second, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide further discussion and justification, but the action is not concrete. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proposed sensitivelayer selection and the lack of mathematical or theoretical justification for Algorithm.1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that the authors do not further discuss this observation. It also notes the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The authors are left to infer the significance of the observation and the need for justification, which could be challenging. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not provide further discussion on this observation. This feedback highlights a gap in the analysis and suggests that the authors should elaborate on the implications of their findings. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm.1, which is a critical aspect that needs to be addressed for the paper to be more robust and credible. By pointing out these specific areas, the comment provides clear guidance for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to strengthen the justification. Overall, the comment is 4 as it identifies important areas for improvement and encourages the authors to expand their analysis and theoretical grounding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This provides a specific and explicit action for the authors to take, as they can directly address this suggestion by revising the notation to better reflect the tuple structure. The comment is clear and concrete, offering a direct and actionable improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This feedback is precise and actionable, guiding the authors on how to enhance the clarity of their notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This is a specific and actionable suggestion that could improve the clarity of the paper. However, the comment does not provide any reasoning or examples to support why this change would be beneficial or how it would enhance the understanding of the triples. Without additional context or justification, the claim is 3, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that triples denoted as $(e_1, r, e_2)$ would be clearer if they were shown as tuples rather than sets. This feedback is actionable and directly addresses a potential area for enhancing the clarity of the paper. By suggesting a change in notation, the comment offers a concrete way for the authors to improve the presentation of their work. However, the comment could be more helpful if it included additional context or examples to illustrate why this change would be beneficial. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the scalability of optimal quantization, suggesting that it is costly to both the number of data points (N) and the dimension (M). It also points out that the paper aims to speed up variational inference (VI) through fast convergence, but quantization is a bottleneck in this process, making the method less effective for big data and big model settings. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the method or what specific changes might be necessary. As a result, the authors are left without clear direction on how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the scalability of optimal quantization, a topic mentioned in the abstract and introduction. It highlights the cost associated with both the number of data points (N) and the dimension (M), and suggests that quantization is a bottleneck for variational inference (VI) in big data and big model settings. However, the comment does not specify which part of the paper discusses the scalability of quantization or how it relates to the overall methodology. This makes it difficult for the authors to pinpoint the exact section or aspect that needs attention. While the comment is specific about the issue of scalability, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It argues that even with clustering, it is costly to both the number of data points (N) and the dimension (M). The paper aims to speed up variational inference (VI) through fast convergence, but the reviewer suggests that quantization is a bottleneck, making the method less effective for big data and big model settings. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the cost and scalability of quantization. While the logic is present, the absence of concrete evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is a significant concern for the paper\"s claims about speeding up variational inference. It highlights that even with clustering, quantization remains costly in terms of both the number of data points (N) and the dimension (M). The reviewer also points out that this bottleneck limits the effectiveness of the method in big data and big model settings, questioning the method\"s relevance. While the comment raises a valid concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of their method. Without actionable advice or detailed reasoning, the feedback is 3, as it provides a clear direction for improvement but does not offer a comprehensive roadmap for the authors to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if it does not address the notations issues. However, the comment does not provide explicit guidance on how to compare the methods or address the notations issues. The actions are implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the effectiveness of the proposed method against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if it does not address the notations issues. However, the comment does not specify which part of the paper discusses the methodology or the issues mentioned above, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific guidance on how to compare the methods or address the notations issues further weakens the comment. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also suggests aiming for a more applicationoriented venue if the notations issues are not addressed. However, the comment lacks specific examples or references to support the claim about the comparison with existing methods or the nature of the issues mentioned above. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if the notations issues are not addressed. However, the comment lacks specific guidance on how to compare the methods or address the notations issues, leaving the authors with limited actionable feedback. While it identifies areas for improvement, the lack of detailed suggestions or examples makes it 3, as it provides a general direction but not a comprehensive roadmap for the authors to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the algorithm\"s effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit or concrete actions for the authors to take. The suggestions are somewhat vague and lack detailed guidance on how to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the algorithm, specifically mentioning its reliance on the entire training dataset. It also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is moderate as it provides some details about the issues but lacks specific examples or guidance on how to address them. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment provides some context and questions, it lacks specific examples or detailed reasoning to fully substantiate the claims. The feedback is 3, as it offers a general critique but could be strengthened with more detailed explanations or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points regarding the limitations of the algorithm, specifically its reliance on the entire training dataset, the comprehensiveness of the validation experiments, and the lack of analysis regarding time complexity and efficiency. It also suggests that the authors should further elucidate the technical contribution rather than focusing solely on the form of the attack. While the comment identifies key areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it provides a clear direction for the authors to consider, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a counterexample, noting that RBF kernels have an infinitedimensional RKHS, which would require an infinitely wide neural network to represent. The comment suggests that the limitation of neural networks in representing such kernels should be made clearer. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors are left to infer how to improve the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, line 104, allowing the authors to accurately identify the section being addressed. It also provides specific feedback by pointing out a counterexample to the claim that every kernel can be described by a feature space parameterized by a neural network. The comment specifies what needs to be addressed, namely the limitation of neural networks in representing certain kernels, such as RBF kernels with infinitedimensional RKHSs. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is trivially not true, providing a counterexample with RBF kernels and their infinitedimensional RKHSs. The comment suggests that the limitation of neural networks in representing such kernels should be made clearer. This claim is supported by logical reasoning and a specific example, making it 4. However, it could be strengthened by providing more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with a claim made in the paper, noting that the assertion that every kernel can be described by a feature space parameterized by a neural network is not entirely accurate. It provides a counterexample using RBF kernels, which have an infinitedimensional Reproducing Kernel Hilbert Space (RKHS), and explains that representing such kernels with neural networks would require an infinitely wide network. This critique highlights a potential limitation of the claim and suggests that the authors should clarify this limitation. The comment is 4 as it points out a specific area for improvement and provides a clear example to support the critique. However, it could be more helpful if it offered suggestions on how to address the issue or provide additional context. Overall, the feedback is valuable and actionable, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training versus the limited tokens used during inference. While the comment highlights a potential issue or area for clarification, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors would need to infer that they should discuss the implications of using long token dimensions during training and the impact on inference. However, the comment lacks concrete details on how to implement this feedback, making it 3.", "grounding_specificity_rationale": "The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training versus the limited tokens used during inference. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or aspect of the paper is being referred to, making the comment weakly grounded. The comment is specific in that it identifies a potential issue with the handling of autoregressive decoding, but without clear grounding, the authors may struggle to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training versus the limited tokens used during inference. While the comment highlights a potential issue or area for clarification, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The authors would need to infer the basis of the question, which makes the comment 2. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training versus the limited tokens used during inference. This question highlights a potential area for clarification or further discussion, which could be valuable for the authors to address. However, the comment lacks specific guidance or suggestions on how to improve the draft or address the issue. While it identifies a potential area for improvement, it does not provide actionable feedback or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the analysis presented in Figure 4. It asks whether GPI with noise added could reproduce the data similarly well, suggesting that additional measures should be considered to show that GPI cannot have as good a fit with behavioral data. The reviewer also suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the possibility of GPI with noise added reproducing the data similarly well and the need for additional measures to show that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. This provides clear guidance on what aspects of the analysis need further exploration or discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the analysis presented in Figure 4, specifically regarding the reproducibility of data with GPI and noise, and suggests considering additional measures to show that GPI cannot have as good a fit with behavioral data. It also proposes discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors are left to interpret the suggestions, which may make it difficult to fully understand and address the issues. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail or evidence to fully substantiate them.", "helpfulness_rationale": "The review comment raises several important points that could enhance the paper\"s analysis and discussion. It questions the reproducibility of data with GPI and noise, suggesting that additional measures should be considered to demonstrate that GPI cannot have as good a fit with behavioral data. The comment also proposes discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment lacks specific guidance on how to address these points or what additional analyses might be necessary. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions for specific analyses or comparisons that could be made to strengthen the paper\"s claims. Therefore, the comment is 3, as it identifies areas for improvement but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their proposed approach with a \"small learning rate for attention parameters\" benchmark. However, it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should perform the comparison, but it lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed approach\" and \"the \"small learning rate for attention parameters\" benchmark, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests a comparison between these two elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification or comparison, rather than a claim that requires verification. It does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it should be classified as \"No\".", "helpfulness_rationale": "The review comment is 3 as it suggests a comparison between the proposed approach and a \"small learning rate for attention parameters\" benchmark. However, it lacks specific guidance on how to conduct this comparison or what aspects of the comparison should be highlighted. The comment provides a direction for improvement but does not offer detailed feedback or actionable steps for the authors to take. Therefore, it aligns with a score of 3, as it offers some insight but could be more comprehensive and detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about aspects that were not understood. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue raised in the paper, referencing lines 106 and 29. It questions the handling of a debate and asks for clarification on why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. However, it does not provide any evidence, reasoning, or references to support these claims. The comment lacks specific examples or justifications, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a critical issue regarding the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about aspects that were not understood. While the comment identifies a potential weakness in the paper\"s approach, it lacks specific guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it highlights an area that needs clarification, but it does not provide actionable steps or detailed insights to improve the draft. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results using the same setting, as most recent methods have their code released. However, the comment does not provide explicit guidance on how to reproduce the results or what specific steps should be taken to ensure a fair comparison. While the action is implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the use of AdamW with cosine learning rate for training the proposed method, while comparing it with methods that use Adam with fixed learning rate. This provides a specific point of comparison and highlights a potential issue with the fairness of the comparison. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the learning rate settings, but without explicit references to sections or figures, the authors may need to infer the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison between the proposed method and other methods is unfair because the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results using the same setting, as most recent methods have their code released. However, the comment lacks specific examples or references to support the claim about the unfairness of the comparison. It does not provide detailed reasoning or evidence to justify why the proposed method\"s use of AdamW with cosine learning rate is an advantage or why the comparison is unfair. Without this additional context, the claim is 3, as it is based on a logical argument but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It highlights that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results using the same setting, as most recent methods have their code released. This feedback is 3 as it points out a potential inconsistency in the experimental setup and suggests a way to address it. However, it lacks detailed guidance on how to reproduce the results or what specific steps should be taken to ensure a fair comparison. The comment could be more helpful with additional suggestions or examples to guide the authors in addressing the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the quality of the plots, specifically mentioning that they are too small, have hardtodistinguish colors, poorly labeled axes (e.g., \"error\"), and visually similar labels. The reviewer suggests that these issues are the reason for the substandard clarity. While the comment identifies several aspects of the plots that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should make the plots larger, use more distinct colors, label the axes clearly, and differentiate the labels. This lack of explicit action makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the plots,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their size, color distinguishability, poor labeling, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques the quality of the plots, detailing specific issues such as their size, color distinguishability, poor labeling, and visually similar labels. These claims are supported by examples and logical reasoning, providing clear evidence for the issues. The comment is 4 as it offers specific examples and detailed descriptions of the problems, allowing the authors to understand and address the concerns effectively. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific feedback on the quality of the plots, which are a crucial part of the paper. It identifies several issues, such as the small size of the plots, the difficulty in distinguishing colors, poorly labeled axes, and visually similar labels. These observations are actionable and provide clear guidance on how the authors can improve the clarity and presentation of their experimental results. By addressing these issues, the authors can enhance the overall quality and impact of their work. The comment is detailed and constructive, making it highly valuable for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. While it prompts the authors to consider the value of this information, it does not provide explicit guidance on how to address this question or what actions should be taken. The comment is somewhat vague, as it does not specify how the authors should analyze the performance or what kind of analysis would be beneficial. Therefore, the comment is 3, as it provides a direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This makes it difficult for the authors to identify the exact area where the comment is relevant. While the question is specific about the type of information being considered, the lack of grounding makes it challenging for the authors to address the comment effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is important or how it might affect the feedback network. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. This question is relevant as it seeks to understand the value of the information provided in the paper. However, the comment lacks actionable guidance or suggestions on how the authors might address this question or what kind of analysis would be beneficial. While it identifies an area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a relevant area for further exploration but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that Table 1 should include standard deviations, which is a concrete action for the authors to take. It also provides a specific reason for this suggestion, stating that including standard deviations would make the submission stronger and that the experiments should be more extensive. This feedback is clear and actionable, providing the authors with a direct instruction on what to improve. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear feedback on what is missing in the table, namely the inclusion of standard deviations, and suggests that the experiments should be more extensive. This feedback is detailed and actionable, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations and suggests that including them would make the submission stronger. However, the comment lacks specific examples or references to support the claim about the impact of standard deviations on the submission\"s strength. While the suggestion is logical, the absence of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides a basis for improvement but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also suggests that the experiments should be more extensive to strengthen the submission. This feedback is clear and actionable, providing the authors with a direct direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct more extensive experiments or suggested specific ways to enhance the presentation of the results. Despite this, the comment is 4 as it provides a clear and actionable critique that guides the authors towards improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. While it identifies a potential issue with the current analysis, it does not provide explicit guidance on how to address this concern or what actions the authors should take. The comment is somewhat vague, as it leaves the authors to infer the need for further investigation or experimentation. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" which allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the performance boost due to additional parameters, particularly regarding the comparison between LinearTop, NLTop, and Unary baselines. The comment provides a clear and detailed explanation of the issue, making it 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references a comparison with results reported in 14, suggesting that the current analysis might be incomplete. However, the comment lacks detailed reasoning or specific examples to fully support the claim. While it provides a basis for questioning the analysis, it does not offer a comprehensive explanation or evidence to substantiate the concern. Therefore, the comment is considered 2, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It points out a potential issue with the current analysis, noting that the comparison between LinearTop, NLTop, and Unary baselines is not fully explained, especially considering the different neural networks used in 14. This feedback is 3 as it identifies a potential area for further investigation or clarification. However, it could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as suggesting additional experiments or analyses. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is hard to follow and recommends improving the structure, specifically mentioning the introduction, method, and experiments sections. It also suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment does not provide explicit guidance on how to improve the structure or the figures, nor does it specify which parts of the figures need improvement. The actions are implicit and vague, leaving the authors with a general idea of what needs to be done but without concrete steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests improving the structure of the paper, specifically mentioning the introduction, method, and experiments sections. It also recommends focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment does not specify which parts of the paper these sections or figures correspond to, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment provides some guidance, it lacks specific details about what aspects of the structure or figures need attention. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is hard to follow and recommends improving the structure, specifically mentioning the introduction, method, and experiments sections. It also suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies areas where the paper could be improved, specifically mentioning that it is hard to follow and suggesting improvements in structure and visualization. It recommends focusing more on the IEM in Figure 3 and enhancing the visualization of Figures 7 and Figure. However, the comment lacks specific guidance on how to improve the structure or the figures, such as suggesting particular restructuring techniques or visualization methods. While it provides some direction, the feedback is somewhat vague and could be more helpful if it included actionable suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the final learning rates used for the deep models, specifically mentioning CIFAR10 and CIFAR100. It also notes that the authors only searched four different learning rates, suggesting that the optimal learning rate for the baseline might be outside the tested interval, potentially affecting the results. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the robustness of their results. The action is implicit and vague, as it does not specify how the authors should determine the final learning rates or how they should mitigate the potential impact of the limited search interval. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not detail what needs to be addressed regarding the learning rates or the potential impact of the limited search interval. Without explicit references or detailed guidance, the authors cannot effectively respond to the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the final learning rates used for the deep models, particularly CIFAR10 and CIFAR100. It notes that the authors only searched four different learning rates, which could potentially affect the results if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not provide any specific reasoning, examples, or references to support the claim that this limitation could impact the results. Without additional justification or evidence, the claim remains 3, as it lacks detailed explanation or supporting details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the final learning rates used for the deep models, specifically mentioning CIFAR10 and CIFAR100. It notes that the authors only searched four different learning rates, which could potentially affect the results if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the robustness of their results. While it identifies a potential area for improvement, it lacks actionable advice or detailed feedback, making it 3. The authors would need to infer how to address the concern, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the authors\" choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions in the context of limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in the transformer model is not a concern. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the model need to be clarified. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the suitability of using a transformer model without locality bias, questioning whether it is the best option given the nature of neighborhood interactions and limited information propagation. However, the comment does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the issue needs to be addressed. While the comment is specific in its critique of the model choice, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the authors\" choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions and limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in the transformer model is not a concern. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the authors\" choice is questionable or problematic. Without additional context or evidence, the reviewer\"s concern remains speculative and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the authors\" choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions and limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in the transformer model is not a concern. However, the comment lacks specific details or suggestions on how the authors might address this concern or what aspects of the model need clarification. While it identifies a potential issue, it does not provide actionable guidance or examples to help the authors improve their draft. Therefore, the comment is 3, as it highlights a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the proposed approaches only outperform the baselines in one out of three setups, and there is no consistent trend in the results. It suggests that the results are insufficient to prove the benefits of the proposed methods and recommends additional experiments or more indepth analysis. The comment provides clear guidance on what needs to be addressed, including the need for more experiments and analysis. This makes the comment 5, as it directly instructs the authors on how to improve their draft. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend, making it unclear which method is better. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It provides specific evidence, such as the fact that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This allows the authors to understand the basis of the claim and how it relates to the paper. However, the comment could be more verifiable by including examples or references to support the claim about the lack of consistent trends. Overall, the comment is 4, as it provides some justification but lacks detailed evidence or references. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This observation is crucial for justifying the claims made in the paper. The comment suggests that additional experiments or more indepth analysis are necessary to strengthen the results and provide a clearer understanding of the benefits of the proposed methods. By highlighting these areas for improvement, the comment offers actionable guidance for the authors to enhance the robustness and clarity of their findings. However, the comment could be more helpful if it provided specific suggestions for additional experiments or analysis techniques. Overall, the feedback is 4 as it directs the authors towards necessary improvements but could be more comprehensive with detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the effectiveness of the proposed engineering method for ReC and notes the incorporation of combinatorial and heuristic aspects, particularly the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment suggests that the authors should clarify the impact of these heuristic components. However, it does not provide explicit guidance on how to clarify this impact, such as specific sections or examples to discuss. The action is implicit and somewhat vague, as the authors are left to infer how to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to clarify the impact of heuristic components, particularly the sophisticated filtering template used in this procedure. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, particularly the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment suggests that the authors should clarify the impact of these heuristic components. However, the comment lacks specific examples or detailed reasoning to support the claim that the heuristic components are significant or how they impact the overall effectiveness of the method. Without additional context or evidence, the claim remains 3, as the authors may need to infer the significance of the heuristic components themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but highlights the incorporation of combinatorial and heuristic aspects, particularly the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment suggests that the authors should clarify the impact of these heuristic components. This feedback is 3 as it identifies a specific area where the authors could improve their explanation or analysis. However, it lacks detailed guidance on how to clarify the impact of these components, leaving the authors with a general idea but without specific steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses doubt about the proposed method\"s ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. While the comment highlights a potential issue with the method\"s reliance on camera information, it does not provide explicit guidance on how to address this concern or suggest any specific actions the authors should take. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the proposed method\"s ability to train without camera information, specifically referencing Line 223 and the \"knowledge of CAD model correspondences.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its questioning of the method\"s reliance on camera information, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses doubt about the proposed method\"s ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. The comment highlights a potential issue with the method\"s reliance on camera information, but it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the proposed method\"s reliance on camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. This feedback highlights a potential limitation or area for improvement in the method\"s implementation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the method\"s applicability. While it identifies a critical aspect of the method, the absence of actionable advice limits its helpfulness to the authors. Therefore, the comment is 3, as it points out a potential weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not provide explicit guidance on how to achieve this detailed comparison or what specific aspects of the comparison should be emphasized. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be made or which sections of the related work are relevant. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting a detailed comparison of time complexity and competitiveness, but without explicit guidance on how to implement this comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without detailed examples or references, the claim is 3, as it provides a general direction for improvement but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct this comparison or what aspects of the comparison would be most valuable. The feedback is 3 as it points out a relevant area for enhancement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the lowresource regime. While the comment provides a clear direction for improvement, it does not specify which additional datasets should be used or how the experiments should be conducted. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the lowresource regime. However, the comment does not specify which datasets should be used or how the experiments should be conducted, making it weakly grounded. The suggestion is specific in terms of the need for more comprehensive evaluation, but the lack of detail on the datasets or experimental setup makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the lowresource regime. However, the comment lacks specific details or examples of which additional datasets should be used or how the experiments should be conducted. Without this information, the authors may find it challenging to understand the exact nature of the suggested improvements. Therefore, the claim is 3, as it provides a general direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of experimental results on more datasets. This feedback is valuable as it highlights the need for a more comprehensive evaluation of the proposed method. The suggestion to conduct experiments on more datasets and to consider the full dataset instead of the lowresource regime provides clear directions for improvement. However, the comment could be more helpful if it offered specific examples of additional datasets or detailed guidance on how to conduct these experiments. Overall, the feedback is 4 as it directs the authors towards enhancing the robustness and comprehensiveness of their evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the lack of clarity in how the generic argument task and the random argument task support the authors\" claims, and the cumbersome nature of the dataset transformation and experimental setup. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the tasks or improve the experimental setup. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the clarity of the generic argument task and the random argument task in relation to the authors\" claims, as well as the cumbersome nature of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the tasks and the experimental setup, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task did not clearly prove the authors\" claims, and that the dataset transformation and experimental setup were cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of clarity in how the generic argument task and the random argument task support the authors\" claims, and the cumbersome nature of the dataset transformation and experimental setup. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need clarification, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline 31, 33, *. However, the comment does not specify how the authors should conduct this analysis or what specific aspects of the computational effort need to be addressed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide this analysis for a fair comparison with the baseline, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a complete lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This is a crucial aspect that needs to be addressed for a fair comparison with the baseline. However, the comment lacks specific guidance on how the authors should conduct this analysis or what specific aspects of the computational effort need to be considered. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but could be more comprehensive with actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the analysis. While the authors can infer that they need to clarify the analysis and provide theoretical evidence, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, but it does not specify which part of the paper this analysis is discussed. The authors cannot confidently determine which section or figure this analysis is related to, making the comment weakly grounded. However, the comment is specific in detailing the issue of the lack of clarity in the analysis and the absence of theoretical evidence. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, noting that the trend is not clear across different model architectures and that no theoretical evidence is provided. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It highlights that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. This feedback is valuable as it points out a gap in the analysis and suggests that the authors should consider expanding their discussion to include theoretical evidence or clarify the analysis. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested alternative approaches. Overall, the comment is 3, as it directs the authors to areas that need improvement but lacks detailed actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues or what steps the authors should take to address them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the references list, such as the presence of duplicates and missing publication venues and years. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that publication venues and years are missing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples or references, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it points out these problems, it does not provide any suggestions or guidance on how the authors might address these issues. The feedback is clear and identifies areas for improvement, but it lacks actionable advice or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical analysis presented in Theorem 1, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare the theoretical results with other comparable methods. However, the comment does not provide explicit guidance on how to analyze or compare the results, nor does it offer concrete steps on what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other comparable methods. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare the theoretical results with other comparable methods. However, the comment lacks specific examples or references to support the claim about the lack of clarity or the need for comparison. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and lacks comparison with other comparable methods. This feedback is actionable as it provides a clear direction for the authors to improve the clarity and depth of their theoretical analysis. However, the comment could be more helpful if it offered specific suggestions or guidance on how to analyze and compare the results with other methods. Despite this, the feedback is 4 as it directs the authors towards a crucial area for improvement, allowing them to enhance the rigor and clarity of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs further finetunes a multilingual model and uses the method like R3F to maintain generalization ability. It also notes that the improvement of 0.8 in some lowresource language translations from 1.2 to 2.0 is insignificant in a practical sense. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the model or the results. The feedback lacks concrete steps or suggestions, making it difficult for the authors to know how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs to finetune a multilingual model and mentions the method like R3F to maintain generalization ability. It also notes that the improvement of 0.8 in some lowresource language translations from 1.2 to 2.0 is insignificant in a practical sense. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the improvement being insignificant, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement of 0.8 in some lowresource language translations from 1.2 to 2.0 is insignificant in a practical sense. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is not 5, as it relies on subjective interpretation. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the practical significance of the improvement in lowresource language translations, specifically noting that an improvement of 0.8 may be insignificant in a practical sense. It also points out a missing reference, which could be relevant for further context or discussion. However, the comment lacks detailed guidance on how the authors might address this issue or what specific actions they should take to improve the model or results. While it highlights a potential area for improvement, the feedback is somewhat limited in its actionable and comprehensive nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. While it prompts the authors to explain this discrepancy, it does not provide explicit guidance on how to address it or what specific actions should be taken. The action is implicit, as the authors need to infer that they should provide a justification for the limited scope of the experiments. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its request for explanation, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. However, it does not provide any specific reasoning, examples, or references to support why the authors chose to focus solely on Gaussian noise. This lack of justification makes the claim 1, as the authors are left without a clear understanding of the reasoning behind the limited scope of the experiments. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model\"s ability to handle various image noise types. This feedback highlights a potential gap in the experimental validation, as it does not provide a clear explanation for why the authors chose to focus solely on Gaussian noise. While the comment identifies an area for improvement, it lacks actionable guidance on how the authors might address this issue or what additional experiments could be conducted to provide a more comprehensive evaluation. The feedback is 3 as it points out a specific area for improvement, but it could be more helpful with additional suggestions or guidance on how to enhance the experimental validation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods. It implies that this visualization is crucial for supporting the research motivation of the paper. However, the comment does not provide explicit guidance on how to visualize this effect or what specific aspects of the visualization should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods, which is important for supporting the research motivation of the paper. However, the comment does not specify which part of the paper this visualization should be included in, making it weakly grounded. It is specific in suggesting a visualization technique to address the issue of performance decline with increasing dimensionality, but without explicit guidance on how to create or implement this visualization, the comment is somewhat specific. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. This is a subjective opinion that could be supported by referencing existing literature or providing empirical evidence. However, the comment lacks specific examples or references to substantiate this claim, making it difficult for the authors to fully understand and address the issue. The suggestion to visualize this effect is logical but requires further elaboration or evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim regarding the performance decline of PU learning methods with increasing data dimensionality. It suggests that visualizing this effect would be beneficial for supporting the research motivation of the paper. While the comment highlights an important aspect that could enhance the paper\"s impact, it lacks specific guidance on how to visualize the effect or what kind of visualization would be most effective. The suggestion is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific claim about Corollary 10, stating that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is explicit and provides a clear action for the authors to consider, as they need to address the implications of this observation. However, the comment does not offer specific guidance on how to improve the draft or what aspects of the argument need to be revised. The action is clear and direct, but it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" which allows the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the claim that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what aspect of the paper requires attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This claim is based on a logical reasoning argument, as it highlights a specific aspect of the corollary and its implications. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further elaborate on the reasoning to fully understand the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Corollary 10, noting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily imply that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is clear and actionable, as it highlights a potential misunderstanding or gap in the interpretation of the corollary. However, the comment could be more helpful if it provided additional context or suggestions for how the authors might address this issue. Overall, the comment is 3, as it provides a clear point of improvement but lacks depth in terms of actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should provide details about the division of the dataset into training and testing sets, including the numbers used and the method of division. It mentions that the division could be random or based on other considerations, implying that the authors should clarify this aspect. The comment is clear and provides specific guidance on what information is missing and how it should be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division of the dataset into training and testing sets, which is a specific part of the paper. It specifies what information is missing, including the numbers used and the method of division, such as whether it was random or based on other considerations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point is a request for additional information regarding the division of the dataset into training and testing sets. It does not contain a subjective claim or opinion, but rather a suggestion for improvement. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper by providing more details about the division of the dataset into training and testing sets. It requests information such as the numbers used and the method of division, which could be random or based on other considerations. This feedback is clear and actionable, as it directly points out a missing element that could enhance the transparency and reproducibility of the research. By addressing this suggestion, the authors can improve the clarity and completeness of their work. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive if it offered additional guidance or examples."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing guidance on how to address these issues. The feedback lacks concrete steps or suggestions, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique of the need for human labor and the scalability issue, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors are left without a clear understanding of why these issues are significant or how they might be addressed. As a result, the comment is considered 1, as it does not provide sufficient evidence or justification for the claims made.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific suggestions or actionable feedback on how to address these issues. While it identifies potential areas for improvement, it does not provide detailed guidance or examples that would help the authors enhance their draft. As a result, the comment is 3, as it offers some insight but lacks depth and practical advice for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the significance of the performance improvement of the proposed methods, specifically noting that the improvement in the bank dataset is only ~0.02. It also suggests that using tables to directly show key improvements could be more intuitive and detailed. While the comment identifies a potential issue with the significance of the results and suggests a way to improve the presentation, it does not provide explicit guidance on how to address the issue or how to make the tables more detailed. The action is implicit and somewhat vague, as the authors are left to infer that they need to reevaluate the significance of the results and consider using tables for better presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the significance of the performance improvement and suggests using tables for better presentation. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, as evidenced by the ~0.02 improvement in the bank dataset. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the claim is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a potential issue with the significance of the performance improvement of the proposed methods, specifically noting that the improvement in the bank dataset is only ~0.02. It also suggests that using tables to directly show key improvements could be more intuitive and detailed. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to address the issue or how to enhance the presentation of results. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they should consider to strengthen their work. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that the authors do not prove any new theoretical results, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or reasoning to support this claim. Without additional context or justification, the authors are left without a basis to understand or address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out that while the use of a specific type of loss in a particular setting might be new, the work does not provide any new theoretical results. This feedback is 3 as it highlights a specific area where the authors could strengthen their work by either providing theoretical analysis or expanding on the implications of their findings. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue, making it 3 rather than fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion by adding the baselines to the table. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be added to the table to improve understanding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim. The authors would need to infer the need for such baselines to enhance the understanding of the gap. Therefore, the comment is 3, as it provides a logical basis but lacks detailed justification or references.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their draft by including additional baselines. By adding these baselines, the authors can gain a more comprehensive understanding of the performance differences between fully supervised and SSL methods. This feedback is valuable and directly addresses a potential area for improvement in the paper, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide explicit guidance or suggestions on how to address this issue, such as proposing alternative methods or optimizations. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the time complexity of the proposed algorithm, specifically mentioning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not specify which part of the paper discusses the algorithm or the hypervolume calculation, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue of time complexity, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the repeated calculation of hypervolume could be timeconsuming. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide any suggestions or insights on how to address this issue or improve the algorithm\"s efficiency. While it identifies a potential weakness, it lacks actionable guidance or recommendations for the authors to consider. Therefore, the comment is 2, as it does not offer substantial feedback or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve their draft. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to include results on larger datasets, but it lacks grounding as it does not mention the specific section or part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the dataset size is a concern or how it impacts the overall quality of the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the experiments, noting that it is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. While the comment highlights a valid concern, it does not provide specific guidance or suggestions on how to address this issue or what changes could be made to the experiments. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should delve deeper into the limitations of evolutionary methods, particularly regarding leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise in their critical remarks. The comment implies that the authors should clarify what \"brittle convergence properties\" mean and consider the adoption of DeepRL methods. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should explore deeper aspects of evolutionary methods, such as leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise in their critical remarks. However, the comment does not specify which part of the paper discusses these limitations, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the areas that need attention, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the paper for being too generic and vague, particularly in its title, and suggests that the authors should be more precise in their critical remarks. It also questions the meaning of \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The feedback is 3 as it provides some reasoning but lacks detailed evidence or references, which could help the authors better understand and improve their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper\"s title as being too generic and suggests that the authors should be more precise in their critical remarks. It also questions the meaning of \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods, which could provide valuable context. However, the comment lacks specific guidance on how the authors might address these issues or what changes could be made to improve the paper\"s clarity and relevance. While it identifies areas for improvement, the feedback is somewhat vague and could benefit from more detailed suggestions or examples. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not specify how this justification should be presented or what kind of empirical evidence would be most effective. The action is implicit, as the authors need to infer that they should include empirical evidence to support their claim. While the comment provides a direction for improvement, it lacks concrete guidance on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, suggesting that there should be empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. This provides the authors with a clear understanding of what needs to be addressed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical justification for the first claimed contribution, which is that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional evidence or context, the authors may find it challenging to understand why this claim is important or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of empirical justification for the first claimed contribution. It points out that the claim about the proposed algorithm not taking as many points or not needing apriori knowledge about dimensions of subspaces is not supported by empirical evidence. This feedback is valuable as it directs the authors to strengthen their claims by providing empirical evidence, which would enhance the credibility and impact of their work. However, the comment could be more helpful if it suggested specific ways to conduct or present the empirical justification, such as proposing experiments or data analysis methods. Overall, the comment is 3 as it highlights an important area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the discussion are missing or what additional information would be beneficial. The comment lacks explicit guidance on how the authors should address this issue, such as suggesting specific areas of previous work to include or how to expand the discussion. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a specific section or paragraph. This lack of grounding makes it difficult for the authors to understand where to address the issue. Additionally, the comment does not provide specific guidance on what aspects of the discussion are missing or how to expand it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, the comment lacks specific details or examples to support this claim. Without additional information or references, the authors may find it challenging to understand the extent of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. This is a valuable piece of feedback as it highlights a potential gap in the literature review, which is crucial for situating the research within the existing body of knowledge. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending specific areas of previous work to include or how to expand the discussion. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment highlights a potential area of confusion for the authors, it does not provide explicit guidance on how to address this issue or what specific aspects need clarification. The action is implicit, as the authors are expected to infer that they need to provide a more detailed explanation of the difference between similarity and exit times. However, the comment lacks concrete details on how to achieve this clarification, making it 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not specify which part of the paper discusses this topic, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in its request for a detailed explanation but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not provide any specific evidence, reasoning, or references to support the claim or the need for clarification. The comment lacks depth and does not offer a clear path for the authors to address the issue. Therefore, it is considered 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the authors\" claim regarding unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment identifies a potential area of confusion for the authors, it does not provide specific guidance or suggestions on how to address this issue. The feedback is 3 as it highlights a point that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and improve their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. It does not provide explicit instructions or suggestions on how the authors should address this question or what changes might be needed in their draft. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not provide any specific evidence, reasoning, or references to support the claim or question posed. The comment lacks depth and does not offer any guidance or justification for why this question is important or relevant. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. This question is relevant as it challenges the authors to consider the scope and applicability of their framework. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or expand their work. While it identifies an important area for consideration, it does not offer actionable advice or insights that would significantly enhance the authors\" draft. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the creation of the dataset is optional and recommends using the Kialo dataset, which is wellstudied and cleaner than the one created in the paper. However, it does not provide explicit guidance on how the authors should implement this suggestion or what specific actions they should take to utilize the Kialo dataset. The comment implies that the authors should consider using the Kialo dataset as an additional resource, but it lacks concrete steps or examples to guide them. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests using the Kialo dataset as an alternative to the one created in the paper, noting its cleanliness and suitability for the authors\" needs. However, it does not specify which part of the paper discusses the dataset creation or how the authors should incorporate the Kialo dataset. The comment lacks grounding as it does not provide explicit references to sections or figures, making it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while it suggests an alternative dataset, it does not specify what needs to be addressed or how the authors should use the Kialo dataset. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the creation of the dataset is optional and recommends using the Kialo dataset, which is wellstudied and cleaner than the dataset created in the paper. The comment provides a logical reasoning by pointing out the advantages of using the Kialo dataset, such as its cleanliness and suitability for the authors\" needs. However, it lacks specific examples or references to support the claim fully. While the reasoning is clear, the absence of detailed examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the creation of the dataset is optional and recommends using the Kialo dataset, which is wellstudied and cleaner than the dataset created in the paper. It highlights the potential benefits of using the Kialo dataset as an additional resource for learning. However, the comment does not provide specific guidance on how the authors should implement this suggestion or what steps they should take to utilize the Kialo dataset effectively. While it offers a valuable insight, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides a direction but lacks detailed guidance for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the Transformer in the context of machine learning, suggesting that the authors\" modification, while claimed, does not provide significant insight. It also questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the paper or what specific changes should be made to enhance the novelty and significance of the work. As a result, the comment is 1, as the authors are left without clear directions on how to proceed.", "grounding_specificity_rationale": "The comment critiques the novelty of the Transformer in the field of machine learning, suggesting that its adoption is no longer novel. It also questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific in its critique of the Transformer\"s novelty and the ablation study results, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the novelty of the Transformer in the field of machine learning, suggesting that its adoption is no longer novel. It questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is 3, as it provides some justification but lacks key elements for full understanding and support.", "helpfulness_rationale": "The review comment critiques the novelty of the Transformer in the field of machine learning, suggesting that its adoption is no longer novel. It questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve the novelty of their work. While it identifies areas for improvement, it lacks depth and guidance, making it 3. The authors would benefit from additional feedback that offers concrete suggestions or constructive advice on enhancing the paper\u2019s contribution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider conducting experiments on other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a clear and explicit action for the authors to take, which is to expand their experiments to include more types of sentence pair tasks. This guidance is concrete and specific, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation in the experiments conducted by the authors, specifically noting that they only evaluate sentence similarity and open domain QA tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for additional experiments on other sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This provides a clear direction for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited, as the authors only conduct evaluations on sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE. While the comment identifies a limitation in the scope of the experiments, it does not provide specific examples or references to support the claim that these additional tasks are common or necessary. The reasoning is somewhat clear but lacks detailed justification or references, making it 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the scope of the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should expand their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions for how to conduct these additional experiments or why these tasks are important. Overall, the comment is 4 as it highlights a clear area for improvement and provides a concrete suggestion for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment identifies a potential gap in the reasoning, it does not provide explicit guidance on how the authors should address this question or what additional analysis might be needed. The action is implicit, as the authors would need to infer that they should provide a clearer explanation for their analysis choice. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its question about the motivation, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. This is a valid question that requires the authors to provide a clear rationale for their analysis choice. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that numerosity might not appear in earlier layers. Without additional context or evidence, the authors may find it challenging to fully understand and address the question. Therefore, the comment is considered 2, as it provides a basis for discussion but lacks sufficient support.", "helpfulness_rationale": "The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. This question highlights a potential gap in the reasoning or explanation provided in the paper, prompting the authors to clarify their analysis choices. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or what additional analysis could be conducted to strengthen their work. While it identifies an area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While it implies that human evaluation is a good idea, it does not provide explicit instructions or guidance on how to implement this suggestion. The authors are left to infer that they should conduct a human evaluation, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to understand where to apply the suggestion. Additionally, the comment does not provide specific details on how to conduct a human evaluation or why it would be more convincing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional justification or evidence, the claim remains unsubstantiated, making it difficult for the authors to understand why this suggestion is important or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. This feedback is valuable as it highlights a potential limitation in the current evaluation approach and suggests an alternative method that could provide more reliable results. However, the comment lacks specific guidance on how to conduct a human evaluation or why it would be more convincing. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a clear direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the triviality of the convergence proof, suggesting that it lacks substantial novelty and rigor. It provides a specific example of how the proof could be adapted by referencing a modification in the appendix. However, the comment does not explicitly instruct the authors to address this issue or provide detailed guidance on how to improve the proof. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising the proof to enhance its novelty and rigor. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Triviality of Convergence Proof\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, explaining that it lacks substantial novelty and rigor due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The comment provides clear guidance on how the authors might address this issue by referencing a modification in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial, as it relies on the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The reviewer suggests that the proof lacks substantial novelty and rigor, and that it could be adapted by referencing a modification in the appendix. However, the comment does not provide specific examples or detailed reasoning to support the claim that the proof is trivial or lacks novelty. While the reasoning is logical, the lack of detailed examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof of convergence, noting that it appears trivial due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The reviewer suggests that the proof lacks substantial novelty and rigor, and that it could be adapted by referencing a modification in the appendix. This feedback is clear and actionable, providing the authors with a specific area to address and a direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to enhance the proof\"s novelty or rigor. Overall, the comment is 4, as it effectively highlights a critical weakness and suggests a path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict in the paper regarding the performance of the multienvironment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this conflict or clarify the statements. The action is implicit, as the authors need to infer that they should clarify the conflicting statements, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s statements regarding the performance of the multienvironment model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the conflicting statements and asks for clarification, providing a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential conflict in the paper regarding the performance of the multienvironment model, specifically mentioning that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing. This is a clear and logical observation that highlights a contradiction in the paper\"s claims. However, the comment does not provide any additional context, examples, or references to support the claim, making it 3. The authors would need to infer the basis of the claim and seek clarification from the paper to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential conflict in the paper regarding the performance of the multienvironment model. It highlights that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. This feedback is clear and actionable, as it points out a specific inconsistency that needs clarification. However, the comment could be more helpful if it provided guidance on how the authors might address this conflict or clarify the statements. Overall, the comment is 4 as it directs the authors to a critical area that requires attention and further explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation of the metrics or citing the metrics. While the comment implies that the authors should include more details about the metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to expand the description of the metrics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper needs improvement. Additionally, the comment is somewhat specific in that it suggests providing more detail or citations about the metrics, but it lacks concrete guidance on how to achieve this. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. However, the comment does not provide any specific reasoning, examples, or references to support why this is a desirable improvement. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that the authors should provide an explanation of the metrics or cite the metrics to enhance the clarity and comprehensiveness of the paper. While the comment highlights a potential weakness in the presentation of the metrics, it does not offer detailed guidance on how to improve the description or what specific aspects of the metrics should be elaborated upon. This feedback is 3 as it points out an area for improvement, but it lacks depth and actionable suggestions, making it only 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment identifies these areas, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to motivate the applications and consider using streaming datasets. However, the lack of specific suggestions or examples makes the action vague and difficult to implement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective of designing fast label aggregation algorithms for a streaming setting, noting that it lacks motivation for the applications. It also points out that the empirical analysis uses static datasets, which limits the paper\"s usefulness. However, the comment does not specify which part of the paper discusses the motivation or the datasets used, making it weakly grounded. The comment is specific in identifying the issues with motivation and the use of static datasets, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting and that the empirical analysis uses static datasets, limiting the paper\"s usefulness. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the scope of the study is underspecified, suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the scope of the study and the missing CoT baselines for incontext learning of Large Language Models. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of additional relevant CoT baselines for incontext learning of Large Language Models in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is 3, as it provides a basis for improvement but lacks detailed justification or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the scope of the study, suggesting that it focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of additional relevant CoT baselines for incontext learning of Large Language Models in Table 2 and 3, referencing a question for clarification. This feedback is 3 as it highlights a potential area for improvement and suggests the inclusion of additional baselines. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested additional relevant baselines. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that Figure 3 is difficult to read, but it does not provide any specific guidance or suggestions on how to improve the figure\"s readability. The authors are left without any actionable steps to take to address this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper Figure 3 is located in, making it difficult for the authors to identify the issue. Additionally, the comment is specific in that it identifies the problem as the difficulty in reading the figure, but without grounding, the authors cannot pinpoint the exact section to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that Figure 3 is \"very hard to read anything on the figure.\" However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors cannot determine why the figure is difficult to read or how it could be improved. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it lacks actionable suggestions or guidance on how to improve the figure\"s readability. Without specific advice on what aspects of the figure need to be addressed or how to enhance its clarity, the authors are left without a clear path forward. This makes the comment 2, as it points out a problem but does not provide sufficient assistance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit suggestions on how the authors might address this connection or incorporate it into their work. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the connection between the statement about the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any specific evidence, reasoning, or references to support the claim that this connection is relevant or important. Without additional context or justification, the authors may find it challenging to understand the basis of the comment and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While the comment identifies a potential area for clarification or further discussion, it does not provide specific guidance or suggestions on how the authors might address this connection or incorporate it into their work. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two specific suggestions for the authors to consider: replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1 instead of the Adam default value. However, it does not explicitly instruct the authors on how to implement these changes or provide guidance on why these replacements or adjustments are necessary. The actions are implicit, as the authors need to infer that they should make these changes and understand the reasoning behind them. The lack of detailed guidance on how to apply these suggestions makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment provides two specific suggestions for the authors to consider, but it does not specify which part of the paper these suggestions relate to. The references to lines 119121 and line 164 indicate that the authors can infer the sections being addressed, but the comment lacks explicit grounding. The suggestions are specific in terms of what needs to be considered, but without clear grounding, the authors may struggle to identify the exact parts of the paper that require attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two specific questions about the paper, one regarding the use of `n^2/(2*s^2)` and the other about the choice of the SGD learning rate. However, it does not provide any claims or suggestions that require verification or justification. The comment is purely descriptive and does not offer any new insights or reasoning that would help the authors understand the issues or improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment provides two specific suggestions for the authors to consider, which could potentially improve the clarity and robustness of their work. The first suggestion involves replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which could simplify the notation and make the paper more accessible. The second suggestion questions the choice of a SGD learning rate of ~0.1, unlike the Adam default value, and asks for justification. This feedback is actionable as it provides concrete suggestions for improvement and prompts the authors to consider the rationale behind their choices. However, the comment could be more helpful if it offered additional guidance on how to justify the parameter or learning rate choice. Overall, the comment is 4, as it identifies areas for improvement and encourages the authors to provide more detailed reasoning."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should analyze the domain gap between datasets and discuss how this gap might affect the adaption of the method. It also recommends considering the value of finetuning a pretrained model on synthetic data. However, the comment does not provide explicit instructions on how to analyze the domain gap or how to incorporate the discussion about the gap into the paper. While it implies that these actions should be taken, the lack of concrete guidance makes the comment 3. The authors are left with a general idea of what needs to be addressed but without specific steps to follow. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends considering the value of finetuning a pretrained model on synthetic data. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. While it provides some specificity by mentioning the domain gap and the potential value of finetuning, the lack of explicit references to sections or figures makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends considering the value of finetuning a pretrained model on synthetic data. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the suggestions. Therefore, the comment is considered 2, as it provides some direction but lacks the necessary depth and support for effective action.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by analyzing the domain gap between datasets and discussing its potential impact on the adaptation of the method. It also recommends considering the value of finetuning a pretrained model on synthetic data, which could enhance the paper\"s contribution. However, the comment lacks detailed guidance on how to analyze the domain gap or how to effectively incorporate the discussion into the paper. While it offers valuable insights, the suggestions could be more actionable with additional details or examples. Therefore, the comment is 3, as it identifies areas for improvement but does not fully guide the authors in executing these suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. However, the comment does not provide explicit guidance on how to incorporate this method into the authors\" draft or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors would need to infer that they should include a comparison with a NCEbased method and potentially discuss the findings of the referenced paper. The lack of concrete details makes the action somewhat vague, aligning with a score of 3.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. However, the comment does not specify which part of the paper this comparison should be made or where the authors should discuss the findings of the referenced paper. This makes it difficult for the authors to identify the specific section or aspect of the paper that needs improvement. The comment is 1 as it does not provide clear guidance on which part of the paper to address. Therefore, it is rated as \"1\".", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. However, the comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. The reasoning is vague, and the claim is not 5 without additional context or references. Therefore, the comment is rated as \"2\".", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an EnergyBased Model (EBM) on natural images with a strong noise distribution. This feedback is 3 as it identifies a potential area for improvement by suggesting a relevant comparison method. However, the comment lacks specific guidance on how to incorporate this method into the authors\" draft or what aspects of the comparison should be highlighted. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment is rated as \"3\"."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that several curriculum learning methods have been discussed in Section 1, but it does not provide explicit guidance on how to address the need for designing a new curriculum learning method for text graphs. While the comment implies that the authors should justify the need for a new method, it lacks concrete suggestions or detailed instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on why existing methods cannot be applied. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that several curriculum learning methods have been discussed in Section 1 but does not provide a detailed justification or explanation of why a new method is needed for text graphs. It mentions the research gap but lacks specific examples or references to support the claim. Without additional context or evidence, the claim is 3, as it is based on an observation but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that while several curriculum learning methods have been discussed, the need for designing a new method for text graphs is not adequately justified. It highlights the lack of discussion on why existing methods might not be applicable to text graphs, which is a crucial aspect for the research to address. This feedback is clear and actionable, as it directs the authors to provide a more detailed justification for their approach and to explore the limitations of existing methods in the context of text graphs. However, the comment could be more helpful if it suggested specific ways to address this gap or provided examples of how to justify the need for a new method. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest ngram features. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, detailing which models to use and how to compare the transfer parts. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"domain adaptation in the NLP field\" and suggests using powerful pretrained language models like BERT and XLNet as the base encoder. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on how the authors should improve their draft by comparing the efficacy of the transfer parts instead of using the simplest ngram features. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using powerful pretrained language models like BERT and XLNet as the base encoder can overcome the domainshift problem, and suggests comparing the efficacy of the transfer parts instead of using the simplest ngram features. While the claim is based on the understanding of domain adaptation in the NLP field, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to provide more evidence or examples to fully understand the basis of this suggestion. Therefore, the comment is 3, as it provides a basis for improvement but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the use of powerful pretrained language models like BERT and XLNet as the base encoder for domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of relying on simpler ngram features. This feedback is actionable and offers a clear direction for the authors to enhance their draft by incorporating more advanced models and conducting a more thorough comparison. However, the comment could be more helpful if it included additional details or examples to guide the authors in implementing this suggestion effectively. Overall, the comment is 4, as it provides a valuable insight into potential improvements but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more explanation for why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, indicating that the authors might consider revising their draft based on this feedback. However, the comment does not explicitly instruct the authors to provide this explanation or detail how to implement it. The action is implicit, as the authors need to infer that they should expand on the explanation. Additionally, the comment lacks concrete guidance on what specific aspects of the explanation need to be elaborated upon. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section of the paper (lines 196197), allowing the authors to accurately identify the part being addressed. It is also specific because it requests more explanation for why two quantities are different and how this captures the difference in learning settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the explanation of why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors might consider revising their draft based on this feedback. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the explanation is lacking or unclear. Without additional justification or evidence, the claim remains 3, as the authors are left to interpret the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper that requires more explanation, specifically the difference between two quantities and how this captures the difference in learning settings. It provides a clear question for the authors to address, which is valuable for improving the clarity and depth of their work. However, the comment lacks additional suggestions or guidance on how to provide this explanation effectively. While it points out a weakness, it does not offer a comprehensive solution or detailed advice on how to enhance the explanation. Therefore, the comment is 3, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "No", "helpfulness_label": "4", "actionability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and explicit action that the authors can take to address the comment. However, the comment does not provide specific guidance on how to conduct this discussion or what aspects of sensitivity to consider. While the action is explicit, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for a discussion on sensitivity, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a request for clarification and does not contain a subjective claim or suggestion that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment requests a discussion on the sensitivity of fixed tuning parameters in the model, specifically asking for both strengths and weaknesses. This feedback is clear and actionable, as it provides a specific area for the authors to address in their draft. By discussing the sensitivity of these parameters, the authors can improve the robustness and reliability of their model. However, the comment could be more helpful if it included suggestions on how to approach this discussion or what aspects to focus on. Overall, the comment is 4 as it identifies a specific area for improvement and encourages a detailed analysis of the model parameters."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. While the comment implies that the authors should conduct additional experiments to address these points, it does not provide explicit instructions on how to implement this exploration or how to determine the number of random seeds. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore different policy gradient approaches and to clarify the number of random seeds used, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the number of random seeds used for learning the policies (DDPO and IPPG) in the experiment results. However, it does not provide any specific reasoning, examples, or references to support why this information is important or how it might impact the results. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG, and raises a question about the number of random seeds used for learning the policies. While the comment identifies an area for further investigation, it lacks specific guidance on how to conduct these experiments or analyze the results. The suggestion to explore different policy gradient approaches is somewhat vague, as it does not provide detailed instructions or examples of how to implement this exploration. Similarly, the question about the number of random seeds is openended and does not offer any guidance on how to determine the appropriate number. Overall, the comment provides some direction but lacks the depth and specificity needed to be fully helpful to the authors. Therefore, it aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting definition 2.1 due to the lack of clarity regarding \"relevant\" auxiliary model weights. While the comment identifies an area for improvement, it does not provide explicit guidance on how to improve the writing or suggest specific actions to take. The authors are left to infer that they need to clarify the definition, but the lack of concrete suggestions makes the action vague and difficult to execute. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of clarity in the definition, specifically regarding the \"relevant\" auxiliary model weights, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting definition 2.1 due to the lack of clarity regarding \"relevant\" auxiliary model weights. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the writing could be improved, namely the clarity of definition 2.1. It points out that the term \"relevant\" auxiliary model weights is not clearly defined, making it difficult for the authors to understand the definition. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how to improve the clarity of the definition. This feedback is 3 as it directs the authors to a specific area for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the robustness of MIA testing for privacy guarantees and recommends using ULiRA. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The comment suggests that the authors should consider using ULiRA, but it lacks detailed instructions or examples on how to implement this recommendation. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing in the paper, specifically mentioning the robustness of MIA testing for privacy guarantees and recommending the use of ULiRA. However, it does not specify which part of the paper discusses MIA testing or how it is used. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a potential issue with the use of MIA testing and suggests an alternative method, ULiRA. However, without explicit references to the paper sections, the authors may struggle to pinpoint the exact areas that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA testing is not sufficiently robust for privacy guarantees and recommends using ULiRA. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of MIA (Membership Inference Attack) testing for evaluating unlearning effectiveness, suggesting that the current approach may not be sufficiently robust for privacy guarantees. It recommends using ULiRA as an alternative method. However, the comment lacks specific guidance on how the authors should address this issue or what changes they should make to their draft to improve the robustness of their privacy evaluation. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment identifies a potential area for expansion or clarification, it does not provide specific guidance or suggestions on how to address this issue. The feedback is 3 as it points out a potential avenue for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also implies that providing a single review of the various advances in this area would be beneficial for the community. However, the comment does not specify which parts of the paper need to be revised or how the settings should be presented to align with prior work. The action is implicit and vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also implies that providing a single review of the various advances in this area would be beneficial for the community. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to improve the paper by providing more details on the algorithm settings and offering a comprehensive review of prior work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand how to implement the suggested changes. Without detailed guidance or examples, the claim remains 3, as it lacks the necessary depth and specificity to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement these suggestions or what aspects of the algorithm settings need to be detailed. The feedback is 3 as it points out a direction for improvement but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of the specific examples presented in the paper, particularly concerning biases of target statistics and prediction shifts of gradient values. While it points out that the paper demonstrates these biases can occur, it does not provide explicit guidance on how to address or clarify the generalizability of these situations. The comment suggests that the authors should consider expanding on the discussion to provide a more comprehensive understanding of the scope and applicability of these findings. However, the action is implicit and somewhat vague, as it does not specify how the authors should address the issue or what additional information would be beneficial. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the clarity of the paper, particularly regarding the generalizability of the examples presented in section 3.2 and Theorem 1. It highlights that while the paper demonstrates specific biases and prediction shifts, it does not provide a clear understanding of how general these situations are. This feedback is fully grounded as it explicitly mentions the sections and theorems being discussed, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies the areas where the authors need to provide more clarity or expand their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the specific examples presented in the paper, particularly concerning biases of target statistics and prediction shifts of gradient values. It suggests that while the paper demonstrates these biases can occur, it is unclear how general these situations are. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the authors are unsure about the generalizability of these situations. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the generalizability of the examples presented in section 3.2 and Theorem 1. It points out that while the paper demonstrates specific biases and prediction shifts, it does not provide a clear understanding of how general these situations are. This feedback is 3 as it highlights a potential gap in the paper\"s discussion, suggesting that the authors should consider expanding on the scope and applicability of their findings. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what additional information would be beneficial. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would have appreciated more datasets, particularly for the crosstask transferability aspect. However, it does not provide explicit guidance on how to incorporate these additional datasets or what specific datasets would be beneficial. The action is implicit, as the authors need to infer that they should add more datasets to address the crosstask transferability. While the comment is 3, it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the authors would have appreciated more datasets, especially concerning the crosstask transferability aspect. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section or figure that needs improvement. The comment is 1 as it does not provide specific guidance on which part of the paper should be addressed. Therefore, this comment is 1 and does not provide specific feedback, aligning with a score of 1 and Not Specific.", "verifiability_rationale": "The review point suggests that the authors would have appreciated more datasets, particularly concerning the crosstask transferability aspect. However, the comment does not provide any specific reasoning, examples, or references to support why more datasets would be beneficial or how they could enhance the study. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, this comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors would have appreciated more datasets, especially concerning the crosstask transferability aspect. While this feedback provides a clear direction for improvement, it lacks specific guidance on which datasets to include or how they might enhance the study. The comment is 3 as it identifies a potential area for expansion, but it does not offer detailed suggestions or examples, which could further enhance its usefulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved imagetext tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not provide explicit guidance on how to implement these unique tasks or what specific aspects of the dataset should be utilized for these tasks. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks performed on the dataset are somewhat standard, specifically mentioning figure captioning and matching figures/subfigures to appropriate captions. It then proposes the inclusion of unique tasks, such as interleaved imagetext tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not specify which part of the paper discusses these tasks or the dataset itself, making it difficult for the authors to identify the exact section or figure that needs attention. While the comment is specific about the type of tasks suggested, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved imagetext tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment lacks specific examples or references to support the claim that the current tasks are standard or that the suggested tasks would effectively demonstrate the dataset\"s diversity. Without detailed reasoning or examples, the claim remains 3, as the authors may need to infer the basis for the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting the inclusion of unique tasks, such as interleaved imagetext tasks like Question Answering from images, to showcase the diversity of the dataset. This feedback is 3 as it provides a direction for enhancing the tasks performed on the dataset, which could potentially enrich the dataset\"s utility and demonstrate its versatility. However, the comment lacks specific guidance on how to implement these unique tasks or what aspects of the dataset should be utilized for these tasks. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors have made any additional novel effort in the Sec. 3.1 for 3D Gaussians generation, noting that it seems to follow the previous work, Luciddreamer. While the comment implies that the authors should clarify the novelty of their approach, it does not explicitly instruct them to provide evidence or details about any additional contributions. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the novelty of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. However, it does not specify which part of the paper Sec. 3.1 corresponds to, making it weakly grounded. The comment is specific in its request for clarification regarding the novelty of the approach, but without explicit grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. While the comment implies that the authors should address the novelty of their approach, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of explicit evidence or justification makes the claim 3, as the authors are left to infer the need for clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the novelty of the Sec. 3.1 for 3D Gaussians generation, noting that it appears to follow the previous work, Luciddreamer. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the novelty of their approach, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to improve the tractability of MMD DRO or how to refine the upper bound. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1, specifically mentioning that MMD DRO does not have a tractable exact equivalent reformulation. It also highlights the crude nature of the upper bound due to the omission of the nonnegative constraint on the distribution and the need for further approximation. Additionally, the comment points out the restrictive assumption of the loss function belonging to the RKHS. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific guidance on how to address these issues limits the comment\"s effectiveness. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also criticizes the crude nature of the upper bound due to the omission of the nonnegative constraint on the distribution and the need for further approximation, even in simple cases. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises several valid concerns about the tractability of MMD DRO and the limitations of the upper bound presented in Theorem 3.1. It points out that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also criticizes the crude nature of the upper bound due to the omission of the nonnegative constraint on the distribution and the need for further approximation, even in simple cases. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the tractability of MMD DRO or the upper bound. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. However, the comment does not provide explicit guidance on how to implement this action or what specific steps should be taken. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague. Therefore, the comment is 3, as it provides a direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an action to be taken with the baselines on the lefthand side of the figure, specifically to sparsify the trained models and compare accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about an action that could be taken with the baselines in Figure 3, specifically suggesting sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, the comment does not provide any justification, reasoning, or references to support why this action is relevant or beneficial. Without additional context or explanation, the claim is 1, as the authors are left to interpret the suggestion without any supporting evidence. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This feedback is 3 as it identifies a potential area for improvement and provides a clear direction for the authors to consider. However, the comment lacks depth and does not offer detailed guidance or suggestions on how to implement this action effectively. To enhance its helpfulness, the comment could include more specific examples or reasoning behind why this comparison is important. Overall, the comment provides a starting point for improvement but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the paper\"s clarity and reproducibility. It suggests that while the paper provides an intuitive understanding, it lacks the necessary technical details for reproduction, such as specifics about the RNN implementation. However, the comment does not explicitly instruct the authors to include these details or provide guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper being written to provide an intuitive understanding but lacking details for reproduction, specifically mentioning the need for technical details like RNN implementation parameters. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what is missing in terms of technical details required for reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is written to provide an intuitive understanding but lacks details for reproduction, such as RNN implementation parameters. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity and reproducibility. It points out that while the paper provides an intuitive understanding, it lacks the necessary technical details for reproduction, such as specifics about the RNN implementation, including the number of units. This feedback is clear and actionable, as it directs the authors to include additional details to enhance the paper\"s reproducibility. However, the comment could be more helpful if it provided specific examples or guidance on what kind of technical details are needed. Overall, the comment is 4, as it effectively highlights a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the FIITED approach, suggesting that relying solely on utility scores for eviction decisions could introduce biases. It provides an example of how this might occur, where recent chunks might be evicted prematurely. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to mitigate it. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider alternative eviction strategies or incorporate additional factors beyond utility scores. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the FIITED approach, specifically mentioning the utilitybased approach to determine chunk significance. It highlights a potential issue with relying solely on utility scores for eviction decisions, suggesting that this could introduce biases. However, the comment does not specify which part of the paper discusses the FIITED approach or the utilitybased method, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in identifying the issue with the approach, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that relying solely on utility scores for eviction decisions in the FIITED approach might introduce biases. It provides an example of how this could occur, where recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment lacks specific references or detailed reasoning to fully substantiate this claim. While the logic is somewhat clear, the absence of concrete evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the FIITED approach, specifically the reliance on utility scores for eviction decisions. It highlights that this approach might introduce biases, as recent chunks could gain a temporary high utility, leading to premature evictions of other valuable chunks. While the comment points out a valid concern, it does not provide specific suggestions or guidance on how to address this issue or improve the approach. The feedback is 3 as it raises a critical point that could impact the effectiveness of the method, but it lacks actionable advice for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the performance and contribution of the framework. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It mentions that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment is fully grounded as it explicitly mentions the areas where the authors need to clarify their work, such as the experimental aspects and comparisons. However, the comment is somewhat specific as it does not provide detailed guidance on what specific experiments or comparisons should be included. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the experimental aspects of the paper, specifically regarding the performance and contribution of different parts of the framework. It notes that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by highlighting the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions, which is a crucial point for the authors to address. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could conduct additional experiments or provide more detailed explanations to clarify the performance and contribution of the framework. Overall, the comment is 3 as it identifies a key area for improvement but lacks depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the model need to be clarified. The comment lacks concrete guidance on how the authors can improve the draft to address this concern. As a result, the authors are left without a clear understanding of what actions to take to enhance the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment does not provide specific guidance or suggestions on how to address the issue of novelty or testability. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any specific evidence, reasoning, or references to support the claim that the model could generate novel knowledge or testable hypotheses. The comment lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. While it identifies a potential area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to enhance the paper. As a result, the comment is 2, as it does not offer any actionable insights or suggestions for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, it does not provide explicit guidance on how to simplify the theorem or what aspects should be emphasized. The action is implicit, as the authors would need to infer that they should simplify the theorem, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a direction but not a detailed path for implementation.", "grounding_specificity_rationale": "The comment suggests presenting a simplified version of Theorem 2 for the general audience, noting that it is currently difficult to understand. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The comment is fully grounded in terms of identifying the area of concern, as it mentions \"Theorem 2\" and \"definition 2,\" allowing the authors to infer the specific parts of the paper being addressed. However, it lacks specificity in detailing what aspects of the theorems are difficult to understand or how they could be simplified. Therefore, the comment is weakly grounded and underspecific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, the comment does not provide any specific reasoning, examples, or references to support why this simplification would be beneficial or how it could be achieved. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of Theorem 2, suggesting that it might be difficult for the general audience to understand. It proposes that a simplified version of the theorem could be presented to enhance clarity. However, the comment does not provide specific guidance on how to simplify the theorem or what aspects should be emphasized. While it offers a suggestion for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it points out a potential area for enhancement but does not fully address the authors\" needs for actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct experiments using a larger resolution than 224*224. While it implies an action, it does not provide explicit guidance on how to implement this suggestion, such as specifying which experiments should be conducted at a larger resolution or what the expected impact might be. The action is implicit and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments with a larger resolution, which is a specific aspect of the methodology. However, it does not explicitly mention which part of the paper this relates to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer which part is being addressed. The comment is specific in suggesting an improvement to the experimental setup, but the lack of grounding makes it difficult for the authors to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments with a larger resolution, which is a logical and practical suggestion. However, it lacks specific details or references to support why this change would be beneficial or how it might impact the results. The comment is 3 as it provides a clear direction for improvement but does not offer detailed reasoning or evidence to support the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests conducting experiments with a larger resolution, which is a logical and practical suggestion to potentially improve the performance of the experiments. However, the comment lacks specific guidance on which experiments should be conducted at a larger resolution or what the expected impact might be. While it provides a direction for improvement, it does not offer detailed insights or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for enhancement but does not fully support the authors in making informed decisions about their experiments. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide explicit guidance on how the authors should revise their method or what specific changes to make. The action is implicit, as the authors need to infer that they should reconsider their approach and potentially implement the suggested alternative. While the action is somewhat concrete, it lacks detailed instructions on how to apply it, making the comment 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section\" and the specific part of the section, \"What is the keypoint mask averaged feature vector?\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the approach used in calculating the averaged feature vector and suggests an alternative method. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current method might be incorrect or why the alternative approach is better. Without additional context or explanation, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment lacks detailed guidance or suggestions on how the authors should revise their method or what specific changes to make. While it identifies a potential issue, it does not provide actionable feedback or detailed reasoning to help the authors address the concern effectively. Therefore, the comment is 3, as it highlights a potential area for improvement but does not offer comprehensive guidance for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. It suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment does not offer any specific guidance or suggestions on how the authors might address this issue or strengthen their argument. The authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. However, it does not specify which part of the paper discusses this contribution or the issue of neural ODEs exhibiting inaccuracy while recomputing activations. The authors are left to infer that the comment pertains to the introduction or methodology sections, but without explicit references, the grounding is weak. The comment is specific in its critique of the analytical argument and empirical evidence provided, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. It claims that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the central contribution of the paper, particularly the modeling of weight evolution using ODEs. It questions the novelty of the problem addressed, suggesting that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or strengthen their argument. While it highlights a potential weakness, it does not offer actionable steps for improvement, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a specific and explicit action that the authors can take to improve their draft. The comment provides a clear instruction on what needs to be added, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a minor addition to improve clarity by mentioning that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the \"No\" category.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a clear and actionable piece of feedback that could enhance the clarity and completeness of the paper. However, the comment lacks broader context or suggestions for other potential improvements, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial, but acknowledges that computational resources might be a constraint. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is explicit in suggesting additional experiments, which provides a clear action for the authors to take. However, it lacks specific guidance on which datasets or types of experiments to conduct, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests additional experiments on larger datasets, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper these experiments relate to, making it weakly grounded. The comment is specific in suggesting that these additional experiments would be beneficial, but it lacks detailed guidance on how to conduct them or what specific issues they aim to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on larger datasets would be beneficial, but it also expresses a preference for maintaining probabilities, particularly at large batch sizes, and deems this aspect not critical. While the comment provides a rationale for the suggestion, it lacks specific examples or detailed reasoning to fully substantiate the claim. The feedback is 3 as it offers a logical argument but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial, which is a valuable piece of feedback for improving the paper. However, the comment also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. While the feedback provides a clear direction for improvement, it lacks specific guidance on which datasets or types of experiments to conduct, making it 3. The comment is 4 as it offers actionable suggestions but could be more comprehensive with additional details or examples to fully guide the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples of how the performance of the models in Table 4 is behind more recent models, citing GLaMM and UNINEXT. However, it does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of how the performance of the models in Table 4 is behind more recent models, citing specific models and their performance metrics. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of how these models perform compared to the current models. The claim is supported by the inclusion of references to GLaMM and UNINEXT, which provide specific performance metrics. This level of detail and evidence makes the claim 5, as it provides a clear basis for comparison and highlights areas for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that they are behind more recent models. It provides concrete examples of how these models perform, referencing GLaMM and UNINEXT, which achieve higher performance metrics. This feedback is valuable as it highlights a clear area for improvement and provides specific examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this performance gap or what steps they could take to improve their models. Despite this, the comment is 4 as it directs the authors towards areas that need attention and provides a basis for further discussion. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on fewshot classification using such a dataset. However, the comment does not provide explicit guidance on how the authors should address this weakness or what specific steps they should take to improve their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or figure that needs attention. Additionally, the comment does not provide specific guidance on how to address this issue or what changes should be made to the paper. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method, suggesting that it might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on fewshot classification using such a dataset. However, the comment lacks specific guidance on how the authors might address this issue or what changes could be made to their draft to improve its relevance or applicability. While it provides a direction for further exploration, it does not offer actionable feedback or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, perhaps in the appendix. This provides a clear and explicit action for the authors to take, which is to expand the explanation of the bounds. The comment is specific in its suggestion, detailing what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, specifically mentioning the possibility of including this in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which section or part of the paper needs improvement. Additionally, the comment is specific in suggesting the inclusion of the explanation in the appendix, providing clear guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. However, the comment does not provide any specific reasoning or evidence to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. This feedback is specific and actionable, as it provides a clear direction for the authors to improve the clarity and comprehensibility of their work. By suggesting the inclusion of a more detailed explanation of the bounds, the reviewer offers a concrete and constructive suggestion that could enhance the paper\"s overall quality. However, the comment could be more helpful if it provided additional guidance on how to explain the bounds or examples of where this explanation could be included. Despite this, the feedback is 4 as it directs the authors towards a specific area for improvement. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, it does not provide explicit guidance on how the authors should address this point or what changes might be needed in their draft. The comment implies that the authors should consider removing the fullpage explanation, but it lacks concrete instructions on how to do so or what specific aspects of the explanation are redundant. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Kernels are implemented with OpenAI\"s Triton, not CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains why the fullpage explanation is unnecessary, citing \"wellknown engineering improvements.\" This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, the comment does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how it applies to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific implementation detail regarding the use of OpenAI\"s Triton versus CUDA for kernel implementation. It suggests that the fullpage explanation is unnecessary due to wellknown engineering improvements, which provides a clear point of reference for the authors to consider. However, the comment lacks depth and does not offer specific guidance on how the authors might address this issue or what aspects of the explanation are redundant. While it offers a starting point for improvement, the feedback could be more comprehensive and actionable to fully enhance the draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the zeroshot nature of the experiment and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides examples of tasks that could be used to demonstrate the transferability. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the transferability and provide more information about the tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the experiment and questions the transferability due to the difficulty of the source and target tasks. It provides examples of tasks, such as \"Walkerrun\" being harder than \"walkerwalk,\" and suggests that the manipulation scenario with rotations could provide sufficient information for policy transfer. However, the comment does not explicitly mention specific sections or parts of the paper that need to be addressed, making it weakly grounded. It is specific in detailing the issues with the transferability and the potential limitations, but without clear references, the authors may struggle to identify the exact areas to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiment and the transferability of policies due to the difficulty of the source and target tasks. It provides examples, such as \"Walkerrun\" being harder than \"walkerwalk,\" and suggests that the manipulation scenario with rotations could provide sufficient information for policy transfer. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims, making it 3. The authors are left to infer the basis for these claims, which could be improved with more detailed explanations or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the zeroshot nature of the experiment and suggests that the transferability of policies might be limited due to the difficulty of the source and target tasks. It provides examples, such as \"Walkerrun\" being harder than \"walkerwalk,\" and suggests that the manipulation scenario with rotations could provide sufficient information for policy transfer. However, the comment does not offer specific guidance or suggestions on how to address these concerns or improve the paper\"s clarity on policy transferability. While it identifies a potential issue, it lacks actionable advice, making it 3. The authors would need to infer that they need to clarify the transferability and provide more information about the tasks to address the concerns raised. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. It mentions specific sections of the paper (3.2 and 3.3) where this issue is discussed. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific aspects of their analysis could be improved. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of the analysis of neural networks and the triviality of extending from linear models to wide fullyconnected neural networks. This provides clear guidance on how the authors can improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. While the comment provides a logical reasoning based on the existing theorem, it lacks specific examples or references to support the claim fully. The authors are left to infer the basis of the claim, which makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the analysis of neural networks contributes less, suggesting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. This critique provides a clear and actionable feedback, highlighting a potential weakness in the analysis. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or expand their analysis to include more complex neural networks. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework. It points out a discrepancy in the terminology used (\"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology used in these sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper (Stroh et al. 2017). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework, pointing out a discrepancy in terminology. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract and introduction use inconsistent terminology regarding the cost of the multifidelity framework, specifically mentioning \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. While the comment identifies a potential issue with clarity, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the inconsistency, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework. It points out a discrepancy in terminology, noting that the abstract uses \"relatively inexpensive\" while the introduction uses \"expensive to evaluate.\" This feedback highlights a need for the authors to clarify their terminology to avoid confusion. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples or rephrasing the terms to ensure consistency. While it points out a potential area for improvement, the feedback is 3 as it directs the authors\" attention to a specific issue that could impact the clarity of their work. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their method. The feedback is vague and lacks concrete steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method addresses sparse reward problems, suggesting that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its questioning of the method\"s approach to sparse rewards, but it lacks grounding as it does not pinpoint the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment lacks specific examples or detailed reasoning to support its claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general observation but lacks depth and specific evidence to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their method. It does not provide actionable feedback or detailed insights into the areas where the method could be enhanced. As a result, the comment is 2, as it identifies a potential issue but does not offer concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and suggests that other methods, such as HMR and SPIN, might have access to this data during training, which could affect the fairness of the comparison. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to provide this information or how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the dataset usage. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset for training and suggests that other methods, such as HMR and SPIN, might have access to this data during training, which could affect the fairness of the comparison. However, the comment does not specify which part of the paper discusses the dataset or the training process, making it difficult for the authors to pinpoint the exact section that needs clarification. While the comment is specific about the issue of dataset usage, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and suggests that other methods, such as HMR and SPIN, might have access to this data during training, which could affect the fairness of the comparison. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the use of the curated AH36M dataset for training and questions whether other methods, such as HMR and SPIN, might have access to this data during training, potentially affecting the fairness of the comparison. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or ensure a fair comparison. The feedback is 3 as it highlights a critical aspect of the methodology that needs clarification, but it lacks actionable advice or detailed guidance on how to resolve the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment also suggests comparing to other approaches that have been proposed since the initial work, which have significantly improved the results. By providing these detailed suggestions, the comment gives the authors a clear understanding of what needs to be done to enhance the paper. The action is explicit and concrete, as it specifies exactly what comparisons should be made and where to find relevant information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the captioning experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for comparison, including references to the official COOC leader board on the blind test set and specific examples of related work that have won the challenge. The comment also suggests comparing to other approaches that have been proposed since then, which are significant improvements. This level of detail and specificity makes the comment highly informative and actionable for the authors. Therefore, this comment is rated as 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the captioning experiment with official test sets or development sets, but it suggests comparing them on the official COOC leader board on the blind test set, referencing specific examples and related work that have won the challenge. The comment provides specific references and examples, such as 5, 17, which support the claim. However, it could be more robust if it included a detailed explanation of why these comparisons are necessary or how they would impact the paper\"s conclusions. Overall, the claim is 4, as it is supported by logical reasoning and references, but it could benefit from additional depth and detail.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. Additionally, it suggests comparing to other approaches that have been proposed since then and have significantly improved the results. By providing detailed guidance on what comparisons should be made and where to find relevant information, the comment offers actionable feedback that can help the authors enhance the rigor and comprehensiveness of their work. This feedback is 4 as it addresses a specific area for improvement but could be further expanded to cover other aspects of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. While the comment implies that the authors need to provide more context, it does not explicitly instruct them to clarify the meaning of \"wrong\" or how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors need to clarify the meaning of \"wrong\" in the context of the paper, particularly before using terms like \"good,\" \"bad,\" or \"wrong\" explanation. This provides a clear direction for the authors to improve the clarity of their writing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" in the context of the paper, specifically at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the use of \"wrong\" is problematic or unclear. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the use of the term \"wrong\" at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address the issue. By clarifying the meaning of \"wrong,\" the authors can enhance the clarity and precision of their writing, making it easier for readers to understand the nuances of their arguments. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive if it provided additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting that the paper only compares ELF (the author\"s method) with a baseline without Mid Vision Feedback (MVF) but lacks a comparison with the image classification results of Mid Vision Feedback (MVF). This feedback suggests that the authors should include such a comparison to better demonstrate the contribution of their method. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add a comparison with the image classification results of MVF to strengthen the experimental demonstration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental demonstration, namely the comparison with the image classification results of MVF. This provides the authors with a clear understanding of what needs to be addressed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The comment suggests that this lack of comparison does not prove the superiority of the schema searched by ELF (the author\"s method) over the schema in MVF. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It highlights the lack of comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for substantiating the claim that the schema searched by ELF (the author\"s method) is better than the schema in MVF. This feedback is valuable as it directs the authors to include a more comprehensive experimental comparison, thereby strengthening the paper\"s claims. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects of the comparison should be included. Overall, the comment is 4, as it points out a critical area for improvement but lacks detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially concerning occupant comfort and energy efficiency. While the comment identifies a specific area that needs more attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to expand on this aspect, but the comment lacks concrete suggestions or detailed instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what the authors should cover, namely the types of activities and their importance in smart homes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. This feedback is 3 as it highlights a specific area that needs improvement, but it lacks detailed guidance on how the authors might address this gap. The comment provides a clear direction for the authors to expand their discussion, but it does not offer specific suggestions or examples of how to incorporate this information into the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of the concept of \"state\" in the paper, suggesting that it is represented by the \"grid status\" and obtained after applying an action. It also asks whether the term \"elements\" is equivalent to \"states\" or \"actions,\" implying that more elaboration is needed. While the comment explicitly states the need for clarification, it does not provide specific guidance on how the authors should elaborate on the concept or the relationship between \"elements,\" \"states,\" and \"actions.\" The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the concept of \"state\" in the paper, specifically questioning its clarity and providing examples of how it is represented. It references specific lines (186187) to pinpoint the part of the paper being discussed. However, it does not specify what needs to be addressed in terms of elaborating on the concept or providing more context. The comment is fully grounded as it mentions specific lines, but it is underspecific because it does not detail what needs to be addressed. Therefore, this comment is categorized as 4, aligning with category 4.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" in the paper, specifically asking whether \"elements\" are equivalent to \"states\" or \"actions.\" This is a subjective question that requires clarification and does not present a claim that needs verification. The comment is factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the concept of \"state\" in the paper, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" This feedback is 3 as it highlights a specific area that needs clarification, which can guide the authors in improving the consistency and understanding of their terminology. However, the comment lacks depth and does not provide detailed suggestions or guidance on how to elaborate on the concept or address the ambiguity. As a result, it is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This comment provides a clear and explicit action for the authors to take, as they can directly compare the support of their proposed scheme with baseline methods using the suggested metric. The action is also concrete, as it specifies the exact method for comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. However, it does not specify which part of the paper this comparison should be made or where the baseline methods are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs to be addressed. While the comment is specific about the type of comparison, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods using a Jaccard index. This is a suggestion for an additional analysis or comparison that could enhance the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is important or how it would be conducted. The lack of detailed justification or guidance makes it difficult for the authors to understand the significance of the suggestion and how to implement it. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient support.", "helpfulness_rationale": "The review comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This feedback is 3 as it provides a specific suggestion for an additional analysis that could enhance the paper. However, it lacks depth and does not offer detailed guidance on how to conduct this comparison or why it is important. The comment identifies a potential area for improvement but does not fully address the authors\" needs for a comprehensive analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete details on what needs to be clarified or improved. As a result, the authors are left without a clear understanding of how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper discusses these comparisons, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment identifies a potential area for improvement but lacks actionable advice, leaving the authors with limited insight into how to enhance their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\"s comprehension of object presence. However, it does not provide explicit guidance on how the authors should address this issue or what alternative methods could be used. The comment implies that the authors should consider expanding their evaluation to include more nuanced measures, but it lacks concrete suggestions or detailed instructions on how to implement this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\"s comprehension of object presence. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the measurement method, the absence of explicit grounding limits its effectiveness. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\"s comprehension of object presence. The comment implies that a yes response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide more detailed reasoning or evidence to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a positive response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects in other tasks. This feedback is 3 as it highlights a potential limitation in the evaluation method, suggesting that the authors should consider expanding their evaluation to include more nuanced measures. However, the comment could be more helpful if it provided specific suggestions or examples of alternative evaluation methods that could address this issue. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not provide explicit guidance on how to detail the innovative aspects or what specific aspects need to be elaborated upon. The action is implicit and vague, as the authors are left to infer that they need to provide more details on the innovative aspects of the FRM. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not specify which part of the paper this comment is addressing, such as a specific section or figure. The comment is vague and does not provide detailed guidance on what needs to be detailed or how to elaborate on the innovative aspects. As a result, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Since the comment lacks specificity in detailing what needs to be addressed, it is not specific. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or logical arguments to substantiate the assertion that the FRM is a simple combination of these attention mechanisms. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed FRM, suggesting that it is a simple combination of channel attention and spatial attention. It implies that the innovative aspects of the FRM should be detailed. However, the comment lacks specificity and does not provide concrete suggestions or guidance on how to elaborate on the innovative aspects. Without additional details or examples, the authors may struggle to understand what specific areas need to be expanded upon. Therefore, the comment is 2, as it provides a general observation but lacks actionable feedback. The score of 2 aligns with this assessment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clear connection between two concepts: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should clarify this connection, but it does not provide specific guidance on how to do so. The comment is explicit in identifying the issue but lacks detail on how to address it, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in identifying the need for clarification but lacks grounding as it does not provide explicit references to the paper sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the connection between two concepts: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should clarify this connection, which is crucial for understanding the paper\"s main argument. However, the comment lacks specific details or suggestions on how to improve the clarity, making it 3. The authors would benefit from additional guidance on how to enhance the explanation of this connection, but the feedback is incomplete without concrete examples or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not provide explicit guidance on how to conduct these analyses or experiments, nor does it offer concrete steps for the authors to take. The comment is 3 as it identifies a potential area for improvement, but it lacks specific details on how to implement the suggested analyses or experiments, making it difficult for the authors to know exactly what to do. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not specify which part of the paper these analyses or experiments should be conducted in, making it difficult for the authors to identify the exact sections or parts of the paper that need attention. The comment is specific in its suggestions but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform robust probabilistic predictors. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that such analyses are missing. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is rated as 2, as it offers a suggestion but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that it could be more novel and interesting if it included theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. This feedback is 3 as it points out a specific direction for enhancing the paper\"s contribution, but it lacks detailed guidance on how to conduct these analyses or experiments. The comment provides a clear suggestion for improvement but does not offer specific steps or examples, which could make it more actionable for the authors. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to provide a citation for the kmax problem, implying that it has been discussed elsewhere in the paper. However, it does not explicitly instruct the authors to include a citation or specify where the discussion can be found. The action is implicit, as the authors need to infer that they should add a citation, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment asks the authors to provide a citation for the kmax problem, implying that it has been discussed elsewhere in the paper. However, it does not specify which part of the paper or section contains the discussion, making it weakly grounded. The comment is specific in that it requests a citation, which is a clear and actionable request. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification or additional information regarding the kmax problem. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment is a question that prompts the authors to provide a citation for the kmax problem, suggesting that it has been discussed elsewhere in the paper. While it identifies a potential area for improvement by requesting a citation, it does not provide specific guidance on where to find the discussion or how to integrate the citation effectively. The feedback is 3 as it directs the authors to a specific area for improvement, but it lacks depth and actionable suggestions. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it points out a missing detail, it does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify or improve the explanation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the estimation process and the model\"s reliability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. While it does not contain a subjective claim or suggestion, it points out a missing detail that could be important for the authors to address. However, without additional context or explanation, the comment is 3 as it highlights a potential gap in the paper that needs clarification. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is clear and actionable, as it directs the authors to provide additional details or clarification regarding the estimation process and the model\"s reliability. By addressing this issue, the authors can improve the transparency and robustness of their methodology, making the paper more comprehensive and understandable. The comment is 4 as it provides a clear direction for improvement, though it could be more detailed by suggesting specific ways to enhance the explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also notes that the material supporting the main contributions, such as the deeprag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. While the comment explicitly mentions these issues, it does not provide specific guidance on how the authors should address them. The authors are left to infer that they need to clarify the forward referencing, provide more detailed explanations of the contributions in the introduction, and ensure that the supporting material is moved to the main sections. This lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. Additionally, it points out that the material supporting the main contributions, including the deeprag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, which is not properly explained, and that the contributions are unclear in the introduction. It also notes that the material supporting the main contributions, such as the deeprag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. The comment provides specific examples of issues, such as Figure 1 and the introduction, and suggests that the authors should clarify the forward referencing and provide more detailed explanations of the contributions. However, it lacks detailed reasoning or references to support these claims, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key issues with the paper: the lack of explanation for forward referencing and the unclear presentation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deeprag algorithm and discussion on high concurrency, is located in the appendix rather than the main sections. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the clarity and completeness of their paper. By highlighting these issues, the comment guides the authors to make necessary revisions, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the two test settings in visual dialog and the results presented in Table 1, which only shows the result for the discriminative setting. The reviewer questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This comment implies that the authors should provide results for the generative setting to address the gap in the evaluation. However, it does not explicitly instruct the authors to include the generative setting results or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the generative setting results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what is missing in the evaluation and what additional results are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the discriminative setting in realworld applications and requests the results for the generative setting. While the comment identifies a potential gap in the evaluation, it does not provide any specific reasoning or evidence to support why the discriminative setting might not be applicable or why the generative setting is important. The request for results is clear, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to realworld applications and asks for the results on the generative setting. This feedback is clear and actionable, as it directs the authors to provide additional results for the generative setting to address the gap in the evaluation. By highlighting this discrepancy, the comment helps the authors improve the comprehensiveness and relevance of their evaluation. However, it could be more helpful if it provided some guidance on how to conduct the generative setting evaluation or suggested specific metrics to consider. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what additional evidence or reasoning should be included, nor does it provide concrete guidance on how to achieve this. The comment is vague and lacks explicit instructions, making it difficult for the authors to understand what action to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is vague and lacks specificity, as it does not detail what evidence or reasoning should be included. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to address it. Without additional context or guidance, the claim remains vague and challenging to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specificity and does not offer detailed guidance or suggestions on how to achieve this. It is vague and does not provide actionable feedback, making it 2. The authors are left without a clear understanding of what additional information or reasoning is needed to strengthen their claims. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed approach, noting that its effectiveness is not known for other language families. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or demonstrate the effectiveness of their approach across different language families. Without specific suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed approach, noting that its effectiveness is unknown for other language families. However, it does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to understand where the issue lies and how to address it. Additionally, the comment does not provide specific guidance or suggestions for improvement, further limiting its usefulness. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach is unknown for other language families. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without any supporting information, the authors are left without a basis to understand or address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that the effectiveness of the proposed approach is unknown for other language families. This observation highlights a critical gap in the research, as it suggests that the findings may not be generalizable to other language families. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or explore the effectiveness of their approach across different language families. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it identifies a crucial weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not explicitly instruct the authors on how to improve the section or what specific aspects need to be addressed. The action is implicit, as the authors can infer that they need to expand on the descriptions of the differences between the related works. While the action is clear, it lacks concrete guidance on how to achieve this improvement, making it 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to improve the description of differences, but without explicit references to the section, the authors may find it challenging to pinpoint the exact area that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the improvement needed. Without detailed examples or references, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, noting that while some related works are named, their differences are not described in detail. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the related work section by elaborating on the distinctions between the cited works. However, the comment could be more helpful if it suggested specific ways to improve the descriptions or provided examples of how to differentiate the works. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the authors should clarify this point, but it does not provide specific guidance on how to do so. The comment is clear in identifying a gap in the explanation, but it lacks concrete instructions on how to address it. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. While the comment raises a valid point about the need for clarity in the explanation, it does not provide any specific examples, references, or detailed reasoning to support the claim. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it suggests an area for improvement but lacks sufficient evidence or guidance.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while the authors mention the importance of reliable PPP metrics for understanding PPP effects, they do not explicitly explain what kind of understanding one reaches by examining the PPP maps. This feedback is 3 as it highlights a specific area where the authors could improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided some guidance or examples on how to clarify this point. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with stateoftheart methods, such as SpanBERT, which could impact the credibility of the authors\" work. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons they should include. The action is implicit, as the authors need to infer that they should compare their methods with stateoftheart approaches to strengthen their credibility. While the action is somewhat vague, it is clear that the authors need to make comparisons to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods, such as SpanBERT, which is a specific aspect of the paper. It clearly specifies what needs to be addressed, namely the absence of such comparisons, which is crucial for credibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which could impact the credibility of their work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is 3, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of comparison with stateoftheart methods, specifically mentioning SpanBERT. This is a crucial oversight as it affects the credibility and impact of the authors\" work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as which additional methods to compare with or how to strengthen their evaluation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a critical gap but does not offer detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the lack of detailed explanation of the forwardprediction model and the poor schematic representation in Figure 2(b). It suggests that the figure should be redrawn and that the connection between the text, figure, and equations is unclear. While the comment provides explicit actions\u2014implying that the authors should improve the explanation, redraw the figure, and clarify the connection\u2014it does not offer concrete guidance on how to achieve these improvements. The actions are somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the forwardprediction model, including the lack of detailed explanation, the poor schematic representation in the figure, and the difficulty in connecting the text, figure, and equations. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, and Figure 2(b) does not accurately represent the schematic of the model. It also notes that the connection between the text, figure, and equations is unclear. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The authors are left to infer the nature of the issues, which could make it challenging to address them effectively. Therefore, the comment is rated as 2, as it provides some basis for the claim but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that needs improvement, namely the explanation of the forwardprediction model. It points out that the details are not well explained and that Figure 2(b) does not accurately represent the schematic of the model. Additionally, it notes that the connection between the text, figure, and equations is unclear, making it difficult for the authors to understand the model. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to improve the explanation or the figure. This feedback is 3 as it directs the authors to areas that require attention, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The suggestion to provide a stronger baseline is vague and lacks concrete details on how to implement it. Therefore, the comment is not actionable, as it does not offer clear and specific instructions for the authors to follow. This aligns with a score of 1.", "grounding_specificity_rationale": "The comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. However, the comment does not specify which part of the paper discusses the training data or the tasks, making it difficult for the authors to pinpoint the exact issue. While the comment identifies a potential issue, it lacks specificity in detailing what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment lacks specific examples or references to support the claim that such supervision is ignored. It does not provide detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments or analyses could be conducted to strengthen their claims. While it identifies a potential weakness, it lacks actionable advice or detailed recommendations, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to clarify the statement. The action is implicit, as the authors would need to infer that they should revise the statement to accurately reflect the operation of the RNNs. The comment is vague in terms of how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides a specific critique about the logical time scale, it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer provides a logical argument explaining why this distinction is important and how it affects the understanding of the model. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. This observation is insightful and could help the authors clarify their explanation of the model\"s operation. However, the comment does not provide specific guidance on how the authors might address this issue or what changes could be made to improve the clarity of the statement. While it offers a valuable point for consideration, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the baseline methods used in the paper are weak and do not represent stateoftheart approaches. It also notes the absence of a discussion on limitations. Additionally, the reviewer suggests that the conclusion could include a discussion of the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors need to infer how to improve their draft based on the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of weak baseline methods and the lack of discussion on limitations, suggesting that the authors should include a comparison with stateoftheart methods and discuss the generalizability of their results to reinforcement learning settings. However, the comment does not specify which parts of the paper should be revised or how the authors should address these issues. The authors may infer that the feedback pertains to the introduction, methodology, or conclusion sections, but this is not explicitly stated. The comment is specific in its suggestions but lacks grounding as it does not pinpoint the exact sections or parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and do not represent stateoftheart approaches, and that there is no discussion of limitations. It also suggests that the conclusion could include a discussion of the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. The feedback is 3 as it provides a general direction for improvement but lacks detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the baseline methods are weak and do not represent stateoftheart approaches. It also notes the absence of a discussion on limitations, which is a crucial aspect for a comprehensive evaluation of the work. The comment suggests that the conclusion could be enhanced by discussing the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. While the feedback provides a clear direction for improvement, it lacks specific guidance on how to address these issues or what actions the authors should take. The comment is 4 as it highlights important areas for improvement but could be more comprehensive with detailed suggestions or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also suggests that the performance of the proposed approaches may be weak due to this dependence. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the clarity or robustness of their results. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know exactly how to respond. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also suggests that the performance of the proposed approaches may be weak due to this dependence. However, the comment does not explicitly mention specific sections, tables, or figures that need attention, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact parts of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches due to this dependence. The comment provides some logical reasoning by explaining the implications of the exponential dependence on the constant factor of the required feature size and the performance of the proposed approaches. However, it lacks specific examples or references to support these claims, making the verifiability somewhat limited. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also suggests that the performance of the proposed approaches may be weak due to this dependence. While the comment provides some insight into potential weaknesses, it lacks detailed guidance on how the authors might address these issues or what specific improvements could be made. The feedback is 3 as it highlights areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s explanation of the poor longrange modelling ability of DGNs, suggesting that oversmoothing could also be a contributing factor. However, it does not provide explicit guidance on how the authors should address this issue or incorporate the additional explanation. The comment implies that the authors should consider discussing oversmoothing, but it lacks concrete steps or suggestions on how to do so. As a result, the authors are left without a clear action to take, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the poor longrange modelling ability of DGNs and suggests that oversmoothing could also be a contributing factor, referencing a specific paper. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue and suggesting an additional explanation, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs could be due to oversmoothing, in addition to oversquashing and vanishing/exploding gradients, referencing a specific paper. This claim is 3 as it provides a reference to support the suggestion of oversmoothing as a contributing factor. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s explanation of the poor longrange modelling ability of DGNs, suggesting that oversmoothing could also be a contributing factor. It references a specific paper to support the claim, which could help the authors address this issue more comprehensively. However, the comment could be more helpful if it provided additional guidance on how to incorporate this explanation into the paper or suggested specific sections where this discussion should be included. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit actions or concrete details on how to improve the clarity of the problem formulation. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is unclear, making it difficult for the authors to identify the exact section that needs improvement. It is also not specific because it does not provide details on what aspects of the problem formulation are unclear. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors cannot determine the exact nature of the unclear problem formulation, making the claim 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the problem formulation in the introduction and statement examples. However, it lacks specific details or suggestions on how the authors might address this issue. Without actionable guidance or examples, the authors may find it challenging to improve the clarity of their problem formulation. Therefore, the comment is 2, as it provides a general observation but no concrete feedback to enhance the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and explicit action for the authors to take, as they can directly implement the suggestion by adding experiments with these models. The comment is specific in its recommendation, detailing which models should be used and how this would enhance the paper\"s applicability and generalizability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental section. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks experiments on different LLM families and suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the paper lacks these experiments or how the suggested trials would enhance its applicability. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly points out a specific area for improvement and provides concrete examples of models that could be used to enhance the paper\"s comprehensiveness. By addressing this suggestion, the authors can strengthen the paper\"s impact and demonstrate the robustness of their method. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer suggests that the current presentation does not clearly explain how these two parts are related, which could make it difficult for readers to understand the overall narrative. However, the comment does not provide specific guidance on how the authors should improve the connection between the two parts. It lacks concrete suggestions or actionable steps that the authors can take to address this issue. As a result, the comment is not actionable, as the authors are left without clear directions on how to improve their draft. Therefore, this comment aligns with a score of 1.", "grounding_specificity_rationale": "The comment expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. However, it does not specify which part of the paper this concern is related to, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in its critique of the connection between the two parts, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the discrepancy between the initial understanding of the first part and the actual content, suggesting that the connection is not as clear as it could be. However, the comment lacks specific examples or references to support the claim that the connection is weak. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out a lack of clear connection between the first part, which discusses curve finding, and the second part, which focuses on FGE. The reviewer highlights a discrepancy in the reviewer\"s initial understanding of the first part and the actual content, suggesting that the connection between the two parts is weak. However, the comment does not provide specific suggestions or guidance on how the authors might improve the connection between these parts. While it raises a valid concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the performance of learningbased and heuristicbased solvers, noting that heuristicbased solvers, specifically the SOTA heuristicsolver (e.g., Concorde), usually perform better for singleobjective TSP. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This provides a clear and explicit action for the authors to take, which is to include the results for linear scalarization + Concorde in their analysis. The action is concrete, as it specifies exactly what needs to be done to improve the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"competitive baselines\" and \"heuristicbased solvers,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the performance of the SOTA heuristicsolver (e.g., Concorde) for singleobjective TSP and suggests including results for linear scalarization + Concorde for a better comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are much better than the heuristicbased solvers according to the experimental results. However, it highlights that for singleobjective TSP, the SOTA heuristicsolver (e.g., Concorde) usually performs better. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This claim is 3 as it provides a logical reasoning for why the inclusion of linear scalarization + Concorde is necessary for a comprehensive comparison. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers, but it highlights a potential gap in the comparison by suggesting the inclusion of results for linear scalarization with the SOTA heuristicsolver (e.g., Concorde). This feedback is actionable and provides a clear direction for the authors to improve their analysis by including additional comparisons. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their experimental evaluation. Therefore, the comment is 4, as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use longterm storage through pose graphs in SLAM, like those discussed in the appendix. However, the comment does not provide explicit guidance on how to incorporate or discuss these methods, nor does it specify which aspects of the proposed method should be compared or contrasted with these existing approaches. The action is implicit and vague, as the authors are left to infer how to apply the suggested discussion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"general ideas\" and provides specific examples of existing methods, such as those using generalized Voronoi graphs or semantic maps, and those related to longterm storage through pose graphs in SLAM. It also references the appendix section where these methods are discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed by discussing the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some general ideas in the proposed method are already present in other methods, such as those using topological reasoning with generalized Voronoi graphs or semantic maps, and those related to longterm storage through pose graphs in SLAM. The comment provides specific examples of these methods, such as those discussed in the appendix section, which supports the claim. However, the reasoning could be more detailed, and the claim could be strengthened with additional examples or references to specific aspects of the proposed method. Overall, the claim is 4, as it is supported by logical reasoning and specific examples, but it could benefit from more comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use longterm storage through pose graphs in SLAM. This feedback is 3 as it provides a clear direction for the authors to consider, but it lacks depth and specificity. The comment does not offer detailed guidance on how to incorporate or discuss these methods, nor does it specify which aspects of the proposed method should be compared or contrasted with the existing approaches. While it highlights an important aspect of the paper, the feedback could be more comprehensive and actionable to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific advice or suggestions, the authors are left without a clear path to respond to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is vague and lacks specificity, as it does not provide any guidance or suggestions on how to address the question or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. However, it does not provide any claim, suggestion, or reasoning to support the question or why it is important. The comment lacks any evidence or justification, making it difficult for the authors to understand the basis of the question or how it relates to the paper. Therefore, the comment is classified as \"1\" as it does not provide any verifiable information or reasoning.", "helpfulness_rationale": "The review comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. This question highlights a potential area for improvement in the paper, as it suggests that the authors might have overlooked a more detailed approach to quantization. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve their draft. Without specific advice or recommendations, the authors are left without actionable feedback, making the comment 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should study the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by conducting additional experiments or analyses. The comment is specific in its request for further investigation, making it 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes, specifically mentioning how performance varies with different ratios of unlabeled examples. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes it weakly grounded, as the authors may need to infer which part of the paper is being addressed. The comment is specific in its suggestion to study the impact of the ratio of unseen classes, providing clear guidance on what needs to be done. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This is a suggestion for further investigation and analysis, which is a subjective opinion or judgment. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would impact the paper. Without additional context or justification, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This feedback is clear and actionable, as it provides a specific direction for the authors to take in their research. By focusing on the impact of the ratio of unseen classes, the authors can gain a deeper understanding of their model\"s performance and potentially improve its robustness. The suggestion is welldefined and offers a concrete path for further investigation, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part. It asks whether the combination of these two architectures is a reason for the improvements observed. However, the comment does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. It lacks guidance on how the authors might address this concern or what changes they should consider. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address the question or improve the combination of architectures. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or explanation, making it difficult for the authors to understand the basis of the question or how it relates to the paper. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, which is a valid concern for the authors. However, the comment does not provide any specific suggestions or guidance on how the authors might address this question or improve their approach. It lacks depth and actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer substantial assistance in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. It also points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The comment suggests that the authors might be underestimating the use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies a gap in the paper\"s discussion and suggests an area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out areas for improvement but lacks detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the lack of mention of the theory\"s inapplicability to the used model and the vagueness of \"structural assumptions.\" This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section, which is a valid observation. It also highlights the vagueness of \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The comment suggests that the authors might be underestimating the use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to provide more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. This oversight is a critical oversight that needs to be addressed to provide a complete and accurate picture of the paper\"s scope and applicability. Additionally, the comment highlights the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The reviewer also suggests that the authors might be underestimating the use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. This feedback is 4 as it provides clear areas for improvement and actionable suggestions, guiding the authors to enhance the completeness and depth of their paper. However, it could be more helpful if it included specific examples or detailed guidance on how to address these issues."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilongreedy exploration in addition to their proposed strategy. However, the comment does not provide explicit guidance on how the authors should clarify this point or address the potential use of epsilongreedy exploration. The action is implicit, as the authors need to infer that they should clarify the meaning of \"epsilongreedy\" and consider its implications for their strategy. The action is vague because it does not specify how to clarify the meaning or what aspects of the strategy need to be addressed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Just before Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilongreedy\" in the context of the training process and suggests that the authors might be using epsilongreedy exploration in addition to their proposed strategy. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of the training process described in Appendix D.2. It does not contain a subjective claim or suggestion but rather asks for clarification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of the training process described in Appendix D.2. It suggests that the authors might be using epsilongreedy exploration in addition to their proposed strategy. However, the comment does not provide any guidance or suggestions on how the authors should clarify this point or address the potential use of epsilongreedy exploration. While it identifies an area that needs clarification, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide explicit guidance on which parts are vital or how to address the issue. The comment implies that the authors should clarify the discussion, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment also suggests that the discussion is necessary but does not provide specific guidance on what needs to be discussed or how to distinguish the paper from related work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the discussion is necessary. Therefore, the claim is considered 2, as it provides some context but lacks sufficient justification or examples to fully support the argument.", "helpfulness_rationale": "The review comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific guidance or examples to help the authors address this issue. While the comment identifies a potential area for improvement, it lacks depth and actionable suggestions, making it 3. The authors would benefit from additional guidance on how to clarify the discussion and distinguish their work from related studies. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bitserial accelerators. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The comment implies that the authors should consider the limitations of their approach in the context of existing ML accelerators that use bitparallel fixedpoint numbers. While the authors can infer that they need to discuss the implications of their methodology in this context, the lack of concrete suggestions or guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the applicability of dynamic precision control during training, specifically mentioning bitserial accelerators and the limitations of existing ML accelerators that use bitparallel fixedpoint numbers. However, it does not explicitly mention specific sections, tables, or figures of the paper that discuss these aspects. The authors can infer that the comment relates to the methodology or experimental setup, but without explicit references, the grounding is weak. The comment is specific in detailing the issue with dynamic precision control and its implications for existing accelerators, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bitserial accelerators. It then suggests that most existing ML accelerators use bitparallel fixedpoint numbers, which might restrict the implications of the proposed methodology. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence or examples weakens the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bitserial accelerators. It then suggests that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. This feedback highlights a potential limitation or area for further exploration, providing the authors with a clear direction for consideration. However, the comment could be more helpful if it offered suggestions on how to address this issue or how to expand the methodology to accommodate bitparallel accelerators. Overall, the comment is 3 as it identifies a relevant concern but lacks depth in addressing potential solutions or alternative approaches. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples and comparisons to support the claim that the analysis of vit quantification could be explained in depth. It highlights discrepancies in the variance difference between the proposed approach and the baseline, and mentions that the quantization of MHSA introduces a large loss of precision, a finding already established in other models. However, the comment does not explicitly instruct the authors to provide a detailed explanation of the vit quantification analysis or to address the discrepancies and loss of precision. While the authors can infer that they need to expand on the analysis, the action is somewhat vague and lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as Line 45 and Figures 1(b) and 5(b), allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the analysis of vit quantification, including the discrepancies in variance and the loss of precision in MHSA quantization. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, providing specific examples and comparisons to support this claim. It highlights discrepancies in variance differences between the proposed approach and the baseline, as well as the loss of precision in MHSA quantization, referencing findings in other models. The claim is supported by detailed reasoning and examples, making it 4. However, it could be strengthened by including more explicit references or detailed explanations of the comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed analysis of the paper\"s claims regarding vit quantification, offering specific examples and comparisons to support the argument that the analysis could be explained in depth. It highlights discrepancies in variance differences between the proposed approach and the baseline, as well as the loss of precision in MHSA quantization, referencing findings in other models. This feedback is 4 as it identifies areas where the paper could be improved by providing a more comprehensive explanation of the vit quantification analysis. However, it could be more helpful if it included suggestions for how to address these issues or provide additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It points out that the proposed Xtransformation is similar to STN, applied locally, and notes that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions that there are no empirical or conceptual comparisons to STN, which is a significant gap. While the comment identifies a key issue and suggests that the authors should address the similarity and lack of comparison to STN, it does not provide explicit guidance on how to improve the draft or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should compare their work to STN and include empirical or conceptual comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It highlights the similarity between the proposed Xtransformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also points out the absence of empirical or conceptual comparisons to STN, which is a significant gap. However, the comment does not specify which part of the paper discusses the technical novelty or the comparison to STN, making it weakly grounded. The specificity of the comment is high as it clearly identifies the issue and suggests improvements, such as including comparisons to STN. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and that there are no empirical or conceptual comparisons to STN. The comment provides examples of existing works that have applied STN in local pixel neighborhoods, such as PointNet, which supports the claim about the limited novelty. However, the comment does not offer specific examples or detailed reasoning to fully substantiate the claim about the missing comparisons. While the reasoning is somewhat clear, the lack of detailed examples or references makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN). It highlights the similarity between the proposed Xtransformation and existing STN applications, noting that other works have explored applying STN in local pixel neighborhoods. The comment also points out the absence of empirical or conceptual comparisons to STN, which is a critical gap in the paper. While the comment provides a clear critique of the work\"s novelty, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors to consider the limitations of their approach and the need for comparisons to existing work, but it could be more actionable with additional guidance on how to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to attach proofs to theorems and corollaries in the main paper to improve readability. However, the comment does not explicitly instruct the authors to correct the figure reference or to implement the suggestion about proof links. While the actions are implied, they are vague and lack concrete details on how to execute them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure reference, suggesting that \"Fig.7\" should be \"Fig.12.\" Additionally, the comment provides a clear suggestion to attach proofs to theorems and corollaries in the main paper, enhancing the paper\"s readability. However, the comment lacks specificity in terms of what aspects of the methodology or experiments need to be improved to address the concerns about motivation, methodology soundness, and experiment persuasion. While the authors can infer that these concerns relate to the content of the paper, the comment does not provide detailed guidance on how to address them. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point contains a claim that the paper is \"qualified,\" \"clear,\" and \"convincing,\" which are subjective opinions. It also suggests that the paper has good novelty, clear theoretical guarantees, and convincing empirical results. However, the comment lacks specific evidence or reasoning to support these claims, making it difficult for the authors to understand the basis of the positive feedback. The absence of detailed justification or examples makes the claim 3, as it relies on subjective interpretation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to attach proofs to theorems and corollaries in the main paper to improve readability. However, the comment lacks depth and does not address the primary concerns mentioned, such as motivation, methodology soundness, and experiment persuasion. While it offers some actionable feedback, the lack of comprehensive guidance limits its helpfulness. Therefore, the comment is 3, as it provides some insights but does not fully address the authors\" needs for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, it does not provide explicit guidance on how to implement this improvement or what specific aspects of the feature selection should be considered. The action is implicit and vague, as it leaves the authors to infer the necessary steps to enhance their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed invariant learning module in Section 4.2, specifically mentioning mask selection and rawlevel features. It also refers to the discussion of representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. However, the comment does not specify which part of Section 4.2 is being discussed, making it weakly grounded. It is specific in suggesting that the feature selection could be improved by considering representation learning, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why considering representation learning would enhance the feature selection process or how it could be integrated into the existing framework. Without additional context or evidence, the claim remains 3, as it lacks the necessary depth and specificity to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the feature selection presented in Section 4.2 could be further enhanced by considering representation learning, which is discussed in the appendix. This feedback is 3 as it points out a specific aspect that could be improved, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of the feature selection should be considered. The comment provides a clear direction for improvement but does not offer a comprehensive or actionable plan, leaving the authors with a general idea of what to work on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on what specific details are missing or how the authors should clarify the design of rewards. Without concrete suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper is missing details or lacks understanding regarding the design of rewards. However, it is specific in identifying the issue of missing details and the lack of understanding about the reward design. This allows the authors to infer that the feedback pertains to a specific section or part of the paper where these details are discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details or how to address them. Without additional context or evidence, the claim remains vague and challenging to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, noting that some details are missing and that the design of rewards is not fully understandable. This feedback is clear and actionable, as it points out a specific area where the authors need to provide more information or clarification. By highlighting this issue, the comment guides the authors to improve the completeness and clarity of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the missing details or design the rewards. Overall, the comment is 3 as it identifies a clear area for improvement, but it lacks depth in terms of actionable suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the incremental improvement to the KNN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors\" execution is replicable and beats the idea in terms of novelty. However, the comment does not provide explicit guidance on how to address this issue or improve the novelty of the approach. The authors are left without a clear path to enhance their work, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the incremental improvement to the KNN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors\" execution is replicable and beats the idea in terms of novelty. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to understand where to address the issue. Additionally, the comment is somewhat specific in that it highlights the tradeoff between execution and novelty, but without clear references, it remains challenging to apply. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the novelty of the incremental improvement to the KNN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. The comment acknowledges that the authors\" execution is replicable and beats the idea in terms of novelty, but it does not provide specific examples or references to support this claim. This lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the novelty of the incremental improvement to the KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors\" execution is replicable and beats the idea in terms of novelty. However, the comment does not provide specific suggestions or guidance on how to enhance the novelty of the approach or address the concerns raised. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would benefit from additional feedback that offers concrete suggestions for improvement, such as exploring alternative approaches or providing a more detailed analysis of the novelty of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the computational efficiency of the Prithvi WxC model, suggesting that its runtime should be discussed as a limitation. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the draft. The comment implies that the authors should consider discussing the runtime, but it lacks concrete instructions or suggestions on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the computational efficiency of the Prithvi WxC model, specifically mentioning its large parameter count and suggesting that its runtime should be discussed as a limitation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to discuss the runtime, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the computational efficiency of the Prithvi WxC model should be discussed, given its large parameter count. However, the comment does not provide specific evidence, examples, or references to support this claim. It lacks detailed reasoning or justification for why discussing the runtime is important. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the computational efficiency of the Prithvi WxC model, specifically mentioning its large parameter count. It suggests that the runtime of the model should be discussed as a limitation for applications involving climate model parametrizations. While the comment highlights a relevant aspect of the model\"s performance, it does not provide specific guidance on how to address this issue or what actions the authors should take to improve their draft. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what changes could be made to the framing or how the contribution could be clarified. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper is being referred to, leaving the authors uncertain about the exact section or aspect that needs attention. The comment is vague and does not provide specific guidance on how to address the overselling or clarify the contribution. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the framing of the paper, suggesting that it oversells the method and makes the contribution less clear. However, the comment lacks specific details or actionable suggestions on how the authors might address this concern. Without further guidance or examples, the authors may find it difficult to understand the nature of the overselling or how to improve the clarity of their contribution. Therefore, the comment is 2, as it provides a general observation but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps, which would enhance understanding. It also notes that the use of many symbols and a notation table could be better. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific steps or examples. The action is implicit and somewhat vague, as the authors are left to infer how to improve the model description. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning that presenting the generative process in separate steps would enhance understanding. It also notes that the use of many symbols and a notation table could be better. However, the comment does not specify which part of the paper the model description is located in, making it weakly grounded. The comment is specific in its suggestions for improvement, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps to enhance understanding and by using fewer symbols and a notation table. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The feedback lacks depth and clarity, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies areas for improvement in the model description, specifically suggesting that presenting the generative process in separate steps could enhance understanding. It also notes that the use of many symbols and a notation table could be better. While the comment provides some actionable feedback, it lacks depth and specificity, as it does not offer detailed guidance on how to implement these suggestions or provide examples of how the model description could be improved. The feedback is 3, as it points out areas for enhancement, but it could be more comprehensive and detailed to fully assist the authors in improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the FlippedQA framework, which is described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take to address it. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not specify which part of the paper discusses the FlippedQA framework or the models it is applied to. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its suggestion to verify the framework\"s effectiveness and universality, the absence of explicit grounding makes it challenging for the authors to understand where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by suggesting that the FlippedQA framework, described as general for various generative VideoQA models, is only applied to LLMbased models. It recommends further verification of the framework\"s effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. This feedback is 3 as it points out a specific area for improvement and suggests a direction for further exploration. However, the comment lacks detailed guidance on how to conduct this verification or what specific aspects of the framework should be examined. The suggestion is clear but could be more actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, indicating that the writing could be improved. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the writing or what aspects need clarification. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment expresses the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment is somewhat specific in that it highlights the difficulty in understanding the main idea and theoretical analysis, but without further guidance on what aspects need clarification, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point expresses the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or suggestions, the claim is not 5, as it does not provide a clear basis for improvement. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it lacks specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not provide actionable advice or examples of how to enhance the clarity or coherence of the paper. As a result, the comment is 3, as it highlights a weakness but does not offer comprehensive feedback to guide the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and does not present significant theoretical novelty. The comment also expresses a willingness to improve the score if the authors address these concerns. However, it does not provide specific guidance on how to address these concerns or what aspects of the method need to be improved to enhance its theoretical novelty. The action is implicit and vague, as the authors are left to infer how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific methods it builds upon, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the proposed method, noting that it lacks significant theoretical novelty. The authors are informed about the specific methods and the concern about novelty, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and does not present significant theoretical novelty. The comment provides specific references to these methods, which are wellknown and established in the field. However, it does not offer additional reasoning or examples to fully support the claim that the method lacks theoretical novelty. While the references provide some context, the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key weakness in the proposed method, noting that it primarily builds upon existing methods without presenting significant theoretical novelty. This feedback is valuable as it highlights an area where the authors could enhance their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing new theoretical frameworks or methods. While it provides a clear direction for improvement, the absence of detailed advice limits its helpfulness. Therefore, the comment is 3, as it offers a clear insight but could be more comprehensive with actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide specific guidance on how to make the sentence clearer or what aspects of the sentence need improvement. The authors are left with an implicit action to revise the sentence, but without concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to make the sentence in lines 1217 clearer. This feedback is actionable and provides a clear direction for improvement, making it a 5 comment.", "verifiability_rationale": "The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the sentence is cumbersome or how to make it clearer. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that the sentence describing the number of questions is cumbersome and could be clearer. This feedback is actionable as it provides a clear suggestion for improvement, guiding the authors to refine the sentence for better readability. However, the comment could be more helpful if it offered additional guidance on how to make the sentence clearer, such as suggesting specific ways to rephrase it or provide more context. Overall, the comment is 4 as it highlights an area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, as shown in \"3)\". It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that similar tradeoffs could be explored by changing hyperparameters in Decouple Kang et al.. The comment encourages the authors to continue this line of work for future submission. However, the comment does not provide specific guidance on how to address these issues or what changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the performance comparison with Decouple Kang et al. and the tradeoff between head and tail categories. The comment suggests that the baselines should be investigated further, which provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, as shown in \"3)\". It also notes that Table 5 demonstrates a tradeoff between head and tail categories but does not fully investigate this tradeoff for the baselines. The reviewer suggests that by changing hyperparameters in Decouple Kang et al., the tradeoff could be improved. This claim is 3 as it provides a logical reasoning for the observation but lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, as shown in \"3)\". It also notes that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that similar tradeoffs could be explored by changing hyperparameters in Decouple Kang et al.. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, the comment could be more helpful if it offered more detailed guidance on how to address these issues or suggested specific experiments to conduct. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is limited, primarily relying on 4 OCR QA datasets. It acknowledges that this evaluation may be unreliable, as the authors themselves admit in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. However, the comment does not provide explicit guidance on how the authors should incorporate these additional scenarios or how to conduct the ablation studies. While the action is implied, it is vague and lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation, noting that it is limited to 4 OCR QA datasets and that the authors themselves acknowledge this limitation. The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. This provides clear guidance on what additional scenarios should be included. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, primarily relying on 4 OCR QA datasets, and that this evaluation may be unreliable, as acknowledged in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. However, the comment lacks specific examples or detailed reasoning to support the claim that the evaluation is unreliable or why the LLaVA benchmark would be more appropriate. Without concrete evidence or references, the claim is 3, as it provides a basis for improvement but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the paper, noting that it primarily relies on 4 OCR QA datasets. The authors themselves acknowledge this limitation in Figure 4(5), suggesting that the evaluation may be unreliable. The comment proposes that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. This feedback is 3 as it highlights a specific area for improvement and suggests additional scenarios that could strengthen the evaluation. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these additional scenarios or how to conduct the ablation studies. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to the tasks. The feedback lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not specify which part of the paper discusses these tasks, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the tasks, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not provide specific examples, reasoning, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice, which provides a clear area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or what changes could be made to the tasks. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly instruct the authors to address these issues or provide guidance on how to improve the realism of their evaluations. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluation of weak supervision, specifically mentioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The specificity is high as it clearly specifies what needs to be addressed in the evaluation of weak supervision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be better evaluated by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is 3 as it provides some justification but lacks depth and specific examples to guide the authors in improving their evaluation process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic nature of the author embeddings. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the realism of the evaluation. While it points out a valid concern, it does not offer actionable steps or insights that would help the authors enhance their work. Therefore, the comment is 3, as it highlights an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of visualization in the paper, specifically mentioning the absence of intermediate processes and comparisons. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. The comment lacks concrete guidance on what kind of visualizations would be beneficial or how to incorporate them into the draft. Without specific advice on what to visualize or how to compare, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which sections or figures are missing these visualizations. This lack of grounding makes it difficult for the authors to address the issue effectively. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons in the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific areas where visualization is lacking. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance the visual representation of their work. However, the comment could be more helpful if it provided suggestions on what kind of visualizations would be beneficial or how to effectively compare the intermediate processes. Despite this, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment implies that the authors should investigate the nature of these relations and consider whether they align with standard discourse relations in other languages. While the action is somewhat inferred, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by questioning the presence of a large number of dobj relations and asking whether this might be an artifact of colloquial language or a specific choice in the UD dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation, making the comment 1.", "helpfulness_rationale": "The review comment raises a question about the presence of a large number of dobj relations in Table A2, specifically questioning whether this might be an artifact of colloquial language or a specific choice in the UD dataset. While the comment identifies a potential issue with the data representation, it does not provide any suggestions or guidance on how the authors might address this concern. The feedback is 3 as it highlights a potential area for further investigation, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, it aligns with a score of 3, as it offers some clarity but could be more comprehensive and helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the output quality of the paper is reasonable but still far from realistic, citing recent GAN works that achieve highquality synthesized results. It implies that there is room for improvement in the result quality. However, the comment does not provide specific guidance on how to improve the output quality or what aspects of the paper need to be addressed to achieve higher quality results. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know exactly what steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"output quality\" and \"synthesized results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the output quality is \"reasonable but still far from realistic\" and suggests that recent GAN works have shown \"amazing quality.\" The comment is specific in its critique of the output quality and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, citing recent GAN works that achieve highquality synthesized results. This claim is 3 as it provides a general reference to recent advancements in GANs, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The comment suggests that there is room for improvement in the result quality, but it does not offer detailed guidance or evidence to support this assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved highquality synthesized results, suggesting that there is room for improvement in the paper\"s output quality. The comment also mentions the limited novelty, low resolution output, and high hardware requirements, which could impact the paper\"s acceptance. While the comment provides a clear critique of the output quality and highlights areas for improvement, it lacks specific suggestions or actionable steps for the authors to address these issues. The feedback is 3 as it points out the need for improvement but does not offer detailed guidance on how to achieve it. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of subpar hyperparameters, similar to those used in other works, which could affect the validity of the results. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their hyperparameters. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the use of subpar hyperparameters, similar to those used in other works, which could affect the validity of the results. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is vague and lacks specificity, as it does not provide detailed guidance on how the authors should address this concern. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the use of subpar hyperparameters, similar to those used in other works, which could affect the validity of the results. However, the comment does not provide specific examples or references to support the claim that the hyperparameters are subpar or how they might impact the results. Without detailed justification or evidence, the claim remains 3, as it lacks sufficient support to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the use of subpar hyperparameters, similar to those used in other works, which could affect the validity of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes they should make to their hyperparameters. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors are left with a general concern but without clear direction on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While it identifies a potential issue with the dataset size, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the dataset or the approach. The comment lacks concrete suggestions or detailed instructions on how to enhance the dataset or the validity of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifically mentioning the number of images in each category. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in questioning the sufficiency of the dataset size to validate the approach, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the number of images in the VioT dataset to validate the approach. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the study, specifically questioning the sufficiency of the number of images in each category to validate the approach. This feedback highlights a critical aspect of the research that needs further consideration. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address this concern or improve the dataset. While it points out a potential weakness, it does not provide specific steps or recommendations for the authors to take, which limits its helpfulness. Therefore, the comment is 3, as it identifies an important area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, it does not provide explicit guidance on how to conduct this study or what specific aspects of performance should be analyzed. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply this suggestion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests an ablation study on the number of layers versus performance, which is a specific and actionable suggestion. However, it does not specify which part of the paper this study should be conducted in or how it relates to the overall content. The authors can infer that it might be relevant to the sections discussing model architecture or performance evaluation, but the lack of explicit mention makes it weakly grounded. The comment is specific in its suggestion but lacks grounding, making it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, it does not provide any specific reasoning, examples, or references to support why this study would be beneficial or how it could be conducted. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an ablation study on the number of layers versus performance, which is an interesting idea that could provide valuable insights into the model\"s architecture and performance. However, the comment lacks specific guidance on how to conduct this study or what aspects of performance should be analyzed. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a potential direction for the authors to explore but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including its difficulty to follow, the need for more intuitive explanations of mathematical derivations, and the lack of detailed explanations for figure captions. It suggests that the authors should provide additional explanations and legends for figures, such as explaining the colors in Fig. 2. However, the comment does not explicitly instruct the authors to add these explanations or legends, nor does it provide specific guidance on how to improve the clarity of the figures. While the authors can infer that they need to address these issues, the lack of concrete instructions makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s difficulty to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not explicitly mention specific sections, tables, or figures, making it weakly grounded. It is specific in detailing what needs to be addressed, such as intuitive explanations and detailed figure captions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leading to a score of 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically noting that it is hard to follow and lacking in intuitive explanations for mathematical derivations. It also points out the absence of detailed explanations for figure captions, such as the need to explain the colors in Fig. 2. The comment suggests that these issues hinder the reader\"s understanding, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve the clarity and accessibility of the mathematical derivations and figure captions. Without concrete guidance, the authors may struggle to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a critical concern about the sensitivity of the empirical results to hyperparameter choices. It highlights the importance of this issue, noting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this concern, such as conducting additional experiments or providing a detailed analysis of the impact of different hyperparameter settings. The action is implicit, as the authors are left to infer that they need to investigate the robustness of their results to hyperparameter variations. While the comment is 3, it lacks concrete details on how to implement the suggested action, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a crucial issue. However, it does not specify which part of the paper this concern pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its focus on hyperparameter sensitivity, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, suggesting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, noting that incorrect choices could potentially negate the benefits of the method. This is a significant issue that needs to be addressed to ensure the robustness and reliability of the findings. However, the comment lacks specific guidance or suggestions on how the authors might investigate or mitigate this issue. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable nature, as it does not provide detailed steps or recommendations for addressing the concern. Therefore, the comment is 3, as it identifies a crucial weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, given that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their method need to be highlighted to demonstrate its novelty and contribution. The action is implicit and vague, as it leaves the authors without a clear understanding of how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, given that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. However, the comment does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to understand where to address the issue. While the comment is specific in its suggestion to claim novelty and contribution, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. This claim is 3 as it highlights a potential issue with the novelty of the proposed method. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to provide more context or evidence to fully understand the basis of this critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, noting that it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. This feedback is 3 as it points out a need for the authors to further claim the novelty and contribution of their method. However, the comment lacks specific guidance on how the authors might address this issue or what aspects of their method need to be highlighted to demonstrate its novelty. The feedback is incomplete and could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not provide any explicit or implicit suggestions on how to address these issues. The comment lacks concrete guidance on how the authors might improve the readability of the text in Table 1 or how to correct the missing gradient symbol in Algorithm 1. Without specific actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses issues with the readability of text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment does not provide specific guidance on how to improve the readability of the text or correct the missing gradient symbol. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two claims: that the text in Table 1 is too small and hard to read, and that the gradient symbol is missing in Algorithm 1. The first claim is 3 as it highlights a potential issue with readability, but it lacks specific examples or references to support the claim. The second claim is also 3 as it points out a missing element in the algorithm, but it does not provide detailed reasoning or examples to substantiate the claim. Overall, the comment is 3, as it identifies potential issues but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. While it points out these weaknesses, it does not provide any suggestions or guidance on how the authors might address these issues. The feedback is clear and identifies areas for improvement, but it lacks actionable advice, making it 3. The authors are aware of the issues but are left without a clear path to resolve them. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the discussion of computational aspects, noting that the authors do not provide a detailed analysis of how their proposed methods can be practically useful for highdimensional data. It also points out that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for their experiments being conducted on smallscale datasets, which does not align with the practical applicability of the methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer how to improve the discussion and experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and highlights the challenges associated with solving LPs in such settings. It also points out that the experiments are performed on smallscale datasets, which does not align with the practical applicability of the methods. However, the comment does not specify which part of the paper discusses computational aspects or which sections are relevant to the issue of highdimensional data. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss computational aspects, particularly in high dimensions, and that their algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for conducting experiments on smallscale datasets, which does not align with the practical applicability of the methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a gap in the discussion of computational aspects, particularly in high dimensions, and highlights the challenges associated with solving linear programs (LPs) in such settings. It points out that the algorithm requires solving several LPs in high dimensions, where a key parameter is not easily calculable, and notes that the experiments are conducted on smallscale datasets, which does not align with the practical applicability of the methods. This feedback is 3 as it directs the authors to address the computational aspects and the limitations of their experiments. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the discussion or experiments to enhance the practical applicability of the proposed methods. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests that comparing the current setup to a deeper ResNet with parameter sharing could be an interesting baseline, potentially equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide explicit guidance on how the authors should address this question or incorporate the suggested baseline. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between residual blocks and suggests an interesting baseline for comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the ResNet architecture in section 7.1, specifically whether it shares parameters between residual blocks. It suggests comparing the current setup to a deeper ResNet with parameter sharing as an interesting baseline, potentially equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support this claim or suggestion. Without additional context or justification, the authors are left to interpret the comment, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the ResNet architecture in section 7.1, specifically whether it shares parameters between residual blocks. It suggests comparing the current setup to a deeper ResNet with parameter sharing as an interesting baseline, which could potentially be equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it identifies a potential area for further exploration and comparison, but it lacks detailed guidance on how to implement or evaluate this suggestion. The comment provides a starting point for the authors to consider additional experiments or analyses, but it does not offer a comprehensive or actionable response. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation of the paper, suggesting that the crossencoder architecture is not \"ignoring crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond or enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the motivation of the paper, specifically questioning the claim that the crossencoder architecture \"ignores crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not specify which part of the paper discusses the crossencoder architecture or the motivation, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the claims made about the architecture, the lack of grounding makes it challenging for the authors to understand the context and address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the crossencoder architecture is not \"ignoring crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed reasoning or evidence, the claim remains unsubstantiated, and the authors may struggle to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the motivation of the paper, specifically questioning the claim that the crossencoder architecture \"ignores crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. While the comment highlights a potential misinterpretation or lack of clarity in the paper\"s claims, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out a critical area for improvement, but it lacks actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bagofwords question model. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the model or the question design. The comment lacks concrete guidance on how to implement or revise the approach, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what the authors should consider regarding the design choice of trimming questions, particularly in the context of a bagofwords question model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bagofwords question model. While the comment raises a valid concern about the efficiency of encoding longer sequences, it does not provide specific examples or references to support the claim that this design choice is \"odd.\" The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique and how it might impact their work. Therefore, the comment is considered 2, as it provides some context but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific design choice in the paper, namely the decision to trim questions after the first 10, and questions its effectiveness, especially in the context of a bagofwords question model. This is a valuable point as it highlights a potential inefficiency or limitation in the approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their model. While it raises a concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is 3, as it identifies a potential area for improvement but does not offer concrete solutions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the work uses an antiquated GNN model and method, which negatively impacts performance. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. The authors are left without guidance on how to improve their draft or what specific changes to make. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the use of an antiquated GNN model and method. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific because it does not detail what aspects of the model or methods are considered \"antiquated\" or how this impacts performance. Without specific examples or references, the authors are left without guidance on what to address. Therefore, this comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point claims that the work uses an \"antiquated GNN model and method,\" which seriously impacts performance, and that the baseline algorithms/methods are also \"antiquated.\" However, the comment lacks specific examples or references to support these claims. Without detailed evidence or references, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an \"antiquated GNN model and method,\" which could impact the performance of the framework. It also points out that the baseline algorithms/methods are also \"antiquated.\" However, the comment lacks specific details or suggestions on how the authors might address these issues or improve their work. While it highlights a potential weakness, it does not provide actionable guidance or insights that would help the authors enhance their draft. Therefore, the comment is 2, as it points out a problem but does not offer substantial assistance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically mentioning the need for \"additional adhoc postanalysis\" to extract shared motifs. It suggests that the analysis might be easier with the proposed method but still requires this step. While the comment implies that the authors should clarify the explanation, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to improve the clarity of the explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation in Figure 1, noting that it is unclear how the proposed method produces the explanation and suggests that additional postanalysis might be necessary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically mentioning the need for \"additional adhoc postanalysis\" to extract shared motifs. The comment suggests that this analysis might be easier with the proposed method but still requires this step. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the explanation is unclear or requires additional analysis. This lack of detailed justification makes the claim 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that the explanation of how the proposed method produces the results is unclear. It suggests that additional adhoc postanalysis might be necessary to extract shared motifs, implying that the analysis could be easier with the proposed method but still requires this step. This feedback is 3 as it points out a potential area for improvement in the clarity of the explanation. However, it could be more helpful if it provided specific suggestions or guidance on how to improve the explanation or address the need for additional analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take: first, to clarify the experiment and its implications, and second, to strengthen the experiment by considering additional factors. The first action is clear and concrete, as it instructs the authors to clarify the experiment and its implications. The second action is also explicit and provides a clear direction for improvement by suggesting considering additional factors. The comment is fully actionable as it provides specific guidance on how the authors can address the identified issues. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"one experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the use of pseudo feature importance and the reliance on Prop 3.2 and a large enough perturbation value. This provides clear guidance on how to improve the experiment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the limitations of the experiment due to the use of pseudo feature importance and the reliance on Prop 3.2 and a large perturbation value. It suggests that the experiment could be strengthened by considering additional factors. However, the comment lacks specific examples or references to support the claim about the difficulty in judging the trustworthiness of the experiment. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiment, noting that it uses pseudo feature importance instead of true feature importance, which makes it difficult to assess the correctness of the results. The comment suggests that the experiment could be strengthened by considering additional factors, such as the number of perturbations and the reliance on Prop 3.2. This feedback is clear and actionable, providing the authors with specific areas to improve their experimental design. However, the comment could be more helpful if it offered more detailed guidance on how to address these issues or suggested alternative approaches. Overall, the comment is 4 as it highlights a critical aspect of the experiment and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on the meaning of a specific term in Equation (2). While it does not explicitly instruct the authors to provide this clarification, it implies that they should explain the term to ensure the reader understands the equation. However, the action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the term. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the authors should focus on. It raises a question about the meaning of a term in Equation (2), but without any context or reference to a specific section, the authors cannot determine which part of the paper is being addressed. The comment is also not specific, as it does not provide any guidance or suggestions on how to clarify the term. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the meaning of a specific term in Equation (2), but it does not contain any claims, opinions, or suggestions that require verification. It is a factual question that seeks clarification, which does not align with the criteria for a claim. Therefore, this comment is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the meaning of a specific term in Equation (2), which could be helpful for the authors to clarify and ensure that the equation is understandable to the readers. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it specify which part of the paper this clarification is needed. As a result, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific guidance on how to achieve this. The comment lacks explicit instructions or concrete steps for the authors to take to enhance their analysis. As a result, the authors are left without a clear understanding of what actions to undertake to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should be applied to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of analysis would be more comprehensive or dataintensive. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific guidance on how to achieve this. While it identifies a potential area for improvement, it lacks actionable advice or detailed suggestions on how to enhance the analysis. The comment is 3 as it points out a direction for improvement, but it does not offer concrete steps or examples for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should cite and discuss works related to metalearning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific sections or examples to include. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cite and discuss works related to metalearning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not specify which part of the paper these works are relevant to, making it weakly grounded. The comment is specific in its suggestions regarding the need to cite and discuss these works, but without clear references to specific sections or parts of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cite and discuss works related to metalearning, particularly those that are relevant to continual learning, even if they do not directly target it. The comment also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand and address the feedback effectively. The claim is 3 as it provides a general direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, suggesting that it should cite and discuss works related to metalearning, particularly those that are relevant to continual learning, even if they do not directly target it. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment lacks specific guidance on which parts of the paper should be addressed or how the authors should incorporate these suggestions. While it offers a clear direction for improvement, the lack of detailed examples or actionable steps makes it 3. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different feedback to better reflect reallife situations. However, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should explore methods to increase the diversity of feedback. While the comment offers a potential direction, it lacks concrete steps or examples, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would impact the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback to better reflect reallife situations. This feedback is 3 as it prompts the authors to consider enhancing the diversity of their feedback, which could improve the robustness and comprehensiveness of their analysis. However, the comment lacks specific guidance or suggestions on how to implement this idea, such as providing examples of different feedback types or methods for generating diverse feedback. While it offers a potential direction for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide explicit instructions on how to achieve this, such as specific sections or formatting to include. The action is implicit, as the authors need to infer that they should add a summary of the supplement experiments to the main text. This makes the comment 3, as it provides a clear direction but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the paper this clarification should be made, leaving the authors to infer that it should be in the main text. The comment is specific in its suggestion to summarize the results of the additional experiments, but it lacks grounding as it does not explicitly mention the section or part of the paper where this clarification is needed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification, making it difficult for the authors to understand why this clarification is necessary or how it would benefit their work. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it lacks specific guidance on how to achieve this, such as suggesting where in the text these additional experiments should be discussed or what kind of summary would be most effective. The comment is 3 as it identifies an area for improvement but does not provide detailed feedback or actionable advice, leaving the authors with limited guidance on how to address the issue."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen their claims. The feedback is implicit and lacks concrete details, making it difficult for the authors to understand how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper this claim is made or which tables or figures are being referenced. The lack of specific references makes it challenging for the authors to identify the exact section or data that needs to be addressed. Therefore, the comment is 1, as the authors cannot confidently determine which part of the paper is being discussed. It is also not specific because it does not provide detailed guidance on how to improve the claim or address the issue. This aligns with a score of 1.", "verifiability_rationale": "The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. While the comment identifies a potential issue with the claim, it does not provide specific guidance or suggestions on how the authors might address this concern or strengthen their experimental results. The feedback is 3 as it highlights a critical point that needs attention, but it lacks actionable advice or detailed insights to help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the Cycle FC method, noting that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests that there could be many different designs for this method and recommends exploring experiments or analysis with different sampling intervals and sample sizes. While the comment identifies an area for improvement and provides a direction for further exploration, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the Cycle FC method, specifically mentioning that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests exploring experiments or analysis with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC method or where the analysis is conducted. This makes it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue of insufficient analysis, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the Cycle FC method is slightly insufficient, suggesting that there could be many different designs and that exploring experiments with different sampling intervals and sample sizes could enhance the analysis. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The reasoning is vague and lacks detailed evidence, which limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the Cycle FC method, specifically noting that aligning features at different spatial locations to the same channel results in slightly insufficient analysis. It suggests that exploring experiments with different sampling intervals and sample sizes could enhance the analysis. While the comment points out a specific area for improvement, it does not provide detailed guidance or examples on how to conduct these additional experiments or what specific aspects of the analysis could be improved. The feedback is 3 as it directs the authors to consider expanding their analysis, but it lacks depth and specificity, making it challenging for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the lack of standard deviations in the results, questioning the certainty of the best method\"s superiority. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or providing additional analysis to clarify the performance of other RF configurations. The action is implicit and vague, as the authors are left to infer that they need to include standard deviations to address the concern. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of standard deviations in the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, questioning the certainty of the best method\"s superiority due to the lack of standard deviations. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the results makes it uncertain whether the best method is truly the best or if other RF configurations have performances close to it. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of standard deviations in the results, which raises concerns about the certainty of the best method\"s superiority. This feedback is clear and actionable, as it directs the authors to include standard deviations to address the uncertainty in their findings. However, the comment could be more helpful if it provided additional guidance on how to present or interpret the results with standard deviations. Despite this, the comment is 4 as it offers a clear direction for improvement, allowing the authors to enhance the robustness and clarity of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. While the comment identifies a specific detail that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this question. The action is implicit, as the authors need to infer that they should clarify the feature extractor used. However, the comment lacks concrete guidance on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This is a factual question that requires the authors to provide additional information or context. However, it does not contain a subjective claim or opinion that needs verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific detail in the paper, namely the dimensionality of each region being 512, and asks for clarification on which feature extractor is used. This is a clear and actionable question that prompts the authors to provide more context or detail about the feature extraction process. By addressing this question, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it suggested specific ways to clarify the feature extractor or provided examples of how this information could be presented. Overall, the comment is 3 as it identifies a need for clarification but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit, as the authors can infer that they need to add these details, but the lack of specificity makes it difficult to know exactly what to do. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in or how they should be presented. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of information or examples would be beneficial. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not offer any specific reasoning or examples to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it lacks specificity and does not offer any guidance on how these details should be presented or what kind of information would be most beneficial. The comment is vague and does not provide actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the choice of p < 0.4 in Algorithm 1, but it does not provide any guidance or suggestions on how the authors might address this choice or why it was made. The comment lacks explicit instructions or concrete advice, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper Algorithm 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it questions the choice of p < 0.4, but without the context of where Algorithm 1 is located, the authors cannot fully understand the scope of the question. Therefore, this comment is 3, aligning with category 2.", "verifiability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1, but it does not provide any justification, reasoning, or references to support why this specific value was chosen. Without additional context or explanation, the authors are left without guidance on how to address this question or why it is important. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of p < 0.4 in Algorithm 1, which could be a point of confusion for the authors. However, the comment does not provide any guidance or suggestions on how the authors might address this choice or why it was made. Without additional context or explanation, the authors are left without actionable feedback on how to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the analysis or what specific aspects of the methods should be examined. The suggestion to compare with other methods is clear, but the lack of detailed instructions on how to perform the analysis makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. However, it does not specify which part of the paper this analysis should be conducted or which sections of the paper discuss the methods being compared. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the need for analysis and comparison, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides specific references to support the suggestion, which helps the authors understand the need for comparison. However, it lacks detailed reasoning or examples of how the analysis should be conducted or what specific aspects of the methods should be compared. This makes the claim 3, as it provides a basis for improvement but could benefit from more detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of the proposed method. The inclusion of references further supports the suggestion, providing a clear direction for the authors to enhance their work. This feedback is 4 as it highlights specific areas for improvement and offers a clear path for the authors to address these issues, though it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model when negative samples are assigned to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit instructions or suggestions on how to address this question or what actions should be taken. The comment lacks concrete guidance on how to analyze or improve the model\"s performance in this context. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model when negative samples are assigned to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the question should be addressed. While the comment is specific in its inquiry about model performance, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point poses a question about the performance of a model when negative samples are assigned to a distractor class. It does not contain a claim or assertion that requires verification or justification. The comment is factual and descriptive, asking for an analysis of a specific scenario. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the performance of a model when negative samples are assigned to a distractor class. This question prompts the authors to consider a specific scenario and analyze its implications. However, the comment lacks depth and does not provide any guidance or suggestions on how to address this question or what actions should be taken to improve the model\"s performance. While it identifies an area for further analysis, it does not offer actionable feedback or insights that would be beneficial for the authors. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation about the performance of RLCD and RLAIF as the model size increases, noting that the advantage of RLCD diminishes from 7B to 30B. It raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. While the comment identifies an area for further exploration and questions the scalability of RLCD, it does not provide explicit or implicit actions for the authors to take. The authors are left to infer that they should investigate the scaling behavior of RLCD and RLCDRescore with larger models. This lack of direct guidance makes the comment 3, as it provides a direction for further research but does not offer concrete steps for improvement. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the performance of RLCD and RLAIF as the model size increases, specifically noting the shrinking advantage of RLCD from 7B to 30B. It raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. However, the comment does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section or table where this data is presented. While the authors can infer that it relates to the experimental results, the lack of explicit grounding makes the comment weakly grounded. The specificity of the comment is also limited as it does not provide detailed guidance on how to address the scalability issue or what experiments might be needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, based on the data presented in Table 2. The comment raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. However, the comment lacks specific examples or detailed reasoning to support the claim about the diminishing advantage. It does not provide references or logical arguments to substantiate the observation, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or detail to be 5.", "helpfulness_rationale": "The review comment highlights a specific observation regarding the performance of RLCD and RLAIF as the model size increases, noting that the advantage of RLCD diminishes from 7B to 30B. It raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. This feedback is 3 as it points out a potential area for further exploration and questions the scalability of RLCD. However, it lacks detailed guidance or suggestions on how the authors might investigate this issue or what experiments could be conducted to address it. The comment provides a direction for further research but does not offer concrete steps or insights for improvement, making it 3 rather than fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of quantitative analysis regarding computational gains from replacing the MAE model with a CNNbased data augmentation strategy. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements. The comment is explicit in stating the need for quantitative analysis and provides concrete details on what kind of measurements would be beneficial. This allows the authors to directly address the issue by including the suggested analysis in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"computational gains\" and \"quantitative analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the need for quantitative measurements such as GPU hours, memory usage, or training time to substantiate the claim of computational benefits. This provides clear guidance on what needs to be addressed to support the claim. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks quantitative analysis on computational gains, specifically mentioning the absence of measurements like GPU hours, memory usage, or training time. This claim is 3 as it provides a clear suggestion for improvement by specifying the type of quantitative analysis needed. However, it lacks detailed examples or references to support the claim, which could make it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights that while the paper claims efficiency improvements from replacing the MAE model with a CNNbased data augmentation strategy, it does not provide specific measurements or comparisons to substantiate these claims. The suggestion to include quantitative analysis, such as GPU hours, memory usage, or training time, is clear and actionable. This feedback is valuable as it guides the authors to strengthen their claims with empirical evidence, making the paper more robust and credible. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing, which implies that the method might be less efficient for these scenes. However, the comment does not provide explicit guidance on how to incorporate this information into the comparison or how to address the efficiency issue. The action is implicit and vague, as it does not specify what needs to be done to make the comparison more accurate or how to demonstrate the efficiency of the method. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"COLMAP\" and \"scenebyscene finetuning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, noting that the time taken for these processes should be considered, making the method less efficient. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing, rendering the method less efficient for these scenes. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of COLMAP and scenebyscene finetuning, suggesting that the time taken for these processes should be considered to accurately assess the method\"s efficiency. However, the comment lacks specific guidance or suggestions on how to address this issue or what data should be included in the comparison. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important aspect that needs attention but does not offer comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the reporting of results, suggesting that the paper only shows results after a significant amount of training. It also speculates about the potential impact of early training on the CNN\"s performance. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the reporting of results, specifically noting that the results are only reported after a significant amount of training. It also speculates about the potential impact of early training on the CNN\"s performance. However, the comment does not specify which part of the paper discusses the results or the training process, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reporting of results, specifically noting that the results are only reported after a significant amount of training. It also speculates about the potential impact of early training on the CNN\"s performance, suggesting that the model parameters might be \"essentially garbage\" and that the planning component might \"hurt\" more than it helps. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concern. The feedback is 3 as it provides a logical reasoning but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent concern about the reporting of results, noting that the paper only shows results after a significant amount of training. It also speculates on the potential impact of early training on the CNN\"s performance, suggesting that the model parameters might be \"essentially garbage\" and that the planning component might \"hurt\" more than it helps. While the comment identifies an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the draft. The feedback is 3 as it points out a potential gap in the reporting of results, but it does not provide actionable advice or detailed insights to help the authors improve their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide explicit guidance on how to implement this suggestion or what specific aspects of the lowresolution stream should be emphasized. The action is implicit and vague, as the authors are left to infer that they should consider adding a lowresolution stream. However, the comment lacks concrete details on how to approach this addition, making it 3.", "grounding_specificity_rationale": "The comment expresses an opinion about the marginal contribution of the paper, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not specify which part of the paper this suggestion relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its suggestion to add a lowresolution stream, which provides a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide specific guidance on how to implement this suggestion or what aspects of the lowresolution stream should be emphasized. While the comment identifies a potential area for improvement, it lacks actionable advice or detailed suggestions, making it 3. The authors are left to infer the meaning and implications of the comment, which limits its effectiveness in guiding them to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of the main contribution, suggesting that the performance gain is primarily due to PBSD. It also asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment implies that the authors should clarify the main contribution and provide additional motivations for PBSD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer what needs to be addressed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the clarity of the main contribution and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the content being questioned, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the main contribution and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, specifically questioning whether it is welldefined. It also prompts the authors to consider additional motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment highlights an area for improvement, it does not provide specific suggestions or guidance on how to address the issue or enhance the motivation for PBSD. The feedback is 3 as it points out a potential area for clarification but lacks depth and actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relationship between a tester for the spread parameter and an (\u03f5, \u03b4)identity tester. It asks whether the spread parameter tester immediately yields an (\u03f5, \u03b4)identity tester and provides an example of how it might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. However, the comment does not explicitly instruct the authors to address this question or provide guidance on how to clarify the relationship or handle the example. The action is implicit and vague, as the authors are left to infer that they need to address the question and provide more details. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between a tester for the spread parameter and an (\u03f5, \u03b4)identity tester, specifically questioning whether the former immediately yields the latter. It provides an example of how the tester might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in detailing the question and the example, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between a tester for the spread parameter and an (\u03f5, \u03b4)identity tester, specifically questioning whether the former immediately yields the latter. It provides an example of how the tester might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. However, the comment lacks detailed reasoning or references to support the claim that the spread parameter tester does not immediately yield an (\u03f5, \u03b4)identity tester. Without further explanation or evidence, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a question about the relationship between a tester for the spread parameter and an (\u03f5, \u03b4)identity tester, specifically questioning whether the former immediately yields the latter. It provides an example of how the tester might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. However, the comment does not offer any suggestions or guidance on how the authors might address this question or clarify the relationship between the two types of testers. It lacks actionable advice or constructive feedback, making it 2. The authors are left to interpret the comment and potentially address the issue on their own, which limits the comment\"s usefulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the dataset distribution. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the detailed distribution of the proposed dataset. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is specific in that it points out a lack of clarity in the dataset distribution, but without grounding, the authors are left without a clear understanding of where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a basis to understand why the dataset distribution is unclear or how it might be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the detailed distribution of the proposed dataset is unclear. However, it does not provide any suggestions or guidance on how the authors might address this lack of clarity. Without actionable feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a problem but does not offer any constructive advice or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a selfsupervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how the authors should address this issue or incorporate a selfsupervised pretraining method. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s reliance on annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of supervised training. The authors may need to infer the relevant sections, making the comment weakly grounded. The comment is specific in detailing the issue with annotated labels and suggesting an alternative approach, which provides clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method necessitates annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, specifically that it requires annotated labels for learning semantic tokens, which restricts its applicability to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it highlights a potential weakness in the method and proposes an alternative approach that could broaden its applicability. However, the comment could be more helpful if it provided specific guidance on how to implement or adapt the method for selfsupervised learning. Overall, the comment offers valuable insights but lacks detailed actionable suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides a clear and explicit action for the authors to take, as they need to expand their experiments to include these more complex tasks. The comment is specific in its suggestion and offers a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to demonstrate the scalability of LFF on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides clear guidance on which part of the paper the authors should focus on. The comment is also specific, as it specifies the type of tasks that would help demonstrate the scalability of LFF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and suggests that demonstrating LFF\"s effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids, is important for fully demonstrating its scalability. This claim is 3 as it provides a logical reasoning for why the suggested tasks are important for demonstrating scalability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of LFF, the authors should show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, providing a specific direction for the authors to enhance their experiments and better showcase the capabilities of LFF. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their work, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for considering only one deep learningbased baseline, MULT, which was proposed in 2019 and is no longer considered stateoftheart. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how the authors might update their baseline comparisons or justify their choice of baselines. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a list of references related to multimodal sentiment analysis and emotion recognition, but it does not specify which part of the paper these references are relevant to. The authors cannot confidently determine which sections or aspects of their work are being addressed by the critique. Additionally, the comment does not specify what needs to be addressed in these references or how they relate to the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper regards MISA as the only deep learningbased baseline that considers crosssensory interaction but notes that MISA was proposed in 2020, making it somewhat out of fashion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by suggesting that the baseline used, MISA, is outdated and no longer considered stateoftheart. It points out that MISA was proposed in 2020, which may make it less relevant for current research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as considering more recent baselines or justifying their choice of MISA. Without actionable advice or suggestions, the comment is 3 as it highlights a potential weakness but lacks depth and direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare the tensor completion results for all models, including TW, TT, and TR, while ensuring that the models have the same number of model parameters. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue of unclear comparisons. The comment is fully actionable because it specifies the exact steps required to improve the fairness of the comparison. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a comparison against other models in the experiments, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on how to address the issue, including the omission of model ranks and the suggestion to compare tensor completion results with the same number of model parameters. This level of detail helps the authors understand exactly what needs to be done to improve the fairness of their comparisons. Therefore, this comment is rated as 5, corresponding to category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the omission of model ranks makes it difficult to ensure a fair comparison. The comment suggests that the authors should compare tensor completion results for all models, including TW, TT, and TR, while having the same number of model parameters. This claim is 3 as it provides a logical reasoning for why the comparison is unclear and suggests a specific way to address the issue. However, it lacks detailed examples or references to support the claim fully, which could make it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it identifies a significant issue with the experimental comparisons, specifically the lack of clarity and the omission of model ranks. It provides clear guidance on how to address this issue by suggesting that the authors compare tensor completion results for all models, including TW, TT, and TR, while ensuring that the models have the same number of model parameters. This detailed feedback is actionable and constructive, as it helps the authors improve the fairness and rigor of their comparisons. The comment is comprehensive and provides a clear path for the authors to enhance their experimental design, making it highly valuable for improving the draft. Therefore, it is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the normalization module between two versions of the paper, suggesting that the text might be misleading. It also points out the need for standardization in the pictograms used in the figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the reviewer notes minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to resolve them. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the normalization module, suggesting that it appears different in two versions despite the text implying consistency. It also recommends standardizing pictograms in figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing the issues with the normalization module and the need for standardization in the pictograms, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the consistency of the normalization module between two versions of the paper, suggesting that the text might be misleading. It also recommends standardizing the pictograms in the figures, particularly noting the confusion in Figure 4 due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment lacks detailed reasoning or specific examples to fully substantiate these claims, making it 3. The authors would need to infer the basis for the concerns, which limits the clarity and support provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the normalization module between two versions of the paper, which could lead to confusion for readers. It also suggests the need for standardization in the pictograms used in the figures, specifically mentioning Figure 4, where overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range make it difficult to understand. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the feedback lacks detailed guidance on how to address these issues or what specific actions the authors should take to resolve them. While the comment highlights areas for improvement, it does not provide concrete suggestions or detailed explanations, making it 3. The authors would need to infer the necessary steps to address the identified issues, which limits the overall impact of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, where the authors do not provide details on how the algorithm removes subdivision splines. The comment implies that the authors should clarify the algorithm\"s details and address the computational cost, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the algorithm and its computational cost. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. However, the comment is specific in its request for clarification and additional details regarding the algorithm and its computational cost. This makes the comment weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It does not provide any specific evidence, reasoning, or references to support the claim that the authors did not detail how the algorithm removes subdivision splines or the computational cost involved. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the utility of subdivision splines and the computational cost of their proposed algorithm. It questions whether the theoretical part of the paper provides sufficient detail on how the algorithm removes these splines and whether it introduces extra computational costs. This feedback is 3 as it highlights a gap in the paper\"s explanation and encourages the authors to provide more detailed information. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the comment provides a clear direction for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that while the paper claims the same procedure is used as for baselines, most baselines do not use this dataset. The reviewer questions whether 300WLP is used in all experiments or just some, suggesting it could provide an unfair advantage to the proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the experimental methodology and address the concern about the dataset usage. The comment is concrete, as it specifies exactly what needs to be clarified and how it might impact the fairness of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the concern about the experimental methodology is raised, specifically mentioning the use of 300WLP in training the model. It also specifies the issue by questioning whether the same procedure is used as for baselines and whether the dataset is used in all experiments, which could provide an unfair advantage. This level of detail allows the authors to accurately identify the section of the paper being addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the experimental methodology, specifically regarding the use of the 300WLP dataset in training the model. It questions whether the same procedure is used as for baselines, noting that most baselines do not use this dataset. The reviewer suggests that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. This claim is 3 as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the clarity of the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that while the paper claims the same procedure is used as for baselines, most baselines do not use this dataset, raising concerns about potential unfair advantages for the proposed method. This feedback is clear and actionable, as it directs the authors to clarify the experimental setup and address the inconsistency in dataset usage. By highlighting this issue, the comment provides valuable guidance for improving the transparency and fairness of the experimental methodology, making it 5 for the authors. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to make the techniques more novel. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not specify which part of the paper these techniques are discussed in, making it difficult for the authors to identify the exact sections or parts that need attention. The comment is specific in identifying the techniques but lacks grounding as it does not provide clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, the comment lacks specific evidence or references to support this claim. Without detailed examples or references to existing literature, the authors may find it challenging to understand the basis of this claim or how to address it. The comment is therefore considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of some techniques used in the algorithm, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their techniques. The comment lacks actionable feedback, leaving the authors without a clear path to improve their work. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks indepth analysis, specifically regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. While the comment implies that the authors should conduct a more detailed analysis, it does not explicitly instruct them to do so or provide specific guidance on how to analyze the training dynamics. The action is implicit and somewhat vague, as the authors need to infer that they should perform a more thorough analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis, specifically regarding the inverse scaling observed over compute. It implies that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. It is specific in suggesting that the authors should provide an analysis explaining the training dynamics, but without a clear reference to a specific section or figure, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis, specifically regarding the inverse scaling observed over compute, and suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper: the lack of indepth analysis regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to strengthen the paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work. However, the comment could be more helpful if it provided some guidance on how to conduct this analysis or suggested specific areas of investigation. Despite this, the comment is 4 as it highlights a critical aspect of the paper that needs attention, providing the authors with a clear direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the comprehensiveness of the experiments, noting that the analyses of the method itself and the experimental outcomes are not sufficiently detailed. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific aspects of the analysis need to be expanded. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the experiments, specifically noting that the analyses of the method itself and the experimental outcomes are not comprehensive enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issue of comprehensiveness, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analyses of the method itself and the experimental outcomes are not comprehensive enough, and that the performance improvement attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level is questionable. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the comprehensiveness of the experiments, noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. This feedback is 3 as it highlights a critical area for improvement, but it lacks depth and specificity. The authors would benefit from additional guidance on how to expand the analyses and address the concerns raised. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation of the paper, noting that its focus on explaining multitask models restricts its applicability. However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or improve the applicability of their work. The comment lacks concrete guidance on what changes could be made to broaden the paper\"s scope or relevance. As a result, the authors are left without a clear understanding of how to proceed to enhance the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what aspects of the paper are limited in terms of applicability. Without specific guidance or references, the authors cannot effectively address the feedback. Therefore, this comment is rated as 1.", "verifiability_rationale": "The review point claims that the paper \"mainly focuses on explaining multitask models, which somehow limits the applicability.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to substantiate the assertion about the paper\"s focus and its impact on applicability. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on explaining multitask models, suggesting that this limitation restricts the paper\"s applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\"s applicability. Without actionable feedback or detailed suggestions, the authors are left without a clear understanding of how to improve their work. Therefore, the comment is 2, as it highlights a concern but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the literature review should include several papers that seem relevant, specifically mentioning 1 and 2. It also notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. The action is implicit, as the authors need to infer that they should add these papers and compare their rates. The lack of concrete instructions makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the literature review should include several papers that seem relevant, specifically mentioning 1 and 2. It also notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not specify which section of the paper the literature review is located, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as including relevant papers and comparing their rates. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning 1 and 2. It suggests that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issue. The absence of references or detailed explanations weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the literature review, noting that it may be overlooking relevant papers that could be included. It provides specific examples of papers, 1 and 2, that seem relevant and suggests that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not offer detailed guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and guidance for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not provide explicit or implicit actions for the authors to take, such as conducting additional experiments or providing detailed analysis. The comment lacks concrete guidance on how the authors should address these questions or what specific actions they should take to improve their draft. As a result, the comment is 1, as it does not provide the authors with a clear path forward for addressing the concerns raised.", "grounding_specificity_rationale": "The comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections or content being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address the performance concerns or what additional experiments might be needed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not provide any specific evidence, reasoning, or references to support these claims or questions. The comment lacks detailed justification or examples to substantiate the concerns raised, making it difficult for the authors to understand the basis of the feedback. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. While it identifies an area for further investigation, it does not provide specific guidance or suggestions on how the authors might address these concerns or what additional experiments could be conducted. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that it does not describe the hyperparameters used by each defense or how they are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack, indicating the amount of clean data required to remove the attack. This feedback provides a clear and explicit action for the authors to take, as they need to include details about the hyperparameters used and their derivation. The suggestion to optimize hyperparameters against the attack is also concrete, offering a specific direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of description regarding hyperparameters used by each defense and how they are derived, suggesting a maximally charitable evaluation of defenses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not describe the hyperparameters used by each defense or how they are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack, indicating the amount of clean data required to remove the attack. This claim is 3 as it highlights a gap in the paper\"s description of hyperparameters, but it lacks specific examples or references to support the claim fully. The authors would need to provide more detailed information to address this feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of information regarding the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation of defenses would involve optimizing hyperparameters against the attack, which would provide a more comprehensive understanding of the data requirements for removing the attack. This feedback is clear and actionable, as it directs the authors to include detailed descriptions of the hyperparameters and their derivation, enhancing the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided specific examples or guidance on how to optimize hyperparameters against the attack. Overall, the comment is 4, as it effectively highlights an area for improvement and encourages the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the practical implications of the theoretical results, suggesting that the paper could benefit from providing more takeaway points for practitioners. It also notes that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not explicitly instruct the authors to add more takeaway points or clarify the novelty of the finding. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the practical implications of the theoretical results, suggesting that the paper could benefit from providing more takeaway points for practitioners. It also notes that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not specify which part of the paper discusses the theoretical results or the takeaway points, making it weakly grounded. The comment is specific in identifying the issue with the practical implications and the lack of clarity regarding the novelty of the finding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper would benefit from providing more takeaway points for practitioners. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors are left to infer the need for more practical takeaways, but the reasoning is logical and somewhat clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key area for improvement by highlighting the lack of immediate practical implications for the theoretical results. It suggests that the paper could benefit from providing more takeaway points for practitioners, which is a valuable and actionable feedback. The comment also points out that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty, which is a specific and constructive suggestion for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to enhance the practical implications or clarify the novelty of the finding. Overall, the feedback is 4 as it directs the authors towards important areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the necessity of introducing separators in Section 4, asking for clarification on their purpose beyond T/I/O. While it prompts the authors to explain the role of separators, it does not provide explicit guidance on how to address this issue or what specific changes might be needed. The action is implicit, as the authors need to infer that they should clarify the purpose of separators. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of introducing separators and asks for clarification on their purpose beyond T/I/O, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of introducing separators in Section 4, specifically asking for clarification on their purpose beyond T/I/O. While it does not contain a subjective claim or opinion, it prompts the authors to provide additional information or reasoning to justify the inclusion of separators. The comment is 3 as it encourages the authors to elaborate on the purpose of separators, but it lacks specific examples or references to support the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the introduction of separators in Section 4, questioning their necessity and purpose beyond T/I/O. This feedback is clear and actionable, as it prompts the authors to clarify the role of separators and provide additional context or reasoning for their inclusion. By addressing this question, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it suggested specific ways to clarify the purpose of separators or provided examples of how they enhance the understanding of the content. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide explicit guidance on which alternative strategies to explore or how to implement them. The action is implicit, as the authors need to infer that they should consider other pooling methods and potentially explore them. While the comment is 3, it lacks concrete details on how to apply the suggested exploration. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (L235), allowing the authors to accurately identify the part being addressed. It is also specific because it questions the choice of mean pooling and suggests exploring alternative strategies, providing clear guidance on what needs to be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide any specific reasoning, examples, or references to support why mean pooling is chosen or why other strategies might be better. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. This feedback is 3 as it prompts the authors to consider alternative approaches, which could potentially improve the robustness or effectiveness of their method. However, the comment lacks depth and does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how to implement them. As a result, while it offers a direction for improvement, it does not fully empower the authors to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to include them in the draft. The action is implicit, as the authors can infer that they need to add this information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks specific instructions on implementation.", "grounding_specificity_rationale": "The comment raises a question about the training details of the VQGAN, specifically whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this information is relevant to, making it weakly grounded. The comment is specific in that it identifies a missing detail that needs clarification, but without explicit references to sections or figures, the authors may struggle to locate the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a factual question that requires the authors to provide specific details about their methodology. However, the comment does not offer any additional context, reasoning, or references to support the need for this information. As a result, the claim is 3, as it lacks sufficient justification or evidence to fully substantiate the need for clarification.", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a pertinent concern that could help the authors clarify their methodology and ensure the reproducibility of their results. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it offer any additional context or reasoning to support the need for this clarification. While the feedback is 3 in identifying a potential area for improvement, it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the experimental strengths of the proposed approach, suggesting that running the algorithm on 40 different networks from the training phase might be unnecessary. It proposes an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their experimental setup. The action is implicit, as the authors need to infer that they should consider the proposed alternative method. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which is a clear and specific suggestion for improvement. The comment provides a detailed rationale for why the proposed approach might be unnecessary, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the proposed approach is unnecessary or that the suggested alternative is a viable alternative. The lack of supporting evidence makes the claim 3, as the authors may need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. This feedback is 3 as it identifies a potential inefficiency in the experimental setup and offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the claim, or if it suggested specific changes to the experimental design. Overall, the comment provides a clear direction for improvement, but it could be more comprehensive and actionable to fully benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the clarity and specificity of certain aspects of the paper. It asks the authors to clarify the meaning of \"Omega\" in line 178, to be more explicit about the OMD family of algorithms, and to specify the link function and theorem in reference to the regret guarantee. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how the authors should address these points. The authors are left to infer the necessary actions, which makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 178, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as clarifying the meaning of \"Omega,\" being more explicit about the OMD family of algorithms, and specifying the link function and theorem. This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity and specificity of certain aspects of the paper, such as the meaning of \"Omega\" in line 178, the OMD family of algorithms, the link function, and the specific theorem referenced. While the questions are logical and seek clarification, they do not provide explicit reasoning, references, or examples to support the claims made. The comment lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be clearer and more explicit. It questions the meaning of \"Omega\" in line 178, suggests that the paper should be more explicit about the OMD family of algorithms, and requests clarification on the link function and theorem referenced for the regret guarantee. These questions and suggestions provide actionable feedback that could help the authors improve the clarity and precision of their writing. However, the comment could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the feedback is 3, as it provides a clear direction for improvement but lacks depth in terms of specific suggestions or detailed explanations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using longer video sequences to better capture motion, color, and object changes. It also acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the stateoftheart. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and provides examples, such as \"16 frames,\" which helps the authors identify the specific part of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of longer video sequences to capture motion, color, and object changes. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is interesting and extensive in its experiments, noting that the results are still not perfect but show improvement over the stateoftheart. However, the comment lacks specific evidence or references to support these claims, making it difficult for the authors to verify the claims fully. The reasoning is somewhat vague, as it does not provide detailed examples or comparisons to substantiate the claims. Therefore, the comment is rated as 3, as it provides some justification but lacks key elements for full verification.", "helpfulness_rationale": "The review comment provides specific feedback on the use of short video sequences, suggesting that longer sequences could better capture motion, color, and object changes. It acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the stateoftheart. However, the comment lacks detailed guidance on how to implement the suggestion of using longer video sequences or what specific changes should be made to the draft. While it offers a direction for improvement, the feedback could be more helpful if it included concrete suggestions or examples of how to enhance the evaluation. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment implies that the authors should consider the relevance of this experiment, it does not provide explicit guidance on how to address this question or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion about the experiment\"s relevance, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. However, the comment lacks specific evidence or reasoning to support the claim that the experiment is unnecessary or how it might strengthen the paper. The authors are left to infer the relevance of the experiment, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments could be conducted to strengthen the paper. The feedback is 3 as it points out a potential area for further exploration, but it does not provide detailed actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not explicitly instruct the authors on how to clarify this difference or what specific aspects of the paper need to be addressed. While the suggestion is clear, the lack of explicit guidance on implementation makes it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not specify which part of the paper discusses meta solvers or centralized RL, making it difficult for the authors to pinpoint the exact section that needs clarification. While the suggestion is specific about the content to be clarified, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights, and provides a specific example by citing Foester et al. This claim is 3 as it offers a clear suggestion and a reference to support the idea. However, it lacks detailed reasoning or examples beyond the cited work, which could enhance the clarity and persuasiveness of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for clarification in the paper, namely the distinction between meta solvers and centralized RL where agents share weights. It provides a clear suggestion to include a discussion of this difference, which could enhance the paper\"s clarity and depth. However, the comment lacks specific guidance on how to implement this clarification or what aspects of the paper need to be addressed. While it offers a valuable suggestion, the lack of detailed instructions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s categorization method, noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the availability of some papers on arXiv before the anthology. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their categorization method. The action is implicit, as the authors need to infer that they should consider the arXiv dates when categorizing the papers. While the comment identifies a potential problem, it lacks concrete instructions on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the categorization of papers based on publication years on the ACL anthology, noting that some papers are available on arXiv earlier than the anthology. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in detailing the issue with the categorization method, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s categorization method, which splits papers according to their publication years on the ACL anthology, is inaccurate because many papers are posted on arXiv much earlier than the anthology. The example provided, such as the BERT paper being available on arXiv in October, supports the claim. However, the comment lacks specific examples or references to other papers that might have been posted earlier on arXiv, which could strengthen the argument. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s categorization method, specifically noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the availability of some papers on arXiv before the anthology. The example provided, such as the BERT paper being available on arXiv in October, effectively illustrates the concern. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their categorization method. Without actionable feedback or specific recommendations, the comment is 3 as it highlights a potential area for improvement but lacks depth and direction for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the definition of M_T on page 3 could be clearer by providing examples. While the comment implies that the authors should consider adding examples to improve the understanding of M_T, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the definition of M_T, suggesting that it is defined over the probabilities of atomic events and that the notation is not clear. The authors are advised to consider providing examples to explain M_T, which is a clear and actionable suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T on page 3 could be clearer by providing examples. While the comment implies that the authors should consider adding examples to improve the understanding of M_T, it does not provide specific examples or references to support this suggestion. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the definition of M_T on page 3, suggesting that it is defined over the probabilities of atomic events. The comment implies that the notation used is not making it easy to understand the concept and recommends providing examples to clarify it. While the comment points out a specific area for improvement, it does not offer detailed guidance on how to provide these examples or what kind of examples would be most effective. The feedback is 3 as it directs the authors to a specific area for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks specific guidance on how to refine the performance or what aspects of the future work might need improvement. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment is somewhat specific in that it suggests future refinement, but without detailed guidance on what aspects to focus on, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting room for further refinement. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or detailed reasoning to substantiate the assertion that the enhancements are modest. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work might need improvement. The comment lacks actionable advice, making it 3 as it identifies a potential area for future work but does not offer concrete steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the experimental setup. The action is implicit, as the authors are left to infer that they need to investigate the similarity in performance and potentially refine their experimental design or analysis. The lack of concrete steps or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the issue with the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the results are not convincing enough. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the performance on the last two datasets is similar to IRM, which raises questions about the effectiveness of the proposed method. This feedback is 3 as it highlights a potential weakness in the experimental validation. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or improve their experimental design. Without specific recommendations, the authors may struggle to fully understand and rectify the problem. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long entity is known. However, it does not provide explicit instructions or suggestions on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should consider adding a discussion or clarification regarding the detection of both entities. The comment is vague and lacks concrete guidance on how to implement the suggested action. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. However, it does not provide any specific reasoning, examples, or references to support the claim that both entities should be detected. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2 and asks for a comparison with a scenario where only the long entity is known. This question prompts the authors to consider the rationale behind their detection method and whether it aligns with the expected outcome. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or incorporate it into their draft. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of empirical validation in the paper and suggests that the authors would like to see experiments where the bounds are validated. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these experiments or what specific aspects of the bounds need validation. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical validation, which is a specific aspect of the paper. It also suggests that the authors would like to see experiments where the bounds are validated, providing a clear direction for improvement. However, the comment does not specify which part of the paper lacks empirical validation or what specific aspects of the bounds need validation. This makes the comment specific but not fully specific, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, specifically suggesting the need for experiments where the bounds are validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of empirical validation. It suggests that the authors would benefit from conducting experiments to validate the bounds discussed in the paper. This feedback is clear and actionable, providing a direct direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to design these experiments or what aspects of the bounds should be validated. Despite this, the comment is 4 as it highlights a crucial area for enhancement, allowing the authors to focus on improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. While the comment identifies a specific point of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the meaning of \"chunks\" in the context of the paper. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it directly questions the clarity of the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This is a subjective question that requires the authors to interpret the meaning of \"chunks\" in the context of the paper. However, the comment does not provide any evidence, reasoning, or references to support the claim that the phrase is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the question. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a specific question about the phrase \"nonsequential information such as chunks\" and asks for clarification on whether chunks are still considered sequential information. This feedback is clear and actionable, as it directly points out a potential area of confusion for the authors. By addressing this question, the authors can improve the clarity and precision of their writing, ensuring that the terminology used is consistent and understandable. The comment is 4 because it provides a clear direction for improvement, but it could be more comprehensive if it suggested specific ways to clarify the phrase or provide examples. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. While the reviewer identifies a potential issue with the theorem, the comment does not provide explicit guidance or suggestions on how to address this concern. The authors are left to infer that they need to clarify or correct the theorem, but the lack of concrete steps or detailed explanations makes the action implicit and vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about a specific aspect of Theorem 1, focusing on a potential issue with an assumption regarding a node with 0 neighbors. However, it does not specify which part of the paper this theorem is located in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique of the theorem but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. The reviewer claims that the upper bound in this case is 0, which is not true. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the reviewer\"s assertion remains unsubstantiated, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about a potential issue with Theorem 1, particularly concerning the assumption of a node with 0 neighbors. The reviewer questions the validity of the upper bound in this scenario, suggesting that it might be 0, which contradicts the theorem. However, the comment does not provide any guidance or suggestions on how to address this issue or clarify the theorem. While it identifies a potential area for improvement, the lack of actionable feedback leaves the authors without clear steps to take. Therefore, the comment is 2, as it highlights a concern but does not offer constructive advice or solutions. The score is consistent with a rating of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the limited technical novelty of the paper, suggesting that it is similar to previous works that focus on graphbased approaches, coattention mechanisms, and architectures. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the paper could be improved to enhance its novelty. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to respond or improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b) that the authors should compare with, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of limited technical novelty and the similarity of the idea, coattention mechanism, and architecture to previous works. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper has limited technical novelty, as it is similar to previous works focusing on graphbased approaches, coattention mechanisms, and architectures. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed comparisons to substantiate the assertion of similarity, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the limited technical novelty compared to previous works. It highlights the similarity of the paper\"s approach to graphbased methods, coattention mechanisms, and architectures, which are discussed in the mentioned papers. This feedback is valuable as it points out a potential area for improvement, suggesting that the authors should differentiate their work more effectively from existing literature. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as by emphasizing unique contributions or expanding on the novelty of their approach. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that while it mentions the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment suggests that the paper should explore why GPTgenerated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the need for further analysis and solutions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the handling of rumors generated by GPT, specifically noting that the paper mentions the challenges of detecting such rumors but lacks further analysis or solutions. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the issue of the difficulty in detecting GPTgenerated rumors compared to natural ones, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting GPTgenerated rumors compared to natural rumors, suggesting that the paper should provide further analysis or solutions. However, it does not offer any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while it acknowledges the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions to address this issue. The comment questions why GPTgenerated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. This feedback highlights an area where the paper could be strengthened by offering more detailed analysis or proposing potential solutions. However, the comment lacks specific suggestions or guidance on how to address the issue, making it 3 as it points out a need for further exploration but does not provide actionable steps for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the font size in Figure 6 is small, which could be a minor issue. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the font size or what specific changes are needed. Without actionable steps, the authors are left without a clear path to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the font size in Figure 6, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the font size in Figure 6 is small. While this is a factual observation, the comment does not provide any reasoning, examples, or references to support why this is a significant issue or how it affects the paper. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with the font size in Figure 6, which could affect the readability of the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue or improve the figure. The comment is vague and does not provide actionable feedback, making it 2. The authors are left without a clear understanding of how to resolve the issue or what steps to take to enhance the presentation of their work. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the comparison. The comment lacks concrete guidance on how to improve the draft or what specific actions the authors should take. As a result, the comment is 1, as it does not provide the authors with any direction or steps to follow to improve their work.", "grounding_specificity_rationale": "The comment questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. Without this context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific guidance on how to address the issue or what changes might be necessary. Therefore, the comment is 1 and lacks specificity, making it unsuitable for the authors to improve their draft. The comment is rated as 1 and Not Specific.", "verifiability_rationale": "The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. This is a pertinent issue that could affect the interpretation of the results and the overall conclusions of the paper. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or what changes could be made to the comparison. Without actionable advice or detailed reasoning, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it identifies a potential weakness but lacks depth and guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether the mono tonic relationship imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. However, the comment does not provide explicit guidance on how the authors should address this question or what specific aspects of the relationship need to be explored. The action is implicit and vague, as it does not specify how the authors should investigate or discuss the possibility of replacing the mono tonic relationship. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the training process, particularly the imposition of a monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It references a specific paper 1 to support the claim about the Pareto Front. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. It is specific in detailing the question about whether the monotonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the monotonic relationship imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. The comment references a specific paper 1 to support the idea of learning the Pareto Front with hypernetworks. However, the reasoning provided is somewhat vague, as it does not offer detailed explanations or examples of how this replacement could be achieved or why it might be beneficial. The reference to the paper is helpful but lacks depth in explaining the implications or providing specific guidance. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a question about the monotonic relationship imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. It references a specific paper 1 to support the idea of learning the Pareto Front with hypernetworks. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might explore or address this issue. While it identifies a potential area for improvement, it does not offer actionable advice or detailed insights that would help the authors enhance their work. Therefore, the comment is 2, as it provides a starting point for discussion but lacks the necessary depth and guidance to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the clarity of the paper\"s goal in the introduction and suggests that the examples provided do not effectively convey the need for interprocess communication. It also offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. While the comment provides a clear action\u2014improving the clarity of the introduction and suggesting specific areas for focus\u2014it does not offer detailed guidance on how to achieve this. The suggestion is concrete but lacks specific steps or examples, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the paper\"s goal in the introduction, suggesting that the examples provided do not effectively convey the need for interprocess communication. It also offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. However, the comment does not specify which part of the introduction or the paper this issue is discussed, making it weakly grounded. The comment is specific in its critique of the examples and suggestions for improvement, but without explicit references to sections or figures, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the paper\"s goal in the introduction and suggests that the examples provided do not effectively convey the need for interprocess communication. It offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. However, the comment lacks detailed reasoning or examples to support the claim that the current examples are insufficient. It does not provide specific references or detailed explanations to justify the suggestion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper\"s goal in the introduction, which is a significant issue for readers trying to understand the paper\"s purpose. It provides a specific suggestion for improvement by recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This feedback is actionable and constructive, as it offers a clear direction for the authors to enhance the clarity and relevance of their work. However, the comment could be more helpful if it included additional examples or detailed reasoning to support the suggestion. Overall, the comment is 4, as it provides valuable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that the hyperlinks for footnote 3 and 4 are not working. This is a clear and explicit action that the authors can take to address the issue. The comment provides specific information about which parts of the paper need correction, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the hyperlink functionality, providing a clear direction for improvement. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is factual and does not contain any subjective opinions or claims. It simply states that the hyperlinks for footnote 3 and 4 do not work. As it is a factual observation without any additional reasoning or references, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific issue with the hyperlink functionality in the paper, noting that the hyperlinks for footnote 3 and 4 do not work. This is a clear and actionable feedback that the authors can easily address by ensuring the hyperlinks are functional. The comment is specific and provides a direct suggestion for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should revise the discussion, particularly in the modeling section, as it is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is explicit in its suggestions and provides concrete details on how the authors can improve the discussion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests revising the discussion, especially in the modeling section, which is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is fully grounded as it explicitly mentions the modeling section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, such as the need for better formalization and clarification of the Label Embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the discussion, particularly in the modeling section, is not clear enough and needs revision. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is 4 as it offers clear reasoning and examples to support the claim, but it could be strengthened by providing more detailed references or additional context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and completeness of the discussion, particularly in the modeling section. It suggests that the discussion is not clear enough and offers concrete examples for improvement, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is 4 as it identifies areas for improvement and provides actionable suggestions, but it could be more comprehensive if it included additional guidance on how to address these issues. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the description of the neural network is hard to understand, but it also indicates that the final paragraph of the section clarifies it. The comment implies that the authors should consider starting the section with this clearer explanation. However, the action is implicit, as the authors need to infer that they should start the section with the final paragraph. The action is also somewhat vague, as it does not provide specific guidance on how to integrate the clearer explanation into the beginning of the section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number (528), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is: the description of the neural network is hard to understand, and suggests that the final paragraph of the section clarifies it. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand, suggesting that the final paragraph of the section clarifies it. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that the final paragraph of the section clarifies it. It suggests that the authors consider starting the section with this clearer explanation. This feedback is actionable and provides a clear direction for improvement, as it guides the authors to enhance the clarity and flow of their paper. However, the comment could be more helpful if it offered additional suggestions or examples of how to improve the clarity of the description. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that empowers the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. While it implies that the authors should consider this possibility, it does not provide explicit guidance on how to implement or explore this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the comment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is relevant or beneficial. The comment lacks depth and does not offer a clear justification for the proposed change, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to implement or explore this idea. The comment lacks depth and does not offer actionable advice, making it 3. The authors are left to infer the exact steps needed to address the comment, which limits its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While the comment implies that the current division might be redundant or unnecessary, it does not provide explicit guidance on how the authors should revise the tables or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the need for a change and the exact nature of that change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252)\" and the specific issue regarding the division of tables. It clearly specifies what part of the paper is being addressed, allowing the authors to accurately identify the section. The comment is also specific because it questions the necessity of dividing tables into three types, suggesting that one type (the column header) might suffice. This provides a clear direction for the authors to consider and potentially revise their table structure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should work. However, it does not provide any evidence, reasoning, or references to support this claim or suggestion. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While it identifies a potential issue with the current table structure, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, as it does not offer specific advice on how to revise the tables or what changes might be necessary. Without concrete suggestions or examples, the authors are left without a clear path to improvement, making the comment 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not provide explicit guidance on which other methods should be included or how they might impact the results. The comment implies that the authors should consider expanding their evaluation to include a broader range of attack methods, but it lacks concrete suggestions or detailed instructions on how to do so. As a result, the authors are left with a vague idea of what to improve, making the comment 3.", "grounding_specificity_rationale": "The comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not specify which other methods should be included or why they are relevant. The comment lacks grounding as it does not mention specific sections, tables, or figures of the paper that address the issue. It is also not specific because it does not provide detailed reasoning or examples of why other attack methods should be considered. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not provide specific examples or references to support the claim that these other methods are not suitable or relevant. The comment lacks detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 2, as it is somewhat supported but lacks sufficient detail or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. While it identifies a potential area for improvement, it does not provide specific examples of other attack methods that could be relevant or explain why the current methods are insufficient. The comment lacks actionable guidance on how the authors might address this issue, such as suggesting additional methods or providing references to relevant literature. As a result, the feedback is 3, as it points out a potential weakness but does not offer detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods used in the paper, suggesting that they might affect the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might investigate or mitigate this issue, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It mentions \"mitigation methods affect the image generation capabilities of diffusion models,\" but it does not provide context or references to specific sections, tables, or figures. The comment is also not specific because it does not detail what aspects of the mitigation methods or image generation capabilities are problematic. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains unsubstantiated, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they might affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. It lacks actionable advice, making it difficult for the authors to take meaningful steps to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure fair comparisons. The action is implicit and vague, as it does not specify how the authors can mitigate the risk of information leakage or how they should adjust their comparisons to account for this concern. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the comparisons with existing SSL methods. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique, the absence of explicit references to the paper\"s sections or content limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the comparisons are unfair. Without concrete evidence or examples, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is barely verifiable, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk that the pretrained visual model and target dataset might leak additional information, skewing results and leading to unfair comparisons. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure fair comparisons. While it identifies a critical concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is 3, as it points out a significant issue but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit suggestions for improvement or clarification. The authors are left without guidance on how to address this observation or what might be causing it. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the reviewer is referring to, such as a specific section or figure. It is also not specific because it does not provide details on what is surprising or how the dominance of function words over content words might be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which is followed by a question about the reviewer\"s understanding. While the observation is based on a subjective interpretation of the content, it lacks specific examples or references to support the claim. The comment does not provide a clear reasoning or evidence to justify the reviewer\"s surprise, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which is followed by a question about the reviewer\"s understanding. While the comment highlights an interesting aspect of the content, it does not provide specific feedback or suggestions on how this observation might be addressed or clarified. The authors are left without actionable guidance on how to improve the clarity or understanding of the content. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds should be used as a baseline, and it recommends using the minimal kmeans objective over multiple seeds instead. While the suggestion is clear and provides a specific reason for the change, it does not offer detailed guidance on how to implement this change or what specific aspects of the current baseline should be modified. The action is explicit but somewhat vague, as it lacks concrete steps for the authors to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the average of kmeans objectives with multiple seeds should be used as a baseline, and it recommends using the minimal kmeans objective over multiple seeds instead. It also provides references to support the suggestion. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its suggestion and references, but the lack of grounding makes it difficult for the authors to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds should be used as a baseline, and it recommends using the minimal kmeans objective over multiple seeds instead. The comment provides references to support this suggestion, specifically citing two papers that discuss the use of minimal kmeans objectives. This provides a clear rationale and evidence for the claim, making it 4. However, the comment could be more robust if it included a brief explanation of why the minimal objective is more reasonable or provided additional context. Overall, the claim is wellsupported, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a minor suggestion for improving the baseline used in the paper by recommending the use of the minimal kmeans objective over multiple seeds instead of the average. It also includes references to support the suggestion, citing two relevant papers that discuss the use of minimal kmeans objectives. While the comment is specific and provides a clear rationale for the change, it lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of the current baseline should be modified. The feedback is 3 as it directs the authors towards a more robust baseline, but it could be more comprehensive with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions (2.a and 2.b) that require clarification and explanation from the authors. It highlights a potential confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly concerning the regularization term H. The comment explicitly asks for clarification on how temperature calibration is applied after training and why reducing entropy is considered against the paper motivation. While the actions are clear and explicit, the comment lacks concrete guidance on how the authors should address these questions or provide additional context. Therefore, the comment is 3, as it provides clear directions but does not offer detailed steps on how to implement the suggestions. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to uncertainty calibration and the regularization term H, referencing lines 155160 and 133136. It provides detailed questions and suggestions for clarification, making it fully grounded as the authors can accurately identify the sections being discussed. The comment is also specific, as it clearly specifies what needs to be clarified regarding the relationship between temperature calibration and uncertainty calibration and why reducing entropy is considered against the paper motivation. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises two questions about the relationship between temperature calibration and uncertainty calibration, specifically regarding the regularization term H. It questions the independence of these processes and the rationale behind applying temperature calibration after training. The comment also critiques the motivation for calibrating networks, suggesting that reducing entropy might contradict this motivation. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3 as it provides some context but lacks depth and specific examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two specific questions about the relationship between temperature calibration and uncertainty calibration, particularly concerning the regularization term H. It highlights a potential confusion regarding the application of temperature calibration after training and critiques the motivation for calibrating networks, suggesting that reducing entropy might contradict this motivation. The comment is 4 as it identifies areas where the authors need clarification and provides a clear direction for addressing these issues. However, it could be more helpful if it offered additional guidance or suggestions on how to resolve these concerns. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, which implies that the authors need to address this in their draft. However, the comment does not provide explicit guidance on how to incorporate this discussion or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of the relationship between their work and Lista. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unrolling\" and provides a link to a specific paper, \"Lista,\" which is relevant to the topic. It also specifies that the paper should discuss the similarities and differences between the proposed work and Lista, indicating what needs to be addressed. This provides clear guidance on which part of the paper should be revised and what specific content is missing. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista. However, the comment lacks detailed reasoning or examples to support the claim that the omission is significant or how it impacts the paper\"s context. Without specific evidence or examples, the claim is 3, as it provides a basis for improvement but lacks depth. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista,\" which is crucial for contextualizing the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to integrate this discussion into the draft or what aspects of the comparison should be emphasized. While it offers a clear direction for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is explicit and provides a clear action for the authors to take, which is to define the FLOT cost matrix in the paper. The comment is concrete as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of definition for the FLOT cost matrix in Algorithm 1. This provides the authors with a clear understanding of what needs to be addressed to improve the paper.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is clear and actionable, as it directly points out a missing element that needs to be addressed for the paper to be complete and understandable. By defining the FLOT cost matrix, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define the cost matrix effectively. Overall, the comment is 3 as it highlights a crucial aspect that needs attention, but it lacks depth in terms of guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use the structural connections between the brain and body. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not specify how the authors should address this issue or what changes they should make to the paper. Without further guidance, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity\" and its potential misleading use. It clearly specifies what the issue is, namely that the term is not using structural connections between the brain and body. This provides the authors with a clear understanding of the part of the paper that needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not use structural connections between the brain and body. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use structural connections between the brain and body. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the paper. Without actionable feedback or detailed examples, the authors may find it challenging to understand the implications of the comment or how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It also directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that the authors should address these issues in that section. However, the comment does not provide explicit guidance on what specific aspects of the paper need improvement or how to address the issues mentioned. The action is implicit and somewhat vague, as the authors are left to infer the exact areas that require attention. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which provides some grounding by indicating where the issues might be discussed. However, the comment does not specify which parts of the paper are missing details or require improvement, making it weakly grounded. The comment is specific in identifying the areas where the paper needs improvement, such as clarity, quality, novelty, and reproducibility, but it lacks detailed guidance on what specific issues need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that the authors should address these issues in that section. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is missing details or lacks polish. Without concrete examples or references, the authors may find it challenging to understand what specific aspects need improvement. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not polished and lacks polish, with missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that the authors should address these issues in that section. However, the comment lacks specific guidance on what aspects of the paper need improvement or how the authors might address these issues. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps, making it 3. The feedback is valuable but could be more comprehensive and detailed to fully assist the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to state how they handle comparisons between episodes with different lengths, providing a clear and concrete action to take. It also highlights a specific issue with the lack of a normalization factor in the distance calculation, which could bias the results towards longer trajectories. The comment is fully grounded as it directly references the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. The action is explicit and concrete, providing detailed guidance on how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with how comparisons between episodes with different lengths are handled, including the method used (padding) and the potential bias introduced by the lack of a normalization factor. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths, specifically mentioning that the authors pad shorter sequences by replicating their last state. It also highlights a potential issue with the lack of a normalization factor of 1/T, which could bias the results towards longer trajectories. The comment provides specific details about the method used and the potential bias, making it 4. However, it could be strengthened by including examples or references to support the claim about the bias. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on a critical aspect of the paper. It identifies a potential issue with how comparisons between episodes with different lengths are handled, noting that the authors pad shorter sequences by replicating their last state. The comment also points out a potential bias introduced by the lack of a normalization factor of 1/T, which could favor longer trajectories. This feedback is valuable as it directs the authors to clarify their methodology and address a potential flaw in their approach. By providing concrete suggestions and highlighting specific areas for improvement, the comment empowers the authors to enhance the clarity and robustness of their work. Therefore, this comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should mention a specific detail in SI 6.5 regarding the evaluation process, noting that it is slightly different from the evaluation in Mnih et al. 7 due to the absence of human starts. This comment provides an explicit action for the authors to take, which is to include this detail in their supplementary information. The action is concrete as it specifies exactly what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and detailed explanation of the difference in evaluation methodology compared to Mnih et al. 7, specifying that no human starts are used. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should mention a specific detail in SI 6.5 regarding the evaluation process, noting that it is slightly different from the evaluation in Mnih et al. 7 due to the absence of human starts. This claim is 3 as it provides a clear rationale for why the authors should include this detail, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional context or references to strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to improve their draft. It points out a detail in SI 6.5 that needs to be mentioned, namely that the evaluation process is slightly different from that in Mnih et al. 7 due to the absence of human starts. This feedback is clear and directly addresses a specific aspect of the paper, offering a concrete improvement that the authors can easily implement. The comment is 4 as it provides a clear direction for enhancing the draft, but it could be more comprehensive if it suggested additional areas for improvement or elaborated on the implications of this change. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. The comment implies that the authors should include such metrics to substantiate their claims of efficiency. However, the action is implicit, as the authors need to infer that they should report metrics to demonstrate efficiency. The action is also somewhat vague, as it does not specify which metrics should be reported or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the advantages of their proposed method over previous work in terms of efficiency. This allows the authors to accurately identify the section being addressed. The comment is also specific because it points out a lack of reporting of metrics that would demonstrate the efficiency of the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not report any metric that shows the proposed method is more efficient to train compared to previous work. This claim is 3 as it highlights a gap in the paper\"s reporting of efficiency metrics. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand exactly what metrics are missing or how to address this issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any metrics to support this claim. This feedback is clear and actionable, as it directs the authors to include specific metrics that would substantiate their claims of efficiency. By addressing this gap, the authors can strengthen the evidence supporting their claims and enhance the credibility of their work. The comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive if it suggested specific types of metrics or how to present them effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point requests the authors to provide more details about the statespace, actions, and the space of theta. While the authors can infer that they need to clarify these aspects, the comment does not explicitly instruct them to do so. The request for more details is clear, but the action of providing these details is implicit and could be more explicit. Therefore, this comment is 3, as it provides a clear direction but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, L81, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the details about the statespace, actions, and the space of theta. The request for more details is clear and specific, making this comment 5.", "verifiability_rationale": "The review point requests more details about specific aspects of the paper, such as the statespace, actions, and the space of theta. While the request is clear and specific, it does not provide any evidence or reasoning to support why these details are important or how they impact the paper. The authors are left to infer the significance of these details, which makes the comment 3. However, without additional context or justification, the claim is not 5.", "helpfulness_rationale": "The review comment is 3 as it identifies specific areas where the authors could provide more details, such as the nature of the statespace, actions, and the space of theta. This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of these aspects. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, particularly for benchmarks using IoUbased metrics like KITTI and Waymo. It also critiques the use of colorizationbased pretraining, arguing that it primarily learns semantics and may not be suitable for object detection, which requires accurate locations and poses. However, the comment does not provide explicit guidance on how the authors should implement these suggestions or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, particularly for benchmarks using IoUbased metrics like KITTI and Waymo. It also critiques the use of colorizationbased pretraining, arguing that it primarily learns semantics and may not be suitable for object detection, which requires accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream tasks or the use of colorizationbased pretraining. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its critique of the choice of tasks and pretraining methods, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the choice of object detection as the downstream task, suggesting that LiDARbased segmentation might be a better choice, especially for benchmarks using IoUbased metrics like KITTI and Waymo. It also questions the effectiveness of colorizationbased pretraining for object detection, arguing that it primarily learns semantics and may not be suitable for tasks requiring accurate locations and poses. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the critique. The feedback is 3 as it provides a rationale but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the choice of object detection as the downstream task, suggesting that LiDARbased segmentation might be a more suitable alternative, particularly for benchmarks using IoUbased metrics like KITTI and Waymo. It also questions the effectiveness of colorizationbased pretraining for object detection, arguing that it primarily learns semantics and may not be suitable for tasks requiring accurate locations and poses. While the comment identifies potential areas for improvement and offers a rationale for reconsidering the choice of downstream tasks, it lacks specific guidance on how the authors might address these concerns or what changes could be made to their draft. The feedback is 3 as it provides a basis for discussion but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue, such as suggesting alternative notations or clarifying the usage of $p$. The action is implicit and vague, as the authors are left to infer that they need to make the notation clearer. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using $p$ to denote both the phase mixing probability and a dummy variable in Algorithm 1 could be confusing. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion might arise or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. While the comment highlights a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice, making it difficult for the authors to fully benefit from the comment. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include additional benchmarking tasks outside of AitW. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors on how to implement this suggestion. The action is implicit, as the authors would need to infer that they should add more benchmarking tasks to their draft. However, the comment lacks specific guidance on which tasks to include or how to integrate them effectively. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which tasks should be included or how they should be integrated into the paper. This lack of specificity makes it difficult for the authors to understand exactly what needs to be addressed. The comment is 1 as it does not mention specific sections or parts of the paper that would benefit from additional benchmarking tasks. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should include additional benchmarking tasks outside of AitW. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The comment suggests that the authors should include additional benchmarking tasks outside of AitW, which could enhance the comprehensiveness and robustness of their work. However, the comment lacks specificity, as it does not specify which tasks should be included or how they should be integrated into the paper. This makes it 3, as it provides a general direction for improvement but does not offer detailed guidance or actionable steps for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. It suggests that the authors should clarify the use of the name or provide a different label. However, the comment does not specify how the authors should address this issue, such as by providing a detailed explanation of the differences or suggesting an alternative label. The action is implicit and vague, as it does not provide concrete guidance on how to implement the suggested changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the naming of \"PointNet\" in the context of the referenced paper, which is not present in the current paper. The comment provides a clear and detailed explanation of the confusion and suggests a specific reference for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. The comment provides a specific reference to \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi et al., which helps the authors understand the issue and potentially address it. However, the comment does not offer additional reasoning or examples to fully support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the naming of \"PointNet\" in Figure 1, noting that the name is used in another paper that is not referenced in the current work. The comment provides a clear reference to the paper with the same name, which helps the authors understand the confusion and potentially address it. However, the comment could be more helpful by suggesting specific actions the authors could take, such as clarifying the use of the name or providing an alternative label. While it offers some guidance, the feedback is 4 as it directs the authors to a potential issue and provides a reference for further clarification, but it lacks depth in suggesting comprehensive improvements. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This suggests that the authors should clarify the relationship between the equations. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects need clarification. While it implies that the authors should clarify the equations, the action is not concrete, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This part of the comment is fully grounded as it explicitly mentions the equations, allowing the authors to accurately identify the section being addressed. However, the comment does not specify what needs to be addressed in this part, such as clarifying the relationship between the equations or providing additional context. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This is a subjective opinion or critique of the paper\"s content, as it expresses a concern about the clarity and correctness of the equations. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the policy gradient in Equation 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Equation 5. This feedback highlights a potential area of confusion or lack of clarity in the paper, suggesting that the authors should clarify the relationship between the equations. However, the comment does not provide specific guidance or suggestions on how to address this issue, leaving the authors with limited actionable feedback. The minor comments about Line 78 and Line 132 are also brief and lack depth, further limiting their helpfulness. Overall, the comment identifies a potential area for improvement but does not offer comprehensive or detailed advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of the general Gaussian distribution versus the isotropic Gaussian distribution in the proposed algorithm. It asks for clarification on the difference between these two assumptions. While the comment prompts the authors to consider this assumption, it does not provide explicit guidance on how to address it or what changes might be necessary. The action is implicit, as the authors need to infer that they should explore the implications of this assumption and potentially discuss it in their paper. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the clarification is needed. While the comment is specific in its inquiry about the difference between the two assumptions, the absence of explicit grounding limits the authors\" ability to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective opinions, critical judgments, or suggestions for improvement. The comment is purely factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It prompts the authors to consider the implications of this assumption and asks for clarification on the difference between the two. While the comment identifies a potential area for improvement by questioning the assumption, it does not provide specific guidance or suggestions on how to address this issue. The feedback is 3 as it highlights a potential area for further discussion or clarification, but it lacks depth and actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide explicit guidance on how to implement this discussion or what specific aspects of the partitioning strategy should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors discuss the limitations of freezing the partitioning in the first iteration. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the assumption of coverage in the first iteration of partitioning. It suggests that this choice might be risky and recommends that the authors discuss the limitations of this approach. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. However, the comment could be more helpful if it offered additional guidance on how to discuss the limitations or what aspects of the partitioning strategy should be considered. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment implies that the authors should provide a justification for their decision, it does not explicitly instruct them to do so or offer specific guidance on how to explain the choice. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a rationale for their decision. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies the issue: the decision to use early stopping only by link prediction accuracy and questions why it was not averaged with type accuracy. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. However, the comment does not provide any specific reasoning, examples, or references to support why averaging with type accuracy would be a better approach. Without additional justification or evidence, the claim remains 3, as the authors are left to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific point of concern regarding the decision to use early stopping based solely on link prediction accuracy. It questions the rationale behind this choice, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it points out a potential weakness in the methodology, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was performed. This feedback is explicit, as it directly instructs the authors to include more information about the pruning process. However, the action is somewhat vague because it does not specify exactly what details need to be added or how the pruning process should be described. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the lack of detail in explaining how the ground truth of sensitivity is achieved, specifically mentioning the absence of information on the pruning process. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was performed. This feedback is clear and specific, as it identifies a missing element in the explanation. However, it does not provide any additional context or references to support the claim, which could make it slightly less verifiable. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area where the authors lack detail, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide sufficient information on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more details about the methodology used to estimate sensitivity. However, the comment could be more helpful if it provided specific examples or guidance on how to describe the pruning process. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing guidance on how to improve the method. The feedback lacks concrete steps or suggestions, making it difficult for the authors to address the critique effectively. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section being addressed. While the critique provides some specificity regarding the approach and its reliance on FEniCS, it lacks full grounding as it does not explicitly mention the section or part of the paper being discussed. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide references or detailed explanations to support the assertion that the proposed approach is merely learning a surrogate model. This makes the claim 3, as it provides a general critique but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide specific suggestions or actionable feedback on how the authors could improve their approach or address the identified limitations. It lacks depth and specificity, making it difficult for the authors to understand the exact areas that need improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer clear guidance or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific feedback on the clarity of a paragraph (L156166) and suggests that the authors should clarify the use of bandit algorithms and the explanation of the Gittins strategy. It also points out that the figure is hard to understand and that the explanation of dashed lines is vague. While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to clarify these sections or provide concrete guidance on what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper (L156166), allowing the authors to accurately identify the part being addressed. It also provides specific feedback on the clarity of the paragraph, the use of bandit algorithms, the explanation of the Gittins strategy, and the difficulty in understanding the figure. The comment is specific in detailing what needs to be clarified or improved, such as the explanation of bandit algorithms and the vagueness of the figure\"s explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph is barely understandable, despite the reviewer\"s expectation that they understand what is being said. It also critiques the use of bandit algorithms, specifically mentioning the Gittins strategy and the Markov chain nature of posterior evolution. The comment highlights the difficulty in understanding the figure, noting that the explanation of dashed lines is vague. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the basis for the critique, which limits the verifiability of the claim.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity of a paragraph (L156166), noting that it is barely understandable despite the reviewer\"s expectation of comprehension. It identifies issues with the explanation of bandit algorithms, particularly the Gittins strategy and the Markov chain nature of posterior evolution, suggesting that the authors should clarify these concepts. Additionally, the comment points out that the figure is hard to understand, specifically mentioning the vagueness of the explanation regarding dashed lines. While the comment highlights areas for improvement, it lacks detailed guidance on how to address these issues or provide concrete suggestions for clarification. The feedback is 3 as it directs the authors to specific areas that need improvement, but it could be more comprehensive with additional guidance on how to enhance the clarity of the paragraph and the figure."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to resolve the issue or enhance the applicability of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the bounds, the absence of explicit references to the paper\"s sections or elements makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of a certain approach have o(1) terms and improve over previous results for arbitrarily long inputs, but it does not provide any specific evidence or reasoning to support this claim. Without detailed explanations or references to the specific work being discussed, the authors are left without a clear understanding of the basis for this critique. This lack of support makes the claim 1, as the authors cannot determine the validity of the assertion or how it relates to their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide any suggestions or guidance on how to address this issue or enhance the applicability of the approach. The comment lacks actionable advice, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with varying lengths. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what needs to be improved in the paper. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths, but it does not provide any specific claims, opinions, or suggestions. It is a question that prompts further exploration and analysis but does not offer any guidance or feedback that would help the authors improve their work. Therefore, it is classified as \"No\" because it lacks any claim or suggestion that requires verification.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths, which could be a valuable point for further exploration and analysis. However, it does not provide any specific suggestions or feedback on how the authors might address this question or what improvements could be made to their draft. The comment lacks actionable guidance and depth, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion or clarify the distinction in their draft. The action is implicit, as the authors would need to infer that they should clarify the target queries in the introduction or methodology sections. However, the lack of specific guidance on how to clarify the distinction makes the action vague and somewhat challenging to implement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. However, it does not specify which part of the paper this confusion pertains to, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the type of cloze queries targeted, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential confusion regarding the paper\"s focus on singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential area of ambiguity, it does not provide specific suggestions or guidance on how the authors might clarify this distinction in their draft. The feedback is 3 as it points out a potential issue that could affect the clarity of the paper, but it lacks actionable advice on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work 1. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to strengthen the connection between Section 2 and the methodology section and expand the theoretical analysis to include more depth and novelty. The lack of specific actions or detailed suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2\" and \"the methodology section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the limited connection between these sections and the simplicity of the theoretical analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work 1. While the comment provides a general assessment, it lacks specific examples or detailed reasoning to substantiate these claims. The authors are left to infer the nature of the connection and the level of simplicity, which makes the claim 3. To enhance the comment\"s verifiability, the authors could provide more detailed explanations or examples of the connection and the specific aspects of the theoretical analysis that are considered simplistic.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the authors should strengthen this link. It also points out that the theoretical analysis is somewhat simplistic and closely related to a specific work 1, indicating a need for more depth and novelty. While the comment highlights areas for improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is 3 as it directs the authors to areas that require attention, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. While the comment implies an action, it does not explicitly instruct the authors to provide a detailed discussion or analysis of these situations. The action is somewhat vague, as it leaves the authors to infer that they need to expand on the discussion of the losses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests further discussion or exploration of which situations the losses help, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the role of losses in particular situations, such as specular areas. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. This feedback is 3 as it points out a potential area for additional discussion that could enhance the paper\"s depth and clarity. However, the comment lacks specificity and does not provide detailed guidance on how to address this suggestion, leaving the authors with limited actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights two specific issues with the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. While the comment identifies these areas, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the determination of n_t and provide a more precise definition of \"appropriate number.\" This lack of explicit action makes the comment 3, as it points out areas needing improvement but does not offer concrete steps for resolution. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses issues with Algorithm 2 and line 225, specifically regarding the determination of n_t and the ambiguity of \"appropriate number.\" It provides a clear reference to these parts of the paper, allowing the authors to accurately identify the sections being discussed. However, the comment does not specify what needs to be addressed in these sections, such as providing a method for determining n_t or clarifying the meaning of \"appropriate number.\" This makes the comment weakly grounded but specific, as it identifies the areas needing attention but lacks detailed guidance. Therefore, it aligns with category 3.", "verifiability_rationale": "The review point raises questions about the determination of n_t in Algorithm 2 and the meaning of \"appropriate number\" in line 225. It does not contain any subjective opinions or claims that require verification. The comment is factual and descriptive, as it points out specific areas where clarification is needed. However, it lacks detailed reasoning or references to support the claims, making it 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. While the comment points out these areas, it does not provide any suggestions or guidance on how the authors might address these issues. Without actionable advice or examples, the authors are left without a clear path to improvement, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reproducibility of the results, questioning whether the code will be publicly available. While it identifies a potential issue, it does not provide any explicit or implicit suggestions on how the authors might address this concern. The comment lacks concrete guidance on what steps the authors should take to ensure reproducibility, such as suggesting specific practices for sharing code or providing detailed documentation. As a result, the authors are left without a clear understanding of how to improve their draft to address this issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the reproducibility issue, such as recommending specific practices for sharing code or providing detailed documentation. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific details or examples that would help the authors understand the issue or how to address it. Without additional context or justification, the claim remains 1, making it difficult for the authors to address the concern effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. This is a critical issue for scientific research, as reproducibility is essential for validating findings and ensuring the reliability of the work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific practices for sharing code or providing detailed documentation. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a significant concern but lacks depth and guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the claim that \"in practice the mixing time is even better\" and argues that this claim is not sufficiently supported by the experiments. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or strengthen their evidence. The comment lacks explicit instructions on what actions the authors should take to improve their draft, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about \"mixing time\" and its support by experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, stating that the evidence provided is insufficient. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the reviewer\"s assertion remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. This feedback is clear and actionable, as it highlights a gap in the evidence provided to practitioners. However, the comment could be more helpful if it suggested specific ways the authors could strengthen their evidence or provide additional experimental results. Despite this, the comment offers valuable guidance for improving the paper, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. It implies that the authors should consider this extension, but it does not explicitly instruct them to do so or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should extend the feature and understand the implications of such an extension. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not offer any justification or reasoning for why this extension is necessary or beneficial. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. This feedback is specific and actionable, as it offers a clear direction for the authors to consider in their work. By suggesting a potential extension, the comment provides a concrete idea for improvement, which could enhance the depth and comprehensiveness of the paper. However, the comment could be more helpful if it included additional context or reasoning behind why this extension is beneficial. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semisupervised learning, specifically selftraining methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the novelty of their method or what specific aspects need to be clarified or differentiated from existing methods. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semisupervised learning, specifically selftraining methods. However, it does not specify which part of the paper this concern relates to, such as a particular section or method description. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the method\"s novelty, the absence of grounding information limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semisupervised learning, specifically selftraining methods. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or examples, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semisupervised learning, specifically selftraining methods. While the comment identifies a potential issue with the novelty of the method, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their approach. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should include these two relevant papers in their comparison, but it does not specify how to do so or what aspects of the comparison should be addressed. Without concrete guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the issue of a shallow comparison, it lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison section, noting that it is shallow and lacks two relevant papers. This feedback is clear and actionable, as it directs the authors to address the comparison by including the missing papers. However, the comment could be more helpful if it provided suggestions on how to integrate or discuss these papers effectively. Overall, the comment is 3 as it highlights a critical area for improvement, but it lacks depth in terms of actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This provides a clear and explicit action for the authors to take, as they need to review their usage of the word and ensure that it is appropriate and accurate. The comment is specific in its suggestion and provides concrete guidance on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the usage of the word \"equivalent\" is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" especially if the equivalence is not verified. This provides clear guidance on how the authors should revise their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This is a subjective observation and does not provide specific examples or references to support the claim. While it implies a potential issue, it lacks detailed reasoning or evidence to fully substantiate the concern. Therefore, the comment is considered 2, as it provides some indication of a potential problem but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their usage, especially if the equivalence is not verified. This feedback is clear and actionable, providing the authors with a specific area to review and improve their draft. By addressing this issue, the authors can enhance the accuracy and clarity of their writing. However, the comment could be more helpful if it provided additional guidance on how to verify the equivalence or suggested alternative terms. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the multiview clustering approach, specifically questioning why other views are useful if the paraphrase similarity view performs significantly better. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a detailed analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis, but without clear references to specific sections or figures, it is difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment lacks specific examples or references to support the claim that the other views are not useful. It does not provide a clear rationale or evidence to justify the need for a detailed analysis of the views. As a result, the claim is not wellsupported, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It highlights a gap in the analysis by noting that while one empirical example is provided, there is no further analysis of how the different clustering techniques differ or how they contribute to the overall understanding of the data. This feedback is 3 as it points out a specific area where the authors could enhance their analysis and provide a more comprehensive understanding of the different views. However, the comment could be more helpful if it offered suggestions or guidance on how to conduct this additional analysis, such as specific techniques or metrics to consider. Overall, the comment identifies a meaningful weakness in the paper, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that maintaining consistency would be beneficial. While the comment identifies a specific issue, it does not provide explicit guidance on how to achieve consistency or what steps the authors should take to address this. The action is implicit, as the authors would need to infer that they should ensure consistent formatting of these terms. However, the lack of concrete instructions on how to implement this change makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent typesetting and suggests a solution: maintaining consistency. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of BertScore and BLEURT throughout the paper, noting that they are inconsistently typeset as Bertscore or Bleurt. This observation is clear and actionable, as it points out a minor but noticeable inconsistency that could affect the readability and professionalism of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a specific formatting style or providing examples of consistent usage. While the feedback is 3, it lacks depth and could be more impactful with additional suggestions or guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question relates to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is 1 as it does not provide specific references or sections of the paper. Additionally, it lacks specificity as it does not detail what the authors should do to address this question or how it relates to the overall content of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how it relates to their work. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. While it raises a relevant question that could be explored further, it does not provide any specific guidance or suggestions on how the authors might address this question or what steps they should consider. The feedback is somewhat limited in its scope, as it lacks actionable advice or detailed insights into how the authors could improve their work based on this observation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the text in lines 293295 is unclear and difficult for readers to understand and evaluate. It suggests that the authors should clarify this section by providing more context or explanation. However, the comment does not specify how the authors should clarify the text or what specific aspects need to be addressed. The action is implicit and vague, as it requires the authors to infer the need for clarification and then decide how to implement it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the text in lines 293295, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the text is unclear and difficult for readers to understand and evaluate, suggesting that the authors should clarify the section by providing more context or explanation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 is unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the text is unclear or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it is unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should clarify this section by providing more context or explanation. While the feedback is specific about the problematic text, it lacks detailed guidance on how to improve the clarity or what specific aspects of the text need clarification. This makes the comment 3, as it provides a clear area for improvement but could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by incorporating experiments on realworld datasets. The comment is specific in its recommendation, detailing what kind of experiments would be beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. The comment is specific in its suggestion, as it clearly indicates what kind of experiments would be beneficial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This claim is 3 as it provides a logical reasoning for why realworld datasets might be more appropriate for evaluating the paper\"s claims. However, it lacks specific examples or references to support the suggestion, which could make it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by aligning the experiments with realworld scenarios. By recommending the use of realworld datasets, the comment addresses a potential gap in the paper\"s evaluation and suggests a way to enhance its practical relevance. However, the comment could be more helpful if it provided additional guidance on how to select or implement these experiments. Overall, the feedback is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to clarify the explanation or what specific aspects need to be improved. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. Additionally, the comment is vague and does not provide specific guidance on what needs to be addressed or improved. Therefore, it is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the explanation is vague or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the clarity of these explanations. Without additional details or constructive feedback, the authors are left without a clear path to address the identified issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. While the comment implies that this extension would be more interesting and practical, it does not provide explicit guidance on how to implement this extension or what specific aspects of the current study need to be addressed to make this extension feasible. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is also specific in that it suggests an interesting and practical extension to the study, but without grounding, the authors are left to make an educated guess about where to apply this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical suggestion that aligns with the idea of making the study more interesting and practical. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim is considered 2, as it lacks sufficient support to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical and interesting suggestion that could enhance the practicality and applicability of the study. However, the comment does not provide specific guidance on how to extend the study to multiple trucks and drones, nor does it offer any suggestions on how to implement this extension. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a direction for future work but lacks detailed guidance for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the consistency of the number of biases across different parts of the paper, specifically noting that the authors mention having C biases in section 3.4 but only find one hyperparameter for the feedforward models. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the discrepancy in the number of biases. The comment is specific in its request for clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a discrepancy in the number of biases mentioned in the text and the hyperparameter found in section 3.4, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the consistency of the number of biases mentioned in the text and the hyperparameter found in section 3.4. It suggests that the authors should clarify why they have C biases mentioned in the text but only one hyperparameter for the feedforward models described in section 3.4. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the number of biases is inconsistent. This lack of detailed explanation or evidence makes the claim 3, as the authors may need to infer the basis for the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper regarding the number of biases mentioned in the text and the hyperparameter found in section 3.4. It points out that the authors mention having C biases but only find one hyperparameter for the feedforward models described in section 3.4, which is confusing. This feedback is clear and actionable, as it directs the authors to clarify the discrepancy in the number of biases. By addressing this inconsistency, the authors can improve the clarity and consistency of their paper. The comment is 4 as it provides a specific area for improvement but could be more comprehensive if it suggested additional ways to enhance the clarity of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how to address these questions or what experiments to conduct to explore these effects. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it identifies areas that could be explored further, it does not provide specific suggestions or guidance on how to address these questions or what experiments to conduct. The feedback is 3 as it points out potential areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests showing smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any explicit guidance on how to implement this suggestion, such as which specific elements of the figures should be highlighted or how the smoothing process should be visualized. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5, which provides some grounding as it mentions specific figures. However, it does not specify which parts of the figures should be highlighted or how the smoothing process should be visualized, making the comment specific but not fully grounded. The lack of detail on what needs to be addressed in these figures makes it somewhat specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the understanding of the reconstruction quality. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. While this feedback is relevant and provides a clear direction for improvement, it lacks depth and specificity. The comment does not explain why showing these shapes is crucial or how it would enhance the understanding of the reconstruction quality. Additionally, it does not offer any guidance on how to effectively present these shapes or what aspects of the figures should be highlighted. As a result, the comment is 3, as it identifies an area for improvement but does not provide comprehensive or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the evaluation of the proposed approach by noting the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it does not provide explicit guidance on how to conduct a direct comparison of test accuracy. The action is implicit, as the authors are expected to infer that they need to include a direct comparison of test accuracy to demonstrate the improvement of the proposed approach over the baseline. However, the lack of concrete instructions on how to perform this comparison makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of direct comparisons with the prior approach PRANC in both language and vision tasks, and the lack of a direct comparison of test accuracy. This provides the authors with a clear understanding of what needs to be addressed to strengthen the evaluation of the proposed approach. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in either the language or vision tasks used to evaluate the proposed approach. However, the comment does provide some evidence by mentioning comparisons of training loss in Section 3.4 and a comparison of the rank of possible solutions in Section 3.5. While these comparisons are mentioned, they do not directly address the lack of a direct comparison of test accuracy, which is the core of the claim. The comment is 3 as it provides some evidence but lacks a clear and detailed explanation of why the absence of a direct test accuracy comparison is a significant issue. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it highlights the critical issue of the lack of a direct comparison of test accuracy, which is essential for demonstrating the improvement of the proposed approach over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or suggested additional metrics to consider. Overall, the comment is 4, as it effectively guides the authors to address a key limitation in their evaluation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the SCNN model\"s performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their model or presentation. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the SCNN model\"s performance on domain pricing, suggesting it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not specify which part of the paper discusses the SCNN model or the domain pricing results, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the concerns raised, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the SCNN model\"s performance on domain pricing, suggesting it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment lacks specific evidence or references to support these claims, making it difficult for the authors to verify the validity of the concerns. The feedback is 3 as it provides a basis for questioning the results but does not offer detailed reasoning or examples to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the SCNN model\"s performance on domain pricing, suggesting it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. While the comment identifies a potential issue with the model\"s performance, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their model. The feedback is 3 as it points out a potential area for further investigation, but it does not provide actionable steps or detailed explanations to enhance the authors\" understanding or improve their work. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or how the authors should address these issues. The comment lacks concrete actions or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which parts of the paper these issues relate to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific about the nature of the issues, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what specific issues need to be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity and motivation of the experimental setup, specifically mentioning corpora and datasets. However, it lacks detailed guidance or suggestions on how to address these issues. The comment is vague and does not provide actionable feedback, leaving the authors uncertain about what steps to take to improve the clarity and motivation of their experimental setup. As a result, the comment is 2, as it does not offer substantial assistance in enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It also notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is explicit and provides a clear action for the authors to take: they should provide more detailed information about the size of each hourglass module. However, the comment lacks specific guidance on how to measure or compare the size of the model, making it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This provides a clear reference to a specific part of the paper, allowing the authors to identify the relevant section. However, the comment does not specify what needs to be addressed in this part, such as how the model size compares to competing approaches or how the size of each hourglass module was determined. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This feedback is clear and provides a specific question that the authors should address to improve the clarity and completeness of their paper. However, it does not offer any additional context or justification for why this information is important or how it relates to the overall work. Therefore, the comment is 3, as it provides a clear question but lacks detailed reasoning or references to support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, particularly noting that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the model\"s architecture, which is crucial for understanding and replicating their work. However, the comment could be more helpful if it suggested specific ways to measure or compare the model size with competing approaches. Overall, the comment is 4 as it highlights a clear area for improvement and provides a direct suggestion for action, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it is not novel or better than existing theoretical results. It implies that the authors should consider how to improve the metric learning aspect of their work. However, the comment does not provide specific guidance on what changes or improvements could be made to address the identified issue. The action is implicit and vague, as the authors are left to infer that they need to enhance the metric learning section. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, referencing the generalization theory of neural networks and suggesting that the proposed metric perspective analysis does not offer better results compared to previous work. It also notes that the part of metric learning in the paper does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific in its critique of the metric learning aspect, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is not novel or better than existing theoretical results, referencing the generalization theory of neural networks. It suggests that the proposed metric perspective analysis does not yield better results compared to previous work. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of references or detailed explanations weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, noting that it is not novel or better than existing theoretical results. It suggests that the proposed metric perspective analysis does not yield better results compared to previous work, and that the part of metric learning in the paper does not seem to work. While the comment identifies a potential weakness in the paper\"s theoretical contribution, it lacks specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is 3 as it points out an area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a key experiment. It also recommends condensing the current figures to make space for these visual results. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on which figures to condense or which specific visual results to include. The action is somewhat explicit but could be more concrete. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, emphasizing the lack of visual results on crowd density estimation, a key experiment. It also recommends condensing the current figures to make space for these visual results. However, the comment does not specify which figures are being referred to or which visual results should be included. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its suggestion to include visual results on crowd density estimation, but the lack of explicit grounding makes it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, emphasizing the lack of visual results on crowd density estimation, a key experiment. It recommends condensing the current figures to make space for these visual results. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the main paper lacks visual results on crowd density estimation. While the suggestion is logical, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the organization of the paper, suggesting that visual results from the supplementary material should be moved to the main paper. It highlights the lack of visual results on crowd density estimation, a key experiment, and recommends condensing the current figures to make space for these visual results. This feedback is clear and actionable, as it directs the authors to improve the presentation of their results and enhance the clarity of their main experiment. However, it could be more helpful if it provided more detailed guidance on which figures to condense or which specific visual results to include. Overall, the comment is 4, as it offers valuable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not explicitly instruct the authors to change their dataset or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using WebQuestions and understand the reasoning behind the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not specify which part of the paper discusses the choice of the testbed dataset, making it difficult for the authors to identify the exact section being addressed. While the suggestion is specific, the lack of grounding makes it challenging for the authors to understand the context and apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. The reasoning provided is that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions is more intuitive or straightforward for weak supervision tasks. Without detailed reasoning or evidence, the claim is 3, as it provides a rationale but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of the testbed dataset, suggesting that the authors consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. The rationale provided explains that WebQuestions is more intuitive and straightforward for weak supervision tasks, which would facilitate direct comparison with mainstream QA research. This feedback is clear and actionable, as it provides a specific suggestion for improvement and offers a rationale for why the change might be beneficial. However, the comment could be more helpful if it included additional guidance on how to implement the change or why WebQuestionsSP was initially chosen. Overall, the comment is 4, as it provides valuable feedback that the authors can use to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It also implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or demonstrate the value of sparsity. The action is implicit and vague, as it does not specify how the authors should demonstrate the benefits of sparsity or what kind of evidence would be needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not specify which part of the paper discusses sparsity or training, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of sparsity and its relevance to training, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of making claims about sparsity in training, questioning whether it is obvious that sparsity is desirable. It suggests that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment lacks specific guidance on how the authors might demonstrate these benefits or what kind of evidence would be needed. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet1k, and ImageNet100. It implies that these results are important for verifying the effectiveness of the framework. However, the comment does not provide explicit guidance on how to present these results or what specific aspects of the framework should be analyzed on these datasets. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these results in the main paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet1k, and ImageNet100. It implies that these results are important for verifying the effectiveness of the framework. However, the comment does not specify which part of the paper should be addressed or provide detailed guidance on how to present these results. The authors cannot confidently determine which section or figure this comment refers to, making it weakly grounded. The comment is specific in suggesting the inclusion of results on these datasets, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet1k, and ImageNet100, to verify the effectiveness of the framework. This claim is 3 as it provides a clear direction for the authors to enhance their analysis. However, it lacks specific examples or references to support the suggestion, which could make it less robust. The authors would need to infer the need for additional results, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while improvements are shown on CIFAR derivatives, the analysis lacks results on other datasets, such as ImageNet derivatives, ImageNet1k, and ImageNet100. This feedback is valuable as it highlights an area where the authors could strengthen their evaluation of the framework\"s effectiveness. By suggesting the inclusion of these results, the comment provides a clear direction for improvement, though it could be more helpful if it offered specific guidance on how to present or analyze these results. Overall, the comment is 3, as it points out a specific area for enhancement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the initial mention of BigFive and MBTI as models in the Abstract and Introduction sections and their subsequent use as datasets in the Experiments section. It suggests that the authors should either extend their explanation for using these as models or consider stating them as datasets throughout the paper. While the comment identifies a specific issue and provides a clear direction for addressing it, it does not explicitly instruct the authors on how to extend their explanation or provide detailed guidance on how to revise the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the use of BigFive and MBTI as models in the Abstract and Introduction sections but inconsistently uses them as datasets in the Experiments section. It suggests that the authors should either extend their explanation for using these as models or consider stating them as datasets throughout the paper. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in detailing the inconsistency and suggesting a possible solution, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that BigFive and MBTI are used inconsistently as models and datasets throughout the paper. The comment suggests that the authors should either extend their explanation for using these as models or consider stating them as datasets throughout the paper. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the issue. Without detailed reasoning or evidence, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant inconsistency in the paper by pointing out that Big Five and MBTI are initially presented as models in the Abstract and Introduction but are later used as datasets in the Experiments section. This inconsistency raises concerns about the clarity and coherence of the paper. The comment suggests that the authors should either provide an extended explanation for using these as models or consider stating them as datasets throughout the paper. While the comment highlights a specific issue, it does not offer detailed guidance on how to address it or provide examples of how to revise the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential nuance in the initial claim, it does not provide explicit guidance on how the authors should address this issue or what specific features they should consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of different features on answer detection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. While the comment provides some specificity by mentioning the potential influence of features, it lacks full grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment provides a logical reasoning by pointing out the potential influence of specific features, it lacks detailed examples or references to support the claim fully. The authors are left to infer the exact nature of the influence and how it might be explored, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques a specific claim made in the paper, pointing out that the conclusion about the relationship between RC dataset readability and question difficulty might be influenced by the method or features used for answer detection. This feedback is 3 as it highlights a potential nuance in the initial claim, suggesting that the authors should consider the impact of different features on answer detection. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what additional experiments or analyses could be conducted to strengthen the paper. Overall, the comment offers a valuable critique but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how to improve the writing quality or address the issue of missing related work. The authors are left to infer that they need to revise the explanation of basic memory networks and the forward model to be more concise and that they should include more reinforcement learning tasks in the related work section. This lack of explicit and detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing quality or the related work section require improvement makes the comment weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically noting that the authors spend the same space on explaining basic memory networks and the forward model. It also mentions that the related work section has missing pieces on more reinforcement learning tasks. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of evidence or references weakens the verifiability of the claim, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the writing quality of the paper and the completeness of the related work section. It points out that the authors spend the same space explaining basic memory networks and the forward model, suggesting that the explanation could be more concise. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is 3 as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of replacing the first column of Qo with vo, which affects the reachability of the first state. It suggests that this change might impact the validity of Assumption 1, which concerns the finite length of an option. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of this change on their assumptions and potentially revise their approach. The lack of concrete instructions makes the action somewhat vague, aligning with a score of 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the implications of replacing the first column of Qo with vo and its impact on the reachability of the first state and Assumption 1. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the implications of a specific change in the paper, namely the replacement of the first column of Qo with vo, which affects the reachability of the first state. It suggests that this change might impact Assumption 1, which concerns the finite length of an option. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a specific concern about a change made in the paper, namely the replacement of the first column of Qo with vo, which affects the reachability of the first state. It questions whether this change might impact Assumption 1, which concerns the finite length of an option. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what changes could be made to ensure the validity of their assumptions. While it identifies a potential problem, it lacks actionable advice or constructive feedback, making it 3. The authors would need to infer that they should consider the implications of this change and potentially revise their approach, but the comment does not offer a clear path forward. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not explicitly instruct the authors on how to implement this suggestion or what specific aspects to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the suggestion is specific in terms of what to consider, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties, with an example of a potential improvement in a recurrent model. However, the comment lacks specific reasoning or examples to support why this suggestion is beneficial or how it might be implemented. Without detailed justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence to be fully substantiated.", "helpfulness_rationale": "The review comment provides a suggestion for improvement by pointing out that if the authors did not see gains in FLOPs or inference time, they should consider examining accuracy or specific properties. It offers an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to analyze accuracy or specific properties, or how to implement the suggested approach. While it offers a direction for improvement, the feedback is somewhat vague and could be more helpful if it included more detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should have tested this assumption, the comment does not explicitly instruct or suggest how to conduct the test. The action is implicit, as the authors need to infer that they should test the assumption. However, the comment lacks concrete guidance on how to perform the test or what specific aspects to consider. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not specify which part of the paper this assumption is made or where it is discussed. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the testing of the assumption, but without explicit references to the paper, it remains 3. Therefore, this comment aligns with the label 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to assume that the assumption has not been tested, which could be a valid concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the assumption made regarding the use of d_e as replacements for entity embeddings. It questions whether this assumption has been tested, which is a crucial aspect of ensuring the validity of the research. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific tests could be conducted. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should test the assumption, but the comment does not offer detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. While it acknowledges that the information is unclear, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to clarify the process. The comment is vague and lacks concrete suggestions, making it difficult for the authors to know how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide any specific examples, reasoning, or references to support these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. This feedback is valuable as it highlights a potential gap in the transparency and reproducibility of the methodology. However, the comment lacks actionable guidance on how the authors might address this issue, such as suggesting specific steps or providing additional context. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not provide any guidance or suggestions on how to address this question or what aspects of the simulation might benefit from such an analysis. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without this context, the authors cannot accurately identify the area that needs clarification or discussion. The comment is 1, as it lacks specific references to the paper, making it difficult for the authors to understand which part of the paper is being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review point raises a question about the number of different kinds of physical interactions that can be included in a simulation. While it prompts the authors to consider this aspect, it does not provide any guidance or suggestions on how to address the question or what implications it might have for the simulation. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is 2, as it identifies a potential area for discussion but does not offer any constructive advice or insights. The score is consistent with a rating of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. While the comment identifies specific issues with the dataset selection and the lack of onehot encoding, it does not provide explicit guidance on how the authors should address these issues or what changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the model comparison section. It provides detailed feedback on the dataset selection, noting that only one dataset contains categorical features while the others are exclusively numerical. This feedback is specific, as it clearly specifies what needs to be addressed in the model comparison section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. The comment provides a clear and logical explanation of why the dataset selection is inadequate and how it might affect the conclusions. It references specific aspects of the paper, such as the \"thorough\" comparison of models on a \"wide range\" of datasets, making the critique wellsupported. Therefore, the claim is 5, as it is thoroughly supported by logical reasoning and specific examples.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, highlighting a significant limitation in the dataset selection. It points out that only one dataset contains categorical features, while the others are exclusively numerical, which is a concern given the general regard for categorical features in deep learning. The comment also notes the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. This feedback is clear and actionable, as it identifies specific areas where the authors need to improve their draft. By addressing these issues, the authors can enhance the robustness and comprehensiveness of their model comparison. Therefore, the comment is 5, as it provides detailed and constructive feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the choice of IoT datasets, specifically FlatCam Face 26 and Headpose detection 11, is unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. While the comment identifies a potential issue with the dataset selection, it does not provide explicit guidance on how the authors should address this concern or what specific datasets they should consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative datasets and potentially reevaluate their benchmarking results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the popularity and relevance of the IoT datasets used, suggesting that the choice of these datasets is questionable. The comment provides clear guidance on what the authors should consider, such as exploring better options like wearable health or mobile activity recognition data, or data from UCI. This level of specificity and grounding makes the comment 5 and informative for the authors. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the choice of IoT datasets, specifically FlatCam Face 26 and Headpose detection 11, for their popularity and relevance. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. While the comment provides a rationale for the critique, it lacks specific examples or references to support the claim that these datasets are unpopular or outdated. The reasoning is somewhat clear but could be strengthened with additional evidence or references to substantiate the authors\" concerns. Therefore, the comment is 4, as it provides a basis for the critique but requires further substantiation.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, namely FlatCam Face 26 and Headpose detection 11. It questions the popularity and relevance of these datasets, suggesting that they may not be the most appropriate choices for benchmarking. The comment provides a rationale for this critique, noting that these datasets are relatively recent but not widely followed and were published in 2004, making them less relevant for current research. It also suggests alternative datasets, such as wearable health or mobile activity recognition data, or data from UCI, which could be more suitable for benchmarking. This feedback is clear and actionable, as it provides the authors with specific suggestions for improving the relevance and comparability of their benchmarking results. However, the comment could be more helpful if it included a brief explanation of why these alternative datasets are more appropriate or provided some context on the limitations of the current datasets. Overall, the comment is 4, as it offers valuable guidance for the authors to enhance the quality and relevance of their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to verify the claim or what steps to follow to address the issue. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not specify which subfigures are in question or provide any details about the potential issue. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed or how the issue should be resolved, making it not specific. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any evidence, reasoning, or references to support this claim. Without specific details or examples, the authors are left without a basis to address or verify the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about potential errors in the subfigures of Figs 1 and 2, questioning whether they have been swapped by mistake. While this feedback identifies a potential issue, it lacks specific details or suggestions on how the authors might address or correct the problem. Without additional guidance or examples, the authors may find it challenging to improve their draft based on this feedback alone. Therefore, the comment is 2, as it points out a potential issue but does not provide actionable advice or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the dropout probe improves sensitivity and identifies a potential concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the dropout probe improving sensitivity and highlights a concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in identifying the concern about false positives, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the dropout probe improves sensitivity but also raises a concern about the increased risk of false positives. The comment suggests that this issue should be a substantial part of the discussion. However, the comment lacks specific examples or detailed reasoning to substantiate the claim about the increased risk of false positives. It does not provide references or logical arguments to support the assertion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential concern regarding the increased risk of false positives when using the dropout probe, which improves sensitivity. It suggests that this issue should be a substantial part of the discussion. While the comment highlights a specific area that needs attention, it does not provide detailed guidance on how to address this concern or what aspects of the discussion should be expanded. The feedback is 3 as it points out a potential issue that could impact the validity of the results, but it lacks depth and actionable suggestions for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim about the placement of the regret bound and the reviewer\"s inability to find it in the supplementary material. While the comment points out a potential issue with the authors\" claim, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should doublecheck the placement of the regret bound in the appendix or supplementary material. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" claim about the placement of the regret bound in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors did not find the regret bound for the minibatch estimator in the supplementary material, and it references a specific paper 1 that might contain relevant information. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the regret bound being cast to the appendix is not supported by the supplementary material. However, the comment does not provide any specific evidence or reasoning to substantiate this claim. It lacks detailed references or examples that would allow the authors to verify the claim. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" claim regarding the placement of the regret bound in the appendix. It points out that the authors did not find the regret bound for the minibatch estimator in the supplementary material, referencing a specific paper 1 that might contain relevant information. This feedback is clear and actionable, as it directs the authors to doublecheck the placement of the regret bound and consider the provided reference. However, the comment could be more helpful if it offered additional guidance on how to address the issue or suggested alternative approaches. Overall, the comment is 4, as it provides a clear direction for improvement but lacks depth in terms of actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM). However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. The action is implicit and vague, as it does not specify which parts of the paper should be expanded or how the authors should incorporate these methods. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper is not sound and does not discuss or compare exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these exploration methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed examples or references, the claim is 3, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that it does not discuss or compare exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM). This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive discussion of related work. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue, such as recommending additional sections or comparisons. Without these details, the feedback is 3, as it provides a clear direction for improvement but lacks depth and actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer the actions they should take, such as clarifying the impact of inference, providing the coefficient, and addressing the hyperparameter details. The feedback is 3 as it points out specific areas for improvement, but it lacks concrete instructions on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment does not provide any specific evidence, reasoning, or references to support these claims. The questions raised are speculative and lack detailed justification, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues or provide additional details. The feedback is 3 as it points out potential weaknesses and areas for clarification, but it does not offer concrete suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation identifies a key weakness of the method, but it does not provide any explicit or implicit guidance on how to address this issue or improve the method. The authors are left without any actionable steps to take to enhance their draft, making the comment 1. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed compression\" and \"PQ,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed compression performs worse than PQ when a small code length is allowed, which is a clear and specific critique. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed compression performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation highlights a critical area for improvement, as it points out a limitation of the method that could impact its practical applicability. However, the comment lacks actionable guidance or suggestions on how to address this issue or enhance the method. While it identifies a significant concern, it does not provide the authors with a clear path forward for improvement, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several areas where the paper could be improved, such as the inclusion of subjective statements, the need for proofs and references to support claims, and the lack of detailed explanation for certain statements. It also suggests that the paper should provide a detailed explanation to verify these claims. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses issues with subjective statements and the need for proofs and references to support claims. It also mentions specific areas, such as the laborintensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with subjective statements and the need for additional evidence, but without explicit references, it is challenging for the authors to pinpoint the exact parts of the paper that require attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about subjective statements and the need for proofs and references to support claims. It provides specific examples, such as the laborintensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, the comment lacks detailed reasoning or references to substantiate these claims, making it 3. The authors would need to infer the basis for these claims, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, such as the inclusion of subjective statements and the need for proofs and references to support claims. It also highlights specific issues, such as the laborintensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment suggests that the paper should provide a detailed explanation to verify these statements, which is a constructive suggestion for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is 3 as it points out areas for improvement but lacks depth and detail, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not explicitly instruct the authors to add more detailed analyses or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their analysis to include more detailed comparisons between different languages/nationalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included, such as Japanese, Chinese, English, Arabic, and German, and raises a question about potential interesting observations comparing them. However, the comment does not specify which part of the paper this suggestion relates to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific about the type of analysis that could be more detailed, it lacks grounding as it does not clearly indicate which part of the paper is being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included, such as Japanese, Chinese, English, Arabic, and German, and raises a question about potential interesting observations comparing them. However, the comment lacks specific examples or references to support the claim that the current analysis is lacking in detail. While the suggestion is logical and could be substantiated with further evidence, the absence of detailed reasoning or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing them. This feedback is 3 as it identifies an area for improvement by suggesting more detailed analysis. However, it lacks specific guidance on how to expand the analysis or what kind of observations would be interesting, making it 3 rather than fully helpful. The authors would need to infer that they should add more detailed comparisons between different languages/nationalities to address the comment effectively."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used in the approach design. While it suggests that exploring additional properties might be beneficial, it does not provide explicit guidance on how to identify or utilize these properties. The comment is somewhat vague, as it does not specify which properties to consider or how they might impact the approach. Therefore, the action is 3, as the authors know they need to explore additional feature properties but lack concrete steps on how to do so.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not provide any guidance or suggestions on how to explore these additional properties. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. This feedback is 3 as it prompts the authors to consider expanding their approach by exploring additional feature properties. However, the comment lacks specificity and does not provide any guidance or suggestions on how to identify or utilize these additional properties. Without concrete examples or recommendations, the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where the proposed method (PE) is important. However, it does not provide any specific guidance or suggestions on how to achieve this, such as which tasks to include or how to demonstrate the importance of PE in those tasks. The comment lacks explicit instructions or concrete details, making it difficult for the authors to understand what actions they should take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not specify which tasks should be included or how they should be integrated into the paper. This makes it difficult for the authors to understand the exact scope of the suggestion, leaving them unable to confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity in detailing what aspects of the tasks or the importance of PE are missing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to incorporate it into their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it lacks specific guidance or examples on how to achieve this, making it difficult for the authors to understand the implications of the suggestion or how to incorporate it into their work. The comment is vague and does not provide actionable feedback, which limits its helpfulness. Therefore, it aligns with a score of 2, as it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the authors\" work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it prompts the authors to elaborate on these differences, it does not provide explicit guidance on how to address this question or what specific aspects need to be clarified. The action is implicit, as the authors need to infer that they should compare their work with the mentioned papers and explain the differences. However, the comment lacks concrete details on how to implement this comparison or what specific aspects to focus on, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"other works focusing on the semantic face editing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it prompts the authors to elaborate on the differences between their work and these papers, particularly regarding continuous control over attributes. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the differences between the authors\" work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it does not contain a direct claim, it prompts the authors to elaborate on these differences, which could be considered a suggestion for improvement. However, the comment lacks specific examples or detailed reasoning to support the need for this elaboration, making it 3. The authors would need to infer the importance of addressing this question, which limits the verifiability of the comment.", "helpfulness_rationale": "The review comment raises a question about the differences between the authors\" work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. This is a relevant point for the authors to consider, as it highlights a potential area for comparison and differentiation. However, the comment lacks specific guidance on how to address this question or what aspects of the comparison should be emphasized. While it prompts the authors to elaborate on the differences, it does not provide detailed suggestions or examples, which limits its helpfulness. Therefore, the comment is 3, as it identifies an important area for improvement but does not fully guide the authors in addressing it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that footnotes are used excessively, making the paper distracting, and recommends moving important content into the main body and details about parameter settings into the appendix. While the comment provides explicit guidance on how to improve the paper by suggesting specific actions, such as moving content to the main body and appendix, it lacks detailed instructions on which sections or parts of the paper should be moved. The action is somewhat vague, as the authors need to infer which sections to move and where to place the details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that footnotes are used excessively, making the paper distracting, and recommends moving important content into the main body and details about parameter settings into the appendix. However, it does not specify which sections or parts of the paper are being referred to, making it weakly grounded. The comment is specific in its suggestion to move content to the main body and appendix, but the lack of explicit references makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that footnotes are used excessively, making the paper distracting, and suggests moving important content to the main body and details about parameter settings to the appendix. However, the comment lacks specific examples or references to support the claim about excessive use of footnotes. It does not provide any evidence or reasoning to justify why the current use of footnotes is problematic. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the excessive use of footnotes, which can make the paper distracting. It provides actionable suggestions for improvement, such as moving important content to the main body and details about parameter settings to the appendix. This feedback is clear and constructive, offering the authors a clear direction for enhancing the readability and flow of their paper. However, the comment could be more helpful if it provided specific examples of where the footnotes are excessively used or suggested alternative ways to present the information. Overall, the comment is 4 as it offers actionable guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the inclusion of fewshot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific demonstrations to include or how to integrate them into the paper. The comment is somewhat vague, as it leaves the authors to infer the exact action needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the inclusion of fewshot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. While it is specific in suggesting the inclusion of fewshot demonstrations, the lack of grounding makes it difficult for the authors to understand where to apply the suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. The comment does not provide specific examples or references to support the claim that the inclusion of zeroshot results is necessary or beneficial. As a result, the claim is 3, as it lacks sufficient evidence or reasoning to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what additional experiments might be relevant. The feedback is 3 as it points out a potential area for further exploration, but it lacks depth and actionable advice, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this information can be computed from a reference 2. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions or detailed guidance on how to conduct the analysis or present the findings. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of the GS module on the effective receptive field. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the GS module and its impact on the effective receptive field, referencing a specific paper 2. It does not explicitly mention a specific part of the paper where this issue is discussed, making it weakly grounded. However, the comment is specific in its focus on the effective receptive field and its relevance to the GS module. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this information can be computed from a reference 2. While the comment implies that the authors should investigate this aspect, it lacks specific details or examples to support the claim. The reasoning is somewhat vague, as it does not provide a clear explanation of how the effective receptive field is computed or how the GS module influences it. Without additional context or references, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment raises a question about the impact of the GS module on the effective receptive field, suggesting that this information can be computed from a reference 2. This feedback is 3 as it points out a potential area for further investigation and provides a reference for the authors to explore. However, the comment lacks depth and does not offer specific guidance on how to conduct the analysis or present the findings. The authors are left to infer the importance of this aspect and how to address it, which limits the overall helpfulness of the comment. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights potential issues with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to optimize the method or what specific changes might be necessary to reduce the time complexity. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper these issues are discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in detailing the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high, citing the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references or logical arguments to support the assertion that these factors contribute to a high time complexity. Without such evidence, the claim remains 3, as the authors may need to infer the basis for the claim or seek additional information to understand the issue fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies potential issues with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment highlights these concerns, it does not provide specific suggestions or actionable advice on how to address these issues or improve the method. The feedback is 3 as it points out areas that need attention, but it lacks depth and guidance on how to resolve the identified problems. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. This comment provides a clear and explicit action for the authors to take, which is to label the figures more precisely. The suggestion is concrete, as it specifies exactly what needs to be done to improve the clarity of the figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, it does not explicitly mention which figures are being referred to, making it weakly grounded. The comment is specific in its suggestion to improve the clarity of the figures by providing more detailed labels. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification or examples to fully substantiate the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the figures, suggesting that labeling them as \"pretrained solution encoders & solution decoders\" would improve their readability. This feedback is clear and actionable, providing the authors with a direct suggestion for enhancing the presentation of their figures. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or provided examples of how the figures could be improved. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also suggests that the relevance of the occlusion experiment is unclear, as the method does not seem to propose anything specific to occlusion. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific comparisons or clarifying the relevance of the occlusion experiment. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific comparisons with NeRFbased methods, such as \"Zero1to3\" and \"pointe,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the relevance of the occlusion experiment, questioning its significance in the context of the method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of comparison with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that it does not align with the method\"s specific contributions. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or justifications weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" This feedback is valuable as it highlights the need for the authors to contextualize their work within the existing literature. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it does not align with the method\"s specific contributions. However, the comment lacks detailed guidance on how the authors should address these issues, such as providing specific comparisons or clarifying the relevance of the occlusion experiment. While the feedback is 3 in identifying areas for improvement, it could be more actionable with additional suggestions or guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for information about the computational requirements of the experiments, specifically the time taken and the hardware used. While it prompts the authors to provide this information, it does not explicitly instruct them to include it in the paper or suggest where to add it. The action is implicit, as the authors can infer that they need to provide this information, but it lacks concrete guidance on how to present or discuss it. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for information about the computational requirements of the experiments, including the time taken and the hardware used. This allows the authors to accurately identify the part of the paper where this information should be addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the computation required for the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the computational requirements of the experiments, specifically the time taken and the hardware used. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is 3 as it prompts the authors to provide information about the computational requirements of their experiments, specifically the time taken and the hardware used. This feedback is valuable as it highlights an important aspect of the experimental setup that could enhance the reproducibility and transparency of the work. However, the comment could be more helpful if it provided additional guidance on how to present or discuss this information in the paper. Overall, the feedback is clear and actionable, but it could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. While the comment prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the paper. The action is implicit, as the authors need to infer that they should discuss the model\"s robustness to imperfect data and explore potential strategies for handling missing modalities. However, the lack of concrete guidance on how to implement these suggestions makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not specify which part of the paper addresses this issue, making it weakly grounded. The comment is specific in its inquiry about the model\"s behavior and potential strategies for handling missing data, but without explicit references to sections or figures, the authors may struggle to identify the exact area to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not provide any specific evidence, reasoning, or references to support the claims made. It lacks detailed explanations or examples to substantiate the concerns, making it difficult for the authors to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It prompts the authors to consider the impact of such data imperfections on the model and whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it highlights a potential area for further exploration and improvement in the paper. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these questions or incorporate them into the draft. Overall, the comment is 3, as it identifies a relevant area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the authors\" draft, noting that they do not verify the stability of the OGEAug model on OOD benchmarks like DrugOOD, where SPE 2 is validated. This feedback is explicit and provides a clear action for the authors to take, which is to verify the stability of their model on these benchmarks. The comment is specific in its suggestion, guiding the authors to address a particular aspect of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the stability of the OGEAug on OOD benchmarks such as DrugOOD,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of verification of the model\"s stability on these benchmarks. The comment provides a clear direction for the authors to take, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of the OGEAug model on OOD benchmarks such as DrugOOD, where SPE 2 is validated. This claim is 3 as it points out a specific issue related to the evaluation of the model\"s stability. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to provide more context or evidence to fully understand the implications of this feedback.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" draft, noting that they do not verify the stability of the OGEAug model on OOD benchmarks such as DrugOOD, where SPE 2 is validated. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs verification. By highlighting this omission, the comment provides a concrete suggestion for improvement, which can help the authors enhance the robustness and reliability of their model. Therefore, the comment is 4, as it offers a clear and actionable piece of feedback that aligns with the authors\" needs for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment implies that multiple seed experiments would provide a more robust evaluation. However, it does not explicitly instruct the authors to conduct multiple seed experiments or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should perform multiple seed experiments to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments being conducted on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This lack of grounding makes it challenging for the authors to identify the exact area that needs improvement. While the comment is specific in its critique of the experimental setup, the absence of explicit grounding makes it difficult for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed guidance on how to conduct multiple seed experiments or why this would be beneficial. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, specifically that the experiments are conducted using a single seed. This makes it challenging to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that using multiple seed experiments would provide a more robust evaluation, which is a valuable piece of feedback. However, the comment could be more helpful by providing additional guidance on how to implement multiple seed experiments or by suggesting specific metrics or analyses that would be beneficial to include. Overall, the comment is 3 as it highlights a critical issue and offers a potential solution, but it lacks depth and detail to fully assist the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it highlights a lack of clarity in the motivation, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the motivation behind their choice of distributions. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in questioning the motivation, the absence of grounding information makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. Without additional context or justification, the claim remains 1, as the authors are left to interpret the reasoning themselves. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of clarity in the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the explanation of the chosen distributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative distributions or providing a more detailed rationale. Without actionable advice, the authors may find it challenging to fully address the feedback, making the comment 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. It suggests that this requirement might limit the potential users who can access or implement the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific guidance on how to make the method more accessible or how to justify the need for a multiGPU setup. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"optimizations in the proposed method\" and the \"requirement of a multiGPU setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains the issue of accessibility due to the need for a multiGPU setup, which could limit potential users. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the requirement of a multiGPU setup for the proposed method makes it inaccessible to many potential users. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. This is a valid concern that could limit the potential users who can access or implement the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it highlights a potential weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current system captures semantics through RNNbased models and recommends comparing it with another system that also captures semantics. It also suggests using Ref2 as a strong baseline for comparison. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific aspects of the comparison should be highlighted or how the performance of the current system should be evaluated against the baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, implying a need for comparison. However, it does not specify which part of the paper this comparison should be made or which sections or figures would be relevant. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting a comparison with Ref2 as a strong baseline, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, recommending Ref2 as a strong baseline. However, it lacks specific details or references to support the claim that Ref2 is indeed a strong baseline. The comment does not provide a clear rationale or evidence to justify why this comparison is necessary or how it would enhance the paper. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that captures semantics, recommending Ref2 as a strong baseline. However, it lacks specific guidance on how to conduct this comparison or what aspects of the performance should be evaluated. The comment identifies a potential area for improvement but does not provide detailed suggestions or actionable steps for the authors to take. As a result, the feedback is 3, as it points out a relevant area for comparison but does not fully address the authors\" needs for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. While the comment identifies a lack of clarity, it does not provide explicit guidance on what actions the authors should take to address this issue. The authors are left to infer that they need to clarify these details in their draft, but the comment lacks concrete instructions on how to do so. Therefore, the comment is 3, as it points out a specific area needing clarification but does not provide detailed guidance on how to implement the suggestion.", "grounding_specificity_rationale": "The comment raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for information, it lacks grounding as it does not provide clear guidance on where to find or address this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. This is a factual question that requires the authors to provide additional information to ensure the reproducibility and transparency of their results. However, the comment does not offer any suggestions or reasoning to address this issue, making it a normal statement rather than a claim. Therefore, it should be classified as \"No\".", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by questioning the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. This feedback is valuable as it highlights a lack of transparency and reproducibility in the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or clarifications. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear indication of a need for clarification but does not offer detailed guidance on how to achieve this."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the model or assumptions need to be investigated. Without concrete suggestions or a clear path forward, the authors are left without actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is vague and lacks specificity, as it does not provide detailed guidance on what needs to be addressed or how to approach the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve their model or assumptions. It does not provide actionable advice or insights that would help the authors enhance their draft. As a result, the comment is 2, as it identifies a potential problem but does not offer a clear path forward for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what changes could be made to the approach. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the limitation of the approach, but it lacks detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the system should be able to generalize to more views without difficulty. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or what changes could be made to the approach. The comment is 3 as it points out a potential issue that could enhance the paper, but it does not provide actionable feedback or detailed insights to help the authors improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their draft. As a result, the authors are left without a clear understanding of what to do next, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area of the paper that needs clarification. While the comment is specific in its question about the rationale, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any claim, suggestion, or reasoning to support the question. The comment lacks any evidence or justification, making it 1. Therefore, it does not provide any guidance or insight for the authors to address the question or improve their draft.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. This question highlights a potential area for clarification or improvement in the methodology section of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to their approach. Without actionable feedback or specific suggestions, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 2, as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the discussion regarding the hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback provides a clear and explicit action for the authors to take, which is to include a detailed discussion on how to set the hyperparameter in practice and to analyze its sensitivity. The comment is concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the discussion on arbitrary hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in detailing what is missing, such as guidance on setting the hyperparameter and sensitivity analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the hyperparameter \u03b3 is missing, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This claim is 3 as it highlights a gap in the paper but does not provide specific examples or references to support the claim. The authors would need to infer the missing information, which limits the verifiability of the comment. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the hyperparameter \u03b3, specifically regarding how to set it in practice for a given graph and the lack of sensitivity analysis. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the importance of this hyperparameter and its impact on the results, the comment guides the authors to include a detailed discussion that would enhance the clarity and reproducibility of their work. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment does not provide explicit guidance on how to implement this controlled baseline or what specific experiments should be conducted to address this issue. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the different locations of induction heads and FV heads within the model, which could be a confounding factor in the analysis of ICL performance. It suggests that a controlled baseline should be considered to account for this difference. However, the comment does not explicitly mention which part of the paper this issue is discussed or addressed, making it weakly grounded. The comment is specific in detailing the potential confounding factor and suggesting a controlled baseline, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the different locations of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting the performance difference when ablating these heads. The comment implies that a controlled baseline should be considered to address this issue. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations in the model, should be considered. This feedback is clear and actionable, as it provides a specific suggestion for improving the experimental design and analysis. However, the comment could be more helpful if it included details on how to implement the controlled baseline or what specific experiments should be conducted to address this issue. Overall, the comment is 4, as it offers valuable guidance for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under the similarity measurement section, which describes how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, namely to include this section in their draft. The comment is explicit and concrete, as it specifies exactly what is missing and where it should be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of a section on synonym identification that describes how the multiplechoice task is approached. This provides the authors with a clear understanding of what needs to be added to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under the similarity measurement section, which describes how the multiplechoice task is approached. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this section is missing or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of a section on synonym identification under the similarity measurement section. This is a clear and actionable piece of feedback that would help the authors improve their draft by ensuring that all relevant aspects are addressed. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific guidance on how to create this overview or what aspects of the workflow and model should be included. The action is implicit, as the authors need to infer that they should provide a detailed overview, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not specify which part of the paper this overview should be included in or how it should be structured. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include an overview, but it lacks details on what aspects of the workflow and model should be covered. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. While this feedback is relevant and provides a clear direction for improvement, it lacks specific guidance on how to create such an overview or what aspects of the workflow and model should be included. The comment is 3 as it identifies a potential area for enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should redefine Figure 3 to show expected quantities as scalars instead of vectors. This is a clear and explicit action that the authors can readily follow. The comment provides specific guidance on what needs to be changed, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be done: redefine the figure to show expected quantities as scalars instead of vectors. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point suggests that the authors should redefine Figure 3 to show expected quantities as scalars instead of vectors. This is a specific and actionable suggestion that directly addresses a potential issue in the presentation of the figure. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the expected quantities are scalars but are shown as vectors. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the accuracy and clarity of their figure. By redefining the figure to accurately represent the expected quantities as scalars, the authors can enhance the precision and effectiveness of their presentation. This level of detail and specificity makes the comment 5, as it guides the authors in making a necessary correction. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific guidance or suggestions on how the authors should improve the experiment setup or address these questions. The comment lacks explicit actions or concrete details, leaving the authors uncertain about what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not specify which part of the paper the ablations are discussed in, nor does it provide any guidance on how to address these questions. The lack of specific information about the sections or content being referred to makes it difficult for the authors to understand the exact issue being raised. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address these concerns or improve the experiment setup. Without detailed guidance or examples, the authors may find it challenging to understand the issues or how to resolve them. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the paper by noting that while a reasonable argument is made about the usefulness of the proposed models for learning representations of lowfrequency words, no empirical evidence is provided to support this claim. The comment suggests that the authors could have explored this aspect further, which implies an action to conduct additional experiments or analysis. However, the comment does not specify how to conduct these experiments or what specific data to use, making the action somewhat vague. The feedback is explicit in identifying the need for empirical evidence but lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper by focusing on the usefulness of the proposed models for learning representations of lowfrequency words. It highlights that while a reasonable argument is made, no empirical evidence is provided to test the hypothesis. The comment suggests that the authors could have looked deeper into this aspect, implying a need for further exploration. However, the comment does not explicitly mention which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the issue of the lack of empirical evidence and the suggestion to explore the aspect further. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no empirical evidence is provided to test the hypothesis about the usefulness of the proposed models for learning representations of lowfrequency words. However, the comment does not offer any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand why the claim is valid or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks empirical evidence to support a claim about the usefulness of the proposed models for learning representations of lowfrequency words. It highlights that the argument is reasonable but lacks testing, which could be interesting for the authors to explore further. However, the comment does not provide specific suggestions or guidance on how to conduct this exploration or what data to use. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a gap in the paper but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a difficulty in understanding Figure 5 due to overlapping lines, suggesting that the authors could report additional metrics such as FLOPs or model size to make the figure more concrete. While the comment provides a clear action\u2014improving the clarity of Figure 5 by adding more metrics\u2014it does not specify how to implement this action, such as which metrics to include or how to present them. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue with the figure, namely the difficulty in understanding due to overlapping lines, and suggests a concrete improvement by reporting additional metrics like FLOPs or model size. This provides clear guidance on what needs to be addressed to enhance the clarity and comprehensiveness of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to overlapping lines, and suggests that reporting additional metrics like FLOPs or model size would make the figure more concrete. While the comment identifies a specific issue with the figure\"s clarity, it lacks detailed reasoning or examples to fully support the claim. The suggestion to include additional metrics is logical but could be more robust with specific examples or references to similar practices in the field. Therefore, the comment is 3, as it provides a basis for improvement but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could enhance the figure\"s clarity by reporting additional metrics such as FLOPs or model size. This feedback is actionable and provides a clear direction for improvement, as it guides the authors on what additional information to include to make the figure more informative and easier to interpret. However, the comment could be more helpful if it offered specific examples of how to present these additional metrics or suggested alternative ways to visualize the data. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how the authors should address these omissions. The action is implicit, as the authors need to infer that they should provide more details in the questions section. The lack of specific guidance on what details are missing makes the action vague and difficult to execute. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which part of the paper this section is located in, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment does not provide specific guidance on what details are missing or how they should be addressed. This lack of grounding and specificity makes the comment challenging for the authors to understand and act upon. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the nature of the missing details or how to address them. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how the authors might address these omissions. This feedback is vague and lacks actionable suggestions, making it difficult for the authors to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that Figure 4 is confusing and that the columns are not explained in the text or caption. While the comment highlights a specific issue with the figure, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the meaning of the columns in the figure, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Figure 4, namely that the columns are not explained in the text or caption. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because it is not clear what the columns mean, as this is not explained in the text or caption. This claim is 3 as it provides a specific issue with the figure but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer that the lack of explanation in the text or caption contributes to the confusion, but the comment does not offer additional context or evidence to support this assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that the columns are not explained in the text or caption, making the figure confusing. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the figure, such as suggesting specific ways to label the columns or provide additional context. Despite this, the comment offers valuable guidance for the authors to enhance the clarity of their presentation, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or improve their results, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. The lack of specific referencing makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, it is 1 because it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. While the comment identifies a potential issue with the experimental setup or methodology, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps or detailed explanations to help the authors enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to include an ablation study. The comment identifies a gap in the analysis but does not offer guidance on how to fill that gap, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of a small performance gain. However, it does not specify which part of the paper lacks ablation analysis or provide any guidance on how to address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the need for ablation analysis but lacks detailed suggestions on how to implement it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis in the main paper makes it difficult to determine the source of a small performance gain. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. This feedback is clear and actionable, as it highlights a critical gap in the analysis that could impact the paper\"s conclusions. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as suggesting specific ablation studies or analyses that could be included. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the CNN experiments are not fully convincing but does not provide any specific details or suggestions on how to improve them. The comment lacks explicit guidance on what aspects of the experiments need to be addressed or how the authors should enhance the results. Without concrete actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the CNN experiments are discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is not specific because it does not provide details on what aspects of the experiments are not convincing or how the authors might address this issue. Without specific guidance or examples, the authors cannot effectively respond to the comment. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors cannot determine why the experiments are not convincing or how to address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the CNN experiments, stating they are not fully convincing. However, it lacks specific details or suggestions on how the authors might address this issue or improve the experiments. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient depth or direction for the authors to act upon."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXplain models. This provides a clear and explicit action for the authors to take, as they can directly compare their results with these models. The comment is specific in its suggestion, guiding the authors on how to enhance their work by including such comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXexplain models. However, it does not specify which part of the paper this comparison should be made or where the results are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs to be addressed. While the suggestion is specific in terms of the models to compare with, the lack of grounding makes it challenging for the authors to understand the exact scope of the comparison. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXplain models. This is a suggestion for improvement, but it lacks specific details or examples of how this comparison should be conducted. Without further elaboration or references, the authors may find it challenging to understand the exact nature of the comparison and how it would benefit their work. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXplain models. This provides a clear and actionable suggestion for the authors to enhance their work by including such comparisons. By comparing their results with stateoftheart models, the authors can better contextualize their findings and demonstrate the significance of their contributions. This feedback is specific and constructive, offering a clear direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. While the comment implies that the authors should consider using adaptive methods, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the current method need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer that they should explore adaptive methods and potentially revise their approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in questioning the rationale behind the use of freezing, the absence of explicit grounding limits the authors\" ability to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. However, it does not provide any evidence, reasoning, or references to support the claim that adaptive methods are superior or why freezing is necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. This feedback highlights a potential area for clarification and improvement in the paper, as it challenges the authors to justify their choice of method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential weakness, it does not offer actionable advice or detailed insights that would significantly enhance the authors\" understanding or the quality of their work. Therefore, the comment is 3, as it points out an area for improvement but does not fully address the authors\" needs for comprehensive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It also recommends performing a similar analysis on the proposed model. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions or detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It references a specific paper (https://arxiv.org/abs/2104.06378) to support the claim. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in suggesting that the authors perform a similar analysis on their proposed model, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It references a specific paper to support the claim, providing a basis for understanding the context. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the connection between the existing work and the proposed model, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It references a specific paper to support the claim, providing context for the discussion. The comment recommends performing a similar analysis on the proposed model, which could be valuable for the authors to explore. However, the comment lacks detailed guidance or suggestions on how to conduct this analysis, leaving the authors with a general idea but no specific steps to follow. While the feedback is 3, it could be more impactful with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in certain settings. While the comment implies that the authors should provide a more comprehensive discussion of computational complexity, it does not explicitly instruct them to do so or offer specific guidance on how to address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of computational complexity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment does not specify which part of the paper discusses the computational cost or where the authors should provide a more comprehensive discussion. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the computational cost, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the computational cost of the proposed approach. It points out that while the paper mentions the additional cost not leading to significant delays, it does not provide a clear explanation or justification for this claim. The reviewer also questions whether the approach might become prohibitive in certain settings, which is a valid concern that could impact the practical applicability of the work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or provide a more comprehensive discussion of the computational complexity. While it highlights an important area for improvement, the feedback could be more helpful if it included actionable steps or examples of how to enhance the discussion of computational cost. Therefore, the comment is 3, as it identifies a relevant area for improvement but does not provide detailed guidance for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is an explicit action that the authors can directly implement by adding a brief explanation in the relevant section of the paper. The comment is specific and provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (l.97) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining how novel values in the test set are handled for clarity. This provides the authors with a clear and precise direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests that the authors should clarify how novel values in the test set are handled for better understanding. This feedback is clear and provides a direct direction for improvement, allowing the authors to enhance the clarity of their paper. However, the comment could be more helpful if it offered additional suggestions or examples of how to improve the explanation. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that the authors can readily address."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point mentions that similar methods have been proposed for multitask learning but does not discuss them in the paper, referencing a specific work 1. While it highlights a potential gap in the discussion, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the related work need to be discussed. The action is implicit, as the authors would need to infer that they should include a discussion of similar methods in their paper. However, the lack of concrete instructions on how to implement this suggestion makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"multitask learning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely the discussion of similar methods in the paper, which is a clear and specific request for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar methods have been proposed for multitask learning but does not discuss them in the paper, referencing a specific work 1. However, the comment lacks detailed reasoning or examples to support the claim that similar methods are missing. It does not provide specific evidence or references to illustrate why these methods are relevant or how their absence impacts the paper\"s contribution. As a result, the claim is 3, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out that similar methods have been proposed for multitask learning but are not discussed. This feedback is valuable as it highlights an area where the authors could enhance their paper by providing a more comprehensive discussion of related work. However, the comment lacks specific guidance on how the authors might address this gap, such as suggesting particular related works or areas of discussion. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of indepth analysis of the experimental results. It provides a specific example, asking for clarification on why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is explicit and concrete, as it directly points out the need for a more detailed analysis and provides a clear direction for the authors to address this issue. The authors can infer that they should include a more thorough discussion of the experimental results, explaining the observed differences in model performance across different datasets. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it provides a clear example of what needs to be addressed, prompting the authors to delve deeper into the analysis of their experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of indepth analysis of the experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set, which highlights a critical area for further exploration. This feedback is clear and actionable, as it directs the authors to provide a more detailed analysis of their experimental findings. However, the comment could be more helpful if it suggested specific ways to conduct this analysis or provided examples of how to interpret the results. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and that a more extensive hyperparameter search could be beneficial for a fair comparison with the baseline. However, it does not provide explicit guidance on which hyperparameters to focus on or how to conduct the search. The action is implicit, as the authors need to infer that they should perform a more thorough hyperparameter search to ensure a fair comparison. While the comment is 3, it lacks concrete details on how to implement the suggested action, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper introduces multiple hyperparameters and that a more extensive hyperparameter search could be beneficial for a fair comparison with the baseline. However, it does not specify which hyperparameters are being referred to or provide any guidance on how to conduct the search. The comment lacks grounding as it does not identify a specific part of the paper that needs attention. It is also not specific because it does not detail what needs to be addressed or how the hyperparameter search should be conducted. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and that a more extensive hyperparameter search could be beneficial for a fair comparison with the baseline. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or justification, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out the introduction of multiple hyperparameters and the extensive hyperparameter search conducted. It suggests that ensuring the baseline is fully tuned with similar resources could lead to a fairer comparison. However, the comment lacks specific guidance on which hyperparameters to focus on or how to conduct the search, making it 3. The authors are given a direction to consider, but the feedback could be more comprehensive with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, making it difficult to assess the significance of the results. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as including standard deviations in future experiments or analyses. Without concrete guidance on how to improve the results, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of standard deviations, which makes it difficult to judge the significance of the results. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the results lack standard deviations or how this affects their interpretation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to judge the significance of the results. This feedback is clear and actionable, as it highlights a critical aspect of the experimental analysis that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how the authors might include standard deviations or discuss their implications. Despite this, the comment offers valuable guidance for improving the clarity and rigor of the experimental results, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the theoretical foundation of the analysis, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, it does not provide explicit instructions or suggestions on how the authors might address these issues. The comment implies that the authors should consider providing these details, but it lacks concrete guidance on how to do so. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical work on sampling and particlebased optimization methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis seems weak in light of theoretical work on sampling and particlebased optimization methods, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the theoretical foundation of the analysis, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. This feedback is valuable as it highlights areas where the authors could strengthen their analysis by providing more detailed theoretical underpinnings. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these concerns, such as suggesting additional theoretical frameworks or methods to consider. Without concrete recommendations, the authors may find it challenging to improve their draft effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the realism of their generated images, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the issue with the realism of generated images, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This feedback is clear and actionable, as it highlights a key area for improvement in the paper. However, it could be more helpful if it provided suggestions on how to enhance the realism of the generated images or suggested specific techniques that could be employed. Despite this, the comment offers valuable guidance for the authors to address the identified weakness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counterargument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any explicit or implicit suggestions on how the authors should revise or improve their draft to address this critique. The authors are left without guidance on what specific changes to make or how to clarify the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (559560) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies what is incorrect, suggesting that the claim made in the paper is not entirely true and providing a counterargument about the Cycle Consistency loss. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the statement on lines 559560 is not entirely true, specifically regarding the Cycle Consistency loss. It provides a counterargument, suggesting that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the accuracy of the statement or understand the basis of the critique. Without detailed evidence or examples, the claim remains 3, as it lacks sufficient justification to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counterargument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any suggestions or guidance on how the authors might revise or improve their draft to address this critique. While it points out a potential issue, it lacks actionable advice, making it 3. The authors are left without a clear path to address the feedback, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or improve the clarity of their terminology. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. The authors cannot confidently determine where the confusion arises, making the comment weakly grounded. Additionally, the comment is specific in identifying the need for clarification regarding the term, but it lacks detailed guidance on how to address this confusion. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that calling \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the term is confusing. As a result, the authors are left without a clear understanding of why the term is confusing or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"hyperspectral,\" which can be confusing. It provides a definition of hyperspectral imaging, which could help the authors clarify their terminology and improve the clarity of their paper. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the confusion or improve the clarity of the terminology. While it points out a potential area for improvement, it does not provide actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete advice on how to improve the paper, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the role of visual information in the paper, noting that it is not explicitly discussed or verified. It mentions an ablation study in Table 10, where the performance of the model with and without the perception module is similar, and the implementation details of the \"w/o perception\" module are unknown. The comment also questions the significance of the experimental results given the sample size of 1000 users, suggesting that the improvements might not be significant. However, the comment does not specify which part of the paper discusses the role of visual information or the ablation study, making it weakly grounded. It is specific in detailing the issues with the ablation study and the experimental results, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. The comment provides specific examples, such as the similar performance of \"w/o perception\" and \"w perception\" in Table 10, and questions the statistical significance of the improvements given the sample size. However, the reasoning is somewhat vague, as it does not provide detailed explanations or references to support the claims. The lack of specific examples or detailed reasoning makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the lack of explicit verification in the ablation study. It points out that the performance of the model with and without the perception module is similar, and the implementation details of the \"w/o perception\" module are unknown. Additionally, the comment questions the statistical significance of the experimental results, suggesting that the improvements might not be significant given the sample size. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, making it a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. It also points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. The comment is fully actionable because it specifies exactly what needs to be done, including identifying and citing previous works on Lasso screening. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue: the lack of citation and comparison of previous works on Lasso screening, providing a clear example of what needs to be addressed. This feedback is detailed and provides a clear direction for improvement, making it 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not provide any evidence or reasoning to support this claim. It suggests that previous works on Lasso screening are not cited or compared, such as Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 29923006. However, the comment lacks specific examples or detailed reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. However, it points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. By highlighting this gap, the comment offers constructive guidance for improving the completeness and accuracy of the paper. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the notation used for results, specifically questioning the meaning of the percentage improvement claim for CIFAR10. While the comment identifies a specific issue with the clarity of the notation, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the notation used for results, particularly the unclear meaning of the percentage improvement claim for CIFAR10. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity in the notation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation for results is unclear and that the paper does not specify what the percentage improvement claim for CIFAR10 means. However, the comment lacks specific examples or references to clarify the issue, making it difficult for the authors to understand and address the concern. Without additional context or explanation, the claim remains 1, as it does not provide sufficient information for the authors to make informed decisions about how to improve their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation used in the results section, noting that the paper claims a 3% improvement for CIFAR10 but does not specify what the \"%p\" stands for. This feedback is clear and actionable, as it directs the authors to clarify the notation and provide a precise definition of the percentage improvement. By addressing this issue, the authors can improve the clarity and accuracy of their results presentation, making the paper more understandable. The comment is 4 as it provides a clear direction for improvement, though it could be more comprehensive if it suggested specific ways to clarify the notation. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This provides a clear and explicit action for the authors to take, as they can directly address the ambiguity in the title. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the clarity of the title. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. However, it does not provide specific guidance on which part of the paper this issue is related to, such as a particular section or figure. The authors may need to infer that the title is ambiguous, but the comment lacks full grounding. It is specific in its suggestion to clarify the title, but the lack of grounding makes it difficult for the authors to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim fully. The authors would need to infer the need for clarification based on the suggestion, which could be improved with additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This is a valuable piece of feedback as it helps the authors ensure that their work is accurately represented and easily understood by the readers. By addressing this ambiguity, the authors can enhance the clarity and precision of their paper, making it more impactful. The comment is specific and actionable, providing a clear direction for improvement, but it could be more helpful if it suggested specific ways to clarify the title. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. While the comment identifies a potential issue with the evaluation methodology, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider using a human metric instead of an automatic one. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper discusses the human evaluation or the use of TSS. This makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific about the issue of using an automatic metric, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support why an automatic metric might be less convincing or why a human metric is preferable. Without additional justification or evidence, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the use of an automatic metric TSS for human evaluation, questioning its effectiveness compared to a human metric. This feedback highlights a potential weakness in the evaluation methodology, which could impact the convincingness of the human evaluation results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what changes they could make to their draft. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues with the authors\" draft: the lack of confidence intervals for their results and the limited evaluation on only two datasets. While the comment identifies these areas as needing improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to include confidence intervals and expand their evaluation to more datasets. This lack of explicit action makes the comment 3, as the authors can deduce the necessary steps but do not have a clear roadmap for implementation. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of confidence intervals for the results and the limited evaluation on only two datasets. However, it does not specify which part of the paper these issues are discussed or how they should be addressed. The authors are left to infer that these issues need to be addressed in the results section or the evaluation section. The comment is weakly grounded as it does not provide explicit references to specific sections or parts of the paper. It is also somewhat specific in that it identifies the need for confidence intervals and the limitation of the evaluation to two datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment provides references to relevant works that have evaluated similar aspects, suggesting that the authors should consider expanding their evaluation to include more datasets and potentially include confidence intervals. However, the claim lacks detailed reasoning or specific examples to fully support the assertion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the authors\" draft: the lack of confidence intervals for their results, which makes it difficult to assess the statistical significance of performance gains. It also points out that the evaluation is limited to only two datasets, which may not be sufficient to generalize the findings. The comment provides references to relevant works in the RLP community, suggesting that the authors should consider expanding their evaluation to include more datasets and potentially include confidence intervals. This feedback is clear and actionable, as it directs the authors to address specific areas of their draft that need improvement. However, it could be more helpful if it provided more detailed guidance on how to include confidence intervals or expand the evaluation. Overall, the comment is 4, as it effectively highlights important areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to include the training losses or what specific information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or experimental setup, but without explicit mention, the comment is weakly grounded. The comment is specific in that it identifies a potential issue with the training process and suggests including training losses, which provides a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not provide any reasoning, examples, or references to support why this is a concern or how the inclusion of training losses would address the issue. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or examples on how to address the issue. The comment is 3 as it points out a potential area for further exploration, but it does not offer actionable advice or suggestions for improvement, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide explicit guidance on how the authors should address this overclaiming or what specific aspects need to be revised. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the overclaiming of the BC loss and provides a clear explanation of why the different aspects are considered the same concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential overclaiming of the proposed BC loss in the theoretical analysis section, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. This feedback is 3 as it points out a potential issue with the paper\"s claims, but it lacks specific guidance on how the authors might address this concern or what changes could be made to clarify the distinction. The comment provides a clear direction for improvement but does not offer detailed suggestions or actionable steps, which limits its overall impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are questioned about the fairness of this comparison. While the comment identifies a potential issue and suggests a possible reason for unfair comparison, it does not provide explicit guidance on how to address this concern or what specific changes should be made to the training process. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of the 2x samples on the running speed and consider whether the comparison is fair. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the training process, noting that RegMixup sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, leading to a slower running speed compared to other methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, specifically noting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. This observation raises concerns about the fairness of the comparison with other methods. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how to address this issue or improve the comparison. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using focal loss in regression tasks, specifically focusing on the potential issue of lower gradients for easy samples leading to inaccurate predictions. It suggests that the authors might be aiming for a unified approach without considering the differences between classification and regression tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for further clarification or discussion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of focal loss in regression tasks, specifically questioning its application in the context of IoU regression. It highlights the difference between focal loss\"s effectiveness in classification tasks, where it handles class imbalance, and its potential issues in regression, where lower gradients for easy samples might lead to inaccurate predictions. However, the comment does not specify which part of the paper discusses the use of focal loss or the IoU regression, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of focal loss in regression, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind using focal loss in regression tasks, specifically focusing on the potential issue of lower gradients for easy samples leading to inaccurate predictions. It highlights the difference between focal loss\"s effectiveness in classification tasks and its potential issues in regression, particularly in the context of IoU regression. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of detailed explanation or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the use of focal loss in regression tasks, specifically questioning its effectiveness in IoU regression. It points out that while focal loss is effective for class imbalance in classification, its lower gradients for easy samples might lead to inaccurate predictions in regression tasks. This observation suggests that the authors might be aiming for a unified approach without considering the differences between classification and regression tasks. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer the need for further clarification or discussion, which limits the comment\"s overall impact."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any explicit or implicit actions for the authors to take to address this question. The comment lacks guidance on how the authors might investigate or address the scalability issue, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the scalability issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any claim, judgment, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this issue. Without actionable advice or insights, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific datasets to include or how to analyze the results. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, it does not specify which parts of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more datasets, but without clear references to specific sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or examples, the claim is considered 2, as it provides a general direction but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is 3 as it points out a potential area for improvement in terms of dataset diversity and generalizability. However, the comment lacks specific guidance on which datasets to include or how to analyze the results, making it somewhat incomplete. The authors would benefit from additional details on how to implement this suggestion effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant concern regarding the lack of implementation details for the proposed methods, which the authors should address in Section 4.1. While the comment explicitly suggests that the authors should include these details, it does not provide specific guidance on what aspects of the implementation should be included or how to present them effectively. The action is clear and explicit, but it lacks concrete details on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a clear and specific issue. It also suggests that these details should be included in Section 4.1, providing a clear reference point for the authors. This feedback is fully grounded as it explicitly mentions the section where the implementation details should be added, and it is specific in detailing what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a concern regarding the lack of implementation details for the proposed methods, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples, references, or reasoning to support why this is a significant issue or how it impacts the paper. Without additional context or evidence, the claim remains 3, as the authors may need to infer the importance of the missing details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for understanding and replicating the research. By pointing out the absence of these details, the reviewer provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on what kind of implementation details should be included or how they should be presented. Despite this, the feedback is 4 as it directs the authors to a specific area that needs attention, allowing them to enhance the clarity and reproducibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting the absence of empirical evaluation and comparison with other methods. It also questions the practical value of the contribution, suggesting that even theoretical papers should provide some justification for their significance. However, the comment does not offer any specific guidance or suggestions on how the authors might address these issues, such as proposing additional experiments, comparisons, or theoretical arguments. Without concrete actions or recommendations, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, which are specific aspects of the paper. It also questions the practical value of the contribution, which is a clear and specific issue. However, the comment does not provide detailed guidance on how to address these issues, such as suggesting specific experiments or comparisons. Therefore, the comment is 5, but it lacks actionable guidance, making it 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, questioning the practical value of the contribution. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of empirical evidence and comparison makes it difficult for the authors to understand the basis of the criticism. Therefore, the claim is 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It questions the practical value of the contribution, suggesting that even theoretical papers should provide some justification for their significance. This feedback is valuable as it highlights a significant gap in the paper\"s presentation and impact. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address these issues, such as proposing additional experiments or comparisons. Without specific recommendations, the comment is 4, as it directs the authors towards important areas for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential confusion in the manuscript regarding the use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the usage of P throughout the manuscript, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment identifies a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. It provides examples, such as equations (3) and (4) and line 44 in the appendix, where this confusion arises. This allows the authors to accurately pinpoint the part of the paper that needs clarification. The comment is specific in detailing what needs to be addressed, as it highlights the inconsistency and suggests that the authors should clarify the usage of P. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. The comment provides examples, such as equations (3) and (4) and line 44 in the appendix, where this confusion arises. However, it does not offer any additional reasoning, references, or examples to support the claim that this inconsistency leads to confusion. While the authors can infer that the comment is valid, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the manuscript, noting that the variable P is sometimes used as a probability and sometimes as a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it points out a potential source of ambiguity that could affect the clarity and understanding of the paper. However, the comment could be more helpful if it provided suggestions on how the authors might address this confusion, such as clarifying the usage of P throughout the manuscript or providing additional context. Overall, the comment is 4 as it highlights a significant issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the understanding of how neural networks learn natural rare spurious correlations. It also points out that most analysis and ablation studies use artificial patterns instead of natural spurious correlations, and that duplicating artificial patterns is different from natural spurious features. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to incorporate natural spurious correlations into their analysis or how to differentiate between artificial and natural patterns. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of how neural networks learn natural rare spurious correlations, which is a specific aspect of the paper. It highlights that the community is unaware of this, and that most analysis uses artificial patterns instead of natural ones. The comment also clarifies the difference between duplicating artificial patterns and natural spurious features. However, it does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and the distinction between artificial and natural patterns, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the community is unaware of how neural networks learn natural rare spurious correlations, and that most analysis uses artificial patterns instead of natural ones. The comment provides a logical explanation of the issue and highlights the difference between duplicating artificial patterns and natural spurious features. However, it lacks specific examples or references to support the claim about the community\"s unawareness. While the reasoning is clear, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the understanding of how neural networks learn natural rare spurious correlations. It points out that most analysis and ablation studies use artificial patterns instead of natural spurious correlations, which is a critical oversight. The comment also clarifies the difference between duplicating artificial patterns and natural spurious features, emphasizing the complexity and variability of natural spurious correlations. This feedback is valuable as it highlights an important area for improvement and suggests that the authors should consider incorporating natural spurious correlations into their analysis. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested additional experiments to explore the topic. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRMRL and asks if the algorithms can be applied in more general tasks. While the comment identifies a potential area for further exploration, it does not provide explicit guidance on how to address the limitations or how to expand the application of the method. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it can be applied in general MDP but is limited in navigation problems. It also references PRMRL, indicating that combining RL and planning has been discussed in that context. However, the comment does not specify which part of the paper discusses the method or navigation problems, making it weakly grounded. The comment is specific in suggesting that the authors explore the application of the algorithms in more general tasks, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also references PRMRL, suggesting that combining RL and planning has been discussed in that context. However, the comment lacks specific examples or detailed reasoning to fully support the claim. While the reference to PRMRL provides some context, the authors would need to infer the specific areas where the method is limited and how it could be applied more broadly. Therefore, the claim is 3, as it provides some basis but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method discussed can be applied in general MDP but is limited in navigation problems. It also references PRMRL, which has already explored the combination of RL and planning, suggesting that the authors could consider applying these algorithms in more general tasks. This feedback provides a clear direction for the authors to expand the scope and applicability of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to achieve this expansion, such as suggesting particular tasks or methodologies to explore. Overall, the comment is 4 as it highlights an area for improvement and provides a starting point for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion that individual standardization of feature dimensions could avoid this issue. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to modify their feature spaces or experiments. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of feature space suitability on 1NN performance and explore the suggestion of standardization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the suitability of feature spaces for 1NN and suggesting that standardizing feature dimensions could improve performance. This provides clear guidance on how to revise the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and suggests that standardizing feature dimensions could improve performance. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that feature spaces not close to a spherical Gaussian may perform poorly. The suggestion to standardize feature dimensions is clear, but the overall claim is 3 as it lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the suitability of feature spaces for 1NN and provides a suggestion that standardizing feature dimensions could improve performance. While it identifies a potential issue with the feature space, it does not offer detailed guidance or specific advice on how to address this concern or what changes might be necessary. The comment is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the definition of the \"contrastive gap,\" which is a core concept of the work. It points out that while an intuitive example is provided, the setting of this example is less convincing, and a clear, formal definition is still missing. However, the comment does not provide explicit guidance on how the authors should define the contrastive gap or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear and formal definition. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific part of the paper being addressed. It provides a clear and specific explanation of the issue, noting that the concept has not been defined clearly and lacks a formal definition. The comment also suggests that the setting of the example is less convincing, indicating a need for improvement in the example\"s presentation. This level of detail allows the authors to understand exactly what part of the paper needs attention and what specific issues need to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"contrastive gap\" has not been defined clearly, which is a subjective opinion. It suggests that the setting of the example is less convincing and that a clear, formal definition is lacking. However, the comment does not provide specific examples or references to support the claim that the definition is unclear or lacking. Without additional evidence or reasoning, the claim is difficult to verify, making it 2. Therefore, the comment is labeled as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out that the \"contrastive gap\" is not clearly defined. This is a critical oversight that could hinder the understanding and impact of the work. The comment suggests that while an intuitive example is provided, the setting of this example is less convincing, and a clear, formal definition is still lacking. This feedback is valuable as it highlights a specific area where the authors need to improve the clarity and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to define the contrastive gap or examples of how to make the setting of the example more convincing. Overall, the comment is 3 as it identifies a key weakness but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns and raised their score. However, the comment does not provide explicit guidance on how to incorporate these additional baselines or how to test beforehand whether the chosen baseline is the most appropriate. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work 29, 5, 6\" and \"other works discussed in related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including other baselines and testing beforehand, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that other baselines should be included, referencing specific works in the related work section. It also suggests that the authors have addressed their concerns and raised their score, indicating that the feedback is based on their response. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The authors are encouraged to include additional baselines, but the comment does not provide specific guidance on how to do so or why this is necessary. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns and raised their score, implying that the feedback is based on their response. However, the comment lacks detailed guidance on how to incorporate these additional baselines or how to test beforehand whether the chosen baseline is the most appropriate. While it provides a clear direction for improvement, the feedback could be more helpful if it included specific suggestions or examples of how to enhance the draft. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text (L_task) and the notation used in Figure 1 (L_class). This suggests that the authors should ensure consistency in their notation throughout the paper. However, the comment does not provide explicit guidance on how to address this inconsistency or what specific changes need to be made. The action is implicit, as the authors can infer that they need to correct the notation, but the lack of detailed instructions makes the action vague and challenging to execute. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a discrepancy in the notation used for the task loss, specifically noting that it is called L_task in the text but L_class in Figure 1. This provides a clear and specific reference to the part of the paper where the inconsistency is mentioned, allowing the authors to accurately identify the issue. The comment is fully grounded as it explicitly mentions the section or figure where the discrepancy is noted. It is also specific because it clearly specifies what needs to be addressed, which is the inconsistency in the notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and requires no further explanation or justification to be understood. The comment is a normal statement, as it describes a factual observation without making any claims or suggestions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and highlights a potential source of confusion for the readers. However, the comment does not provide any suggestions or guidance on how the authors might address this inconsistency or improve the clarity of their notation. While it points out a minor issue, it lacks actionable advice, making it 3. The authors would need to infer that they should ensure consistency in their notation, but the comment does not offer detailed steps or examples to facilitate this process. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these limitations or what specific aspects of the method need to be improved. Without clear instructions or suggestions, the authors are left without a clear path to respond to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or how the authors should respond. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples to substantiate the assertion about the method\"s limitations. Without such support, the authors are left without a clear understanding of the basis for the critique, making it difficult to address the comment effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide any specific suggestions or guidance on how the authors might address these limitations or improve their method. The comment lacks actionable feedback, leaving the authors without a clear understanding of what changes are needed or how to proceed. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It implies that the current evaluation, which only includes answer generation and summarization, is close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment provides a clear action for the authors to take, which is to include machine translation in their evaluation. However, it does not specify how to implement this suggestion, such as which datasets or metrics to use. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the evaluation of the proposed method should include machine translation, which is considered a \"close domain\" generation task, as opposed to the current \"open domain\" tasks of answer generation and summarization. However, the comment does not specify which part of the paper discusses the evaluation methodology or which sections should be expanded to include machine translation. This makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the type of evaluation that should be included, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation of the proposed method is limited to answer generation and summarization, which are considered close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that including machine translation would make the evaluation more convincing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed justification or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2, as it provides a suggestion but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization, which are considered close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that including machine translation would make the evaluation more convincing. This feedback is 3 as it points out a specific area for improvement and provides a clear direction for the authors to consider. However, it lacks depth and does not offer detailed guidance on how to implement the suggested evaluation or what specific aspects of machine translation to focus on. Therefore, the comment is rated as 3, as it provides a clear direction but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is explicit in its request for clarification, it does not provide any guidance or suggestions on how the authors might address these questions or improve their draft. The action is implicit, as the authors need to infer that they should clarify these details in their paper. However, the lack of concrete guidance on how to implement or address these questions makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and refers to the \"response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the \"dropping rate\" and the \"number of masks generated,\" providing clear guidance on what needs to be addressed. Therefore, this comment is classified as 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is factual and seeks clarification, it does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the implementation details of the dropout mechanism, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it directs the authors to provide more detailed information about their implementation. However, the comment could be more helpful if it suggested ways to improve the clarity or consistency of the description, or if it provided examples of how to present this information effectively. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth in terms of actionable suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that it does not provide information about the type of GPUs used and the inference time during testing. However, it does not offer any explicit or implicit suggestions on how the authors might address this gap. The comment lacks guidance on what actions the authors should take to include this information, leaving them without a clear path forward. As a result, the comment is 1, as it does not provide any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing information regarding the type of GPUs and inference time when testing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a factual issue regarding the lack of information about the type of GPUs and inference time when testing in the paper. However, it does not provide any reasoning, examples, or references to support why this information is important or how it impacts the paper. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that it does not provide information about the type of GPUs used and the inference time during testing. This feedback is clear and actionable, as it highlights a crucial aspect that needs to be addressed for the paper to be more comprehensive and informative. However, the comment could be more helpful if it suggested specific ways the authors might include this information or how it could be presented effectively. Overall, the comment is 3 as it points out a significant area for improvement, but it lacks depth in terms of actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node attends to its own lowerlevel representation, based on the description of equation 2. While it implies that the authors should clarify this aspect, the comment does not provide explicit instructions or suggestions on how to address this issue. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether each node attends to its own lowerlevel representation, based on the description of equation 2. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its focus on the description of equation 2, but without explicit mention of the section or equation, the authors may need to infer the relevant part. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether each node attends to its own lowerlevel representation, based on the description of equation 2. However, it does not provide any evidence, reasoning, or references to support this claim or question. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about whether each node attends to its own lowerlevel representation, based on the description of equation 2. This question highlights a potential ambiguity in the paper\"s description, which could lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify their description. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer what changes might be necessary to address the question, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the results of the bottomup method 9 on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. While the comment provides explicit guidance on what data to include and how to evaluate performance, it lacks specific instructions on how to implement these suggestions, such as which columns or metrics to focus on. The action is somewhat vague, as it does not provide detailed steps or examples for inclusion and evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the bottomup method 9\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what data to include in the table and how to evaluate the performance of the authors\" method on the MS COCO dataset, particularly in easy (nonoccluded) settings. This level of detail helps the authors understand exactly what needs to be addressed and how to do it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the results of the bottomup method 9 on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. While the comment provides a clear suggestion for improvement, it lacks specific examples or detailed reasoning to support why this inclusion would be beneficial. The authors would need to infer the rationale behind the suggestion, which could be challenging. Therefore, the comment is barely verifiable, as it lacks sufficient evidence or justification to fully understand the reasoning behind the suggestion.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by including the results of the bottomup method 9 on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. This feedback is actionable and constructive, as it guides the authors on what additional data and analysis to include to strengthen their work. However, the comment could be more helpful if it provided more detailed guidance on how to present the results or what specific metrics to focus on. Overall, the comment is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The authors are left without guidance on how to revise their claims or incorporate a more nuanced understanding of annotation guidelines. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples from the TACRED slot filling guidelines, illustrating the complexity of annotation guidelines and suggesting that the paper might not fully capture this depth. This feedback is clear and specific, guiding the authors on how to revise their claims or improve their understanding of annotation guidelines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s use of \"annotation guideline\" may be an overstatement, suggesting that the paper only considers label names, descriptions, and fewshot examples, while annotation guidelines in the IE domain are complex and curated by linguists. The reviewer provides specific examples from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines. This provides a clear and detailed basis for the claim, making it 4. However, the comment could be strengthened by explicitly referencing the paper or providing more detailed examples of how the proposed prompts might not fully capture the depth of true guideline understanding. Overall, the comment is 4.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper\"s claim regarding the use of \"annotation guideline.\" It provides specific examples from the TACRED slot filling guidelines, highlighting the complexity of annotation guidelines in the Information Extraction (IE) domain. This critique is valuable as it challenges the authors to reconsider the scope and depth of their work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or provide additional context to support their claims. As it stands, the feedback is 3, as it prompts the authors to refine their understanding and claims, but it lacks detailed guidance on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential weakness in the paper by stating that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might identify or discuss these weaknesses, leaving the authors without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for improvement. Therefore, this comment aligns with a score of 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the authors did not show the possible weaknesses of the proposed model. It lacks any reference to a specific section, table, or figure, making it difficult for the authors to identify the exact area that needs improvement. Additionally, the comment is not specific because it does not provide any details on what aspects of the model\"s weaknesses are not addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the authors did not show the possible weaknesses of the proposed model. This feedback is clear and actionable, as it directs the authors to address a specific area that needs improvement. However, the comment could be more helpful if it provided additional guidance on how to identify or discuss these weaknesses, such as suggesting specific analyses or comparisons that could be included. Despite this, the comment is 4 as it highlights a critical aspect of the paper that needs attention, providing a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the introduction of related work is not sufficient and suggests that more work on GLN should be included to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. While the comment identifies a gap in the related work section, it does not provide explicit guidance on how to address this issue or what specific aspects of GLN should be discussed. The action is implicit, as the authors would need to infer that they need to expand the related work section to include more details about GLN and its differences from BGLN. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this refers to, making it weakly grounded. The comment is specific in that it suggests including more work on GLN to reflect the advantages or differences of the proposed method, particularly mentioning the difference from BGLN. This provides clear guidance on what needs to be addressed in the related work section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is not sufficient and suggests that more work on GLN should be given to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the introduction of related work. It points out that the current introduction is not sufficient and suggests that more work on GLN should be included to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by expanding the related work section. However, the comment could be more helpful if it offered additional guidance on which specific aspects of GLN should be discussed or how to effectively compare the proposed method with BGLN. Overall, the comment is 4, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout and recurrent dropout parameters are used. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider using multiple dropout rates for Moon\"s approach to align with the other methods. While the suggestion is concrete, the lack of explicit guidance on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment questions the use of a single dropout rate for Moon\"s approach, suggesting that Variational dropout and recurrent dropout parameters are used. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the method but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind using only one dropout rate for Moon\"s approach, suggesting that Variational dropout and recurrent dropout parameters are used. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout and recurrent dropout parameters are used. This feedback is 3 as it points out a potential inconsistency in the methodology and prompts the authors to consider alternative approaches. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is clear and actionable, but it could be more comprehensive to fully assist the authors in improving their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While it implies that the authors should consider optimizing and validating their approach, the comment does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed for optimization and validation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that ProtPainter provides an empirical conformation estimation but lacks further optimization and validation, suggesting that these aspects need to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While the comment suggests that further optimization and validation are required, it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. This feedback is clear and actionable, as it directs the authors to consider enhancing the optimization and validation aspects of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to optimize and validate the approach. Despite this, the feedback is 4 as it highlights a crucial area for improvement, allowing the authors to focus on enhancing their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more evaluation would be beneficial, particularly for CIFAR10 in full label and lower label scenarios. However, it does not provide explicit guidance on what specific evaluations should be conducted or how the authors should approach this additional evaluation. The action is implicit, as the authors need to infer that they should add more evaluations, but it lacks concrete details on what to evaluate or how to implement this suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, especially for CIFAR10 in full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be conducted in or how it should be integrated. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while it suggests the need for more evaluation, it does not provide specific details on what kind of evaluation is required or how it should be conducted, making it specific but not fully specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, particularly for CIFAR10 in full label and lower label scenarios. However, it does not provide any specific reasoning, examples, or references to support why this additional evaluation is necessary or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, especially for CIFAR10 in full label and lower label scenarios. However, it lacks specificity and does not provide detailed guidance on what kind of additional evaluation is needed or how it should be conducted. While it points out a potential area for improvement, the comment does not offer actionable advice or suggestions for enhancing the paper\"s evaluation, making it 3. The authors would need to infer that they should add more evaluations, but the comment does not provide enough detail to guide them effectively. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting that it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several issues, it does not provide explicit guidance on how to address them or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific guidance on how to address these issues further reduces the comment\"s effectiveness. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the issues and how to address them. The lack of detailed justification or references makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several areas for improvement, it lacks specific guidance on how the authors might address these issues or what actions they should take. The feedback is 3 as it highlights areas that need attention, but it does not provide detailed suggestions or actionable steps for the authors to take, which limits its overall impact. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment does not explicitly instruct the authors to remove or reorganize the section, nor does it provide specific guidance on how to better integrate the description of the proposed methodology with the model choice or how to use the time spent on ResNet architecture more effectively. The action is implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in suggesting that the description of the proposed methodology should be better integrated with the model choice and that the time spent on ResNet architecture could be used more effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or logical arguments to substantiate the assertion that the description of the proposed methodology is independent of the model choice or that the time spent on ResNet architecture could be better used. As a result, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of Section 2.1, specifically questioning the relevance of Batch Normalization in the context of the proposed Conditional Batch Normalization (CBN) approach. It suggests that the description of the methodology might be independent of the model choice and that the time spent on describing the ResNet architecture could be better utilized to provide motivation and intuition for the CBN approach. This feedback is 3 as it points out a potential area for improvement in the paper\"s structure and clarity. However, it lacks specific guidance on how to address these issues or what changes might be necessary, which limits its overall impact on the authors. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It highlights a potential inconsistency in the reasoning, suggesting that multiplying by a nicelyconditioned matrix might not result in a sparse matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for clarification or correction. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue raised in the paper at line 122, where the authors assume a dense projection matrix multiplication leads to a sparse matrix. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly explains the inconsistency in the reasoning and questions the assumption, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It highlights a potential inconsistency in the reasoning, suggesting that multiplying by a nicelyconditioned matrix might not result in a sparse matrix. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the assumption is incorrect or how it affects the overall argument. Without additional context or evidence, the claim remains somewhat 1. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper regarding the assumption made in equation (1) about the sparsity of the resulting matrix after multiplication by a dense projection matrix. It questions the reasoning behind this assumption, suggesting that multiplying by a nicelyconditioned matrix might not result in a sparse matrix. This feedback is clear and actionable, as it highlights a potential inconsistency in the paper\"s logic and provides a specific area for the authors to address. By pointing out this issue, the comment helps the authors clarify their reasoning and ensure the accuracy of their claims. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It also provides a reference to support the claim that initialization should play a role, such as pretraining. However, the comment does not explicitly instruct the authors to revise the statement or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the statement to be more precise. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the role of initialization in the context of NGD and NGF, suggesting that it should be more carefully stated. It references a specific paper to support the claim that initialization should play a role, such as pretraining. However, the comment does not specify which part of the paper discusses initialization or where the reference is located, making it weakly grounded. The comment is specific in its suggestion to revise the statement about initialization, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It provides a reference to support this claim, referencing a specific paper that discusses the limitations of the empirical Fisher approximation for natural gradient descent. The reference is relevant and provides context for the claim, making it 4. However, the comment could be more robust if it included a brief explanation of why the reference is relevant or how it supports the claim. Overall, the comment is 4.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by providing more detail about the role of initialization in the context of NGD and NGF. It suggests that the statement about initialization should be more carefully stated and provides a reference to support the claim that initialization should play a role, such as pretraining. This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their writing. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of initialization should be emphasized. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to improve readability. While the comment explicitly mentions the need for clarification regarding the extraction process, it does not provide specific guidance on how to achieve this. The suggestion for English proofreading is clear and actionable, as it indicates a direct action the authors should take. However, the lack of detailed guidance on how to improve the extraction process makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the extraction of named entities from the datasets, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The comment also suggests that English proofreading would improve readability, but it does not specify which part of the paper would benefit from this. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that it is not clear how named entities were extracted from the datasets, and that English proofreading would significantly improve the readability of the paper. While the comment identifies a potential issue with the clarity of the extraction process, it does not provide specific examples or references to support the claim about the lack of clarity. Similarly, the suggestion for English proofreading is logical but lacks detailed justification or examples of how it would improve readability. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two key areas for improvement: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to enhance readability. While the comment points out these issues, it does not provide specific guidance or suggestions on how to address them. The feedback is 3 as it highlights areas that need attention, but it lacks depth and actionable advice, making it only partially beneficial for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the paper, noting that the variables L and E are not consistently defined and sometimes italicized, which can lead to confusion for the reader. While the comment highlights the inconsistency, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to ensure consistent definitions and formatting of L and E throughout the paper. This lack of explicit action makes the comment 3, as it points out a clear issue but does not provide detailed steps on how to resolve it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296\" and \"Line 302,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent definitions and formatting of variables L and E, which needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue regarding the inconsistent definition and formatting of variables L and E in the paper. It points out that these variables are sometimes italicized and sometimes not, which can lead to confusion for the reader. However, the comment does not provide any additional context, reasoning, or references to support why this inconsistency is problematic or how it affects the paper. Without further explanation or evidence, the authors may find it challenging to understand the significance of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the variables L and E are not consistently defined and sometimes italicized, which can lead to confusion for the reader. While the comment highlights a minor but important detail, it does not provide any suggestions or guidance on how the authors might address this inconsistency. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and implement the suggested changes. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should consider including these comparisons, it does not explicitly instruct them to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to include more comparisons, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for more comprehensive comparisons. However, the comment lacks specific guidance or suggestions on which models or techniques should be included, making it somewhat vague and incomplete. The authors would need to infer that they should expand their comparisons, which could be challenging without further direction. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the use of \"Despite of\" and \"to a even deeper,\" and to correct the grammatical error on line 265. These instructions are clear and direct, allowing the authors to understand exactly what changes are needed. However, the comment does not provide additional guidance on how to achieve these changes or what specific aspects of the writing should be improved. Therefore, the comment is 4, as it provides explicit instructions but lacks detailed guidance on implementation. This aligns with a score of 4.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper, focusing on lines 2, 56, 158, and 265. It explicitly instructs the authors to revise the sentences to remove specific phrases and correct a grammatical error. This allows the authors to accurately identify the parts of the paper that need revision, making the comment fully grounded. Additionally, the suggestions are specific, detailing what needs to be changed in each instance. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of four specific suggestions for improving the writing style and clarity of certain sentences in the paper. Each suggestion is clear and provides explicit instructions on how the authors should revise the sentences. However, the comment does not offer any reasoning, examples, or references to support why these changes are necessary or beneficial. While the suggestions are actionable, the lack of justification or explanation makes it difficult for the authors to fully understand the reasoning behind the feedback. Therefore, the comment is rated as 3, as it provides some justification but lacks key elements for full understanding and application.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It instructs the authors to revise sentences on lines 2, 56, and 158 to remove specific phrases and correct a grammatical error on line 265. These suggestions are clear and actionable, offering the authors a clear path to improve the clarity and grammatical correctness of their text. However, the comment could be more helpful if it provided additional guidance on how to achieve these changes or what specific aspects of the writing should be improved. Overall, the feedback is 4, as it directs the authors towards specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This suggests that the authors should clarify the distinction between these two concepts and correct any errors in the equations. However, the comment does not provide explicit guidance on how to address the issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the concepts and correct the equations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This allows the authors to accurately identify the part of the paper being addressed, providing full grounding. The comment is specific in its request for clarification and correction regarding the equations, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This is a factual question that requires the authors to clarify the distinction between these two concepts and correct any errors in the equations. However, the comment does not provide any additional context, reasoning, or references to support the claim. As a result, the authors are left to interpret the question and address it independently, making the comment 1.", "helpfulness_rationale": "The review comment raises a specific question about the inversion of matrix determination or the number of samples, particularly in the context of equations labeled \"W4.\" This feedback is clear and actionable, as it directs the authors to clarify the distinction between these two concepts and correct any potential mistakes in the equations. By addressing this issue, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided additional context or guidance on how to approach the clarification. Overall, the comment is 4, as it identifies a specific area for improvement and encourages the authors to make necessary corrections."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests that it might be easier to model without staterelated registers. It also proposes an interesting comparison between sequential and combinational design. However, the comment does not provide explicit guidance on how the authors should address this question or what specific actions they should take to improve their draft. The suggestion for comparison is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests that it might be easier to model without staterelated registers. It also proposes an interesting comparison between sequential and combinational design. However, the comment does not specify which part of the paper this question or suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs attention. The lack of specific grounding makes it challenging for the authors to understand the context and relevance of the comment. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests that it might be easier to model without staterelated registers. It also proposes an interesting comparison between sequential and combinational design. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the proposed method performs better in pure combinational logic or that it is easier to model without staterelated registers. Without such evidence, the authors are left without a basis for addressing the question or making the suggested comparison. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests that it might be easier to model without staterelated registers. It also proposes an interesting comparison between sequential and combinational design. However, the comment lacks specific guidance or suggestions on how the authors might address this question or what experiments could be conducted to provide a more comprehensive analysis. While it identifies an area for improvement, it does not offer actionable advice or detailed insights that would help the authors enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it suggests that the authors should provide this information, it does not explicitly instruct them to include it in the draft or specify how to calculate or present the results. The action is implicit, as the authors need to infer that they should add this information to the experiment section. However, the lack of detailed guidance on how to implement this suggestion makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment section where the authors have designed a baseline combining LDA and LSTM. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it requests the performance of this baseline in terms of the topic switch percent metric, which is a clear and actionable request for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of a baseline model in terms of the topic switch percent metric. However, it does not provide any specific reasoning, examples, or references to support why this metric is important or how it should be evaluated. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of a baseline model in terms of the topic switch percent metric. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what data might be relevant. The comment lacks actionable advice, such as suggesting alternative metrics or providing examples of how to analyze the results. As a result, the feedback is 3, as it highlights a potential area for improvement but does not offer detailed guidance on how to enhance the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study, as it is crucial for understanding these synergies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, specifically noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study. However, the comment does not specify which part of the paper discusses the synergies or the comparison to TD3GA, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the study. However, the comment lacks specific examples or references to support the claim about the insufficiency of backing, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, requiring the authors to infer the need for more detailed discussion and comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It suggests that the comparison to TD3GA should be central to the study. However, the comment lacks detailed guidance on how the authors should address this issue or what specific actions they should take to improve their draft. While it points out a critical gap in the paper, it does not provide actionable steps or suggestions for improvement, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the use of the word \"confident\" in the context of applying ceterus paribus convexity, specifically questioning whether it refers to model confidence or human interpretability. While the comment identifies a potential point of confusion for the authors, it does not provide explicit guidance on how to address this issue or suggest specific actions to clarify the concept. The action is implicit, as the authors would need to infer that they need to rephrase the sentence to avoid ambiguity. However, the comment lacks concrete details on how to rephrase the sentence or what specific aspects to focus on. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the confusion arises, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the use of the word \"confident,\" questioning whether it refers to model confidence or human interpretability. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about the use of the word \"confident\" in the context of applying ceterus paribus convexity, specifically questioning whether it refers to model confidence or human interpretability. While the comment identifies a potential point of confusion, it does not provide any supporting evidence, examples, or references to clarify the issue. The authors are left to infer the meaning and implications of the word, which may hinder their understanding of the concept. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential point of confusion regarding the use of the word \"confident\" in the context of applying ceterus paribus convexity. It questions whether the word refers to model confidence or human interpretability, which could lead to ambiguity for the authors. While the comment highlights a specific issue that needs clarification, it does not provide detailed guidance or suggestions on how to rephrase the sentence to avoid confusion. The feedback is 3 as it points out a potential area of confusion, but it lacks depth and actionable advice, making it only marginally helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the novelty of the work is limited, pointing out that tighter confidence intervals (CIs) with finetuning are expected outcomes. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might enhance the novelty of their work or what specific aspects need to be improved to make the findings more impactful. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the work is limited, pointing out that tighter confidence intervals (CIs) with finetuning are expected outcomes. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is 1 as it does not provide specific guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, suggesting that tighter confidence intervals (CIs) with finetuning are expected outcomes. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the work, suggesting that the findings might be expected outcomes of taskspecific finetuning. While it points out an area for consideration, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully address the concern. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this question or what aspects of their work could be improved to clarify this point. As a result, the authors are left without any actionable feedback, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it does not provide explicit references to specific sections, tables, or figures. Additionally, it does not specify what needs to be addressed in this context, leaving the authors with no clear direction for improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any claim, judgment, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any new insights or critiques that would help the authors improve their work. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. This question highlights a potential gap in the paper\"s discussion of the practical implications of the proposed method. However, the comment does not provide any suggestions or insights on how the authors might address this gap or improve the clarity of their work. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation section, including the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of incontext examples. It also notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the evaluation section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of incontext examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of mention of the number of different sets of incontent examples used in the experiments and the lack of exploration of the effects of varying the number of incontext examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. These claims are supported by logical reasoning and specific examples, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims about the limitations of the evaluation.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding the comprehensiveness and transparency of the evaluation section. It highlights the lack of detail in the experiment setup, such as the absence of information on the number of different sets of incontent examples used. Additionally, it points out the lack of exploration of the effects of varying the number of incontext examples, which is a crucial aspect for understanding the robustness of the results. The comment also notes that the evaluation relies solely on one dataset, which may limit the generalizability of the findings. These observations provide valuable feedback to the authors, offering specific areas for improvement and suggesting that the evaluation section should be expanded to include more detailed information and analysis. However, the comment could be more helpful if it provided additional guidance on how to address these issues or suggested specific experiments that could be conducted to enhance the evaluation. Overall, the comment is 4 as it identifies key areas for improvement but lacks some depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the related work should be considered. The action is implicit, as the authors need to infer that they should expand their discussion of related work to include these references. While the comment is 3, it lacks concrete details on how to implement the suggested improvement, making it 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, it does not specify which part of the paper this issue pertains to, such as the introduction, related work section, or discussion. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in suggesting the need for additional related work, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, the comment lacks specific details or reasoning to support why these references are particularly relevant or how they would enhance the paper. Without additional context or explanation, the claim is difficult to verify or fully understand. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, the comment lacks specificity and does not provide any guidance on how the authors should address this issue or what aspects of related work should be considered. Without concrete suggestions or examples, the authors may find it challenging to understand the nature of the improvement needed. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer actionable feedback. The score aligns with a rating of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific aspects of the algorithmic focus they should consider. The comment implies that the authors should expand on the algorithmic aspects, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. While the comment implies that the authors should consider expanding on the algorithmic aspects, it lacks specificity in terms of what exactly needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should have focused more on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. This feedback highlights a specific aspect that could enhance the paper\"s novelty and impact. However, the comment lacks depth and does not provide specific guidance on how the authors might address this suggestion or what particular aspects of the algorithmic focus they should consider. While it points out a potential area for improvement, it does not offer actionable steps or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with the most closely related work of Zemel et al. (2013) more systematic, particularly by comparing the best performance of each method. However, the comment does not provide explicit guidance on how to achieve this, such as suggesting specific metrics or approaches for comparison. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the most closely related work of Zemel et al. (2013), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making the comparisons more systematic, particularly by comparing the best performance of each method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the most closely related work of Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. However, the comment lacks specific details or examples of how this comparison could be made more systematic or how the best performance of each method should be determined. Without additional guidance or examples, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the comparisons with the most closely related work of Zemel et al. (2013) could be made more systematic, particularly by comparing the best performance of each method. This feedback is clear and actionable, as it provides a concrete direction for enhancing the paper\"s analysis and comparisons. However, the comment could be more helpful if it offered additional guidance on how to systematically compare the methods or suggested specific metrics for evaluating performance. Overall, the comment is 4, as it provides a clear and actionable suggestion for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, specifically referencing Chapter 4 of Steinwart and Christmann. While it prompts the authors to explore this connection, it does not provide explicit guidance on how to address it or what specific aspects of the connection should be investigated. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the connection further. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the connection between the third point and the properties of universal kernels, referencing a specific chapter in a relevant work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing Chapter 4 of Steinwart and Christmann. While the comment provides a specific reference to a relevant work, it does not offer a detailed explanation or justification for why this connection is important or how it relates to the paper\"s content. The lack of explicit reasoning or examples makes it 3, as the authors would need to infer the relevance of the reference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the connection between the third point of definition one and the properties of universal kernels, referencing a relevant work by Steinwart and Christmann. This feedback is 3 as it prompts the authors to explore a potential link that could enhance the depth and rigor of their paper. However, the comment lacks detailed guidance on how to investigate this connection or what specific aspects of the relationship should be explored. While it provides a direction for improvement, it does not offer comprehensive suggestions or actionable steps, making it 3."}
