{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a revision due to the lack of clarity in the precise steps of the methodology. However, it does not provide explicit guidance on what specific aspects need clarification or how the authors should revise the paper to address this issue. The action is implicit, as the authors need to infer that they should improve the clarity of the methodology section. The comment is 3 because it identifies a specific area for improvement but lacks concrete details on how to implement it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a revision due to the lack of clarity in the precise steps of the methodology, particularly in the context of minmax optimization for PDEs with advective terms. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in identifying the issue with the methodology\"s clarity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper would benefit from a revision due to the lack of clarity in the precise steps of the methodology, especially in the context of minmax optimization for PDEs with advective terms. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of clarity in the methodology section, particularly concerning the minmax optimization for PDEs with advective terms. It suggests that the paper would benefit from a revision to improve the clarity of the methodology. However, the comment lacks specific guidance on what aspects of the methodology need clarification or how the authors should revise the paper to address this issue. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale for using the original proposal (Algorithm 1) over a modified learning algorithm (Definition 5.1) in practice. While it does not explicitly instruct the authors to provide a justification or explanation, it implies that the authors should consider why the modified algorithm, which is defined for theoretical analysis, is not used in practice. The action is implicit, as the authors need to infer that they should provide a rationale for their choice. However, the action is vague because it does not specify how to justify the use of the original algorithm or what factors should be considered. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the rationale for using the original proposal (Algorithm 1) over a modified learning algorithm (Definition 5.1) in practice. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or why the original algorithm should be preferred. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the rationale for using the original proposal (Algorithm 1) over a modified learning algorithm (Definition 5.1) in practice. However, it does not provide any specific reasoning, examples, or references to support why the original algorithm should be preferred. The comment lacks detailed justification or explanation, making it difficult for the authors to understand the basis for the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale for using the original proposal (Algorithm 1) over a modified learning algorithm (Definition 5.1) in practice. While it raises a valid point about the practical implications of using a modified algorithm for theoretical analysis, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable advice or detailed reasoning, making it 3 as it highlights an area for improvement but does not offer comprehensive feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the practical utility of the diversity coefficient as a data quality metric. It notes that the paper does not provide empirical validation for this claim, which is a significant issue, especially given the emphasis on Task2Vec and model diversity. However, the comment does not explicitly instruct the authors to validate the claim or provide guidance on how to do so. While the authors can infer that they need to address this issue, the action is implicit and somewhat vague, as it lacks specific details on how to validate the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"diversity coefficient\" as a potential data quality metric, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the lack of empirical validation for this claim, particularly in the context of Task2Vec and model diversity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not empirically validate the use of the diversity coefficient as a data quality metric, which is a significant concern given the emphasis on Task2Vec and model diversity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed evidence or guidance, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the practical utility of the diversity coefficient as a data quality metric. It highlights that the paper does not provide empirical validation for this claim, which is a critical issue, especially considering the emphasis on Task2Vec and model diversity. This feedback is valuable as it directs the authors to a specific area that needs further investigation or validation. However, the comment could be more helpful if it provided suggestions on how to empirically validate the claim or examples of how such validation could be conducted. Overall, the comment is 4 as it points out a crucial gap in the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using canary clients is less efficient than using canary examples, implying that more resource allocation might be needed. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to implement the proposed changes. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that using canary clients is less efficient than using canary examples, implying that more resource allocation might be needed. However, it does not specify which part of the paper discusses the use of canary clients or examples, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is vague and lacks specificity, as it does not provide detailed guidance on how to address the inefficiency or what specific changes should be made. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that using canary clients is less efficient than using canary examples, suggesting that more resource allocation might be needed. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the assertion about the inefficiency of using canary clients. Without such evidence, the claim remains unsubstantiated, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential inefficiency in the use of canary clients compared to canary examples, suggesting that more resource allocation might be needed. However, the comment lacks specific details or suggestions on how the authors could address this issue or what changes might be necessary to improve their draft. While it points out a potential area for improvement, it does not provide actionable guidance or detailed feedback that would help the authors enhance their work. Therefore, the comment is 3, as it highlights a potential area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point questions the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM, as indicated by Equation (4) in another paper. However, the comment does not provide explicit guidance on how the authors should address this concern or clarify the relevance of \"Carefl\" in their paper. The action is implicit, as the authors need to infer that they should explain the relevance of \"Carefl\" or provide a justification for its inclusion. The comment is 3 because it identifies a potential issue but lacks concrete steps for the authors to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM, as indicated by Equation (4) in another paper. However, the comment does not specify which part of the paper \"Carefl\" is mentioned or how it is relevant to the authors\" work. The authors cannot confidently determine which section or part of the paper needs clarification. While the comment provides some specificity by mentioning \"nonlinear SEM,\" it lacks full grounding as it does not pinpoint the exact location of the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM, as indicated by Equation (4) in another paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks a clear explanation of why \"Carefl\" is relevant or how it relates to the paper\"s content. Without additional context or justification, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM, as indicated by Equation (4) in another paper. This raises a valid concern about the novelty or specific contribution of the paper\"s approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the relevance of \"Carefl\" in their work. Without actionable feedback or suggestions, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed approach, noting that it is computeintensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times and challenge the speedup claim. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest any specific actions to mitigate the computational intensity or the potential impact on annotation times. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know what steps to take to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the computational intensity of the proposed approach, noting that it requires pretraining of the GAA model on the same dataset as the QA model. This provides some grounding as it mentions a specific aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the methodology or experimental setup. The comment is specific in detailing the issue with the computational intensity and the assumption about the GAA model\"s performance, but it lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach is computeintensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times and challenge the speedup claim. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how it might impact their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed approach, specifically noting that it is computeintensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times and challenge the speedup claim. While the comment highlights a potential weakness in the approach, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. The feedback is 3 as it points out a critical aspect of the approach that needs further consideration, but it lacks actionable advice, making it difficult for the authors to take concrete steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and generality. However, it does not provide any explicit or implicit suggestions on how to address this limitation or improve the method. The authors are left without guidance on how to modify or enhance their approach to overcome this dependence. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment identifies a limitation of the proposed method, specifically its high dependence on the server dataset, which restricts its potential use cases and generality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method has a high dependence on the server dataset, limiting its potential use cases and generality. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it difficult to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method, specifically its high dependence on the server dataset. This dependence restricts the method\"s potential use cases and generality, which is a critical issue for the authors to address. However, the comment lacks specific suggestions or guidance on how to mitigate this dependence or improve the method\"s applicability. While it highlights a crucial weakness, the feedback is 3 as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3 in identifying a problem but lacks depth in providing solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale for using only a single downstream search method (EA) and suggests adding other methods like BO and LS. While the comment implies that the authors should consider adding these methods, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should add the suggested methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale for using only a single downstream search method (EA) and suggests adding other methods like BO and LS. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. This lack of grounding makes it difficult for the authors to identify the exact section that needs attention. While the comment is specific in suggesting the addition of other methods, the absence of explicit grounding makes it challenging for the authors to understand the context and relevance of the suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale for using only a single downstream search method (EA) and suggests adding other methods like BO and LS. However, it does not provide any specific reasoning or justification for why only EA was used or why the suggested methods were not included. The comment lacks detailed explanation or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the limited number of downstream search methods used in the study, specifically questioning why only a single method (EA) was provided. The suggestion to include additional methods like BO and LS is logical and could enhance the comprehensiveness of the study. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or why these additional methods are crucial. While it offers a direction for improvement, the feedback is somewhat limited in its scope and actionable, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that while FLOPs and FPS are critical in sparse network research, the paper does not sufficiently highlight this comparison. It mentions that FLOPs for pDETR are listed in Table 7 but notes the absence of a direct comparison with other sparse models. This feedback provides a clear and explicit action for the authors to take, which is to include a direct comparison with other sparse models. The comment is specific in its suggestion and provides concrete guidance on how to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FLOPs and FPS are critical in sparse network research\" and refers to Table 7, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the missing comparison with other sparse models, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not sufficiently highlight the importance of FLOPs and FPS in sparse network research, specifically noting the absence of a direct comparison with other sparse models. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim. The authors are left to infer the need for a comparison, which makes the feedback 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by highlighting the lack of a direct comparison of FLOPs and FPS with other sparse models, which are critical in sparse network research. This feedback is clear and actionable, as it directs the authors to include a comparison with other sparse models to enhance the paper\"s relevance and comprehensiveness. By addressing this gap, the authors can strengthen the paper\"s contribution and provide a more thorough analysis of the models discussed. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the metrics used in the paper, noting that they are hard to understand and lack clarity in the result tables. It provides an example to illustrate the confusion, suggesting that the metrics are not welldefined. However, the comment does not offer any explicit or implicit actions for the authors to take to address this issue. It does not provide guidance on how to improve the clarity of the metrics or how to make the result tables more understandable. Therefore, the comment lacks actionable feedback, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are hard to understand and lack clarity in the result tables. The example provided further clarifies the confusion, making the comment highly specific and grounded. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the metrics described in Appendix A.1 are hard to understand, making it unclear what the numbers in the result tables mean. The reviewer provides an example to illustrate this issue, showing that reversing the prediction of DollyV27B could lead to a misleadingly high accuracy. This example provides a clear justification for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or providing more detailed examples to support the claim comprehensively. Overall, the comment is 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the metrics used in the paper, specifically noting that the metrics described in Appendix A.1 are hard to understand. The reviewer provides a clear example to illustrate this point, explaining that the accuracy for binary boolean questions in Table 5 is not welldefined, leading to confusion. This feedback is valuable as it highlights a critical area for improvement, allowing the authors to enhance the clarity and interpretability of their results. However, the comment could be more helpful if it suggested specific ways to improve the clarity of the metrics or provided guidance on how to make the result tables more understandable. Despite this, the comment is 4 as it directs the authors to a specific area of concern and provides a clear example to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the Gaussian assumption, its applicability in the limit r << N, and the possibility of computing effective variance for nonGaussian outputs. It also inquires about finiteN expansions that characterize the departure from Gaussianity in nonideal cases. While the comment prompts the authors to consider these aspects, it does not explicitly instruct them to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these points in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the Gaussian assumption, its applicability in the limit r << N, and the possibility of computing effective variance for nonGaussian outputs. It also inquires about finiteN expansions that characterize the departure from Gaussianity in nonideal cases. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections or content being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the Gaussian assumption, its applicability, and the possibility of computing effective variance for nonGaussian outputs. While it does not contain explicit subjective opinions or claims, it poses logical questions that require the authors to consider and address these aspects in their work. The questions are based on common knowledge and logical reasoning, but they lack specific references or detailed explanations, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises several pertinent questions about the Gaussian assumption, its applicability in the limit r << N, and the possibility of computing effective variance for nonGaussian outputs. It also inquires about finiteN expansions that characterize the departure from Gaussianity in nonideal cases. These questions are valuable as they prompt the authors to consider the limitations and applicability of their assumptions, which is crucial for the robustness and generalizability of their analysis. However, the comment lacks specific guidance or suggestions on how to address these questions or what aspects of the paper might need revision. While it provides a clear direction for improvement, it could be more helpful if it offered more detailed advice or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the approach to the math and science categories, suggesting that it does not clearly address an open vocabulary problem. It contrasts this approach with the methods used for other categories, which involve Wikipedia and a popularity metric. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their approach. The action is implicit, as the authors need to infer that they should consider alternative methods or provide a clearer explanation of how they handle the open vocabulary problem. The comment is 3 because it identifies a potential area for improvement but lacks concrete details on how to implement it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the approach to the math and science categories, suggesting that it does not clearly tackle an open vocabulary problem. It contrasts this approach with methods used for other categories, such as Wikipedia and a popularity metric. However, the comment does not specify which part of the paper discusses the math and science categories, making it weakly grounded. It is specific in detailing the issue with the approach to these categories, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly tackled. It contrasts this approach with methods used for other categories, such as Wikipedia and a popularity metric. However, the comment lacks specific examples or detailed reasoning to support the claim that the approach to math and science categories does not clearly address the open vocabulary problem. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach to the math and science categories, specifically noting that it does not clearly address an open vocabulary problem. It contrasts this approach with methods used for other categories, such as Wikipedia and a popularity metric, which suggests a more comprehensive approach. However, the comment lacks specific guidance on how the authors might address the open vocabulary problem or what alternative methods they could consider. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the similarity between the work and stochastic routing warrants a more thorough discussion. However, it does not provide explicit guidance on what aspects of the discussion should be expanded or how the authors should address this similarity. The action is implicit, as the authors need to infer that they should elaborate on the comparison. Additionally, the comment lacks concrete details on what specific aspects of the discussion need to be addressed, making it vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the similarity between the work and stochastic routing warrants a more thorough discussion. However, it does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in its suggestion to provide a more thorough discussion, but without clear guidance on what aspects of the discussion should be expanded, it remains somewhat specific. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the similarity between the work and stochastic routing warrants a more thorough discussion. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the similarity between the work and stochastic routing warrants a more thorough discussion. This feedback is valuable as it highlights a specific aspect that could enhance the paper\"s depth and clarity. However, the comment lacks specific guidance on how to expand the discussion or what aspects of the comparison should be addressed. While it provides a direction for improvement, it does not offer detailed suggestions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the terminology used in the paper, specifically the use of \"convergence in direction\" versus \"convergence\" in the context of CE loss. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the paper. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the terminology used in the paper, specifically the use of \"convergence in direction\" versus \"convergence\" in the context of CE loss. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location. The comment is vague and does not provide specific guidance on how to address the issue or what changes might be necessary. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern about the terminology used in the paper, specifically the use of \"convergence in direction\" versus \"convergence\" in the context of CE loss. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that CE loss can never be minimized due to the exponential nature of the loss function. Without this additional context, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the terminology used in the paper, specifically the use of \"convergence in direction\" versus \"convergence\" in the context of CE loss. The reviewer suggests that \"convergence\" might be a more appropriate term given that CE loss can never be minimized due to its exponential nature. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the paper. Without actionable advice or examples, the authors may find it challenging to understand the implications of this concern and how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors mention the possibility of replacing components with other models for flexibility but do not provide any evidence or attempt to demonstrate the robustness of the proposed framework through such changes. While the comment highlights a potential area for improvement, it does not explicitly instruct the authors to try alternative models or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments or analyses to support the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of flexibility in the proposed framework by mentioning that the authors state components can be replaced by other models. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it highlights the lack of attempts to prove the robustness of the framework through alternative models, but without clear references to specific sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas that need improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not try any change or alternative to prove the robustness of the proposed framework, despite mentioning the possibility of replacing components with other models for flexibility. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains 3, as it is based on an assertion without thorough justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that while the authors mention the possibility of replacing components with other models for flexibility, they did not attempt any changes or provide evidence to demonstrate the robustness of the proposed framework. This feedback is 3 as it highlights an area where the authors could strengthen their work by conducting additional experiments or analyses. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct these experiments or analyses. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind choosing 30 disentangled factors for the Atari game experiments, suggesting that this choice might be difficult to generalize for other domains. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to justify their choice. The action is implicit and vague, as it leaves the authors to infer the need for further explanation or justification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the choice of 30 disentangled factors for Atari game experiments, questioning its rationale and suggesting it might be difficult to generalize for other domains. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the choice of factors but lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind choosing 30 disentangled factors for Atari game experiments, suggesting that this choice might be difficult to generalize for other domains. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis for the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind choosing 30 disentangled factors for the Atari game experiments. It highlights a potential issue with the generalizability of this choice, which could be a concern for readers or other researchers. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or justify their choice. While it identifies a potential area for improvement, it does not provide detailed feedback or steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific instance of unprofessional language in the paper, noting that the use of a colloquial expression like \"By the way\" is inappropriate. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should revise the text to remove the unprofessional language or suggest specific alternatives. The action is implicit, as the authors would need to infer that they should revise the text to be more professional. However, the lack of concrete suggestions or examples makes the comment somewhat vague and difficult to act upon. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the use of colloquial expressions in the paper, noting that \"By the way\" is unprofessional. However, it does not specify which part of the paper contains this expression, making it weakly grounded. The comment is specific in identifying the issue with the language, but without a clear reference to the section or paragraph, the authors may find it challenging to pinpoint the exact area for revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the use of colloquial expressions, such as \"By the way,\" is unprofessional. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the context or address the issue effectively. Without detailed examples or references, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of colloquial expressions in the paper, noting that \"By the way\" is unprofessional. While it points out a potential weakness in the writing style, it does not provide any suggestions or guidance on how the authors might improve the language to be more professional or academic. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice or examples, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are not defined in the paper, despite being mentioned. It also notes that \"OOD\" has been explicitly defined elsewhere, which is a contradiction. The comment suggests that these abbreviations are pivotal metrics but does not provide explicit guidance on how the authors should define them or where to find the definitions. While the authors can infer that they need to define these abbreviations, the action is not concrete, as it lacks specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abbreviations \"LLH,\" \"OOD,\" and \"ECE,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of definition for these abbreviations, despite their importance as pivotal metrics. The comment provides clear guidance on what needs to be addressed, which is the definition of these abbreviations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are not defined in the paper, despite being mentioned. It also notes that \"OOD\" has been explicitly defined elsewhere, creating a contradiction. However, the comment lacks specific examples or references to support the claim that these abbreviations are pivotal metrics. Without detailed reasoning or references, the claim is 3, as it provides a basis for the authors to consider the issue but does not offer a comprehensive explanation or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper by pointing out that the abbreviations \"LLH,\" \"OOD,\" and \"ECE\" are not defined, despite being mentioned. It also notes that \"OOD\" has been explicitly defined elsewhere, creating a contradiction. This feedback is valuable as it highlights a lack of clarity and precision in the use of abbreviations, which can hinder the understanding of the paper. However, the comment could be more helpful if it provided guidance on where these abbreviations are typically defined in the field or suggested specific sections where they might be found. Overall, the comment is 3 as it identifies a significant issue that needs attention, but it could be more comprehensive with additional suggestions or context."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure increases with each layer. It questions the authors\" justification of the method\"s stability and asks for clarification on how stability is maintained and what happens when more layers are stacked. While the comment identifies a potential issue and asks for clarification, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the method\"s stability and explore the implications of stacking more layers. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"stochastic/random projection\" and \"WLS units,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the concern regarding the stability of the proposed method when stacking multiple layers, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure increases with each layer. The comment questions the authors\" justification of the method\"s stability and asks for clarification on how stability is maintained. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim about the increased probability of failure. Without additional evidence or justification, the claim remains 3, as it lacks sufficient detail to fully understand or address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units. It points out that the probability of failure increases with each layer, which could hinder the formation of deeper GNNs. The comment questions the authors\" justification of the method\"s stability and asks for clarification on how stability is maintained. This feedback is 3 as it identifies a potential issue and prompts the authors to address it, but it lacks specific guidance on how to justify the method\"s stability or explore the implications of stacking more layers. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the paper, noting that some sections lack clarity, particularly in the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the clarity of this section or what specific aspects need clarification. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the clarity of some sections, particularly the computation of the Bottleneck Distance in Definition 4.1. However, it does not specify which sections or parts of the paper are unclear, leaving the authors to infer that it applies to the entire paper or the section mentioned. This lack of specific grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide specific guidance on how to address the clarity issue, such as suggesting alternative explanations or examples. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks clarity, namely the computation of the Bottleneck Distance in Definition 4.1. This feedback is valuable as it highlights a potential weakness in the paper\"s presentation, which could hinder understanding for readers. However, the comment does not provide any suggestions or guidance on how the authors might improve the clarity of this section. Without actionable advice or examples, the authors are left without a clear path to address the issue, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the visualization in Figure 5 is weaker compared to Balikas COLING16\"s work, which raises doubts about the segmenting and assigning results of the document. It recommends providing a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4. While the comment provides explicit guidance on what could be improved, it lacks specific details on how to implement these suggestions, such as what kind of exemplar to include or how to ensure color consistency. The action is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the visualization, suggesting that it is weaker compared to Balikas COLING16\"s work and recommending the inclusion of a longer exemplar and consistent color assignment with topics listed in Figure 4. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visualization in Figure 5 is weaker compared to Balikas COLING16\"s work, which raises doubts about the segmenting and assigning results of the document. It suggests providing a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4. However, the comment lacks specific examples or references to support the claim about the weakness of the visualization or the effectiveness of the suggested improvements. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment 2. Therefore, the label is 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the visualization in Figure 5, noting that it is weaker compared to Balikas COLING16\"s work, which raises doubts about the segmenting and assigning results of the document. It suggests that providing a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4 could enhance the clarity and persuasiveness of the results. This feedback is actionable and provides clear guidance on how the authors might improve the visualization and the consistency of their results. However, the comment could be more helpful if it included specific examples of what constitutes a \"longer exemplar\" or how to ensure color consistency. Overall, the comment is 4 as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the necessity of using a parameterefficient training method when the backbone model, P5small, is a small model. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this concern or clarify the rationale behind their choice. Without specific advice or questions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the necessity of using a parameterefficient training method with the P5small model, which is a small model. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is vague and lacks specificity, as it does not provide any guidance or suggestions on how to address the concern. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the necessity of using a parameterefficient training method with the P5small model, which is a small model. However, the comment does not provide any specific reasoning, examples, or references to support why this choice is questionable or problematic. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the necessity of using a parameterefficient training method with the P5small model, which is a small model. However, it does not provide any specific reasoning or suggestions for why this choice might be problematic or how it could be addressed. The comment lacks depth and actionable feedback, leaving the authors without clear guidance on how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern that the authors\" proposed method for creating a challenging set is specific and not scalable. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or make their method more scalable. The comment lacks concrete actions or detailed advice, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the specificity of the authors\" proposed method for creating a challenging set, suggesting that it is not scalable. However, it does not specify which part of the paper this concern relates to, making it difficult for the authors to pinpoint the exact issue. The comment is 1 as it does not provide explicit references to sections or parts of the paper. It is also not specific because it does not detail what aspects of the method are specific or how they might be made scalable. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern that the authors\" proposed method for creating a challenging set is specific and not scalable. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" proposed method for creating a challenging set, noting that it is specific and not scalable. While the comment highlights a concern that could impact the generalizability and applicability of the method, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential limitation, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this concern. The comment lacks guidance on how the authors might address this issue or what changes could be made to the method. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this concern pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the specific area that needs attention. While the comment is specific in its critique, the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. While it identifies a potential issue with the method\"s dependence on this relationship, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their method. The comment lacks actionable advice, making it difficult for the authors to understand how to respond or make necessary changes to their work. Therefore, the comment is 2, as it highlights a potential weakness but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the approach is derivative, taking two existing approaches and combining them. It expresses a preference for derivatives if they work. However, it does not provide any specific guidance or suggestions on how the authors might address this aspect or improve their approach. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It provides a general statement about the approach being derivative, which is a subjective opinion but lacks specific details or references to the paper. The comment does not offer any guidance or suggestions for improvement, making it unspecific. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the approach being derivative, taking two existing approaches and combining them. While the reviewer acknowledges that it is not necessarily a bad thing, the comment lacks specific reasoning or evidence to support this claim. It does not provide any examples or references to substantiate the assertion that the approach is derivative. As a result, the claim is 1 due to the absence of supporting evidence or logical reasoning. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses an opinion about the approach being derivative, taking two existing approaches and combining them. While the reviewer acknowledges that this is not necessarily a bad thing, the comment lacks specific feedback or suggestions on how the authors might address this aspect or improve their approach. It does not provide actionable guidance or insights into potential areas for enhancement, leaving the authors with limited information to make improvements. Therefore, the comment is 2, as it offers a subjective assessment without actionable advice. The score is consistent with a rating of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison against baseline approaches in the evaluation section, suggesting that a simple photographic style transfer method might achieve similar or better results. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons would be beneficial. The action is implicit, as the authors need to infer that they should include comparisons against baseline methods to strengthen their evaluation. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of comparisons against baseline approaches and suggests that a simple photographic style transfer method might achieve similar or better results. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no comparisons against baseline approaches in the evaluation, suggesting that a simple photographic style transfer method might achieve similar or better results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. The claim is 3 as it provides a general idea but lacks detailed evidence or guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation section by pointing out the absence of comparisons against baseline approaches. It suggests that a simple photographic style transfer method might achieve similar or better results, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it provided specific examples of baseline methods or guidance on how to conduct such comparisons. Without these details, the authors may struggle to fully address the feedback. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the clarity of the paper, noting that the difficulty in mapping symbols between Figure 2 and the equations hinders understanding of the proposed method. It provides examples of symbols that are not explained in the main context, such as C_i, Q_i, R_i, and A_i in Figure 2, and points out a discrepancy between S_i in Figure 2 and the calligraphic S_j mentioned in line 431. However, the comment does not offer explicit guidance on how the authors should address these issues or what specific actions they should take to improve the clarity of the paper. The feedback is somewhat vague and lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with mapping symbols between the figure and the equations, providing clear guidance on what needs to be addressed. The comment specifies the exact elements that are unclear, such as the meaning of C_i, Q_i, R_i, and A_i in Figure 2, and the discrepancy between S_i in Figure 2 and the calligraphic S_j in line 431. This level of detail and specificity makes the comment 5 and fully grounded.", "verifiability_rationale": "The review point raises a claim about the difficulty in mapping symbols between Figure 2 and the equations, which affects the understanding of the proposed method. The comment provides specific examples of symbols that are not explained in the main context, such as C_i, Q_i, R_i, and A_i in Figure 2, and highlights a discrepancy between S_i in Figure 2 and the calligraphic S_j mentioned in line 431. However, the comment lacks detailed reasoning or references to support the claim, making it 3. The authors would need to infer the basis for the claim, which could be improved with additional explanation or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper, particularly regarding the mapping of symbols between Figure 2 and the equations. It provides concrete examples of symbols that are not explained in the main context, such as C_i, Q_i, R_i, and A_i in Figure 2, which hinders the understanding of the proposed method. Additionally, it points out a discrepancy between S_i in Figure 2 and the calligraphic S_j mentioned in line 431, noting that the computation of S_i is not explained. This feedback is clear and actionable, as it directs the authors to address these specific areas of confusion by providing detailed explanations of the symbols and their relationships. However, the comment could be more helpful if it suggested specific ways to improve the clarity of the presentation, such as adding a table or a more detailed caption. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should study the number of backtracking steps and the acceptance rate, as these parameters are crucial for tuning the results. However, it does not provide explicit instructions on how to conduct this study or what specific actions the authors should take. The comment implies that these parameters are important, but it lacks concrete guidance on how to implement the suggested analysis. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should study the number of backtracking steps and the acceptance rate, which are important parameters for tuning results. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or table. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific about the parameters being studied, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should study the number of backtracking steps and the acceptance rate, which are important parameters for tuning results. However, it does not provide any specific reasoning, examples, or references to support why these parameters are crucial or how they might affect the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should study the number of backtracking steps and the acceptance rate, as these parameters are crucial for tuning results. However, the comment does not provide any guidance on how to conduct this study or what specific actions the authors should take. While it highlights an important aspect of the research, the lack of detailed suggestions or examples limits its helpfulness. The feedback is 3 as it points out a potential area for further analysis, but it could be more comprehensive with additional guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the objective function used in the experiments. It asks for clarification on the objective function for GSdyn and FABOLAS, and it also questions the specific accuracy metric used (validation or test dataset). While the comment does not explicitly instruct the authors to provide this information, it implies that it is necessary for clarity and understanding. The action is somewhat explicit, as it directs the authors to clarify these aspects, but it lacks concrete guidance on how to address the questions or what specific information to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the questions the authors need to address regarding the objective function and the accuracy metric used in the experiments. The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the objective function and the specific accuracy metric used in the experiments, specifically mentioning the DNN\"s accuracy in Section 5.1. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, lacking any assertion or guidance that would need to be substantiated. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises specific questions about the objective function and the accuracy metric used in the experiments, particularly in Section 5.1. It points out that the objective function is mentioned as the DNN\"s accuracy but does not specify whether it is the validation or test dataset accuracy. This feedback is clear and actionable, as it directs the authors to clarify these aspects in their paper. By addressing these questions, the authors can improve the clarity and completeness of their experimental description, making the comment 4. However, it could be more helpful if it provided additional guidance on how to present this information effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that section 3.1 should be moved to the related work section, and section 3.2 should become section 3 with a proposal. It also implies that section 3 should be split more properly. While the comment provides explicit guidance on where sections should be placed and how they should be organized, it does not specify how the authors should implement these changes or what specific aspects of the sections need to be addressed. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that section 3.1 should be moved to the related work section, and section 3.2 should become section 3 with a proposal. It also implies that section 3 should be split more properly. However, the comment does not specify which part of the paper section 3.1 or 3.2 refers to, making it difficult for the authors to identify the exact sections being discussed. Additionally, while it provides a general suggestion for restructuring the sections, it lacks specific details on what aspects of the sections need to be addressed or how the restructuring should be implemented. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that section 3.1 should be moved to the related work section and section 3.2 should become section 3 with a proposal. This comment provides a clear and logical suggestion for restructuring the paper, making it 3. However, it lacks specific examples or references to support the claim, which could make it difficult for the authors to fully understand and implement the changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear suggestion for improving the organization of the paper by recommending that section 3.1 be moved to the related work section and section 3.2 be integrated into section 3 with a proposal. This feedback is actionable and offers a specific direction for restructuring the paper, which could enhance its clarity and coherence. However, the comment could be more helpful if it included additional guidance on how to integrate the proposal or what specific aspects of the proposal need to be addressed. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare the methods in terms of different metrics like Accuracy, Robustness, and EAO. This provides a clear and explicit action for the authors to take, as they know exactly what additional evaluation is needed and what metrics to focus on. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should perform additional evaluation on the VOT dataset to compare methods using metrics like Accuracy, Robustness, and EAO. However, it does not specify which part of the paper this evaluation should be conducted in or which sections of the paper are relevant to this suggestion. The authors may infer that this additional evaluation should be included in the experimental section, but the comment lacks explicit grounding. The suggestion is specific in terms of the metrics and dataset, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors should perform additional evaluation on the VOT dataset to compare methods using metrics like Accuracy, Robustness, and EAO. This claim is 3 as it suggests an additional evaluation, which is a logical extension of the existing work. However, it lacks specific examples or references to support the suggestion, making it 3. The authors would need to infer the relevance of this suggestion to the paper, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should perform additional evaluation on the VOT dataset to compare methods using metrics like Accuracy, Robustness, and EAO. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their evaluation. By suggesting an additional dataset and metrics, the comment offers a concrete way to improve the comprehensiveness of the evaluation. However, it could be more helpful if it included a brief explanation of why the VOT dataset is important or how the suggested metrics would provide additional insights. Overall, the comment is 4, as it guides the authors towards a meaningful improvement in their evaluation process."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the lack of comparison to stateoftheart unsupervised semantic segmentation techniques. It notes that the paper claims comparable performance to supervised methods but does not provide any performance metrics against these techniques. While the comment identifies a gap in the evaluation, it does not explicitly instruct the authors to include such comparisons or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to add comparisons to stateoftheart unsupervised methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the lack of comparison to stateoftheart unsupervised semantic segmentation techniques, which is a specific issue related to the methodology. However, it does not explicitly mention which part of the paper this concern pertains to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of comparison to stateoftheart unsupervised semantic segmentation techniques, which is a valid claim. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim is 3, as it highlights a potential gap in the evaluation of the proposed method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of comparison to stateoftheart unsupervised semantic segmentation techniques. It highlights that the paper claims comparable performance to supervised methods but does not provide any performance metrics against these techniques. This feedback is valuable as it directs the authors to include a more comprehensive evaluation of their method, which is crucial for demonstrating its effectiveness and relevance. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct the comparison, such as mentioning relevant datasets or evaluation metrics. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the clarity of the explanation regarding the first curvefinding part and its connection to the FGE work. It questions whether the cyclical learning rate scheduling adequately explains the weight changes described in the first part. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects need clarification. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses concern about the clarity of the explanation regarding the first curvefinding part and its connection to the FGE work. However, it does not specify which part of the paper this concern pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the explanation but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the clarity of the explanation regarding the first curvefinding part and its connection to the FGE work. It questions whether the cyclical learning rate scheduling adequately explains the weight changes described in the first part. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the explanation regarding the first curvefinding part and its connection to the FGE work. It questions whether the cyclical learning rate scheduling adequately explains the weight changes described in the first part. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable advice or examples, the authors may find it challenging to understand how to enhance the draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should present a case study, ideally with synthetic datasets, to illustrate why or when a distillation strategy is better. It also questions the performance difference between LFADSHard and LFADSSoft, and NDT NDTCorrelation, asking the authors to provide more reasoning or hypotheses. While the comment implies that the authors should conduct additional experiments and provide explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to conduct the case study or analyze the performance differences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should present a case study, ideally with synthetic datasets, to illustrate why or when a distillation strategy is better. It also questions the performance difference between LFADSHard and LFADSSoft, and NDT NDTCorrelation, asking the authors to provide more reasoning or hypotheses. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. It is specific in detailing what the authors should do to address the issue, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance difference between LFADSHard and LFADSSoft, and NDT NDTCorrelation, suggesting that the authors should provide more reasoning or hypotheses. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that the authors should provide more reasoning or hypotheses. This lack of evidence makes the claim 3, as the authors are left to infer the need for additional reasoning or hypotheses. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by asking the authors to present a case study, ideally with synthetic datasets, to illustrate why or when a distillation strategy is better. It also questions the performance difference between LFADSHard and LFADSSoft, and NDT NDTCorrelation, prompting the authors to provide more reasoning or hypotheses. This feedback is clear and actionable, as it directs the authors to conduct additional experiments and provide detailed explanations for the observed performance differences. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the case study or analyze the results. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should create clozestyle or question answering evaluation sets that focus exclusively on the generation of factual knowledge, as the current evaluation of LM loss is not clean enough. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need to be revised or how to implement this suggestion. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should create clozestyle or question answering evaluation sets that focus exclusively on the generation of factual knowledge. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion regarding the type of evaluation sets, but without clear grounding, the authors may find it challenging to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors\" focus on evaluating LM loss is not clean enough because only a few tokens in a sentence are related to facts. The comment suggests that creating clozestyle or question answering evaluation sets focusing on factual knowledge would be a better approach. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation methodology, specifically the focus on LM loss, which may not be sufficient for assessing factual knowledge. It suggests that creating clozestyle or question answering evaluation sets that focus exclusively on factual knowledge could provide a more comprehensive assessment. This feedback is clear and actionable, offering a specific direction for improvement. However, it could be more helpful if it included additional suggestions or examples of how to implement this change. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and suggestions for the authors to consider. It questions the claim that the RTD score is sensitive to clusters and suggests that the authors should provide theoretical or topological explanations for this sensitivity. Additionally, it asks why the proposed RTD score is specifically applicable to network representation rather than any vectors of the same size. These questions and suggestions are explicit and provide clear guidance on what the authors should address or clarify in their draft. The feedback is detailed and actionable, allowing the authors to understand the specific areas that need improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises questions about the sensitivity of the RTD score to clusters and suggests that theoretical or topological explanations should be provided. It also questions the applicability of the proposed RTD score to network representation, specifically asking why it is tailored to this domain rather than any vectors of the same size. However, the comment does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the sensitivity of the RTD score to clusters and its applicability to network representation. It suggests that the authors should provide theoretical or topological explanations for the sensitivity and clarify why the proposed RTD score is specifically designed for network representation rather than general vectors. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises several important questions and suggestions for the authors to consider. It questions the claim that the RTD score is sensitive to clusters and suggests that the authors should provide theoretical or topological explanations for this sensitivity. Additionally, it asks why the proposed RTD score is specifically applicable to network representation rather than any vectors of the same size. These questions and suggestions are clear and actionable, providing the authors with specific areas to address and improve their draft. By addressing these points, the authors can enhance the clarity and depth of their work, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that ROCK has similar complexity to the original model, arguing that the addition of 8 convolutional layers, 3 pooling layers, and 1 fusion layer makes this claim unlikely. However, it does not provide any specific guidance or suggestions on how to address this concern or how to substantiate the claim with experimental evidence. The comment lacks actionable steps for the authors to take, such as suggesting additional experiments or providing data to support their claims. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the claim that ROCK has similar complexity to the original model, arguing that the addition of 8 convolutional layers, 3 pooling layers, and 1 fusion layer makes this claim unlikely. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section being addressed. Additionally, while the comment provides some detail about the layers added, it does not specify what needs to be addressed in this part, such as providing inference timings or additional experiments. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point critiques the claim that ROCK has similar complexity to the original model, arguing that the addition of 8 convolutional layers, 3 pooling layers, and 1 fusion layer makes this claim unlikely. However, the comment does not provide any specific evidence or reasoning to support this claim, such as experimental data or logical arguments. Without additional justification or examples, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment critiques the claim that ROCK has similar complexity to the original model, arguing that the addition of 8 convolutional layers, 3 pooling layers, and 1 fusion layer makes this claim unlikely. However, the comment does not provide specific suggestions or guidance on how to substantiate this claim or address the concern. It lacks actionable advice, such as suggesting additional experiments or providing data to support the claim. Without these details, the authors may not be able to effectively address the feedback, making the comment 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two key areas for improvement: the diversity and quality of the dataset, particularly concerning rare conditions or imaging variations, and the model\"s behavior on noisy or imbalanced realworld medical datasets. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to expand the discussion on dataset diversity and quality and consider the model\"s performance on noisy or imbalanced datasets. However, the lack of concrete suggestions or actionable steps makes the comment somewhat vague and challenging for the authors to implement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and the model\"s behavior on noisy or imbalanced realworld medical datasets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the areas that need attention, such as the diversity of the dataset and the model\"s performance on noisy or imbalanced datasets. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact sections to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and the model\"s behavior on noisy or imbalanced realworld medical datasets. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the diversity and quality of the dataset, especially regarding rare conditions or imaging variations, and the model\"s behavior on noisy or imbalanced realworld medical datasets. This feedback is valuable as it highlights important aspects that could enhance the robustness and applicability of the research. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, such as potential strategies for improving dataset diversity or methods for evaluating model performance on noisy data. While the feedback is 3, it could be more impactful with additional details or suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the reproducibility of the results due to the lack of promised code and the complexity of the model training process. It suggests that the authors should consider providing code or additional details to ensure reproducibility. However, the comment does not explicitly instruct the authors to provide the code or additional details, nor does it specify how to ensure reproducibility. The action is implicit and somewhat vague, as the authors need to infer that they should address the reproducibility issue by providing code or more detailed training information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the reproducibility of results due to the lack of promised code and the complexity of the model training process. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The authors may infer that it pertains to the methodology or experimental details, but the comment lacks explicit grounding. The comment is specific in detailing the issue with reproducibility, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the lack of promised code and the complexity of the model training process make the results reproducible. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion that the absence of code hinders reproducibility. Without additional context or justification, the claim remains 3, as the authors may need to infer the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the reproducibility of the results due to the lack of promised code and the complexity of the model training process. It highlights that the provided training details about data and hyperparameters do not guarantee reproducibility, which is a significant concern for scientific research. However, the comment does not offer any suggestions or guidance on how the authors might address this issue, such as providing code or additional details. While it points out a crucial problem, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is 3, as it raises an important concern but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that critical setup information is missing, particularly the total number of agents available in Flow\u2019s default configuration. This feedback is explicit, as it directly points out what information is lacking. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to include this information. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"critical setup information\" and \"Flow\u2019s default configuration,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing, namely the total number of agents available in Flow\u2019s default configuration. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue regarding the missing critical setup information, particularly the total number of agents available in Flow\u2019s default configuration. While the comment identifies a gap in the paper, it does not provide any reasoning, examples, or references to support why this information is important or how its absence impacts the paper. Without additional context or justification, the claim remains 3, as the authors may need to infer the importance of this information themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of critical setup information, particularly the total number of agents available in Flow\u2019s default configuration. This feedback is clear and actionable, as it directly points out a missing element that could impact the reproducibility and understanding of the paper. However, the comment could be more helpful if it provided additional context or suggested specific ways the authors might address this issue, such as including a table or a detailed description of the setup. Overall, the comment is 4 as it highlights a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that the paper presents the \"first deep generative model for unsupervised scenegraph discovery\" by suggesting that there are other works that infer structures in an unsupervised way. However, the comment does not provide specific examples or details to support the claim that the paper\"s definition of \"scene graph\" is narrow or unfair. It lacks actionable guidance on how the authors might address this critique or clarify their definition. As a result, the comment is not actionable because it does not provide explicit or implicit instructions on how the authors should respond or improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scenegraph discovery\" by suggesting that there are other works that infer structures in an unsupervised way. However, it does not specify which part of the paper this claim is made or which section discusses the definition of \"scene graph.\" This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the claim, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the claim that the paper presents the \"first deep generative model for unsupervised scenegraph discovery\" by suggesting that there are other works that infer structures in an unsupervised way. However, the comment lacks specific examples or references to support the claim that the paper\"s definition of \"scene graph\" is narrow or unfair. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scenegraph discovery\" by suggesting that there are other works that infer structures in an unsupervised way. This critique highlights a potential overstatement in the paper\"s claim and questions the narrow definition of \"scene graph.\" However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper\"s definition is unfair or narrow. Without actionable guidance or additional context, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it identifies a potential issue but lacks depth and specificity to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. However, it does not offer any explicit or implicit suggestions on how the authors might address this gap or what additional experiments could be conducted to provide a more comprehensive analysis. The comment lacks concrete guidance on how to improve the study or what specific actions the authors should take. As a result, the authors are left without a clear understanding of how to address the identified issue, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a gap in the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This provides the authors with a clear understanding of what needs to be addressed to improve the study. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This feedback is clear and actionable, as it highlights a gap in the study that needs to be addressed. However, the comment could be more helpful if it suggested specific ways to address this gap or provided guidance on how to conduct additional experiments. Despite this, the comment provides a valuable insight that can guide the authors in improving their draft, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more experiments on diverse datasets should be conducted to further demonstrate the generalization capabilities of the model. It specifically mentions that the current experiments are limited to three categories (chair, airplane, car) and that more complex shapes with various topologies should be evaluated. The comment provides explicit guidance on what additional experiments should be conducted, making it a clear and actionable suggestion for the authors. The authors know exactly what needs to be added to their draft to strengthen the demonstration of the model\"s generalization capabilities. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more experiments on diverse datasets should be conducted to further demonstrate the generalization capabilities of the model, specifically mentioning the need to evaluate more complex shapes with various topologies. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more complex shapes, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on diverse datasets should be conducted to further demonstrate the generalization capabilities of the model, specifically mentioning the need to evaluate more complex shapes with various topologies. While the comment provides a clear rationale for the suggestion, it lacks specific examples or references to existing literature that could support the claim. The authors would need to infer the need for additional experiments based on the provided reasoning, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by recommending additional experiments on diverse datasets to better demonstrate the generalization capabilities of the model. It highlights the need to evaluate more complex shapes with various topologies, which aligns with the core idea of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the experimental section of their draft. However, the comment could be more helpful if it included specific examples of datasets or topologies that could be used, or if it suggested particular metrics for evaluating the model\"s performance. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a comparison against methods requiring more training time is necessary, particularly in the context of the neural networks proposed by Park & Van Hentenryck (2023) and others, which do not necessitate extensive training time. It highlights the implications of low computational requirements and questions the necessity of training restrictions like a hard limit of 10 minutes on a single CPU core. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the neural networks proposed by Park & Van Hentenryck (2023) and others, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the need for a comparison against methods that require more training time, particularly in the context of low computational requirements. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that a comparison against methods requiring more training time is necessary, particularly in the context of neural networks that do not necessitate extensive training. The comment provides a rationale by highlighting the implications of low computational requirements and questioning the necessity of training restrictions like a hard limit of 10 minutes on a single CPU core. However, the claim lacks specific examples or detailed reasoning to fully substantiate the need for such a comparison. The reasoning is somewhat logical but could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific need for comparison against methods that require more training time, particularly in the context of neural networks that do not necessitate extensive training. It highlights the implications of low computational requirements and questions the necessity of training restrictions, such as a hard limit of 10 minutes on a single CPU core. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a direction for further analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to consider. Overall, the comment is 4, as it provides valuable insights and direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It recommends providing a more comprehensive comparison between DetNAS and other networks constructed using effective blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. While the comment explicitly suggests a specific action\u2014providing a more detailed comparison and including a specific result in Table 2\u2014it does not offer detailed guidance on how to implement this suggestion. The authors would need to infer that they should expand their comparison and include the suggested result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DetNAS\" and \"ResNet,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a more comprehensive comparison between DetNAS and other networks constructed using effective blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It suggests providing a more comprehensive comparison with other networks constructed using effective blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. However, the comment lacks specific examples or references to support the claim that the comparison is unfair. While the suggestion to include a more detailed comparison is logical, the absence of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between DetNAS and ResNet, suggesting that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It provides a specific suggestion to include a more comprehensive comparison with other networks constructed using effective blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is actionable and constructive, as it guides the authors to enhance the depth and fairness of their comparison. However, the comment could be more helpful if it provided additional context or examples to support the claim, making it easier for the authors to understand and address the issue. Overall, the comment is 4, as it offers clear guidance but could be expanded for greater depth."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the scope of the input and output spaces/representations discussed in the paper and the generality of the representations used in two other papers. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider expanding the scope of their work to include more general representations, but it lacks concrete steps or detailed advice on how to achieve this. As a result, the authors are left without a clear understanding of what specific changes to make to their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the scope of the input and output spaces/representations discussed in the paper, specifically mentioning that they are restricted to either the group itself under the regular or trivial representation, or a homogeneous space of the group. It then contrasts this with two other papers that can work with any finitedimensional representation. However, the comment does not specify which part of the paper discusses these input and output spaces, making it difficult for the authors to pinpoint the exact section being addressed. While the authors can infer that it relates to the methodology or experimental setup, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the discrepancy between the paper\"s scope and the generality of other works, but without clear grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the input and output spaces/representations discussed in the paper are restricted to specific cases, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It contrasts this with two other papers that can work with any finitedimensional representation. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without clear evidence or references, the claim remains 3, as it is based on an observation without sufficient substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the scope of the input and output spaces/representations discussed in the paper, noting that they are restricted to certain cases compared to the generality demonstrated in two other papers. This observation is clear and provides a specific area for improvement, suggesting that the authors should consider expanding the scope of their work to include more general representations. However, the comment lacks detailed guidance or suggestions on how to achieve this expansion, which limits its helpfulness. While it points out a potential area for enhancement, it does not provide actionable steps or examples, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. This feedback suggests that the system might be overly complex for typical users seeking simpler image adjustments. However, the comment does not provide explicit guidance on how the authors might address this complexity or what specific changes could be made to improve the system. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and potential restrictions it imposes on the system, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a potential issue with the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. This feedback suggests that the system might be overly complex for typical users seeking simpler image adjustments. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or examples, the claim is 3, as it provides a general observation but lacks sufficient evidence to fully substantiate the concern.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. This feedback highlights a limitation in the system\"s usability for typical users seeking simpler image adjustments. However, the comment lacks specific suggestions or guidance on how the authors might address this complexity or improve the system\"s practical usability. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it provides a clear observation but does not offer substantial guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s contributions are not very significant, even though the technique is novel. It also points out that there is a lack of attempt in contrasting the technique with traditional classification or manifold learning literature. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to enhance the significance of their contributions or to include a comparison with traditional methods. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the contributions of the paper are not very significant, even though the technique is novel, and that there is a lack of attempt in contrasting the technique with traditional classification or manifold learning literature. However, the comment does not specify which part of the paper discusses the contributions or the lack of contrast, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the lack of contrast but lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contributions of the paper are not very significant, even though the technique is novel, and that there is a lack of attempt in contrasting the technique with traditional classification or manifold learning literature. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of these claims and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of significance of the contributions and the absence of a comparison with traditional classification or manifold learning literature. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and implement the suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary. It mentions that larger datasets could provide more accurate estimates but would require significantly more time to compute, referencing two external works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be included. The action is implicit, as the authors need to infer that they should discuss the tradeoffs between dataset size and computational time. While the comment is 3, it lacks concrete details on how to implement the suggested discussion, making it 3.", "grounding_specificity_rationale": "The comment suggests a discussion on the impact of the fewshot dataset for the sparsity ratio, referencing two external works. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in that it identifies a need for a discussion on the tradeoffs between dataset size and computational time, but the lack of grounding makes it difficult for the authors to know where to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary, referencing two external works that discuss the tradeoffs between dataset size and computational time. The claim is supported by logical reasoning and references to relevant literature, making it 4. However, the comment could be strengthened by providing more specific examples or detailed reasoning to enhance its persuasiveness. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a need for a discussion on the impact of the fewshot dataset for the sparsity ratio, which is a relevant and important aspect of the paper. It suggests that larger datasets could provide more accurate estimates but would require significantly more time to compute, referencing two external works to support this claim. This feedback is clear and actionable, as it provides a specific area for improvement and references relevant literature to strengthen the argument. However, the comment could be more helpful if it offered additional guidance on how to structure the discussion or what specific points to address. Overall, the comment is 4, as it provides a clear direction for improvement but could be expanded for more comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that the authors do not provide a clear explanation or justification for why it is better to keep representations in the same hidden space. Additionally, the comment points out that this aspect has not been experimentally verified. While the authors understand the need to address these issues, the comment lacks explicit guidance on how to improve the paper. The action is implicit, as the authors can infer that they need to provide a clearer explanation and experimental verification. However, the comment does not offer concrete steps or suggestions on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of explanation and experimental verification for keeping representations in the same hidden space. It is fully grounded as it explicitly mentions the part of the paper that needs improvement. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of justification and experimental verification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not illustrate why it is better to keep representations in the same hidden space and that this aspect has not been experimentally verified. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that the authors do not provide a clear explanation or justification for why it is better to keep representations in the same hidden space. Additionally, it notes that this aspect has not been experimentally verified. This feedback is 3 as it highlights a critical area that needs clarification and further support. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address these issues, such as suggesting specific experiments or analyses that could be conducted to verify the claim. Overall, the comment offers a clear direction for improvement but lacks depth in its suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the novelty of the paper\"s methodologies, specifically questioning whether the use of Faster RCNN as an extension of Karwande et al. (2022) provides a significant advancement. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this issue or improve the novelty of their approach. It lacks concrete guidance on what specific changes or enhancements could be made to the methodology to differentiate it from existing methods. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Longitudinal Representation Learning\" and \"Karwande et al. (2022)\" and \"Faster RCNN (Ren et al., 2015)\" as specific parts of the paper being addressed. It clearly specifies the issue of lack of sufficient novelty in the methodologies, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient novelty in its methodologies, specifically noting that the use of Faster RCNN as an extension of Karwande et al. (2022) does not offer a significant advancement. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the approach does not offer a significant advancement. Without such evidence, the claim remains 3, as the authors may need to conduct further analysis or provide additional context to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper\"s methodologies, specifically questioning whether the use of Faster RCNN as an extension of Karwande et al. (2022) offers a significant advancement. While the comment highlights a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the clarity and specificity of the paper. It questions the accuracy of the description of the data generating mechanism, suggesting that it is not as presented. It also recommends using causal graphs instead of label inference for the underlying system, which would be more standard. Additionally, the reviewer points out that Definition 4 is difficult to understand because it lacks clarity on which graph should be considered to determine independencies. The comment does not provide explicit instructions on how to address these issues, such as suggesting specific revisions or providing examples. While the feedback is 3, it lacks concrete guidance on how to improve the clarity and readability of the paper, making it 3.", "grounding_specificity_rationale": "The comment raises several concerns about the clarity and specificity of the paper, particularly regarding the description of the data generating mechanism, the use of causal graphs, and the readability of Definition 4. However, it does not explicitly mention specific sections, tables, or figures that need attention, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the inaccuracy of the description of the data generating mechanism and the recommendation to use causal graphs. However, without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that require revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the clarity and accuracy of the paper, specifically regarding the description of the data generating mechanism, the use of causal graphs, and the readability of Definition 4. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it points out areas that need clarification, but it does not provide sufficient evidence or guidance to address the issues effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding the clarity and accuracy of the description of the data generating mechanism, the use of causal graphs, and the readability of Definition 4. It suggests that the data generating mechanism is not as presented and recommends using causal graphs instead of label inference for the underlying system, which would be more standard. Additionally, the comment points out that Definition 4 is difficult to understand due to a lack of clarity on which graph should be considered to determine independencies. While the feedback provides some actionable suggestions, it lacks depth and specificity, making it 3. The authors would benefit from more detailed guidance on how to address these issues, such as providing specific examples or detailed explanations of the concepts mentioned. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dualfree approach. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to address this issue or what specific examples to include. The action is implicit, as the authors would need to infer that they should explore the cost of evaluating the gradient and provide more examples to motivate the dualfree approach. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dualfree approach. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion to include more examples, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dualfree approach. However, it does not provide any specific reasoning, references, or examples to support the claim that evaluating the gradient is expensive or infeasible. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dualfree approach. While it identifies a potential area for improvement, it lacks specific guidance or detailed suggestions on how to address this issue. The comment does not provide actionable advice or examples that would help the authors enhance their work. As a result, the feedback is 3, as it points out a potential area for improvement but does not offer substantial guidance for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the rationale behind randomly selecting a probability for the appearance of an unobservable data point within the range [0, Pcj(0)]. It does not explicitly instruct the authors to provide an explanation for this choice, nor does it offer any guidance on how to address this issue. The action is implicit, as the authors need to infer that they should explain the reasoning behind the selection. However, the comment lacks concrete details on how to implement this explanation, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the data approximation technique (step 3 of the Algorithm 1)\" and \"unobservable data point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of explanation for the random selection of a probability within the range [0, Pcj(0)]. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rationale behind randomly selecting a probability for the appearance of an unobservable data point within the range [0, Pcj(0)]. While the comment identifies a potential area for clarification, it does not provide any specific reasoning or evidence to support the claim that this choice lacks explanation. The authors are left to infer the need for clarification, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors could improve their explanation, particularly regarding the data approximation technique. It points out that the authors randomly choose a probability for the appearance of an unobservable data point but do not provide a clear rationale for this choice. This feedback is valuable as it directs the authors to explain the reasoning behind their selection, which could enhance the clarity and understanding of their methodology. However, the comment could be more helpful if it provided some guidance on how to explain the rationale or suggested specific ways to improve the explanation. Overall, the comment is 4, as it highlights an important area for improvement but lacks detailed guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should provide a precise definition or informal description of the term \"spectrum of distributions and their characteristic functions\" throughout the paper. This feedback is explicit and concrete, as it clearly indicates what needs to be done to improve the paper. The authors know exactly what aspect of the text requires clarification, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (128 and 168) where the authors refer to the spectrum of distributions and their characteristic functions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests that the text would benefit from a precise definition or informal description of this notion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a precise definition or informal description of the term \"spectrum of distributions and their characteristic functions\" throughout the paper. While the comment implies that this clarification would improve the text, it does not provide specific examples or references to support why this clarification is necessary or beneficial. The authors may infer the need for clarification but lack concrete guidance on how to achieve it. Therefore, the comment is 3, as it provides a suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors could improve the clarity and precision of their writing. It points out that the term \"spectrum of distributions and their characteristic functions\" is referenced throughout the paper without a precise definition or informal description. This feedback is actionable and provides a clear direction for the authors to enhance the readability and understanding of their work. By offering a suggestion to include a precise definition or informal description, the comment empowers the authors to make significant improvements to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the AIGgeneration task, suggesting that it is not convincing and that the paper does not provide sufficient background or context for readers unfamiliar with the area of logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the persuasiveness of the task. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to provide more background or conduct benchmarking. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the AIGgeneration task, which is a specific part of the paper. It provides feedback on the lack of clarity regarding the task\"s challenge and suggests that more background should be provided for readers unfamiliar with logic synthesis. Additionally, it recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the persuasiveness of the task. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be improved, such as providing more background and benchmarking on existing datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the AIGgeneration task, suggesting that it is not convincing and that the paper lacks sufficient background for readers unfamiliar with logic synthesis. It recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the persuasiveness of the task. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the basis for the critique and the suggestions for improvement, which limits the clarity and robustness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the AIGgeneration task, noting that it is not convincing and lacks sufficient background for readers unfamiliar with logic synthesis. It suggests that providing more context and background would enhance the paper\"s persuasiveness. Additionally, the comment recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to strengthen the evaluation of the task. While the comment highlights specific areas for improvement and provides a clear rationale for these suggestions, it could be more helpful if it offered more detailed guidance on how to provide the necessary background or conduct the benchmarking. However, the feedback is 4 as it directs the authors to specific areas that need attention to improve the clarity and persuasiveness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some statements in the paper lack detail and analysis. However, it does not provide any specific guidance or suggestions on which parts of the paper need more detail or analysis. The authors are left without a clear understanding of what specific statements or sections require improvement, making it difficult for them to apply the feedback effectively. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some statements in the paper lack detail and analysis, but it does not specify which parts of the paper these statements are located in. Without knowing the exact sections or parts of the paper that need more detail or analysis, the authors cannot effectively address the feedback. This makes the comment weakly grounded, as it does not provide specific guidance on which parts of the paper need improvement. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some statements in the paper lack detail and analysis. However, it does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors cannot determine which parts of the paper need more detail or analysis. This lack of specificity makes the claim difficult to verify, as the authors are left without a clear understanding of what needs to be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some statements lack detail and analysis. However, it does not provide specific examples or suggestions for improvement, leaving the authors without actionable guidance on how to address this concern. The feedback is vague and lacks depth, making it difficult for the authors to understand the specific areas that need enhancement. As a result, the comment is 2, as it does not offer clear direction or actionable advice. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison with other generative models, such as VAE, could be more informative. It highlights the unique features of diffusion models, such as diffusion timesteps, and proposes an analysis of how these differences affect feature learning. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison with other generative models, such as VAE, could be more informative and proposes an analysis of how diffusion models, with their unique features like diffusion timesteps, affect feature learning. However, the comment does not specify which part of the paper this comparison is intended to address, making it weakly grounded. It is specific in suggesting the inclusion of an analysis of diffusion model features, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas to improve. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the comparison with other generative models, such as VAE, could be more informative and proposes an analysis of how diffusion models, with their unique features like diffusion timesteps, affect feature learning. However, the comment lacks specific examples or references to support the claim that this analysis would add significant value. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to incorporate it into their work. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests that the comparison with other generative models, such as VAE, could be more informative and proposes an analysis of how diffusion models, with their unique features like diffusion timesteps, affect feature learning. This feedback is 3 as it identifies a potential area for improvement in the comparison section of the paper. However, the comment lacks specific guidance on how to conduct this analysis or what aspects of the comparison should be emphasized. The suggestion is clear and actionable, but it could be more helpful if it provided more detailed examples or guidance on how to integrate the analysis into the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main issues. First, it questions the complementarity of the selfsupervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI, which doubles GPU memory usage, is not significant. This suggests that the authors should provide a more detailed explanation or justification for the combination of these tasks. Second, the comment points out that the ICoL method is proposed to mitigate insufficient memory on a single GPU and allow more negative instances for better performance, but there are no corresponding experiments to support this claim. The reviewer also suggests that the quality of negatives is more important than the quantity, referencing TASB. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the combination of selfsupervised tasks in Table 4 and the effectiveness of the DaPI task, noting that the memory usage is doubled but the performance improvement is not significant. It also highlights the lack of experiments to support the claim about the influence of the number of negatives in the ICoL method, suggesting that the quality of negatives is more important. The comment is fully grounded as it explicitly mentions \"table 4\" and \"ICL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the combination of tasks and the lack of experimental evidence for the claim about negative instances. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two main issues. First, it questions the complementarity of the selfsupervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI, which doubles GPU memory usage, is not significant. This claim is supported by the numerical results presented in the table, which show a minimal improvement in performance. Second, the comment points out that the ICoL method is proposed to mitigate insufficient memory on a single GPU and allow more negative instances for better performance, but there are no corresponding experiments to support this claim. The reviewer also suggests that the quality of negatives is more important than the quantity, referencing TASB. While the comment provides some justification for the issues raised, it lacks detailed examples or specific references to fully substantiate the claims. Therefore, the comment is 4, as it offers some support but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment provides specific feedback on two key areas of the paper. First, it questions the complementarity of the selfsupervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI, which doubles GPU memory usage, is not significant. This raises concerns about the practical utility of the combination of these tasks. Second, the comment points out that the ICoL method is proposed to mitigate insufficient memory on a single GPU and allow more negative instances for better performance, but there are no corresponding experiments to support this claim. The reviewer also suggests that the quality of negatives is more important than the quantity, referencing TASB. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific experiments could be conducted to validate the claims. The feedback is 3 as it highlights important aspects of the paper that need further clarification or experimental validation, but it could be more actionable with additional suggestions or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of Figure 3, specifically questioning the difference between the plots on the same row. It suggests that the caption should be added to emphasize this difference. While the comment implies that the authors should add a caption, it does not provide explicit instructions on how to do so or what specific information should be included in the caption. The action is implicit and somewhat vague, as the authors need to infer that they should add a caption and understand that it should emphasize the difference between the plots. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between the plots on the same row in Figure 3, suggesting that a caption should be added to emphasize this difference. This provides the authors with clear guidance on how to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of Figure 3, specifically regarding the difference between the plots on the same row. It suggests that the caption should be added to emphasize this difference. However, the comment does not provide any evidence, reasoning, or references to support why this is a significant issue or how it impacts the paper. Without additional context or justification, the authors may find it challenging to understand the importance of addressing this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is unclear what the difference is between the plots on the same row. The comment suggests that a caption should be added to emphasize this difference. While the feedback is clear and points out a potential area for improvement, it lacks depth and does not provide specific guidance on how to create the caption or what information should be included. This makes the comment 3, as it highlights a minor but important aspect that could enhance the clarity of the paper. However, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of handcrafted PSEs, specifically their high computational complexity on large graphs. It suggests that the paper could benefit from a deeper dive into GPSE\"s computational complexity, particularly when compared against handcrafted PSEs and other encoding strategies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of computational complexity need to be explored. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a limitation of handcrafted PSEs, specifically their high computational complexity on large graphs. It suggests that the paper could benefit from a deeper dive into GPSE\"s computational complexity, particularly when compared against handcrafted PSEs and other encoding strategies. However, the comment does not specify which part of the paper discusses computational complexity or where the comparison is made. This makes it difficult for the authors to pinpoint the exact section or aspect that needs improvement. While the comment is specific about the issue of computational complexity, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that a major limitation of most handcrafted PSEs is their high computational complexity on large graphs. It suggests that the paper could benefit from a deeper dive into GPSE\"s computational complexity, particularly when compared against handcrafted PSEs and other encoding strategies. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it is based on a general observation without clear justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of handcrafted PSEs, specifically their high computational complexity on large graphs. It suggests that the paper could benefit from a deeper exploration of GPSE\"s computational complexity, particularly when compared to handcrafted PSEs and other encoding strategies. This feedback is valuable as it highlights an area where the paper could be improved by providing more detailed analysis and comparisons. However, the comment could be more helpful if it offered specific guidance on how the authors might address this issue or what aspects of computational complexity should be investigated. Overall, the comment is 3, as it points out a crucial area for improvement but lacks detailed actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the reporting of results on the VQA dataset, specifically noting that the testdev split is used instead of the teststandard split as recommended by the VQA dataset authors. While the comment identifies a potential issue with the reporting, it does not provide explicit guidance on how the authors should address this discrepancy or what changes should be made to the draft. The action is implicit, as the authors need to infer that they should report results on the teststandard split to align with the guidelines. However, the lack of concrete instructions on how to implement this change makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and the specific issue with the reporting of results on the VQA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the problem, which is the use of the testdev split instead of the teststandard split as recommended by the VQA dataset authors. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results on the VQA dataset in Table 1 are reported on the testdev split, which is inconsistent with the guidelines provided by the VQA dataset authors. The comment provides a specific reference to the VQA dataset authors\" guidelines, which supports the claim. However, it does not elaborate on why this discrepancy is problematic or how it might affect the interpretation of the results. While the claim is supported by a reference, the lack of detailed explanation or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the reporting of results on the VQA dataset, noting that the testdev split is used instead of the teststandard split as recommended by the VQA dataset authors. This is a valuable piece of feedback as it highlights a potential overfitting issue that could affect the interpretation of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to their draft. While it points out a critical concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the methods presented in the paper to more structured layers like convolutions, noting that the performance of the methods is considerably lower compared to fully connected architectures. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the applicability of their methods to nonfully connected architectures. The comment lacks concrete actions or detailed advice, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the applicability of the methods to more structured layers like convolutions, noting that the performance is considerably lower compared to fully connected architectures. However, it does not specify which part of the paper discusses the applicability of the methods or which sections or figures might be relevant. This lack of grounding makes it difficult for the authors to identify the specific issue being addressed. While the comment is specific in its critique of the methods\" performance, it is 1 because it does not provide clear references or sections for the authors to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the methods to more structured layers like convolutions, noting that the performance is considerably lower compared to fully connected architectures. However, the comment does not provide specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the methods presented in the paper to more structured layers like convolutions, noting that the performance is considerably lower compared to fully connected architectures. This observation highlights a potential limitation of the methods and questions their readiness for extension to nonfully connected architectures. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the lack of clarity in evaluating the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be used for evaluation. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to implement the suggested metrics. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the evaluation process and consider the suggested metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment expresses a concern about the lack of clarity in evaluating the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be used for evaluation. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in suggesting potential metrics, the lack of grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the lack of clarity in evaluating the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be used for evaluation. However, the comment does not offer any specific reasoning, examples, or references to support why a pass rate is insufficient or why the suggested metrics are appropriate. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the refactoring process, specifically noting that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for evaluation, which offers some guidance to the authors. However, the comment lacks depth and does not elaborate on why a pass rate is inadequate or how the suggested metrics would improve the evaluation process. While it points out a potential area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a starting point for the authors to consider but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the Wiener deconvolution has been proposed before, suggesting that the main contribution of the paper is not significant. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of their work need to be clarified or improved. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the Wiener deconvolution or the main contribution. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is specific in that it points out a potential issue with the novelty of the contribution, but without grounding, the authors are left to guess which part of the paper needs attention. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the Wiener deconvolution has been proposed already, suggesting that the main contribution of the paper is not much sufficient. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or references to prior work, the authors may find it challenging to understand the basis of the criticism or how to address it. The comment is therefore 1, as it does not provide sufficient justification for the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper\"s contribution, specifically questioning whether the Wiener deconvolution has been proposed before. While it points out a concern, it does not provide detailed feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. The comment lacks actionable guidance, making it 3 as it highlights a potential area for improvement but does not offer specific steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a weakness in the connection made between spin glasses and the regularization term of the energy function. It points out that the paper does not explain how the regularization helps escape local minima, the effect on Parisi\u2019s order parameter, or the role of temperature (learning rate) in reaching lowentropic states. While the comment identifies specific areas where the connection is unclear, it does not provide explicit guidance on how the authors should address these issues. The action is implicit, as the authors need to infer that they should elaborate on these aspects to strengthen the connection. However, the lack of concrete suggestions or detailed guidance on how to implement these changes makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the connection to spin glasses and the regularization term of the energy function, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the connection, such as how the regularization helps escape local minima, the effect on Parisi\u2019s order parameter, and the role of temperature. This provides detailed guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the connection to spin glasses is weak because it does not explain how the regularization term helps escape local minima, the effect on Parisi\u2019s order parameter, or the role of temperature (learning rate). The comment provides specific areas where the connection is unclear, suggesting that the authors need to elaborate on these aspects to strengthen the connection. However, it lacks detailed reasoning or examples to fully support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of explanation regarding the connection between spin glasses and the regularization term of the energy function. It highlights specific areas where the connection is unclear, such as how the regularization helps escape local minima, the effect on Parisi\u2019s order parameter, and the role of temperature (learning rate) in reaching lowentropic states. This feedback is valuable as it directs the authors to improve the clarity and depth of their explanation, which is crucial for understanding the theoretical underpinnings of their work. However, the comment could be more helpful if it provided some guidance on how the authors might address these issues or suggested specific ways to enhance the explanation. Overall, the comment is 4, as it provides clear feedback that can guide the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the selftraining scheme is a direct application and that the contribution is relatively limited. However, it does not provide explicit guidance on how the authors should address this limitation or what specific aspects of the scheme need to be improved. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the selftraining scheme is a direct application and that the contribution is relatively limited. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. The comment lacks specificity in identifying what needs to be addressed, as it does not provide detailed guidance or examples. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the selftraining scheme is a direct application and that the contribution is relatively limited. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the selftraining scheme is a direct application and that the contribution is relatively limited. While it identifies a potential area for improvement, it lacks specific guidance or actionable suggestions on how the authors might address this limitation or enhance their contribution. The comment provides a general observation but does not offer detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the results shown in the paper are lowresolution and recommends zooming in on the rendered focal stack or allinfocus images to inspect the quality. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve the visual quality of their results. The comment is specific in its recommendation, detailing exactly what needs to be done to enhance the presentation of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results shown in the paper are lowresolution and recommends zooming in on the rendered focal stack or allinfocus images to inspect the quality. However, it does not specify which part of the paper this issue is addressed, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be done to improve the visual quality of the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the results shown in the paper are lowresolution and recommends zooming in on the rendered focal stack or allinfocus images to inspect the quality. This claim is 3 as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors can infer that the lowresolution nature of the results might impact the assessment of quality, but the comment does not offer detailed reasoning or evidence to substantiate this concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in the paper, noting that they are lowresolution. It suggests that zooming in on the rendered focal stack or allinfocus images would allow for a better inspection of the quality. This feedback is clear and actionable, providing the authors with a direct and specific direction to improve the presentation of their results. By addressing this issue, the authors can enhance the clarity and comprehensiveness of their findings, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two potential issues with the comparative inference method: increased inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration. While the comment identifies specific problems, it does not provide explicit guidance on how the authors might address these issues or suggest alternative approaches. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparative inference method, specifically mentioning the increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration. However, it does not specify which part of the paper discusses the comparative inference method, making it weakly grounded. The comment is specific in detailing the issues with the method, such as the computational cost and the need for validation data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparative inference method increases inference cost due to multiple forward passes and requires validation data for posthoc calibration, which may limit its applicability in realworld scenarios with limited computational resources. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the comparative inference method, specifically mentioning the increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration. This critique highlights potential limitations in the method\"s applicability, particularly in realworld scenarios where computational resources are constrained or validation data is not readily available. While the comment points out these concerns, it does not offer specific suggestions or guidance on how the authors might address these issues or improve the method. The feedback is 3 as it identifies a critical area for improvement, but it lacks actionable advice, making it only partially beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an alternative approach to handling exploding gradients by performing gradient clipping with a high value for the gradient norm, rather than simply reinitializing the model. This provides a specific action for the authors to consider, offering a concrete suggestion for improvement. However, the comment does not explicitly instruct the authors to implement this suggestion or provide detailed guidance on how to do so. The action is somewhat vague, as it leaves the authors to determine the exact implementation steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (L265), allowing the authors to accurately identify the part being addressed. It also provides a specific suggestion for improvement by recommending gradient clipping as an alternative to reinitialization, which is a clear and actionable piece of advice. The comment is specific in its suggestion, detailing what could be done to address the issue of exploding gradients. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an alternative approach to handling exploding gradients by performing gradient clipping with a high value for the gradient norm, rather than simply reinitializing the model. This is a specific suggestion that provides a clear and actionable recommendation for the authors to consider. However, the comment does not provide any additional reasoning or justification for why this approach is effective or how it might be implemented. While the suggestion is logical, it lacks depth and detailed explanation, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the handling of exploding gradients, and suggests an alternative approach to address this problem. It recommends performing gradient clipping with a high value for the gradient norm, which is a more robust and less hacky solution compared to simply reinitializing the model. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement. However, the comment could be more helpful if it included additional details on how to implement the suggested approach or why it is expected to be effective. Overall, the comment is 4 as it offers a valuable insight and a practical suggestion, but it could be further enhanced with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the exact meaning of the term \"common pattern\" and requests a more detailed explanation. This is an explicit action that the authors can readily understand and implement by providing a clearer definition or elaborating on the concept. The comment is specific and concrete, as it directly points out the need for a more detailed explanation of a key term. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a more detailed explanation of the term \"common pattern,\" which is a clear and actionable request for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the exact meaning of the term \"common pattern\" and requests a more detailed explanation. This is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper that needs clarification, specifically the term \"common pattern.\" It requests a more detailed explanation of this term, which is crucial for understanding the context and content of the paper. This feedback is clear and actionable, as it directs the authors to provide additional context or elaboration on the term. However, the comment could be more helpful if it suggested specific ways to clarify the term or provided examples. Overall, the comment is 3 as it highlights an important area for improvement, but it lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to improve the model\"s generalizability. The comment lacks concrete guidance or actionable advice, leaving the authors without a clear understanding of how to respond or improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is 1 as it does not provide specific guidance or examples of how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the pretrained model to datasets from sources other than Reddit. It questions whether the model\"s performance might be limited when applied to datasets from platforms like Twitter or Facebook. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what steps they could take to improve the model\"s generalizability. Without actionable advice or specific recommendations, the authors may find it challenging to respond to this feedback effectively. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the quality of the generated dataset, specifically questioning how the authors address the issue of LLM hallucinations. However, it does not provide any explicit or implicit suggestions on how to quality check the dataset or what methods could be used. The comment lacks concrete guidance on how to implement the suggested action, leaving the authors without a clear understanding of what steps to take. As a result, the comment is 1, as it does not provide any actionable feedback or direction for improvement.", "grounding_specificity_rationale": "The comment raises a concern about the quality of the generated dataset, specifically questioning how the authors address the issue of LLM hallucinations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is 1 as it does not provide specific guidance on how to quality check the dataset or what methods could be used. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the quality of the generated dataset, specifically questioning how the authors address the issue of LLM hallucinations. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the quality of the generated dataset, specifically questioning how the authors address the issue of LLM hallucinations. However, it does not provide any suggestions or guidance on how to improve the quality of the dataset or address the issue of hallucinations. The comment lacks actionable feedback, leaving the authors without any clear direction on how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the meaningfulness of the comparison across four models, suggesting that the finetuned wav2vec model might perform best, making the comparison less insightful. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the comparison. The comment implies that the authors should consider alternative approaches or provide more detailed analysis to make the comparison more meaningful. While the action is somewhat inferred, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the meaningfulness of the comparison across four models, suggesting that the finetuned wav2vec model might perform best, making the comparison less insightful. However, it does not specify which part of the paper this issue is related to, such as the experimental setup or results section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the meaningfulness of the comparison across four models, suggesting that the finetuned wav2vec model might perform best, making the comparison less insightful. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to fully substantiate the concern, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for concern but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment raises a valid concern about the meaningfulness of the comparison across four models, suggesting that the finetuned wav2vec model might perform best, making the comparison less insightful. While the comment identifies a potential issue with the experimental design, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the comparison. The feedback is 3 as it highlights a potential weakness, but it lacks actionable advice or detailed suggestions for improvement, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the paper is wellwritten but feels dense, especially when compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help. However, the comment does not specify which parts of the paper would benefit from additional examples or how the authors should incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that more examples would be beneficial. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the paper is wellwritten but feels dense, especially when compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help. However, the comment does not specify which part of the paper would benefit from additional examples or how the authors should incorporate them. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in suggesting the inclusion of more examples, but without explicit mention of the section or figure, the authors still need to infer where to apply the suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper feels dense, even compared to other puremath ML papers, and suggests that more examples, such as Figure 2, would help. However, the comment lacks specific examples or references to support the claim that the paper is dense or that additional examples would significantly improve its clarity. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the density and the benefit of additional examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the paper is wellwritten but feels dense, especially when compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help. However, the comment lacks specificity in terms of which parts of the paper would benefit from additional examples or how the authors should incorporate them. While it provides a general direction for improvement, it does not offer detailed guidance or actionable suggestions, making it 3. The feedback is valuable but could be more comprehensive if it included specific sections or examples that would benefit from additional examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a difference in the level of detail provided in sections 4.1 and 4.2. It notes that 4.2 starts with highlevel intuition, while 4.1 does not. However, the comment does not specify what the authors should do to address this issue or how they can improve the consistency between the two sections. The action is implicit and vague, as it does not provide explicit guidance on what needs to be done to make the sections more consistent. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"Section 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a difference in the level of detail provided in these sections, noting that 4.2 starts with highlevel intuition while 4.1 does not. This provides clear guidance on what needs to be addressed to improve the consistency and clarity of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the structure of the paper, noting that section 4.2 starts with highlevel intuition while section 4.1 does not. This observation is based on the content of the sections but does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The comment points out a structural difference in the paper, noting that section 4.2 starts with highlevel intuition while section 4.1 does not. This observation is factual and highlights a potential inconsistency in the presentation of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the consistency between the sections. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Figure 3 contains permutation matrices and recommends that more discussions be introduced. However, it does not specify which part of the paper these figures are located in, nor does it provide explicit guidance on what kind of discussions should be included. The action is implicit and vague, as the authors are left to infer that they need to expand the discussion section related to these figures. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that Figure 3 contains permutation matrices and recommends that more discussions be introduced. However, it does not specify which part of the paper these figures are located in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific about the type of content (permutation matrices) and the need for more discussions, it lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that Figure 3 contains permutation matrices and recommends that more discussions be introduced. However, it does not provide any specific reasoning or evidence to support why this is a necessary or beneficial addition. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis for the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 3 contains permutation matrices and recommends that more discussions be introduced. However, it lacks specificity and does not provide detailed guidance on what kind of discussions would be beneficial. The comment is 3 as it identifies a potential area for improvement, but it does not offer actionable advice or examples to help the authors enhance their work. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the identity and recruitment/training of crowd workers, which is a relevant detail for the authors to consider. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the identity and recruitment/training of crowd workers, which is a relevant detail for the authors to consider. However, it does not specify which part of the paper this information is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is 1 as it does not provide specific guidance on which part of the paper to address. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the identity and recruitment/training of crowd workers, which is a relevant detail for the authors to consider. However, it does not contain a claim or assertion that requires verification. The comment is factual and descriptive, lacking any subjective opinions or suggestions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the identity and recruitment/training of crowd workers, which is a relevant detail for the authors to consider. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the draft. The comment lacks actionable feedback, leaving the authors with no clear direction on how to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the weak correlation between automatic metrics and human evaluations, suggesting that this might raise questions about the validity and robustness of the conclusions. It implies that the authors should consider the importance of human evaluations of the quality of the results. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should incorporate human evaluations or what changes might be necessary. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of weak correlation between automatic metrics and human evaluations, suggesting that this raises questions about the validity and robustness of the conclusions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem and suggesting that human evaluations are more important, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the correlation between automatic metrics and human evaluations is weak, which raises questions about the validity and robustness of the conclusions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to fully substantiate the assertion, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for concern but lacks the necessary depth and support to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the correlation between automatic metrics and human evaluations, suggesting that this might raise questions about the validity and robustness of the conclusions. It highlights the importance of human evaluations of the quality of the results, which is a valuable point for consideration. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate human evaluations into their work. While it raises a concern, it lacks actionable advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits the comment\"s overall impact."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment requests more specificity regarding the \"Chain of Reasoning\" section, particularly mentioning line 276. While the comment implies that the authors should provide more detailed information or examples in this section, it does not explicitly instruct them to do so or specify how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the chain of reasoning and provide more context or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment requests more specificity regarding the \"Chain of Reasoning\" section, specifically mentioning line 276. However, it does not provide any guidance on what aspects of the chain of reasoning need to be elaborated upon or how the authors should address the issue. The authors cannot confidently determine which part of the paper is being addressed, as the comment is vague and does not specify the exact section or line. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point requests more specificity regarding the \"Chain of Reasoning\" section, particularly mentioning line 276. However, it does not provide any specific examples, reasoning, or references to support why this section needs more detail. The comment lacks sufficient justification or evidence to be considered verifiable. Therefore, it is classified as 1.", "helpfulness_rationale": "The comment requests more specificity regarding the \"Chain of Reasoning\" section, particularly mentioning line 276. While it identifies a potential area for improvement, it lacks detailed guidance or suggestions on how to enhance the section. The feedback is 3 as it directs the authors to a specific part of the paper that needs more detail, but it does not provide comprehensive advice or examples to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a sample quality metric on the CARLA data, specifically mentioning the common metrics minADE or minMSD. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific metric to use or how to integrate it into the analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the ability to perform \"hypothetical inference\" or planning, suggesting that the authors should include a sample quality metric on the CARLA data. It mentions specific metrics like minADE or minMSD, which are common in the field. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in detailing what needs to be addressed, such as the inclusion of sample quality metrics. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there should be a sample quality metric on the CARLA data, specifically mentioning minADE or minMSD. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this suggestion is necessary or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a sample quality metric on the CARLA data, specifically mentioning minADE or minMSD. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the evaluation of the model\"s performance. However, the comment could be more helpful if it offered additional guidance on how to implement or interpret the inclusion of such a metric. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors assume they can naturally have every constraint and its corresponding discriminator. This is a direct and explicit question that prompts the authors to clarify their assumptions about the constraints and discriminators used in their work. The comment is clear and specific, providing a clear action for the authors to take, which is to address the assumption in their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment questions whether the authors assume they can naturally have every constraint and its corresponding discriminator. However, it does not specify which part of the paper this assumption is made or where the constraints and discriminators are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs clarification. While the comment is specific in its questioning, it lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the assumptions made regarding constraints and discriminators, but it does not provide any specific reasoning, examples, or references to support the claim. The comment is purely speculative and does not offer any guidance or justification for the authors to consider. Therefore, it is classified as \"1\" as it lacks any supporting evidence or logical reasoning.", "helpfulness_rationale": "The review comment raises a question about the assumptions made regarding constraints and discriminators, which is a critical aspect of the paper. By questioning whether the authors assume they can naturally have every constraint and its corresponding discriminator, the reviewer highlights a potential gap in the paper\"s clarity and completeness. This feedback is valuable as it prompts the authors to explicitly address their assumptions, ensuring that the paper is clear and welldefined. However, the comment could be more helpful if it provided specific examples or guidance on how to clarify these assumptions. Overall, the comment is 3 as it identifies an important area for improvement but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that using Optimal Transport (OT) or the Wasserstein Distance in GANs is first seen in the Wasserstein GAN paper (WGAN) and recommends discussing WGAN or adding it as a baseline method. While the comment provides a clear action\u2014either discussing WGAN or adding it as a baseline\u2014it does not specify which part of the paper this discussion or addition should occur. The action is explicit but lacks concrete guidance on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Optimal Transport (OT), or more specifically leveraging the Wasserstein Distance, in GAN\" and refers to the \"Wasserstein GAN paper, i.e. WGAN (Arjovsky et al. ICML 2017).\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it suggests discussing WGAN or adding it as a baseline method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using Optimal Transport (OT) or the Wasserstein Distance in GANs is first seen in the Wasserstein GAN paper (WGAN) and suggests discussing WGAN or adding it as a baseline method. The comment provides a specific reference to the WGAN paper, which is a wellknown work in the field. However, it lacks detailed reasoning or examples to fully support the claim, making it 3. The authors would benefit from additional context or references to fully understand the significance of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the use of Optimal Transport (OT) or the Wasserstein Distance in GANs is first seen in the Wasserstein GAN paper (WGAN). It recommends discussing WGAN or adding it as a baseline method. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft by referencing a relevant and wellknown work in the field. However, the comment could be more helpful if it offered additional guidance on how to integrate or discuss WGAN effectively. Overall, the comment is 4 as it directs the authors to a relevant area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of important related work on MCMC in discrete spaces, specifically mentioning methods that apply Langevin MCMC to sample discrete sequences. It provides references to these works, suggesting that they should be discussed. The comment also critiques the paper\"s preliminary results, clarity, and organization, suggesting that it may be more suitable for a workshop presentation rather than a conference publication. However, the comment does not explicitly instruct the authors to include these related works or address the issues with clarity and organization. While the authors can infer that they need to incorporate the suggested references and improve the paper\"s presentation, the lack of explicit guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work on MCMC in discrete spaces\" and provides specific references to papers that should be discussed. It also critiques the paper\"s preliminary results, clarity, and organization, suggesting that it may be more suitable for a workshop presentation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that important related work on MCMC in discrete spaces is absent, specifically mentioning methods that apply Langevin MCMC to sample discrete sequences. It provides references to these works, suggesting that they should be discussed. The claim is supported by the references provided, which are specific and relevant to the topic. However, the comment could be more verifiable by including a brief summary of the methods discussed in the references or by explaining how their absence impacts the paper\"s contribution. Overall, the claim is 4, as it is supported by evidence but lacks some depth in explanation or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important related work on MCMC in discrete spaces, specifically mentioning methods that apply Langevin MCMC to sample discrete sequences. It provides references to these works, which the authors should discuss to contextualize their contribution. Additionally, the comment critiques the paper\"s preliminary results, clarity, and organization, suggesting that it may be more suitable for a workshop presentation rather than a conference publication. This feedback is 4 as it provides clear guidance on what needs to be addressed, such as including the suggested references and improving the paper\"s presentation. However, it could be more comprehensive if it offered specific suggestions on how to enhance the clarity and organization of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind using different methods for estimating $g$ in DSFedDRO and FedDRO. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to clarify the differences in methods. As a result, the authors are left without any actionable feedback on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind using different methods for estimating $g$ in DSFedDRO and FedDRO. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it does not provide explicit references to specific sections, tables, or figures. Additionally, it does not specify what needs to be addressed or why the question is important. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the rationale behind using different methods for estimating $g$ in DSFedDRO and FedDRO. However, it does not provide any claim, suggestion, or judgment that requires verification. The comment is purely factual and descriptive, asking for clarification rather than making an assertion. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using different methods for estimating $g$ in DSFedDRO and FedDRO. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or what steps they should take to improve their understanding. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. While it highlights a potential issue with the experimental methodology, it does not provide explicit instructions or suggestions on how to address this problem. The authors are left to infer that they need to conduct multiple experiments and include variance analysis, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it identifies an action but does not provide detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment highlights a potential issue with the experiments, specifically noting that they were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the problem, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this is a concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, specifically noting that they were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is clear and actionable, as it highlights a specific area where the authors could improve their experimental methodology. However, the comment could be more helpful if it provided suggestions on how to conduct multiple experiments or how to perform variance analysis. Despite this, the comment offers valuable guidance for the authors to enhance the rigor and reliability of their results, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by pointing out that the authors acknowledge inherent gaps between AL experiments and the goal of achieving label efficiency with a human in the loop. It mentions specific factors, such as differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. However, the comment does not provide explicit guidance on how the authors should address these gaps or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses gaps with realworld datasets, specifically mentioning the limitations of AL experiments in achieving label efficiency with a human in the loop. It highlights factors such as differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. However, the comment does not specify which part of the paper discusses these gaps or datasets, making it weakly grounded. The comment is specific in detailing the issues that need to be addressed, such as the lack of consideration for realworld data characteristics. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper acknowledges inherent gaps between AL experiments and the goal of achieving label efficiency with a human in the loop. It provides specific examples, such as differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. However, the comment lacks detailed reasoning or references to support these claims, making it 3. The authors would need to infer the basis for these claims, which could be improved with additional explanation or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of consideration for realworld datasets and the limitations of the experiments in achieving label efficiency with a human in the loop. It highlights specific factors, such as differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. This feedback is valuable as it directs the authors to address these gaps and improve the robustness and applicability of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to incorporate these considerations into the experiments or the discussion. Overall, the comment is 3, as it offers a clear direction for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the significance of the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms that achieve O(H) communication rounds. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. Without specific suggestions or instructions, the authors are left without a clear path to respond or improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the significance of the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms that achieve O(H) communication rounds. However, the comment does not specify which part of the paper discusses the communication cost or which algorithms are being referenced. This lack of grounding makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. While the comment is specific in its critique of the communication cost, the absence of explicit references or grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the significance of the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms that achieve O(H) communication rounds. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the significance of the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms that achieve O(H) communication rounds. This feedback highlights a potential area for improvement, as it challenges the authors to consider whether their communication cost is truly competitive or if it could be optimized further. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable advice or detailed reasoning, the authors may find it challenging to respond effectively. Therefore, the comment is 3, as it identifies a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the novelty of the main idea, suggesting that using an ensemble of neural networks is a common practice in machine learning. It also points out that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment does not offer explicit guidance on how the authors should address this issue or what specific aspects of the ensemble method or its adaptation to homomorphic encryption need to be clarified or improved. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the novelty of the main idea, suggesting that using an ensemble of neural networks is a common practice in machine learning. It also points out that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment does not specify which part of the paper discusses the use of ensemble neural networks or how it relates to the homomorphic encryption domain. This lack of grounding makes it difficult for the authors to identify the specific sections or parts of the paper that need attention. While the comment is specific in its critique of the novelty, it is 1 because it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, suggesting that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it is based on a general observation without thorough justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the main idea, suggesting that using an ensemble of neural networks is a common practice in machine learning. It also points out that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what specific aspects of the ensemble method or its adaptation to homomorphic encryption need to be clarified or improved. While it highlights a potential weakness, it does not offer actionable feedback or constructive advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by questioning the lack of clarity regarding why and how the new model works better than the previous stateoftheart, MH. While it points out that the paper presents a new model and demonstrates its improvement on a few benchmark datasets, it does not provide explicit guidance on how the authors should address this gap. The comment suggests that the authors should clarify the mechanisms behind the model\"s improvement, but it does not offer specific steps or examples on how to do so. Therefore, the action is implicit and somewhat vague, as the authors need to infer the need for clarification and then determine how to address it. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"General Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a key issue: the lack of clarity regarding why and how the new model works better than the previous stateoftheart, MH. This provides clear guidance on what needs to be addressed in the discussion section. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the lack of clarity regarding why and how the new model works better than the previous stateoftheart, MH. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by questioning the lack of clarity regarding why and how the new model works better than the previous stateoftheart, MH. This feedback is valuable as it highlights an area where the authors could improve the depth and understanding of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting additional experiments or analyses that could clarify the model\"s performance. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point questions the reasonableness of a formula in the \"Adjective Projection\" part of the paper. It suggests that the authors should calculate the similarity between the object and \"large\" and \"small\" separately, then calculate the difference between these similarities, rather than using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. This feedback provides a clear and explicit action for the authors to take, specifying exactly how they should revise the formula. The comment is concrete and directly instructs the authors on how to improve their approach, making it 5.", "grounding_specificity_rationale": "The comment questions the reasonableness of a formula in the \"Adjective Projection\" part of the paper, specifically regarding how similarity is calculated to determine if an object is large or small. It provides a detailed explanation of the suggested approach, which involves calculating similarity separately for \"large\" and \"small\" and then calculating the difference between these similarities. This feedback is fully grounded as it explicitly mentions the \"Adjective Projection\" part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in the formula. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reasonableness of a formula in the \"Adjective Projection\" part of the paper, suggesting an alternative approach to estimating whether an object is large or small. The comment provides a detailed explanation of the suggested method, which involves calculating similarity separately for \"large\" and \"small\" and then calculating the difference between these similarities. This feedback is 4 as it offers a clear rationale for why the current approach might be unreasonable and suggests a more logical alternative. However, it could be strengthened by providing additional context or examples to further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the reasonableness of a formula used in the \"Adjective Projection\" part of the paper. It suggests an alternative approach to estimating whether an object is large or small, which involves calculating the similarity between the object and \"large\" and \"small\" separately, and then calculating the difference between these similarities. This feedback is clear and actionable, providing the authors with a specific suggestion for how to improve their approach. By offering a detailed explanation of the current method and proposing an alternative, the comment helps the authors understand and address a potential weakness in their methodology. Therefore, the comment is 5, as it provides clear guidance on how to enhance the paper\"s approach."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should discuss and compare its approach to more recent works on anyresolution image generation, providing specific examples of relevant papers. This feedback is explicit and concrete, as it directly instructs the authors to include a discussion and comparison with recent works. The authors are given clear guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss and compare the paper\"s approach to more recent works on anyresolution image generation, providing specific examples of relevant papers. This allows the authors to accurately identify the part of the paper that needs improvement. The comment is also specific because it clearly specifies what needs to be addressed, namely the discussion and comparison with recent works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should discuss and compare its approach to more recent works on anyresolution image generation, providing specific examples. This claim is 3 as it offers a suggestion for improvement by referencing specific papers, which could help the authors understand the context and relevance of their work. However, the comment lacks a detailed explanation of why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the reasoning behind the suggestion, which could be improved with more explicit justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should discuss and compare its approach to more recent works on anyresolution image generation. It provides specific examples of relevant papers, which can help the authors contextualize their work and highlight its contributions. This feedback is clear and actionable, offering a concrete direction for enhancing the paper. However, it could be more helpful if it included additional guidance on how to effectively discuss and compare the works. Overall, the comment is 4, as it provides a valuable suggestion for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the sufficiency of Section 6 in describing the limitations of the work, specifically regarding overfitting due to the small test set size. It suggests that the authors should discuss the limitations of the approach, including theoretical assumptions, implementation considerations, and other relevant factors. Additionally, the comment questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and asks for a comparison of training times between these alternatives and online learning implementations. While the comment provides explicit suggestions for improvement, it lacks concrete guidance on how to address these issues or what specific aspects of the limitations should be discussed. The action is somewhat vague, as the authors need to infer the exact steps to take to address the concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (84: 1763\u2013 1780) and provides a link to a reference, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies two key areas for improvement: the sufficiency of limitations described in Section 6 and the comparison of training times between ODER and RED (Unfold/Denoising) with online learning implementations. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the sufficiency of Section 6 in describing the limitations of the work, specifically regarding overfitting due to the small test set size. It suggests that the authors should discuss the limitations of the approach, including theoretical assumptions, implementation considerations, and other relevant factors. Additionally, the comment questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and asks for a comparison of training times between these alternatives and online learning implementations. While the comment provides specific examples and questions that could guide the authors in addressing these issues, it lacks detailed reasoning or references to support the claims. The feedback is 3 as it offers suggestions for improvement but could be more robust with additional evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the CT experiment with only one subject in the test set is prone to overfitting. It also points out that Section 6 does not sufficiently describe the limitations of the work. The comment suggests that the authors should discuss the limitations of the approach, including theoretical assumptions, implementation considerations, and other relevant factors. Additionally, it questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and asks for a comparison of training times between these alternatives and online learning implementations. This feedback is 4 as it provides clear suggestions for improvement and directs the authors to specific areas that need attention. However, it could be more comprehensive if it included more detailed guidance or examples of how to address these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the proposed multiscale hierarchical predictor and existing methods like IEConv, CDConv, and ProNet, which also use pooling layers and learn different scale representations. It provides a list of references to support the discussion. However, it does not explicitly instruct the authors to address this question or provide specific guidance on how to compare their method with these existing approaches. The comment lacks actionable steps for the authors to improve their draft, making it 1.", "grounding_specificity_rationale": "The comment addresses the comparison of the proposed method with other methods like IEConv, CDConv, and ProNet, which also use pooling layers and learn different scale representations. It provides a list of references to support the discussion, which helps the authors understand the context of the comparison. However, the comment does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in detailing the comparison with existing methods, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between the proposed multiscale hierarchical predictor and existing methods like IEConv, CDConv, and ProNet, which also use pooling layers and learn different scale representations. It provides a list of references to support the discussion, which helps in understanding the context of the comparison. However, the comment lacks detailed reasoning or specific examples to fully justify the claim that the proposed method is different from these existing approaches. While the references provide some support, the absence of a clear explanation or detailed comparison makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the differences between the proposed multiscale hierarchical predictor and existing methods like IEConv, CDConv, and ProNet, which also use pooling layers and learn different scale representations. It provides a list of references to support the discussion, which helps the authors understand the context of the comparison. However, the comment lacks detailed reasoning or specific guidance on how to address this comparison or what aspects of the proposed method are unique. Without actionable suggestions or a clear path for improvement, the comment is 3, as it identifies an area for clarification but does not provide substantial guidance for the authors to enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide any specific guidance or suggestions on what aspects of the paper need to be proofread or how to improve the writing quality. The comment lacks concrete actions for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment suggests that the paper does not read well and recommends more careful proofreading. However, it does not specify which sections or parts of the paper need improvement, nor does it provide any guidance on how to conduct the proofreading. The lack of specific information makes it difficult for the authors to address the issue effectively. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not read well and suggests more careful proofreading. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the paper does not read well and suggests that more careful proofreading is needed. However, it lacks specific details or actionable suggestions on what aspects of the paper require improvement or how the authors can enhance the writing quality. Without concrete guidance or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several points that could be addressed to improve the paper. It suggests that the authors should provide an analysis of the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, as this difference is important for the synthetic task. Additionally, the value and selection process of the tradeoff parameter (Theta) are not mentioned, and the authors should clarify this. The comment also suggests exploring the performance of a baseline where the attention from the previous question is simply used instead of a soft attention mechanism. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises several specific questions and suggestions regarding the analysis of addressing coefficients (Betas) and the tradeoff parameter (Theta). It explicitly mentions the importance of this analysis for the synthetic task, which helps the authors understand the relevance of the feedback. However, the comment does not specify which part of the paper discusses the addressing coefficients or the tradeoff parameter, making it weakly grounded. The suggestions for additional analysis and baseline comparisons are specific and provide clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the analysis of addressing coefficients (Betas) and the tradeoff parameter (Theta). It questions the importance of the distribution of Beta with and without bias towards sequential addressing, particularly for the synthetic task, and asks for clarification on the value and selection process of Theta. The comment also suggests exploring the performance of a baseline where the attention from the previous question is simply used instead of a soft attention mechanism. However, the comment lacks specific examples, detailed reasoning, or references to support these claims, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment provides several specific suggestions for improvement, such as analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, which is particularly important for the synthetic task. It also questions the value and selection process of the tradeoff parameter (Theta) and suggests exploring the performance of a baseline where the attention from the previous question is simply used instead of a soft attention mechanism. However, the comment lacks detailed guidance on how to implement these suggestions or what specific actions the authors should take. While it offers valuable insights, the feedback could be more helpful if it included concrete steps or examples for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of concentration inequalities is expected. The reviewer also expresses a personal opinion that the proposition is \"decorative math\" and does not contribute to the paper\"s interest or complexity measure in a statistical learning sense. While the comment raises a valid point about the relevance of the proposition, it does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed. The action is implicit, as the authors would need to infer that they should reconsider the inclusion or relevance of Proposition 1. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of concentration inequalities is expected. It also expresses a personal opinion that the proposition is \"decorative math\" and does not contribute to the paper\"s interest or complexity measure in a statistical learning sense. However, the comment does not specify which part of the paper discusses Proposition 1 or provide any context for why this proposition is being questioned. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in its critique of the proposition\"s relevance, but without grounding, the authors are left to make their own connections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of concentration inequalities is expected. The reviewer argues that the proposition is \"decorative math\" and does not contribute to the paper\"s interest or complexity measure in a statistical learning sense. However, the comment lacks specific examples or references to support the claim that the proposition is a standard regression problem or that it does not contribute to the paper\"s interest. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of concentration inequalities is expected. The reviewer expresses a personal opinion that the proposition is \"decorative math\" and does not contribute to the paper\"s interest or complexity measure in a statistical learning sense. While the comment identifies a potential issue with the inclusion of the proposition, it lacks specific guidance on how the authors might address this concern or what changes could be made to improve the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the limited evaluation of defense techniques in the context of backdooring classification, specifically mentioning the importance of evaluating the proposed method against defenses that rely on input perturbation. It provides references to relevant works, Doan et al. Lira: Learnable, imperceptible and robust backdoor attacks. ICCV 2021. and Doan et al. Backdoor attack with imperceptible input and latent modification. NeurIPS 2021. However, the comment does not explicitly instruct the authors to include a detailed evaluation of these defenses or to incorporate the suggested references into their work. While the authors can infer that they need to address this aspect, the lack of explicit guidance on how to do so makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of defense techniques in the context of backdooring classification, allowing the authors to accurately identify the part of the paper being addressed. It specifies the importance of evaluating the proposed method against defenses that rely on input perturbation, referencing specific works by Doan et al. Lira and Doan et al. Backdoor attack with imperceptible input and latent modification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that the paper lacks a detailed evaluation of defense techniques, particularly in the context of backdooring classification. It suggests that the evaluation should include defenses that rely on input perturbation and provides references to relevant works, Doan et al. Lira: Learnable, imperceptible and robust backdoor attacks. ICCV 2021. and Doan et al. Backdoor attack with imperceptible input and latent modification. NeurIPS 2021. The claim is supported by the references, which provide examples of relevant works that could be included in the evaluation. However, the comment could be more verifiable by explicitly explaining how the inclusion of these defenses would enhance the paper\"s comprehensiveness. Overall, the comment is 4, as it provides a clear basis for improvement but lacks some depth in terms of detailed reasoning or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of defense techniques, particularly in the context of backdooring classification. It highlights the importance of evaluating the proposed method against defenses that rely on input perturbation, referencing relevant works such as Doan et al. Lira: Learnable, imperceptible and robust backdoor attacks. ICCV 2021. and Doan et al. Backdoor attack with imperceptible input and latent modification. NeurIPS 2021. This feedback is valuable as it directs the authors to consider a more comprehensive evaluation of their method, which could enhance the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it provided specific guidance on how to incorporate these defenses into the evaluation or suggested additional references that could be included. Overall, the comment is 4, as it offers a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. It also criticizes the shallow presentation of context and evidencebased methods in the related work. However, the comment does not provide explicit guidance on how to achieve these improvements or what specific aspects of the related work should be expanded. The actions are implicit and vague, leaving the authors uncertain about how to implement the suggestions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the related work section should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. It also criticizes the shallow presentation of context and evidencebased methods in the related work. However, the comment does not specify which part of the paper the related work section is located, making it weakly grounded. The comment is specific in its suggestions regarding the need for more detailed descriptions and examples, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. It also criticizes the shallow presentation of context and evidencebased methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides feedback on the related work section, suggesting that it should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. It also criticizes the shallow presentation of context and evidencebased methods. However, the comment lacks specific guidance on how to achieve these improvements or what aspects of the related work should be expanded. While it identifies areas for improvement, the feedback is 3 as it offers a clear direction for the authors to enhance their work, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific observation about the performance of a model with Batch Normalization (BN) before ReLU, noting that it hurts performance. The authors are then questioned about their argument that BN can be folded into a convolutional layer, particularly in the context of BN after ReLU being foldable into the next convolutional operation. This feedback is explicit and provides a clear action for the authors to take, which is to address the question and provide a detailed explanation of the folding process. The comment is specific and actionable, as it directly points out a potential area of confusion or lack of clarity in the authors\" argument. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"same paragraph\" and \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\" argument about the foldability of Batch Normalization (BN) after ReLU, providing a detailed explanation of why BN after ReLU can be folded into the next convolutional operation. This feedback is clear and specific, guiding the authors to address a particular aspect of their argument. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the authors\" argument regarding the foldability of Batch Normalization (BN) after ReLU. It suggests that BN after ReLU can be folded into the next convolutional operation because all activations in the same convolutional feature map share the same mean, variance, scale, and offset in the BN implementation. This claim is supported by logical reasoning and a clear explanation of the underlying principles. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is 4, as it provides a reasonable basis for the claim but lacks some depth in terms of detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific observation about the performance of a model with Batch Normalization (BN) before ReLU, noting that it hurts performance. It then questions the authors\" argument about the foldability of BN after ReLU, particularly in the context of BN after ReLU being foldable into the next convolutional operation. This feedback is clear and actionable, as it prompts the authors to address the question and provide a detailed explanation of the folding process. By doing so, the authors can clarify their argument and improve the clarity of their paper. The comment is 4 as it provides a specific area for improvement and encourages the authors to address a potential point of confusion. However, it could be more helpful if it included suggestions for how the authors might address the question or provide additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of largescale experiments in the paper, noting that the models used in the experiments are small. It suggests that including experiments that vary the size of the network and show a trend could be beneficial. While the comment identifies a specific area for improvement and provides a clear direction for the authors to consider, it does not explicitly instruct them on how to conduct these experiments or what specific results to look for. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of smallscale experiments and suggests that the authors should include experiments that vary the size of the network to show trends. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models used in the experiments are small, specifically mentioning 80 hidden neurons for MNIST and a single convolutional layer with 40 channels for SVHN. The comment suggests that including experiments with varying network sizes could provide insights into the scalability of the results. However, the comment lacks specific examples or references to support the claim that such experiments would be beneficial or how they would demonstrate trends. Without detailed reasoning or evidence, the claim is 3, as it provides a general suggestion but lacks depth and specificity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of largescale experiments. It points out that the models used in the experiments are small, which may limit the generalizability of the results. The comment suggests that including experiments that vary the size of the network could provide valuable insights into whether the findings from smallscale experiments extend to larger scales. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their work. However, it could be more helpful if it included suggestions on how to conduct these experiments or what specific results to look for. Overall, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the behavior of the method when W is an identity matrix, suggesting that the problem reduces to a spherical case. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to compare their results with prior work. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the behavior of the method when W is an identity matrix, suggesting that the problem reduces to a spherical case and asking how the results compare with prior work. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its inquiry about the spherical case and comparison with prior work, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of the method when W is an identity matrix, suggesting that the problem reduces to a spherical case and asking how the results compare with prior work. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the problem reduces to a spherical case or how the results should be compared with prior work. Without these details, the authors are left without guidance on how to address the question or what evidence is needed to substantiate the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the behavior of the method when W is an identity matrix, suggesting that the problem reduces to a spherical case. It also asks how the results compare with prior work, which is a relevant point for the authors to consider. However, the comment lacks specific guidance or suggestions on how the authors might address this question or what steps they should take to compare their results with prior work. While it identifies an area for improvement, it does not provide actionable advice or detailed insights, making it 3. The authors would need to infer the need for further analysis and comparison, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs, which restricts its applicability to general MILP or QUBO problems. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this limitation or expand the scope of their work. Without specific guidance on what changes could be made, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus of the work on CO problems on graphs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the limitation regarding the application scope, which is clear and specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work primarily focuses on CO problems on graphs, which limits its applicability to general MILP or QUBO problems. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs, which restricts its applicability to general MILP or QUBO problems. This feedback is clear and actionable, as it highlights a specific area where the authors could potentially broaden the scope of their work. However, the comment could be more helpful if it provided suggestions on how the authors might address this limitation or expand the applicability of their work. Despite this, the comment offers valuable insight that could guide the authors in enhancing their research. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that learning both low and highfrequency information in balance is not novel and suggests that the authors should analyze and compare their work to several related works. However, it does not provide explicit guidance on how to conduct this analysis or comparison, nor does it specify which aspects of the work should be compared. The comment is 3 as it identifies a potential area for improvement, but it lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works that the authors should analyze and compare their approach to, providing clear guidance on which parts of the paper need attention. It specifies the need to analyze and compare the work to several related works, enhancing the authors\" understanding of the context and potential improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that learning both low and highfrequency information in balance is not novel and suggests that the authors should analyze and compare their work to several related works. The comment provides specific references to relevant papers, such as [1] Stochastic Frequency Masking to Improve SuperResolution and Denoising Networks. ECCV 2020, [2] FSDR: Frequency Space Domain Randomization for Domain Generalization. CVPR 2021, [3] Spectrum Random Masking for Generalization in Imagebased Reinforcement Learning. NeurIPS 2022, and [4] MASKED FREQUENCY MODELING FOR SELFSUPERVISED VISUAL PRETRAINING. ICLR 2023. These references provide evidence to support the claim that the work is not novel and suggests that the authors should compare their approach to these related works. However, the comment could be more verifiable by providing a brief summary of the key aspects of these related works that are relevant to the authors\" approach. Overall, the claim is 4, as it is supported by references but lacks some depth in explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the work, suggesting that learning both low and highfrequency information in balance is not a novel concept. It provides a list of related works that the authors should analyze and compare their approach to, which could help them position their work more effectively within the existing literature. However, the comment lacks specific guidance on how to conduct this analysis or comparison, and it does not offer actionable suggestions on how to address the identified issue. While it highlights an important area for improvement, the feedback is 3 as it directs the authors to relevant literature but does not provide detailed guidance on how to integrate this information into their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the compression bandwidth of PC+IDF compared to IDF should be considered. However, it does not provide any specific guidance or action on how the authors should address this recommendation. The authors are left without a clear understanding of what changes or improvements are needed to incorporate this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the compression bandwidth of PC+IDF compared to IDF should be considered in Section 5. However, it does not specify which part of Section 5 this refers to, making it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the content it addresses, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the compression bandwidth of PC+IDF compared to IDF should be considered in Section 5. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the recommendation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the compression bandwidth of PC+IDF compared to IDF should be considered in Section 5. However, it lacks specific guidance or detailed reasoning on why this comparison is important or how it might impact the results. The comment is vague and does not provide actionable advice or suggestions for improvement, leaving the authors with limited insight into how to address the feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the model names T5ind and T5seq are misleading and proposes alternative names such as Descind/seq, Egind/Demoind/seq. While the comment provides a suggestion for improvement, it does not explicitly instruct the authors to change the model names or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adopting the suggested names. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the model names T5ind and T5seq are misleading and proposes alternative names. However, it does not specify which part of the paper these model names are used, making it difficult for the authors to identify the exact context. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model names T5ind and T5seq are misleading and proposes alternative names. However, it does not provide any reasoning, examples, or references to support why these names are misleading or why the proposed alternatives are better. Without additional context or justification, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the naming of model names in the paper, specifically suggesting that T5ind and T5seq are misleading and proposing alternative names such as Descind/seq, Egind/Demoind/seq. While the comment points out a potential area for improvement in clarity and consistency, it does not provide specific guidance or suggestions on how to address the issue or what changes might be necessary. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful to the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and points out that the acronym is used again in line 055. While the comment highlights a potential inconsistency, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the acronym\"s usage or consider a different acronym. The action is implicit and somewhat vague, as it does not specify how to resolve the issue or what changes should be made. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and points out that it is used again in line 055. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact location. The comment is weakly grounded as it does not provide clear guidance on what needs to be addressed. It is also specific in that it highlights a potential inconsistency in the use of the acronym. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and points out that it is used again in line 055. This is a factual observation about the paper\"s content, and the comment does not contain any subjective opinions or suggestions. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and points out that the acronym is used again in line 055. While this observation highlights a potential inconsistency in the paper\"s writing, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how the authors might address this issue or what changes could be made to enhance the clarity of their work. As a result, the comment is 2, as it does not contribute significantly to the authors\" understanding or improvement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of clarity in the motivation of the gating design for multitask learning (MTL) and the claim that the gating mechanism is not a new story in MTL. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to clarify the motivation or how to demonstrate the novelty of the gating mechanism. Without specific suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of taskspecific features to taskshared features. However, it does not specify which part of the paper this idea is discussed in, making it weakly grounded. The comment also mentions the motivation of the gating design for MTL and claims that the gating mechanism is not a new story in MTL, but it does not provide specific details or examples to support this claim, making it specific. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the gating mechanism is not a new story in multitask learning (MTL). However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors cannot verify the claim, making it difficult to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of clarity in the motivation of the gating design for multitask learning (MTL) and the claim that the gating mechanism is not a new story in MTL. While the comment points out these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights areas that need clarification, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the practical scenarios where learning to defer is preferable and details how it is expected to behave. It also points out that the practicability of this approach is impaired due to strong assumptions, such as the availability of ground truth and the DMs\" decisions for each DM of interest. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to mitigate the impact of these assumptions or how to improve the model\"s behavior. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of learning to defer being impractical due to strong assumptions, such as the availability of ground truth and the DMs\" decisions for each DM of interest. However, it does not specify which part of the paper discusses these assumptions or how they impact the model. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while it mentions the impracticality of the approach, it does not provide specific guidance on how to address this issue or improve the model. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the practicability of learning to defer is impaired due to strong assumptions, such as the availability of ground truth and the DMs\" decisions for each DM of interest. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the practicality of learning to defer, specifically highlighting the strong assumptions required for its effectiveness. It points out that the availability of ground truth and the DMs\" decisions for each DM of interest are crucial for the model\"s behavior, which can impair its practicability. This feedback is valuable as it directs the authors to reconsider the assumptions and potentially explore alternative approaches or modifications to enhance the model\"s applicability. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these limitations. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the experimental part, noting that the LR and SVM baselines are too weak compared to deep learning approaches. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve their experimental setup or baselines. As a result, the authors are left without a clear path to enhance their draft, making the comment 1.", "grounding_specificity_rationale": "The comment expresses concern about the experimental part of the paper, specifically mentioning the weakness of the LR and SVM baselines compared to deep learning approaches. However, it does not specify which part of the paper this concern pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the baselines, the absence of grounding information limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental part is less convincing because the LR and SVM baselines are too weak compared to deep learning approaches. However, the comment lacks specific evidence or examples to support this claim. Without detailed reasoning or references to specific studies, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental part of the paper, specifically noting that the LR and SVM baselines are too weak compared to deep learning approaches. This feedback is 3 as it highlights an area for improvement, but it lacks depth and specificity. The authors are left with a general idea of what needs to be addressed but without detailed guidance on how to enhance their experimental setup or baselines. To be more helpful, the comment could provide suggestions on alternative baselines or methods for comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that while the motivation of the GLASU algorithm is to save communication, neither the theorem nor the experiment discuss the communication cost. This feedback points out a specific area where the paper lacks detail and impact. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting where to include the discussion of communication cost or how to demonstrate its significance. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion of communication cost to the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation of the GLASU algorithm\" and the \"theorem and experiment\" that do not discuss the communication cost. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of discussion on communication cost, which undermines the contribution of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion of the communication cost, which undermines the contribution. However, the comment does not provide specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that while the motivation of the GLASU algorithm is to save communication, the paper does not discuss the communication cost. This omission undermines the contribution of the paper, as it fails to provide a clear understanding of the algorithm\"s efficiency. The comment is clear and actionable, as it highlights a specific area where the paper lacks detail and suggests that the authors should include a discussion of the communication cost to strengthen their contribution. However, it could be more helpful if it provided guidance on how to include this discussion or examples of where to discuss it. Overall, the comment is 4, as it effectively identifies a critical issue that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the contributions of the paper should be explicitly stated. This is a clear and explicit action that the authors can take to improve their draft. By explicitly stating the contributions, the authors can provide a clearer understanding of the paper\"s significance and impact. The comment is specific in its suggestion, guiding the authors on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the contributions of the paper should be explicitly stated. However, it does not specify which part of the paper this refers to, such as the introduction, conclusion, or a specific section. This lack of grounding makes it difficult for the authors to understand where to make the changes. While the comment is specific in its suggestion, the absence of grounding limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the contributions of the paper should be explicitly stated. This is a subjective opinion or a suggestion for improvement, as it does not provide a specific claim or critique that requires verification. The comment is not verifiable because it does not offer any evidence or reasoning to support the suggestion. Therefore, it is classified as \"No\"", "helpfulness_rationale": "The review comment suggests that the contributions of the paper should be explicitly stated. This is a clear and actionable piece of feedback that provides the authors with a specific direction for improvement. By highlighting the importance of clearly articulating the contributions, the comment helps the authors enhance the clarity and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to effectively communicate the contributions or examples of how to do so. Overall, the comment is 3 as it identifies a crucial aspect of the paper that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the motivation of the work and suggests that the explanation of \"different densities directly causing semantic conflicts\" needs to be supported experimentally or theoretically. While the comment identifies a specific area that requires clarification and provides a direction for improvement, it does not explicitly instruct the authors on how to conduct the experimental or theoretical justification. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work and the explanation of \"different densities directly causing semantic conflicts,\" suggesting that this explanation needs to be supported experimentally or theoretically. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to justify the explanation, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work is not clear and the explanation is not convincing, specifically mentioning the need for experimental or theoretical justification for the statement \"different densities directly will cause semantic conflicts.\" However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and depth of the motivation and explanation in the paper. It points out that the authors mention \"different densities directly will cause semantic conflicts\" but do not provide sufficient justification, either experimental or theoretical. This feedback is valuable as it highlights a critical gap in the paper\"s argumentation and suggests a clear direction for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct the necessary experiments or theoretical analysis. Overall, the comment is 3 as it directs the authors to areas that need strengthening, but it lacks the depth of detail required for comprehensive improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks whether the three transformer modules are trained iteratively or endtoend, and second, it critiques the similarity between Figure 5 and Figure 1, suggesting that the visualization might not be necessary if no new points are demonstrated. While the first question is explicit and requires the authors to clarify the training method, the second part is more implicit and lacks specific guidance on how to address the issue of similarity in the figures. The authors are left to infer that they need to either remove the redundant visualization or provide a clear explanation of the new points demonstrated in Figure 5. This makes the comment 4, as it provides some direction but could be more explicit and detailed. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"three transformer modules\" and \"Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the similarity between Figure 5 and Figure 1, suggesting that the visualization might not be necessary if no new points are demonstrated. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises two questions: whether the three transformer modules are trained iteratively or endtoend and critiques the similarity between Figure 5 and Figure 1. The first question is a direct inquiry that requires the authors to clarify their methodology. The second part critiques the figures, suggesting that the visualization might not be necessary if no new points are demonstrated. However, the comment lacks specific examples or references to support the claim about the similarity between the figures, making it 3. The authors are left to infer the need for clarification or removal of the redundant visualization, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two key points that could help the authors improve their draft. First, it questions the training method of the three transformer modules, asking whether they are trained iteratively or endtoend. This is a relevant question that could guide the authors in clarifying their methodology and ensuring consistency in their approach. Second, the comment critiques the similarity between Figure 5 and Figure 1, suggesting that the visualization might not be necessary if no new points are demonstrated. This feedback is valuable as it prompts the authors to consider the necessity of including redundant visualizations and to provide a clear explanation of any new points demonstrated in Figure 5. While the comment is 3 due to its identification of areas for clarification and improvement, it could be more comprehensive if it provided specific guidance on how to address the issue of similarity in the figures. Overall, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing could benefit from greater precision and clarity, and provides specific examples of areas for improvement, such as clarifying the distinction between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also notes that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs, and suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. However, the comment does not provide explicit guidance on how the authors should address these points or what specific changes to make. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the areas where the writing could benefit from greater precision and clarity, providing specific examples such as the distinction between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also highlights the relationship between the proposed method and infoDiffusion, suggesting that the authors should explicitly outline the unique contributions of ParamReL. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the writing would benefit from greater precision and clarity, providing specific examples of areas for improvement, such as clarifying the distinction between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also notes that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs, and suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors are left to infer the need for clarification and the specific areas where the writing could be improved, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies areas where the writing could be improved for greater precision and clarity, providing specific examples such as the distinction between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also highlights the relationship between the proposed method and infoDiffusion, suggesting that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. This feedback is 4 as it provides clear guidance on how the authors can enhance the clarity and precision of their writing, but it could be more comprehensive if it included specific suggestions or examples of how to address the identified issues. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the clarity of the paper, specifically regarding the focus on a situation where the gradient of the sum is not the sum of the individual gradients. It suggests that this concept is not well communicated in the text, particularly in the paragraph from lines 7074. The comment implies that this paragraph is shared across all ERM approaches and could be discussed in less space. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the clarity of the paper. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion in lines 6074, which corresponds to the beginning of Section 2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the authors are concerned about the lack of communication regarding a situation where the gradient of the sum is not the sum of the individual gradients, and it suggests that the paragraph in lines 7074, which is shared across all ERM approaches, could be discussed in less space. It also highlights the rarity of the situation where the gradient of the sum of the losses is not the sum of the individual loss gradients, suggesting that it might require more space. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the clarity of the paper, specifically regarding the focus on a situation where the gradient of the sum is not the sum of the individual gradients. It suggests that this concept is not well communicated in the text, particularly in the paragraph from lines 7074, which is shared across all ERM approaches. The comment implies that this situation is rare and might require more space. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion. The comment provides a general observation but does not offer detailed evidence or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the paper, specifically regarding the focus on a situation where the gradient of the sum is not the sum of the individual gradients. It suggests that this concept is not well communicated in the text, particularly in the paragraph from lines 7074, which is shared across all ERM approaches. The comment implies that this situation is rare and might require more space. However, the feedback lacks specific guidance on how the authors could address this issue or what changes might be necessary to improve the clarity of the paper. While it points out an area for improvement, it does not provide actionable suggestions or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the proposed questionrewrite strategy, noting that a significant number of questions become invalid due to unresolved coreference. It highlights that the method rewrites only a small percentage of questions, questioning its effectiveness. However, the comment does not provide explicit or implicit suggestions on how to address this issue or improve the strategy. The authors are left without guidance on how to enhance the method or what specific changes could be made to increase the coverage of questions. As a result, the comment lacks actionable feedback, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed questionrewrite strategy\" and provides specific data on the percentage of invalid questions and the number of questions rewritten for each model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the proposed method, providing quantitative data to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed questionrewrite strategy, specifically questioning whether it covers a sufficiently large number of questions. It provides data on the percentage of invalid questions and the number of questions rewritten for each model, suggesting that the method\"s effectiveness is questionable. However, the comment lacks detailed reasoning or references to support the claim that the method is insufficient. While the data provided offers some context, it does not fully substantiate the concern, leaving the authors with a general understanding but without a clear basis for addressing the issue. Therefore, the comment is rated as 2, as it provides some evidence but lacks depth and clarity.", "helpfulness_rationale": "The review comment raises a concern about the proposed questionrewrite strategy, specifically questioning its effectiveness in covering a sufficient number of questions. It provides data on the percentage of invalid questions and the number of questions rewritten for each model, suggesting that the method\"s impact is limited. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the strategy. While it identifies a potential weakness, it does not offer any concrete steps or insights for the authors to enhance their work. Therefore, the comment is 3, as it highlights an area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the use of L2 distance in equation (4) within the context of Optimal Transport (OT), suggesting that the more common earth mover\"s distance (EMD) might be more appropriate. However, it does not provide explicit guidance on how the authors should address this issue or what benefits L2 distance might offer. The comment implies that the authors should consider using EMD instead, but it lacks concrete suggestions or detailed reasoning on why L2 distance is still relevant. As a result, the authors are left without clear instructions on how to improve their draft, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (4)\" and \"Optimal Transport (OT),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in this context and suggests that Earth Mover\"s Distance (EMD) might be more common, prompting the authors to consider the benefits of L2 distance. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of L2 distance in equation (4) within the context of Optimal Transport (OT), suggesting that Earth Mover\"s Distance (EMD) is more common. However, it does not provide any justification or reasoning for why L2 distance is still relevant or beneficial in this context. Without additional explanation or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the use of L2 distance in equation (4) within the context of Optimal Transport (OT), suggesting that Earth Mover\"s Distance (EMD) is more common. However, it does not provide any explanation or reasoning for why L2 distance might still be relevant or beneficial in this context. The comment lacks actionable guidance on how the authors might address this issue or what benefits L2 distance might offer. While it points out a potential area for improvement, it does not offer detailed suggestions or insights that would help the authors enhance their work. Therefore, the comment is 3, as it highlights a specific area for consideration but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of the related work is scattered throughout the paper, with some relevant papers mentioned. However, it does not provide explicit guidance on how to improve the organization or presentation of the related work section. The comment implies that a broader discussion comparing the algorithm to other offline RL algorithms would be beneficial, but it does not specify which parts of the paper need to be revised or how to achieve this broader discussion. As a result, the authors are left without clear instructions on how to address the feedback, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the description of the related work is scattered throughout the paper, noting that some relevant papers are mentioned. However, it does not specify which parts of the paper contain this scattered information or which sections need to be addressed. The comment implies that a broader discussion comparing the algorithm to other offline RL algorithms would be beneficial, but it does not provide specific guidance on how to achieve this. Therefore, the comment is 1 as the authors cannot confidently identify the specific part of the paper being addressed, and it is also not specific as it lacks detailed guidance on what needs to be improved. This aligns with a score of 1 and Not Specific.", "verifiability_rationale": "The review point suggests that the description of the related work is scattered throughout the paper, with some relevant papers mentioned. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks a clear justification for why the related work is scattered or how it impacts the paper\"s overall coherence. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the organization of the related work section, noting that the description is scattered throughout the paper. It suggests that a broader discussion comparing the algorithm to other offline RL algorithms would be beneficial. However, the comment lacks specific guidance on how to improve the organization or presentation of the related work section, or which parts of the paper need to be revised. While it points out a potential area for improvement, it does not provide actionable steps or detailed suggestions for the authors to follow. Therefore, the comment is 3, as it highlights an area for enhancement but does not offer comprehensive guidance. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about how the final solution would change if all increments were available at the same time. While it prompts the authors to consider this scenario, it does not provide explicit instructions or suggestions on how to address this question or what changes might occur. The action is implicit, as the authors need to infer that they should explore the impact of simultaneous increments on the solution. However, the comment lacks concrete guidance on how to implement this exploration, making it 3.", "grounding_specificity_rationale": "The comment raises a question about how the final solution would change if all increments were available at the same time. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the specific part of the paper being addressed. While the question is specific in its inquiry, the lack of grounding makes it difficult for the authors to fully understand the scope of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point poses a question about how the final solution would change if all increments were available at the same time. This is a question that requires the authors to consider and analyze the impact of simultaneous increments on their solution. However, the comment does not provide any specific reasoning, examples, or references to support the question or its implications. As a result, the authors are left to interpret the question and potentially explore it on their own, making the comment 1.", "helpfulness_rationale": "The review comment raises a question about how the final solution would change if all increments were available at the same time. This is a relevant and insightful question that prompts the authors to consider the impact of simultaneous increments on their solution. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this question or what changes might occur. While it identifies an area for further exploration, it does not offer actionable advice or detailed insights, making it 3. The authors would need to infer the need for further analysis and exploration on their own, which limits the comment\"s overall impact."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the convoluted and potentially circular nature of the technique used in the paper, specifically mentioning the use of multiple feature spaces. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their approach. The comment lacks concrete guidance on what changes could be made to make the technique more streamlined or less circular. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the technique of using multiple different feature spaces, referencing specific feature spaces like the 25 feature space of Mitchell et. al and the full/pruned glove model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly identifies the issue with the technique, describing it as convoluted and potentially circular. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the convoluted nature of the technique used in the paper, specifically mentioning the use of multiple feature spaces. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the technique used in the paper, specifically the convoluted nature of using multiple feature spaces. While it highlights a concern about the technique being convoluted and potentially circular, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to enhance their work. Therefore, the comment is 2, as it points out a problem but does not offer constructive advice or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Table 7 should include comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and provide details on their FLOPs and parameter sizes. It also questions why the results of OFA with progressive shrink are not included in the table. While the comment provides explicit guidance on what comparisons should be made and why certain results are missing, it does not offer specific instructions on how to implement these suggestions, such as which additional works to include or how to present the data. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and their FLOPs and parameter sizes. Additionally, it questions why the results of OFA with progressive shrink are not included in the table, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 7 should include comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and provide details on their FLOPs and parameter sizes. It also questions why the results of OFA with progressive shrink are not included in the table. This comment is 3 as it provides a clear rationale for the suggested improvements, but it lacks specific examples or references to support the claim that these comparisons are necessary or beneficial. The authors would need to infer the importance of these comparisons and the relevance of the missing results, which could make the comment somewhat challenging to fully understand and implement. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by requesting additional comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and including their FLOPs and parameter sizes. It also questions the absence of results for OFA with progressive shrink in the table, which could help the authors understand the comprehensiveness of their comparisons. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these comparisons or why these additional comparisons are necessary. Overall, the feedback is 3 as it offers actionable suggestions but lacks depth and specificity, leaving the authors with a clear direction for improvement but not a fully comprehensive guide."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be beneficial to include a brief discussion of why hallucinations are undesirable, in addition to pointing to existing work. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by adding a section or paragraph explaining the importance of fixing hallucinations. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a brief discussion of why hallucinations are undesirable, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include a discussion on the undesirability of hallucinations, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it might be useful to include a brief discussion of why hallucinations are undesirable, in addition to pointing to existing work. However, the comment lacks specific reasoning or examples to support why this is a useful suggestion. It does not provide any references or detailed explanations to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include a brief discussion of why hallucinations are undesirable, in addition to pointing to existing work. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors elaborate on the importance of addressing hallucinations. By including this discussion, the authors can enhance the depth and clarity of their paper, making it more informative and impactful. The comment is 4 as it offers a clear direction for improvement, though it could be further expanded to provide more detailed guidance. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the clarity of the introduction, specifically noting that terms like Type1 error, Type2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This feedback is explicit and provides a clear action for the authors to take: they should ensure that the null hypothesis is introduced before these terms are discussed. The comment is specific and concrete, as it directly points out where the issue lies and how it should be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 5054 of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly points out that terms like Type1 error, Type2 error, and false positive rate are mentioned before the null hypothesis is stated, which is a specific issue that needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue in the introduction of the paper, noting that terms like Type1 error, Type2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This feedback is clear and specific, providing a direct observation of a potential issue in the paper\"s structure and clarity. However, it does not offer any additional reasoning or references to support why this is a problem or how it might affect the paper\"s overall understanding. While the comment is 3 due to its specificity, it lacks depth in terms of providing guidance or context. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction of the paper, noting that terms like Type1 error, Type2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This feedback is clear and actionable, as it provides a direct observation of a potential problem that could affect the clarity and understanding of the paper. By highlighting this issue, the comment guides the authors to reorganize the introduction to ensure that the null hypothesis is introduced before these terms are discussed. This feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it suggested specific ways to rephrase or integrate these terms. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the uncertainty inherent in estimating a continuous importance weight function, which could affect the model\"s reliability. It poses a question about how this issue can be addressed. While the comment identifies a potential problem and asks for a solution, it does not provide explicit guidance on how to solve it. The action is implicit, as the authors would need to infer that they need to address the uncertainty and propose a solution. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the uncertainty inherent in estimating a continuous importance weight function, which could affect the model\"s reliability. It poses a question about how this issue can be addressed. However, the comment does not specify which part of the paper discusses the estimation of the importance weight function or where the uncertainty is mentioned. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the uncertainty inherent in estimating a continuous importance weight function, which could affect the model\"s reliability. However, it does not provide any specific evidence, reasoning, or references to support the claim that this uncertainty is a significant issue. The comment lacks detailed explanation or examples to substantiate the concern, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the estimation of a continuous importance weight function, noting that it may introduce uncertainty affecting the model\"s reliability. It poses a question about how this issue can be addressed, which is a relevant and actionable feedback for the authors. However, the comment lacks specific suggestions or guidance on how to solve the problem, making it 3. The authors would need to infer that they need to address the uncertainty and propose a solution, but the feedback is incomplete without detailed guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the SFAM scorers used in the LISA embedding, noting that they correlate well with human judgments on semanticsrelevant styles but not on linguisticsrelevant styles. The comment suggests that this might indicate a contentfocused rather than stylefocused approach. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further investigation or modification of the SFAM scorers. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the correlation of SFAM scorers with human judgments on different linguistic styles, such as semanticsrelevant (e.g., sentiment, emotion) and linguisticsrelevant (e.g., simplification, linguistic acceptability). It highlights a potential issue with the LISA embedding, suggesting that the scorers might be more contentfocused than stylefocused. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The specificity of the comment is good as it clearly identifies the problem and suggests a potential reason for it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on linguisticsrelevant styles. The comment provides an example of linguisticsrelevant styles, such as simplification and linguistic acceptability, to support this claim. However, it lacks specific references or detailed reasoning to substantiate the claim fully. The absence of concrete evidence or examples makes it 3, as the authors may need to seek additional information or reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the SFAM scorers used in the LISA embedding, noting that they correlate well with human judgments on semanticsrelevant styles but not on linguisticsrelevant styles. This observation suggests that the LISA embedding might be more contentfocused than stylefocused. While the comment highlights a specific area for improvement, it does not provide detailed guidance or suggestions on how the authors might address this issue or what changes could be made to enhance the embedding\"s style focus. The feedback is 3 as it points out a potential area for further investigation, but it lacks actionable steps or specific recommendations for improvement, leaving the authors with limited direction for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be evaluated on additional realworld datasets, such as DexYCB, using more recent handobject pose estimation pipelines. While the comment provides a clear direction for improvement, it does not specify which datasets or pose estimation pipelines should be used, nor does it offer any guidance on how to implement these suggestions. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests evaluating the experiments on additional realworld datasets like DexYCB using more recent handobject pose estimation pipelines. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more datasets and pipelines, but without clear references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the experiments on additional realworld datasets like DexYCB with more recent handobject pose estimation pipelines. However, it does not provide any specific reasoning, examples, or references to support why these datasets or pipelines would be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests evaluating the experiments on additional realworld datasets, such as DexYCB, using more recent handobject pose estimation pipelines. This feedback is 3 as it provides a direction for improving the experimental evaluation, which could enhance the paper\"s comprehensiveness and relevance. However, the comment lacks specificity regarding which datasets or pipelines should be used, and it does not offer detailed guidance on how to implement these suggestions. As a result, the authors may find it challenging to fully address the feedback, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explicit explanation regarding the design of sequential models and the update mechanism of the attention model, which are crucial for understanding the rationale of the proposed work. While the comment identifies a gap in the explanation, it does not provide specific guidance on how the authors should address this issue. The authors are left with the implicit action of expanding the explanation, but without concrete details on what needs to be added or how to do so. Therefore, the comment is 3, as it points out a specific area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment identifies a lack of explicit explanation regarding important components of the paper, specifically the design of sequential models and the update mechanism of the attention model. However, it does not specify which part of the paper these components are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that require improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks explicit explanation on important components, such as the design of sequential models and the update mechanism of the attention model. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of explicit explanation regarding the design of sequential models and the update mechanism of the attention model. This is a critical oversight that could hinder the reader\"s understanding of the proposed work. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors to areas that need clarification, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that making the entire code accessible would be helpful if the paper is accepted. This is a clear and explicit action that the authors can readily follow. By making the code accessible, the authors can provide additional context and support for their claims, enhancing the reproducibility of their work. The comment is specific in its suggestion and provides a concrete action for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the entire code should be made accessible, which is a practical and helpful suggestion for improving the reproducibility of the research. However, it does not specify which part of the paper or section the code is associated with, making it weakly grounded. The comment is specific in its suggestion to enhance reproducibility, but the lack of grounding makes it difficult for the authors to pinpoint exactly where the code is mentioned or relevant. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the entire code should be made accessible to enhance the reproducibility of the research. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would impact the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that making the entire code accessible would be helpful if the paper is accepted. This is a practical and actionable suggestion that could enhance the reproducibility and transparency of the research. By providing access to the code, the authors would allow other researchers to verify their findings and potentially build upon their work. However, the comment lacks specific guidance on how to make the code accessible or what platforms to use, which could limit its helpfulness. Overall, the comment is 3 as it identifies a valuable improvement but does not provide detailed instructions for implementation. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the explanations of specific processes, such as spikedriven token selection and intra and interstage feature fusion, could be clearer. It also recommends including pseudocode or flow diagrams to enhance the reader\u2019s understanding of the model\u2019s operation. While the comment provides explicit guidance on what needs to be improved, it lacks concrete details on how to achieve this clarity. The authors are informed about the areas that require clarification and the methods to improve understanding, but they are not given specific instructions on how to implement these suggestions, such as which sections to revise or how to create the pseudocode. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"hybrid architecture\" and the specific processes, such as \"spikedriven token selection\" and \"intra and interstage feature fusion,\" which allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as including pseudocode or flow diagrams to enhance the reader\u2019s understanding of the model\u2019s operation. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations of specific processes, such as spikedriven token selection and intra and interstage feature fusion, could be clearer. It suggests that including pseudocode or flow diagrams might enhance the reader\u2019s understanding of the model\u2019s operation. However, the comment lacks specific examples or references to support the claim that these processes are unclear or difficult to understand. Without detailed reasoning or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the explanations of specific processes, such as spikedriven token selection and intra and interstage feature fusion, could be clearer. It suggests that including pseudocode or flow diagrams could enhance the reader\u2019s understanding of the model\u2019s operation. This feedback is actionable and provides a clear direction for the authors to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to create or integrate these visual aids effectively. Overall, the comment is 4 as it highlights a significant area for improvement and provides a basis for action, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment provides feedback on the proposed method, noting that it is an incremental improvement over AutoAugment and that the performance improvements are not significant when compared to recent methods. It also highlights concerns about the large standard deviation, which raises doubts about the method\"s generalizability. However, the comment does not offer specific suggestions or actions for the authors to take to address these issues. The feedback is somewhat vague and lacks concrete guidance on how the authors might improve their method or address the concerns about performance and generalizability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, noting that it is an incremental improvement over AutoAugment. It also mentions that the performance improvements are not significant when compared to recent methods, specifically citing a 0.3 improvement on ImageNet with ResNet50 over [18]. The comment highlights concerns about the large standard deviation, which raises doubts about the method\"s generalizability. However, the comment does not specify which part of the paper discusses the performance improvements or the comparison with recent methods, making it weakly grounded. It is specific in detailing the issues with performance and generalizability, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is an incremental improvement over AutoAugment and that the performance improvements are not significant when compared to recent methods. It provides a specific example of a 0.3 improvement on ImageNet with ResNet50 over [18]. However, the claim lacks detailed reasoning or references to support the assertion about the significance of the performance improvements. The comment also mentions a large standard deviation, which raises doubts about generalizability, but does not provide specific evidence or examples to substantiate this claim. Therefore, the comment is 3, as it provides some evidence but lacks depth and clarity in supporting the claims.", "helpfulness_rationale": "The review comment provides feedback on the proposed method, noting that it is an incremental improvement over AutoAugment and that the performance improvements are not significant when compared to recent methods. It highlights concerns about the large standard deviation, which raises doubts about the method\"s generalizability. However, the comment lacks specific suggestions or actionable advice on how the authors might address these issues or improve their method. While it identifies areas for improvement, it does not offer detailed guidance or concrete steps for the authors to take, making it 3. The feedback is valuable but could be more impactful with additional suggestions or constructive advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the comparison made in the paper, noting that it lacks references to existing prior arts and that a simple search reveals significant performance gaps between the proposed method and the latest methods. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific references or conducting additional experiments. The action is implicit and vague, as it does not specify how the authors should incorporate these references or address the performance gaps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison made in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it highlights the lack of references to existing prior arts and points out significant performance gaps between the proposed method and the latest methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison is weak without references to existing prior arts, such as [1], and that a simple search reveals significant performance gaps between the proposed method and the latest methods. However, the comment lacks specific examples or detailed reasoning to support the claim. It does not provide references or detailed explanations of why the comparison is weak or how the performance gaps are significant. This makes the claim 3, as it is based on a general observation but lacks sufficient evidence or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of references to existing prior arts and the absence of a thorough comparison with the latest methods. It highlights that a simple search reveals significant performance gaps between the proposed method and the latest methods, which suggests that the comparison is weak. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting additional references or conducting more comprehensive experiments. While it raises an important point about the need for a more robust comparison, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear indication of a weakness but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should quantify the diversity of the data gathered, even if it is a shallow types vs. token statistic. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, detailing the type of quantification that would be useful. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should quantify the diversity of the data gathered, even if it is a shallow types vs. token statistic. However, it does not specify which part of the paper discusses the data diversity or where the quantification should be applied. This makes the comment weakly grounded, as the authors cannot confidently determine which section or part of the paper needs revision. While the comment is specific in its suggestion to quantify diversity, the lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should quantify the diversity of the data gathered, even if it is a shallow types vs. token statistic. This claim is 3 as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors could benefit from additional context or examples to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors quantify the diversity of the data gathered, even if it is a shallow types vs. token statistic. This feedback is actionable and provides a clear direction for the authors to enhance their draft. By quantifying the diversity, the authors can provide a more robust and comprehensive analysis of their data, which would strengthen the paper. However, the comment could be more helpful if it included specific examples or guidance on how to perform the quantification. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point claims that the paper created a more diverse set of positive instance pairs but does not provide any explicit or implicit actions for the authors to take. It highlights the lack of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. However, the comment does not offer any guidance on how the authors might address this issue or what steps they should take to improve the diversity of their instance pairs. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the paper creating a more diverse set of positive instance pairs, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the claim, noting the lack of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. This provides the authors with a clear understanding of what needs to be addressed to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. This feedback is clear and actionable, as it points out a gap in the paper\"s claims and suggests areas for improvement. However, the comment could be more helpful if it provided some guidance on how the authors might measure diversity or compare their examples with those in previous works. Despite this, the comment is 4 as it directs the authors to areas that need attention and improvement, providing a solid foundation for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the authors\" approach compares to or aligns with other inputs, specifically mentioning structured information and the AUCROC metric. While it prompts the authors to consider this comparison, it does not provide explicit guidance on what specific aspects of their approach should be compared or how to conduct this comparison. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the authors\" approach compares to or aligns with other inputs, specifically mentioning structured information and the AUCROC metric. However, it does not specify which part of the paper this comparison should be made or which sections of the literature should be referenced. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its request for comparison but lacks detailed guidance on how to conduct this comparison or what aspects of the approach should be considered. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the authors\" approach with other inputs, specifically mentioning structured information and the AUCROC metric. It notes that the AUCROC seems high in other models in literature, which implies a need for comparison. However, the comment lacks specific details or references to support the claim that the AUCROC is unusually high or how it aligns with other inputs. Without further elaboration or evidence, the claim remains 3, as it lacks sufficient justification for the authors to understand the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about how the authors\" approach compares to or aligns with other inputs, specifically mentioning structured information and the AUCROC metric. It notes that the AUCROC seems high in other models in literature, which suggests a need for comparison. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the approach should be considered. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. As a result, the comment is 3, as it highlights a relevant concern but does not offer comprehensive guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests several actions that could improve the paper. First, it recommends explicitly stating the objective function in the experiments, including Monte Carlo estimates of the expectations. This provides a clear and actionable suggestion for the authors to enhance the clarity and reproducibility of their work. Second, the comment questions the inclusion of a reverse inequality sign in Equation 7, based on the definition of v as the expected loss. This is a specific and actionable suggestion that could help the authors clarify their mathematical formulation. Third, the comment points out that some parts of Section 3, particularly Section 3.2, are technical and do not effectively explain the main method in Section 4. This suggests that the authors should consider providing more space or explanation in Section 4 to make the method more accessible to the audience. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"Section 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as explicitly stating the objective function, questioning the inclusion of a reverse inequality sign in Equation 7, and recommending additional explanation in Section 4. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the clarity and technical aspects of the paper. It questions the inclusion of a reverse inequality sign in Equation 7, based on the definition of v as the expected loss, and suggests that some parts of Section 3, particularly Section 3.2, are too technical and do not effectively explain the main method in Section 4. These points are based on logical reasoning and common knowledge, as they relate to the clarity and consistency of the mathematical formulation and the presentation of the method. However, the comment lacks specific examples or references to support these claims, which could make it 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends explicitly stating the objective function in the experiments, including Monte Carlo estimates of the expectations, which would enhance the clarity and reproducibility of the work. Additionally, it questions the inclusion of a reverse inequality sign in Equation 7, based on the definition of v as the expected loss, offering a specific point for clarification. The comment also suggests that some parts of Section 3, particularly Section 3.2, are too technical and could be better explained in Section 4, which could improve the accessibility of the method to the audience. These suggestions are clear and provide valuable guidance for the authors, making the comment 4. However, the comment could be more comprehensive if it included additional suggestions or examples to further enhance the paper."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions why the Disc. reward for SPACE and fPCPO decreases in Grid (Fig. 3, top right plot) and suggests that this should be explained. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to explain the decrease in the reward. However, the comment lacks specific guidance on how to address this issue or what aspects of the results might be contributing to the decrease. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment questions why the Disc. reward for SPACE and fPCPO decreases in Grid (Fig. 3, top right plot) and suggests that this should be explained. However, it does not specify which part of the paper this observation is made or which section of the figure is being referenced. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment implies that the authors should explain the decrease, it does not provide specific guidance on what aspects of the results might be contributing to this observation. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions why the Disc. reward for SPACE and fPCPO decreases in Grid (Fig. 3, top right plot) and suggests that this should be explained. However, the comment does not provide any specific reasoning, examples, or references to support why this observation is significant or how it should be addressed. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the decrease in the Disc. reward for SPACE and fPCPO in Grid (Fig. 3, top right plot) and suggests that this should be explained. While the comment identifies a potential area of confusion or inconsistency in the results, it does not provide any guidance or suggestions on how to address this issue. The authors are left with a question that needs to be clarified, but without any actionable advice on how to resolve it. Therefore, the comment is 2, as it highlights a potential issue but does not offer any constructive feedback or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that key implementation details are missing, particularly regarding the resolutions at which images successfully achieve adversarial effects. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific information they should include. Without concrete suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding missing implementation details, particularly concerning the resolutions at which images achieve adversarial effects. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the missing details, but without clear references, the authors may struggle to locate the relevant section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that key implementation details are missing, specifically mentioning the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that key implementation details are missing, particularly regarding the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it points out a critical gap in the paper that needs to be addressed for the authors to improve their draft. By highlighting this specific detail, the comment provides a clear direction for the authors to enhance the completeness and clarity of their work. However, the comment could be more helpful if it suggested specific ways to include or discuss these details. Overall, the comment is 4, as it effectively guides the authors in addressing a significant aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the current approach of using DDIM Inversion for motion guidance does not significantly simplify the overall complexity and recommends exploring improvements to the motion guidance strategy to enhance training efficiency. While the comment provides a clear direction for improvement, it does not specify how to explore or improve the motion guidance strategy. The authors are left with a general idea of what needs to be done but lack concrete steps or suggestions on how to achieve this. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the section on data preprocessing, specifically mentioning the use of DDIM Inversion for motion guidance. It suggests that while this approach reduces training time, it does not significantly simplify the overall complexity. The reviewer recommends exploring improvements to the motion guidance strategy to enhance training efficiency. However, the comment does not specify which part of the paper discusses data preprocessing or the exact sections that need attention. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in suggesting improvements to the motion guidance strategy, but the lack of explicit grounding makes it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point claims that the approach of using DDIM Inversion for motion guidance does not significantly simplify the overall complexity, suggesting that exploring improvements to the motion guidance strategy could enhance training efficiency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the data preprocessing section. It highlights that while the use of DDIM Inversion for motion guidance effectively reduces training time, it does not significantly simplify the overall complexity. The comment suggests exploring improvements to the motion guidance strategy to enhance training efficiency. This feedback is clear and actionable, providing the authors with a specific direction to consider in their work. However, it could be more helpful if it offered additional suggestions or guidance on how to implement these improvements. Overall, the comment is 4 as it directs the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the statistics of relation phrases and their prediction in sentences, suggesting that chunking might lead to a problem with heavy tails in relations. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to respond. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the statistics of relation phrases and their prediction in sentences, suggesting that chunking might lead to a problem with heavy tails in relations. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is vague and does not provide specific guidance on how to address the issue or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the statistics of relation phrases and their prediction in sentences, suggesting that chunking might lead to a problem with heavy tails in relations. However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed explanations or examples to substantiate the concerns, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the statistics of relation phrases and their prediction in sentences, suggesting that chunking might lead to a problem with heavy tails in relations. This feedback highlights a potential issue with the methodology or data analysis, which could impact the accuracy and reliability of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve their draft. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the robustness of the method in dynamic regions, suggesting that the current approach might not adequately address scenarios where dynamic elements are prevalent. It provides an example from the Bonn dataset, where moving objects occupy a significant portion of the image, and proposes potential solutions, such as using segmentation masks or rerunning relative pose estimation. However, the comment does not explicitly instruct the authors to address this issue or provide detailed guidance on how to implement the suggested solutions. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dynamic regions,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the robustness of the method in these dynamic regions and suggests potential solutions like using segmentation masks or rerunning relative pose estimation. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements\" is generally true but suggests that there are edge cases requiring more robust approaches. The reviewer provides an example from the Bonn dataset, where moving objects occupy over 50% of the image, and proposes potential solutions such as using segmentation masks or rerunning relative pose estimation. However, the comment lacks detailed reasoning or references to support the claim about the limitations of the current approach in dynamic regions. While the suggestion for improvement is clear, the lack of specific examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the robustness of the method in dynamic regions, specifically noting that the current approach might not adequately address scenarios where dynamic elements are prevalent. It provides a clear example from the Bonn dataset, where moving objects occupy over 50% of the image, and suggests potential solutions, such as using segmentation masks or rerunning relative pose estimation. This feedback is actionable and provides specific guidance on how the authors might improve their method\"s robustness in dynamic regions. However, the comment could be more helpful if it included a more detailed explanation of why the current approach is insufficient or how the suggested solutions would address the issue. Overall, the comment is 4, as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they only compare the proposed models with other methods proposed by the authors but lack comparison with other existing methods. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this limitation. The authors are left to infer that they need to include comparisons with other existing methods to strengthen their experimental evaluation. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of comparison with other methods, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments only compare the proposed models with other methods proposed by the authors and lack comparison with other existing methods. This is a factual observation that highlights a gap in the experimental evaluation. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the need for additional comparisons to strengthen their experimental evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental evaluation, noting that the experiments only compare the proposed models with other methods proposed by the authors and lack comparison with other existing methods. This feedback is clear and actionable, as it highlights a critical gap in the experimental design that could impact the validity and comprehensiveness of the results. By pointing out this issue, the comment provides the authors with a clear direction for improvement, encouraging them to include comparisons with other existing methods to strengthen their experimental evaluation. This feedback is 4 as it offers a specific and constructive suggestion for enhancing the paper, though it could be further detailed to provide more guidance on how to conduct these comparisons."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a minor issue regarding the labeling of models in Table 3 and 4, specifically noting that the MAVIS models are not marked with a * despite being considered math specialists. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on whether the authors should correct the labeling or provide a rationale for the absence of the * on the MAVIS models. As a result, the authors are left without a clear action to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details a minor issue regarding the labeling of models, noting that the MAVIS models are not marked with a * despite being considered math specialists. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a minor observation about the labeling of models in Table 3 and 4, noting that the MAVIS models are not marked with a * despite being considered math specialists. While the comment identifies a specific issue, it does not provide any reasoning, examples, or references to support why this observation is important or how it affects the paper. The lack of detailed explanation or justification makes the claim 3, as the authors may need to infer the significance of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue in the labeling of models in Table 3 and 4, specifically noting that the MAVIS models are not marked with a * despite being considered math specialists. While the comment points out this inconsistency, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their presentation. The feedback is specific but lacks actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 3, as it highlights a minor issue but does not offer substantial guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the technical novelty of the paper, noting that KNNbased methods are widely studied in language modeling and machine translation. It suggests that the paper provides few insights into the use of such nonparametric methods for text classification. However, the comment does not offer any specific guidance or suggestions on how the authors might address this limitation or enhance the novelty of their work. The authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the technical novelty of the paper, noting that KNNbased methods are widely studied in language modeling and machine translation. It suggests that the paper provides few insights into the use of such nonparametric methods for text classification. However, the comment does not specify which part of the paper discusses the technical novelty or the use of KNNbased methods. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its critique of the limited novelty, it is 1 because it does not provide clear references or sections for the authors to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical novelty of the paper is limited, as KNNbased methods are widely studied in language modeling and machine translation. The comment suggests that the paper provides few insights into the use of such nonparametric methods for text classification. However, the comment lacks specific examples or references to support the claim that the paper does not offer new insights. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a limitation in the technical novelty of the paper, noting that KNNbased methods are widely studied in language modeling and machine translation. It suggests that the paper provides few insights into the use of such nonparametric methods for text classification. This feedback is 3 as it highlights a specific area where the paper could be improved by offering more novel insights or a deeper exploration of the methods. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. Overall, the comment offers some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential overstatement in the paper regarding the extent of enhancement of the IM for most existing RL algorithms, specifically mentioning that the most recent description of mainstream RL algorithms in related work is SAC in 2018. It suggests that the paper lacks a comparison with the latest work, particularly nonpixelbased approaches to solving data efficiency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific comparisons they should include. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper by mentioning the emphasis on the extensive enhancement of the IM for most existing RL algorithms and highlights a specific issue with the most recent description of mainstream RL algorithms in related work, which is SAC in 2018. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the overstatement and the lack of comparison with the latest work, especially nonpixelbased approaches to solving data efficiency. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper overstates the extent of enhancement of the IM for most existing RL algorithms, specifically mentioning that the most recent description of mainstream RL algorithms in related work is SAC in 2018. It suggests that the paper lacks a comparison with the latest work, especially nonpixelbased approaches to solving data efficiency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the extent of enhancement of the IM for most existing RL algorithms, specifically mentioning that the most recent description of mainstream RL algorithms in related work is SAC in 2018. It suggests that the paper lacks a comparison with the latest work, particularly nonpixelbased approaches to solving data efficiency. This feedback is 3 as it points out a specific area where the paper could be improved by providing a more comprehensive comparison with recent advancements. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors could address this issue, such as including comparisons with recent nonpixelbased approaches. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests expanding the background discussion in Section 2 and related work by including further background knowledge on adversarial examples and different threat models (whitebox, greybox, and blackbox). It also recommends referencing relevant surveys to clarify the threat model and position of the paper, making it more accessible to nonexpert readers. While the comment provides a clear direction for improvement, it lacks specific guidance on which parts of the background discussion need to be expanded or how to integrate the suggested references. The action is explicit but somewhat vague, as it does not specify which sections or aspects of the background discussion require expansion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests expanding the background discussion in Section 2 and related work, specifically mentioning the need for further background knowledge on adversarial examples and different threat models (whitebox, greybox, and blackbox). It also recommends referencing relevant surveys to clarify the threat model and position of the paper, making it more accessible to nonexpert readers. However, the comment does not specify which parts of the paper these expansions should be applied to, leaving the authors to infer the exact sections. The comment is specific in detailing what needs to be addressed, but it is weakly grounded as it does not explicitly mention the sections or parts of the paper that require expansion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests expanding the background discussion in Section 2 and related work with further background knowledge on adversarial examples and different threat models (whitebox, greybox, and blackbox). It also recommends referencing relevant surveys to clarify the threat model and position of the paper, making it more accessible to nonexpert readers. However, the comment lacks specific examples or references to support the claim that the current background discussion is insufficient. Without detailed examples or references, the authors may find it challenging to understand how to implement the suggested improvements. Therefore, the comment is considered 2, as it provides a general direction but lacks the necessary depth and specificity to fully support the claim.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the background discussion in Section 2 and related work by expanding on adversarial examples and different threat models (whitebox, greybox, and blackbox). It also recommends referencing relevant surveys to clarify the threat model and position of the paper, making it more accessible to nonexpert readers. This feedback is clear and actionable, offering concrete guidance on how the authors can enhance the depth and clarity of their background discussion. However, the comment could be more helpful if it provided specific examples of where these expansions should be made or suggested particular surveys that would be beneficial. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the proposed multiplespan answer setting in realworld applications. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify this point or what specific aspects of the paper need to be explained in more detail. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the proposed multiplespan answer setting in realworld applications, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its focus on the clarity of the multiplespan answer setting. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the proposed multiplespan answer setting in realworld applications. However, it does not provide any specific evidence, reasoning, or references to support why this clarity is essential or how it might be addressed. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the proposed multiplespan answer setting in realworld applications, which is a valid concern for the authors. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their paper. Without actionable feedback or detailed examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the authors to mix in train set examples with hypernyms and nonhypernyms, specifically referencing sections 558 and 574. However, it does not provide any explicit or implicit instructions on how the authors should proceed with this suggestion or what specific changes are needed. The comment lacks concrete guidance, leaving the authors uncertain about how to address the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment refers to specific sections of the paper, \"Testsets\" and \"574ff,\" which provides full grounding as the authors can accurately identify the parts being addressed. It also specifies the issue by questioning why the authors did not mix in train set examples with hypernyms and nonhypernyms, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the authors\" decision to not mix train set examples with hypernyms and nonhypernyms, specifically referencing sections 558 and 574. However, it does not provide any justification or reasoning for why this decision was made. The comment lacks supporting evidence or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the authors\" decision to not mix train set examples with hypernyms and nonhypernyms, referencing sections 558 and 574. While it identifies a potential area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue. The comment does not provide any insight into why this decision was made or what impact it might have on the results or analysis. Without specific advice or examples, the authors may find it challenging to understand the implications of this decision and how to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer substantial guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point requests the authors to provide results for the AdpCLR_full approach for the ResNet50 architecture, specifically for the 1x, 2x, and 4x scaling factors, similar to the results provided for AdpCLR_pre in Table 1. This request is explicit and concrete, as it clearly directs the authors to include additional results in their paper. The action is welldefined and provides a clear path for the authors to improve their draft by adding the requested results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment requests the authors to provide results for the AdpCLR_full approach for the ResNet50 architecture, specifically for the 1x, 2x, and 4x scaling factors, similar to the results provided for AdpCLR_pre in Table 1. This request is fully grounded as it explicitly mentions the specific part of the paper where the results are being requested, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what additional results are needed, enhancing the authors\" understanding of the required changes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests the authors to provide additional results for the AdpCLR_full approach for the ResNet50 architecture, specifically for the 1x, 2x, and 4x scaling factors, similar to the results provided for AdpCLR_pre in Table 1. This request is clear and specific, as it directs the authors to include additional data that would enhance the comprehensiveness of their results. However, the comment does not provide any reasoning or justification for why these additional results are necessary or how they would impact the paper. Without further explanation or context, the authors may find it challenging to understand the significance of the request. Therefore, the comment is 3, as it lacks detailed reasoning or references to support the claim.", "helpfulness_rationale": "The review comment requests the authors to provide additional results for the AdpCLR_full approach for the ResNet50 architecture, specifically for the 1x, 2x, and 4x scaling factors, similar to the results provided for AdpCLR_pre in Table 1. This feedback is clear and actionable, as it directs the authors to include additional data that would enhance the comprehensiveness of their results. By providing these results, the authors can strengthen the empirical support for their claims and improve the overall quality of their paper. However, the comment could be more helpful if it included a brief explanation of why these additional results are important or how they might impact the conclusions. Despite this, the feedback is 4 as it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the similarity of N trajectories to the concept of replay in the Dyna model. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the similarity of N trajectories to the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it lacks specific references or context, and it is also not specific because it does not provide detailed guidance on how to address the question. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the similarity of N trajectories to the concept of replay in the Dyna model. However, it does not provide any claim, judgment, or suggestion that requires verification or justification. The comment is purely factual and does not offer any insight or guidance for the authors. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the similarity of N trajectories to the concept of replay in the Dyna model. While it identifies a potential area for clarification or further explanation, it does not provide any actionable feedback or suggestions on how the authors might address this question or incorporate it into their work. The comment lacks depth and specificity, leaving the authors without clear guidance on how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the experiment results, specifically noting that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks concrete guidance on how to verify the results or what steps to take to resolve the discrepancy. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a potential issue with experiment results, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the nature of the problem, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiment results are suspicious, specifically noting that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiment results, specifically noting that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. This observation raises concerns about the consistency and reliability of the experimental findings. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what steps they should take to verify the results. Without specific advice or examples, the authors are left without a clear path forward, making the comment 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the results are still competitive with stateoftheart algorithms. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. The authors are left without guidance on how to improve the significance of their results or what specific aspects of their algorithms need to be enhanced. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions \"experimental results\" but does not provide any specific details about the experiments or the algorithms being compared. The comment is also not specific because it does not detail what aspects of the results are not significant or how the authors might improve them. Therefore, this comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point claims that the experimental results show some advantages of the proposed algorithms, but these advantages are not very significant. It also notes that the results are still competitive with stateoftheart algorithms. However, the comment lacks specific details or examples to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the experimental results show some advantages of the proposed algorithms, but it notes that these advantages are not very significant. It also mentions that the results are still competitive with stateoftheart algorithms. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the significance of the results. While it identifies a potential area for improvement, it lacks actionable advice or detailed feedback, making it 3. The authors may gain some insight into the need for more significant results, but the comment does not offer concrete steps to achieve this. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the persentence assessment protocol, suggesting that it might be prone to LLM overconfidence. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might mitigate this issue or what changes could be made to the protocol. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of a persentence assessment protocol to identify and fix inconsistencies, suggesting that it may be prone to LLM overconfidence. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique of the protocol but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the persentence assessment protocol may be prone to LLM overconfidence, as it prefers predictions even when incorrect. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the claim remains 1, as the authors cannot confidently understand or address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the persentence assessment protocol, specifically noting that it may be prone to LLM overconfidence, as it prefers predictions even when incorrect. This feedback is 3 as it highlights a potential weakness in the methodology used for identifying and fixing inconsistencies. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable advice or detailed examples, the authors may struggle to fully understand and implement the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the source of a promising experimental result, specifically whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. While the question prompts the authors to consider the potential reasons behind the results, it does not provide explicit guidance on how to address this concern or what actions to take. The authors are left to infer that they need to investigate the impact of different kernel functions and feature maps on the results, but the comment lacks concrete steps or suggestions on how to conduct this investigation. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment raises a question about the source of a promising experimental result, specifically whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the issue needs to be addressed. While the comment is specific in its inquiry, the absence of grounding information makes it challenging for the authors to understand the context and relevance of the question. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the source of a promising experimental result, specifically whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. This is a logical question that requires the authors to consider the potential reasons behind the results. However, the comment does not provide any specific evidence, examples, or references to support the claim that the result is due to the method or the kernel function. Without additional context or justification, the claim remains 3, as the authors are left to infer the reasoning behind the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the source of a promising experimental result, specifically whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. This question prompts the authors to consider the potential reasons behind the results and to investigate the impact of different components on the outcome. However, the comment lacks detailed guidance or suggestions on how to address this concern, such as specific experiments or analyses that could be conducted. While it identifies an important area for further exploration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to consider but does not offer comprehensive guidance on how to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s complexity, specifically mentioning the use of modified GromovHausdorff distances and hypergraph structures, which could increase time complexity. It notes that while the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, a discussion of the computational costs associated with training is missing. The comment suggests that this discussion would be beneficial, providing a clear and explicit action for the authors to take. However, it does not specify how to address this issue or what aspects of the training process should be discussed. The action is explicit but somewhat vague, as it lacks detailed guidance on how to incorporate the discussion of computational costs into the draft. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method, specifically mentioning the use of modified GromovHausdorff distances and hypergraph structures, which likely increases time complexity. It notes that while the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, a discussion of the computational costs associated with training is missing. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in detailing the issue of computational costs and suggesting that it should be discussed, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is complex, involving modified GromovHausdorff distances and hypergraph structures, which likely increases time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but it suggests that a discussion of the computational costs associated with training would be beneficial. However, the comment does not provide specific examples or references to support the claim about the increased time complexity or the need for a discussion on training costs. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis for the claim and potentially seek additional evidence to fully understand the reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s complexity, specifically mentioning the use of modified GromovHausdorff distances and hypergraph structures, which could increase time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but it suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is clear and actionable, as it provides a specific area for improvement by highlighting the need for a discussion on training costs. However, the comment could be more helpful if it offered guidance on how to address this issue or suggested specific aspects of the training process that should be discussed. Overall, the comment is 4, as it provides a clear direction for the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern that the proposed method may not represent a groundbreaking innovation within the field of LLMs. It also points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need to be clarified. The action is implicit and vague, as it does not specify how the authors should differentiate their method from existing techniques or what additional information is needed to clarify the unique contributions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the concern that the proposed method may not represent a groundbreaking innovation within the field of LLMs. It also highlights the lack of differentiation from existing contrastive decoding techniques, which leaves readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment does not specify which part of the paper discusses the proposed method or the contrastive decoding techniques, making it weakly grounded. The comment is specific in detailing the issue of distinguishing the proposed method from existing techniques, but without explicit references to sections or figures, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may not represent a groundbreaking innovation within the field of LLMs and does not adequately distinguish it from existing contrastive decoding techniques. This claim is 3 as it highlights a potential gap in the paper\"s contribution and suggests that the authors need to clarify the unique aspects of their method. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the proposed method may not represent a groundbreaking innovation within the field of LLMs. It also points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. The feedback is 3 as it directs the authors to a critical area for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the clarity of Figure 4\"s tabular representation of node agent interactions. However, it does not provide any explicit or implicit suggestions on how to improve the representation or make it more intuitive. The authors are left without guidance on what specific changes or actions they should take to address this issue. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the tabular representation of node agent interactions being \"not intuitive.\" This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4\"s tabular representation of node agent interactions is not intuitive. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left without a basis to understand why the representation is not intuitive or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of Figure 4\"s tabular representation of node agent interactions, suggesting that it is not intuitive. However, the comment lacks specific guidance or suggestions on how to improve the representation or make it more intuitive. Without actionable advice or examples, the authors are left without a clear path to address the issue, making the comment 3. It provides a starting point for improvement but does not fully empower the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the appropriateness of baselines other than PU, suggesting that noiseaware losses might be more suitable. It also asks about the impact of PU loss on calibration and the importance of uncertainty estimation for downstream use cases. While the comment provides specific questions and suggestions, it does not offer explicit guidance on how to address these points or what actions the authors should take to improve their draft. The actions are implicit and somewhat vague, as the authors need to infer how to respond to the questions and suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the appropriateness of baselines other than PU, suggesting that noiseaware losses might be more suitable. It also asks about the impact of PU loss on calibration and the importance of uncertainty estimation for downstream use cases. However, the comment does not specify which part of the paper these questions or suggestions relate to, making it difficult for the authors to identify the exact sections or aspects that need attention. The questions are specific, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the appropriateness of baselines other than PU, suggesting that noiseaware losses might be more suitable. It also asks about the impact of PU loss on calibration and the importance of uncertainty estimation for downstream use cases. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The questions are openended and do not provide clear guidance or evidence for the authors to address. As a result, the claim is not verifiable, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a question about the appropriateness of baselines other than PU, suggesting that noiseaware losses might be more suitable. It also asks about the impact of PU loss on calibration and the importance of uncertainty estimation for downstream use cases. While the comment identifies a potential area for improvement by questioning the choice of baselines, it does not provide specific guidance or suggestions on how to address these concerns or what actions the authors should take to enhance their draft. The feedback is 3 as it prompts the authors to consider alternative baselines and the importance of calibration, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL). The reviewer argues that TL is a broader term encompassing the phenomenon of learning from one task benefiting another, and that FT is a sequential approach to TL. However, the comment does not provide explicit guidance on how the authors should revise their description or address this critique. It lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL), arguing that TL is a broader term and that FT is a sequential approach. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the terminology, the lack of grounding makes it challenging for the authors to understand where to make the necessary revisions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL), arguing that TL is a broader term encompassing the phenomenon of learning from one task benefiting another, and that FT is a sequential approach to TL. The comment provides a logical explanation of why the authors\" characterization might be inaccurate, aligning with the principles of common knowledge and logical reasoning. However, it lacks specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL), arguing that TL is a broader term encompassing the phenomenon of learning from one task benefiting another, and that FT is a sequential approach to TL. While the comment identifies a potential inaccuracy in the authors\" description, it does not provide specific suggestions or guidance on how the authors might revise their characterization to be more accurate. This feedback is 3 as it highlights an area for improvement, but it lacks actionable advice, making it only partially beneficial for the authors to address the critique effectively. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a deficiency in the paper by stating that it lacks a Limitation section. While it identifies a specific area that needs improvement, it does not provide any guidance on how the authors should address this issue. The comment suggests that the authors should include a Limitation section, but it does not offer any specific advice on what content should be included or how to structure it. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the lack of a Limitation section. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact location where the Limitation section should be added or discussed. While the comment is specific in its critique, it lacks grounding as it does not provide clear guidance on where to address the issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks a Limitation section, which is important. However, the comment does not provide any specific reasoning or evidence to support this claim. It does not explain why the absence of a Limitation section is a significant issue or how it affects the paper\"s overall quality or credibility. Without additional context or justification, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of a Limitation section. This is a critical oversight that can impact the paper\"s comprehensiveness and credibility. However, the comment lacks specific guidance or suggestions on how the authors might address this issue. While it highlights an important area for improvement, it does not provide actionable advice or examples of what content could be included in the Limitation section. As a result, the authors are left with a clear understanding of the problem but without a clear path forward for improvement. Therefore, the comment is 3, as it points out a crucial issue but does not offer detailed guidance for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on several aspects of the paper, including the need for more detailed explanations of the theory behind diffusion models in Section 2.1, the use of CLIP guidance in Sections 2.2, and the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021). Additionally, it points out that the captions of figures (3, 4, 7, 8) are not explanatory of what they are illustrating. While the comment explicitly suggests that the authors should provide more detailed explanations, it does not specify how to achieve this or what kind of additional details are needed. The feedback is 3 as it directs the authors to areas where more explanation is required, but it lacks concrete guidance on how to improve the explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides specific feedback on several sections of the paper, including the need for more detailed explanations of the theory behind diffusion models in Section 2.1, the use of CLIP guidance in Sections 2.2, and the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021). It also points out that the captions of figures (3, 4, 7, 8) are not explanatory of what they are illustrating. This feedback is fully grounded as it explicitly mentions the sections and figures being addressed, allowing the authors to accurately identify the parts of the paper that need improvement. The comment is also specific, as it details what needs to be addressed in each section, such as providing more detailed explanations or improving figure captions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detailed explanations of the theory behind diffusion models in Section 2.1, the use of CLIP guidance in Sections 2.2, and the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021). It also notes that the captions of figures (3, 4, 7, 8) are not explanatory of what they are illustrating. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as it lacks the necessary depth to fully substantiate the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on several aspects of the paper, including the need for more detailed explanations of the theory behind diffusion models in Section 2.1, the use of CLIP guidance in Sections 2.2, and the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021). Additionally, it points out that the captions of figures (3, 4, 7, 8) are not explanatory of what they are illustrating. While the comment identifies areas where the paper could be improved, it lacks specific guidance on how to address these issues. For instance, it does not suggest what additional details or explanations should be included to enhance the clarity of the theory or the captions. This feedback is 3 as it directs the authors to areas needing improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the title should include the term \"tensor completion\" because that is the only application of the new model presented in the paper. This is an explicit action that the authors can take to improve the title, making it more specific and accurate. The comment provides a clear and direct instruction on how the authors should revise their title. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the title should include the term \"tensor completion\" because that is the only application of the new model presented in the paper. However, it does not specify which part of the paper this comment is referring to, such as a specific section or figure. This makes it difficult for the authors to identify the exact location of the issue. While the comment is specific about the need to include \"tensor completion\" in the title, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the title should include the term \"tensor completion\" because that is the only application of the new model presented in the paper. This claim is 3 as it provides a specific reason for the suggestion, indicating that the title should be more accurate and reflective of the paper\"s content. However, it lacks detailed examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the title should include the term \"tensor completion\" because that is the only application of the new model presented in the paper. This feedback is specific and actionable, as it provides a clear direction for improving the title to better reflect the content of the paper. By incorporating \"tensor completion\" into the title, the authors can enhance the accuracy and clarity of their work, making it more informative and easier for readers to understand. This feedback is 4 as it offers a direct and constructive suggestion for improvement, though it could be further expanded to include additional aspects of the paper that could be improved. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their proposed method to other prior methods, specifically mentioning the need to implement a simple baseline like character frequencies. While the comment implies that this comparison is necessary to strengthen the paper, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to compare the proposed method to other prior methods, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests implementing a simple baseline like character frequencies to enhance the empirical evaluation. This provides clear guidance on what needs to be done to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not make an attempt to compare their proposed method to other prior methods, limiting the empirical evaluation. The reviewer suggests implementing a simple baseline, such as character frequencies, to enhance the persuasiveness of the paper. However, the comment lacks specific examples or references to support the claim that the current evaluation is insufficient. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper: the lack of comparison to prior methods, which limits the empirical evaluation. The reviewer suggests implementing a simple baseline, such as character frequencies, to enhance the persuasiveness of the paper. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, the comment could be more helpful if it included additional suggestions or guidance on how to effectively compare the proposed method to other approaches. Despite this, the comment is 4 as it directs the authors towards a crucial area for enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to reduce computational load in real applications. It points out that different tokens activate different channels, making it difficult to apply a uniform activation pattern across all tokens. The comment suggests that the method\"s reliance on precomputed PPL and activation patterns may not generalize well to other tokens, potentially negating the intended efficiency gains. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest specific actions to improve the method. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or modifications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of limited practicality in reducing computational load, specifically mentioning the challenges in real applications due to different tokens activating different channels. It highlights that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially negating efficiency gains. However, the comment does not specify which part of the paper discusses the method or the challenges in detail, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of computational load reduction, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the proposed method in reducing computational load, specifically noting that different tokens activate different channels, making it difficult to apply a uniform activation pattern. The comment suggests that the method\"s reliance on precomputed PPL and activation patterns may not generalize well to other tokens, potentially negating the intended efficiency gains. However, the comment lacks specific examples or references to support the claim that different tokens activate different channels or that the method\"s reliance on precomputed patterns hinders generalization. Without detailed evidence or examples, the claim is 3, as it provides a logical argument but lacks sufficient substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method regarding its practicality in reducing computational load. It highlights the challenge of applying a uniform activation pattern across different tokens due to the varying activation patterns of each token. The comment also points out that the method\"s reliance on precomputed PPL and activation patterns may not generalize well to other tokens, potentially negating the intended efficiency gains. This feedback is valuable as it provides a clear and actionable insight into a critical issue that needs to be addressed. However, the comment could be more helpful if it suggested specific ways to overcome these challenges or provided guidance on how to improve the method\"s generalizability. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the paper\"s core motivation, noting that the abstract presents stacked statements about the difficulty of demarcating task boundaries and the introduction of new benchmarks, metrics, and gating techniques. However, it does not provide explicit guidance on how the authors should clarify the motivation or what specific aspects need to be addressed to make the motivation more clear. The action is implicit and vague, as it does not specify how the authors should restructure the abstract or what specific elements need to be emphasized. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the core motivation of the paper, which is not clearly articulated. It points out that the abstract presents stacked statements about the difficulty of demarcating task boundaries and the introduction of new benchmarks, metrics, and gating techniques, which can make it hard to capture the main problem being solved. However, the comment does not specify which part of the paper discusses the motivation or the abstract itself, making it weakly grounded. It is specific in detailing the issue with the abstract\"s presentation, but without explicit references, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the core motivation of the paper is not clear enough, as the abstract presents stacked statements that make it difficult to understand the main problem being addressed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or examples, the claim is 3, as it lacks sufficient evidence to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper\"s core motivation, noting that the abstract presents stacked statements about the difficulty of demarcating task boundaries and the introduction of new benchmarks, metrics, and gating techniques. This feedback is 3 as it points out a specific area where the authors could improve the clarity of their paper. However, the comment could be more helpful if it provided suggestions on how to restructure the abstract or what specific elements should be emphasized to make the motivation clearer. Without actionable guidance, the authors may struggle to address the issue effectively, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sequence inference classifier used to filter data, specifically questioning the nature of the data that passes the filter and its relation to the original MNLI distribution. While the comment identifies a potential issue with the filtering process, it does not provide explicit guidance on how to address this concern or what steps the authors should take to clarify the issue. The action is implicit, as the authors would need to infer that they should provide examples of the filtered data to better understand the issue. However, the lack of concrete instructions on how to implement this action makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises concerns about the sequence inference classifier used to filter data, specifically questioning the nature of the data that passes the filter and its relation to the original MNLI distribution. However, the comment does not specify which part of the paper discusses the sequence inference classifier or the filtering process, making it weakly grounded. It is specific in detailing the concern about the difference between the filtered data and the original MNLI distribution, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the sequence inference classifier used to filter data, specifically questioning the nature of the data that passes the filter and its relation to the original MNLI distribution. The comment suggests that the task of filtering data using the task description seems different from the original MNLI distribution, and it requests examples of the filtered data to clarify the issue. However, the comment does not provide any specific reasoning, references, or examples to support the claim that the filtering process is unclear or problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the sequence inference classifier used to filter data, specifically questioning the nature of the data that passes the filter and its relation to the original MNLI distribution. The reviewer requests examples of the filtered data to clarify this issue, which is a helpful suggestion for improving the clarity and transparency of the data filtering process. However, the comment lacks depth and does not provide specific guidance on how the authors might address the concern or what additional information would be beneficial. While it identifies a potential area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights several issues with the application experiments, including the use of a single model (DALLE) and a small dataset, which raises concerns about the generalizability and persuasiveness of the results. It suggests that the authors should conduct more comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, the comment recommends an indepth editorial review of the paper, focusing on structure, argumentation, and language clarity, providing specific examples such as chaotic equation numbering and the lack of indentation in Algorithm 1. The feedback is explicit and provides concrete details on how the authors can address these issues, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application experiments and the specific issues with the model and dataset used, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the limitations of the experiments, such as the use of a single model and a small dataset, and suggests improvements like conducting more comprehensive experiments. The comment also provides specific examples of issues, such as chaotic equation numbering and the lack of indentation in Algorithm 1, which further enhances the specificity of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the application experiments may have biases due to the use of a single model (DALLE) and a small dataset, making the results difficult to be convincing. The comment suggests that the authors should conduct more comprehensive experiments to validate the effectiveness of the proposed methods. However, the claim lacks specific examples or detailed reasoning to fully substantiate the concern about the limitations of the experiments. While the authors are encouraged to address these issues, the feedback is 3 as it provides a general direction but lacks detailed evidence or references to support the claim comprehensively.", "helpfulness_rationale": "The review comment identifies a significant issue with the application experiments, noting the reliance on a single model (DALLE) and a small dataset, which raises concerns about the generalizability and persuasiveness of the results. It suggests that the authors should conduct more comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, the comment recommends an indepth editorial review of the paper, focusing on structure, argumentation, and language clarity, providing specific examples such as chaotic equation numbering and the lack of indentation in Algorithm 1. This feedback is clear, actionable, and provides detailed suggestions for improvement, making it 5 for the authors to enhance the quality and impact of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the practical applications of the paper, suggesting that the experiments are based on datasets created by concatenating manipulated samples from standard benchmarks. The reviewer expresses a desire for the authors to comment on the relevance of these experiments to realworld applications. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should discuss the practical applications of their work and consider realworld datasets. The comment is 3 because it provides a clear direction but lacks concrete details on how to implement it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the practical applications of the paper, specifically mentioning the use of datasets created by concatenating manipulated samples from standard benchmarks. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or experiments. The authors cannot confidently determine which section the comment addresses, making it weakly grounded. The comment is specific in that it highlights a concern about the practical relevance of the experiments, but without clear grounding, the authors may struggle to understand which part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the practical applications of the paper, specifically questioning the relevance of experiments conducted on datasets created by concatenating manipulated samples from standard benchmarks. While the reviewer expresses a desire for the authors to comment on the practical applications of their work, the comment lacks specific examples or references to support the claim that these datasets are not representative of realworld scenarios. Without detailed justification or examples, the claim remains 3, as the authors may need to infer the reasoning behind the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the practical applications of the paper, specifically questioning the relevance of the experiments conducted on datasets created by concatenating manipulated samples from standard benchmarks. The reviewer suggests that there might be realworld tasks with available data that would make such a model more applicable. This feedback highlights a potential gap in the paper\"s discussion of practical relevance and encourages the authors to consider expanding their work to address this concern. However, the comment could be more helpful if it provided specific examples of realworld applications or suggested ways to incorporate such examples into the paper. Overall, the comment is 3 as it identifies an area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the method of selecting m\" in the CALMIR framework, specifically asking whether it is done exhaustively over all loss minimizer subsets. While the comment identifies a potential issue with the method, it does not provide explicit guidance on how to address this concern or suggest any specific actions the authors should take. The action is implicit, as the authors would need to infer that they should clarify the selection process or provide more details on how m\" is determined. However, the comment lacks concrete details on how to implement this clarification or address the concern, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the method of selecting m\" in the CALMIR framework, specifically asking whether it is done exhaustively over all loss minimizer subsets. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its inquiry about the selection process, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the method of selecting m\" in the CALMIR framework, specifically asking whether it is done exhaustively over all loss minimizer subsets. This is a question that seeks clarification rather than a claim that requires verification. The comment does not provide any evidence, reasoning, or references to support the question itself. Therefore, it aligns with the \"No\" category, as it does not contain a claim that needs verification.", "helpfulness_rationale": "The review comment raises a question about the method of selecting m\" in the CALMIR framework, specifically asking whether it is done exhaustively over all loss minimizer subsets. This question highlights a potential area of confusion or lack of clarity in the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or suggestions, the comment is not particularly helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1, as it is 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the \"Robustness\" section should consider input datafree backdoor detection methods, such as those based on weight matrix statistics or matrix factorization. However, it does not provide explicit guidance on how the authors should incorporate these methods into their analysis or what specific aspects of the algorithm performance should be addressed. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"Robustness\" section of the paper, providing specific examples of alternative backdoor detection methods that are input datafree. It suggests that these methods, such as those based on weight matrix statistics or matrix factorization, should be considered in the analysis of algorithm performance. This provides clear guidance on what aspects of the paper need to be addressed, making the comment fully grounded. Additionally, it specifies the type of methods to consider, enhancing the specificity of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"Robustness\" section should consider input datafree backdoor detection methods, such as those based on weight matrix statistics or matrix factorization. This claim is 3 as it provides specific examples of alternative methods that could be included in the analysis. However, it lacks detailed reasoning or references to support why these methods are relevant or how they would enhance the analysis. The comment could be more robust if it provided a clear rationale or cited relevant literature to substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the \"Robustness\" section. It suggests that the authors consider input datafree backdoor detection methods, such as those based on weight matrix statistics or matrix factorization, which are not currently discussed. This feedback is actionable as it provides a clear direction for the authors to enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it offered specific guidance on how to incorporate these methods or what aspects of the algorithm performance should be addressed. Overall, the comment is 4, as it provides a valuable suggestion for improvement but could be more detailed in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the relation works section is incomplete and suggests that the authors need to describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. While the comment identifies a specific area that needs improvement and provides a clear direction for the authors to address it, it does not explicitly instruct them on how to complete the section or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relation works section, which is a specific part of the paper. However, it does not provide explicit references to a particular section, table, or figure, making it weakly grounded. The comment is specific in that it suggests the authors need to describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relation works section is incomplete and suggests that the authors need to describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires improvement, namely the relation works section. It points out that the section is incomplete and suggests that the authors need to describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This feedback is clear and actionable, providing the authors with a specific direction to enhance their draft. However, the comment could be more helpful if it offered additional guidance on how to describe the different views or provided examples of how to integrate this information into the paper. Overall, the comment is 4 as it highlights a crucial aspect of the paper that needs attention, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the relevance of the problem setup to the proposed method, specifically questioning whether the optimality gap is a suitable metric given the focus on regression and prediction. It suggests that the contribution revolves around regression and implies that the accuracy of the method on this task should be compared to strong baselines. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relevance of the problem setup to the proposed method, specifically questioning whether the optimality gap is a suitable metric given the focus on regression and prediction. It suggests that the contribution revolves around regression and implies that the accuracy of the method on this task should be compared to strong baselines. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the relevance of the optimality gap and the need for comparison with strong baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relevance of the problem setup to the proposed method, specifically questioning whether the optimality gap is a suitable metric given the focus on regression and prediction. It suggests that the contribution revolves around regression and implies that the accuracy of the method on this task should be compared to strong baselines. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the optimality gap is not relevant or that the comparison with strong baselines is necessary. This lack of substantiation makes the claim 3, as it lacks the necessary evidence to fully support the authors\" concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the relevance of the problem setup to the proposed method, specifically questioning whether the optimality gap is a suitable metric given the focus on regression and prediction. It suggests that the contribution revolves around regression and implies that the accuracy of the method on this task should be compared to strong baselines. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve their draft. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and direction for the authors to act upon."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of theoretical support for the technical design, specifically mentioning the update derivation for intrinsic reward parameters (Eq. 710). It suggests that the update process, while accepted, lacks justification, particularly in the context of the work by Sorg et al. (2010). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen the theoretical support. The action is implicit and vague, as it does not offer concrete steps or suggestions for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of theoretical support for the technical design, specifically mentioning the update derivation for intrinsic reward parameters (Eq. 710). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the update derivation, but without explicit references to sections or equations, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical design lacks theoretical support, specifically regarding the update derivation for intrinsic reward parameters (Eq. 710). It suggests that the update process, while accepted, lacks justification, particularly in the context of the work by Sorg et al. (2010). However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the update derivation is \"hardly convincing.\" Without additional evidence or explanation, the authors may find it difficult to fully understand and address the issue. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper\"s technical design, specifically noting the lack of theoretical support for the update derivation of intrinsic reward parameters. It highlights that while the update process is accepted, the justification for the update derivation, particularly in the context of Sorg et al. (2010), is not convincing. This feedback is valuable as it points out a critical area where the authors need to strengthen their theoretical foundation or provide more detailed reasoning. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as suggesting additional theoretical frameworks or providing more detailed derivations. Overall, the comment is 3 as it identifies a key area for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the authors\" claim of adaptive variance reduction, suggesting that it is weakened by the choice of a small enough \u03b2 parameter. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The comment implies that the adaptivity claim is not valid under the current parameter choice, but it lacks concrete suggestions or actionable steps for the authors to take. As a result, the authors are left without a clear understanding of how to respond or improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" claim of adaptive variance reduction, suggesting that it is weakened by the choice of a small enough \u03b2 parameter. However, it does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact issue and address it effectively. While the comment is specific in its critique of the adaptivity claim, the absence of explicit references to the paper limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors\" adaptive variance reduction property is weakened by the choice of a small enough \u03b2 parameter, arguing that this choice does not align with the adaptivity claim, particularly in contrast to methods like AdaGrad. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The reasoning is logical but lacks detailed evidence or examples, which could enhance the verifiability. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" claim of adaptive variance reduction, suggesting that the choice of a small enough \u03b2 parameter undermines the adaptivity claim. This feedback is clear and actionable, as it provides a specific critique that the authors can address by revising their draft. However, the comment could be more helpful if it offered suggestions on how to strengthen the adaptivity claim or how to choose a parameter that aligns with the adaptivity property. Despite this, the comment provides a valuable insight that the authors can use to improve their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the unclear value of different augmentation techniques and suggests further investigation into why DINOv2 performs best. It implies that the authors should explore the reasons behind the effectiveness of DINOv2 and consider how to improve it. However, the comment does not provide explicit guidance on what specific aspects of the augmentation techniques or the DINOv2 model should be investigated, nor does it offer concrete steps on how to conduct this investigation. The action is implicit and somewhat vague, as the authors need to infer the need for further exploration and improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the value of different augmentation techniques, suggesting that while different techniques have different effects on different models, DINOv2 performs best most of the time. It recommends further investigation into why and how to improve the bestperforming model. However, the comment does not specify which part of the paper discusses augmentation techniques or the performance of DINOv2, making it weakly grounded. It is specific in suggesting further investigation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the value of different augmentation techniques is unclear and suggests further investigation into why DINOv2 performs best. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or logical arguments to substantiate the assertion that the value of augmentation techniques is unclear. Without additional context or justification, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the value of different augmentation techniques, noting that while different techniques have varying effects on different models, DINOv2 appears to be the most effective. It suggests further investigation into why this is the case and how to improve the bestperforming model. This feedback is 3 as it points out a specific area for improvement and encourages the authors to explore the reasons behind the effectiveness of DINOv2. However, the comment could be more helpful if it provided specific guidance on what aspects of the augmentation techniques or the DINOv2 model should be investigated. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the acronym used for \"Follow the Top Perturbed Leader\" is unfortunate because it conflicts with the common usage of \"FTL\" for \"Follow the Leader\" in literature. The comment implies that a change in acronym might be beneficial, but it does not provide explicit guidance on how to implement this change or what specific aspects of the acronym should be revised. The action is implicit and somewhat vague, as the authors are left to infer that they should consider changing the acronym. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the acronym \"FTL\" and its potential conflict with the common usage of \"FTL\" in literature. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the acronym, suggesting that it is unfortunate and potentially confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the acronym \"FTL\" used for \"Follow the Top Perturbed Leader\" is unfortunate because it conflicts with the common usage of \"FTL\" for \"Follow the Leader\" in literature. While the comment identifies a potential issue with the acronym, it does not provide specific examples or references to support the claim. The suggestion for a change in acronym is clear, but the lack of detailed reasoning or evidence makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the acronym used for \"Follow the Top Perturbed Leader,\" noting that it conflicts with the common usage of \"FTL\" for \"Follow the Leader\" in literature. This observation is clear and highlights a potential inconsistency in terminology that could cause confusion for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative acronyms or clarifying the usage of the existing one. While it points out a potential area for improvement, the feedback is somewhat limited in its actionable value. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the selection of attacks in Table 1 is arbitrary and not stateoftheart, providing specific examples like MIDIFGSM and a reference to a survey for further analysis. It also requests that the authors mention the number of iterations for the attacks and their hyperparameters. These actions are clear and concrete, allowing the authors to directly address the issues by revising the table and providing additional details. The comment is fully actionable, as it provides specific guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the selection of attacks, suggesting that they are not stateoftheart and recommending the inclusion of better attacks like MIDIFGSM, as well as providing a reference for further analysis. Additionally, the comment requests specific details about the number of iterations and hyperparameters for the attacks, which are crucial for improving the clarity and completeness of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the selection of attacks in Table 1 is arbitrary and not stateoftheart, suggesting that there are better attacks available, such as MIDIFGSM, and providing a reference to a survey for further analysis. The claim is 3 as it provides a specific example of a better attack and a reference, but it lacks detailed reasoning or examples to fully support the claim. The authors would need to infer the reasoning behind the claim, which could be improved with more detailed explanations or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the selection of attacks in Table 1, noting that they are not stateoftheart and suggesting the inclusion of better attacks like MIDIFGSM. It also provides a reference to a survey for further analysis, which is helpful for the authors to understand the context and improve the comprehensiveness of their work. Additionally, the comment requests the authors to mention the number of iterations for the attacks and their hyperparameters, which are important details for clarity and reproducibility. This feedback is clear, actionable, and provides specific guidance, making it 4 for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the method, noting that it is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or improve the method\"s applicability to other pretraining methods. The comment identifies a gap in the paper but lacks actionable guidance for the authors to address it. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the method is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM).\" This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on how to address the limitation or suggest improvements. It lacks specific examples or actionable steps for the authors to take. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the method is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). This claim is 3 as it is based on the limitations and conclusion sections of the paper, which provide context for the method\"s effectiveness. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation of the method, specifically noting that it is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). This observation is based on the limitations and conclusion sections of the paper, which provide context for the method\"s effectiveness. However, the comment does not offer any suggestions or guidance on how the authors might address this limitation or improve the method\"s applicability to other pretraining methods. While it highlights an important area for consideration, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the description of qualitative analysis. It asks for clarification on how the two input sentences were determined for qualitative analysis, specifically mentioning whether they occurred during the finetuning process. Additionally, it questions the normalization of attribution values in Figure 1 and the effectiveness of the attribution map for input examples that failed to be classified. While the comment provides specific questions and areas for clarification, it does not offer explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the qualitative analysis section, including the determination of input sentences, the finetuning process, and the attribution values in Figure 1. It also questions the normalization of vector norms and the effectiveness of the attribution map for failed examples. However, the comment does not explicitly mention the section or figure where these issues are discussed, making it weakly grounded. The specificity of the comment is high as it provides detailed questions and suggestions about the qualitative analysis, which helps the authors understand what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the qualitative analysis section, specifically about the determination of input sentences, the finetuning process, and the attribution values in Figure 1. It also questions whether the attribution values are normalized and the effectiveness of the attribution map for input examples that failed to be classified. While the comment provides specific questions and areas for clarification, it lacks detailed reasoning or references to support the claims. The feedback is 3 as it offers suggestions for improvement but does not provide a comprehensive explanation or evidence to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific questions and suggestions for improvement regarding the qualitative analysis section. It asks for clarification on how the input sentences were determined, whether they occurred during finetuning, and questions the normalization of attribution values in Figure 1. Additionally, it inquires about the effectiveness of the attribution map for input examples that failed to be classified. While the comment identifies areas for improvement and provides some guidance, it lacks detailed explanations or actionable steps for the authors to take. The feedback is 3 as it offers insights into potential issues and areas for clarification, but it could be more comprehensive and detailed to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifies how these scenarios validate the advantages of using equivariant tensor functions. This provides a clear and explicit action for the authors to take, as they can directly incorporate these examples into their draft. The suggestion is concrete, as it specifies what needs to be added and how it should be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifies how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes it weakly grounded, as the authors may need to infer which part of the paper is being addressed. The comment is specific in its suggestion, as it provides clear guidance on what needs to be included to enhance the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifies how these scenarios validate the advantages of using equivariant tensor functions. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand and implement the suggestion. Without concrete examples or references, the claim is 3, as it provides a general direction but lacks the necessary details to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for improvement by recommending the inclusion of examples of practical applications where specific types of tensors need to be equivariant. This is a valuable piece of feedback as it helps the authors enhance the practical relevance and applicability of their work. By providing a clear direction for improvement, the comment is 4, as it offers actionable guidance but could be more comprehensive if it included additional suggestions or details. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point identifies two specific issues with the paper: the lack of clarity in the representation of methods like ERM, cRT, and LWS in Table 2, and the misalignment between Section 3.2.3 and the table. While the comment explicitly mentions these issues, it does not provide any guidance on how the authors should address them. The authors are left without any actionable steps to take, as the comment lacks concrete suggestions or instructions on how to improve the clarity or alignment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the representation of methods like ERM, cRT, and LWS in Table 2 and the misalignment between Section 3.2.3 and the table. This provides clear guidance on what needs to be addressed in these specific parts of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are issues with the tables, specifically mentioning that methods like ERM, cRT, and LWS are not referenced properly in Table 2, making it unclear what these methods represent. It also notes that Section 3.2.3 does not align with the table. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the nature of the issues or how to address them. Without detailed reasoning or examples, the claim is considered 2, as it provides some basis for concern but lacks sufficient evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the lack of clarity in the representation of methods like ERM, cRT, and LWS in Table 2 and the misalignment between Section 3.2.3 and the table. While the comment points out these problems, it does not provide any suggestions or guidance on how the authors might address these issues. Without actionable feedback or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights areas for improvement but lacks depth and direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment provides two specific questions for the authors to address, asking about the applicability of the model to sarcastic/nonsarcastic utterances and the utility of eyemovement data for sentiment classification beyond textual features. These questions are explicit and direct, guiding the authors to consider additional details and explanations. However, the comment does not offer concrete suggestions on how to address these questions or what specific aspects of the analysis should be expanded. The actions are implicit and somewhat vague, as the authors need to infer how to apply the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"General Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and suggestions for the authors to consider, such as whether the model is suitable for sarcastic/nonsarcastic utterances and why eyemovement data is useful for sentiment classification beyond textual features. This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two questions about the applicability of the model to sarcastic/nonsarcastic utterances and the utility of eyemovement data for sentiment classification beyond textual features. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\".", "helpfulness_rationale": "The review comment provides two specific questions for the authors to address, focusing on the applicability of the model to sarcastic/nonsarcastic utterances and the utility of eyemovement data for sentiment classification beyond textual features. These questions are clear and actionable, guiding the authors to consider additional details and explanations that could enhance the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how to expand the analysis. Overall, the feedback is 3 as it identifies areas for improvement but lacks depth and guidance on specific actions to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experimental results: the limited number of datasets used and the mislabeling of DDIM as a sampler method in tables 1 and 2. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should conduct more experiments on larger datasets and correct the mislabeling in the tables. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on implementation. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically mentioning the limited number of datasets used and the mislabeling of DDIM as a sampler method in tables 1 and 2. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experimental results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on two smallscale datasets and that the tables are mislabeled, with DDIM being described as a sampler method instead of a model. While the comment identifies specific issues, it lacks detailed reasoning or references to support these claims. The authors are left to infer the basis of these claims, which makes the comment 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies two key issues with the experimental results: the limited number of datasets used and the mislabeling of DDIM as a sampler method in tables 1 and 2. While the comment points out these weaknesses, it does not provide specific suggestions or guidance on how to address them. The authors are left to infer that they need to conduct more experiments on larger datasets and correct the mislabeling in the tables. This feedback is 3 as it highlights areas for improvement, but it lacks actionable advice, making it rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more clarification about the importance of the proposed method. It points out that the method might be adjusting the variance level of DPSGD and questions what impact this has on utility and privacy. However, the comment does not explicitly instruct the authors to clarify the importance of the method or provide specific guidance on how to address the concerns about utility and privacy. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more clarification about the importance of the proposed method. It mentions that the method might be adjusting the variance level of DPSGD and questions what impact this has on utility and privacy. However, the comment does not specify which part of the paper this clarification should be included in, making it weakly grounded. The comment is specific in its request for clarification regarding the importance of the method and its impact on utility and privacy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more clarification about the importance of the proposed method, specifically questioning whether adjusting the variance level of DPSGD affects utility and privacy. However, the comment lacks specific examples or references to support the claim that the method is merely adjusting the variance level. It does not provide detailed reasoning or evidence to substantiate the assertion that the authors should present what is lost in terms of privacy or utility. As a result, the claim is 3, as it lacks sufficient justification or examples to fully support the authors in addressing the issue.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that the authors should provide more clarification about the importance of the proposed method. It questions whether the method is merely adjusting the variance level of DPSGD and asks what impact this might have on utility and privacy. However, the comment does not offer specific guidance or suggestions on how to address these concerns or clarify the method\"s importance. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors would need to infer what additional information or discussion is needed to address the comment effectively."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical result is more illustrative than demonstrative and recommends a largerscale experiment, specifically a longerhorizon example. While the comment implies that the authors should conduct a largerscale experiment, it does not provide explicit instructions on how to implement this suggestion, such as what kind of additional experiments would be beneficial or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the empirical result is more illustrative than demonstrative and recommends a largerscale experiment, specifically a longerhorizon example. It does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. However, the comment is specific in its suggestion to include a longerhorizon example, which would enhance the empirical results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical result is more illustrative than demonstrative and recommends a largerscale experiment, specifically a longerhorizon example. While the comment implies that a largerscale experiment would be beneficial, it does not provide specific examples or references to support this claim. The suggestion is 3 as it offers a direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the empirical result is more illustrative than demonstrative and recommends a largerscale experiment, specifically a longerhorizon example. This feedback is 3 as it provides a direction for improvement, suggesting that the authors should consider conducting more extensive experiments to enhance the empirical results. However, the comment lacks specific guidance on how to implement this suggestion or what kind of additional experiments would be beneficial. While it offers a valuable insight, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that Equation (13) does not have a closedform solution in general and suggests that the authors provide details about how it is solved in the experiments and on the computational complexity. This feedback is explicit and concrete, as it directly instructs the authors to include specific details about the solution process and computational complexity. The authors can directly apply this action by adding the requested information to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of a closedform solution and suggests providing details about the solution process and computational complexity, which are concrete and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Equation (13) does not have a closedform solution in general and suggests providing details about how it is solved in the experiments and on the computational complexity. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or references to support why this information is important or how it would enhance the paper. The authors would need to infer the importance of this information, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation (13), noting that it does not have a closedform solution in general. It suggests that the authors provide details about how the equation is solved in the experiments and on the computational complexity. This feedback is clear and actionable, as it directly points out a gap in the paper and provides a concrete direction for improvement. By including these details, the authors can enhance the clarity and completeness of their work. Therefore, the comment is 4, as it offers specific guidance on how to address the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the discussion of the \"proximity\" choice and the nature of the tasks. It points out that the relationship between proximity in fingertip Cartesian positions and proximity in the solution space is not consistently strong across all tasks, particularly in complex mazes and robotic tasks with obstacles. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure cases on those that do not. While the comment identifies an area for improvement and provides a specific direction for analysis, it does not explicitly instruct the authors on how to implement this suggestion. The action is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of \"proximity\" and the nature of the tasks, specifically mentioning the correlation between proximity in fingertip Cartesian positions and proximity in the solution space. It provides examples of tasks where this relationship does not hold, such as complicated mazes and robotic tasks with obstacles. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it provides clear examples of tasks where the proximity metric is not reasonable and suggests analyzing these tasks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the choice of \"proximity\" and the nature of the tasks. It provides examples of tasks where the relationship between proximity in fingertip Cartesian positions and proximity in the solution space does not hold, such as complicated mazes and robotic tasks with obstacles. The comment suggests that the paper would be better if it analyzes what tasks have reasonable proximity metrics and demonstrates failure on those that do not. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion. The comment provides a general idea but does not offer a comprehensive explanation or evidence to support the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by highlighting the lack of discussion on the choice of \"proximity\" and the nature of the tasks. It provides specific examples of tasks, such as complicated mazes and robotic tasks with obstacles, where the relationship between proximity in fingertip Cartesian positions and proximity in the solution space does not hold. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure cases on those that do not. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by addressing the identified gap in the discussion. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific metrics to consider. Overall, the comment is 4, as it effectively guides the authors to improve their work by addressing a critical aspect of their research."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the experiments lack implementation details, which are necessary for readers to fully understand or reproduce the results. However, it does not provide explicit guidance on what specific details are missing or how the authors should address this issue. The comment implies that the authors should include more implementation details, but it does not specify what those details are or how to implement them. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what to do. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiments lack implementation details necessary for readers to fully understand or reproduce the results. However, it does not specify which part of the paper or which sections are missing these details. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific examples of what implementation details are missing, such as specific algorithms, parameters, or data preprocessing steps. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experiments lack implementation details necessary for readers to fully understand or reproduce the results. However, the comment does not provide any specific examples or references to support this claim. Without detailed information or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experiments, noting that they lack implementation details necessary for readers to fully understand or reproduce the results. This feedback is valuable as it highlights a critical gap in the paper\"s presentation, which could hinder the reproducibility and understanding of the research. However, the comment could be more helpful if it provided specific examples of what implementation details are missing or suggested ways to address this issue. Without such guidance, the authors may struggle to improve their draft effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison between the SSUL method and the paper\"s approach, noting that SSUL uses an offtheshelf saliencymap detector while the paper uses Mask2Former for region proposals. The reviewer points out that Mask2Former is trained on COCO and has more parameters, potentially introducing an unfair advantage. The comment suggests exploring alternative approaches, such as using Mask2Former for SSUL or generating object proposals unsupervisedly. However, the comment does not provide explicit guidance on how the authors should address these suggestions or what specific actions they should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of different methods for detecting unseen classes in the SSUL method and the paper, specifically mentioning the use of an offtheshelf saliencymap detector versus the Mask2Former for region proposals. It highlights a potential issue of unfair comparison due to the differences in data and model size. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, allowing the authors to accurately identify the sections being discussed. It is also specific because it clearly specifies the issue of unfair comparison and suggests alternative approaches, such as using Mask2Former for SSUL or generating object proposals unsupervisedly. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison between the SSUL method and the paper\"s approach, specifically regarding the use of different saliencymap detectors. It highlights that SSUL uses an offtheshelf detector, while the paper uses Mask2Former for region proposals. The reviewer points out that Mask2Former is trained on COCO and has more parameters, potentially introducing an unfair advantage. The comment suggests exploring alternative approaches, such as using Mask2Former for SSUL or generating object proposals unsupervisedly. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the reasoning and explore the suggestions to address the concern, which limits the verifiability.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the SSUL method and the paper\"s approach, particularly regarding the use of different saliencymap detectors. It highlights that SSUL uses an offtheshelf detector, while the paper employs Mask2Former for region proposals, which could introduce an unfair advantage due to Mask2Former being trained on COCO and having more parameters. The comment suggests exploring alternative approaches, such as using Mask2Former for SSUL or generating object proposals unsupervisedly, which could potentially address the issue. However, the comment lacks specific guidance on how to implement these suggestions or what additional experiments might be needed to validate the proposed approaches. While it identifies a potential weakness, it does not provide detailed actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights potential issues with the metrics used in the experiments, suggesting that style accuracy might be too accurate to capture the style of the proposed algorithm. It also points out that transfer results based on stylized inputs may not be easily verifiable. However, the comment does not provide explicit guidance on how to address these issues or suggest alternative metrics or methods for validation. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically mentioning the metrics used and their potential limitations. It highlights issues with style accuracy and the transferability of results with stylized inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the problems with the metrics, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the metrics used in the experiments, specifically questioning their ability to validate the performance of the proposed approach. It provides examples, such as the style accuracy being based on a style classifier and the transferability of results with stylized inputs. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3 as it provides some justification but lacks depth and specific examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the metrics used in the experiments, specifically questioning their ability to validate the performance of the proposed approach. It provides examples, such as the style accuracy being based on a style classifier and the transferability of results with stylized inputs. However, the comment lacks detailed reasoning or suggestions for alternative metrics or methods that could better validate the performance. While it highlights a concern, it does not offer actionable guidance or constructive feedback that would help the authors improve their experimental design or analysis. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient depth or actionable advice to fully address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of how individual preferences are generated in the proposed method. It suggests that the authors may have interpreted \"preference\" as rules or policies learned from experiences, but this is not explicitly stated. The comment implies that the authors need to clarify how these preferences are generated on an individual level, which is a specific action they should take. However, the action is not explicitly stated, making it 3. The authors know what needs to be addressed but lack guidance on how to implement the clarification. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the issue of how individual preferences are generated in the proposed method, specifically questioning the clarity of this process. It mentions that the paper argues the method can take individual preferences into account but does not specify which part of the paper this is discussed. However, it clearly specifies what needs to be clarified regarding the generation of these preferences. This makes the comment weakly grounded, as the authors may need to infer the specific section, but it is specific in detailing the issue. Therefore, the comment is rated as 3.", "verifiability_rationale": "The review point raises a question about the clarity of how individual preferences are generated in the proposed method, specifically questioning whether the paper adequately explains how certain agents are more risk averse than others. The comment suggests that the authors may have interpreted \"preference\" as rules or policies learned from experiences, but this is not explicitly stated. While the comment implies a need for clarification, it lacks specific examples or references to support the claim. Therefore, the comment is considered 2, as it provides some context but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the generation of individual preferences in the proposed method. It questions how these preferences are generated on an individual level, particularly noting the lack of clarity in distinguishing between risk aversion and other factors. This feedback is valuable as it highlights a potential gap in the explanation of the method, suggesting that the authors need to clarify how individual preferences are generated. However, the comment could be more helpful if it provided specific examples or guidance on how to address this issue. Overall, the comment is 3, as it points out a critical area for improvement but lacks detailed suggestions for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the clarity and computation of values in Figure 4, specifically regarding the meaning of \"1200 frames,\" the computation of these values, the relationship between precision/recall and trajectory length, and the definition of \"action repeat.\" While the comment explicitly asks for clarification on these aspects, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the figure\"s clarity and accuracy. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed in the figure, including the meaning of \"1200 frames,\" how the values are computed, the relationship between precision and recall and trajectory length, and the definition of \"action repeat.\" This level of detail provides clear guidance for the authors to improve the clarity and accuracy of the figure. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises questions about the clarity and computation of values in Figure 4, specifically regarding the meaning of \"1200 frames,\" the computation of these values, the relationship between precision and recall and trajectory length, and the definition of \"action repeat.\" While the comment identifies areas that need clarification, it does not provide any supporting evidence, reasoning, or references to justify the claims made. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies specific areas in the paper that require clarification, such as the meaning of \"1200 frames\" in Figure 4, how the values are computed, the relationship between precision and recall and trajectory length, and the definition of \"action repeat.\" While the comment highlights these issues, it does not provide detailed explanations or suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas that need improvement, but it lacks depth and actionable guidance, making it only partially beneficial for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the arbitrariness of certain design decisions, specifically the number of initial ground truth examples and labeled examples. It suggests that given the costeffectiveness as a primary motivation, a more satisfying comparison would be to see the performance of LLaMAA versus finetuning with a number of samples equivalent in cost to the additional samples from the LLM. The comment implies that the authors should provide some justification for these design choices. However, it does not explicitly instruct the authors on how to provide this justification or what specific aspects of the justification should be included. The action is implicit and somewhat vague, as the authors need to infer that they should justify their design decisions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the arbitrariness of design decisions, specifically the number of initial ground truth examples and labeled examples. However, it does not specify which part of the paper these design decisions are discussed in, making it weakly grounded. The comment is specific in that it suggests a comparison between LLaMAA and finetuning with a costequivalent number of samples, which provides a clear direction for the authors to address the issue. However, without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the arbitrariness of design decisions, specifically the number of initial ground truth examples and labeled examples. It suggests that given the costeffectiveness as a primary motivation, a more satisfying comparison would be to see the performance of LLaMAA versus finetuning with a number of samples equivalent in cost to the additional samples from the LLM. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that these design choices are arbitrary or why the suggested comparison would be more satisfying. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the arbitrariness of design decisions, specifically the number of initial ground truth examples and labeled examples. It suggests that given the costeffectiveness as a primary motivation, a more satisfying comparison would be to see the performance of LLaMAA versus finetuning with a number of samples equivalent in cost to the additional samples from the LLM. The comment implies that the authors should provide some justification for these design choices, which could potentially increase their soundness score. However, the comment lacks specific guidance on how to justify these decisions or what aspects of the justification should be included. While it provides a direction for improvement, it does not offer detailed suggestions or examples, making it 3. Therefore, the comment aligns with a score of 3, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the motivation for using a graphstructured model, particularly in comparison to Transformerbased models that can already capture global dependencies. It highlights a potential confusion regarding the complexity of the approach. However, the comment does not provide explicit guidance or suggestions on how the authors might address this confusion or clarify the motivation. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation for investigating a graphstructured model, specifically questioning why it is necessary given that Transformerbased encoders and decoders can already capture global dependencies. However, it does not specify which part of the paper this motivation is discussed or how the authors might address this confusion. The lack of explicit grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper being addressed. Additionally, the comment is somewhat specific in its critique of the motivation but lacks detailed guidance on how to improve the clarity or effectiveness of the motivation. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the motivation for investigating a graphstructured model in comparison to Transformerbased models, which can already capture global dependencies. The reviewer expresses confusion about the complexity of the approach. However, the comment lacks specific examples or detailed reasoning to support the claim that the motivation is unclear or that the approach is overly complex. Without additional context or evidence, the claim remains 3, as the authors may need to infer the reasoning behind the confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the motivation for investigating a graphstructured model, particularly in comparison to Transformerbased models that can already capture global dependencies. The reviewer expresses confusion about the complexity of the approach, which could be helpful for the authors to clarify their reasoning and address potential misunderstandings. However, the comment lacks specific suggestions or guidance on how the authors might improve the clarity or effectiveness of their motivation. While it identifies an area for improvement, the feedback is somewhat vague and could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide videos to illustrate how different policies control cars on different tracks, which would enhance the understanding of the methods. It also points out that some implementation details are lacking, making it difficult to reproduce the results, and that the policy gradient approach used is not clear. The comment provides explicit actions for the authors to take, such as including videos and clarifying the policy gradient approach. However, it does not offer concrete guidance on how to implement these actions, such as specific types of videos or detailed explanations of the policy gradient approach. Therefore, the comment is 4, as it identifies the need for additional information but lacks detailed instructions on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"implementation details\" and \"policy gradient approach,\" allowing the authors to accurately identify the parts of the paper that need improvement. It is also specific because it clearly specifies what is lacking: some implementation details and the policy gradient approach used, which are crucial for reproducibility. This provides the authors with clear guidance on what needs to be addressed to enhance the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of implementation details and the unclear policy gradient approach used, which are critical for reproducibility. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the need for more information, which makes the feedback 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reproducibility due to the lack of implementation details and the unclear policy gradient approach used. It suggests that providing videos illustrating different policies controlling cars on different tracks would enhance the understanding of the methods, which is a valuable and actionable suggestion. However, the comment could be more helpful if it provided specific examples of what these videos should include or how the policy gradient approach is implemented. Despite this, the feedback is 4 as it directs the authors towards improving the clarity and reproducibility of their work, which are essential for the paper\"s impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the approximation made in Equation 11, suggesting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. It also points out that Figure 1(a) does not indicate which specific layer each color represents, suggesting that the authors should conduct more experiments and theoretical analyses to explore this aspect. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what actions should be taken. The actions are implicit and somewhat vague, as the authors need to infer how to conduct additional experiments and analyses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the approximation made in Equation 11 and questions its validity, suggesting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. It also critiques Figure 1(a), noting that it does not indicate which specific layer each color represents, implying that the authors should conduct more experiments and theoretical analyses to explore this aspect. The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Equation 11 and Figure 1(a), allowing the authors to accurately identify the sections being addressed. It is also specific because it provides clear details about the issues with the approximation and the lack of clarity in Figure 1(a). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the approximation made in Equation 11, suggesting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. The comment also critiques Figure 1(a), noting that it does not indicate which specific layer each color represents, implying that the authors should conduct more experiments and theoretical analyses to explore this aspect. While the comment provides a logical reasoning for questioning the approximation and the clarity of Figure 1(a), it lacks specific examples or references to support the claims fully. The feedback is 3 as it offers a clear rationale but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the approximation made in Equation 11, questioning whether it adequately considers the impact of parameters in each layer and the effect of the order of layers with the same parameters. It also critiques Figure 1(a), noting that it does not indicate which specific layer each color represents, suggesting that the authors should conduct more experiments and theoretical analyses to explore this aspect. This feedback is 3 as it identifies specific areas where the paper could be improved, such as providing a more comprehensive analysis of the approximation and enhancing the clarity of Figure 1(a). However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting additional experiments or theoretical analyses. Overall, the comment offers valuable insights but could be more actionable with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that addressing offlinetoonline learning adaptation is incremental, as most previous offline RL benchmarks are based on simulation environments and rulebased reward functions. It implies that implementing online finetuning on existing benchmarks is feasible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their work need to be revised. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of offlinetoonline learning adaptation, suggesting that it appears to be incremental. It mentions that most previous offline RL benchmarks are based on simulation environments and rulebased reward functions, implying that implementing online finetuning on existing benchmarks is feasible. However, the comment does not specify which part of the paper discusses offlinetoonline learning adaptation or provide details on what aspects need to be addressed. The authors cannot confidently determine which section or part of the paper is being referenced, making the comment weakly grounded. Additionally, while it provides some context, it does not specify what needs to be addressed or how the authors should approach the issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that addressing offlinetoonline learning adaptation appears to be incremental, based on the observation that most previous offline RL benchmarks are based on simulation environments and rulebased reward functions. The comment suggests that implementing online finetuning on existing benchmarks is feasible. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion that the adaptation is incremental. While the reasoning is somewhat logical, it could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach to offlinetoonline learning adaptation, suggesting that it may be incremental. It provides a rationale by pointing out that most previous offline RL benchmarks are based on simulation environments and rulebased reward functions, implying that implementing online finetuning on existing benchmarks is feasible. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or what aspects of their work need improvement. While it highlights a potential area for concern, the feedback lacks actionable insights, making it 3. The authors would need to infer how to address the issue based on the comment, which limits its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific examples of contradictory evidence in Table 6, highlighting instances where the results do not support the claim that emotionawareness is useful for synthetic text detection. It explicitly points out that AT finetunes the detection model with emotion classification data of news headlines but achieves a worse F1 score than BERTsynth, and GAS achieves the lowest F1 score despite finetuning with emotion classification datasets. This feedback is clear and actionable, as it directs the authors to revisit and potentially revise their claims based on the contradictory evidence. The comment is fully actionable, providing a detailed explanation of the issues and suggesting that the authors should consider the implications of these results. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of contradictory evidence, such as the performance of AT and GAS models, and suggests that the results do not support the claim that emotionawareness is useful. This level of detail helps the authors understand exactly what needs to be addressed and how to improve their claims. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 6 provides contradictory evidence, specifically mentioning examples where the F1 scores of AT and GAS are lower than expected, suggesting that emotionawareness might not be useful. The claim is supported by specific examples and detailed reasoning, providing a clear and logical basis for the assertion. However, the comment could be strengthened by including references to external works or additional data to further substantiate the claim. Overall, the comment is 4, as it provides a strong basis for the claim but lacks some depth in terms of additional evidence or references.", "helpfulness_rationale": "The review comment provides a detailed analysis of contradictory evidence in Table 6, specifically highlighting instances where the results do not support the claim that emotionawareness is useful for synthetic text detection. It offers specific examples, such as the lower F1 score of AT compared to BERTsynth and the low F1 score of GAS despite finetuning with emotion classification datasets. This feedback is clear and actionable, guiding the authors to reconsider their claims and potentially revise their results or analysis. By pointing out these inconsistencies, the comment effectively helps the authors improve the accuracy and reliability of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting more experiments to address the research question and demonstrate the method\"s generalizability. It recommends testing with various models, such as Vision Transformers (ViT), and including results under more complex input noise models, such as those involving multiplicative distortions. While the comment provides explicit guidance on what additional experiments should be conducted, it lacks specific details on how to implement these suggestions or what specific models or noise models should be used. The action is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting more experiments to address the research question and demonstrates the method\"s generalizability by testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as those involving multiplicative distortions. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. It is specific in detailing what additional experiments should be conducted, such as testing with different models and noise models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting more experiments to address the research question and demonstrates the method\"s generalizability by testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as those involving multiplicative distortions. However, the comment lacks specific examples or references to support the claim that these additional experiments would provide a more comprehensive evaluation. The reasoning is somewhat vague, as it does not provide detailed justification or evidence for why these additional experiments are necessary or beneficial. Therefore, the claim is barely verifiable, aligning with a score of 2.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by recommending additional experiments to address the research question and demonstrate the method\"s generalizability. It suggests testing with various models, such as Vision Transformers (ViT), and including results under more complex input noise models, such as those involving multiplicative distortions. These suggestions are actionable and provide a clear direction for enhancing the comprehensiveness and robustness of the research. However, the comment could be more helpful if it included specific examples of how these experiments should be conducted or what metrics should be used to evaluate the results. Overall, the feedback is 4 as it offers valuable guidance for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the number of human annotators mentioned in the D.2 appendix should be four, based on the author responses. This provides a clear and explicit action for the authors to take, which is to update the appendix to reflect the correct number of annotators. The comment is specific and concrete, as it directly instructs the authors on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the D.2 appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the number of human annotators should be four, based on author responses. This provides a clear direction for the authors to make the necessary changes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the number of human annotators mentioned in the D.2 appendix should be four, based on author responses. This claim is 3 as it provides a specific suggestion for updating the appendix, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to refer to the author responses to understand the basis of this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out an inconsistency in the number of human annotators mentioned in the D.2 appendix, suggesting that it should be four based on author responses. This feedback is clear and actionable, as it provides a specific correction that the authors can easily implement. By addressing this inconsistency, the authors can improve the accuracy and consistency of their paper. The comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it suggested additional areas for attention or provided more detailed guidance. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not provide explicit guidance on how to improve the motivation or what specific aspects need to be addressed. The action is implicit, as the authors would need to infer that they should provide a more detailed explanation of the motivation behind the encoder and decoder structure. While the comment is 3, it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not specify which part of the paper this motivation is intended for, making it weakly grounded. The comment is specific in its suggestion to improve the motivation, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to understand where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered verifiable. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to develop this motivation. The comment is 3 as it points out a relevant aspect that could be addressed to improve the clarity and impact of the paper, but it does not provide detailed feedback or actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the novelty of the explored loss functions, noting that they are not new and that the conducted attacks are primarily whitebox with a lack of blackbox evaluation. It also suggests that the paper should consider extending the analysis to targeted attacks to better showcase the strength of the proposed attack method. While the comment identifies specific issues and areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take to enhance their draft. The actions are implicit and somewhat vague, as the authors are left to infer how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the novelty of the explored loss functions, specifically mentioning JS divergence, masked CE loss, and masked spherical loss. It highlights that these loss functions are not new and suggests that the conducted attacks are primarily whitebox with a lack of blackbox evaluation. The comment also recommends extending the analysis to targeted attacks to showcase the strength of the proposed attack method. However, the comment does not specify which part of the paper discusses the loss functions or the attacks, making it weakly grounded. It is specific in detailing the issues with the novelty and the limitations of the attacks, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the novelty of the explored loss functions, specifically mentioning JS divergence, masked CE loss, and masked spherical loss. It claims that these loss functions are not new and suggests that the conducted attacks are primarily whitebox with a lack of blackbox evaluation. The comment also recommends extending the analysis to targeted attacks. However, the claim about the novelty of the loss functions is not substantiated with specific references or detailed explanations, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or examples weakens the verifiability of the claim. Therefore, the comment is rated as 2, as it provides some basis for concern but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises several concerns about the novelty of the explored loss functions, noting that they are not new and that the conducted attacks are primarily whitebox with a lack of blackbox evaluation. It also suggests extending the analysis to targeted attacks to better showcase the strength of the proposed attack method. While the comment identifies specific areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take to enhance their draft. The feedback is 3 as it points out important limitations and areas for further exploration, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the results for CIFAR10 are not impressive compared to other approaches mentioned in the paper. It suggests that a direct comparison is absolutely necessary and that the authors should also include results for CIFAR100. While the comment implies that the authors should conduct these comparisons, it does not provide explicit instructions on how to perform them or what specific aspects of the results need to be improved. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CIFAR10\" and \"CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out that the results for CIFAR10 are not impressive and suggests a direct comparison with other approaches, as well as the inclusion of results for CIFAR100. This provides clear guidance on what needs to be addressed and why. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for CIFAR10 are not impressive and suggests a direct comparison with other approaches. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to other approaches mentioned in the paper. It suggests that a direct comparison is necessary and that the authors should also include results for CIFAR100. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included suggestions on how to present or analyze the results to highlight their significance. Overall, the comment is 4 as it directs the authors to address a critical aspect of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a known property of hyperbolic space, stating that it is wellsuited for hierarchical datasets. However, it points out that the experiments do not clearly demonstrate this suitability. While the comment identifies a gap in the experimental evidence, it does not provide explicit guidance on how the authors should address this issue or what specific experiments could be added to demonstrate the suitability of hyperbolic space. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more evidence to support the claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"hyperbolic space\" and its suitability for hierarchical datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a known property of hyperbolic space and points out that the experiments do not clearly demonstrate this suitability. This provides clear guidance on what needs to be addressed in the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"It is known that hyperbolic space is well suited for hierarchical dataset, however, none of the experiments clearly demonstrate this.\" This statement is based on a known property of hyperbolic space and the lack of experimental evidence to support it. However, the comment does not provide specific examples or references to substantiate the claim, making it 3. The authors would need to infer the basis of the claim and potentially seek additional evidence to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, noting that while it is known that hyperbolic space is wellsuited for hierarchical datasets, the experiments do not clearly demonstrate this suitability. This feedback is 3 as it highlights a gap in the experimental evidence and suggests that the authors should consider adding experiments to better support their claims. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct such experiments. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises several questions about the main strength of MixBoost, specifically in relation to computational savings, generalization performance, and the use of Random Fourier Features. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to these questions. The comment lacks guidance on how the authors might address these questions or what specific aspects they should focus on. As a result, the authors are left without a clear understanding of what to do next, making the comment 1. Therefore, this comment aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment raises questions about the main strength of MixBoost, specifically in relation to computational savings, generalization performances, and the use of Random Fourier Features. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections or aspects being discussed. The comment is 1 as it lacks explicit references to specific sections, tables, or figures. Additionally, it does not provide specific guidance on how to address these questions or what aspects of the method should be emphasized. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the main strength of MixBoost, specifically in relation to computational savings, generalization performances, and the use of Random Fourier Features. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive, asking for clarification rather than making assertions or recommendations. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises several questions about the main strength of MixBoost, specifically in relation to computational savings, generalization performances, and the use of Random Fourier Features. While it identifies areas where the authors might need clarification, it does not provide any suggestions or guidance on how to address these questions or improve the paper. The feedback is 3 as it points out specific areas that require further explanation, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the wording used in line 243, suggesting that it is hard to understand. It also offers an alternative approach to avoid the use of a smaller training set by training the network with optimal parameters on the complete train+val. However, the comment does not explicitly instruct the authors to revise the wording or provide specific guidance on how to implement the suggested alternative. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue raised in line 243, which is the wording used to describe the use of the test set for hyperparameter tuning. It also suggests an alternative approach to avoid the use of a smaller training set. However, the comment does not explicitly mention the section or line number where the issue is discussed, making it weakly grounded. The comment is specific in detailing the concern about the wording and the suggestion to use the complete train+val set. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the wording used in line 243, suggesting that it is hard to understand. It also offers an alternative approach to avoid the use of a smaller training set by training the network with optimal parameters on the complete train+val. However, the comment lacks specific examples or references to support the claim that the wording is hard to understand or that the alternative approach is superior. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording used in line 243, noting that it is hard to understand. It also suggests an alternative approach to avoid the use of a smaller training set by training the network with optimal parameters on the complete train+val set. While the comment provides a clear observation and a potential solution, it lacks depth and specificity, as it does not elaborate on why the current wording is problematic or how the suggested alternative would improve the paper. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction is obscure and highlevel, lacking detailed elaboration on the implementation of tokenization and the use of DDPM for parameter prediction. While the comment provides a general direction for improvement, it does not explicitly instruct the authors on how to incorporate these suggestions or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more details about tokenization and DDPM usage. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction is obscure and highlevel, lacking detailed elaboration on the implementation of tokenization and the use of DDPM for parameter prediction. However, it does not specify which part of the introduction is obscure or highlevel, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment provides some guidance on what could be added, it lacks specificity in terms of which sections or aspects of the introduction require more detail. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the introduction is obscure and highlevel, lacking detailed elaboration on the implementation of tokenization and the use of DDPM for parameter prediction. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or examples, the claim remains 3, as the authors may need to infer the basis of the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the introduction, noting that it is obscure and highlevel, lacking detailed elaboration on the implementation of tokenization and the use of DDPM for parameter prediction. This feedback is valuable as it provides a clear direction for improvement, suggesting that the authors should include more specific details about these aspects. However, the comment could be more helpful if it offered additional guidance on how to incorporate these suggestions or provided examples of what kind of elaboration would be beneficial. Overall, the comment is 4, as it highlights a critical area for improvement and encourages the authors to enhance the clarity and depth of their introduction."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses dissatisfaction with the presentation of the paper but does not provide any specific suggestions or guidance on how to improve it. The comment lacks actionable information, leaving the authors without a clear understanding of what aspects of the presentation need to be addressed. As a result, the authors are left without any concrete steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses dissatisfaction with the presentation of the paper but does not specify which part of the paper is affected or what aspects need improvement. It lacks grounding as the authors cannot confidently determine which section or part of the paper is being referred to. Additionally, the comment is vague and does not provide specific suggestions or guidance on how to improve the presentation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the presentation of the paper, stating that it is \"not good.\" However, it lacks any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the presentation is considered unsatisfactory. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the presentation of the paper, stating that it is \"not good.\" However, it lacks specific details or suggestions on how the presentation could be improved. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation need attention. This comment is 2 as it identifies a general issue but does not provide any concrete steps or insights for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific omission in the related work section, noting that the authors have missed citing the work by Rieck et al. [2] regarding the correlation of topological complexity with generalization ability. This feedback is explicit and provides a clear action for the authors to take, which is to include the mentioned work in their related work section. The comment is specific and concrete, as it directly points out the missing citation and its relevance to the topic. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific omission in the related work section, namely the missing citation of Rieck et al. [2] regarding the correlation of topological complexity with generalization ability. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have missed citing the work by Rieck et al. [2] regarding the correlation of topological complexity with generalization ability. This claim is 3 as it points out a specific omission in the related work section. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would benefit from providing more context or evidence to support the claim, such as explaining why this specific work is relevant and how its inclusion would enhance the paper.", "helpfulness_rationale": "The review comment identifies a specific omission in the related work section, noting that the authors have missed citing the work by Rieck et al. [2] regarding the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it provides a specific suggestion for improvement. By including the mentioned work, the authors can enhance the comprehensiveness and depth of their related work section, which is crucial for contextualizing their research. However, the comment could be more helpful if it provided additional context or guidance on how to integrate the cited work into the discussion. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the usefulness of the exploration parameter gamma in the context of only providing upperbounds on the pseudoregret. It suggests that the choice gamma=0 might be optimal and proposes that a remark on highprobability upperbounds and the role of gamma could be interesting. The comment also asks whether the analysis, which is heavily based on expectations, can be extended to highprobability bounds on the regret. While the comment identifies a potential area for improvement and suggests specific aspects to consider, it does not provide explicit instructions on how to address these points or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors need to infer how to incorporate the suggested remarks and explore the possibility of extending the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Alg 1 and Thm 3.1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the usefulness of the exploration parameter gamma and the potential for extending the analysis to highprobability bounds on the regret. This level of detail provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the usefulness of the exploration parameter gamma in the context of only providing upperbounds on the pseudoregret. It suggests that the choice gamma=0 might be optimal and proposes that a remark on highprobability upperbounds and the role of gamma could be interesting. The comment also asks whether the analysis, which is heavily based on expectations, can be extended to highprobability bounds on the regret. While the comment raises a valid point about the potential usefulness of gamma, it does not provide specific evidence or references to support the claim that the analysis could be extended to highprobability bounds. The reasoning is somewhat logical but lacks detailed justification or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the exploration parameter gamma in the context of only providing upperbounds on the pseudoregret. It questions the usefulness of gamma=0 and suggests that a remark on highprobability upperbounds and the role of gamma could be interesting. The comment also raises a question about whether the analysis, which is heavily based on expectations, can be extended to highprobability bounds on the regret. This feedback is 3 as it points out a potential area for further exploration and suggests specific aspects that the authors could consider. However, it lacks detailed guidance or suggestions on how to address these points, which could limit its impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to address a specific issue on line 150, where the LCA relaxation was referenced but not defined. It provides a clear action: either to add a restatement of the definition from Wang et. al in the body of the paper or to add a description to the appendix. This direct instruction makes the action concrete and explicit, allowing the authors to understand exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the LCA relaxation was referenced but never directly defined, and it provides a concrete suggestion to address this by either restating the definition from Wang et. al in the body of the paper or adding a description to the appendix. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point claims that the LCA relaxation was referenced but never directly defined on line 150. This is a factual observation that requires no additional evidence or reasoning to be understood. The comment is clear and specific, making it 5. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue in the paper, namely that the LCA relaxation was referenced but not directly defined. It provides a clear and actionable suggestion for improvement by instructing the authors to either add a restatement of the definition from Wang et. al in the body of the paper or to include a description in the appendix. This feedback is precise and directly addresses a potential gap in the paper, allowing the authors to make necessary revisions and enhance the clarity and completeness of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the dataset description is thorough but implies that more information on how validation and test splits influence model training could strengthen reproducibility. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include this information or specify how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should add details about the influence of validation and test splits on model training. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that while the dataset is thoroughly described, more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper discusses the dataset or where the influence of validation and test splits is mentioned. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs improvement. The comment is specific in its suggestion but weakly grounded as it does not provide clear guidance on where to add the information. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset description is thorough but implies that more information on how validation and test splits influence model training could strengthen reproducibility. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that more information on how validation and test splits influence model training could strengthen reproducibility. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance the clarity and reproducibility of their work. However, the comment could be more helpful if it offered additional guidance on how to incorporate this information or suggested specific ways to improve the description of the dataset. Despite this, the comment is 4 as it provides a valuable insight for the authors to consider in their revisions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" decision to limit the scope of regularization techniques to dropout, suggesting that other techniques like L2 regularization, data augmentation, and adding noise should be considered. It also raises a practical concern about the combination of ZeroLiers with these techniques. However, the comment does not provide explicit guidance on how the authors should address these points or what specific actions they should take. The suggestion is implicit and lacks concrete details, making it difficult for the authors to know exactly how to respond or improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the authors\" decision to limit the scope of regularization techniques to dropout, suggesting that other techniques like L2 regularization, data augmentation, and adding noise should be considered. It also raises a practical concern about the combination of ZeroLiers with these techniques. However, the comment does not specify which part of the paper discusses regularization techniques or where the authors address the overfitting problem. This lack of grounding makes it challenging for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its suggestions, the absence of explicit references to the paper makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" decision to limit the scope of regularization techniques to dropout, suggesting that other techniques like L2 regularization, data augmentation, and adding noise should be considered. It also raises a practical concern about the combination of ZeroLiers with these techniques. However, the comment does not provide any specific reasoning, examples, or references to support why these other techniques should be considered or how they might impact the results. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" decision to limit the scope of regularization techniques to dropout. It questions the rationale behind this choice and suggests considering other techniques like L2 regularization, data augmentation, and adding noise. The comment also highlights a practical concern about the combination of ZeroLiers with these techniques, which could provide valuable insights for the authors. However, the comment lacks specific guidance or suggestions on how the authors might address these points or what experiments could be conducted to explore these techniques. While it identifies an area for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the generalizability of Assumption A from a tabular setting to a function approximation setting. It suggests that the authors should discuss this generalization, as they have mentioned it in the section about consistency. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the assumption need to be discussed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and refers to the section about consistency, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests discussing the generalization of the assumption from a tabular setting to a function approximation setting, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of Assumption A from a tabular setting to a function approximation setting. It suggests that the authors should discuss this generalization, as they have mentioned it in the section about consistency. However, the comment does not provide any specific reasoning, examples, or references to support why this generalization is important or how it should be addressed. The lack of detailed justification makes the claim 3, as the authors are left to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the generalizability of Assumption A from a tabular setting to a function approximation setting. It suggests that the authors should discuss this generalization, as they have mentioned it in the section about consistency. This feedback is clear and actionable, providing the authors with a specific direction to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to approach the generalization or what aspects of the assumption need to be discussed. Overall, the comment is 4 as it highlights a crucial area for improvement and encourages the authors to expand their discussion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit guidance on how to improve the presentation of the paper. It suggests that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a twocolumn width. Additionally, it notes that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. These suggestions are clear and actionable, providing the authors with specific steps to take to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures, especially 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the figures, suggesting that they would benefit from a twocolumn width. The comment is specific in detailing what needs to be addressed, such as straightening up the content to improve understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the presentation of Table 1 and figures, suggesting that they should be adjusted for clarity. However, it does not provide specific reasoning or examples to support why these adjustments are necessary or how they would improve the paper. The comment lacks detailed justification or references, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific feedback on the presentation of Table 1 and figures, suggesting that they should be adjusted for clarity. It also notes that the paper was not easy to understand during the first read, indicating a need for improvement in the overall presentation. While the comment offers actionable suggestions, such as adjusting the width of figures and improving the overall clarity, it could be more helpful if it provided more detailed guidance on how to achieve these improvements. For instance, it could suggest specific techniques for improving the layout or clarity of the figures. However, the feedback is 4 as it directs the authors towards areas that need attention, making it a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests a modification to the TextDPO baseline by using generated images for additional imagequestionanswer triplets. It implies that the performance benefit might be due to the perturbed images rather than the specific DPO objective. However, the comment does not provide explicit guidance on how the authors should implement this suggestion or what specific changes to make to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests a modification to the TextDPO baseline by using generated images for additional imagequestionanswer triplets. It implies that the performance benefit might be due to the perturbed images rather than the specific DPO objective. However, the comment does not specify which part of the paper this suggestion relates to, such as a specific section or table. This lack of grounding makes it difficult for the authors to understand where to address the feedback. While the comment is specific in its suggestion, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a modification to the TextDPO baseline by using generated images for additional imagequestionanswer triplets. It implies that the performance benefit might be due to the perturbed images rather than the specific DPO objective. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or logical arguments to substantiate the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a modification to the TextDPO baseline by using generated images for additional imagequestionanswer triplets. It implies that the performance benefit might be due to the perturbed images rather than the specific DPO objective. However, the comment lacks specific guidance on how the authors should implement this suggestion or what changes to make to their draft. It does not provide detailed reasoning or examples to support the claim, leaving the authors with limited actionable feedback. As a result, the comment is 2, as it does not offer a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption made regarding the expertise levels of Alice and Bob in a humanAI collaboration scenario. It suggests that this assumption might not hold in many realworld tasks where nonlinear interactions between success rate and speedup could occur due to varying expertise levels. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or revise their assumptions. The action is implicit, as the authors would need to infer that they should consider the possibility of different expertise levels and their impact on the task. The lack of concrete guidance makes the action somewhat vague and challenging to implement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific assumption made in the paper regarding the expertise levels of Alice and Bob in a humanAi collaboration scenario. It highlights that the assumption might not hold in many realworld tasks where nonlinear interactions between success rate and speedup could occur due to varying expertise levels. However, the comment does not explicitly mention which part of the paper discusses this assumption, making it weakly grounded. It is specific in detailing the issue with the assumption, but without clear references, the authors may find it challenging to pinpoint the exact section to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption made regarding the expertise levels of Alice and Bob in a humanAI collaboration scenario. It suggests that this assumption might not hold in many realworld tasks where nonlinear interactions between success rate and speedup could occur due to varying expertise levels. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the assumption made regarding the expertise levels of Alice and Bob in a humanAI collaboration scenario. It points out that the assumption might not hold in many realworld tasks where nonlinear interactions between success rate and speedup could occur due to varying expertise levels. This feedback highlights a potential limitation in the paper\"s assumptions and suggests that the authors should consider the implications of different expertise levels on their work. However, the comment could be more helpful if it provided specific examples or guidance on how the authors might address this issue or revise their assumptions. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed suggestions for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the generalizability of the mitigation strategies, specifically mentioning that sanitizing data might be datasetspecific and not applicable to other LLMs or datasets. While the comment identifies a potential issue with the current draft, it does not provide explicit guidance on how the authors should address this concern or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should consider making the mitigation strategies more general or exploring alternative approaches. However, the lack of concrete suggestions or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the generalizability of the mitigation strategies, specifically mentioning that sanitizing data might be datasetspecific and not applicable to other LLMs or datasets. However, it does not specify which part of the paper discusses the mitigation strategies or the framework\"s generalizability. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in identifying the issue with the generalizability of the mitigation strategies, but without explicit references to the paper, it is difficult for the authors to pinpoint the exact area that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation strategies, such as sanitizing the data, might be datasetspecific and not applicable to other LLMs or datasets, limiting the generalizability of the framework. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the claim is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a critical limitation of the mitigation strategies, specifically that sanitizing data might be datasetspecific and not applicable to other LLMs or datasets. This observation highlights a significant concern regarding the generalizability of the framework, which is a crucial aspect for its applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the generalizability of their approach. While it points out a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should consider making the mitigation strategies more general or exploring alternative approaches to improve the framework\u2019s applicability. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper is not sufficiently clear in some aspects and provides a list of questions to address these issues. However, it does not explicitly instruct the authors to address these questions or provide specific guidance on how to improve the clarity of the paper. The action is implicit, as the authors can infer that they need to address the questions raised in the review point to enhance the clarity of their paper. However, the lack of concrete instructions or detailed guidance on how to address these questions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is unclear or provide a list of questions that need to be addressed. The authors cannot confidently determine which sections or aspects of the paper are unclear, making it difficult to identify the specific areas that require attention. Additionally, the comment lacks specificity, as it does not detail what aspects of the paper are unclear or what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not sufficiently clear in some aspects, but it does not provide specific examples or detailed reasoning to support this claim. Without concrete examples or references, the authors may find it challenging to understand the nature of the unclear aspects and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the paper, noting that it is not sufficiently clear in some aspects. However, the comment lacks specific details or examples to guide the authors on how to improve the clarity of their work. While it provides a general direction for improvement, it does not offer actionable feedback or suggestions that would help the authors address the identified weaknesses. As a result, the comment is 3, as it highlights an area for improvement but does not provide comprehensive guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the specific task being performed by the participants. While it prompts the authors to clarify these aspects, it does not provide explicit instructions or suggestions on how to address these questions. The authors are left to infer that they need to provide more context and detail regarding the audio signals and the task, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the specific task being performed by the participants. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact section or figure being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the specific task being performed by the participants. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, lacking any assertion or guidance that would need to be substantiated. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the specific task being performed by the participants. While it identifies areas where clarification is needed, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by pointing out that the authors did not address other problems in open domain dialogue, such as memory to register, personalize to user characteristics, reasoning over common sense and facts. However, it does not provide any explicit or implicit actions for the authors to take to address this gap. The comment lacks guidance on how the authors might explore or incorporate these additional aspects into their work. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what problems the authors should tackle or how they might address them. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not tackle other problems in open domain dialogue, such as memory to register, personalize to user characteristics, reasoning over common sense and facts. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism or how to address it. Without detailed examples or evidence, the claim is 1, as it is based on an assumption without sufficient justification.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors did not address other problems in open domain dialogue, such as memory to register, personalize to user characteristics, reasoning over common sense and facts. This feedback highlights an area where the authors could potentially expand their work to enhance its comprehensiveness and impact. However, the comment lacks specific suggestions or guidance on how the authors might address these additional aspects. While it provides a clear direction for improvement, the absence of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a meaningful area for enhancement but does not provide detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the lack of statistical distribution of papers across different venues, specifically mentioning ACL, EMNLP, and Arxiv. It questions the significance of the results presented, particularly those from Arxiv papers, due to the lack of peerreviewed status and the potential for lowquality content. However, the comment does not provide explicit guidance on how the authors should address these issues or what steps they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the lack of statistical distribution of papers across different venues, specifically mentioning ACL, EMNLP, and Arxiv. It questions the significance of results from Arxiv papers, which are not peerreviewed, and suggests that these results might not be considered significant. However, the comment does not specify which part of the paper discusses the distribution of papers across venues or how the authors should address this issue. The lack of specific guidance makes it challenging for the authors to understand which sections need revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the lack of statistical distribution of papers across different venues, specifically mentioning ACL, EMNLP, and Arxiv. It questions the significance of results from Arxiv papers, which are not peerreviewed, and suggests that these results might not be considered significant. However, the comment does not provide specific examples or references to support the claim that Arxiv papers are not considered formal publications or that they are \"junk\" and do not represent severe writing. This lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises concerns about the lack of statistical distribution of papers across different venues, specifically mentioning ACL, EMNLP, and Arxiv. It questions the significance of results from Arxiv papers, which are not peerreviewed, and suggests that these results might not be considered significant. The comment also expresses reservations about including Arxiv papers in the study, noting that most of these papers are of low quality and do not represent severe writing. However, the comment lacks specific guidance on how the authors should address these issues or what steps they should take to improve their draft. While it identifies a potential weakness in the paper\"s analysis, it does not provide actionable feedback or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should focus more on the proposed problem and framework, rather than spending excessive time on applications. While it provides a general direction for improvement, it does not specify which aspects of the problem and framework need more attention or how the authors should adjust their focus. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should focus more on the proposed problem and framework, rather than spending much space on applications. However, it does not specify which part of the paper discusses the applications or the proposed problem and framework. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting a shift in focus, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should focus more on the proposed problem and framework rather than spending excessive time on applications. However, the comment lacks specific details or examples to support this claim. It does not provide any reasoning or references to justify why the focus should be shifted, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending excessive time on applications. This feedback provides a clear direction for improvement, indicating that the authors should prioritize the core aspects of their work. However, the comment lacks specific details or suggestions on how to achieve this balance, which limits its helpfulness. While it offers a general idea, it does not provide actionable guidance or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the paper is marginally above the acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any specific actions or suggestions for improvement. The comment lacks guidance on what aspects of the paper need further attention or enhancement to meet the acceptance criteria. As a result, the authors are left without a clear direction for how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It only mentions that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide specific details or examples of what needs to be addressed. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is marginally above the acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment does not provide any specific evidence or reasoning to support this claim. It lacks detailed justification or examples to substantiate the assertion that the paper meets the acceptance criteria. As a result, the claim is 1, making the comment unsuitable for guiding the authors to improve their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment indicates that the paper is marginally above the acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment does not provide specific feedback or suggestions on how the authors might further improve their draft to meet the acceptance criteria. It lacks actionable guidance, such as identifying specific areas that need refinement or additional discussion. Without concrete advice or constructive feedback, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also notes that the natural language is generated by patterns, making natural language understanding easy. The comment further implies that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters as tools. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to improve the dataset or the paper to enhance its research impact. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the simplicity of the current dataset might limit its research impact, as future studies could follow the path of the GSM8K dataset using methods like PAL or LLMs with code interpreters. However, the comment does not specify which part of the paper discusses the dataset or the methods mentioned, making it weakly grounded. It is specific in suggesting that the paper may have limited research impact, but without clear references, the authors cannot confidently identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the simplicity of the current dataset might limit its research impact, suggesting that future studies could follow the path of the GSM8K dataset using methods like PAL or LLMs with code interpreters. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument or how to address it. The reasoning is vague and does not provide a clear path for the authors to respond or improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the research impact of the current dataset, suggesting that it might be too simple and could be addressed by following the path of the GSM8K dataset using methods like PAL or LLMs with code interpreters. This feedback provides a clear direction for the authors to consider expanding the scope or complexity of their dataset to enhance its research impact. However, the comment could be more helpful if it offered specific suggestions or guidance on how to implement these ideas, such as providing examples of how to translate natural language into <source, path, destination> triples or how to use code or search libraries effectively. Overall, the comment is 3 as it highlights an important area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests revising a specific statement in the paper, indicating that the authors should address the issue of the limitations of the proposed measure. It provides a clear action by instructing the authors to revise the statement and discuss the limitations more thoroughly. The comment also mentions that the proposed measure does not provide a stronger theoretical connection to generalization or outperform other measures experimentally, which provides a concrete direction for improvement. Therefore, this comment is 5 as it provides explicit guidance on what needs to be addressed and how to do it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections of the paper being addressed (25 and 242), allowing the authors to accurately identify the parts being discussed. It also specifies what needs to be addressed, namely the revision of a statement regarding maximum likelihood estimation and the discussion of the limitations of the proposed measure. The comment is specific in detailing the issues with the current presentation and suggesting that the authors should provide a stronger theoretical connection to generalization and demonstrate the measure\"s outperformance experimentally. This level of detail provides clear guidance for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not adequately discuss the limitations of the proposed measure, specifically noting that it does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. The comment provides a logical reasoning by pointing out the lack of discussion and suggesting that the authors should address these limitations. However, it does not provide specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the discussion of the limitations of the proposed measure is not adequately addressed. It points out that the paper does not provide a stronger theoretical connection to generalization or demonstrate the measure\"s outperformance experimentally. This feedback is clear and actionable, as it directs the authors to revise the discussion of the limitations and provide additional evidence to support their claims. By highlighting these specific areas for improvement, the comment offers valuable guidance for enhancing the paper\"s clarity and rigor. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant gap in the paper by pointing out the absence of results from finetuned opensource LLMs, which is crucial for a domainspecific benchmark. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should include these results, but it does not offer guidance on how to do so or what specific aspects of the results should be included. Without concrete instructions or suggestions, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of results from finetuned opensource LLMs, which is important for a domainspecific benchmark. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where to address the problem. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks results from finetuned opensource LLMs, which is important for a domainspecific benchmark. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the significance of the missing results or how they impact the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of results from finetuned opensource LLMs, which is crucial for a domainspecific benchmark. This feedback highlights an important aspect that the authors may have overlooked, suggesting that including these results would enhance the paper\"s relevance and impact. However, the comment lacks specific guidance on how to incorporate these results or what particular aspects of the results should be included. While it provides a clear direction for improvement, the lack of detailed suggestions or examples makes it 3. Therefore, the comment aligns with a score of 3, as it offers a meaningful insight but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the training process of the regression model, including the input and output, the parameter space differences for models with varying feature sizes, and the impact of parameter count on model performance. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or incorporate them into their draft. The questions are clear and specific, but the lack of actionable guidance leaves the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on how to implement them.", "grounding_specificity_rationale": "The comment raises several questions about the training process of the regression model, including the input and output, the parameter space differences for models with varying feature sizes, and the impact of parameter count on model performance. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the training process of the regression model, including the input and output, the parameter space differences for models with varying feature sizes, and the impact of parameter count on model performance. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or feedback that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises several questions about the training process of the regression model, including the input and output, the parameter space differences for models with varying feature sizes, and the impact of parameter count on model performance. While these questions highlight areas where the authors might need to provide more detail or clarification, they do not offer specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the operator after w_i in equation 6 should be the multiplication of the underlying vector space instead of the cross product. It provides a specific reason for this suggestion, stating that the operator is between a scalar and a tensor, not just two scalars. This explicit action and detailed reasoning allow the authors to directly understand how to modify their equations. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and detailed explanation of the issue, specifying that the operator should be the multiplication of the underlying vector space rather than the cross product. This level of detail helps the authors understand exactly what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the operator after w_i in equation 6 should be the multiplication of the underlying vector space instead of the cross product. It provides a specific reason for this claim, explaining that the operator is between a scalar and a tensor, not just two scalars. This reasoning is logical and detailed, making the claim 5. The comment is clear and provides a clear justification for the suggested change, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the equations, noting that the operator after w_i should be the multiplication of the underlying vector space rather than the cross product. It provides a clear explanation of why this correction is necessary, as the operator is between a scalar and a tensor, not just two scalars. This feedback is actionable and detailed, offering the authors a specific direction to improve their equations. However, it could be more helpful if it suggested alternative ways to approach the problem or provided additional context. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more ablation experiments to demonstrate the effectiveness of the proposed model. It provides specific examples of what these experiments should include, such as the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This explicit guidance on what additional experiments to conduct and why they are necessary makes the comment 5. The authors know exactly how to apply the suggested action to improve their draft.", "grounding_specificity_rationale": "The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper these experiments should be added to or which sections of the paper are being discussed. This lack of grounding makes it difficult for the authors to identify the exact areas where the additional experiments should be conducted. While the comment is specific about the type of experiments needed, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should add more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, the comment does not provide any specific reasoning, examples, or references to support why these additional experiments are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by adding more ablation experiments. It highlights the need to demonstrate the effectiveness of the proposed model by exploring the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback is actionable and constructive, as it guides the authors on what additional experiments to conduct to strengthen the paper. However, the comment could be more helpful if it provided more detailed guidance on how to design these experiments or what specific metrics to use. Overall, the comment is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from related works as baseline approaches. While the comment provides a clear direction for improvement, it does not specify which aspects of the experimental setup need to be altered or how the authors should implement these suggestions. The action is explicit but somewhat vague, as it lacks detailed guidance on how to conduct the experiments with more complex datasets or how to compare the proposed approach with the suggested baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from related works as baseline approaches. However, the comment does not specify which part of the paper discusses the experimental setup or results, making it weakly grounded. It is specific in suggesting improvements and providing examples of more complex datasets and learning tasks, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from related works as baseline approaches. While the comment provides a rationale for improving the experimental setup, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use more complex datasets and learning tasks is logical but could be strengthened with additional justification or references. Therefore, the comment is 3, as it provides a basis for improvement but requires further elaboration or evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experimental results by suggesting the use of more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from related works as baseline approaches for comparison. While the comment provides a clear direction for enhancing the experimental setup, it lacks specific guidance on how to implement these suggestions or what specific aspects of the current experiments need to be addressed. The feedback is 3 as it offers a general idea of improvement but could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results, specifically questioning whether the PRESENCE method is sufficiently justified based on the relationship between temperature $\tau$ and downstream performance in Figure 5. It suggests that the results do not convincingly demonstrate the importance of reweighting using a positive or negative $\tau$ and that the crosslingual zeroshot transfer results in Table 4 do not show an advantage. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the experimental results, specifically questioning the justification for PRESENENCE based on the relationship between temperature $\tau$ and downstream performance in Figure 5. It also mentions the lack of advantage in crosslingual zeroshot transfer results in Table 4. However, the comment does not specify which parts of the paper these figures and tables are located in, making it difficult for the authors to pinpoint the exact sections being discussed. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the experimental results, specifically questioning the justification for PRESENCE based on the relationship between temperature $\tau$ and downstream performance in Figure 5. It suggests that the results do not convincingly demonstrate the importance of reweighting using a positive or negative $\tau$ and that the crosslingual zeroshot transfer results in Table 4 do not show an advantage. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3, as it provides a general idea of the issue but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the experimental results, specifically questioning the justification for PRESENCE based on the relationship between temperature $\tau$ and downstream performance in Figure 5. It suggests that the results do not convincingly demonstrate the importance of reweighting using a positive or negative $\tau$, and the crosslingual zeroshot transfer results in Table 4 do not show an advantage. This feedback is 3 as it identifies areas where the authors\" results may need further justification or clarification. However, the comment lacks detailed guidance on how the authors might address these concerns or what specific improvements could be made to their methodology or results. Without more specific suggestions or examples, the feedback is 3 but could be more impactful with additional detail."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation in Table 2, noting that the results for k=1 are better than the baselines. It suggests that this might indicate a different reason for the performance gain compared to applying Eq. 10. However, the comment does not provide explicit guidance on what action the authors should take to address this observation or how to explore the potential reasons for the performance gain. The suggestion is implicit and lacks concrete details, making it difficult for the authors to understand how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation in the table, noting that the results for k=1 are better than the baselines and suggests that this might indicate a different reason for the performance gain compared to applying Eq. 10. This provides clear guidance on what aspect of the results needs further exploration. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for k=1 in Table 2 are better than the baselines, suggesting that the performance gain might be due to a reason different from applying Eq. 10. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out an interesting observation in Table 2, where the results for k=1 are better than the baselines. It suggests that this might indicate a different reason for the performance gain compared to applying Eq. 10. While the comment highlights a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might investigate or address this observation. The feedback is 3 as it identifies a noteworthy aspect of the results, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of justification for the choice of mixedinteger programming in the proposed method. It points out that the advantages of this approach over alternative methods are not clearly explained. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve the justification of their method. The action is implicit but vague, as it does not specify what needs to be done to strengthen the justification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of justification for the choice of mixedinteger programming in the proposed method, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the need for a clearer justification of the choice of mixedinteger programming and its advantages over alternative approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks solid grounding, specifically regarding the choice of mixedinteger programming. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, specifically the lack of justification for the choice of mixedinteger programming. It highlights that the advantages of this approach over alternative methods are unclear, which is a critical point for the authors to address. However, the comment does not provide any suggestions or guidance on how the authors might strengthen the justification for their method or explore alternative approaches. While it points out a crucial weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear area for improvement but lacks depth and guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the confusing notation in Equation 1 and the missing reference for Pedersen et al 2007. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should clarify the notation and ensure the reference is included. This lack of explicit guidance makes the comment 3, as the authors can deduce the necessary actions but do not have detailed instructions on how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the confusing notation in Equation 1 and the missing reference for Pedersen et al 2007. It provides explicit references to specific parts of the paper, such as Equation 1 and Line 361, which allows the authors to accurately identify the sections being discussed. Additionally, it specifies the issue with the reference, indicating that the paper is missing a citation. This comment is 5, as it clearly identifies the parts of the paper that need attention and specifies what is missing. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the notation in Equation 1 is confusing, specifically mentioning the use of \"c\" instead of \"o\". This is a subjective observation about the clarity of notation. However, the comment does not provide any evidence or reasoning to support why this notation is confusing or how it affects the understanding of the paper. Similarly, it points out that the reference \"Pedersen et al 2007\" is missing from the reference section, but it does not explain why this omission is significant or how it impacts the paper. Without additional context or justification, the claims are not 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the confusing notation in Equation 1 and the missing reference for Pedersen et al 2007. While the comment points out these areas for improvement, it does not provide detailed guidance on how to address these issues. The authors are left to infer that they should clarify the notation and ensure the reference is included, but without explicit instructions or suggestions, the feedback is somewhat limited in its helpfulness. Therefore, the comment is rated as 3, as it offers some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the novelty of the second contribution, suggesting that the combination of SSMs with Attention has been proposed before in MEGA and Blockstate Transformer. It also points out that the architecture in Figure 5 is very similar to the proposed architecture in Mega, and the similarities and differences between S++ and this work should be discussed thoroughly and ablated. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The authors are left to infer that they need to discuss the similarities and differences and conduct ablation studies, but the lack of concrete instructions makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second contribution of the paper and the specific works, MEGA and Blockstate Transformer, which are cited and discussed. It also refers to Figure 5, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, including the similarities and differences between S++ and the work, and the need for thorough discussion and ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second contribution of the paper, which involves combining SSMs with Attention, is not new and has been proposed before in MEGA and Blockstate Transformer. It provides specific references, including a citation in the results section and a link to a paper on Blockstate Transformer. The comment also notes that the architecture in Figure 5 is very similar to the proposed architecture in Mega, suggesting that the authors should discuss and ablate these similarities. While the claim is supported by references, it lacks detailed reasoning or examples to fully substantiate the assertion of novelty. Therefore, the comment is 4, as it provides some evidence but could be strengthened with more detailed explanations or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the second contribution of the paper, specifically the combination of SSMs with Attention. It points out that this idea has been proposed before in MEGA and Blockstate Transformer, and that the architecture in Figure 5 is very similar to the proposed architecture in Mega. The comment suggests that the authors should discuss and ablate these similarities and differences, which is a constructive piece of feedback. However, the comment could be more helpful by providing specific guidance on how to address these issues or by suggesting additional experiments or analyses that could strengthen the paper. Overall, the comment is 3 as it highlights important areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind reporting results on knowledge transfer only in a few select environments. While it prompts the authors to consider why this decision was made, it does not provide explicit guidance on how to address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should provide a rationale for their choice of environments. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment questions the rationale behind reporting results on knowledge transfer only in a few select environments, specifically mentioning section 4.3. This provides full grounding as the authors can accurately identify the section being addressed. The comment is specific in that it asks for a justification for this choice, which is clear and directly related to the content of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind reporting results on knowledge transfer only in a few select environments, specifically mentioning section 4.3. While the comment prompts the authors to consider why this decision was made, it does not provide any specific reasoning, examples, or references to support the claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the question, rendering the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a valid question about the rationale behind reporting results on knowledge transfer in only a few select environments. It prompts the authors to consider why this decision was made, which is a crucial aspect of transparency and completeness in research reporting. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional environments could be included. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of specific ablation experiments, suggesting that the performance improvement might be due to pretrained weights rather than the proposed method. It implies that the authors should include detailed ablation comparisons to clarify the source of the improvement. However, the comment does not provide explicit guidance on how to conduct these ablation experiments or what specific comparisons should be included. The action is implicit and somewhat vague, as the authors need to infer the need for ablation studies and understand the specific comparisons required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of specific ablation experiments, suggesting that the performance improvement might be due to pretrained weights rather than the proposed method. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is weakly grounded because the authors cannot confidently determine which part of the paper is being addressed. It is also specific in that it highlights the need for detailed ablation comparisons to clarify the source of performance improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance improvement could be attributed to pretrained weights rather than the proposed method due to the lack of specific ablation experiments. However, the comment does not provide any evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of specific ablation experiments, which could lead to confusion regarding the source of performance improvements. It highlights that the performance gains might be attributed to pretrained weights rather than the proposed method, suggesting that detailed ablation comparisons are necessary to clarify this. However, the comment does not provide specific guidance on how to conduct these ablation experiments or what comparisons should be included. While it points out a critical weakness, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific limitation in the lemmatization process, noting that the current method strips suffixes from words that are already lemmas but end with a suffix substring. This is presented as a major concern for realworld texts with evolving vocabularies. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the lemmatization process. The authors are left without guidance on how to resolve this concern, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific limitation in the lemmatization process, noting that the current method strips suffixes from words that are already lemmas but end with a suffix substring. This is a clear and specific issue that the authors can identify and address. The comment is fully grounded as it explicitly mentions the part of the paper being discussed, and it is specific because it details the exact problem with the lemmatization process. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point highlights a specific limitation in the lemmatization process, noting that the current method strips suffixes from words that are already lemmas but end with a suffix substring. This is presented as a major concern for realworld texts with evolving vocabularies. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the lemmatization process, noting that the current method strips suffixes from words that are already lemmas but end with a suffix substring. This is presented as a major concern for realworld texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the lemmatization process. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a problem but lacks depth and direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of pretrained DGCNN for semantic segmentation in Table 2, arguing that the comparison is not meaningful because it only shows that the methods with DGCNN perform worse than the proposed method. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the comparison. It lacks concrete guidance on what changes could be made to make the comparison more meaningful. As a result, the authors are left without actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of segmentation metrics when using pretrained DGCNN for each completion method. The comment provides a clear and specific critique of the comparison, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison of segmentation metrics in Table 2 is not meaningful because the use of pretrained DGCNN for each completion method makes the comparison less informative. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison of segmentation metrics in Table 2, noting that the use of pretrained DGCNN for each completion method makes the comparison less meaningful. While the comment highlights a potential weakness in the experimental setup, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the comparison. The feedback is 3 as it points out a problem that needs attention, but it lacks depth and specificity to guide the authors in making meaningful improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the difficulty of applying statistical rules in realworld applications, suggesting that they may be feasible. However, it does not provide any specific guidance or actionable steps for the authors to address this issue. The comment lacks explicit instructions on how the authors might improve their draft or what aspects of their work need to be revised. As a result, the authors are left without a clear understanding of how to respond or make changes to their paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It raises a general concern about the difficulty of applying statistical rules in realworld applications, but it does not provide specific examples or references to particular sections of the paper. The comment is also not specific because it does not detail what needs to be addressed or how the issue can be resolved. Therefore, this comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point expresses a general observation about the difficulty of applying statistical rules in realworld applications, suggesting that they may be feasible. However, it lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the comment or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the applicability of statistical rules in realworld scenarios, suggesting that they may be feasible. However, it does not provide specific feedback or actionable advice on how the authors might address this issue or improve their draft. The comment lacks depth and specificity, leaving the authors with limited guidance on how to respond or enhance their work. As a result, the feedback is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. While the comment implies that this comparison is missing, it does not explicitly instruct the authors to add this comparison or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the comparison and may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. However, it does not specify which part of the paper this comparison should be made or where the results of such a comparison would be relevant. The comment lacks grounding as it does not provide specific references or sections of the paper that need to be addressed. It is also specific in suggesting the inclusion of a comparison, but without grounding, the authors may struggle to understand where to make the changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the comparison with dynamic sparse trainingbased and other sparsitybased methods is missing. However, it does not provide any specific reasoning, examples, or references to support why this comparison is important or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the missing comparison. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper\"s content and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or why it is important. Despite this, the feedback is 4 as it directs the authors towards a meaningful enhancement of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a statement in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. The authors argue that the paper\"s explanation, which states that the intractability of $p_\u03b8(y|x)$ is due to the intractability of $p_\u03b8(z|x)$, is not necessarily accurate. The reviewer provides a counterexample, suggesting that both the posterior and the likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable. While the comment identifies a potential issue with the paper\"s explanation, it does not provide explicit guidance on how the authors should address this concern or what specific changes are needed. The action is implicit, as the authors would need to infer that they should clarify the explanation or provide a more nuanced discussion of the intractability of $p_\u03b8(y|x)$. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It critiques the paper\"s explanation, which attributes the intractability to $p_\u03b8(z|x)$, arguing that this is not necessarily the case. The reviewer provides a counterexample, suggesting that both the posterior and the likelihood can be tractable while $p_\u03b8(y|x)$ may still be intractable. This comment is fully grounded as it explicitly mentions the part of the paper being discussed, allowing the authors to accurately identify the section. It is also specific because it clearly specifies the issue with the paper\"s explanation and provides a counterexample, guiding the authors on how to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques a statement in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. The authors argue that the paper\"s explanation, which states that the intractability of $p_\u03b8(y|x)$ is due to the intractability of $p_\u03b8(z|x)$, is not necessarily accurate. The reviewer provides a counterexample, suggesting that both the posterior and the likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable. This critique is supported by a logical argument and a specific counterexample, making the claim 4. The comment provides sufficient evidence to support the reviewer\"s critique, allowing the authors to understand the issue and potentially address it in their draft. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the explanation of intractability in the paper, specifically regarding the relationship between $p_\u03b8(y|x)$, $p_\u03b8(z|x)$, and $p_\u03b8(y|x, z)$. The reviewer points out that the paper\"s explanation, which attributes the intractability of $p_\u03b8(y|x)$ to $p_\u03b8(z|x)$, is not necessarily accurate. They provide a counterexample, suggesting that both the posterior and the likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable. This feedback is 3 as it highlights a specific area of confusion and provides a counterexample that could guide the authors in clarifying their explanation. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or provide additional context. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern regarding the irreproducibility of the collected datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might make their datasets more accessible or how they could improve the reproducibility of their results. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the irreproducibility of the collected datasets outside of the associated groups. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to understand where the issue lies and how to address it. Additionally, the comment does not provide specific guidance on how to improve the reproducibility of the datasets or the results. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the collected datasets are inaccessible outside of the associated groups, making the results irreproducible. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the collected datasets, which is a critical aspect of scientific research. However, the comment lacks specific guidance or suggestions on how the authors might address this issue. It does not provide any actionable steps or insights into improving the accessibility or reproducibility of the datasets. Without such guidance, the authors may struggle to make meaningful improvements to their draft. Therefore, the comment is 2, as it highlights a problem but does not offer a comprehensive or constructive response."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions whether a missing equation exists before \"where p is the firing rate\" in section 3.4.1. While it identifies a potential issue, it does not explicitly instruct the authors to add or remove an equation. The action is implicit, as the authors would need to infer that they should check for the equation and address it. However, the comment lacks specific guidance on how to identify or correct the missing equation, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presence of a missing equation before a particular phrase, \"where p is the firing rate,\" which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the presence of a missing equation in section 3.4.1 before the phrase \"where p is the firing rate.\" While it identifies a potential issue, it does not provide any supporting evidence, reasoning, or references to justify the claim. The comment lacks specific details or context to allow the authors to understand why this is a concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting the absence of an equation before the phrase \"where p is the firing rate\" in section 3.4.1. This feedback is clear and actionable, as it directs the authors to check for the missing equation and address it. By pointing out a potential error or omission, the comment provides a concrete suggestion for improvement, which is essential for enhancing the clarity and completeness of the paper. However, the comment could be more helpful if it offered additional guidance on how to identify or correct the missing equation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of evaluation regarding sentiment word detection and correction, specifically mentioning the key ideas of the SWRM method. It suggests that experiments should be conducted to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and the specific areas to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of evaluation of sentiment word detection and correction, which is a specific aspect of the paper. It also specifies the need for experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks evaluation of sentiment word detection and correction, specifically mentioning the key ideas of the SWRM method. It suggests that experiments should be conducted to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of evaluation of sentiment word detection and correction. It highlights the importance of this aspect, given that the key ideas of the SWRM method involve the detection and correction of sentiment word errors. The comment suggests that experiments should be conducted to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. However, the comment lacks specific guidance on how to conduct these experiments or what aspects to focus on, which limits its helpfulness. While it points out a crucial area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a clear direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors to report the results of KMLMXLMR_large(ours) in all result tables, suggesting that the authors did not report the performance of KMLMlarge without logical reasoning. This comment implies that the authors should include these results, but it does not provide explicit instructions on how to do so or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to add the missing results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors to report the results of KMLMXLMR_large(ours) in all result tables, suggesting that the authors did not report the performance of KMLMlarge without logical reasoning. However, the comment does not specify which part of the paper this issue pertains to, such as specific tables or sections. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific about the issue of missing results, it is 1 because it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors to report the results of KMLMXLMR_large(ours) in all result tables, suggesting that the authors did not report the performance of KMLMlarge without logical reasoning. However, the comment does not provide any specific reasoning, examples, or references to support why this omission is significant or how it affects the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the result tables, questioning the absence of reported results for KMLMXLMR_large(ours). It suggests that the authors did not report the performance of KMLMlarge without logical reasoning, which implies a potential gap in the presentation of results. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. While it points out a potential area for improvement, it does not provide detailed feedback or constructive advice on how to enhance the clarity and completeness of the results section. Therefore, the comment is 3, as it highlights a specific area for improvement but does not offer comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the underperformance of incontext learning baselines compared to the backbone model, attributing it to large variance or uncareful baseline design. It suggests that more explanations are needed to support the reliability of the claims. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to provide more detailed explanations. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of underperformance of incontext learning baselines compared to the backbone model, suggesting that the large variance or uncareful design of the baselines might be the cause. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem and suggesting that more explanations are needed to support the reliability of the claims. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that many incontext learning baselines underperform the backbone due to large variance or uncareful design, suggesting that more explanations are needed to support the reliability of the claims. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the basis of the issue or how to address it. The reasoning is vague and lacks detailed evidence, which limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the underperformance of incontext learning baselines compared to the backbone model, attributing it to large variance or uncareful baseline design. It suggests that more detailed explanations are needed to support the reliability of the claims, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues, such as suggesting additional experiments or analyses that could be conducted to clarify the results. Overall, the comment is 3 as it highlights an important area for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the key innovation that drives the improvements claimed by GFNSeqEditor. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, which would enhance the reader\"s understanding of the method\"s unique value. The comment is explicit in identifying the need for clarification and provides a clear action for the authors to take, which is to elaborate on the novel techniques or insights that contribute to the claimed improvements. This explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GFNSeqEditor,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of ambiguity in the key innovation and suggests that the paper should better articulate the novel techniques or insights driving the claimed improvements. This provides the authors with a clear understanding of what needs to be addressed to enhance the paper\"s clarity and value.", "verifiability_rationale": "The review point raises a claim about the lack of clarity regarding the key innovation that drives the improvements claimed by GFNSeqEditor. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, which would enhance the reader\"s understanding of the method\"s unique value. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the key innovation that drives the improvements claimed by GFNSeqEditor. It highlights that the paper should better articulate what novel techniques or insights lead to these improvements, which would enhance the reader\"s understanding of the method\"s unique value. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to articulate these novel techniques or insights effectively. Overall, the comment is 4, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the faithfulness of their proposed approach with at least a simple experiment. This provides a clear and explicit action for the authors to take, as they need to conduct an experiment to support their claim. The comment is specific in its suggestion, detailing what needs to be done to substantiate the claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the faithfulness of their proposed approach with at least a simple experiment. However, it does not specify which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its suggestion to include an experiment, but the lack of grounding makes it difficult for the authors to know exactly where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the faithfulness of their proposed approach with at least a simple experiment. However, the comment lacks specific details or examples of how this demonstration could be conducted or what kind of experiment would be appropriate. Without additional information or guidance, the authors may find it challenging to address this suggestion effectively. Therefore, the comment is considered 2, as it provides a general direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide evidence to support the claim about the faithfulness of their proposed approach. It recommends conducting at least a simple experiment to substantiate this claim. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work. However, the comment could be more helpful if it offered more detailed guidance on how to design or execute the experiment. Overall, the comment is 4, as it directs the authors towards a specific improvement but lacks some depth in terms of detailed suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation section of the manuscript, arguing that it does not align with realworld applications, which are often continuous and difficult to discretize. The comment suggests that the proposed method, which operates with stateaction spaces, is not a suitable motivation. However, the comment does not provide specific guidance on how the authors should revise the motivation section to better reflect realworld applications or continuous stateaction spaces. The action is implicit but vague, as it does not offer concrete suggestions or steps for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation section of the manuscript, arguing that it does not align with realworld applications, which are often continuous and difficult to discretize. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the motivation, the lack of grounding makes it challenging for the authors to understand where to make changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the motivation section of the manuscript, arguing that it does not align with realworld applications, which are often continuous and difficult to discretize. The comment suggests that the proposed method, which operates with stateaction spaces, is not a suitable motivation. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is 3, as it provides a general critique but lacks depth and specificity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation section of the manuscript, arguing that it does not align with realworld applications, which are often continuous and difficult to discretize. The reviewer suggests that the proposed method, which operates with stateaction spaces, is not a suitable motivation. While the comment identifies a potential weakness in the motivation, it does not provide specific guidance or suggestions on how the authors might improve the motivation section. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice or detailed examples, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the experiment results and presentation. It notes that the results are not very competitive to the SOTA methods, with only minor improvements. It also points out that the presentation of the main result Table 1 is unclear, as it compares different backbones to prior methods. The comment suggests moving the baseline to an ablation study and only showing the proposed method. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The actions are implicit and vague, leaving the authors without clear direction on how to improve their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiment results and presentation of the main result Table 1, noting that the results are not very competitive to the SOTA methods and that the presentation is unclear due to comparisons with different backbones. However, the comment does not specify which part of the paper the results are presented in, making it weakly grounded. It is specific in detailing the issues with the results and presentation, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiment results are not very competitive to the SOTA methods, with only minor improvements. It also notes that the presentation of the main result Table 1 is unclear, as it compares different backbones to prior methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, as the authors may struggle to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the competitiveness of the experiment results compared to SOTA methods and the clarity of the presentation of the main result Table 1. It also suggests moving the baseline to an ablation study and only showcasing the proposed method. However, the comment lacks specific guidance on how to address these issues or what changes should be made to the draft. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights important areas for improvement but could be more comprehensive with detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. This comment provides an explicit action for the authors to take, which is to clarify the copyright scenario in their manuscript. It also specifies what needs to be addressed, making the action concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. This comment is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for clarification based on the feedback, which could be improved with additional context or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the manuscript, suggesting that it could benefit from a clearer delineation of the copyright scenario. It specifically asks whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and completeness of their manuscript. By addressing this suggestion, the authors can improve the understanding of the copyright implications discussed in their work, making the comment 4. However, it could be more helpful if it provided additional guidance on how to clarify the copyright scenario or suggested specific sections where this clarification is needed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by pointing out the lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. This feedback suggests that the authors should provide a more detailed explanation to clarify these differences. However, the comment does not specify how the authors should address this issue or what kind of theoretical or intuitive explanation they should include. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the gap in the paper, as it highlights the need for a clearer explanation of the information acquisition process for both adapters. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. This claim is based on the observation that the paper relies on experimental observation rather than providing a theoretical or intuitive basis for these differences. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides a basis for improvement but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more detailed explanation or theoretical basis for the observed phenomena. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, which limits its helpfulness. While it provides a clear direction for improvement, the lack of actionable advice makes it 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the reasoning behind a specific statement regarding local models and their nontriviality in the vicinity of decision boundaries. It prompts the authors to explain why this is true and why they cannot measure differences in probabilities as an alternative approach. While the comment implies an action\u2014asking for clarification and justification\u2014it does not provide explicit instructions on how to address the question or what specific changes might be needed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors need to address by questioning the reasoning behind the statement and suggesting an alternative approach. This provides clear guidance on what needs to be clarified or improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasoning behind a specific statement regarding local models and their nontriviality in the vicinity of decision boundaries. It prompts the authors to explain why this is true and why they cannot measure differences in probabilities as an alternative approach. While the comment does not contain a direct claim, it encourages the authors to provide a more detailed explanation or justification for the statement, which could be considered 3. However, the comment lacks specific examples or references to support the reasoning, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a question about the reasoning behind a specific statement regarding local models and their nontriviality in the vicinity of decision boundaries. It prompts the authors to explain why this is true and why they cannot measure differences in probabilities as an alternative approach. This feedback is 3 as it identifies a potential area for clarification and encourages the authors to provide a more detailed explanation or justification for their claim. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the question or improve the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they only report results on ImageNet and lack results on classic datasets like CIFAR10 and CIFAR100. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include results on these additional datasets to provide a more comprehensive evaluation of their work. The action is implicit and somewhat vague, as it does not specify which datasets to include or how to present the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments and the specific datasets they report results on, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing datasets (CIFAR10 and CIFAR100) that should be included to provide a more comprehensive evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments only report results on ImageNet and lack results on classic datasets such as CIFAR10 and CIFAR100. This is a factual observation about the scope of the experiments. However, the comment does not provide any reasoning or justification for why these additional datasets are important or how their inclusion would enhance the paper. Without further explanation or references, the claim is 3, as it highlights a gap in the experimental evaluation but lacks detailed support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experiments, noting that they only report results on ImageNet and lack results on classic datasets such as CIFAR10 and CIFAR100. This feedback is clear and actionable, as it highlights a gap in the experimental evaluation that could provide a more comprehensive assessment of the proposed method. By suggesting the inclusion of results on these additional datasets, the comment guides the authors to enhance the robustness and comprehensiveness of their experiments. However, the comment could be more helpful if it provided specific guidance on how to include these results or what aspects of the method should be evaluated on these datasets. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the clarity of the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown despite the text description indicating that the encoder does not include it. The reviewer contrasts this with the clarity of the original DinoSR paper, suggesting that the figure in the original paper is more understandable. However, the comment does not provide explicit guidance on how the authors should improve the clarity of the figure or what specific changes should be made. The action is implicit and vague, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the DinoSR part in Figure 1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the softmax layer is not clearly shown despite the text description indicating its absence. The comment provides a clear and detailed explanation of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite the text description indicating its absence. The reviewer contrasts this with the clarity of the original DinoSR paper, suggesting that the figure in the original paper is more understandable. However, the comment lacks specific examples or detailed reasoning to support the claim that the figure is confusing or that the original paper is clearer. Without additional context or evidence, the claim remains 3, as it is based on an observation but lacks thorough justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown despite the text description indicating its absence. The reviewer contrasts this with the clarity of the original DinoSR paper, suggesting that the figure in the original paper is more understandable. This feedback is 3 as it highlights a potential area for improvement in the figure\"s presentation, but it lacks detailed guidance on how the authors might address this issue or what specific changes could be made to enhance clarity. Without actionable suggestions or examples, the comment provides a clear observation but does not fully empower the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should review related work on causal inference and include more relevant works in their discussion. However, it does not provide specific guidance on which parts of the paper need to be revised or how the additional works should be integrated. The action is implicit, as the authors need to infer that they should expand their related work section, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should review related work on causal inference and include more relevant works in their discussion. However, it does not specify which part of the paper this review comment pertains to, such as a specific section or section title. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment is specific in that it suggests including more works related to causal inference, but without explicit references or examples, it lacks detailed guidance. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should review related work on causal inference and include more relevant works in their discussion, citing specific examples [1] [2] [3]. However, the comment lacks detailed reasoning or justification for why these specific works are important or how they relate to the paper\"s content. Without a clear explanation of the relevance or significance of these works, the claim is 3, as it provides a general direction but lacks depth and specificity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should review related work on causal inference and include more relevant works in their discussion, citing specific examples [1] [2] [3]. This feedback is 3 as it points out a potential area for improvement by highlighting the need for a more comprehensive review of related literature. However, the comment lacks specific guidance on which parts of the paper should be revised or how the additional works should be integrated, making it incomplete. The authors would benefit from additional details on how to incorporate these works into their discussion, which would enhance the comment\"s helpfulness. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors could have avoided Sections 3.1 and 3.2 by using the LLM2Vec encoder, which is already cited in the paper. However, it does not provide explicit guidance on how to implement this suggestion or what specific actions the authors should take to validate their decision with ablation studies. The comment implies that the authors should consider this approach, but it lacks concrete instructions on how to proceed. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests that the authors could have avoided these sections by using the LLM2Vec encoder, which is already cited, and that the reasoning for not adopting this approach remains unclear. The comment further recommends validating the decision with ablation studies, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or logical reasoning to substantiate why the LLM2Vec encoder would be a suitable alternative or why the current approach is unclear. Without these details, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a potential improvement in the paper by suggesting that Sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. The comment highlights a lack of clarity in the reasoning behind not adopting this approach and recommends validating the decision with ablation studies. This feedback is 3 as it points out a specific area for improvement and suggests a potential solution, but it lacks detailed guidance on how to implement the ablation studies or what specific aspects of the reasoning need clarification. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments conducted, noting that only synthetic objective functions are used, and there are no realworld problems. This feedback suggests that the authors should consider including experiments with realworld problems to better evaluate the proposed Batch BORE method. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific realworld problems should be addressed. The action is implicit, as the authors need to infer that they should include realworld problems in their experiments. The feedback is 3 because it identifies a clear area for improvement but lacks detailed guidance on how to implement it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, noting that only synthetic objective functions are used and that there are no realworld problems. However, it does not specify which part of the paper this issue is discussed in, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the use of synthetic objective functions, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack realworld problems. This claim is 3 as it highlights a limitation in the experimental setup, but it does not provide specific examples or references to support the claim. The authors could infer that the lack of realworld problems might limit the generalizability of the results, but the comment lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental setup, noting that the comparison of the proposed Batch BORE method with existing baselines is limited to synthetic objective functions and lacks realworld problems. This feedback is valuable as it highlights a gap in the evaluation, suggesting that the authors should consider including experiments with realworld problems to better assess the practical applicability and effectiveness of their method. However, the comment could be more helpful if it provided specific examples of realworld problems or guidance on how to conduct such experiments. Without these details, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a crucial area for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the challenge in distinguishing roles using explanationfocused cues might be due to LLMs relying more on language style than informational depth. It proposes that a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts could clarify these findings. However, the comment does not provide explicit guidance on how to conduct this detailed analysis or what specific aspects of the benchmark sentences should be examined. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that distinguishing roles using explanationfocused cues is challenging and suggests that this could be due to LLMs relying more on language style than informational depth. The comment further proposes a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts to clarify these findings. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that distinguishing roles using explanationfocused cues is challenging, attributing it to LLMs\" reliance on language style over informational depth. The comment suggests that a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts could clarify these findings. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed guidance on how to conduct the analysis or what specific aspects of the benchmark sentences should be examined. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific challenge in distinguishing roles using explanationfocused cues, attributing it to LLMs\" reliance on language style rather than informational depth. It suggests that a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts could help clarify these findings. This feedback is 3 as it points out a potential area for further investigation and provides a direction for the authors to explore. However, the comment could be more helpful if it offered specific guidance on how to conduct this analysis or suggested particular aspects of the benchmark sentences that should be examined. Overall, the comment provides a clear insight into a potential issue, but it lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the paper\"s readability due to the heavy use of acronyms, particularly the acronym \"DU\" which is mentioned without a clear definition. This feedback is explicit, as it directly points out a problem that needs to be addressed. The action is also concrete, as it specifies that the authors should define the acronym \"DU\" to improve the paper\"s readability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper\"s readability due to the heavy use of acronyms, particularly mentioning the acronym \"DU\" without a clear definition. However, it does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in identifying the problem with the use of acronyms, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper makes heavy use of acronyms, which affects readability, and specifically mentions the acronym \"DU\" without a clear definition. This claim is 3 as it highlights a potential issue with readability, but it lacks specific examples or references to support the claim fully. The authors would need to infer the impact of the acronym usage on readability, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s readability due to the heavy use of acronyms, particularly noting that the acronym \"DU\" is mentioned without a clear definition. This feedback is clear and actionable, as it directs the authors to address the lack of clarity in their use of acronyms. By defining the acronym \"DU,\" the authors can improve the readability and accessibility of their paper, making it easier for readers to understand. The comment provides a direct and constructive suggestion that is easy for the authors to implement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the assumption of sentence independence for the variance of the distribution p(q|s) in section 2.3. It asks how this variance is estimated and whether it is determined using the sample variance of quality values in the training data. It also questions the assumption of a diagonal covariance matrix, suggesting that a complete covariance matrix might be more appropriate. While the comment identifies a specific area of the paper that needs clarification, it does not provide explicit instructions on how to address the issue or what changes should be made. The action is implicit, as the authors need to infer that they should clarify the assumptions and estimation methods in section 2.3. However, the comment lacks concrete guidance on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the estimation of variance and the assumptions made about the covariance matrix, guiding the authors to clarify these aspects in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the assumptions made in section 2.3 regarding the variance of the distribution p(q|s). It asks how this variance is estimated and whether it is determined using the sample variance of quality values in the training data. It also questions the assumption of a diagonal covariance matrix, suggesting that a complete covariance matrix might be more appropriate. While the comment does not provide a direct claim or suggestion, it raises important questions that could guide the authors in clarifying their assumptions and estimation methods. However, it lacks specific examples or detailed reasoning to fully substantiate the concerns, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides specific questions and suggestions for the authors to consider regarding the estimation of variance and the assumptions made about the covariance matrix in section 2.3. By questioning the assumption of sentence independence and the use of a diagonal covariance matrix, the comment encourages the authors to clarify these aspects in their paper, potentially improving the accuracy and robustness of their methodology. The detailed nature of the feedback, including specific questions about the estimation process and the implications of different covariance matrix assumptions, makes it a valuable guide for the authors to enhance their draft. Therefore, this comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the initial accuracy of a MILbased baseline model compared to converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve their draft. Without specific suggestions or instructions, the authors are left without a clear path to respond to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Fig. 7\" and asks a question about the initial accuracy of a MILbased baseline model compared to converged models, especially for the NSCLC dataset. However, it does not specify which part of the paper this figure is located in, making it weakly grounded. The comment is specific in its request for clarification regarding the accuracy of the models, but it lacks detailed guidance on how to address the issue or what changes might be necessary. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the initial accuracy of a MILbased baseline model compared to converged models, particularly for the NSCLC dataset. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance for the authors to address the issue. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the initial accuracy of a MILbased baseline model compared to converged models, especially for the NSCLC dataset. While it identifies a potential issue or area for clarification, it does not provide any suggestions or guidance on how the authors might address this concern or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to respond or enhance their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer any constructive advice or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. While the comment implies that the authors should include other datasets, it does not explicitly instruct them to do so or provide specific guidance on which datasets to consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to include other datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is specific in its suggestion to include other datasets, but the lack of grounding makes it challenging for the authors to understand where to apply this feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. However, the comment does not provide any specific reasoning, examples, or references to support why this recommendation is necessary or beneficial. Without additional context or justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional datasets. However, the comment lacks specific guidance on which datasets to consider or how to approach this expansion, making it somewhat incomplete. The authors would benefit from more detailed suggestions or examples to enhance the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the optimality of the systems and suggests that more work needs to be done to establish alternative hypotheses and discriminate between them. It implies that the current analysis is confirmatory and lacks the depth to test the hypothesis. However, the comment does not provide explicit guidance on how to establish these alternative hypotheses or what specific experiments would discriminate between them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for more work to establish alternative hypotheses and discriminate between them, suggesting that the current analysis is confirmatory. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The comment is fully grounded in that it mentions the need for more work, but it is not specific about what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the optimality of the systems and suggests that more work is needed to establish alternative hypotheses and discriminate between them. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment raises a critical question about the optimality of the systems investigated in the paper, specifically questioning why they might not be Bayesoptimal on straightforward problems. It suggests that the paper primarily presents a confirmatory analysis and that more work is needed to establish alternative hypotheses and discriminate between them. This feedback is valuable as it highlights a potential gap in the paper\"s analysis and encourages the authors to expand their work to explore alternative explanations. However, the comment could be more helpful if it provided specific suggestions or guidance on how to establish these alternative hypotheses or what experiments could be conducted to discriminate between them. Overall, the comment is 3, as it identifies an important area for improvement but lacks detailed actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the results presented in Table 1, noting that the reported values are very close, making it difficult to draw meaningful conclusions. The comment suggests that the authors should add confidence intervals to the results. This feedback is explicit and provides a clear action for the authors to take, which is to include confidence intervals in their revised draft. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the reported values being very close, making it difficult to draw conclusions, and suggests adding confidence intervals to address this issue. This provides the authors with a clear understanding of what needs to be addressed and how to do it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the closeness of the reported values in Table 1, making it difficult to draw meaningful conclusions. The comment suggests adding confidence intervals to address this issue. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the values are indeed very close or why confidence intervals would be necessary. This lack of detailed justification makes the claim 3, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 1, noting that the reported values are very close, making it difficult to draw meaningful conclusions. The comment suggests that the authors should add confidence intervals to address this issue. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion to improve the clarity and interpretability of their results. By adding confidence intervals, the authors can provide a more robust and reliable analysis, enhancing the overall quality and impact of their work. Therefore, the comment is 5, as it offers a clear and actionable direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some choices in the paper are not justified or clear, but it does not provide specific examples or actions for the authors to take. The comment lacks explicit guidance on what needs to be addressed or how to improve the clarity of these choices. As a result, the authors are left without a clear understanding of what steps to follow to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some choices in the paper are not justified or clear, but it does not specify which part of the paper these choices are in. Without knowing the exact sections or elements being referred to, the authors cannot confidently identify what needs to be addressed. The comment is vague and lacks specificity, making it difficult for the authors to understand the scope of the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some choices in the paper are not justified or clear, but it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that some choices are not justified or clear. However, it does not provide any specific examples or suggestions for improvement, leaving the authors without actionable guidance on how to address the problem. The feedback is vague and lacks depth, making it difficult for the authors to understand the nature of the issue and how to resolve it. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about hyperparameter tuning, noting that the paper lacks clarity on how the grid search is conducted and how multiple solutions with the same FLOPs can be navigated. While the comment identifies a specific issue regarding the tuning process, it does not provide explicit guidance on how to address it or what actions the authors should take. The suggestion to include detailed discussions for reproducibility is clear, but the lack of specific instructions on how to implement this makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns regarding hyperparameter tuning, specifically mentioning the laborious nature of tuning two hyperparameters that affect both FLOPs and accuracy. It highlights the issue of navigating the tuning process when multiple solutions can achieve the same FLOPs. However, the comment does not specify which part of the paper discusses hyperparameter tuning or where the issue is detailed. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of hyperparameter tuning, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the hyperparameter tuning process, specifically noting that the paper lacks clarity on how the grid search is conducted and how multiple solutions with the same FLOPs can be navigated. The comment suggests that the current presentation does not provide sufficient detail for reproducibility. However, the claim lacks specific examples or references to support the assertion that the tuning process is laborious and difficult to navigate. Without additional context or evidence, the claim is 3, as it highlights a potential issue but does not provide a comprehensive explanation or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the hyperparameter tuning process, specifically noting that the paper lacks clarity on how the grid search is conducted and how multiple solutions with the same FLOPs can be navigated. This feedback is 3 as it identifies a potential issue with the reproducibility of the results, which is an important aspect for scientific rigor. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative tuning strategies or providing more detailed explanations of the grid search process. Without these additional details, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the presentation of results in Figure 1, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown. This implies that the authors should include these accuracies to clarify the difference between known and unknown attacks. However, the comment does not provide explicit guidance on how to incorporate this information into the figure or the manuscript. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the absence of accuracies for the target model using different defenses against the FGSM attack, which makes it unclear the difference between known and unknown attacks. This provides a clear and specific direction for the authors to improve their manuscript. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, making it unclear to distinguish between known and unknown attacks. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Figure 1, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown. This lack of information makes it difficult for the reader to understand the difference between known and unknown attacks. While the comment highlights a clear area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The authors are left to infer the necessary steps, which limits the helpfulness of the comment. Therefore, the comment is 3, as it points out a significant gap in the presentation of results but lacks actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some figures are hard to read and recommends using a logscale for the yaxis. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve the readability of their figures. The comment is specific in its recommendation, detailing exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use a logscale for the yaxis, which directly addresses the issue of readability. This feedback is both grounded and specific, making it 5.", "verifiability_rationale": "The review point suggests that some figures are hard to read and recommends using a logscale for the yaxis. While the suggestion is practical and could improve the clarity of the figures, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer that using a logscale could enhance readability, but the comment does not provide a clear explanation or evidence to support this claim. Therefore, the comment is 3, as it offers a suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of some figures and provides a clear suggestion to improve it by using a logscale for the yaxis. This feedback is actionable and directly addresses a potential weakness in the presentation of the paper. By offering a concrete solution, the comment empowers the authors to enhance the clarity and effectiveness of their figures, which is crucial for the overall impact of the paper. Therefore, the comment is 4, as it provides clear guidance but could be more comprehensive if it included additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the validation of the proposed method, noting that while the authors claim augmentation information is useful and provide examples like flowers and birds, these claims are not supported by experimental validation. The comment suggests using finegrained datasets such as the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and the specific datasets to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the augmentation information is discussed, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue: the lack of validation of the claims made about augmentation information using specific datasets. The authors are directed to use finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims, providing a clear and actionable direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method was motivated by the case where \"augmentation information is useful\" as claimed by the authors, with examples like flowers and birds. However, it notes that this claim was not validated in the experiment. The comment suggests using finegrained datasets such as the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or detailed reasoning on how these datasets would be used to validate the claims effectively. The comment is 4 as it provides a reasonable basis for the suggestion but could be more robust with additional details or references. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the validation of the proposed method, noting that while the authors claim augmentation information is useful and provide examples like flowers and birds, these claims are not supported by experimental validation. The comment suggests using finegrained datasets such as the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and credibility of their experimental results. By recommending the use of these datasets, the comment offers a concrete step for the authors to take in improving their draft. However, it could be more helpful if it included additional guidance on how to conduct the experiments or analyze the results. Overall, the comment is 4, as it effectively highlights a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific claim made in the paper regarding the evolution of opponents towards the Nash equilibrium. It points out that the paper lacks theoretical analyses and empirical evaluations to support this claim, particularly concerning the convergence of GEMS to the Nash equilibrium. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen their analysis. The authors are left with the task of identifying and addressing the missing theoretical and empirical components, but the comment lacks concrete suggestions or detailed instructions on how to do so. Therefore, the comment is 3, as it identifies a clear area for improvement but does not provide explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the claim \"Over time, those opponents will evolve toward the Nash equilibrium\" is made. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue: the lack of theoretical analyses and empirical evaluations to support the claim that GEMS converges to the Nash equilibrium. This provides the authors with a clear understanding of what needs to be addressed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks theoretical analyses and empirical evaluations to support the assertion that \"Over time, those opponents will evolve toward the Nash equilibrium.\" However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper that lacks theoretical or empirical support, noting that the assertion about opponents evolving towards the Nash equilibrium is not substantiated. This feedback is valuable as it highlights a gap in the paper\"s analysis and suggests that the authors should provide more rigorous theoretical or empirical evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might approach this issue, such as suggesting particular theoretical frameworks or empirical methods to explore the convergence of GEMS to the Nash equilibrium. Without such guidance, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a significant area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific questions and suggestions regarding the clarity and correctness of Equation (1). It asks the authors to clarify the purpose of the equation, whether it defines a loss function or an optimization problem, and to correct the unusual constraint notation. While the comment is explicit in its requests, it lacks concrete guidance on how to address these issues. The authors know what needs to be clarified but are not given specific steps or examples to follow. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on implementation. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the clarity of the equation, including questions about its purpose, the definition of the optimization variable, and the unusual constraint notation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of several specific questions and suggestions regarding the clarity and correctness of Equation (1). It asks the authors to clarify the purpose of the equation, whether it defines a loss function or an optimization problem, and to correct the unusual constraint notation. While the questions are clear and specific, they do not provide any additional reasoning, references, or examples to support the claims made. The feedback is mostly based on observations and requests for clarification, which are helpful but not 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and correctness of Equation (1), identifying several areas for improvement. It asks the authors to clarify the purpose of the equation, whether it defines a loss function or an optimization problem, and to correct the unusual constraint notation. These questions and suggestions are actionable and provide clear guidance on how the authors can improve the clarity and accuracy of their paper. By addressing these points, the authors can enhance the understanding and coherence of their work. Therefore, the comment is 4, as it offers detailed and constructive feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the performance of the NMT system after including the collected LIVEN parallel data for finetuning, noting that it performs worse than expected. While the comment suggests that the authors should provide more discussions or explanations, it does not explicitly instruct them to do so or provide specific guidance on how to address this issue. The action is implicit, as the authors need to infer that they should expand on their discussion or provide additional explanations to address the observed performance drop. However, the lack of concrete details on what specific aspects need to be discussed or how to explain the results makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the unexpected performance drop of the NMT system after including the collected LIVEN parallel data for finetuning. This provides the authors with a clear understanding of what needs to be discussed or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the NMT system after including the collected LIVEN parallel data for finetuning, noting that it performs worse than expected. While the comment suggests that the authors should provide more discussions or explanations, it does not offer any specific evidence, examples, or references to support this claim. The lack of detailed reasoning or justification makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the inclusion of collected LIVEN parallel data for finetuning results in a performance drop of the NMT system. It prompts the authors to provide more discussions or explanations to address this unexpected outcome. While the comment highlights a potential area for improvement or clarification, it does not offer specific suggestions or guidance on how to address the issue. The feedback is 3 as it points out a potential area for further discussion, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern regarding the unsubstantiated conjectures in the paper, specifically the claim that \"finetuning as exposure of existing capabilities in LMs\" lacks adequate reasoning or references. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to substantiate their claims. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the unsubstantiated conjectures in the paper, specifically regarding the claim that \"finetuning as exposure of existing capabilities in LMs\" lacks adequate reasoning or references. However, the comment does not specify which part of the paper this claim is made or where the authors discuss it. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its critique of the unsubstantiated conjectures, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper provides \"unsubstantiated conjectures\" about \"finetuning as exposure of existing capabilities in LMs\" without adequate reasoning or references. This claim is 3 as it highlights a lack of substantiation in the paper, but it does not provide specific examples or references to support the claim. The authors would need to independently verify the claim by examining the paper for the unsubstantiated conjectures and the absence of supporting evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs.\" It highlights the lack of adequate reasoning or references, making it difficult for the authors to comprehend the claim. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or substantiate their claims. Without actionable feedback or specific advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it points out a problem but does not offer any constructive solutions or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that FACodec could be a beneficial baseline for voice cloning tasks, specifically mentioning NaturalSpeech 3. However, it does not provide explicit guidance on how the authors should incorporate or compare NaturalSpeech 3 into their draft. The action is implicit, as the authors would need to infer that they should consider adding this baseline, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a direction but not a clear path for action.", "grounding_specificity_rationale": "The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses voice cloning tasks or where the suggestion should be addressed. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in suggesting an addition to the baseline, but the lack of explicit grounding makes it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point suggests that FACodec could be a beneficial baseline for voice cloning tasks, specifically mentioning NaturalSpeech 3. However, the comment does not provide any reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that FACodec could be a beneficial baseline for voice cloning tasks, specifically mentioning NaturalSpeech 3. This feedback is 3 as it identifies a potential area for improvement by suggesting an additional baseline for comparison. However, the comment lacks depth and does not provide specific guidance on how the authors might incorporate or evaluate this baseline. Without more detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference while other methods use it for training. The reviewer suggests that this discrepancy might be unfair and asks the authors to clarify their understanding. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should ensure fairness in their experiments by aligning the data usage for inference and training across different methods. However, the comment lacks concrete details on how to achieve this, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference while other methods use it for training. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this issue or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference while other methods use it for training. The reviewer questions whether this discrepancy might be unfair and asks the authors to clarify their understanding. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the experiments are not fair. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference while other methods use it for training. The reviewer questions whether this discrepancy might be unfair and asks the authors to clarify their understanding. While the comment identifies a potential issue with the experimental setup, it does not provide specific guidance or suggestions on how to address this concern or ensure fairness in the experiments. The feedback is 3 as it highlights a potential weakness, but it lacks depth and actionable advice, leaving the authors with limited insights to improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include results on the speedup obtained compared to the dense and SparseGPT models with varying model sizes and sparsity categories. This provides a clear and explicit action for the authors to take, as they know exactly what additional results to include in their draft. The comment is specific in its request, detailing the exact models and categories to be considered. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its request for additional results, but without clear grounding, the authors may find it challenging to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or beneficial. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include results on the speedup obtained compared to the dense and SparseGPT models with varying model sizes and sparsity categories. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by including additional experimental results. By reporting these results, the authors can better demonstrate the performance of their model in comparison to existing models, which would strengthen the paper. However, the comment could be more helpful if it provided more context or guidance on how to present these results effectively. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the impact of sequential bias on the VisDial results, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to mitigate the effect of sequential bias. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of sequential bias on the VisDial results, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address the issue of sequential bias, leaving the authors without a clear direction for improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the impact of sequential bias on the VisDial results, but it does not provide any specific evidence, reasoning, or references to support the claim. Without additional context or justification, the authors are left to interpret the question, making it difficult to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of sequential bias on the VisDial results, which is a relevant concern for the authors to address. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or mitigate this issue. Without actionable advice or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the experimental results and the stated goal of LTAP, suggesting that the model performs better on head classes than tail classes. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to align the results with the stated goal. The action is implicit, as the authors are left to infer that they need to investigate and potentially adjust their model or experimental setup. The comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ImageNetLT dataset\" and the comparison with \"ATO and RReg,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the performance discrepancy between head and tail classes contradicts the stated goal of strengthening parameter protection for tail classes. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results on the ImageNetLT dataset show a performance improvement for head classes compared to tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes in LTAP. However, the comment does not provide specific evidence, examples, or references to support this claim. Without additional context or data, the authors may find it challenging to verify the claim independently. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential inconsistency between the experimental results and the stated goal of the paper. It highlights that the performance improvement of LTAP is larger for head classes than for tail classes, which contradicts the aim of strengthening parameter protection for tail classes. This observation is insightful and raises a valid concern that the authors should address. However, the comment does not provide specific suggestions or guidance on how to resolve this issue or what changes might be necessary to align the results with the stated goal. While it points out a critical area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the reliability of the reward computation due to its reliance on LLMbased evaluation. It raises questions about potential biases or inconsistencies that could arise from this approach, suggesting that the authors should consider alternative methods or provide more details on the evaluation process. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the reliability of the evaluation. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the concerns raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the reliability of the reward computation due to its reliance on LLMbased evaluation. It raises questions about potential biases or inconsistencies that could arise from this approach, suggesting that the authors should consider alternative methods or provide more details on the evaluation process. However, the comment does not specify which part of the paper discusses the reward computation or the evaluation process, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its critique of the evaluation method, the lack of grounding makes it challenging for the authors to fully understand and address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the reward computation relies on LLMbased evaluation, which raises concerns about the reliability of the search process. The comment suggests that this dependency on LLMs may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that LLMs may generate inaccurate scores. While the concern is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reward computation method, which relies on LLMbased evaluation. It highlights concerns about the reliability of this approach, suggesting that it may introduce biases or inconsistencies in the quality assessment of generated documentations. The comment raises a valid point about the need for more robust evaluation methods or additional details on the current process. However, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve the reliability of their evaluation. While the feedback is 3 in pointing out a potential weakness, it lacks depth and actionable advice, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more empirical examples to support their claim about the effectiveness of the described process. It also mentions that comparing the results to stateoftheart performance from referenced papers would be beneficial. However, the comment does not specify how these empirical examples should be constructed or how the comparison to SOTA performance should be performed. The reference to Eq 12 is vague, as it does not explain how this equation might be used to address the issue. While the authors understand the need for more empirical evidence and comparison, the lack of specific guidance on how to implement these suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more empirical examples to support their claim about the effectiveness of the described process and compare it to stateoftheart performance from referenced papers. However, it does not specify which part of the paper these examples or comparisons should be included in, making it weakly grounded. The comment is specific in its suggestion to include more empirical evidence and comparisons, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas where these additions should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more empirical examples to support their claim about the effectiveness of the described process and compare it to stateoftheart performance from referenced papers. However, the comment lacks specific details or examples to substantiate this claim, making it difficult for the authors to understand how to address it. The suggestion is somewhat vague and lacks a clear path for implementation, which limits its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide more empirical examples to support their claim about the effectiveness of the described process and compare it to stateoftheart performance from referenced papers. It also points out that Equation 12 might be relevant but is unclear. This feedback is 3 as it identifies a need for more empirical evidence and comparison, which could strengthen the paper. However, the comment lacks specific guidance on how to construct these examples or how to effectively compare the results to stateoftheart performance, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty of the problem and questions the rationale behind Assumption 1. It explains that Assumption 1 restricts the adversary to pick samples such that a constant alphafraction of the observations are hidden or removed. The reviewer then provides a logical explanation of how this assumption might still be sufficient for accurate recovery. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to improve the draft. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty of the problem and questions the rationale behind Assumption 1. It provides a logical explanation of how the assumption might still be sufficient for accurate recovery. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its critique of the assumption, it lacks grounding as it does not clearly indicate which part of the paper is being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the difficulty of the problem and questions the rationale behind Assumption 1. It provides a logical explanation of how the assumption might still be sufficient for accurate recovery, offering a clear reasoning process. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the difficulty of the problem and questions the rationale behind Assumption 1. It provides a logical explanation of how the assumption might still be sufficient for accurate recovery, offering a clear reasoning process. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. While it identifies an area for improvement, it does not provide actionable steps or detailed feedback, making it 3. The authors would need to infer the implications and potentially seek additional guidance to fully benefit from the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a contradiction between the findings presented in Figure 1 and Table 1. It points out that Figure 1 suggests an increase in NNGS with an increase in k, which contradicts the results in the last two columns of Table 1. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this contradiction or what specific aspects of the analysis need to be revisited. The authors are left without guidance on how to resolve this inconsistency, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the contradiction between the findings in Figure 1 and the results in the last two columns of Table 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 contradicts the results in the last two columns of Table 1. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left to question the validity of the claim, making it difficult to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between the findings presented in Figure 1 and Table 1. It highlights that Figure 1 suggests an increase in NNGS with an increase in k, which contradicts the results in the last two columns of Table 1. This observation is clear and provides a specific area for the authors to investigate and address. However, the comment does not offer any suggestions or guidance on how to resolve this contradiction or what specific aspects of the analysis might need to be revisited. While it points out a potential issue, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the extensibility of the proposed method to a large number of tasks, specifically questioning the impact on shared parameters. It suggests that the experiments should include results for a larger number of tasks, up to 100, to address this concern. The comment provides a clear action for the authors to take, which is to address the question regarding the effect of the number of tasks on the proposed approach. However, it lacks specific guidance on how to conduct this analysis or what data to include. The action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment raises a concern about the extensibility of the proposed method to a large number of tasks, specifically questioning the impact on shared parameters. However, it does not specify which part of the paper this concern relates to, such as a particular section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a potential issue with the method\"s extensibility and asks for clarification on the impact of a large number of tasks, particularly on shared parameters. However, without explicit grounding, the authors may struggle to locate the relevant section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the extensibility of the proposed method to a large number of tasks, specifically questioning the impact on shared parameters. It suggests that the experiments should include results for a larger number of tasks, up to 100, to address this concern. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the current experiments are insufficient. Without detailed justification or evidence, the claim remains 3, as the authors may need to infer the basis for the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, specifically questioning the impact on shared parameters. It suggests that the experiments should include results for a larger number of tasks, up to 100, to address this concern. The comment provides a clear question for the authors to address, which is to discuss the effect of the number of tasks on the proposed approach. However, it lacks specific guidance on how to conduct this analysis or what data to include, making it 3. The feedback is valuable as it highlights a potential limitation of the method and encourages the authors to expand their experiments. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the eyetracking data selection and filtering process, noting that everything is analyzed with some exclusions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes might be necessary. The action is implicit, as the authors would need to infer that they should clarify the data selection and filtering process or provide more details on the exclusions. The lack of concrete instructions or examples makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eyetracking data selection/filtering,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the analysis of eyetracking data, noting that everything is analyzed with some exclusions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a potential issue with the eyetracking data selection and filtering process, noting that everything is analyzed with some exclusions. However, the comment does not provide any specific reasoning, examples, or references to support why this approach might be perplexing or problematic. Without additional context or justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the eyetracking data selection and filtering process, noting that everything is analyzed with some exclusions. This observation is specific and highlights a potential area for clarification or improvement in the paper. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. While it points out a concern, it does not offer a comprehensive or detailed response, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the credibility of the results presented in Appendix 24, specifically questioning the alignment of InitNO with StableDiffusionv14. While the comment points out that InitNO\"s alignment is lower than that of StableDiffusionv14, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the credibility of their results. The action is implicit, as the authors would need to infer that they should investigate and potentially revise the appendix to align with the reported findings. However, the lack of concrete instructions or suggestions makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the credibility of the results in Appendix 24, specifically questioning the alignment of InitNO with StableDiffusionv14. However, it does not specify which part of the appendix or table this refers to, making it weakly grounded. The comment is specific in detailing the issue with the alignment, but without explicit references to the appendix or table, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the credibility of Appendix results for InitNO is questionable, specifically noting that InitNO\u2019s alignment is lower than that of StableDiffusionv14. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the credibility of the results presented in Appendix 24, particularly concerning the alignment of InitNO with StableDiffusionv14. It points out that the reported alignment for InitNO is lower than that of StableDiffusionv14, which raises concerns about the reliability of the findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the credibility of their results. While it highlights a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing could be improved with additional editing, particularly from a languageusage and type perspective. It also notes that the notation in the equations is exact but can become unwieldy, suggesting that some sub/superscripts could be dropped for convenience. While the comment provides explicit suggestions for improvement, such as additional editing and the potential benefit of simplifying notation, it lacks concrete guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be done but without specific steps or examples, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the writing quality of the paper, noting that it is occasionally uneven and could benefit from additional editing. It also points out that the notation in the equations is exact but can become unwieldy, suggesting that some sub/superscripts could be dropped for convenience. However, the comment does not specify which sections or parts of the paper are affected by these issues, making it weakly grounded. While it provides some specificity by mentioning the writing quality and the potential benefit of simplifying notation, the lack of explicit references to specific sections or parts of the paper limits the authors\" ability to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the writing is occasionally uneven and could benefit from additional editing, particularly from a languageusage and type perspective. It also notes that the notation in the equations is exact but can become unwieldy, suggesting that some sub/superscripts could be dropped for convenience. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to justify the claims. Therefore, the comment is rated as 2, as it provides some basis for the claim but lacks sufficient detail or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the writing quality and the notation in the equations. It suggests that the writing could benefit from additional editing, particularly from a languageusage and type perspective, which is a valuable piece of feedback for the authors to consider. Additionally, the comment points out that the notation in the equations is exact but can become unwieldy, suggesting that some sub/superscripts could be dropped for convenience. This feedback is actionable and provides specific suggestions for improvement, such as considering simplifying the notation. However, the comment could be more helpful if it included examples of where the writing could be improved or more detailed guidance on how to simplify the notation. Overall, the comment is 4 as it offers clear directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides several points for improvement. It suggests that the authors should explain the cost of image acquisition and the type of manual collection used, which is a clear and explicit action. However, it does not specify how the authors should present this information or what kind of explanation is expected. Additionally, the comment mentions minor issues such as the phrasing of a sentence and a request for clarification on \"regulatory requirements,\" but these are not actionable. Therefore, the comment is 4, as it provides some guidance but lacks detailed instructions on how to implement the suggestions. This aligns with a score of 4.", "grounding_specificity_rationale": "The comment addresses specific issues related to the dataset size, the cost of image acquisition, and the phrasing of a sentence. It also requests clarification on \"regulatory requirements.\" However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as explaining the cost and type of manual collection, and clarifying the phrasing of a sentence. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the dataset size, the cost of image acquisition, and the phrasing of a sentence. It does not contain any subjective opinions or claims that require verification. The questions are factual and seek clarification, which aligns with the classification of \"X\". Therefore, the comment is labeled as \"X\" with a score of X.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improvement. It highlights the issue of the dataset size relative to the development cost, suggesting that the authors should explain the cost of image acquisition and the type of manual collection used. This is a clear and actionable point that would help the authors improve the transparency and reproducibility of their work. Additionally, the comment points out a minor issue with the phrasing of a sentence, which is a specific and actionable feedback. However, the comment could be more helpful if it provided more detailed guidance on how to address these issues or suggested alternative approaches. Overall, the feedback is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generation of the third column in Figure 7, noting that the visualizations do not appear to be normalized. While it prompts the authors to clarify this aspect, it does not provide explicit instructions or suggestions on how to address the issue. The action is implicit, as the authors need to infer that they should investigate the normalization process and provide a justification for the visualizations. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the third column of the figure, questioning its generation and noting that the visualizations do not seem to be normalized. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generation of the third column in Figure 7, noting that the visualizations do not appear to be normalized. This is a factual observation and does not contain any subjective opinions or claims that require verification. The comment is descriptive and does not provide any reasoning or evidence to support the observation. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the generation of the third column in Figure 7, noting that the visualizations do not seem to be normalized. This feedback is 3 as it points out a potential issue with the clarity or consistency of the visualizations. However, it lacks actionable guidance or suggestions on how the authors might address this concern. The comment is clear and identifies a specific area for improvement, but it does not provide detailed feedback or recommendations, which limits its overall helpfulness. Therefore, it aligns with a score of 3, as it offers some insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the heuristic nature of the assignment entropy maximization approach and suggests that the authors should evaluate the advantages of using this method in the ablation experiment. It also points out that the authors did not discuss any potential negative societal impacts of their work. While the comment provides explicit guidance on what needs to be addressed, it lacks specific details on how to evaluate the advantages of assignment entropy maximization or how to discuss the potential negative societal impacts. The action is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the heuristic nature of the assignment entropy maximization approach and suggests that the authors should evaluate its advantages in the ablation experiment. It also points out that the authors did not discuss any potential negative societal impacts of their work. However, the comment does not specify which part of the paper discusses the assignment entropy maximization or the ablation experiment, making it weakly grounded. The comment is specific in detailing the issues with the approach and the lack of discussion on societal impacts, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the investigation of assignment entropy maximization is rather heuristic and suggests that the authors should evaluate the advantages of using this method in the ablation experiment. It also notes that the authors did not discuss any potential negative societal impacts of their work. The claim about the heuristic nature of the investigation is 3, as it implies that the approach lacks a strong theoretical foundation or empirical evidence. However, the claim about the lack of discussion on negative societal impacts is not supported by any specific examples or references, making it difficult for the authors to address this aspect. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the heuristic nature of the assignment entropy maximization approach and suggests that the authors should evaluate its advantages in the ablation experiment. It also points out that the paper lacks a discussion of potential negative societal impacts, which is a significant oversight. While the comment highlights areas for improvement, it could be more helpful if it provided specific guidance on how to evaluate the advantages of assignment entropy maximization or suggested ways to address the lack of discussion on societal impacts. Overall, the feedback is 3 as it directs the authors to important aspects of their work that need attention, but it could be more comprehensive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the experimental section, noting that only one baseline model is used. However, it does not provide any explicit or implicit suggestions on how to address this issue or what additional baselines could be included. The comment lacks concrete guidance on how the authors might improve their draft by adding more baselines, making it difficult for them to know what steps to take. As a result, the comment is 1, as it does not offer any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what is missing or what needs to be addressed regarding the lack of baselines. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is only one baseline model in the experimental section. However, the comment does not provide any supporting evidence or justification for this claim. Without additional context or explanation, the authors cannot verify the accuracy of this statement or understand why it is a concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental section, noting that only one baseline model is used. However, it does not provide any suggestions or guidance on how to address this limitation or what additional baselines could be included. The comment lacks actionable feedback, as it does not offer any insights into how the authors might improve their draft by expanding the experimental section. Therefore, the comment is 2, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of comparisons with specific baselines and literature, such as traditional QAT methods (LSQ, LSQ+), other LLMbased QAT work (e.g., LLMQAT [1]), and more recent PTQ baselines like SpinQuant [2]. It also suggests that while these comparisons are more memoryintensive, it would be important to understand the benefits of using extra memory compared to relying solely on finetuning lowrank adapters. However, the comment does not provide explicit guidance on how the authors should address these missing comparisons or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing baselines and literature comparisons, such as traditional QAT methods (LSQ, LSQ+), other LLMbased QAT work (e.g., LLMQAT [1]), and more recent PTQ baselines like SpinQuant [2]. The comment also suggests a comparison to traditional QAT, highlighting the memory cost and the importance of understanding the benefits of using extra memory. This provides clear guidance on what needs to be addressed in the results section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some baselines and literature comparisons are missing in the results section, specifically mentioning traditional QAT methods (LSQ, LSQ+), other LLMbased QAT work (e.g., LLMQAT [1]), and more recent PTQ baselines like SpinQuant [2]. The comment suggests that while these comparisons are more memoryintensive, it would be important to understand the benefits of using extra memory compared to relying solely on finetuning lowrank adapters. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the missing comparisons and the importance of the memory cost to fully understand the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with several important baselines and literature, such as traditional QAT methods (LSQ, LSQ+), other LLMbased QAT work (e.g., LLMQAT [1]), and more recent PTQ baselines like SpinQuant [2]. It also suggests that while these comparisons are more memoryintensive, it would be important to understand the benefits of using extra memory compared to relying solely on finetuning lowrank adapters. This feedback is 4 as it provides clear guidance on what additional comparisons the authors should include to strengthen their results section. However, it could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects of the results would be most relevant to include. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about how to define an attribute and what the difference between attributes is, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper these definitions are needed, nor does it offer any guidance on how to define or differentiate attributes. The action is implicit and vague, as the authors are left to infer that they need to add more detailed instructions in the relevant sections. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about how to define an attribute and what the difference between attributes is, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper these definitions are needed, nor does it provide any guidance on how to define or differentiate attributes. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide any examples or detailed guidance on how to define or differentiate attributes. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about how to define an attribute and what the difference between attributes is, suggesting that more detailed instructions should be provided. However, it does not contain any subjective opinions, claims, or suggestions that require verification. The comment is purely descriptive and does not provide any evidence or reasoning to support the need for more detailed instructions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises questions about how to define an attribute and what the difference between attributes is, suggesting that more detailed instructions should be provided. However, it lacks specificity and does not offer any guidance or suggestions on how to address these issues. The comment is vague and does not provide actionable feedback that would help the authors improve their draft. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the theory\"s ability to predict the robustness of a model against adversarial perturbations. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the theory or the paper to make it more useful for predicting robustness. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a concern about the theory\"s ability to predict robustness against adversarial perturbations, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on how the theory could be improved or what specific aspects of the theory need to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses a concern about the theory\"s ability to predict robustness against adversarial perturbations. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the concern, making the comment 1.", "helpfulness_rationale": "The review comment raises a concern about the theory\"s ability to predict robustness against adversarial perturbations, which is a critical aspect of model evaluation. However, the comment lacks specificity and actionable suggestions. It does not provide any guidance on how the authors might address this issue or what improvements could be made to the theory. Without concrete advice or examples, the authors are left without a clear path forward to enhance their work. Therefore, the comment is 2, as it identifies a potential weakness but does not offer substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the definition of \"scenario\" in the paper and the presence of an \"agnostic\" part. While it prompts the authors to clarify these terms, it does not provide explicit instructions on how to address these uncertainties. The authors are left to infer that they need to provide more context or examples to clarify the meaning of \"scenario\" and explain the \"agnostic\" part. The action is implicit and somewhat vague, as it does not specify what needs to be done to clarify these aspects. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the definition of \"scenario\" in the paper and the presence of an \"agnostic\" part. However, it does not specify which part of the paper these terms are discussed or where the authors should look for clarification. The lack of explicit references to specific sections or elements of the paper makes it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific in its questions, it is 1 because it does not provide clear guidance on which parts of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the definition of \"scenario\" and the presence of an \"agnostic\" part in the paper. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support the questions posed. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the clarity of the term \"scenario\" and the presence of an \"agnostic\" part in the paper. While it identifies areas where the authors might need clarification, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential areas of confusion, but it lacks depth and actionable advice, making it difficult for the authors to improve their draft effectively. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the naming of a method as \"Maestro\" and finds it confusing and never introduced. While the comment suggests that the authors should clarify the naming, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the naming convention. However, the comment lacks concrete details on what specific aspects of the naming should be addressed or how to improve it. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment questions the naming of a method as \"Maestro\" and finds it confusing and never introduced. However, it does not specify which part of the paper discusses the method or why the name is confusing. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of the confusing name, such as suggesting alternative names or explaining the rationale behind the current name. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the naming of a method as \"Maestro\" and finds it confusing and never introduced. However, the comment does not provide any specific reasoning, examples, or references to support why the name is confusing or why it should be reconsidered. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment questions the naming of a method as \"Maestro\" and finds it confusing and never introduced. While the comment identifies a potential issue with the naming convention, it does not provide specific suggestions or guidance on how to address this concern. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to define what \"best\" means in the context of the paper when referring to candidates. This provides a clear and direct action for the authors to take, as they need to clarify the criteria for selecting the \"best\" candidate. The comment is specific and concrete, giving the authors a clear direction on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the definition of \"best\" in the context of the paper. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification on the definition of \"best\" when referring to candidates, which is a request for clarification rather than a claim that needs verification. It does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides a clear and actionable suggestion for the authors to improve their draft. By explicitly asking for clarification on the definition of \"best\" when referring to candidates, the comment directs the authors to a specific area that needs attention. This guidance is precise and constructive, enabling the authors to enhance the clarity and precision of their paper. The feedback is detailed and provides a clear path for improvement, making it a valuable contribution to the authors\" work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential overclaim in the paper, specifically noting that the proposed method does not consider feedforward layers, yet some text suggests it does. This feedback is explicit, as it directly points out the inconsistency in the description of the method. However, it lacks concrete guidance on how the authors should address this issue, such as suggesting a clarification or revision of the text. The action is implicit, as the authors need to infer that they should correct the overclaim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some points are slightly overclaimed\" and \"some text is described as if the proposed method considers all components in transformer networks.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it highlights a potential overclaim and suggests that the text might be misleading by implying the consideration of all components in transformer networks, which is not the case. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some points are slightly overclaimed, specifically noting that the proposed method does not consider feedforward layers, yet some text suggests it does. This claim is 3 as it provides a specific example of an overclaim, but it lacks detailed reasoning or references to support the assertion. The authors would need to infer the basis for the overclaim, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential overclaim in the paper, specifically noting that the proposed method does not consider feedforward layers, yet some text suggests it does. This feedback is clear and actionable, as it highlights a discrepancy in the description of the method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as recommending a clarification or revision of the text. Overall, the comment is 4 as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the experiments design is not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these issues or improve the motivation of their experiments. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments design\" and specifies the issues with \"no variations\" and \"Up to 18 games\" finetuning methods. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly identifies the areas that need improvement, providing detailed feedback on the motivation of the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments design is not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or justifications, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments design, noting that the motivation behind the \"no variations\" and \"Up to 18 games\" finetuning methods is not clearly explained. This feedback is 3 as it highlights a potential area for improvement in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues. Without actionable advice or examples, the authors may struggle to understand how to improve their experiments design. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the presentation of results in Table 1/2, noting that only MissV and MissA results are shown. It suggests that the authors should consider evaluating the method\"s performance under missing modality cases, such as testing sets with different missing ratios. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to address it. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the evaluation of the method performance under missing modality cases, such as testing sets with different missing ratios. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only shows results for MissV and MissA in tables 1/2, suggesting that it is necessary to evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1/2, noting that only MissV and MissA results are shown. It suggests that the authors should consider evaluating the method\"s performance under missing modality cases, such as testing sets with different missing ratios. This feedback is 3 as it highlights a potential area for improvement in the evaluation of the method. However, the comment lacks detailed guidance on how to implement this suggestion or what specific steps the authors should take to address it. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the conditions used in the experiments are not changed during browsing the web shop and recommends including an ablation study on the effect of using image features. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct an ablation study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the conditions used in the experiments are not changed during browsing the web shop and recommends including an ablation study on the effect of using image features. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific about the suggestion to include an ablation study, the lack of grounding makes it challenging for the authors to understand the context and relevance of the comment. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the conditions used in the experiments are not changed during browsing the web shop and recommends including an ablation study on the effect of using image features. However, the comment does not provide any specific reasoning, examples, or references to support why this is a necessary or important consideration. Without additional context or justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the conditions used are not changed during browsing the web shop. It suggests that an ablation study on the effect of using image features would be beneficial. While the comment highlights a potential area for improvement, it lacks detailed guidance on how to conduct the ablation study or what specific aspects of the conditions should be varied. This provides the authors with a general direction but does not offer comprehensive feedback, making the comment 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what steps they could consider to improve the approach in these challenging settings. Without specific advice or suggestions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the performance in challenging settings, but it lacks detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" This question highlights a potential area for further exploration and improvement, as it prompts the authors to consider how their approach might perform in more complex scenarios. However, the comment lacks specific suggestions or guidance on how to address this concern or what steps the authors could take to enhance their approach. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to consider but does not offer detailed guidance on how to implement it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the authors\" understanding of identifiability, stating that it is a property of a model assuming infinite data can be observed, and that one cannot conclude a model is not identifiable due to insufficient data. While the comment identifies a specific issue with the authors\" understanding, it does not provide explicit guidance on how the authors should correct this misunderstanding or improve their understanding of identifiability. The action is implicit and vague, as it does not specify what steps the authors should take to address this issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the authors\" understanding of identifiability, a concept in statistical modeling. It highlights that identifiability is a property of a model assuming infinite data can be observed, and that one cannot conclude a model is not identifiable due to insufficient data. However, the comment does not specify which part of the paper discusses identifiability or where the authors\" misunderstanding is evident. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs clarification. While the comment is specific in its critique of the authors\" understanding, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors\" understanding of identifiability is incorrect, stating that identifiability is a property of a model assuming infinite data can be observed, and that one cannot conclude a model is not identifiable due to insufficient data. This claim is 3 as it provides a clear explanation of the concept of identifiability and its relation to the amount of data available. However, it lacks specific examples or references to support the claim, which could enhance its persuasiveness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific misunderstanding regarding the concept of identifiability in statistical modeling. It correctly points out that identifiability is a property of a model assuming infinite data can be observed, and that one cannot conclude a model is not identifiable due to insufficient data. This feedback is clear and actionable, as it provides the authors with a specific area to clarify and correct their understanding. By addressing this misunderstanding, the authors can improve the accuracy and rigor of their work. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the results do not show any particular benefit compared to a simple baseline. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve their draft or what specific aspects need to be revised to demonstrate a benefit over the baseline. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It is also not specific because it does not detail what aspects of the results or comparison with the baseline need to be improved. The authors cannot confidently determine which section or part of the paper is being referred to, and the comment lacks specificity in addressing the issue. Therefore, this comment is rated as \"1 and Not Specific,\" corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the results show no particular benefit with respect to the simple baseline the authors compare with. However, the comment lacks specific details or examples to support this claim. It does not provide any evidence or reasoning to substantiate the assertion that the results do not show a benefit over the baseline. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the results do not show a particular benefit compared to a simple baseline, which is a valid concern. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their results. It does not provide actionable feedback or detailed insights into potential improvements or alternative approaches that could be explored. Without concrete suggestions or a clear direction for the authors, the comment is 2, as it identifies a problem but does not offer a comprehensive solution. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific areas where the method\"s efficiency could be improved. It mentions the requirement for a vocoder pretrained on 60khour LibriLight and the lack of description regarding the time cost of this pretraining process, specifically the GPU hours. Additionally, it points out that the inference process involves a diffusionbased vocoder, which results in slower inference speed compared to DSP and WarpNet. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to take. The authors are left to infer that they should consider optimizing the pretraining process or exploring alternative methods to improve efficiency. Therefore, the comment is 3, as it provides some direction but lacks concrete details on how to implement the suggestions.", "grounding_specificity_rationale": "The comment addresses the efficiency of the method in the training and inference processes, specifically mentioning the requirement for a vocoder pretrained on 60khour LibriLight and the lack of description regarding the time cost of this pretraining process. It also highlights the slower inference speed due to the use of a diffusionbased vocoder. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the time cost of pretraining and the slower inference speed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method requires a vocoder pretrained on 60khour LibriLight, which trains a WaveFiT vocoder from scratch without detailing the time cost, such as GPU hours. It also notes that the inference process incorporates a diffusionbased vocoder, resulting in slower inference speed compared to DSP and WarpNet. While the comment provides specific details about the method\"s requirements and limitations, it lacks references or examples to fully substantiate the claims. The reasoning is somewhat clear, but the lack of detailed evidence or references makes it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on the efficiency of the method, highlighting the need for a vocoder pretrained on 60khour LibriLight and the lack of description regarding the time cost of this pretraining process. It also points out that the inference process, which incorporates a diffusionbased vocoder, results in slower inference speed compared to DSP and WarpNet. While the comment identifies areas for improvement, it lacks detailed suggestions or guidance on how to address these issues. The feedback is 3 as it directs the authors to consider optimizing the pretraining process or exploring alternative methods to improve efficiency. However, it could be more helpful with additional suggestions or actionable steps. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the generalization of the scoring function s(\u00b7; G) to multiple goal documents or without a gold document. It suggests that the paper does not explore this generalization, which raises questions about the framework\"s generalizability. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore the generalization. The action is implicit and vague, as it does not specify how the authors should proceed to explore the generalization or what aspects of the framework need to be examined. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the generalization of the scoring function s(\u00b7; G) to multiple goal documents or without a gold document, suggesting that this exploration is not explored in the paper. However, the comment does not specify which part of the paper discusses the scoring function or the generalization aspect, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of generalization, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not explore the generalization of the scoring function s(\u00b7; G) to multiple goal documents or without a gold document, which raises questions about the framework\"s generalizability. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains 3, as it is based on an assertion without thorough justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the generalization of the scoring function s(\u00b7; G) to multiple goal documents or without a gold document, questioning the framework\"s generalizability. While the comment highlights a specific area that could be explored further, it does not provide detailed guidance or suggestions on how the authors might address this issue or what specific aspects of the framework need to be examined. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\"s performance. It implies that this additional data could offer insights into the framework\"s comparative performance throughout the recommendation process, allowing readers to better assess its effectiveness. However, the comment does not specify how this data should be presented or what specific aspects of the performance it should address. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\"s performance. It references a specific paper [1] that provides context for this suggestion. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The suggestion is specific in terms of what data should be added, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact area where this information should be incorporated. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\"s performance. It references a specific paper [1] that provides context for this suggestion. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The authors are left to infer the necessity and importance of this additional data, which could be strengthened with more explicit justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\"s performance. This feedback is valuable as it highlights a specific area where additional data could enhance the paper\"s comprehensiveness and allow readers to better assess the effectiveness of the framework. However, the comment could be more helpful if it provided guidance on how to present this data or what specific aspects of the performance it should address. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a general issue with the paper\"s density and suggests that numbered lists should be presented as actual lists for better readability. While the comment provides a clear action\u2014improving readability by converting numbered lists to actual lists\u2014it does not specify which parts of the paper contain these lists or how the authors should implement this change. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of the paper being dense and suggests improvements in readability by converting numbered lists to actual lists. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific, as it provides a clear direction for improvement by recommending a change in the presentation of lists. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is dense and difficult to read, suggesting that numbered lists should be presented as actual lists for better readability. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact sections that need improvement. Without detailed evidence or examples, the claim is 3, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s readability, noting that it is dense and difficult to follow in parts. It suggests that numbered lists, which are frequently used in the paragraphs, could be presented as actual lists for better clarity and ease of understanding. This feedback is actionable and provides a clear direction for improvement, as it offers a specific suggestion that the authors can easily implement. However, the comment could be more helpful if it included examples of where these lists are located or how they could be converted. Overall, the comment is 4 as it highlights a practical issue and offers a constructive suggestion, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they are using the same spectral cues as a simple classifier. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fundamental nature of \"fake image detectors\" and whether they are using the same spectral cues as a simple classifier. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it lacks specific references or context. It is also not specific because it does not provide detailed guidance on how to address the question or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they are using the same spectral cues as a simple classifier. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises an interesting question about the fundamental nature of \"fake image detectors\" and whether they are using the same spectral cues as a simple classifier. This question prompts the authors to consider the underlying mechanisms and assumptions of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this question or what changes they could make to their draft. While it encourages critical thinking, it does not provide actionable feedback or detailed insights that would help the authors improve their work. Therefore, the comment is 3, as it identifies a potential area for deeper exploration but does not offer concrete advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy between the visualization results and the ground truth, suggesting that the results are \"terrible.\" It then requests an analysis of both satisfied and terrible cases. However, the comment does not provide explicit guidance on how to analyze these cases or what specific aspects of the visualization should be examined. The action is implicit, as the authors need to infer that they should analyze the visualization results in more detail, particularly focusing on the differences between satisfied and unsatisfied cases. While the comment is 3, it lacks concrete details on how to implement the suggested analysis, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3,\" which likely refers to a specific section or part of the paper. This allows the authors to accurately identify the section being addressed. The comment is also specific because it requests an analysis of both satisfied and terrible cases in the visualization results, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visualization results are \"terrible\" compared to the ground truth. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the visualization results, noting that they are \"terrible\" compared to the ground truth. This feedback is valuable as it highlights a potential weakness in the paper\"s presentation and suggests that the authors should provide a more detailed analysis of both successful and unsuccessful cases. However, the comment lacks specific guidance on how to analyze these cases or what aspects of the visualization should be examined. While it points out an area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity. The authors would need to infer the need for a more detailed analysis, which could be challenging without further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper builds upon a large body of previous work, suggesting that limitations or issues in those works could affect the validity and effectiveness of the proposed approach. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not provide explicit or implicit actions for the authors to take to address these concerns. It lacks specific guidance on how to mitigate potential issues or improve the validity of the approach. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a large body of previous work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting that the paper builds upon this work, which could affect the validity and effectiveness of the proposed approach. The comment further notes that the implementation process is similar to previous work on GAN, providing specific details about what needs to be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper builds upon a large body of previous work, which could affect the validity and effectiveness of the proposed approach. It also notes that the implementation process is similar to previous work on GAN. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and how it impacts their work. Therefore, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by suggesting that building upon a large body of previous work could affect the validity and effectiveness of the proposed approach. It also notes that the implementation process is similar to previous work on GAN. However, the comment lacks specific details or actionable suggestions on how the authors might address these concerns or improve their work. While it raises a valid point about the need for careful consideration of the limitations of previous work, it does not provide guidance on how to mitigate these issues or enhance the paper\"s contribution. As a result, the comment is 3, as it highlights an important consideration but does not offer concrete advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the design of a policy and the use of information during the partitioning step. It suggests that if information unavailable to the policy is used for clustering, it might be better to incorporate it during policy training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the design of a policy and the use of information during the partitioning step. It questions whether information unavailable to the policy is being used for clustering and suggests that if such information is used, it might be better to incorporate it during policy training. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific in its questioning, it lacks grounding as it does not provide explicit references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the design of a policy and the use of information during the partitioning step. It questions whether information unavailable to the policy is being used for clustering and suggests that if such information is used, it might be better to incorporate it during policy training. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the authors are using information unavailable to the policy for clustering. This lack of evidence makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the design of a policy and the use of information during the partitioning step. It suggests that if information unavailable to the policy is used for clustering, it might be better to incorporate it during policy training. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. The authors would need to infer how to respond to the comment, which limits its overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to improve the rendering quality. Without specific advice or steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for NeRF\"s rendering quality being worse than NeuS and Geo NeuS, providing a clear and specific issue to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, but it does not provide any claim, judgment, or suggestion. It is a factual question that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, which is a relevant issue for the authors to consider. However, the comment does not provide any suggestions or insights on how to address this issue or improve the rendering quality. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and direction."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the boldness of the assumption made in Section 3.7, stating that \"This hints, that purely unsupervised large scale pretraining might not be suitable for NLP applications.\" The reviewer expresses confusion about how this conclusion can be drawn from the proposed evaluation approach. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or substantiate the claim. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the boldness of the assumption made in that section and highlights a lack of clarity regarding how the conclusion can be drawn from the evaluation approach. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the boldness of the assumption made in Section 3.7, stating that \"This hints, that purely unsupervised large scale pretraining might not be suitable for NLP applications.\" The reviewer expresses confusion about how this conclusion can be drawn from the proposed evaluation approach. However, the comment lacks specific examples, detailed reasoning, or references to support the claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific point in the manuscript, Section 3.7, where the authors make a bold assumption about the suitability of unsupervised largescale pretraining for NLP applications. The reviewer questions the basis of this assumption, noting that it is unclear how it can be concluded from the proposed evaluation approach. This feedback is 3 as it highlights a potential weakness in the manuscript\"s argumentation. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or clarify their reasoning. Without additional insights or constructive feedback, the authors may struggle to fully understand and rectify the issue. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific omissions in the related work section, particularly regarding recent studies that achieve higher performance on SUN and DCN, which is not discussed or included in Table 3. It also mentions the relevance of another study [B] with respect to transductive label propagation. However, the comment does not provide explicit guidance on how the authors should address these omissions or include these studies in their paper. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"2.2,\" allowing the authors to accurately identify the sections being addressed. It also specifies what needs to be addressed, such as discussing recent related work, including [A] and DCN in Table 3, and mentioning the relevance of [B] with respect to transductive label propagation. This provides clear guidance on what aspects of the related work need improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper misses to discuss recent related work, specifically mentioning [A] and DCN, and that [B] is relevant with respect to transductive label propagation. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations of why these omissions are significant or how they impact the paper\"s contribution. As a result, the claim is not 5, making it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved, particularly in the related work section. It points out the omission of recent studies, such as [A] and DCN, which achieve higher performance on SUN and are not discussed or included in Table 3. Additionally, it notes the relevance of another study [B] with respect to transductive label propagation. However, the comment lacks detailed guidance on how the authors should address these omissions or incorporate these studies into their work. While it provides a clear direction for improvement, the feedback could be more helpful if it included specific suggestions or examples of how to integrate the mentioned studies. Therefore, the comment is 3, as it identifies important areas for improvement but does not provide comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the operator used in Figure 2 should be a Hadamard product instead of addition. This is a specific and explicit action that the authors should take to correct the figure. The comment provides clear guidance on what needs to be changed, making it 5. The authors know exactly how to implement this change, as it involves replacing the addition operator with a Hadamard product. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the operator used in the figure should be a Hadamard product instead of addition. This provides the authors with a clear understanding of what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the operator in Figure 2 should be a Hadamard product instead of addition. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this change is necessary or beneficial. Without further explanation or evidence, the authors may find it challenging to understand the rationale behind the recommendation. Therefore, the comment is considered 2, as it provides some justification but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific issue in Figure 2, suggesting that the operator should be a Hadamard product instead of addition. This is a clear and actionable suggestion that provides the authors with a specific direction to improve their draft. By addressing this feedback, the authors can enhance the accuracy and clarity of their figure, which is crucial for the overall presentation of their work. The comment is 4 as it offers a direct and constructive improvement, though it could be more comprehensive if it suggested alternative approaches or provided additional context. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges that the authors have addressed the concerns and revised the score from 7 to 8. It highlights that the nonstandard finite sum assumption is discussed in the theoretical analysis section but could be anticipated in the abstract. However, it notes that the discrepancy between the theoretical and practical updates of SABA is mentioned briefly and not properly addressed, with a reference to a question section. While the comment identifies a specific area that needs further attention, it does not provide explicit guidance on how to address the discrepancy or expand on the discussion. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue raised in the review point, allowing the authors to accurately identify the part of the paper being addressed. It specifies the concern regarding the discrepancy between the theoretical and practical updates of SABA, which is mentioned briefly and not properly addressed. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have addressed the concerns and revised the score from 7 to 8. It highlights that the nonstandard finite sum assumption is discussed in the theoretical analysis section but could be anticipated in the abstract. However, it notes that the discrepancy between the theoretical and practical updates of SABA is mentioned briefly and not properly addressed, with a reference to a question section. While the comment provides some justification for the claim, it lacks detailed reasoning or specific examples to fully substantiate the assertion about the discrepancy. The absence of explicit references or detailed explanations makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides a detailed response to the authors, acknowledging that they have addressed the concerns and revised the score from 7 to 8. It highlights specific aspects of the paper that require further attention, such as the discussion of the nonstandard finite sum assumption in the abstract and the discrepancy between the theoretical and practical updates of SABA. The comment is 4 as it offers clear feedback and guidance on areas that need improvement, but it could be more comprehensive if it included suggestions for addressing the discrepancy or expanding on the discussion of the nonstandard assumption. Overall, the feedback is actionable and provides valuable insights for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the paper\"s claim about UnKE\"s ability to preserve pretrained knowledge and the experimental results, which show that UnKE\"s performance is worse than the baseline. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. It lacks concrete guidance on what changes or actions the authors should take to align their claims with the experimental findings. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s claim about UnKE\"s causedriven optimization and the experimental results that contradict this claim. It references specific tables (Table 2 and Table 3) and provides a citation to support the claim, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with UnKE\"s performance compared to the baseline, providing a detailed explanation of the discrepancy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion about UnKE\"s ability to preserve pretrained knowledge is contradicted by the experimental results, which show that UnKE\"s performance is worse than the baseline. The comment provides specific references to tables (Table 2 and Table 3) and a citation to support the claim, offering a clear and detailed explanation of the discrepancy. This level of detail and evidence makes the claim 5, as it provides a logical and comprehensive basis for the authors to understand and address the issue. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant discrepancy between the paper\"s claim about UnKE\"s ability to preserve pretrained knowledge and the experimental results presented in the paper. It highlights that UnKE\"s performance is worse than the baseline, as evidenced by the data in Table 2 and Table 3. This feedback is valuable as it points out a critical inconsistency that needs to be addressed. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might investigate or explain this discrepancy. Without specific advice on how to address the issue, the comment is 3, as it directs the authors to a potential area of concern that requires further attention. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the intention behind the use of BWTP/GLBW, noting that many details are relegated to the appendix, making it difficult for readers to understand them initially. While the comment identifies a potential issue with the clarity of the explanation, it does not provide explicit guidance on how the authors should address this. The authors are left to infer that they need to provide a clearer explanation of the intention behind BWTP/GLBW, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment addresses the explanation of BWTP/GLBW, noting that many details are in the appendix, making it difficult to understand them initially. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. The comment is weakly grounded because the authors cannot confidently determine which part of the paper is being addressed. It is also specific in that it highlights the lack of clarity in the explanation of BWTP/GLBW. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the explanation for the intention of BWTP/GLBW is weak, noting that many details are in the appendix, making it difficult for readers to understand them initially. However, the comment does not provide specific examples or references to support this claim, leaving the authors uncertain about the validity of the feedback. Without additional context or evidence, the claim is considered 1. Therefore, the comment is labeled as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the explanation for the use of BWTP/GLBW, noting that many details are in the appendix, making it difficult for readers to understand them initially. While the comment highlights a specific area that could be improved, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice or specific recommendations, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a proof in the revision, either as supplementary material or potentially in the main paper, due to the omission of a proof at the end of Section 3. The comment is explicit in stating the action to be taken, which is to include the proof. It also provides a clear reason for the action, explaining why the proof was omitted. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the omission of a proof at the end of Section 3, suggesting that the authors should include it in the revision, either as supplementary material or potentially in the main paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a proof in the revision, either as supplementary material or potentially in the main paper, due to the omission of a proof at the end of Section 3. While the comment provides a clear reason for the suggestion, it lacks specific examples or references to support the claim that the proof is essential for the paper\"s integrity or clarity. Without additional context or evidence, the authors may find it challenging to understand the specific reasons for the omission and how to address it. Therefore, the comment is 3, as it provides a logical basis but lacks detailed justification or references.", "helpfulness_rationale": "The review comment is clear and actionable, pointing out a specific issue with the draft: the omission of a proof at the end of Section 3. It suggests that the authors should include the proof in the revision, either as supplementary material or potentially in the main paper. This feedback is helpful as it provides a clear direction for improvement, guiding the authors on what needs to be addressed. However, the comment could be more helpful if it offered additional context or suggestions on how to present the proof effectively. Overall, the comment is 4, as it identifies a significant area for improvement and provides a clear action for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS due to the lack of direct dependence on magnitudes. This feedback is explicit and provides a clear direction for the authors to improve their draft by including detailed evidence. The action is concrete, as it specifies exactly what needs to be done to strengthen the argument. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS due to the lack of direct dependence on magnitudes. However, the comment does not specify which part of the paper this claim is related to, making it weakly grounded. It is specific in suggesting the need for detailed evidence, but without clear references to sections or figures, the authors may find it challenging to identify the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should provide specific experimental results or references to support their assertion that NPPs perform worse than ETAS due to the lack of direct dependence on magnitudes. This claim is 3 as it suggests a need for additional evidence, but it lacks specific examples or references to substantiate the claim. The authors would need to provide detailed experimental results or references to fully support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS due to the lack of direct dependence on magnitudes. This feedback is clear and actionable, as it directs the authors to strengthen their argument by including detailed evidence. By providing specific results or references, the authors can better substantiate their claim and enhance the credibility of their paper. This feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it included suggestions on how to present or analyze the additional evidence effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the implementation details, specifically regarding how Equations 3 and 4, which describe connectivity patterns between layers, should be applied to complex architectures like UNet, ResNet, and MobileNet. The reviewer points out that these details are not adequately explained in the methodology section or incorporated into the Appendix. While the comment identifies a specific area of concern, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify the implementation details. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples of how to apply the equations to these architectures. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the methodology section and the equations outlining connectivity patterns between layers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of guidance on applying these connections to complex architectures like UNet, ResNet, and MobileNet, and the absence of these details in the Appendix. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the implementation details are unclear, specifically regarding the application of Equations 3 and 4 to complex architectures like UNet, ResNet, and MobileNet. The reviewer points out that these details are not adequately explained in the methodology section or incorporated into the Appendix. However, the comment lacks specific examples or references to support the claim that the implementation details are unclear or missing. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of implementation details in the methodology section. It points out that while Equations 3 and 4 describe connectivity patterns between layers, there is a lack of specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet, as evidenced by the absence of these details in Tables 1 and 4, and Table 5. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or examples of how to apply the equations to these architectures. However, the comment could be more helpful if it suggested specific ways to improve the clarity or provided additional context. Overall, the comment is 4, as it effectively highlights a critical area for improvement in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the scalability of the HTER label calculation, suggesting that it relies on automatic scripts that may not be applicable to other annotations like MQM or DA. It implies that the authors should experiment with other languages and annotations to verify the scalability. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific steps should be taken. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the HTER label calculation, suggesting that relying on automatic scripts may limit its applicability to other annotations like MQM or DA. It implies that the authors should experiment with other languages and annotations to verify the scalability. However, the comment does not specify which part of the paper discusses the HTER label calculation or the specific sections that need to be addressed. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that require attention. While the comment is specific about the issue of scalability, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the HTER label calculation, suggesting that relying on automatic scripts may limit its applicability to other annotations such as MQM or DA. The comment implies that the authors should experiment with other languages and annotations to verify the scalability. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for further investigation but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the HTER label calculation, suggesting that relying on automatic scripts may limit its applicability to other annotations such as MQM or DA. It implies that the authors should experiment with other languages and annotations to verify the scalability. However, the comment lacks specific guidance on how to conduct these experiments or what specific steps should be taken to address the issue. While it points out a potential limitation, it does not provide actionable advice or detailed suggestions for improvement, making it 3. The feedback is clear but could be more comprehensive and detailed to fully assist the authors in addressing the concern. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the dependence of overall performance on $m$ in $G_m$. While it highlights an area that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this question. The authors are left to infer that they need to provide more details or analysis regarding the relationship between $m$ and $G_m$ to improve their draft. However, the action is implicit and somewhat vague, as it does not specify what kind of analysis or clarification is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the dependence of overall performance on $m$ in $G_m$. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it lacks specific references or context, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the dependence of overall performance on $m$ in $G_m$. It does not contain any subjective opinions, claims, or suggestions that require verification. The comment is purely factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review point raises a question about the dependence of overall performance on $m$ in $G_m$. While it identifies an area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is 2, as it highlights a potential area for improvement but does not offer any concrete advice or suggestions. The score of 2 aligns with this assessment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue regarding the theorypractice gap in the paper, suggesting that the authors should comment on this gap to help readers understand the key elements that allow CausalStonet to learn sparse neural nets. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what specific aspects of the paper should be discussed. The action is implicit and somewhat vague, as the authors are left to infer how to implement the suggested comment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"theorypractice gap\" in deep learning, which is a specific issue that the authors should address. It also provides a reference to Farrell, Liang, and Misra ECTA 2021, which helps the authors understand the context of the issue. The comment is specific because it suggests that the authors should comment on this gap to help readers understand the key elements that allow CausalStonet to learn sparse neural nets. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"almost all theoretical works on deep learning do not reflect practice,\" and provides an example by referencing Farrell, Liang, and Misra ECTA 2021. The claim is supported by the reference to a specific paper that discusses the difficulty of fitting sparse neural nets. However, the comment could be more verifiable by providing additional examples or references to other works that highlight the theorypractice gap. Overall, the claim is 3, as it is supported by logical reasoning and a specific reference, but it lacks depth in terms of additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue regarding the theorypractice gap in deep learning, which is a critical aspect for understanding the practical implications of theoretical work. It suggests that the authors should comment on this gap to help readers better understand the key elements that allow CausalStonet to learn sparse neural nets. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft. However, the comment could be more helpful if it offered additional guidance on how to address the theorypractice gap or suggested specific areas for discussion. Overall, the comment is 4, as it highlights an important issue and provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the manuscript is densely packed in terms of space, with figures and tables positioned very closely to the text, making it seem cluttered and condensed. It recommends considering making some tables smaller or relocating them to the Appendix, such as Table 1, and reducing the size of certain figures, like Figure 2 with fewer datasets. The comment provides explicit guidance on how to address the issue, including specific suggestions for table and figure adjustments. This level of detail and specificity allows the authors to directly implement the recommendations, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of space density in the manuscript, specifically noting that figures and tables are positioned very closely to the text, making the paper seem cluttered and condensed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and reducing the size of certain figures. These suggestions are actionable and provide a clear path for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the manuscript is densely packed in terms of space, with figures and tables positioned very closely to the text, making it seem cluttered and condensed. The comment suggests that this issue can be addressed by making some tables smaller or relocating them to the Appendix, such as Table 1, and reducing the size of certain figures, like Figure 2 with fewer datasets. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim of space density. Therefore, the claim is 3, as it is based on a reasonable assumption but could benefit from more detailed evidence or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the manuscript\"s layout, specifically the density of figures and tables close to the text, which can make the paper appear cluttered and condensed. It provides actionable suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and reducing the size of certain figures. These recommendations are clear and specific, offering the authors a clear path to address the issue. However, the comment could be more helpful if it included examples of how to implement these suggestions or provided additional guidance on balancing content density with readability. Overall, the feedback is 4 as it directs the authors towards specific improvements that could enhance the paper\"s presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the ReCPE method, suggesting that it is too strategic and lacks a strong theoretical guarantee. It also provides a minor comment about a spelling error. The comment explicitly suggests that the authors may be able to strengthen the article from this perspective, indicating a clear action for improvement. However, it does not provide specific guidance on how to strengthen the method or address the lack of theoretical guarantee. The action is explicit but somewhat vague, as it lacks detailed instructions on how to implement the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the ReCPE method proposed in the article, suggesting that it is too strategic and lacks a strong theoretical guarantee. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the method but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the ReCPE method is too strategic and lacks a strong theoretical guarantee, suggesting that the authors may be able to strengthen the article from this perspective. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the ReCPE method, suggesting that it is too strategic and lacks a strong theoretical guarantee. It provides a minor comment about a spelling error, which is a specific detail that could be addressed. However, the comment does not offer detailed guidance or suggestions on how to strengthen the method or address the lack of theoretical support. While it highlights an area for improvement, the feedback is somewhat limited in its actionable value, as it lacks specific advice on how to enhance the method or provide theoretical backing. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the method to generation tasks, beyond the NLU tasks it is currently applied to. While it prompts the authors to consider the broader applicability of their method, it does not provide explicit guidance on how to address this question or what steps to take. The action is implicit, as the authors need to infer that they should explore the method\"s applicability to generation tasks. However, the comment lacks concrete details on how to do so, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the method to generation tasks, beyond the NLU tasks it is currently applied to. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in that it questions the applicability of the method to a different type of task, which is a clear and actionable question for the authors to consider. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the method to generation tasks, beyond the NLU tasks it is currently applied to. This is a logical question that does not require external references or detailed explanations to understand. The comment is factual and does not contain any subjective opinions or claims. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the applicability of the method to generation tasks, beyond the NLU tasks it is currently applied to. This is a relevant and important consideration for the authors to address, as it could broaden the scope and impact of their work. However, the comment lacks specific guidance or suggestions on how to explore this applicability or what steps the authors should take to investigate it. While it identifies a potential area for improvement, it does not provide actionable advice or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that $N_d$ is not defined and suggests that the authors should explicitly mention that there could be a different number of observations per task. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of definition for $N_d$ and the suggestion to explicitly mention that there could be a different number of observations per task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that $N_d$ is not defined in the paper, specifically at lines 145ff. However, the comment does not provide any context, examples, or references to support this claim. Without additional information or evidence, the authors cannot verify the claim or understand why it is important. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely that the variable $N_d$ is not defined, which could lead to confusion for readers. It provides a clear suggestion to explicitly state that there could be a different number of observations per task, which is a valuable piece of feedback for improving the clarity and completeness of the paper. However, the comment could be more helpful if it provided additional context or examples of how this lack of definition might affect the interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and offers a clear suggestion for action."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that the appendix is not cut from the main paper and that the provided PDF is a 14page document. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should follow to ensure the appendix is correctly handled. As a result, the authors are left without any actionable information to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the appendix being not cut from the main paper and provides the context of the PDF being a 14page document. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific in terms of what needs to be addressed or how it should be handled. It lacks detailed guidance on how the authors should ensure the appendix is correctly integrated or removed. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point is factual and descriptive, stating that the appendix is not cut from the main paper and that the provided PDF is a 14page document. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out that the appendix is not cut from the main paper and that the provided PDF is a 14page document. While this observation is factual, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or what steps they should take to ensure the appendix is correctly handled. Therefore, the comment is 1, as it lacks any meaningful insights or constructive feedback that could guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more light on the results presented in Table 1, specifically regarding the impact of the ternary potential on the model\"s performance. While the comment implies that the authors should elaborate on the results, it does not explicitly instruct them to provide additional analysis or discussion. The action is implicit and somewhat vague, as the authors are not given specific guidance on what aspects of the results to focus on or how to present the information. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors should do, which is to provide more light on the results presented in Table 1, particularly regarding the impact of the ternary potential on the model\"s performance. This guidance is clear and actionable, making the comment 5. Therefore, the comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the main improvement in the proposed model comes from the ternary potential, as evidenced by the results in Table 1. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why the ternary potential is the primary source of improvement or how the results in Table 1 substantiate this claim. Without additional context or evidence, the claim is difficult to verify, making the comment 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the results presented in Table 1, noting that the main improvement in the proposed model appears to stem from the ternary potential. The comment suggests that the authors should provide more light on this observation, which is a valuable piece of feedback. However, the comment lacks specific guidance on how the authors might address this issue or what additional analysis could be conducted to strengthen their findings. While it highlights an important point, the feedback could be more helpful if it provided suggestions for further exploration or discussion. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more information about the methods used in the tables, specifically regarding data augmentations, architecture, and objective. This feedback is explicit and concrete, as it clearly indicates what additional details the authors should include to improve the clarity and comprehensiveness of their paper. The authors know exactly what information is missing and how to address it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the various comparisons in the tables,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what information should be included, such as noting which methods use data augmentations, their architecture, and objective. This detailed feedback helps the authors understand exactly what needs to be added to improve the clarity and comprehensiveness of their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more information about the methods used in the tables, specifically regarding data augmentations, architecture, and objective. This feedback is clear and specific, as it directly addresses the need for additional details to enhance the clarity and comprehensiveness of the paper. However, it does not provide any examples or references to support the claim, which could make it slightly less verifiable. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the clarity and comprehensiveness of the paper. It suggests that the authors should include details about data augmentations, architecture, and objectives used in the methods listed in the tables. This feedback is clear and directly addresses a potential area of confusion for readers, as it helps them better understand the comparisons being made. By providing these additional details, the authors can enhance the transparency and rigor of their work, making it more valuable to the readers. Therefore, the comment is 4, as it offers clear guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, questioning the choice of architectures (LSTM and LSH networks) used in the paper. It suggests that it would be interesting to see how LSH performs on stateoftheart models and notes that the PTB benchmark is small, making it unclear if the hyperpruning method would perform well on more recent benchmarks and architectures. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the claim that hyperpruning methods would beat the state of the art, questioning the choice of architectures (LSTM and LSH networks) used in the paper. It suggests that it would be interesting to see how LSH performs on actual stateoftheart models and notes that the PTB benchmark is a very small dataset, making it unclear if the hyperpruning method would still perform well on more recent benchmarks and architectures. However, the comment does not specify which part of the paper discusses these claims or the architectures used, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the concerns regarding the architectures and benchmarks, it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, questioning the choice of architectures (LSTM and LSH networks) used in the paper. It suggests that it would be interesting to see how LSH performs on stateoftheart models and notes that the PTB benchmark is small, making it unclear if the hyperpruning method would perform well on more recent benchmarks and architectures. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides some reasoning but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the claim that hyperpruning methods would outperform the state of the art, questioning the choice of architectures (LSTM and LSH networks) used in the paper. It suggests that it would be interesting to see how LSH performs on stateoftheart models and notes that the PTB benchmark is small, making it unclear if the hyperpruning method would still perform well on more recent benchmarks and architectures. While the comment identifies a potential issue with the paper\"s claims, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it highlights areas for further exploration and consideration, but it lacks actionable advice, making it difficult for the authors to effectively respond to the critique. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more experimental details, such as the neural networks and hyperparameters used, should be included in the appendix. This provides a clear and explicit action for the authors to take, as they know exactly what information needs to be added. The comment is specific in its request, detailing the exact elements that should be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more experimental details, such as neural networks and hyperparameters used, should be included in the appendix. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its request for additional details, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to identify where to add these details. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experimental details, such as neural networks and hyperparameters used, should be included in the appendix. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the authors may find it difficult to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more experimental details, such as the neural networks and hyperparameters used, should be included in the appendix. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance the completeness and transparency of their experimental setup. By including these details, the authors can improve the reproducibility and understanding of their work. However, the comment could be more helpful if it provided additional guidance on how to present or organize these details effectively. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that section 5.1 does not provide useful information regarding why the new model is superior. However, it does not specify what kind of information is missing or how the authors should address this issue. The comment lacks explicit guidance on what actions the authors should take to improve the section, making it 3. The authors know that the section needs more detail, but they are not given specific instructions on what to include or how to present it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that section 5.1 does not provide useful information regarding why the new model is superior, which is a clear and actionable issue for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that section 5.1 does not provide useful information regarding why the new model is superior. However, the comment lacks specific details or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that section 5.1 does not provide useful information regarding why the new model is superior. This feedback is clear and actionable, as it highlights a gap in the paper\"s explanation and suggests that the authors should include more detailed reasoning or evidence to support their claims. By pointing out this specific area for improvement, the comment provides the authors with a clear direction for enhancing the clarity and depth of their work. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of what kind of information would be useful. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the singleIMP might also have transferability, but it does not specify how this transferability should be assessed or what comparisons are needed. The comment implies that a comparison is necessary, but it lacks concrete guidance on what aspects of transferability should be compared or how this comparison should be conducted. Without explicit instructions or detailed examples, the authors are left to infer the necessary actions, making the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the singleIMP might also have transferability, but it does not specify which part of the paper this claim relates to. It lacks grounding as the authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment does not provide specific details on what comparisons are necessary or how transferability should be assessed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the singleIMP might also have transferability, but it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment points out a potential issue with the transferability of the singleIMP, suggesting that it might also exhibit transferability, albeit less strongly. However, the comment does not provide any specific guidance or suggestions on how to address this issue or what comparisons are necessary to substantiate the claim. Without actionable advice or detailed examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider checking humanfactors literature to address practical challenges of interacting with humans. However, it does not provide explicit guidance on which specific literature to review or how to integrate these insights into the paper. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggested area. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the year and issue number of the paper, allowing the authors to accurately identify the reference. It also specifies the issue by mentioning the lack of specific ethical concerns and the need to consider humanfactors literature. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider checking humanfactors literature to address practical challenges of interacting with humans. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence to fully substantiate the suggestion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors consider incorporating insights from humanfactors literature to address practical challenges in interacting with humans. This feedback is specific and actionable, as it directs the authors to a relevant field of study that could enhance the practical applicability of their proposed methods. However, the comment could be more helpful if it provided more detailed guidance on which specific aspects of humanfactors literature to explore or how to integrate these insights into the paper. Despite this, the comment offers a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the proposed model selection approach beyond MNISTlike datasets and suggests comparing it with other neural network pruning methods. While the comment identifies a potential area for further exploration and comparison, it does not provide explicit guidance on how to conduct these analyses or what specific aspects of the model selection approach should be examined. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the proposed model selection approach beyond MNISTlike datasets, suggesting that the experiments are conducted only on toy datasets such as MNISTfashion. It also suggests comparing the proposed approach with other neural network pruning methods. However, the comment does not specify which part of the paper discusses the experiments or the model selection approach, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the nature of the experiments and the suggestions for comparison, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scalability of the proposed model selection approach beyond MNISTlike datasets and suggests comparing it with other neural network pruning methods. However, it does not provide any specific evidence, reasoning, or references to support the claim that the experiments are limited to toy datasets. The comment lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the proposed model selection approach beyond MNISTlike datasets, which is a crucial aspect for evaluating the generalizability of the method. It also suggests comparing the approach with other neural network pruning methods, which could provide valuable insights into the relative strengths and weaknesses of the proposed method. However, the comment lacks specific guidance on how to conduct these analyses or what aspects of the model selection approach should be examined. While it identifies an important area for further exploration, the feedback could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, as it highlights an important consideration but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several specific issues with the mathematical formulations in the paper, such as inconsistencies in notation and the use of the $max$ function. It provides explicit examples of where these issues occur, such as Line 345, 347, 344, and 374, and Line 225 and 819. The comment suggests that the authors should correct these inconsistencies, but it does not provide detailed guidance on how to do so. While the actions are explicit, they are somewhat vague as the authors need to infer the exact steps to take to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (345, 347, 344, 374, 225, and 819), allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the mathematical formulations, such as the use of $max$ instead of $min$, the inconsistency in indexing objective functions and time steps, the unexplained variable $x\"$ in the hypervolume formula, and the incorrect distribution mentioned. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the paper contains several mathematical formulation issues and inconsistencies, providing specific examples of where these problems occur, such as Line 345, 347, 344, 374, 225, and 819. The comment suggests that the authors should correct these inconsistencies, but it does not provide any logical reasoning, references, or examples to support these claims. Without additional evidence or justification, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several specific issues with the mathematical formulations in the paper, such as inconsistencies in notation and the use of the $max$ function. It provides concrete examples of where these problems occur, such as Line 345, 347, 344, 374, 225, and 819. By pointing out these inconsistencies, the comment offers actionable feedback that can help the authors improve the accuracy and clarity of their mathematical formulations. However, the comment could be more helpful if it provided guidance on how to correct these issues or suggested specific changes to the formulations. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments showing the effect of using different numbers of particles. It implies that the current experiments do not provide sufficient information to understand the importance of this choice. However, the comment does not specify how these experiments should be conducted or what specific results would be expected. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include experiments showing the effect of using different numbers of particles, but it does not specify which part of the paper this relates to. The authors cannot confidently determine which section or figure this comment pertains to, making it weakly grounded. However, the comment is specific in its suggestion to include experiments that demonstrate the effect of varying the number of particles, which would help clarify the importance of this choice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments showing the effect of using different numbers of particles, but it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand why this suggestion is important or how to implement it. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include experiments demonstrating the effect of using different numbers of particles. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific results would be expected. Despite this, the comment is 4 as it directs the authors towards a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific area where the paper lacks comparison, namely the evaluation of plasticity using metrics like covariance metric [1]. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific comparisons should be made. The comment identifies a gap in the paper but does not offer guidance on how to improve the draft by addressing this gap. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric [1]. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the type of comparison missing, it lacks grounding as it does not provide clear guidance on where to address this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric [1]. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of missing comparisons or references to other works that have addressed this issue. Without specific examples or references, the claim remains 1, as the authors cannot determine the validity of the criticism or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks comparison, namely the evaluation of plasticity using metrics like the covariance metric [1]. This feedback is clear and actionable, as it points out a gap in the paper\"s analysis and suggests that the authors should include such comparisons to enhance the comprehensiveness of their evaluation. By highlighting this specific issue, the comment provides the authors with a clear direction for improvement, making it 4. However, it could be more helpful if it suggested specific methods or metrics for comparison or provided guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors to an important area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification on the labels A, B, C, and D in Table 5, as well as an explanation of why positive paths lead to monotonic solutions and under what scenarios. This provides clear and direct instructions for the authors to address these specific issues. The comment is explicit and concrete, giving the authors precise guidance on what needs to be clarified or explained in the table. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the labels A, B, C, and D in Table 5, and the explanation of why positive paths lead to monotonic solutions and under what scenarios. This provides the authors with clear guidance on what aspects of the table require clarification or additional explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and explanation regarding specific elements in Table 5. It does not contain a subjective claim or opinion, but rather asks for additional information to improve the clarity and understanding of the paper. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The comment is 5 as it provides specific and actionable feedback on the need for better explanation of Table 5. It requests clarification on the labels A, B, C, and D, as well as an explanation of why positive paths lead to monotonic solutions and under what scenarios. This detailed feedback guides the authors in improving the clarity and comprehensibility of their work, making it a valuable and constructive suggestion. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the cost of obtaining a single US accuracy and suggests exploring proxy or surrogate methods for making cheap estimations. It also points out that the accuracy curve is saturated at the end, implying that early predictions are not reliable. The comment further asks how to use power law prediction for model selection in practice, referencing specific figures in the appendix. While the comment identifies several areas for consideration and questions, it does not provide explicit instructions or concrete guidance on how to address these points. The authors are left to infer the actions needed, such as exploring alternative methods for costeffective estimation or investigating the reliability of early predictions. Therefore, the comment is 3, as it provides some direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the issue of the cost of obtaining US accuracy and suggests exploring proxy or surrogate methods for making cheap estimations. It also references Figure 1 to illustrate the saturation of the accuracy curve, implying that early predictions are not reliable. The comment further questions how to use power law prediction for model selection in practice, referencing specific figures in the appendix. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. It is specific in detailing the issues and questions raised, but without clear references, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the cost of obtaining US accuracy and suggests exploring proxy or surrogate methods for making cheap estimations. It also questions the reliability of early predictions based on the saturation of the accuracy curve in Figure 1. The comment implies that the authors should consider alternative methods for model selection, referencing specific figures in the appendix. However, the claim lacks detailed reasoning or specific examples to fully support the assertion that early predictions are not reliable predictors of DS accuracy. The comment is 3 as it provides a basis for discussion but lacks comprehensive evidence or references to substantiate the claims fully.", "helpfulness_rationale": "The review comment raises a pertinent question about the cost of obtaining US accuracy and suggests exploring proxy or surrogate methods for making cheaper estimations. It also points out that the accuracy curve in Figure 1 is saturated at the end, indicating that early predictions may not be reliable predictors of DS accuracy. The comment further questions how to use power law prediction for model selection in practice, referencing specific figures in the appendix. While the comment identifies an area for improvement and raises a relevant question, it lacks detailed guidance or suggestions on how to address these issues. The authors are left to infer the steps needed to explore alternative methods or refine their approach, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it provides a starting point for discussion but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This is an explicit action that the authors can directly implement by conducting additional experiments or analyses. The comment is specific in its request for ablation studies, which would help the authors understand the contribution of different factors to the performance of epsilon sampling. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its request for ablation studies, which would help the authors understand the contribution of different factors to the performance of epsilon sampling. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This is a suggestion for improvement, but it lacks specific details or examples of how these ablation studies should be conducted or what factors should be considered. Without additional context or guidance, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is considered 2, as it provides a general direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This feedback is clear and actionable, as it directs the authors to conduct additional experiments or analyses to better understand the factors contributing to the performance of epsilon sampling. By providing ablation studies, the authors can gain a deeper understanding of the model\"s behavior and potentially identify areas for improvement. This feedback is 4 as it offers a specific and constructive suggestion for enhancing the paper, though it could be further detailed to provide more comprehensive guidance. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed attack should be evaluated against a mode connectivitybased defense, referencing a specific paper. However, it does not provide explicit guidance on how to conduct this evaluation or what aspects of the attack should be considered. The comment implies that the authors should compare their attack with the proposed defense, but it lacks concrete steps or detailed instructions on how to perform this comparison. As a result, the authors are left without a clear understanding of how to address the feedback, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLR publication \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" allowing the authors to accurately identify the referenced paper. It is also specific because it requests a comparison of the proposed attack against the mode connectivitybased defense discussed in the mentioned paper, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed attack should be evaluated against a mode connectivitybased defense, referencing a specific paper. However, it does not provide any detailed reasoning, examples, or references to support this claim. The comment lacks specific evidence or logical reasoning to substantiate the assertion that the proposed attack is not effective against the mode connectivitybased defense. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment suggests that the proposed attack should be evaluated against a mode connectivitybased defense, referencing a specific paper. However, it does not provide detailed guidance on how to conduct this evaluation or what aspects of the attack should be considered. While the comment identifies a potential area for improvement, it lacks actionable advice or specific suggestions for the authors to address this concern. As a result, the feedback is 3, as it highlights a potential weakness but does not offer comprehensive guidance for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the transparency of the claims due to the authors\" decision not to include the codes during the review process. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the transparency of their claims or what steps they should consider taking to ensure that the claims are more transparent. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment highlights a concern regarding the transparency of the claims due to the authors\" decision not to include the codes during the review process. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance on how to address this issue or what steps the authors should take to improve transparency. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" decision not to include the codes during the review process makes the claims less transparent. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it impacts the transparency of their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a concern regarding the transparency of the claims due to the authors\" decision not to include the codes during the review process. This feedback highlights a potential issue with the clarity and verifiability of the claims, which could affect the reproducibility and understanding of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the transparency of their claims. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should validate their proposed approach in Waymax, which offers more traffic scenarios than the current version. However, it does not provide explicit guidance on how to implement this validation or what specific steps the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios compared to the current version. However, it does not specify which part of the paper this validation should be included in, making it weakly grounded. The comment is specific in its suggestion to validate the approach, but the lack of grounding makes it difficult for the authors to understand where to apply the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should validate their proposed approach in Waymax, which offers more traffic scenarios compared to the current version. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without additional context or evidence, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to consider a more comprehensive validation process. However, the comment lacks specific guidance on how to implement this validation or what additional steps the authors should take. The feedback is clear but could be more actionable with additional details, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the technical contribution of the paper, suggesting that it is not very significant. It highlights the use of the transformerbased TAPG method, previously studied in RTDNet (ICCV2021), and points out that the main difference lies in the visual features. The reviewer notes that considering 3D pose and action features obtained by Laban Movement Analysis (LMA) is not surprising, as LMA has been proven effective in dance action recognition. The comment suggests that such a choice may not bring enough insights to the community. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks specific guidance on how to improve the technical contribution or what aspects to emphasize to make it more significant. As a result, the authors are left without clear direction on how to respond or improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the technical contribution of the paper, suggesting it is not very significant. It mentions the transformerbased TAPG method and its previous study in RTDNet (ICCV2021), highlighting the main difference in visual features. The reviewer also notes that considering 3D pose and action features obtained by Laban Movement Analysis (LMA) is not surprising, as LMA has been proven effective in dance action recognition. However, the comment does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section being addressed. While the comment provides some context, it lacks full grounding as it does not explicitly mention sections, tables, or figures. The specificity of the comment is somewhat clear, as it critiques the technical contribution and suggests that the use of additional features may not bring enough insights. However, without explicit grounding, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point critiques the technical contribution of the paper, suggesting that it is not very significant. It mentions that the transformerbased TAPG method has been studied in previous works, such as RTDNet (ICCV2021), and highlights the main difference in visual features. The reviewer argues that considering 3D pose and action features obtained by Laban Movement Analysis (LMA) is not surprising, as LMA has been proven effective in dance action recognition. This critique implies that the use of additional features may not bring enough insights to the community. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general critique, it does not offer detailed evidence or references to support the assertion that the technical contribution is not significant. Therefore, the claim is 3, as it is based on logical reasoning but lacks sufficient detail or references to fully substantiate the critique.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, suggesting that it is not very significant. It highlights the use of the transformerbased TAPG method, previously studied in RTDNet (ICCV2021), and points out that the main difference lies in the visual features. The reviewer notes that considering 3D pose and action features obtained by Laban Movement Analysis (LMA) is not surprising, as LMA has been proven effective in dance action recognition. This critique implies that the use of additional features may not bring enough insights to the community. However, the comment lacks specific suggestions or actionable feedback on how the authors could address this issue or enhance the significance of their contribution. Without detailed guidance or suggestions, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 2, as it identifies a potential weakness but does not provide substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more experimental comparisons to support the different design choices of merging nodes among adjacent layers in the tree construction implementation. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to conduct these comparisons or specify which aspects of the design choices should be compared. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to validate their design choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more experimental comparisons to support the different design choices of merging nodes among adjacent layers in the tree construction implementation. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The authors may infer that this comment pertains to the implementation details described in the paper, but without explicit references, they cannot pinpoint the exact section. The comment is specific in its suggestion to add more experimental comparisons, but the lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide more experimental comparisons to support the different design choices of merging nodes among adjacent layers in the tree construction implementation. However, the comment lacks specific details or examples of how these comparisons should be conducted or what aspects of the design choices need to be compared. Without additional context or guidance, the authors may find it challenging to understand the exact nature of the suggested improvements. Therefore, the claim is 3, as it provides a general direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the implementation of tree construction, noting that the different design choices of merging nodes among adjacent layers require more experimental comparisons. This feedback is clear and actionable, as it directs the authors to enhance the robustness of their implementation by conducting additional experiments. However, the comment could be more helpful if it provided specific examples of how these comparisons should be conducted or what aspects of the design choices need to be compared. Despite this, the feedback is 4 as it offers a clear direction for improvement, allowing the authors to address the issue effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that Table 2 in the paper is incomplete because it does not include several baselines that outperform the results presented. The comment suggests that these baselines are reported in the ReBART paper and should be included for completeness, even if their results are slightly weak. This feedback provides a clear and explicit action for the authors to take, which is to include the missing baselines in Table 2. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 2 in the paper is not complete,\" providing clear grounding as it directly identifies the specific part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the paper should include several baselines that outperform the results, referencing the ReBART paper. This feedback is 5, allowing the authors to understand exactly what aspect of the paper needs improvement. Therefore, this comment is rated as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that Table 2 in the paper is incomplete because it does not include several baselines that outperform the results presented. The comment suggests that these baselines are reported in the ReBART paper and should be included for completeness. However, the comment lacks specific examples or detailed reasoning to support why these baselines are important or how their inclusion would enhance the paper. Without additional context or evidence, the claim remains 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 2, noting that it is incomplete and lacks several baselines that outperform the results presented. It suggests that these baselines are reported in the ReBART paper and recommends including them for completeness, even if their results are slightly weak. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By addressing this issue, the authors can enhance the completeness and comprehensiveness of their paper, making it more robust and informative. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the thoroughness of the evaluations on real datasets, specifically asking why only three scenes were chosen from the HSERGB dataset and how the performance would be on other sequences. While the comment implies that the evaluations could be more comprehensive, it does not explicitly instruct the authors to expand their evaluations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider additional scenes and sequences for a more thorough evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the thoroughness of evaluations on real datasets, specifically asking why only three scenes were chosen from the HSERGB dataset and how the performance would be on other sequences. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address the issue of limited scene selection or how to evaluate performance on other sequences. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the thoroughness of evaluations on real datasets, specifically asking why only three scenes were chosen from the HSERGB dataset and how the performance would be on other sequences. However, the comment does not provide any justification or reasoning for why only three scenes were selected or how the performance might vary on other sequences. Without additional context or explanation, the authors are left to infer the reasoning behind the question, making it difficult to fully understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the thoroughness of the evaluations on real datasets, specifically questioning the choice of only three scenes from the HSERGB dataset and the performance on other sequences. This feedback highlights a potential gap in the experimental evaluation, suggesting that the authors should consider expanding their analysis to include a broader range of scenes and sequences to provide a more comprehensive assessment of their work. However, the comment lacks specific guidance on how to address this issue or what additional experiments might be necessary. While it identifies an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the draft, including the size of the dataset (44), suggesting that more bits could be used, and questioning the interpretation of bitembeddings in the context of predicting binary code and the rank of words. It also questions whether the model is simply memorizing the data due to its power. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific changes or improvements. The feedback lacks concrete guidance on how to address these issues, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific issues related to the size of the dataset (44), suggesting that more bits could be used, and questions the interpretation of bitembeddings in the context of predicting binary code and the rank of words. It also raises a question about whether the model is simply memorizing the data. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique of the dataset size and the interpretation of bitembeddings, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the dataset size (44), suggesting that more bits could be used, and questions the interpretation of bitembeddings in the context of predicting binary code and the rank of words. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning provided is somewhat vague, as it does not offer detailed explanations or evidence to substantiate the claims. Therefore, the comment is rated as 2, as it provides some basis for the claims but lacks sufficient detail or support.", "helpfulness_rationale": "The review comment raises several concerns about the draft, including the size of the dataset (44), suggesting that more bits could be used, and questioning the interpretation of bitembeddings in the context of predicting binary code and the rank of words. It also questions whether the model is simply memorizing the data due to its power. While the comment identifies areas for improvement and raises important questions, it lacks specific guidance or suggestions on how to address these issues. The feedback is 3 as it points out potential areas for clarification and improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the practical use of the method, specifically that it requires human annotation, which can be subjective. It notes that the authors mention this limitation in the appendix but do not provide any solutions for mitigation. While the comment highlights a gap in the discussion, it does not explicitly instruct the authors to address this issue or suggest specific actions to mitigate the problem. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide solutions for mitigation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a potential issue with the practical use of the method, specifically mentioning that it requires human annotation, which can be subjective. It notes that the authors mention this limitation in the appendix but do not provide any solutions for mitigation. However, the comment does not specify which part of the paper discusses the practical use of the method or the appendix where the limitation is mentioned. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of human annotation, it lacks grounding as it does not provide clear references or sections for the authors to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed solution for providing semantically meaningful information requires human annotation, which can be subjective. The authors mention this limitation in the appendix but do not offer any solutions for mitigation. The comment is 3 as it identifies a specific issue and provides a logical reasoning for why it is a concern. However, it lacks detailed examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the practical use of the method, specifically that it requires human annotation, which can be subjective. The authors mention this limitation in the appendix but do not provide any solutions for mitigation. This feedback is 3 as it highlights a gap in the discussion and points out a potential area for improvement. However, it lacks depth and actionable suggestions, as it does not offer specific guidance on how to address the issue or provide alternative solutions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take: pretrain a CausalLM using the specified dataset and compare its performance against ObscuraCoder. These actions are clear and direct, allowing the authors to understand exactly what needs to be done to address the feedback. The comment is fully actionable as it provides specific steps for improvement, making it 5.", "grounding_specificity_rationale": "The comment provides specific instructions for the authors to pretrain a CausalLM using a dataset mixed with other datasets used by ObscuraCoder, excluding obfuscated ObscuraX. It also suggests comparing the performance of this model against ObscuraCoder to attribute any improvements to the deobfuscation objective. This feedback is fully grounded as it explicitly mentions the sections or parts of the paper that need to be addressed, and it is specific in detailing the actions to be taken. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific instructions for the authors to pretrain a CausalLM using a dataset and compare its performance against ObscuraCoder. This feedback is clear and actionable, offering a direct path for the authors to address the concern. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors can infer the need for such an experiment but may require additional context to fully understand the implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting two key experiments for the authors to conduct: pretraining a CausalLM using the specified dataset and comparing its performance against ObscuraCoder. This feedback is clear and directly addresses potential weaknesses or areas for improvement in the paper. By outlining these experiments, the comment guides the authors on how to strengthen their work and provide a more comprehensive evaluation of their approach. The detailed suggestions enhance the authors\" understanding of the necessary steps to improve their draft, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a minor issue with the loss equation, suggesting that the geometric loss should be added to the reconstruction loss rather than being separate. This provides a clear and explicit action for the authors to take, as they can directly address this issue by revising the loss equation. The comment is specific in its suggestion, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the loss equation shown in lines L264L266, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the loss equation, suggesting that the geometric loss should be added to the reconstruction loss rather than being separate. This provides a clear direction for the authors to make necessary changes. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point identifies a minor issue with the loss equation, suggesting that the geometric loss should be added to the reconstruction loss rather than being separate. This is a specific and actionable suggestion that provides a clear direction for the authors to improve their draft. However, the comment does not provide any additional reasoning or references to support why this change is necessary or beneficial. While the suggestion is logical and clear, the lack of detailed justification or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue with the loss equation, specifically suggesting that the geometric loss should be added to the reconstruction loss rather than being separate. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. By addressing this issue, the authors can enhance the accuracy and coherence of their methodology. However, the comment could be more helpful if it included additional context or examples to illustrate why this change is necessary. Overall, the comment is 4 as it offers a clear and actionable suggestion, but it could be further enhanced to provide more comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while Multimodal Learning (MLM) is important and used in various applications, it should also be considered in autoregressive language models, which are more prevalent in realworld applications. However, the comment does not provide explicit guidance on how the authors should address this suggestion or incorporate it into their work. It lacks concrete actions or detailed instructions on how to modify the paper to align with this recommendation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that while Multimodal Learning (MLM) is important and used in many applications, it should also be considered in autoregressive language models, which are more prevalent in realworld applications. However, the comment does not specify which part of the paper discusses MLM or autoregressive language models, making it difficult for the authors to pinpoint the exact areas that need attention. While the suggestion is specific in terms of the recommendation, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that while Multimodal Learning (MLM) is important and used in many applications, it should also be considered in autoregressive language models, which are more prevalent in realworld applications. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to justify why this suggestion is important or how it could be implemented. Without additional context or evidence, the claim remains 3, as it lacks the necessary depth and support for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that while Multimodal Learning (MLM) is important and used in many applications, it should also be considered in autoregressive language models, which are more prevalent in realworld applications. This feedback highlights a potential gap in the paper\"s discussion of MLM and its relevance to autoregressive models. However, the comment lacks specific guidance on how the authors might address this issue or incorporate additional information to strengthen their work. Without actionable suggestions or detailed examples, the comment provides a general idea but does not offer substantial assistance for the authors to improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difficulty of optimizing the GAN and using adversarial gradient updating, suggesting that it is not clear why the proposed idea is better than GAN. It also points out that the issue of vanishing gradient and model collapsing is not adequately addressed in the method section. While the comment identifies specific areas that need clarification, it does not provide explicit guidance on how to address these issues or what actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the difficulty of optimizing a GAN and using adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the issue of vanishing gradient and model collapsing is not adequately presented in the method section. However, the comment does not specify which part of the paper discusses the optimization challenges or the method section that lacks clarity. This makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is specific in its critique but weakly grounded as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difficulty of optimizing a GAN and using adversarial gradient updating, suggesting that it is not clear why the proposed idea is better than GAN. It also points out that the issue of vanishing gradient and model collapsing is not adequately addressed in the method section. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the lack of detailed explanation or evidence makes it challenging to fully verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors claim the GAN is difficult to optimize and use adversarial gradient updating, but it is not clear why the proposed idea is better than GAN. The comment also points out that the issue of vanishing gradient and model collapsing is not adequately presented in the method section. While the comment highlights a potential weakness in the paper\"s explanation, it does not provide detailed guidance or suggestions on how to address these issues or improve the clarity of the method section. The feedback is 3 as it directs the authors to areas that need further clarification, but it lacks depth and actionable advice, making it only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind the design of the ablation study, specifically questioning why the ablations are performed on BART and BART+Longformer instead of the original model, GraphSum. While the comment implies that the authors should consider the original model for the ablation study, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should provide a justification for their choice of models. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind the design of the ablation study, specifically questioning why the ablations are performed on BART and BART+Longformer instead of the original model, GraphSum. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in questioning the choice of models, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind the design of the ablation study, specifically questioning why the ablations are performed on BART and BART+Longformer instead of the original model, GraphSum. This is a logical question that seeks clarification on the choice of models used in the ablation study. However, the comment does not provide any evidence, reasoning, or references to support the claim that the choice of models is problematic or requires justification. Without additional context or explanation, the authors may find it challenging to understand the basis for the question or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind the design of the ablation study, specifically questioning why the ablations are performed on BART and BART+Longformer instead of the original model, GraphSum. This question prompts the authors to consider the choice of models used in their ablation study and whether it aligns with the original model. However, the comment does not provide any suggestions or guidance on how the authors might address this question or what changes could be made to the study. While it identifies an area for clarification, it lacks actionable feedback or detailed suggestions, making it 3. The authors would need to infer that they should provide a justification for their choice of models, but the comment does not offer concrete steps or examples to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the removal of previous reports of SciBERT, noting that it exacerbates an earlier issue where the analysis of model outcomes was too cursory and unsupported. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the depth and support of their analysis. The feedback is somewhat vague, as it leaves the authors uncertain about how to respond or what changes are necessary. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment addresses the issue of the removal of previous reports of SciBERT and highlights that this exacerbates an earlier problem where the analysis of model outcomes was too cursory and unsupported. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the problem with the depth and support of the analysis, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas that need improvement. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the removal of previous reports of SciBERT exacerbates an earlier problem where the analysis of model outcomes was too cursory and unsupported. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains 3, as it is based on an inference rather than a clear and substantiated argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the depth and support of the analysis of model outcomes, noting that the removal of previous reports of SciBERT exacerbates an earlier problem. However, the comment does not provide actionable guidance or suggestions on how the authors might address this issue or improve the analysis. While it highlights a potential area for enhancement, it lacks detailed feedback or constructive advice, making it 3. The authors are left with a general idea of what needs improvement but without specific steps to take, which limits the comment\"s overall impact. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the claim that Figure 4(b) indicates faster training, suggesting that it seems farfetched given that all networks are trained for the same number of epochs. It also recommends a longer discussion of related work. While the comment identifies two potential areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to implement them. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses concerns about Figure 4(b) and suggests a longer discussion of related work. However, it does not specify which part of the paper Figure 4(b) is located in, making it weakly grounded. The comment is specific in its critique of the claim about faster training and the recommendation for a longer discussion of related work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the claim that Figure 4(b) indicates faster training, suggesting it seems farfetched given that all networks are trained for the same number of epochs. The reviewer also recommends a longer discussion of related work. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are farfetched or why a longer discussion of related work is necessary. Without these details, the claim is 3, as it provides a basis for questioning the claim but lacks sufficient evidence to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the claim that Figure 4(b) indicates faster training, suggesting that it seems farfetched given that all networks are trained for the same number of epochs. The reviewer also recommends a longer discussion of related work, which could provide valuable context and depth to the paper. However, the comment lacks specific guidance on how to address these issues or what actions the authors should take to improve their draft. While it identifies areas for improvement, it does not provide detailed suggestions or actionable steps, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper is not clear, specifically noting that the introduction part lacks background information about cognitive models. It suggests that the authors may need to refine the writing. However, the comment does not provide explicit guidance on how to improve the clarity or what specific aspects of the introduction need to be revised. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the introduction by providing more background information about cognitive models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly identifies the issue as the lack of background information about cognitive models in the introduction, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not clear, specifically noting that the introduction lacks background information about cognitive models. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the introduction lacks background information about cognitive models, making it unclear. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to enhance the introduction or suggested specific areas where more background information is needed. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, allowing them to refine their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the performance of DFA compared to backpropagation on the NLP task, noting that this difference is not sufficiently emphasized in the paper. It suggests that the abstract gives readers the impression that DFA performs at nearbackprop levels, which is misleading. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit, as the authors need to infer that they should clarify the performance differences and potentially revise the abstract to avoid misleading readers. The comment is 3 because it identifies a specific area for improvement but lacks concrete details on how to implement it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the performance of DFA compared to backpropagation on the NLP task, noting that the abstract gives a misleading impression. However, it does not specify which part of the paper this issue is discussed in, such as the abstract or a specific section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the abstract\"s representation, the absence of explicit references to the paper\"s sections limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the abstract gives readers the impression that DFA performance is near backprop levels on the NLP task, which is misleading given the actual performance difference. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. Without additional evidence or context, the claim remains 3, as it lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the abstract gives readers the impression that DFA performance is near backprop levels on the NLP task, despite the actual performance difference. This observation is insightful and highlights a potential misrepresentation in the abstract. However, the comment lacks actionable guidance on how the authors might address this issue or what specific changes could be made to the paper to clarify the performance differences. While it points out a critical area for improvement, it does not provide detailed suggestions or steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the baseline methods used in the paper are lacking, particularly in the context of dimensional reduction methods for optimal transport estimation. It mentions specific examples, such as SRW and FROT, which should be included as baselines. However, the comment does not provide explicit guidance on how the authors should incorporate these baselines or what specific aspects of the current baselines need improvement. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dimensional reduction methods in optimal transport estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear examples of missing baselines, namely SRW and FROT, which should be included. This level of detail helps the authors understand exactly what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline methods used in the paper are lacking, particularly for dimensional reduction methods in optimal transport estimation. It mentions specific examples, such as SRW and FROT, which should be included as baselines. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand why these baselines are missing or how they impact the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper by pointing out the lack of baseline methods, particularly for dimensional reduction in optimal transport estimation. It provides examples of relevant baselines, such as SRW and FROT, which should be included to strengthen the paper. However, the comment lacks depth and does not offer detailed guidance on how to incorporate these baselines or what specific aspects of the current baselines need improvement. While it provides a clear direction for improvement, the feedback could be more comprehensive and actionable to fully benefit the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that the advantages and disadvantages of transductive learning have not been discussed. However, it does not provide any explicit or implicit actions for the authors to take to address this gap. The comment lacks guidance on how the authors might explore or discuss these aspects, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for improvement.", "grounding_specificity_rationale": "The comment points out that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or paragraph. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific about the content that should be addressed, it lacks grounding as it does not provide clear guidance on where to find or discuss this information. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or details, the authors are left without a basis to verify or address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the advantages and disadvantages of transductive learning have not been discussed. This is a valuable piece of feedback as it highlights an area where the authors could enhance their work by providing a more comprehensive analysis of the topic. However, the comment lacks specific guidance on how the authors might address this gap, such as suggesting potential areas of discussion or analysis. While it provides a clear direction for improvement, the absence of actionable suggestions limits its helpfulness. Therefore, the comment is 3, as it identifies a meaningful weakness but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the invariance of the contractivity should be stated formally. While the comment implies that the authors should provide a formal statement, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to formalize the statement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact location where the issue needs to be addressed. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the invariance of the contractivity should be stated formally. While this feedback provides a specific area for improvement, it lacks depth and does not offer detailed guidance or suggestions on how to achieve this. The comment is 3 as it identifies a potential area for enhancement, but it does not provide actionable steps or examples to help the authors address the issue. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of application or evaluation of uncertainty saliency maps, questioning their significance. It also expresses disagreement with the paper\"s recommendation for acceptance, suggesting that the authors should reconsider their claims about the trustworthiness of uncertainty/confidence compared to explanations. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the lack of application or evaluation of uncertainty saliency maps, questioning their significance. However, it does not specify which part of the paper discusses these maps or where the application or evaluation is lacking. The comment is vague in terms of identifying the specific section or figure that needs improvement, making it weakly grounded. It is also specific in questioning the significance of the maps but does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of application or evaluation of uncertainty saliency maps, questioning their significance. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The comment also expresses disagreement with the paper\"s recommendation for acceptance, but this is a subjective opinion rather than a factual claim. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of application or evaluation of uncertainty saliency maps, questioning their significance. It also expresses disagreement with the paper\"s recommendation for acceptance, suggesting that the authors should reconsider their claims about the trustworthiness of uncertainty/confidence compared to explanations. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their draft. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors would need to infer how to improve their draft based on the feedback, which limits the comment\"s helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of using a diffusion model in the context of style transfer and suggests that it might provide unique capabilities compared to other methods. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the diffusion model should be discussed. The action is implicit, as the authors need to infer that they should elaborate on the importance of the diffusion model and its unique contributions to style transfer. While the comment is 3, it lacks concrete details on how to implement the suggested improvement. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the importance of using a diffusion model in style transfer, suggesting that it might provide unique capabilities compared to other methods. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint where to address the issue. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to understand which part of the paper needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the importance of using a diffusion model in style transfer, suggesting that it might provide unique capabilities compared to other methods. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of using a diffusion model in style transfer, specifically asking what unique capabilities it might offer compared to other methods. This question highlights a potential gap in the paper\"s discussion and encourages the authors to elaborate on the specific advantages of using a diffusion model. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what aspects of the diffusion model should be discussed. While it identifies an area for improvement, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the multiview latent attack enhances the model\u2019s meta generalizability and outperforms other Adversarial MetaLearning methods in the crossdomain setting. It also notes that the multiview training is similar to task augmentation metalearning methods and recommends a discussion or comparison in the related work section. While the comment provides a clear action\u2014asking for a discussion or comparison\u2014it does not specify which parts of the related work section should be addressed or how to implement this suggestion. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the multiview latent attack enhances the model\u2019s meta generalizability and outperforms other Adversarial MetaLearning methods in the crossdomain setting. It also notes that the multiview training is similar to task augmentation metalearning methods and recommends a discussion or comparison in the related work section. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in suggesting a discussion or comparison, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiview latent attack enhances the model\u2019s meta generalizability and outperforms other Adversarial MetaLearning methods in the crossdomain setting. It also suggests that the multiview training is similar to task augmentation metalearning methods, recommending a discussion or comparison in the related work section. While the claim about the multiview latent attack enhancing metageneralizability is somewhat supported by the context of the paper, the claim about the similarity between multiview training and task augmentation metalearning methods lacks specific examples or references. This makes the claim 3, as it provides a basis for discussion but requires further elaboration or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential enhancement in the model\u2019s metageneralizability due to the multiview latent attack and suggests that this enhancement could lead to outperformance compared to other adversarial metalearning methods in crossdomain settings. It also points out the similarity between multiview training and task augmentation metalearning methods, recommending a discussion or comparison in the related work section. This feedback is 3 as it highlights a potential area for improvement and suggests a specific direction for further discussion. However, it could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects of the related work should be discussed. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the ablation study, noting that the impact of Age and FaceID features is not studied. While it points out a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what actions they should take to include these features in the ablation study. The comment is somewhat vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the ablation study, noting that the impact of Age and FaceID features is not studied. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in identifying the missing analysis, the absence of grounding information makes it challenging for the authors to understand where to focus their efforts. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any specific evidence or reasoning to support this claim. Without additional context or references, the authors may find it challenging to understand why this is a significant issue or how it impacts the study. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the ablation study, noting that the impact of Age and FaceID features is not studied. This feedback is clear and actionable, as it highlights a missing analysis that could enhance the comprehensiveness of the study. By pointing out this omission, the comment provides the authors with a clear direction for improvement, encouraging them to include these features in their ablation study. However, the comment could be more helpful if it suggested specific ways to incorporate or analyze these features. Overall, the comment is 4, as it effectively identifies an area for improvement and directs the authors towards a constructive enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions regarding the ablation study, specifically mentioning that Table 2 and Figure 5 were not mentioned in the manuscript. It also asks for clarification on the values in these figures and suggests moving the detailed discussion from the Appendix to the main manuscript. While the comment explicitly suggests moving the discussion, it does not provide detailed guidance on how to implement this change or what specific aspects of the discussion need to be moved. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the clarification of values in the figures and the suggestion to move the detailed discussion from the Appendix to the main manuscript. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the ablation study, specifically regarding the content of Table 2 and Figure 5, and suggests moving the detailed discussion from the Appendix to the main manuscript. While the comment identifies areas that need clarification or adjustment, it does not provide specific reasoning or references to support the suggestions. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies specific issues with the ablation study, noting that Table 2 and Figure 5 were not mentioned in the manuscript and that the detailed discussion is located in the Appendix. It suggests moving the discussion to the main manuscript, which is a constructive and actionable piece of feedback. However, the comment could be more helpful by providing additional guidance on how to effectively integrate the discussion into the main text or by suggesting specific aspects of the discussion that need to be included. Overall, the comment is 4 as it highlights important areas for improvement and provides a clear direction for the authors to follow, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should include more LLMrelated results in their experiments, specifically mentioning the expectation of seeing results from models like llama370B and Mistral7B. This provides a clear and concrete action for the authors to take, as they know exactly what additional experiments they need to conduct to address the reviewer\"s concern. The comment is fully actionable because it is explicit and provides detailed guidance on how to improve the paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the expectation of seeing more LLMrelated results in the experiments, suggesting additional models like llama370B and Mistral7B. This provides the authors with a clear understanding of what needs to be added to the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should include more LLMrelated results in their experiments, specifically mentioning the expectation of seeing results from models like llama370B and Mistral7B. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is necessary or how it aligns with the paper\"s content. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the authors should include more LLMrelated results in their experiments. It provides a clear expectation for additional experiments, such as those involving models like llama370B and Mistral7B. This feedback is actionable and constructive, as it guides the authors on what additional experiments they should conduct to strengthen their paper. However, the comment could be more helpful if it suggested specific ways to conduct these experiments or provided examples of how to present the results effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern regarding the novelty of the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method, suggesting it is closely related to existing techniques like selfconsistency + CoT and Treeofthoughts. It also raises questions about the performance of DFSDT on other types of Large Language Models (LLMs) not within the LLaMA/GPT/Claude category. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method, suggesting it is closely related to existing techniques like selfconsistency + CoT and Treeofthoughts. It also raises questions about the performance of DFSDT on other types of Large Language Models (LLMs) not in the LLaMA/GPT/Claude category. However, the comment does not specify which part of the paper discusses the proposed method or the related techniques, making it weakly grounded. The comment is specific in identifying the areas that need clarification or further exploration, such as the novelty of the method and its performance on different LLMs. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method is closely related to existing techniques like selfconsistency + CoT and Treeofthoughts, and it questions the performance of DFSDT on other types of Large Language Models (LLMs) not in the LLaMA/GPT/Claude category. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method, suggesting it is closely related to existing techniques like selfconsistency + CoT and Treeofthoughts. It also raises questions about the performance of DFSDT on other types of Large Language Models (LLMs) not in the LLaMA/GPT/Claude category. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their work. While it points out areas for further consideration, it does not provide actionable feedback or detailed insights that would help the authors enhance their draft. Therefore, the comment is 2, as it identifies potential weaknesses but does not offer substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the appropriateness of claiming novelty when proposing an identical method to an existing work. It suggests that acknowledging contributions is important, but it does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The comment implies that the authors should consider citing the work or rephrasing their claims to avoid misrepresenting their contribution. However, it lacks concrete instructions on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment addresses the appropriateness of claiming novelty when proposing an identical method to an existing work, specifically mentioning the importance of acknowledging contributions. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is specific in its critique but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the appropriateness of claiming novelty when proposing an identical method to an existing work, suggesting that it is inappropriate to do so. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides some context but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the appropriateness of claiming novelty when proposing an identical method to an existing work, suggesting that it is inappropriate to do so. It highlights the importance of acknowledging contributions and proposes that the authors should consider citing the work or rephrasing their claims to avoid misrepresenting their contribution. While the comment identifies a potential issue, it lacks specific guidance on how to address it or what changes should be made to the paper. The feedback is 3 as it points out a critical aspect of academic integrity, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance comparison between XDC and MMV, specifically questioning why XDC outperforms its baseline while MMV does not, and whether the difference is due to a better backbone architecture. The comment implies that the authors should provide an explanation for this discrepancy, but it does not explicitly instruct them to do so or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the performance differences and the potential reasons behind them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"XDC\" and \"MMV,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by questioning the performance comparison and asking for an explanation of why XDC outperformed its baseline while MMV did not, and whether the difference is due to a better backbone architecture. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance comparison between XDC and MMV, specifically questioning why XDC outperforms its baseline while MMV does not, and whether the difference is due to a better backbone architecture. The comment does not contain a claim that requires verification or justification. It is a question that prompts the authors to provide an explanation, but it does not present an opinion or assertion that needs to be substantiated. Therefore, the comment is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the performance comparison between XDC and MMV, specifically questioning why XDC outperforms its baseline while MMV does not, and whether the difference is due to a better backbone architecture. This question prompts the authors to provide an explanation for the observed performance differences, which is a valuable piece of feedback. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not provide actionable advice or detailed insights that would significantly enhance the authors\" understanding or the quality of their work. Therefore, the comment is 3, as it highlights an important aspect of the paper that requires further clarification and analysis, but it could be more helpful with additional guidance or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses concern about the verbosity and difficulty in following the writing, suggesting that the paper resembles an implementation paper rather than a theoretical or general advancement. It provides a suggestion to focus on main ideas and show analyses of why they work, rather than presenting a wellengineered system with many functions and considerations. However, the comment does not explicitly instruct the authors on how to revise the paper to address these issues. While the suggestion is clear, the lack of explicit guidance on specific actions makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment expresses concerns about the writing style, suggesting it is too verbose and hard to follow, and that the paper resembles an implementation paper rather than a theoretical or general advancement. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is specific in its critique of the writing style but lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses concerns about the writing style, suggesting it is too verbose and hard to follow, and that the paper resembles an implementation paper rather than a theoretical or general advancement. The reviewer provides an opinion, but the comment lacks specific examples or references to support the claim that the writing is verbose or that the paper resembles an implementation paper. Without detailed examples or references, the claim is difficult to verify, making it 2. Therefore, the comment aligns with a score of 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the writing style, noting that it is too verbose and hard to follow, resembling an implementation paper rather than a theoretical or general advancement. This feedback is valuable as it highlights a need for the authors to streamline their writing and focus on core ideas. The suggestion to concentrate on main ideas and show analyses of why they work, rather than presenting a complex, wellengineered system, provides a clear direction for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to revise the writing to be more concise and focused. Overall, the comment is 4 as it provides actionable feedback and direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting the absence of code and supplementary documentation. It suggests that providing these resources would enhance clarity and reproducibility, which are crucial for understanding and replicating the methodology. The comment is explicit in identifying the action to be taken, which is to provide the code and supplementary documentation. It also provides a clear rationale for why this action is beneficial, emphasizing the importance of clarity and reproducibility. Therefore, the comment is 5 as it directly instructs the authors on what needs to be done and why it is important.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of the paper lacking code and supplementary documentation, which is a specific part of the paper that needs improvement. It specifies what is missing and why it is important for clarity and reproducibility. This provides clear guidance for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks the provision of code and supplementary documentation, which could enhance clarity and reproducibility. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim. The authors are left to infer the importance of these resources for understanding and replicating the methodology. Therefore, the claim is 3, as it lacks detailed justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of code and supplementary documentation, which are crucial for enhancing clarity and reproducibility. It provides a clear and actionable suggestion for improvement by recommending that the authors provide these resources. This feedback is valuable as it directly addresses a critical aspect of the paper\"s impact and reproducibility, offering a clear path for the authors to enhance their work. The comment is 4 as it provides a specific and actionable suggestion, but it could be further improved by offering additional guidance on how to present or organize the code and documentation effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should discuss and empirically compare the use of ensembles, particularly REM, in the context of offline RL, specifically on discrete Atari games. It also recommends incorporating value uncertainty in offline RL. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions or what empirical comparisons should be made. The authors are left with a general idea of what needs to be done but without concrete steps or examples, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and \"offline RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to discuss and empirically compare the use of ensembles, particularly REM, in the context of offline RL on discrete Atari games. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that ensembles, particularly REM, have been studied in offline RL and outperform DQN/naive ensembling. It suggests that this should be discussed and empirically compared in the paper. However, the comment lacks specific references or detailed reasoning to support the claim about REM\"s performance. While it provides a general direction, it does not offer sufficient evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for further exploration but requires additional evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the authors discuss and empirically compare the use of ensembles, particularly REM, in the context of offline RL. It highlights the importance of incorporating value uncertainty in offline RL, which is a relevant and valuable point for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to incorporate value uncertainty or detailed suggestions for empirical comparisons. Despite this, the feedback is 4 as it directs the authors towards an important aspect of their work that could enhance its impact and relevance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the two methods have been cleverly combined, but it lacks specific guidance on how the authors should address this issue or what aspects of the combination might need further exploration or clarification. The comment does not provide explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the combination of two methods lacking novelty. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the two methods have been cleverly combined, but it lacks specific evidence or reasoning to support this assertion. Without detailed examples or references, the claim remains subjective and 1. The authors are left without a clear understanding of why this combination lacks novelty, making it difficult to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed methods, suggesting that they have been cleverly combined without sufficient exploration of their individual contributions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. While it points out a concern, it does not provide actionable feedback or detailed insights that would help the authors improve their draft. Therefore, the comment is 3, as it highlights a potential area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scalability of the proposed approach, specifically questioning whether a different model needs to be finetuned for each target language. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this concern or what steps could be taken to improve the approach. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the proposed approach, specifically questioning whether a different model needs to be finetuned for each target language. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is vague and does not provide specific guidance on how to address the scalability issue or what steps could be taken to improve the approach. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the scalability of the proposed approach, specifically questioning whether a different model needs to be finetuned for each target language. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the concern, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the scalability of the proposed approach, specifically questioning whether a different model needs to be finetuned for each target language. This is a valid concern that could impact the practical applicability of the approach. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the approach. Without actionable feedback or specific suggestions, the authors are left without a clear path forward to enhance their work. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more details about Eq. 20, particularly for readers unfamiliar with bAbI or question answering. It also clarifies that \"valid words\" refer to possible answer words for the given story and question. However, the comment does not specify which parts of Eq. 20 need more detail or how the authors should provide these details. The action is implicit and vague, as the authors are left to infer that they need to expand the explanation of Eq. 20. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 20,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is providing more details for readers unfamiliar with bAbI or question answering and clarifying the meaning of \"valid words.\" This level of detail makes the comment specific and helpful for the authors to understand and address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more details about Eq. 20, particularly for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question. However, the comment lacks specific examples or references to support the claim that more details are needed. Without additional context or evidence, the authors may find it challenging to understand the reasoning behind the suggestion. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the authors should provide more details about Eq. 20, particularly for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question. This feedback is 3 as it identifies an area where the paper could be improved by providing more context and explanation. However, the comment lacks specific guidance on how to provide these details or what aspects of the equation need clarification. As a result, the authors may find it challenging to fully address the feedback, making the comment 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the idea of adversarial attacking based on the interested region is not novel, citing a previous work by Yao et al. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable information, leaving the authors without a clear path to respond or enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the idea of adversarial attacking based on the interested region is not novel, citing a previous work by Yao et al. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is 1 as it does not provide specific guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the idea of adversarial attacking based on the interested region is not novel, citing a previous work by Yao et al. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the criticism. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the adversarial attacking method based on the interested region, citing a previous work by Yao et al. This feedback is 3 as it highlights a concern that the authors should consider. However, it lacks specific guidance or suggestions on how the authors might address this issue or improve their work. The comment does not provide actionable steps or detailed insights into how the authors can enhance their draft, leaving them with limited direction. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methods are composed of wellknown components, which raises questions about the novelty and significance of the paper. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the methods need to be clarified or improved. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed methods are composed of wellknown components, questioning the novelty and significance of the paper. However, it does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is vague and lacks specificity, as it does not provide detailed guidance on how the authors might address the issue of novelty or significance. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed methods are composed of wellknown components, which raises questions about the novelty and significance of the paper. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the methods are indeed composed of wellknown components. Without this additional context, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the novelty and significance of the proposed methods, suggesting that they are composed of wellknown components. This feedback highlights a potential weakness in the paper, as it raises concerns about the originality and impact of the contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their methods. Without actionable advice or detailed examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it identifies a critical area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of multiturn data in the test set, suggesting that it might provide assistance in answering the final question, thereby increasing the risk of data leakage. However, the comment does not provide explicit guidance or suggestions on how to address this issue, such as removing the history conversation or implementing a more robust evaluation method. The action is implicit and vague, as it does not specify how the authors should handle the data leakage risk. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of multiturn data in the test set and highlights a potential risk of data leakage. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the test set data, but without clear references to specific sections or tables, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the test set includes multiturn data, which, when used for training models, might provide assistance in answering the final question, thereby increasing the risk of data leakage. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of multiturn data in the test set, suggesting that it might provide assistance in answering the final question, thereby increasing the risk of data leakage. While the comment highlights a concern, it does not provide specific guidance or suggestions on how to address this issue, such as removing the history conversation or implementing a more robust evaluation method. The feedback is 3 as it points out a potential problem, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should check if TTUR is applied and consider a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should verify the application of TTUR and consider a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the application of TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests a comparison with VSD + TTUR for better convincingness. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the application of TTUR in Figure 7 and suggests a comparison with VSD + TTUR for better convincingness. While the comment implies that the authors should verify the application of TTUR and consider a comparison, it does not provide specific evidence or reasoning to support the claim that TTUR improves performance. The suggestion is based on the findings of the DMD2 paper, but the authors are not explicitly directed to compare their results with VSD + TTUR. Therefore, the claim is 3, as it lacks detailed justification or references to support the suggestion.", "helpfulness_rationale": "The review comment raises a specific question about the application of TTUR in Figure 7 and suggests a comparison with VSD + TTUR to enhance the paper\"s convincingness. While the comment identifies a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The authors are left with a vague idea of what to do, which limits the comment\"s helpfulness. Therefore, the comment is rated as 2, as it offers some insight but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the merit of the theoretical result presented in the paper, specifically regarding the definition of outofdistribution (OOD) actions. It highlights a potential inconsistency in the paper\"s approach, noting that the definition of OOD actions is inconsistent with the assumptions made. The comment suggests that the authors have adequately addressed the limitations and social impact of their work, but it does not provide explicit guidance on how to improve the paper or address the inconsistency. The action is implicit, as the authors need to infer that they should clarify the definition of OOD actions or provide a rationale for the inconsistency. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s focus on deriving a conservative estimate of quantiles from offline data and the definition of outofdistribution actions. It references specific elements of the paper, such as line 109 and Assumption 3.1, allowing the authors to accurately identify the part being addressed. The comment is also specific because it clearly specifies the issue with the definition of OOD actions and questions the merit of the theoretical result. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the merit of the theoretical result presented in the paper, specifically regarding the definition of outofdistribution (OOD) actions. It highlights a potential inconsistency in the paper\"s approach, noting that the definition of OOD actions is inconsistent with the assumptions made. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the theoretical result is not meaningful or that the inconsistency is a significant issue. Without detailed justification or evidence, the claim remains 3, as the authors may need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the merit of the theoretical result presented in the paper, specifically regarding the definition of outofdistribution (OOD) actions. It points out a potential inconsistency in the paper\"s approach, noting that the definition of OOD actions is inconsistent with the assumptions made. The comment suggests that the authors have adequately addressed the limitations and social impact of their work, but it does not provide specific guidance or suggestions on how to improve the paper or address the inconsistency. While the comment identifies an area for improvement, it lacks depth and actionable advice, making it 3. The authors may need to infer the need for clarification or further explanation, which limits the comment\"s overall impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper\"s analysis is shallow and lacks clear takeaways or conclusions, which could be better suited for the appendix. It also recommends integrating essential details, such as dataset splitting justifications, into the main text. While the comment provides a clear action\u2014either moving the analysis to the appendix or integrating it into the main text\u2014it does not specify how to implement these actions. The authors are left with a general direction but no concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper\"s analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what the authors should do, such as either moving the analysis to the appendix or integrating essential details into the main text. This feedback is detailed and actionable, making the comment 5.", "verifiability_rationale": "The review point claims that the paper provides a shallow linguistic dataset analysis without clear takeaways or conclusions, suggesting that it might be better suited for the appendix. Conversely, it recommends integrating essential details, such as dataset splitting justifications, into the main text. However, the comment lacks specific examples or references to support the claim about the depth of the analysis or the importance of dataset splitting. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s analysis, noting that it is shallow and lacks clear takeaways or conclusions. This feedback is valuable as it highlights a potential weakness in the paper\"s contribution. The comment suggests that the analysis might be better suited for the appendix, or that essential details, such as dataset splitting justifications, should be integrated into the main text. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or guidance on how to enhance the analysis. Overall, the comment is 4 as it directs the authors towards improving the depth and clarity of their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experimental results: the lack of clarity in the metric of Table 1 and the absence of details regarding experimental parameters such as backbone choice, learning rate, and optimization schedules. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the metric and provide more detailed experimental parameters. This lack of explicit guidance makes the comment 3, as it points out areas for improvement but does not offer concrete steps on how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically mentioning the metric of Table 1 and the lack of clarity in its presentation. It also points out the absence of details regarding experimental parameters such as backbone choice, learning rate, and optimization schedules. However, the comment does not specify which part of the paper contains the detailed experimental setup or results, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the metric and providing experimental details. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric of Table 1 is not clearly stated and that the experimental details, such as backbone choice, learning rate, and optimization schedules, are missing. However, the comment does not provide any specific examples or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of these claims and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two key issues with the experimental results: the lack of clarity in the metric of Table 1 and the absence of details regarding experimental parameters such as backbone choice, learning rate, and optimization schedules. While the comment points out these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights important aspects that need clarification, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that while it mentions the advantage of POMDPs in not directly observing the target variable Y, it does not discuss how this advantage is leveraged in the paper. The comment implies that the authors should address this gap by discussing how previous decisions impact the observable data. However, the action is implicit, as the authors need to infer that they should discuss the impact of previous decisions on observable data to leverage the advantage of POMDPs. The action is somewhat vague, as it does not provide specific guidance on how to implement this discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the advantage of POMDPs in not directly observing the target variable Y, which is a specific aspect of the paper. It also specifies what needs to be addressed, namely that this advantage is not leveraged in the paper, and suggests discussing how previous decisions impact observable data. This provides clear guidance on what part of the paper needs attention and what specific issue needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not leverage the advantage of POMDPs, specifically noting that it does not discuss how previous decisions impact observable data. This claim is 3 as it provides a specific example of a missing discussion, but it lacks detailed reasoning or references to support the assertion that the paper fails to address this aspect. The authors would need to infer that the paper is missing this discussion, which could be improved with additional explanation or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that while it mentions the advantage of POMDPs in not directly observing the target variable Y, it does not discuss how this advantage is leveraged in the paper. The comment suggests that the authors should address this gap by discussing how previous decisions impact observable data. This feedback is clear and actionable, providing the authors with a specific area to improve their draft. However, it could be more helpful if it included suggestions on how to discuss this aspect or examples of how to integrate it into the paper. Overall, the comment is 4 as it highlights a significant oversight and guides the authors on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the small size of the pretraining tokens_per_sample (256) and the batch_size=64 used for pretraining. While it questions the sufficiency of these parameters for a regularsize program, it does not provide explicit guidance on how the authors should adjust these parameters or what specific changes would be beneficial. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to address the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses concerns about the pretraining tokens_per_sample and batch_size, which are important aspects of the paper. However, it does not specify which part of the paper these parameters are discussed in, making it weakly grounded. The comment is specific in its critique of the small size of tokens_per_sample and the batch_size, suggesting that they are insufficient for a regularsize program. This provides clear guidance on what needs to be addressed, but the lack of specific section references makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the small size of the pretraining tokens_per_sample (256) and the batch_size=64 used for pretraining. However, it does not provide any specific reasoning, examples, or references to support why these values are insufficient or how they might impact the results. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific concerns regarding the pretraining tokens_per_sample and batch_size, noting that they are too small for a regularsize program. This feedback is clear and actionable, as it highlights potential issues with the experimental setup that could affect the validity of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address these issues, such as increasing the token_per_sample or batch_size, or discussing the implications of these choices. Overall, the comment is 4 as it points out important areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of ablation experiments in the work, suggesting that the authors should include more experiments to help readers understand the proposed method. It provides specific examples, such as replacing the clustering algorithm with KMeans and evaluating the model\"s performance with differentsized descendant models. This feedback is explicit and concrete, as it clearly directs the authors to add specific ablation studies. The comment is fully actionable, as it provides detailed guidance on how to improve the draft by including additional experiments. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ablation experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear examples of what could be included in the ablation experiments, such as replacing the clustering algorithm with KMeans and evaluating the model\"s performance with differentsized descendant models. This level of detail helps the authors understand exactly what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work lacks enough ablation experiments to help readers understand the proposed method. It provides specific examples, such as replacing the clustering algorithm with KMeans and evaluating the model\"s performance with differentsized descendant models. These examples offer a clear rationale for the claim, making it 3. However, the comment could be more robust if it included references to existing literature or detailed explanations of why these specific experiments are crucial. Overall, the claim is 4, as it is supported by logical reasoning and examples, but lacks some depth in terms of references or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper: the lack of ablation experiments. It provides specific examples, such as replacing the clustering algorithm with KMeans and evaluating the model\"s performance with differentsized descendant models, which would help readers understand the proposed method better. By highlighting these areas, the comment offers actionable guidance for the authors to enhance their draft. However, the comment could be more helpful if it suggested additional experiments or provided more detailed reasoning for why these experiments are necessary. Overall, the feedback is 4 as it directs the authors to improve their draft by including more comprehensive experiments."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the Talking Heads Transformer should be the de facto baseline for all tasks in the paper, not just the one compared in Table 1. It also questions the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to compare the Talking Heads Transformer as a baseline for all tasks, not just the one in Table 1, and questions the benefit of the proposed modules compared to a simple linear transform. This provides a clear direction for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Talking Heads Transformer should be the de facto baseline for all tasks in the paper, not just the one compared in Table 1. It questions the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. The absence of detailed justification or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by suggesting that the Talking Heads Transformer should be the de facto baseline for all tasks, not just the one compared in Table 1. It questions the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform, which is a crucial point for understanding the value of the proposed approach. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what additional experiments or comparisons might be necessary to substantiate the claim. While it offers a clear direction for improvement, the lack of detailed suggestions limits its impact on the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should check the scenario simulation and benchmark speaker identification on the HIMIA dataset. While the comment provides a clear action\u2014checking and benchmarking\u2014it does not specify which aspects of the simulation need to be checked or how the benchmarking should be conducted. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Following2)\" and \"the scenario is simulated,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to check the simulation and benchmark speaker identification on the HIMIA dataset, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should check the scenario simulation and benchmark speaker identification on the HIMIA dataset. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this check is necessary or how it would impact the paper. The suggestion is 3 as it offers a clear direction for improvement but could be strengthened with additional justification or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should check the scenario simulation and benchmark speaker identification on the HIMIA dataset. This feedback is clear and actionable, providing a concrete direction for the authors to enhance their work. However, the comment could be more helpful if it included additional guidance on how to conduct the check or what specific aspects of the simulation need to be examined. Despite this, the comment offers valuable insights and actionable suggestions, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment provides a minor note on the framing of the paper, suggesting that the introduction focuses on breast cancer while the paper\"s contributions are more general. It offers an alternative framing that emphasizes the loss function and its applications, which could be more appropriate. While the comment implies an action, it does not explicitly instruct the authors to reframe their introduction or adjust their framing to align with the suggested alternative. The action is somewhat vague, as the authors need to infer how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus of the introduction on breast cancer, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper\"s contributions are not particularly focused on breast cancer, despite the evaluation of the loss function over multiple datasets, including breast cancer. The comment suggests an alternative framing that focuses on the loss function and its applications, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a minor note on the framing of the paper, suggesting that the introduction focuses on breast cancer while the paper\"s contributions are more general. It offers an alternative framing that emphasizes the loss function and its applications. However, the comment lacks specific examples or detailed reasoning to fully support the claim that the framing is inappropriate or needs adjustment. While the suggestion is logical, it does not provide sufficient evidence or references to substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks depth and clarity.", "helpfulness_rationale": "The review comment provides a minor note on the framing of the paper, suggesting that the introduction focuses on breast cancer while the paper\"s contributions are more general. It offers an alternative framing that emphasizes the loss function and its applications, which could be more appropriate. This feedback is 3 as it identifies a potential issue with the framing and provides a suggestion for improvement. However, the comment could be more helpful if it included specific examples or detailed reasoning to support the claim that the current framing is not aligned with the paper\"s contributions. Without such details, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks the authors to include agreement statistics for the corpus in section 3.1 or 3.2. This is a clear and explicit instruction that provides a specific action for the authors to take. The comment is concrete, as it specifies exactly where the authors should include the statistics. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment requests the inclusion of agreement statistics for the corpus in section 3.1 or 3.2. It explicitly mentions sections of the paper where this information should be added, providing full grounding. The comment is also specific as it clearly specifies what needs to be included, namely agreement statistics. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point requests the inclusion of agreement statistics for the corpus in section 3.1 or 3.2. This is a factual request for additional information, which does not involve any subjective opinions or claims. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment is clear and specific, asking the authors to include agreement statistics for the corpus in section 3.1 or 3.2. This provides a direct and actionable suggestion for improvement, guiding the authors on where to add crucial information. By addressing a specific aspect of the paper, the comment helps the authors enhance the completeness and clarity of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the potential novelty of the instruction aggregation and LLM usage but points out that existing LLMs are used. It also notes that the use of consecutive subtrajectories is straightforward and that crosstrajectory chaining has novelty, with techniques inspired by goalconditioned RL approaches. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific improvements or clarifications. The feedback lacks concrete guidance on how the authors might address these points, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the instruction aggregation and the use of LLMs, noting that while the approach might be novel, existing LLMs are used. It also mentions the straightforward nature of consecutive subtrajectories and the novelty of crosstrajectory chaining, which is inspired by goalconditioned RL approaches. However, the comment does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific guidance on what needs to be addressed further reduces the comment\"s grounding specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of consecutive subtrajectories is straightforward and that crosstrajectory chaining has novelty, with techniques inspired by goalconditioned RL approaches. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations to substantiate the assertion that the techniques are inspired by goalconditioned RL approaches. This lack of evidence makes the claim 3, as the authors may need to infer the basis of the claim or seek additional information to fully understand it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies potential areas for improvement in the paper, specifically regarding the novelty of the instruction aggregation and the use of LLMs. It acknowledges that while the approach might be novel, existing LLMs are used, and the use of consecutive subtrajectories is straightforward. The comment also points out that crosstrajectory chaining has novelty but is inspired by goalconditioned RL approaches, referencing a specific paper. However, the comment does not provide detailed suggestions or actionable feedback on how the authors might address these points or improve the paper. While it highlights areas for attention, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind using the identity map in the attention module and suggests that more discussion should be conducted. While it implies that the authors should provide a justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the reasoning behind their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind using the identity map in the attention module and suggests that more discussion should be conducted. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its suggestion to provide more discussion, the absence of grounding information makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the rationale behind using the identity map in the attention module and suggests that more discussion should be conducted. However, it does not provide any specific reasoning, examples, or references to support why the identity map is a good choice or how it improves the expressive power of the attention module. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using the identity map in the attention module and suggests that more discussion should be conducted. This feedback is 3 as it points out a potential area for improvement in the paper, specifically regarding the justification for the choice of the identity map. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. The authors are left to infer that they need to elaborate on the reasoning behind their choice, which limits the actionable value of the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directs the authors to provide an explanation for why they are considering decoderonly transformers. This is a clear and explicit action that the authors can readily follow. The comment is specific in its request, as it directly asks for an explanation in a particular section of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests an explanation for a particular choice made in the paper, which is a clear and actionable request for the authors to provide additional context or justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests an explanation for why the authors are considering decoderonly transformers. While it does not contain a subjective claim or opinion, it suggests that the authors should provide a rationale for their choice. This request is logical and requires the authors to substantiate their decision, making it 3. However, it lacks specific examples or references to support the request, which could enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is specific and actionable, as it requests an explanation for why the authors are considering decoderonly transformers. This feedback is valuable because it prompts the authors to provide a rationale for their choice, which can help clarify their reasoning and potentially strengthen the paper. However, the comment could be more helpful if it suggested specific areas where this explanation might be needed or provided guidance on how to structure the explanation. Overall, the comment is 3, as it identifies a need for clarification but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the qualitative analysis is missing important details, such as the proportion of each error category. It also implies that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include specific details or analyses. The action is somewhat vague, as the authors are left to infer how to incorporate these suggestions into their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper \"Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting\" by Turpin et al., allowing the authors to accurately identify the source of the feedback. It also specifies the issue with the qualitative analysis, noting the absence of details such as the proportion of each error category. The comment further suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment is rated as 5.", "verifiability_rationale": "The review point claims that the qualitative analysis misses important details, such as the proportion of each error category, and suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment references a specific paper, \"Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" by Turpin et al., which provides context for the discussion. However, the claim lacks detailed reasoning or specific examples to fully substantiate the assertion about the missing details and the need for more fruitful speculation. The reference to the Turpin et al. paper is helpful but does not fully explain why the authors should consider these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the qualitative analysis lacks important details such as the proportion of each error category. It also suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment references a specific paper, \"Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" by Turpin et al., which provides context for the discussion. However, the comment could be more helpful if it provided specific examples or suggestions for how to address the identified issues. Overall, the feedback is 3 as it highlights areas for improvement but lacks detailed guidance, making it a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors could try to apply Reinforcement Learning, RNNs, and Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. This provides a clear and explicit action for the authors to take, as it specifies exactly what experiments to conduct. The comment is detailed and concrete, offering a specific direction for validation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the baselines used for comparison, specifically mentioning the use of Reinforcement Learning, RNNs, and Wasserstein GANs. It also specifies the authors\" approach of comparing their proposed data generation technique with a Markov chain approach. The comment provides clear guidance on what the authors could try to do to empirically validate the suitability of these baselines, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors could apply Reinforcement Learning, RNNs, and Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. This claim is 3 as it provides a logical suggestion for an additional experiment that could strengthen the paper. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider. It identifies a potential weakness in the current approach by noting that the baselines used for comparison, such as Reinforcement Learning, RNNs, and Wasserstein GANs, require significant data and are not applicable to the proposed approach. The comment suggests that the authors could try to apply these methods with data filled by simple methods to empirically validate their suitability. This feedback is valuable as it offers a concrete direction for the authors to strengthen their experimental validation and provide a more comprehensive comparison. However, the comment could be more helpful if it included specific examples or guidance on how to implement this suggestion. Overall, the comment is 4, as it provides a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the GEVAL method, noting that it is based on GPT3.5 and GPT4 but does not include a comparison with the performance of these models using the simplest prompt. This feedback is explicit and provides a clear action for the authors to take: they should include a baseline comparison using the simplest prompt for GPT3.5 and GPT4. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the GEVAL method and the specific issue of lacking a baseline comparison with the simplest prompts for GPT3.5 and GPT4. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the current draft, namely the comparison with the simplest prompts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the GEVAL method lacks a baseline comparison with the simplest prompts for GPT3.5 and GPT4. While the comment identifies a specific issue, it does not provide any evidence or reasoning to support why this comparison is necessary or how it would impact the results. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the GEVAL method, noting that it lacks a baseline comparison with the simplest prompts for GPT3.5 and GPT4. This feedback is clear and actionable, as it directs the authors to include a comparison with the simplest prompts to provide a more comprehensive evaluation of the method. By doing so, the authors can better understand the performance of GEVAL relative to the most basic implementations of the models. This feedback is 4 as it provides a specific and actionable suggestion for improvement, but it could be more comprehensive if it included additional details or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific instructions for updating weights in multiagent environments, including the need to compute expected rewards or NE gaps for different perturbations. It also highlights a potential issue with the base policies, which only get updated based on observed rewards, unlike the base policies which require full knowledge of game payoffs. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to compute NE gaps or update weights. The action is implicit and vague, as the authors are left to infer that they need to clarify or address these points. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment provides specific instructions for updating weights in multiagent environments, including the need to compute expected rewards or NE gaps for different perturbations. It also highlights a potential issue with base policies, which only get updated based on observed rewards, unlike the base policies which require full knowledge of game payoffs. Additionally, it mentions that computing NE gaps requires knowing policies of other agents. However, the comment does not specify which part of the paper discusses these issues or how they relate to the overall content. The authors can infer that the comment pertains to the methodology or experimental setup, but without explicit references, the grounding is weak. The comment is specific in detailing the issues with updating weights and computing NE gaps, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point provides specific instructions for updating weights in multiagent environments, including the need to compute expected rewards or NE gaps for different perturbations. It also highlights a potential issue with base policies, which only get updated based on observed rewards, unlike the base policies which require full knowledge of game payoffs. Additionally, it mentions that computing NE gaps requires knowing policies of other agents. However, the comment does not provide any reasoning, examples, or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is 1.", "helpfulness_rationale": "The review comment provides specific instructions for updating weights in multiagent environments, including the need to compute expected rewards or NE gaps for different perturbations. It also highlights a potential issue with base policies, which only get updated based on observed rewards, unlike the base policies which require full knowledge of game payoffs. Additionally, it mentions that computing NE gaps requires knowing policies of other agents. However, the comment lacks depth and does not provide actionable guidance on how to address these issues or suggest improvements to the methodology. While it identifies areas for enhancement, it does not offer detailed feedback or constructive suggestions, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the comparison need improvement or what additional comparisons should be included. Without further clarification or suggestions, the authors are left without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section being addressed. It is also not specific because it does not detail what aspects of the comparison with DiffUCO need improvement or what additional comparisons should be included. Without this information, the authors cannot effectively address the feedback. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point states that the paper primarily compares the proposed methods with DiffUCO. This is a factual statement that describes the scope of the comparison. However, it does not provide any additional context, reasoning, or references to support why this comparison is limited or what implications it might have. The comment lacks depth and does not offer any guidance or suggestions for improvement. Therefore, it is considered 1.", "helpfulness_rationale": "The review comment points out that the paper primarily compares the proposed methods with DiffUCO. While this observation is factual, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to enhance their comparisons or what additional comparisons might be necessary. Without specific advice or suggestions, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it is rated as 2, corresponding to a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explicit definitions and detailed explanations regarding the decomposition method, specifically the local subtasks and their corresponding policies, as well as the relationship between them. It also points out the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment identifies the areas where the paper is lacking in detail, it does not provide specific guidance on how the authors should address these issues. The authors are left with a general understanding of what needs to be improved but are not given concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it identifies the areas needing improvement but lacks detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contribution\" and the \"exposition of the decomposition method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the paper, such as the lack of explicit definitions of local subtasks and their corresponding policies, the relationship between them, and the absence of a complete proof of equivalence. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is too repetitive and superficial in its exposition of the decomposition method, specifically regarding the lack of explicit definitions of local subtasks and their corresponding policies, the relationship between them, and the absence of a complete proof of equivalence. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of explicit definitions and detailed explanations regarding the decomposition method, including the local subtasks and their corresponding policies, as well as the relationship between them. It also points out the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. This feedback is valuable as it highlights areas where the paper could be improved to enhance clarity and rigor. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues, such as suggesting additional details or examples to include. Overall, the comment is 3, as it directs the authors to areas needing improvement but lacks depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing element in the paper, specifically the performance curve of each algorithm during the training. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting where to include the missing information or how to present it effectively. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the performance curve of each algorithm during the training is missing, but it does not specify which part of the paper this information should be included in or how it should be presented. This lack of grounding makes it difficult for the authors to understand where to address the issue. However, the comment is specific in identifying the missing information, which could guide the authors in improving their draft. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the performance curve of each algorithm during the training is missing. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left without a clear understanding of why this information is missing or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance curve of each algorithm during the training is missing. This feedback is clear and actionable, as it directly points out a gap in the paper that needs to be addressed. However, the comment lacks depth and does not provide suggestions on how the authors might include or present this information effectively. While it highlights an important area for improvement, it could be more helpful if it offered guidance on how to incorporate the missing data or suggested ways to present it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a computational limitation of the proposed Gaussian kernelbased graph construction method, noting that it requires computing the full adjacency matrix, resulting in a time complexity of O(N^2) for largescale graphs. While the comment identifies a potential issue with the method\"s efficiency, it does not provide explicit guidance on how the authors might address this limitation or suggest alternative approaches. The action is implicit, as the authors would need to infer that they should consider more efficient methods for graph construction. However, the lack of concrete suggestions or guidance on how to implement these improvements makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed Gaussian kernelbased graph construction method requires computing the full adjacency matrix, which is computationally expensive for largescale graphs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with a score of 5.", "verifiability_rationale": "The review point claims that the proposed Gaussian kernelbased graph construction method requires computing the full adjacency matrix, resulting in a time complexity of O(N^2) for largescale graphs. This claim is supported by the description of the method and the computational complexity, providing a clear and logical explanation of the issue. However, the comment does not offer specific examples or references to support the claim further, which could enhance its persuasiveness. Despite this, the claim is 4 as it is wellsupported by the provided information. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed Gaussian kernelbased graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for largescale graphs. This critique highlights a potential limitation in the method\"s efficiency, which could impact its applicability to realworld scenarios involving large datasets. While the comment points out a valid concern, it does not provide any suggestions or guidance on how the authors might address this issue or improve the method. Without actionable feedback or recommendations, the comment is 3 as it alerts the authors to a potential weakness but does not offer a path forward for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" explanation for using case (1) in Eq. (5) despite case (3) showing better performance in most widths. It suggests that the authors should consider the importance of all subnetworks with different widths, which is a valid point of concern. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should reconsider their explanation and potentially provide a more nuanced justification for their choice. The lack of concrete suggestions or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the use of case (1) in Eq. (5) despite case (3) showing better performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" explanation for using case (1) in Eq. (5) despite case (3) showing better performance in most widths. The reviewer disagrees with the authors\" reasoning that \"To ensure the performance of the smallest network, we adopt the reweighting manner (1) in practice\" and suggests that all subnetworks with different widths should be equally important. However, the comment does not provide specific examples, reasoning, or references to support the reviewer\"s claim or disagreement. Without detailed justification or evidence, the claim remains 3, as the authors may need to provide additional reasoning to address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the authors use case (1) in Eq. (5) despite case (3) showing better performance in most widths. The reviewer questions the authors\" explanation for this choice, suggesting that all subnetworks with different widths should be equally important. This feedback highlights a potential inconsistency in the authors\" reasoning and provides a clear point for improvement. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or provide a more nuanced explanation for their choice. Overall, the comment is 3 as it points out a specific area for clarification and improvement, but it lacks depth and actionable suggestions, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper\"s claim about the unexplored nature of finetuning multiplicity in Tabular LLMs, arguing that the main results are general and do not leverage the unique characteristics of tabular data or LLMs. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to align their results with the paper\"s scope. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s claim regarding the unexplored nature of finetuning multiplicity in Tabular LLMs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the main results are general and do not leverage the unique characteristics of tabular data or LLMs, which is a clear and specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s main results are general and do not leverage the unique characteristics of tabular data or LLMs, which is a subjective opinion. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s claim regarding the unexplored nature of finetuning multiplicity in Tabular LLMs. It points out that the main results are general and do not leverage the unique characteristics of tabular data or LLMs, which contradicts the paper\"s scope. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s claims and suggests that the authors need to address this issue to align their results with the paper\"s scope. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue. Overall, the comment is 4, as it provides a clear critique and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the use of double summation in the context of multilayered garments and vertices, as well as the function f(.) in the line above equation 3. It also questions the novelty of the approach compared to existing works like TailorNet and Patel et al. 2021, which also use PBS for garment drape. The comment suggests that the authors should clarify the use of double summation and provide details on the challenges of simulating multiple layers. However, the comment does not explicitly instruct the authors to address these points in their draft, leaving them to infer the necessary actions. The suggestions are somewhat vague and lack concrete guidance on how to implement them, making the comment 3.", "grounding_specificity_rationale": "The comment raises several specific questions and suggestions regarding the use of double summation in the context of multilayered garments and vertices, as well as the function f(.) in the line above equation 3. It also questions the novelty of the approach compared to existing works like TailorNet and Patel et al. 2021, which also use PBS for garment drape. The comment suggests that the authors should provide details on how simulating multiple layers is more challenging than simulating singlelayered clothing. However, the comment does not explicitly mention specific sections or parts of the paper that need attention, making it weakly grounded. The questions and suggestions are specific, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the use of double summation, the function f(.), and the novelty of the approach compared to existing works. It questions the authors to clarify the use of double summation and provide details on the challenges of simulating multiple layers. However, the comment lacks specific examples, detailed reasoning, or references to support the claims made. The suggestions are somewhat vague and do not provide a clear path for the authors to address the issues. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises several important questions and suggestions that could help the authors improve their draft. It questions the use of double summation in the context of multilayered garments and vertices, asking for clarification on the function f(.) in the line above equation 3. It also points out the existence of similar works, such as TailorNet and Patel et al. 2021, which use PBS for garment drape, and suggests that the authors provide details on the challenges of simulating multiple layers compared to singlelayered clothing. These points are relevant and actionable, as they highlight areas where the authors could enhance the clarity and depth of their work. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested additional experiments or analyses that could strengthen the paper. Overall, the comment is 3, as it identifies meaningful areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical analysis, specifically regarding the supremum in Definition 1 and how the proposed GRADE reduces it. While it prompts the authors to clarify the theoretical basis, it does not provide explicit guidance on how to address the confusion or improve the analysis. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the theoretical basis and the proof of how GRADE reduces the supremum. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical analysis, specifically regarding the supremum in Definition 1 and how the proposed GRADE reduces it. However, it does not specify which part of the paper this question pertains to, such as a particular section or definition. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for clarification, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical analysis, specifically regarding the supremum in Definition 1 and how the proposed GRADE reduces it. However, it does not provide any evidence, reasoning, or references to support the claim that there is confusion in the theoretical analysis or that the authors need to clarify the basis of the supremum. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the theoretical analysis, particularly regarding the supremum in Definition 1 and how the proposed GRADE reduces it. By questioning the basis of the supremum and the proof of reduction, the comment highlights a potential weakness in the theoretical foundation of the paper. However, it does not provide detailed guidance or suggestions on how to address this confusion or improve the analysis. While it points out an area that needs clarification, the feedback lacks actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include results and analysis on lengthy dialogue samples and asks if the performance might drop on these dialogues. While the comment implies that this analysis should be included, it does not provide explicit instructions on how to conduct the analysis or what specific aspects of performance to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results and analysis on lengthy dialogue samples and asks if the performance might drop on these dialogues. However, it does not specify which part of the paper discusses dialogue samples or where the results are presented. The authors cannot confidently determine which section or part of the paper this comment refers to, making it weakly grounded. The comment is specific in suggesting the inclusion of results and analysis, but without grounding, the authors may struggle to locate the relevant section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include results and analysis on lengthy dialogue samples and asks if the performance might drop on these dialogues. However, the comment lacks specific details or examples to support this suggestion, making it difficult for the authors to understand the reasoning behind the recommendation. Without additional context or justification, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically questioning whether the performance might drop on these dialogues. This feedback is 3 as it identifies a potential area for improvement and raises a relevant question that could guide the authors in enhancing their analysis. However, the comment lacks depth and does not provide specific suggestions or guidance on how to conduct the analysis or what aspects of performance to focus on. As a result, the feedback is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the datasets used in the paper only contain visual modalities and recommends including more natural modalities, such as audio and visual, for better evaluation. It also provides references to support the claim, such as [1] Weiyao Wang, Du Tran, and Matt Feiszli. What makes train 1055 training multimodal classification networks hard? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12695\u201312705, 2020. [2] Thomas Winterbottom, Sarah Xiao, Alistair McLean, and Noura Al Moubayed. On modality bias in the tvqa dataset. BMVC, 2020. [3] Ya Sun, Sijie Mai, and Haifeng Hu. Learning to balance the learning rates between various modalities via adaptive tracking factor. IEEE Signal Processing Letters, 28:1650\u2013 1654, 2021. The comment explicitly states the need to include more modalities and provides references to support the claim, making it 5. The authors know exactly what needs to be done to improve their draft, as they are directed to consider expanding their dataset to include audio and visual modalities. This level of detail and specificity allows the authors to effectively address the feedback and enhance their work.", "grounding_specificity_rationale": "The comment suggests that the datasets used in the paper only contain visual modalities and recommends including more natural modalities, such as audio and visual, for better evaluation. It provides references to support this claim, which helps the authors understand the context and relevance of the suggestion. However, the comment does not specify which part of the paper discusses the datasets or the evaluation methodology, making it weakly grounded. The comment is specific in its suggestion to include more modalities, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that all datasets only contain visual modalities and suggests including more natural modalities, such as audio and visual, for better evaluation. It provides references to support this claim, such as [1] Weiyao Wang, Du Tran, and Matt Feiszli. What makes train 1055 training multimodal classification networks hard? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12695\u201312705, 2020. [2] Thomas Winterbottom, Sarah Xiao, Alistair McLean, and Noura Al Moubayed. On modality bias in the tvqa dataset. BMVC, 2020. [3] Ya Sun, Sijie Mai, and Haifeng Hu. Learning to balance the learning rates between various modalities via adaptive tracking factor. IEEE Signal Processing Letters, 28:1650\u2013 1654, 2021. The references provide evidence to support the claim, making it 4. However, the comment could be more robust if it included a detailed explanation of why the inclusion of more modalities would improve the evaluation, or if it provided specific examples of how this would enhance the analysis. Overall, the claim is wellsupported, making it a 4.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that the datasets used only contain visual modalities. It suggests that incorporating more natural modalities, such as audio and visual, could enhance the evaluation and provide a more comprehensive understanding of the models. The comment is clear and actionable, as it provides specific guidance on how the authors can improve their work by expanding their dataset. By recommending the inclusion of additional modalities, the authors are given a clear direction for enhancing the robustness and depth of their evaluation. This feedback is 4, as it offers a clear path for improvement but could be further strengthened by suggesting specific methods for incorporating these modalities. Overall, the comment is 5, as it provides actionable and constructive feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a similarity between the oraclecontext model and some prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for VisionLanguage Models. However, it does not provide any explicit or implicit suggestions on how the authors should address this similarity or discuss these works in their paper. The comment lacks guidance on what specific actions the authors should take to improve their draft, such as including a discussion of these related works or acknowledging the similarity. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment highlights a similarity between the oraclecontext model and some prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for VisionLanguage Models. However, it does not specify which part of the paper this comparison is intended for, making it difficult for the authors to pinpoint the exact section or context. While the comment identifies a potential area for discussion, it lacks specificity in terms of which part of the paper needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the oraclecontext model is very similar to some prompt tuning works, such as Visual Prompt Tuning and Prompt Learning for VisionLanguage Models, but these works are not discussed in the paper. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains 1, as the authors are left without a clear understanding of why these works are not discussed. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential similarity between the oraclecontext model and some prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for VisionLanguage Models. However, it does not provide any detailed explanation or reasoning to support this claim, nor does it suggest how the authors might address this similarity in their paper. The comment lacks actionable guidance, as it does not offer specific advice on how the authors could improve their draft by discussing or acknowledging these related works. Without clear suggestions or a deeper analysis, the feedback is not particularly helpful in guiding the authors to enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper only discusses the observed phenomenon without providing deeper insights into how these observations can be used to design better resilient systems. It also proposes a specific example of how a proposed defense method could be integrated to demonstrate the usefulness and significance of the observed results. However, the comment does not explicitly instruct the authors to address these points or provide detailed guidance on how to incorporate the suggested elements into their draft. The action is implicit and somewhat vague, as the authors would need to infer the specific areas to focus on and how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper that discusses the observed phenomenon and suggests that the paper does not provide deeper insights into how these observations can be used to design better resilient systems. It also provides a specific example of how a proposed defense method could be integrated to demonstrate the usefulness and significance of the observed results. This allows the authors to accurately identify the section of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, including the lack of deeper insights and the suggestion to integrate a proposed defense method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only discusses the observed phenomenon without providing deeper insights into how these observations can be used to design better resilient systems. It suggests that the paper lacks depth and does not offer guidance on how to leverage the observed results for system design. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it primarily discusses observed phenomena without providing deeper insights into how these observations can be used to design better resilient systems. It suggests that the paper lacks depth and does not offer guidance on leveraging the observed results for system design. The comment also proposes a specific example of how a proposed defense method could be integrated to demonstrate the usefulness and significance of the observed results. This feedback is 4 as it provides clear and actionable suggestions for improvement, guiding the authors to enhance the depth and impact of their work. However, it could be more comprehensive if it included additional examples or a broader discussion of potential applications. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors are evaluating a form of reliability or trust by examining what LLMs \"knows,\" but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to make their evaluation more rigorous. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the authors are evaluating a form of reliability or trust by looking at what LLMs \"knows,\" but it does not specify which part of the paper this evaluation is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the issue of lacking rigorous definitions, which provides clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors are evaluating a form of reliability or trust by examining what LLMs \"knows,\" but it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains speculative and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" evaluation of reliability or trust, specifically noting that the authors are examining what LLMs \"knows\" but lack rigorous definitions. This feedback is 3 as it points out a potential area for improvement in the authors\" methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or develop more rigorous definitions. Without actionable advice or detailed examples, the authors may find it challenging to fully address the feedback, making the comment 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises several questions about the necessity of masked selfattention in the YFuture encoder, the preference for ProbSparse, and the impact on computational efficiency. It also notes that forecasting horizons are larger than history lengths in many experiments. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or what changes might be necessary. The questions are openended and lack concrete advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the necessity of masked selfattention in the YFuture encoder, the preference for ProbSparse, and the impact on computational efficiency. It also notes that forecasting horizons are larger than history lengths in many experiments from Appendix E.2. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections or figures being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the necessity of masked selfattention in the YFuture encoder, the preference for ProbSparse, and the impact on computational efficiency. It also notes that forecasting horizons are larger than history lengths in many experiments from Appendix E.2. However, the comment does not provide any specific reasoning, examples, or references to support these claims. The questions are openended and lack detailed justification, making it difficult for the authors to understand the basis of the concerns. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the necessity of masked selfattention in the YFuture encoder, the preference for ProbSparse, and the impact on computational efficiency. It also notes that forecasting horizons are larger than history lengths in many experiments from Appendix E.2. However, the comment does not provide any specific guidance or suggestions on how the authors might address these concerns or what changes could be made to improve their draft. The questions are openended and lack actionable advice, leaving the authors without a clear path to enhance their work. Therefore, the comment is 2, as it identifies areas for improvement but does not offer detailed feedback or constructive suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a gap in the theoretical analysis of why deep layer parameters are more suitable for distillation. However, it does not provide any explicit or implicit suggestions on how to address this gap or what specific aspects of the analysis should be expanded. The comment lacks concrete guidance on how the authors might improve their theoretical analysis, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for the authors to take to address the identified issue.", "grounding_specificity_rationale": "The comment identifies a gap in the theoretical analysis of why deep layer parameters are more suitable for distillation, but it does not specify which part of the paper this issue is discussed in. Without knowing the exact section or context, the authors cannot confidently determine where the issue lies, making the comment weakly grounded. However, the comment is specific in identifying the need for a more detailed theoretical analysis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. This feedback is clear and actionable, as it highlights a gap in the paper\"s theoretical foundation. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this gap, such as suggesting specific areas of research or methodologies to explore. Without such guidance, the authors may struggle to understand how to improve their analysis. Therefore, the comment is 4, as it points out a significant area for improvement but lacks detailed suggestions for action."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that a significant portion of the paper\"s details is located in the appendix, which makes the paper less selfcontained. While the comment identifies a potential issue with the paper\"s organization, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include more details in the main body of the paper to make it more selfcontained. The action is implicit and somewhat vague, as it does not specify what needs to be moved or how the paper should be reorganized. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that a lot of important paper details are in the appendix, making the paper less selfcontained. This provides the authors with a clear understanding of what needs to be addressed to improve the paper\"s selfcontainment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a significant portion of the paper\"s details is located in the appendix, making the paper less selfcontained. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s organization, noting that a substantial portion of the important details is located in the appendix, making the paper less selfcontained. This feedback is clear and actionable, as it highlights a critical aspect of the paper\"s structure that could hinder its accessibility and comprehensibility. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might reorganize the paper to improve its selfcontainment. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, allowing them to enhance the paper\"s structure and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the scalability of the authors\" method, suggesting that the largest dataset used (50K points) might not be considered \"large enough\" for the argument about gradient descentbased methods scaling to large datasets. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their method or dataset need to be improved. The action is implicit and vague, as it does not specify how the authors can demonstrate the scalability of their method with larger datasets or what additional experiments or analyses they should conduct. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"overall argument\" and the \"largest dataset\" used by the authors, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the concern regarding the dataset size, questioning whether 50K points is \"large enough\" for the argument about gradient descentbased methods scaling to large datasets. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the scalability of the authors\" method, specifically questioning whether the dataset size of 50K points is \"large enough\" for the argument about gradient descentbased methods scaling to large datasets. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the scalability of the authors\" method, specifically questioning whether the dataset size of 50K points is sufficient to support the argument about gradient descentbased methods scaling to large datasets. While the comment identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments or analyses could be conducted to strengthen their claims. The feedback is 3 as it highlights an important aspect of the paper that needs further consideration, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the practicality of the assumptions made in the paper, specifically regarding the \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any explicit or implicit suggestions on how the authors might address this concern or improve the practicality of their assumptions. The comment lacks concrete guidance or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practicality of the assumptions made in the paper, specifically regarding the \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it questions the practicality of the assumptions, but without clear references to the sections or parts of the paper, the authors may find it challenging to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the practicality of the assumptions made in the paper, specifically regarding the \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any evidence, reasoning, or references to support the claim that the assumptions are hard to know how practical they are. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the practicality of the assumptions made in the paper, specifically regarding the \"overloading the library with ASD subroutines\" (assumption 3.2). While it identifies a potential concern, it does not provide any suggestions or guidance on how the authors might address this issue or improve the practicality of their assumptions. The comment lacks actionable feedback, leaving the authors without a clear path forward for improvement. Therefore, the comment is 2, as it highlights a potential area for concern but does not offer constructive advice or suggestions for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the methodology used is less exciting because it is commonly used in data augmentation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the excitement of their methodology. The comment lacks explicit actions or concrete steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology used is less exciting because it is commonly used in data augmentation. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. Without this context, the authors cannot accurately identify where the issue lies, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on how the authors might address the issue or what changes could be made to make the methodology more exciting. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the methodology used is less exciting because it is commonly used in data augmentation. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology used in the paper is less exciting because it is commonly used in data augmentation. While this feedback provides a general critique of the methodology\"s novelty, it lacks specific details or actionable suggestions on how the authors might address this issue or enhance the excitement of their approach. Without concrete guidance or examples, the authors may struggle to understand how to improve their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue in the paper, noting that some statements are incorrect. It highlights a particular claim in section 4, where the authors state that multiimage IMP significantly improves the quality of LIPs in a crossdomain setting. However, the reviewer points out that the results presented in Figure 4 do not support this claim, as the multiIMP shows essentially the same performance as other methods. While the comment identifies an issue and provides a specific example, it does not offer explicit guidance on how the authors should address this discrepancy or what changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to reevaluate and potentially revise their claims or results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details a specific issue in the results presented in Figure 4, noting that the multiimage IMP does not show a significant improvement as claimed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some statements in the paper are incorrect, specifically mentioning a claim in section 4 regarding the performance of multiimage IMP. The reviewer argues that the results presented in Figure 4 do not support this claim, as the multiIMP shows essentially the same performance as other methods. This claim is 3 because it provides a specific example and a logical argument based on the results presented in the figure. However, it lacks detailed reasoning or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that some statements are incorrect and providing a detailed critique of a claim made in section 4. It points out that the results presented in Figure 4 do not support the claim that multiimage IMP significantly improves the quality of LIPs in a crossdomain setting. This feedback is clear and actionable, as it directs the authors to reevaluate and potentially revise their claims or results. However, the comment could be more helpful if it provided suggestions on how to address the discrepancy or what specific changes might be needed. Overall, the comment is 4, as it offers valuable insights and guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point mentions that the rank in the VLN Leaderboard is 22nd and that the proposed method\"s results are not better than existing methods, citing specific references. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their results. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the VLN Leaderboard rank and the specific references to existing methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed information about the results and suggests that the proposed method is not better than existing methods, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rank in the VLN Leaderboard is 22nd and that the results of the proposed method are not better than existing methods, citing specific references. The claim is 3 as it provides specific references to existing methods that outperform the proposed method, offering a basis for comparison. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment highlights a specific issue with the paper\"s results, noting that the rank in the VLN Leaderboard is 22nd and that the proposed method\"s results are not better than existing methods. It provides references to specific papers that outperform the proposed method, which could help the authors understand the context and identify areas for improvement. However, the comment lacks actionable guidance on how the authors might address this issue or what specific aspects of their method could be improved to surpass the existing methods. While it identifies a weakness, it does not offer detailed suggestions or strategies for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the discussion in section 2.2 is not convincing regarding how semantic similarity is modelled with the proposed approach. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the discussion or what specific aspects need clarification. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a lack of convincingness in the discussion regarding how semantic similarity is modelled with the proposed approach. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modelled with the proposed approach. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, namely the discussion in section 2.2, which is not convincing regarding how semantic similarity is modelled with the proposed approach. This feedback is clear and actionable, as it directs the authors to a particular section and highlights a potential weakness in the discussion. However, the comment could be more helpful if it provided suggestions or guidance on how to improve the discussion or address the lack of convincingness. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, allowing them to focus their attention on enhancing the clarity and persuasiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed SEPAI3R3O model, noting that it introduces over 10 parameters, which may be difficult to reliably estimate given limited realworld observations. It also points out that modeling these parameters as timevarying further complicates the estimation process. The comment suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. While the comment identifies a specific issue and suggests a potential improvement, it does not provide explicit guidance on how to conduct the sensitivity analysis or discuss the uncertainty in parameter values. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed SEPAI3R3O model, which introduces over 10 parameters. It highlights the difficulty in reliably estimating these parameters given limited realworld observations and notes that modeling them as timevarying further complicates the estimation process. The comment suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. However, the comment does not specify which part of the paper discusses the model or where the parameters are introduced. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of parameter estimation, it lacks grounding as it does not provide clear references to the relevant sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed SEPAI3R3O model introduces over 10 parameters, which may be difficult to reliably estimate given limited realworld observations. It also notes that modeling these parameters as timevarying further exacerbates the challenge of estimation from scarce data. The comment suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. However, the comment lacks specific examples or references to support the claim about the difficulty in estimating parameters with limited data or the impact of timevarying parameters. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed SEPAI3R3O model, specifically noting the introduction of over 10 parameters, which may be difficult to reliably estimate given limited realworld observations. It also highlights the challenge of modeling these parameters as timevarying, further complicating the estimation process. The comment suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is 3 as it points out a specific area where the authors could improve their model and provide guidance on how to address it. However, the comment could be more helpful if it offered more detailed suggestions or examples of how to conduct the sensitivity analysis. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of random samples for causal parameters across domains and suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how these parameters change across domains. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting specific analyses or modifications to their draft. The comment lacks concrete guidance on how the authors might address this concern or improve their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption of random samples for causal parameters across domains and suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how these parameters change across domains. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of the assumption, it lacks grounding as it does not provide clear references or sections for the authors to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the assumption of random samples for causal parameters across domains and suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how these parameters change across domains. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the assumption is not a consequence of not having latent confounders. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the assumption of random samples for causal parameters across domains and suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how these parameters change across domains. This feedback highlights a potential gap in the paper\"s assumptions and implications for the reliability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve their draft. It does not provide actionable steps or detailed insights into how the authors could enhance their work, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3, as it identifies an important issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the novelty of the paper, suggesting that it is unclear whether the structural optimization method is new or not. It also points out that the novelty is mentioned in the title, which weakens the narrative. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be clarified. The action is implicit and vague, as it does not specify how the authors should demonstrate the novelty of their method or how they can strengthen the narrative. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the novelty of the paper, specifically regarding whether the structural optimization method is new or not. It also notes that the novelty is mentioned in the title, which weakens the narrative. However, the comment does not specify which part of the paper discusses the novelty or the structural optimization method, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the issue of novelty, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the novelty of the paper, specifically regarding whether the structural optimization method is new or not. It suggests that the novelty is mentioned in the title, which weakens the narrative. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, specifically questioning whether the structural optimization method is new or not. It points out that the novelty is mentioned in the title, which weakens the narrative. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen the narrative. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption in the proof, specifically questioning whether the lambda value of 0.5 is correct given that standard mixup can generate mixed samples with this value. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete actions or detailed instructions on how to revise the proof or clarify the assumption. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment raises a concern about the assumption in the proof, specifically questioning whether the lambda value of 0.5 is correct given that standard mixup can generate mixed samples with this value. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique of the assumption, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption in the proof may not be correct because the lambda value of 0.5 is not standard in mixup, which can generate mixed samples with this value. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof, noting that the assumption regarding the lambda value being 0.5 may not be correct, as standard mixup can generate mixed samples with this value. This feedback is clear and actionable, as it points out a potential flaw in the proof that needs to be addressed. However, the comment could be more helpful if it provided guidance on how the authors might revise the proof or clarify the assumption. Despite this, the comment offers valuable insight into a critical aspect of the paper, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides two specific actions for the authors to take. First, it asks the authors to highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. This is an explicit action that the authors can directly address by identifying and labeling the relevant equations. Second, the comment suggests extracting inlined math into environments to improve readability, particularly on page 6. This is also an explicit action that the authors can take by restructuring the mathematical content. Both actions are concrete and provide clear guidance on how the authors should modify their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paragraph above Theorem 3.1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed: highlighting which set of equations have the same form as the Riccati equation and extracting inlined math into environments for better readability. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: first, it asks the authors to highlight which set of equations have the same form as the Riccati equation in a specific paragraph, and second, it suggests extracting inlined math into environments to improve readability. While the first part is a request for clarification, the second part is a suggestion that could be supported by examples or references to improve the paper. However, the comment lacks detailed reasoning or specific examples to fully substantiate the suggestion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two aspects of the paper. First, it requests that the authors highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. This is a clear and direct suggestion that would help improve the clarity and organization of the paper. Second, the comment suggests extracting inlined math into environments to enhance readability, particularly on page 6. This is another concrete and actionable piece of feedback that would make the paper more accessible and easier to follow. By addressing these specific points, the authors can significantly improve the clarity and readability of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that certain sections of the paper would benefit from clearer structure and transitions, and that subjective terms, such as \"significant,\" should be clarified with statistical evidence, such as pvalues. While the comment provides explicit guidance on what needs to be improved, it lacks specific examples or detailed instructions on how to implement these changes. The authors know that they need to clarify the structure and transitions in some sections and to use statistical evidence to support subjective terms, but the comment does not provide concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and that subjective terms, such as \"significant,\" should be clarified with statistical evidence, such as pvalues. However, the comment does not specify which sections of the paper need improvement or provide examples of how to implement these suggestions. This makes it difficult for the authors to identify the specific parts of the paper that require attention. Additionally, the comment is somewhat specific in its suggestion to use statistical evidence, but it lacks detailed guidance on which statistical methods or evidence to include. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that certain sections of the paper would benefit from clearer structure and transitions, and that subjective terms, such as \"significant,\" should be clarified with statistical evidence, such as pvalues. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the feedback. The lack of detailed examples or references to specific sections of the paper makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies areas for improvement in the clarity of the paper\"s structure and transitions, as well as the need for statistical evidence to support subjective terms like \"significant.\" While it provides specific suggestions for improvement, such as using statistical evidence to clarify subjective terms, it lacks detailed guidance on how to implement these suggestions. The comment is 3 as it offers actionable feedback, but it could be more comprehensive by providing examples or detailed steps for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that detailed information on graph construction is missing. It provides an example of what is missing, such as the definition of edges and the construction process for nonEuclidean datasets. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to do so. While the authors can infer that they need to add this information, the action is implicit and somewhat vague, as it lacks concrete steps on what to include or how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"graph construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the missing information regarding the definition of edges and the construction process for nonEuclidean datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that detailed information for graph construction is missing, specifically mentioning the lack of information on how to define edges and construct a graph for nonEuclidean datasets. However, the comment does not provide any evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detailed information, namely the construction of graphs, particularly for nonEuclidean datasets. It points out the absence of information on how edges are defined and how graphs are constructed, which is a crucial aspect for understanding the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as including additional details or examples. While it highlights a significant gap in the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a critical area for improvement but does not offer comprehensive guidance for the authors to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the visual and textual representations used in each method, specifically in Table 4. It also questions whether the endtoend performance gain is due to the proposed attention model. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the representations and the source of the performance gain. The action is implicit and somewhat vague, as it does not specify how to clarify the representations or how to demonstrate the source of the performance gain. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the visual and textual representations used in each method and asks whether the endtoend performance gain is due to the proposed attention model. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the visual and textual representations used in Table 4 and whether the endtoend performance gain is due to the proposed attention model. While it does not contain a subjective claim or opinion, it suggests that the authors should clarify these aspects to ensure the clarity and accuracy of their presentation. However, the comment lacks specific examples or references to support the need for clarification, making it 3. The authors would need to infer the importance of addressing these points to improve the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, questioning the visual and textual representations used in each method and whether the endtoend performance gain is due to the proposed attention model. This feedback is clear and actionable, as it directs the authors to clarify the representations and the source of the performance gain. By addressing these points, the authors can improve the clarity and accuracy of their presentation, making the comment 4. However, it could be more helpful if it provided specific suggestions on how to clarify these aspects, such as including examples or additional explanations. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights several issues with the convergence analysis, including the lack of clarity in the main part, the unclear presentation of notations, assumptions, and the justification for Eq. (15). While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what actions the authors should take to clarify the analysis. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the convergence analysis, which is a specific part of the paper. It mentions that the authors provide a simple proof in the appendix but do not present anything related to convergence in the main part. This allows the authors to identify the specific section that needs improvement. The comment also specifies the issues with the proof, such as the unclear presentation of notations, assumptions, and the lack of justification for Eq. (15). Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the convergence analysis is not clear and that the authors provide a simple proof in the appendix, but the main part does not relate to convergence. It also criticizes the presentation of notations, assumptions, and the justification for Eq. (15). However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The feedback is 3 as it identifies areas for improvement but does not provide sufficient evidence or guidance to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the convergence analysis, noting that the main part of the paper does not relate to it, despite a simple proof being provided in the appendix. It also points out specific problems with the presentation of notations, assumptions, and the justification for Eq. (15). This feedback is clear and actionable, as it directs the authors to address these issues to improve the clarity and completeness of their paper. By highlighting these specific areas for improvement, the comment provides valuable guidance for the authors to enhance the quality and rigor of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of drive and illustration of the studied problems, the insufficient description of uncertainty calibration, and the need for better organization and summarization of the studied issues. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks concrete guidance on how to improve the drive and illustration of the problems, or how to better organize and summarize the issues. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issues with the studied problems, specifically mentioning the lack of drive and illustration, the insufficient description of uncertainty calibration, and the need for better organization and summarization of the issues. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the problems that need to be addressed, such as the need for better organization and summarization of the studied issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the studied problems are not welldriven and illustrated, with specific examples such as the insufficient description of uncertainty calibration. However, the comment lacks detailed reasoning or examples to support these claims. It does not provide specific references or evidence to substantiate the assertion that the problems are unfriendly for new readers. As a result, the claim is not 5, making the comment 2.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically mentioning the lack of drive and illustration of the studied problems, the insufficient description of uncertainty calibration, and the need for better organization and summarization of the issues. While the comment provides some direction for improvement, it lacks detailed suggestions or specific guidance on how to address these issues. The feedback is 3 as it highlights areas for enhancement, but it could be more comprehensive with additional actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that there are no results exploring the incorporation of PACtuning with other finetuning techniques like pruning and data augmentation. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap or what specific experiments could be conducted to explore this area. The comment identifies a potential area for improvement but lacks actionable guidance on how to implement it. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a gap in the paper by noting the absence of results exploring the incorporation of PACtuning with other finetuning techniques such as pruning and data augmentation. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the missing exploration, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there are no results exploring the incorporation of PACtuning with other finetuning techniques such as pruning and data augmentation. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of results exploring the incorporation of PACtuning with other finetuning techniques such as pruning and data augmentation. This feedback highlights a potential area for improvement, as it suggests that the authors could expand their analysis to include these additional techniques. However, the comment lacks specific guidance on how the authors might approach this expansion or what experiments could be conducted to explore this area. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it identifies a meaningful gap but does not provide comprehensive guidance for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental analysis is insufficient and should be validated on more models. It also directs the authors to a fourth question below for further clarification. While the comment provides a clear action\u2014validating the analysis on more models\u2014it does not specify how to implement this action or what additional models should be considered. The authors are left with a general direction but lack concrete guidance on how to enhance their experimental analysis. Therefore, the comment is 3, as it provides an explicit action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the experimental analysis is insufficient and should be validated on more models, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or figure the comment refers to, making it weakly grounded. However, the comment is specific in its suggestion to validate the analysis on more models, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental analysis is insufficient and should be validated on more models. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the analysis is insufficient or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental analysis, suggesting that it should be validated on more models. This feedback is 3 as it points out an area for improvement, but it lacks depth and specificity. The comment does not provide detailed guidance on which additional models should be considered or how the validation should be conducted. While it encourages the authors to expand their analysis, the feedback is incomplete and could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the proposed method\"s improvement over the original initialization, noting that the first part is wellmotivated but lacks detailed explanation. It highlights that the proposed method is only demonstrated on a network with 100 layers on CIFAR, while ImageNet experiments are based on networks with varying normalization layers, showing only marginal improvement over baselines. The comment does not provide explicit guidance on how the authors should address these issues or improve their method. While it identifies areas for improvement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it points out specific areas where the authors need to enhance their work, but it does not provide detailed guidance on how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first part\" of the paper, allowing the authors to accurately identify the section being addressed. It also specifies the issue by highlighting the lack of detailed explanation for the motivation of the first part, the limited demonstration of the proposed method on a 100layer network on CIFAR, and the marginal improvement over baselines in ImageNet experiments with varying normalization layers. This level of specificity provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method only shows trainability on a network with 100 layers on CIFAR and that ImageNet experiments with varying normalization layers show only marginal improvement over baselines. The comment provides specific references to support the claim, such as [1] Zagoruyko et al. DiracNets: Training Very Deep Neural Networks Without SkipConnections, and [2] Qi et al. Deep Isometric Learning for Visual Recognition. ICML 2020. These references provide context and support for the claim, making it 4. However, the comment could be more robust by including more detailed reasoning or additional examples to fully substantiate the claim. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment critiques the proposed method\"s improvement over the original initialization, noting that the first part is wellmotivated but lacks detailed explanation. It highlights that the proposed method is only demonstrated on a network with 100 layers on CIFAR, while ImageNet experiments are based on networks with varying normalization layers, showing only marginal improvement over baselines. The comment provides specific references to support the claim, such as [1] Zagoruyko et al. DiracNets: Training Very Deep Neural Networks Without SkipConnections, and [2] Qi et al. Deep Isometric Learning for Visual Recognition. ICML 2020. This feedback is 4 as it identifies specific areas where the authors need to enhance their work, such as providing more detailed motivation, expanding the experimental validation, and demonstrating more significant improvements. However, it could be more helpful if it offered more detailed guidance on how to address these issues or suggested specific improvements to the method. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method with the method proposed in Yu et al. 2021. This is an explicit action that the authors can directly implement by adding a comparative discussion in their draft. The comment provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a discussion comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it should be in the discussion or results section. The comment is specific in its suggestion but lacks grounding as it does not explicitly mention the section or part of the paper where the comparison should be made. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding a discussion comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding a discussion comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by including a comparative analysis. By addressing this suggestion, the authors can strengthen the paper by demonstrating the relative robustness and immunizability of their method, which is a valuable addition to the discussion. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify their assessment of the proposed algorithm, suggesting that they may be misunderstanding something. It also provides feedback that the authors should consider including a plot of the time complexity of the decoding scheme as a function of m. This feedback is clear and actionable, as it directly instructs the authors to address the concern and provide additional information. The comment is fully actionable because it specifies exactly what the authors should do to improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3), this work proposes an algorithm for adaptive topk decoding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including a plot of the time complexity of the decoding scheme as a function of m, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the authors\" understanding of the proposed algorithm and suggests including a plot of the time complexity of the decoding scheme as a function of m. While the comment implies that the authors should consider this additional information, it does not provide specific reasoning or examples to support why this plot would be beneficial or how it would enhance the paper. The lack of detailed justification makes it difficult for the authors to fully understand the reasoning behind the suggestion, leading to a score of 2.", "helpfulness_rationale": "The review comment addresses a specific concern raised by the authors regarding the proposed algorithm for adaptive topk decoding. It acknowledges the authors\" initial assessment and suggests that it would be beneficial to include a plot of the time complexity of the decoding scheme as a function of m. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to create or interpret such a plot, or if it suggested other areas for improvement. Overall, the comment is 4 as it identifies a specific area for enhancement and encourages the authors to consider it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point questions the level of detail provided regarding the postprocessing effort mentioned in footnote 2. It does not explicitly instruct the authors to provide more information or clarify the postprocessing effort, nor does it offer any suggestions on how to address this issue. The comment is vague and lacks concrete guidance, leaving the authors uncertain about what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the lack of clarity regarding the postprocessing effort in that footnote. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the level of detail provided regarding the postprocessing effort mentioned in footnote 2. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it highlights a lack of clarity in the paper. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out a specific issue in the paper, namely the lack of clarity regarding the postprocessing effort mentioned in footnote 2. While it identifies a potential area for improvement, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is vague and lacks actionable advice, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "No", "helpfulness_label": "3", "actionability_rationale": "The review point asks whether the authors have run the codes for multiple seeds and reported the mean. This is a direct question that prompts the authors to check if they have addressed this aspect in their draft. While it does not explicitly instruct the authors to run the codes or report the mean, it is a clear and actionable request that the authors can easily follow. The action is explicit, and the authors know exactly what needs to be done to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the codes,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether the authors have run the codes for multiple seeds and reported the mean, providing a clear direction for the authors to follow. This feedback is actionable and provides a specific instruction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking whether the authors have run the codes for multiple seeds and reported the mean. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is a direct question asking whether the authors have run the codes for multiple seeds and reported the mean. This is a specific and actionable request that prompts the authors to check if they have addressed this aspect in their draft. By asking this question, the reviewer provides a clear direction for the authors to improve their draft, as they need to ensure that their experiments are robust and their results are reported accurately. However, the comment could be more helpful if it provided additional guidance or suggestions on how to report the mean or what specific aspects of the code need to be checked. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, specifically noting the absence of results for certain models in Table 3 compared to Table 2. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to explain the differences between the datasets and provide results for the missing models. This lack of explicit guidance makes the comment 3, as it points out specific areas for improvement but does not offer detailed guidance on how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, specifically noting the absence of results for certain models in Table 3 compared to Table 2. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the datasets and the inclusion of results for specific models, but without explicit references to sections or tables, the authors must infer the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, specifically noting the absence of results for certain models in Table 3 compared to Table 2. While the comment identifies areas that need clarification, it does not provide any specific reasoning, examples, or references to support the claims made. The authors are left to interpret the questions and potentially address them, but without additional context or justification, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, specifically noting the absence of results for certain models in Table 3 compared to Table 2. This feedback highlights areas where the authors could improve the clarity and completeness of their paper by providing more detailed explanations and results. However, the comment lacks specific guidance on how the authors might address these issues or what changes could be made to improve the presentation of their results. While it identifies important areas for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive and detailed to fully assist the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a more thorough description of the results shown in Fig 4. This is an explicit action that the authors can readily understand and implement. However, the comment lacks specific guidance on what aspects of the results need to be described in more detail. While the authors know they need to expand on the description, they are not given concrete examples or suggestions on what to include. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more thorough description of the results shown in Fig 4. However, it does not specify which part of the paper Fig 4 is located in, making it weakly grounded. The comment is specific in its request for a more detailed description of the results, but without a clear reference to the figure, the authors may find it challenging to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more thorough description of the results shown in Fig 4. However, it does not offer any specific guidance or reasoning on why this is necessary or how it would benefit the paper. Without additional context or justification, the claim lacks sufficient support, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a more thorough description of the results shown in Fig 4. This feedback is clear and actionable, as it directs the authors to enhance the detail and depth of their results section. However, the comment lacks specific guidance on what aspects of the results need to be expanded upon, such as particular trends, patterns, or comparisons. While it provides a clear direction for improvement, the lack of detailed suggestions may leave the authors with limited guidance on how to proceed. Therefore, the comment is 4, as it identifies an area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the most relevant literature is [11] and recommends comparing it with the work in more detail, either in the method part or in more depth. While the comment provides a clear direction for improvement, it does not specify which parts of the method section should be compared or how the comparison should be detailed. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests comparing the most relevant literature, [11], with the work in more detail, either in the method part or more extensively. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it should be in the method section. The comment is specific in its suggestion to compare with the work in more detail, but it lacks full grounding as it does not explicitly mention the method section. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the most relevant literature is [11] and recommends comparing it with the work in more detail, either in the method part or more extensively. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the recommendation or how to address it. Without additional context or examples, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the most relevant literature is [11] and recommends comparing it with the work in more detail, either in the method part or more extensively. This feedback is 3 as it identifies a specific area for improvement by highlighting the need for a more detailed comparison with relevant literature. However, the comment lacks specificity in terms of which parts of the method section should be compared or how the comparison should be detailed, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process, suggesting that there might be legitimate shared words between English and languagespecific vocabulary. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or what specific changes could be made to the process. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process, referencing a specific paper [1] Ten Years of BabelNet: A Survey. This provides a clear reference and grounds the comment in a specific part of the paper being discussed. The comment is specific in its critique, as it directly addresses the potential issue of removing words that might have legitimate shared meanings between English and languagespecific vocabulary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process, referencing a specific paper [1] Ten Years of BabelNet: A Survey. This provides a clear reference and grounds the comment in a specific part of the paper being discussed. The comment is specific in its critique, as it directly addresses the potential issue of removing words that might have legitimate shared meanings between English and languagespecific vocabulary. Therefore, this comment is 5, aligning with category 5.", "helpfulness_rationale": "The review comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process, referencing a specific paper [1] Ten Years of BabelNet: A Survey. This critique provides a clear and actionable suggestion for the authors to consider the potential impact of their cleaning process on the accuracy and validity of their results. By referencing a relevant study, the comment offers a basis for further investigation and potential refinement of the authors\" methodology. However, the comment could be more helpful if it provided additional guidance on how to address the issue or what specific changes might be necessary. Overall, the comment is 4 as it identifies a potential area for improvement and provides a reference for further exploration, but it could be more comprehensive with additional suggestions or guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the study should focus on more models to verify the findings, which is a specific and actionable suggestion. It implies that the authors should consider expanding their analysis to include additional models beyond LLaVA and InstructBLIP. This provides a clear direction for improvement, allowing the authors to enhance the robustness and generalizability of their conclusions. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the study should focus on more models to verify the findings, which is a general suggestion. It does not specify which part of the paper this suggestion relates to, making it weakly grounded. However, the comment is specific in its recommendation to include more models for verification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the study should focus on more models to verify the findings. While this is a logical suggestion, it lacks specific examples or references to support why studying more models would be beneficial. The comment does not provide detailed reasoning or evidence to substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the study should focus on more models to verify the findings, which is a relevant and actionable suggestion. By recommending the inclusion of additional models, the comment provides a clear direction for improving the robustness and generalizability of the study. However, the comment could be more helpful if it offered specific examples of other models that could be included or detailed reasons why expanding the model set would strengthen the conclusions. Despite this, the feedback is 4 as it guides the authors to enhance their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the results presented in Figure 7 and Table 3 regarding the performance of OpenCLIP. It notes that the norm shows significant reduction in Figure 7 but does not demonstrate significant improvement in Table 3 for object localization, which is the main benefit of using register. The comment suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for the wide adoption of the method. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify the discrepancy. The action is implicit and somewhat vague, as the authors are left to infer the need for further explanation and exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the performance of OpenCLIP, noting a discrepancy between the results shown in Figure 7 and Table 3. It highlights that while the norm shows significant reduction in Figure 7, there is no significant improvement in object localization in Table 3, which is the main benefit of using register. The comment suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for the wide adoption of the method. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the discrepancy and the need for further explanation, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the norm shows significant reduction for OpenCLIP in Figure 7, yet in Table 3, it does not show significant improvement for object localization, which is the main benefit of using register. The comment suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for wide adoption. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the issue or how to address it. The reasoning is logical but lacks detailed evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the results presented in Figure 7 and Table 3 regarding the performance of OpenCLIP. It notes that while the norm shows significant reduction in Figure 7, there is no significant improvement in object localization in Table 3, which is the main benefit of using register. The comment suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for the wide adoption of the method. However, the comment lacks specific guidance on how the authors should address this issue or what additional analysis might be needed to clarify the results. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a critical issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of 3D renders in conjunction with GANs, specifically asking how the Point cloud is used in the process described in Section 3.3. While the comment identifies a lack of clarity regarding the integration of 3D rendering and the GAN objective, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the use of the Point cloud in the rendering process and provide more details on the combination of 3D rendering and the GAN objective. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity on how the Point cloud is used in conjunction with the 3D rendering and the GAN objective. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of 3D renders in conjunction with GANs, specifically asking how the Point cloud is used in the process described in Section 3.3. While the comment identifies a lack of clarity regarding the integration of 3D rendering and the GAN objective, it does not provide any specific examples, references, or detailed reasoning to support the claim that the authors need to clarify this aspect. The comment is 3 as it points out a potential issue but lacks sufficient evidence to fully substantiate the need for clarification. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the use of 3D renders in conjunction with GANs. It points out that while the paper explains how the latent code z is used to modulate the weights of the rendering network, it does not clarify how the Point cloud is used in this stage. This lack of clarity makes it difficult for the authors to understand the integration of 3D rendering and the GAN objective. The comment is 4 as it provides a clear direction for the authors to improve the clarity of their paper by adding more details about the use of the Point cloud in the rendering process. However, it could be more helpful if it suggested specific ways to clarify this aspect, such as providing examples or additional explanations."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It notes that while parameter insensitivity is claimed, the supporting evidence is based on simple architectures and datasets, which is not convincing. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the model or experiments need to be improved. The action is implicit and vague, as it does not specify how the authors can strengthen their claims or provide more robust evidence. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of increased hyperparameter complexity in the QIF model compared to the traditional LIF model, noting that the supporting evidence relies on simple architectures and datasets, which is not convincing. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the increased complexity and the lack of convincing evidence, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the supporting evidence for the claim of parameter insensitivity relies on simple architectures and datasets, which is not convincing. However, the comment does not provide specific examples of these simple architectures or datasets, nor does it offer detailed reasoning or references to substantiate the claim. This lack of detailed support makes the claim 3, as the authors may need to infer the basis of the claim or seek additional evidence to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the QIF model, noting that it introduces additional hyperparameters compared to the traditional LIF model. It highlights a concern that the claim of parameter insensitivity is not wellsupported due to the reliance on simple architectures and datasets. This feedback is 3 as it points out a potential weakness in the paper\"s claims and suggests that the authors need to provide more robust evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors could strengthen their evidence or address the issue of parameter insensitivity more effectively. Overall, the comment provides a clear direction for improvement but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the necessity of a sophisticated framework given the marginal improvements over baselines and suggests exploring other PLMs like RoBERTa and T5 for potential further improvements. It also asks for a discussion on the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs or realworld scenarios. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them on how to implement these suggestions or explore the mentioned PLMs. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the proposed method and experiments in the context of LLMs, such as computational costs or realworld scenarios. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what aspects to discuss, such as computational costs and realworld scenarios, which helps the authors understand the need for further analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of a sophisticated framework given the marginal improvements over baselines and suggests exploring other PLMs like RoBERTa and T5 for potential further improvements. It also asks for a discussion on the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs or realworld scenarios. While the comment provides a rationale for questioning the approach, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors would need to infer the reasoning and provide their own justifications, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of a sophisticated framework given the marginal improvements over baselines. It suggests exploring other PLMs, such as RoBERTa and T5, to potentially achieve further improvements. Additionally, the comment prompts a discussion on the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs and realworld scenarios. This feedback is valuable as it challenges the authors to consider alternative approaches and provides direction for further exploration. However, the comment could be more helpful if it offered specific guidance on how to implement these suggestions or discuss the aspects in detail. Overall, the comment is 4, as it provides actionable insights that encourage the authors to refine their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the clarity of the explanation regarding the use of soft assignment versus hard assignment. It notes that the explanation is discussed in the methodology section but lacks clarity on whether the authors have reported an experiment to support their conjecture. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional reporting. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding the use of soft assignment versus hard assignment and the absence of an experiment to support the conjecture. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the explanation regarding the use of soft assignment versus hard assignment and whether the authors have reported an experiment to support their conjecture. However, it does not provide any specific evidence, reasoning, or references to substantiate the claim that the explanation is unclear or that the authors have not reported an experiment. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the explanation regarding the use of soft assignment versus hard assignment. It points out that while the explanation is discussed in the methodology section, it lacks clarity on whether the authors have reported an experiment to support their conjecture. This feedback is 3 as it highlights a specific area where the authors could improve the clarity and completeness of their explanation. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue, such as suggesting specific experiments or analyses that could be included. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the applicability of the methods presented in the paper, suggesting that they are primarily relevant in a crosssilo setting and may not be as effective in general federated learning scenarios with a larger number of clients. However, the comment does not provide explicit guidance on how the authors might address this limitation or improve the methods to be more broadly applicable. The action is implicit and vague, as it does not specify what changes or improvements the authors should make to enhance the paper\u2019s applicability. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the applicability of the methods presented in the paper, specifically mentioning that they are primarily relevant in a crosssilo setting and may not be as effective in general federated learning scenarios with a larger number of clients. However, the comment does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to understand where the critique applies and how to address it. While the comment is specific in its critique of the methods\" applicability, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the applicability of the methods presented in the paper, suggesting that they are primarily relevant in a crosssilo setting and may not be as effective in general federated learning scenarios with a larger number of clients. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment critiques the applicability of the methods presented in the paper, noting that they are primarily relevant in a crosssilo setting and may not be as effective in general federated learning scenarios with a larger number of clients. This feedback highlights a limitation in the paper\"s scope and applicability, which could be valuable for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the methods\" generalizability. Without actionable advice or detailed examples, the comment provides a general observation but does not offer substantial assistance for the authors to enhance their work. Therefore, the comment is 3, as it identifies an important area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about what constitutes distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising than previously thought, given the behavior of smooth regression models. However, it does not provide explicit guidance or actionable steps for the authors to address this question or incorporate it into their draft. The comment lacks specificity and does not offer any concrete suggestions on how to clarify or improve the paper. As a result, the authors are left without a clear understanding of what action to take to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about distributional generalization in the context of regression, suggesting that the phenomenon might be less surprising than previously thought. However, it does not specify which part of the paper this question relates to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper the comment addresses, making it weakly grounded. Additionally, the comment does not provide specific guidance on what needs to be addressed or how to clarify the issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about distributional generalization in the context of regression, suggesting that the phenomenon might be less surprising than previously thought. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about distributional generalization in the context of regression, suggesting that the phenomenon might be less surprising than previously thought. It provides a specific example, noting that a reasonably smooth regression model interpolating the training data would exhibit distributional generalization. However, the comment does not offer any actionable feedback or suggestions on how the authors might address this point or incorporate it into their draft. Without specific guidance or examples, the authors are left without a clear understanding of how to respond to the comment or improve their work. Therefore, the comment is 2, as it identifies a potential area for clarification but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the references and baselines are out of date and recommends including more recent research. It also points out that searching for items like \"Item Frequencies of Data Streams\" can yield many results. However, the comment does not provide explicit guidance on which specific references or baselines should be included, nor does it offer concrete steps on how to ensure the search yields meaningful results. The action is implicit and somewhat vague, as the authors need to infer the need for updating their references and baselines and may struggle to determine the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the references and baselines are out of date and recommends including more recent research. It also mentions that searching for items like \"Item Frequencies of Data Streams\" can yield many results. However, the comment does not specify which parts of the paper are affected by this issue, making it weakly grounded. While it provides some specificity by mentioning the need for more recent research and the potential for many results, it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and somewhat specific, aligning with label 3.", "verifiability_rationale": "The review point claims that the references and baselines are out of date and suggests including more recent research. It also mentions that searching for items like \"Item Frequencies of Data Streams\" can yield many results. However, the comment lacks specific examples or references to support the claim about the outdated nature of the references and baselines. While it provides a general suggestion, it does not offer detailed reasoning or evidence to substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or evidence to fully support it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the references and baselines are out of date and suggests incorporating more recent research. It also highlights a potential problem with the search process, noting that searching for items like \"Item Frequencies of Data Streams\" can yield many results, which may not be helpful for the authors. While the comment points out these areas for improvement, it lacks specific guidance on how to update the references, what new research to include, or how to refine the search process to yield more relevant results. The feedback is 3 as it directs the authors to address these issues, but it could be more actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the experimental analysis, noting that while the introduction discusses the computational challenges of scaling quadratic programs to highdimensional action spaces, the experimental analysis primarily focuses on lowerdimensional spaces. The comment suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of the analysis need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer the need for more detailed analysis in highdimensional spaces. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the gap between the introduction\"s discussion of computational challenges in highdimensional action spaces and the experimental analysis in Section 5, which primarily focuses on lowerdimensional spaces. The comment suggests that the performance of ARAM in highdimensional action spaces would benefit from more indepth analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental analysis in Section 5 primarily explores action constraints in relatively lowerdimensional spaces, while the introduction discusses the computational challenges of scaling quadratic programs to highdimensional action spaces. The comment suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. However, the comment lacks specific examples or references to support the claim about the limitations of the experimental analysis in highdimensional spaces. Without detailed evidence or examples, the claim remains 3, as the authors may need to infer the need for more comprehensive analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the experimental analysis by pointing out that while the introduction discusses the computational challenges of scaling quadratic programs to highdimensional action spaces, the experimental analysis primarily focuses on lowerdimensional spaces. The comment suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This feedback is 3 as it highlights a specific area where the authors could enhance their experimental evaluation. However, it could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects of the analysis should be explored. Overall, the comment provides a clear direction for improvement, but it could be more comprehensive and actionable to fully benefit the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the extra computation required to achieve good experimental results, suggesting that the performance might be due to increased parameters or computation. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or address the concern. The comment is vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the lack of information on the computational cost required to achieve good results and suggests that the performance might be due to extra parameters or computation. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the computational cost associated with achieving good experimental results, suggesting that the performance might be due to increased parameters or computation. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand or address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of information regarding the computational cost required to achieve the good experimental results. It questions whether the performance gains are due to increased parameters or computation, suggesting that if the model has the same floats as the original transformers, the performance might be similar. This feedback is 3 as it identifies a potential area for further investigation and provides a direction for the authors to explore. However, it could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as providing additional experiments or analyses. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the evaluation and results of the paper, noting that they are not convincing and that the results do not show consistent trends. However, it does not provide any specific guidance or suggestions on how the authors might address these issues or improve their results. The comment lacks explicit actions or concrete details on how the authors can enhance the evaluation or results. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses concerns about the evaluation and results of the paper, noting that they are not convincing and that the results do not show consistent trends. However, it does not specify which part of the paper this feedback pertains to, such as the methodology, results section, or discussion. Without explicit references to specific sections or parts of the paper, the authors cannot confidently determine where the feedback applies. Additionally, the comment lacks specificity in detailing what aspects of the evaluation or results need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concerns about the evaluation and results of the paper, noting that they are not convincing and that the results do not show consistent trends. However, it does not provide any specific evidence, examples, or references to support these claims. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the evaluation and results of the paper, noting that they are not convincing and that the results do not show consistent trends. While the comment highlights a potential issue with the evaluation, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their results. The feedback is 3 as it points out a critical area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper includes subjective questions and proposes that it would be beneficial to highlight the percentage of the error rate made up of these subjective questions. It recommends analyzing the agreement among humans to assess the significance of this percentage. While the comment provides a clear action\u2014highlighting the percentage of subjective questions and suggesting an analysis of human agreement\u2014it does not specify how to calculate this percentage or what data to use for the analysis. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"several questions require subjective answers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should highlight the percentage of the error rate made up of subjective questions and recommend analyzing the agreement among humans to assess the significance of this percentage. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper includes subjective questions and proposes that it would be beneficial to highlight the percentage of the error rate made up of these subjective questions. It recommends analyzing the agreement among humans to assess the significance of this percentage. However, the comment lacks specific examples or references to support the claim that subjective questions are a significant issue. Without detailed evidence or examples, the claim remains 3, as it provides a suggestion but lacks the necessary depth to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the presence of subjective questions, and suggests that it would be beneficial to highlight the percentage of the error rate made up of these questions. It recommends analyzing the agreement among humans to assess the significance of this percentage. This feedback is 3 as it points out a specific area for improvement and provides a clear direction for the authors to consider. However, the comment could be more helpful if it offered additional guidance on how to conduct the analysis or what specific metrics to use. Overall, the comment provides a useful starting point for the authors to address the issue, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the paper\"s evaluation would be stronger if it included additional NLP tasks beyond intent recognition, such as sentiment classification and namedentity recognition. This provides a clear and direct action for the authors to take, as they can easily understand which tasks to consider and how to incorporate them into their evaluation. The comment is specific and concrete, offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for additional NLP tasks, such as sentiment classification and namedentity recognition, to enhance the evaluation of the paper. This allows the authors to accurately identify the part of the paper that needs improvement. The comment is also specific, as it clearly specifies which tasks should be considered to improve the evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s evaluation is weak due to the use of only a single dataset and limited NLP tasks, specifically mentioning intent recognition. It suggests that additional tasks like sentiment classification and namedentity recognition would improve the evaluation. However, the comment lacks specific examples or references to support the claim that these additional tasks would indeed enhance the evaluation. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper\"s evaluation, noting that it is limited to a single dataset and only considers intent recognition. The comment suggests that expanding the evaluation to include additional NLP tasks, such as sentiment classification and namedentity recognition, would enhance the paper\"s comprehensiveness and impact. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By addressing this suggestion, the authors can strengthen the evaluation and demonstrate a broader understanding of the tasks relevant to their work. Therefore, the comment is 5, as it offers a clear and constructive path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the label for the class semantic feature in Figure 3 should be \"s\" instead of \"c\". This is a specific and explicit action that the authors can take to correct the labeling in the figure. The comment provides clear guidance on what needs to be changed, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the label for the class semantic feature should be \"s\" instead of \"c,\" providing a clear direction for correction. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point suggests that the label for the class semantic feature in Figure 3 should be \"s\" instead of \"c\". This is a factual observation about a specific element in the paper, and it does not contain any subjective opinions or claims that require verification. The comment is a direct observation and does not provide any reasoning or evidence to support it. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment points out a specific issue with Figure 3, noting that the label for the class semantic feature should be \"s\" instead of \"c\". This is a clear and actionable suggestion that directly addresses a potential error in the figure\"s labeling. By identifying this discrepancy, the comment provides the authors with a concrete step to take to improve the accuracy and clarity of their paper. The feedback is specific and actionable, making it 5 for the authors to address the issue. Therefore, this comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the distinction between deidentification and face swapping, suggesting that the proposed method might be similar to deepfake technology. It recommends comparing the method with stateoftheart face swapping algorithms. However, the comment does not provide explicit guidance on how the authors should implement this comparison or what specific aspects of the comparison are crucial. The action is implicit and somewhat vague, as the authors need to infer the need for comparison and deduce the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the distinction between deidentification and face swapping, suggesting that the proposed method might be similar to deepfake technology. It highlights a key difference, noting that the target face in deepfake technology is a real individual, while in this work, it is derived from a 3DMM. However, the comment does not specify which part of the paper this distinction is discussed or how it relates to the overall content. The authors cannot confidently determine which section or figure this comment pertains to, making it weakly grounded. The comment is specific in detailing the distinction and suggesting a comparison with stateoftheart face swapping algorithms, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the distinction between deidentification and face swapping is not clear, suggesting that the proposed method might be similar to deepfake technology. It recommends comparing the method with stateoftheart face swapping algorithms. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of evidence or references weakens the verifiability of the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the distinction between deidentification and face swapping, suggesting that the proposed method might be similar to deepfake technology. It recommends comparing the method with stateoftheart face swapping algorithms, which could provide valuable context and help the authors better position their work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the comparison are crucial. While it offers a direction for improvement, the feedback could be more helpful if it included detailed suggestions or examples. Therefore, the comment is 3, as it provides a clear area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the experimental results on word embeddings, noting that they are not as compelling as the Gaussian embeddings baseline. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the results or what changes could be made to make the word embeddings more compelling. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results on word embeddings, noting that they are not as compelling as the Gaussian embeddings baseline. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, the chief baseline from the literature. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why the results are considered unconvincing. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results on word embeddings, noting that they are not as compelling as the Gaussian embeddings baseline. This feedback is valuable as it highlights a potential weakness in the experimental setup or results presentation. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the results. Without specific recommendations or examples, the authors may find it challenging to incorporate this feedback into their work. Therefore, the comment is 3, as it points out a problem but does not provide comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern that the proposed method does not seem to differ significantly from previous studies, except for the change in task and reward function. It suggests that the contribution might be small if this is the only difference. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need to be clarified or improved. The action is implicit and vague, as it does not specify how the authors should demonstrate the novelty or effectiveness of their method beyond the mentioned changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous studies (Shi et al., 2018; Ghosh et al., 2021) and the specific changes made in the proposed method, such as the task being changed to text summarization and the reward function being altered accordingly. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the concern that the contribution might be small due to the limited differences from previous studies. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not seem to differ significantly from previous studies, except for the change in task and reward function. It suggests that the contribution might be small if this is the only difference. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or evidence to substantiate the assertion that the contribution is small. As a result, the claim is not 5, making the comment 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the proposed method does not significantly differ from previous studies, except for the change in task and reward function. It questions the contribution\"s size, implying that the novelty might be limited if this is the only difference. While the comment highlights a concern, it does not provide specific guidance or suggestions on how the authors could address this issue or enhance the contribution of their work. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the novelty of the paper, suggesting that it combines multiple pieces to create a new ITrelated dataset. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to enhance the novelty of their work. The comment lacks concrete suggestions or detailed instructions on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the novelty of the paper, suggesting that it combines multiple pieces to create a new ITrelated dataset. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of novelty, it is 1 because it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concern about the novelty of the paper, suggesting that it combines multiple pieces to create a new ITrelated dataset. However, the comment lacks specific details or examples to substantiate this claim. It does not provide any references or evidence to support the assertion that the paper\"s novelty is limited or that it combines multiple pieces to create a new dataset. Without such evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the novelty of the paper, suggesting that it combines multiple pieces to create a new ITrelated dataset. While this feedback highlights a potential issue with the paper\"s contribution, it lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The comment is 3 as it identifies a potential area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper lacks an ablation study related to query embedding. It implies that the authors should conduct such a study to provide insights into the significance and impact of this component. However, the comment does not specify which part of the paper should be revised or how the ablation study should be conducted. The action is implicit and vague, as it does not provide concrete guidance on what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study related to query embedding, which is a specific aspect of the research. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for an ablation study, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that requires attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study related to query embedding, which is a specific aspect of the research. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of where such a study would be beneficial or references to similar studies in the literature. Without this additional context, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks an ablation study related to query embedding. This is a valuable piece of feedback as it highlights a potential gap in the research that could provide insights into the significance and impact of the query embedding component. However, the comment does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be analyzed. While it points out a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to enhance their work but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the contribution of the paper is marginal compared to previous works, referencing specific papers [1, 2, 3]. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the contribution or what specific aspects need to be addressed to make it more significant. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the marginal contribution of the paper compared to previous works, referencing specific papers [1, 2, 3]. However, it does not specify which part of the paper this opinion is based on, making it difficult for the authors to pinpoint the exact area that needs attention. The comment lacks specificity in detailing what aspects of the contribution are marginal or how they could be improved. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper is marginal compared to previous works, referencing specific papers [1, 2, 3]. However, it does not provide any specific evidence, reasoning, or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal compared to previous works, referencing specific papers [1, 2, 3]. However, it lacks specific details or suggestions on how the authors might address this concern or improve the contribution. The comment does not provide actionable feedback or guidance on what aspects of the work could be enhanced to make it more significant. As a result, the feedback is not particularly helpful in helping the authors improve their draft, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question to the authors regarding the performance loss of w2gm against w2g in the analysis of SWCS. It does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve their analysis. As a result, the authors are left without any actionable feedback, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, such as a particular section, table, or figure. It raises a question about the analysis of SWCS, but without any context, the authors cannot determine which part of the paper is being discussed. Therefore, the comment lacks grounding. It is also not specific because it does not provide any guidance or suggestions on how to address the question or improve the analysis. As a result, the comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point is a question posed to the authors, asking them to explain the performance loss of w2gm against w2g in the analysis of SWCS. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, aligning with the label \"No.\" Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a question posed to the authors, asking them to explain the performance loss of w2gm against w2g in the analysis of SWCS. While it identifies a potential issue in the analysis, it does not provide any suggestions or guidance on how the authors might address this concern or improve their analysis. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer substantial assistance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the paper should directly evaluate for overoptimization rather than focusing on caliberation and human evaluation. It provides a specific example of how this could be addressed by discussing the tradeoffs of not using early stopping, referencing AlignProp as a relevant work. The comment is clear and provides concrete guidance on how the authors should improve their evaluation approach. It instructs the authors to consider the benefits of not doing early stopping and to discuss this in the context of their proposed solutions. This level of detail makes the comment 5, as it provides a clear path for the authors to address the issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper that discusses overoptimization, allowing the authors to accurately identify the section being addressed. It is also specific because it provides detailed suggestions for improvement, such as evaluating for caliberation and human evaluation instead of overoptimization, and suggests discussing the tradeoffs of not using early stopping, referencing AlignProp. This level of detail provides clear guidance on how the authors should address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper evaluates for caliberation and human evaluation instead of overoptimization, and it suggests that the current works address the overoptimization issue with early stopping, such as AlignProp. The comment provides a specific example of a relevant work, AlignProp, and suggests that the authors should discuss the tradeoffs of not using early stopping. This claim is supported by the reference to AlignProp and the suggestion to discuss the benefits of not doing early stopping, making it 4. However, it could be more robust with additional examples or a more detailed explanation of the tradeoffs. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper\"s approach to evaluating overoptimization, suggesting that it focuses on caliberation and human evaluation instead. It highlights a gap in the paper by pointing out that current works address the overoptimization issue with early stopping, such as AlignProp, and suggests that the authors should consider not using early stopping to better evaluate their proposed solutions. The comment offers specific guidance on how the authors could improve their evaluation approach, including discussing the tradeoffs of not using early stopping. This feedback is clear, actionable, and constructive, providing the authors with a clear direction for enhancing their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a significant concern about the equivalence of the proposed TW model and the TR model, suggesting that the TW model might be redundant if it can be represented by a TR model. The comment implies that the authors should provide a detailed analysis and discussion to justify the inclusion of the TW model over the TR model. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the equivalence of the proposed TW model and the TR model, suggesting that the TW model might be redundant if it can be represented by a TR model. It implies that the authors should provide a detailed analysis and discussion to justify the inclusion of the TW model over the TR model. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the analysis should be conducted. While the comment is specific in its critique of the model\"s equivalence, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the equivalence of the proposed TW model and the TR model, suggesting that the TW model might be redundant if it can be represented by a TR model. The reviewer expresses a desire to see this analysis in the paper and a discussion justifying the TW model over the TR model. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the TW model is equivalent to the TR model. Without further elaboration or evidence, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the equivalence of the proposed TW model and the TR model, suggesting that the TW model might be redundant if it can be represented by a TR model. The reviewer expresses a desire to see this analysis and a discussion justifying the inclusion of the TW model over the TR model. However, the comment lacks specific details or suggestions on how the authors might address this issue, such as providing a detailed analysis or a comparison of the two models. Without actionable guidance or examples, the comment is 3, as it identifies a critical area for improvement but does not provide the authors with a clear path forward. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should discuss the transferability of the toolset and experiment with creating a general tool set for all tasks. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the experiment or what aspects of transferability to focus on. The action is explicit but somewhat vague, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests discussing the transferability of the toolset and recommends experimenting with creating a general tool set for all tasks. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections for the authors to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the transferability of the toolset and experiment with creating a general tool set for all tasks. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would impact the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the transferability of the toolset across different tasks, specifically noting that the toolsets for the VQA task and the reasoning task are not the same. It suggests that the authors might experiment with creating a general tool set for all tasks to see what happens. This feedback is 3 as it points out a potential area for improvement and provides a direction for the authors to explore. However, the comment lacks depth and specificity, as it does not elaborate on the implications of the toolset transferability or provide detailed guidance on how the authors might conduct the experiment. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an alternative approach to evaluating the model\"s performance by using multiple random feature orders. It implies that this method could help determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. However, the comment does not provide explicit guidance on how to implement this approach or what specific aspects of the model\"s performance should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an alternative approach to evaluating the model\"s performance by using multiple random feature orders. It implies that this method could help determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be simply achieved by exposing the model to diverse orders. However, the comment does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs attention. While the comment provides a general idea of the approach, it lacks specificity in terms of which part of the paper it addresses. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests an alternative approach to evaluating the model\"s performance by using multiple random feature orders. It implies that this method could help determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be simply achieved by exposing the model to diverse orders. However, the comment lacks specific examples or detailed reasoning to support the claim that this approach would effectively address the issue of feature order variability. Without concrete evidence or examples, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment suggests an alternative approach to evaluating the model\"s performance by using multiple random feature orders. This approach aims to assess the impact of feature order variability without the need for a complex controller, potentially duplicating the information. The comment implies that this method could help determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. However, the comment does not provide specific guidance on how to implement this approach or what aspects of the model\"s performance should be evaluated. While it offers a potential improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the related work section is severely lacking and specifically mentions the omission of lexically constrained decoding methods. It provides a clear action for the authors to take, which is to address this issue by including these methods in the related work section and as baselines for comparison. The comment is explicit and concrete, providing specific guidance on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the omission of lexically constrained decoding methods, both in the related work section and as baselines for comparison. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section is severely lacking and specifically mentions the omission of lexically constrained decoding methods. However, it does not provide any evidence or reasoning to support this claim, such as examples of missing references or detailed explanations of why these methods are important. Without specific examples or references, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the criticism. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the related work section, specifically pointing out the omission of lexically constrained decoding methods. This feedback is clear and actionable, as it directs the authors to address this gap by including these methods in both the related work section and as baselines for comparison. By providing specific guidance on what needs to be added, the comment empowers the authors to improve the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested specific references or examples of lexically constrained decoding methods. Overall, the feedback is 4, as it provides a clear direction for improvement but could be more detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the comprehensiveness of the comparison due to the absence of important baseline models and datasets. It provides specific examples of missing models, such as SimVLM and OFA, which suggests that the authors should include these in their comparison. However, the comment does not explicitly instruct the authors to add these models or datasets, nor does it provide detailed guidance on how to incorporate them into the comparison. While the action is implied, it is vague and lacks concrete steps, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the comparison by pointing out the absence of important baseline models and datasets. It provides specific examples of missing models, such as SimVLM and OFA, which helps the authors understand the issue. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in detailing what is missing, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison is not comprehensive because important baseline models and datasets are missing. It provides specific examples of missing models, such as SimVLM and OFA, which supports the claim. However, the comment lacks detailed reasoning or references to explain why these specific models are important or how their absence impacts the comprehensiveness of the comparison. While the examples are provided, the reasoning is somewhat vague, making the claim 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the comprehensiveness of the comparison due to the absence of important baseline models and datasets. It provides specific examples of missing models, such as SimVLM and OFA, which are relevant to the field. This feedback is clear and actionable, as it directs the authors to include these models in their comparison to enhance the comprehensiveness of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to incorporate these models or datasets into the comparison, or suggested specific ways to address the comprehensiveness issue. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the manuscript for being framed as a dataset paper when it primarily presents derivative data, specifically 3D pose estimates from existing datasets. While the comment identifies a potential issue with the framing of the paper, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to clarify the nature of the data and its contribution to the field. The action is implicit and somewhat vague, as it does not specify what changes should be made to the manuscript to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the manuscript for being framed as a dataset paper when it primarily presents derivative data, specifically 3D pose estimates from existing datasets. However, it does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique of the framing, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the manuscript for being framed as a dataset paper when it primarily presents derivative data, specifically 3D pose estimates from existing datasets. This claim is 3 as it highlights a potential issue with the framing of the paper, but it lacks specific examples or references to support the assertion that the data is derivative. The authors are left to infer the nature of the data and its contribution, which may require additional context or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the manuscript for being framed as a dataset paper when it primarily presents derivative data, specifically 3D pose estimates from existing datasets. This critique is 3 as it identifies a potential issue with the framing of the paper, which could be valuable for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might improve the framing or presentation of their data. Without actionable advice or examples, the feedback is limited in its ability to help the authors enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure, but it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks guidance on what specific aspects of the paper need to be revised or clarified. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure. However, it does not specify which part of the paper this criticism is directed towards, such as a specific section or table. This lack of grounding makes it difficult for the authors to understand where the comment applies and what needs to be addressed. Additionally, the comment is specific in its critique of the training procedure but does not provide detailed guidance on how to improve it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors criticize Lsoftmax and Asoftmax for requiring an annealinglike training procedure, but it does not provide any evidence or reasoning to support this claim. Without specific details or references, the authors are left without a basis to understand or address the criticism. This lack of verifiability makes the comment difficult to act upon, as it does not provide a clear understanding of the issue being raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure, noting that this method has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any suggestions or insights on how the authors might address this issue or improve their draft. It lacks actionable feedback, leaving the authors without guidance on how to respond or enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the depth of analysis, specifically asking what can be learned from the visualizations regarding the detection of a chair. It suggests exploring the consistency of the handle transformation across various chairs and whether it is the most prominent feature. However, the comment does not provide explicit guidance on how to address these questions or what specific actions the authors should take to enhance their analysis. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the quantitative and qualitative analysis, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the analysis of the results themselves and the exploration of the handle transformation across various chairs. This provides clear guidance on how the authors can improve their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the depth of analysis, specifically asking what can be learned from the visualizations regarding the detection of a chair. It suggests exploring the consistency of the handle transformation across various chairs and whether it is the most prominent feature. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The feedback lacks sufficient evidence or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, focusing on the depth of analysis and the exploration of visualizations. It questions the consistency of the handle transformation across various chairs and whether it is the most prominent feature, prompting the authors to consider additional analyses. However, the comment lacks specific guidance on how to conduct these analyses or what additional insights might be gained. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions or examples of how to enhance the analysis. Therefore, the comment is 3, as it offers a meaningful critique but could be more comprehensive in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises a specific concern about a potential error in the description of a competitive ratio in the beginning of Section 2.2. It questions whether the ratio should be \"at most $b$\" instead of \"at least $b$\" and provides a detailed explanation of why this correction is necessary. The comment explicitly suggests a change to the text, making it a clear and actionable action for the authors to take. The feedback is specific and provides a concrete example of what needs to be addressed, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the beginning of Section 2.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed explanation of why the competitive ratio should be \"at most $b$\" instead of \"at least $b$\" and offers a logical argument based on the worstcase scenario and other cases. This level of detail helps the authors understand the specific issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a specific question about the description of a competitive ratio in the beginning of Section 2.2, suggesting that it should be \"at most $b$\" instead of \"at least $b$\". The comment provides a detailed explanation of why this correction is necessary, including a logical argument based on the worstcase scenario and other cases. This level of detail and reasoning makes the claim 5, as it provides a clear and logical basis for the suggestion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue in the description of a competitive ratio in the beginning of Section 2.2, suggesting that it should be \"at most $b$\" instead of \"at least $b$\". The comment provides a detailed explanation of why this correction is necessary, including a logical argument based on the worstcase scenario and other cases. This feedback is clear, actionable, and constructive, as it guides the authors on how to improve the accuracy and clarity of their description. The comment is 4 because it provides a specific and detailed critique that can help the authors refine their work, but it could be even more helpful if it suggested alternative ways to phrase the correction or provided additional context. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the third face image in Figure 2 lacks proper expression, but it does not provide any guidance or suggestions on how the authors should address this issue. The comment is vague and does not offer any concrete steps or examples for improvement. As a result, the authors are left without a clear understanding of what needs to be done to resolve this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a missing element, the \"proper expression\" for the third face image in the figure. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the third face image in Figure 2 lacks proper expression. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of why this is an issue or how it might be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the third face image in Figure 2, noting that it lacks proper expression. However, it does not provide any suggestions or guidance on how the authors might address this problem. Without additional context or recommendations, the authors are left without actionable feedback on how to improve the figure. Therefore, the comment is 2, as it highlights a potential area for improvement but lacks depth and direction."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that including an example created by BERT and comparing it with an example created by the proposed model could be helpful. This provides a clear and explicit action for the authors to take, as they can directly incorporate this suggestion into their draft. The comment is specific in its recommendation, detailing what kind of comparison would be beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area where the example should be included. While the suggestion is specific in terms of the type of comparison, the lack of grounding makes it challenging for the authors to understand where to apply the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any specific reasoning, examples, or references to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by adding a comparative example. By including such an example, the authors can better illustrate the differences between the two approaches and potentially strengthen the paper\"s argument. However, the comment could be more helpful if it provided additional context or guidance on how to effectively present this comparison. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the dataset sizes for the code summarization task and the code search task should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, it does not provide any explicit or implicit actions for the authors to take, such as how to adjust the dataset sizes or what specific steps to follow. The comment lacks concrete guidance on how to implement this suggestion, leaving the authors without a clear path to address the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the dataset size for the code summarization and code search tasks, suggesting that the dataset sizes for Vault and CSN should be the same to demonstrate data quality. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs adjustment. While the comment is specific about the issue, it lacks grounding as it does not provide clear references or context. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the dataset sizes for the code summarization and code search tasks should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the dataset sizes for the code summarization and code search tasks, suggesting that they should be the same to effectively demonstrate that Vault is better in terms of data quality compared to CSN. This feedback is clear and actionable, as it provides a specific direction for the authors to take in their analysis. However, the comment could be more helpful if it included additional guidance on how to adjust the dataset sizes or what specific steps the authors should consider to ensure a fair comparison. Despite this, the comment offers valuable insight into a potential area of improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies that some important concepts in the paper are not explained well, specifically mentioning \"actionrepeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully. However, the comment does not provide explicit guidance on how the authors should explain these concepts or what specific aspects need clarification. The action is implicit, as the authors can infer that they need to expand the explanations of these terms, but the lack of concrete details makes the action vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies that some important concepts in the paper are not explained well, specifically mentioning \"actionrepeat\" and \"dithering phenomenon.\" However, it does not specify which part of the paper these concepts are discussed in, making it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific about the concepts that need better explanation, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some important concepts in the paper are not explained well, specifically mentioning \"actionrepeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors are left without a clear understanding of why these concepts are unclear or how they should be explained. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some important concepts are not explained well, such as \"actionrepeat\" and \"dithering phenomenon.\" This feedback is valuable as it highlights areas where the authors could improve the clarity and comprehensibility of their work. However, the comment lacks depth and specificity, as it does not provide detailed suggestions or examples of how these concepts could be better explained. While it points out a need for clarification, it does not offer actionable guidance on how to address the issue, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests an alternative approach to generating and encoding text, proposing a method that avoids discretization between the instruction model and the encoder. It provides a specific alternative method involving creating an instruction embedding and passing it directly to the executor, along with an auxiliary objective to align the generated encoding with a gold instruction encoding. This feedback is explicit and concrete, as it clearly outlines the proposed changes and their potential benefits. The authors can directly implement these suggestions to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment provides a specific suggestion for an alternative approach to generating and encoding text, which could potentially improve the model. It suggests creating an instruction embedding g(f(s)) from state encoding f(s) and passing this directly to the executor, rather than generating text first. This approach aims to avoid discretization between the instruction model and the encoder, which could lead to better performance due to the absence of a single wrong decoding. The comment is fully grounded as it explicitly mentions the parts of the paper that could be improved, and it is specific in detailing the proposed alternative method and its potential benefits. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point suggests an alternative approach to generating and encoding text, proposing a method that avoids discretization between the instruction model and the encoder. It provides a specific alternative method involving creating an instruction embedding and passing it directly to the executor, along with an auxiliary objective to align the generated encoding with a gold instruction encoding. This feedback is logical and wellsupported, as it explains the potential benefits of the proposed method in avoiding discretization and its potential to improve performance. The comment is 5 as it provides a clear rationale and suggests a concrete alternative approach that could be implemented to enhance the paper. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a detailed and actionable suggestion for improving the draft by proposing an alternative approach to generating and encoding text. It suggests creating an instruction embedding g(f(s)) from state encoding f(s) and passing this directly to the executor, rather than generating text first. This approach aims to avoid discretization between the instruction model and the encoder, which could lead to better performance due to the absence of a single wrong decoding. The comment also suggests adding an auxiliary objective to align the generated encoding with a gold instruction encoding. This feedback is clear, specific, and provides a concrete alternative method that the authors can implement to enhance their work. Therefore, the comment is 5, as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the proposed model is not significant. However, it does not provide any specific details or suggestions on how the authors might address this issue or improve the novelty of their model. Without explicit guidance or actionable steps, the authors are left without a clear path to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the proposed model is not significant, but it does not specify which part of the paper this claim pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the model\"s novelty are lacking or how the authors might address this issue. Therefore, this comment is 2, aligning with category 1.", "verifiability_rationale": "The review point claims that the novelty of the proposed model is not significant. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without any supporting details or examples, the authors are left without a basis to understand or address the issue. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment points out that the novelty of the proposed model is not significant, which is a critical aspect for the paper\"s contribution. However, it lacks specific details or suggestions on how the authors might address this issue or enhance the novelty of their model. Without actionable feedback or guidance, the authors are left without a clear path to improve their work. Therefore, the comment is 2, as it identifies a problem but does not provide sufficient assistance for the authors to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the dataset\"s proportion of classes used for the pool subset, suggesting that it might make the dataset easier rather than harder. It provides an example of the imbalance in the dataset, such as the low number of observations for certain classes, and argues that accuracy might not be a good measure of quality in this case. However, the comment does not offer any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how the authors might adjust their dataset or evaluation metrics to better reflect the challenges of the dataset. Therefore, the comment is not actionable, as it does not provide the authors with a clear path forward.", "grounding_specificity_rationale": "The comment raises a concern about the dataset\"s class proportions, suggesting that the dataset might be easier rather than harder due to the imbalance in the number of observations for certain classes. However, it does not specify which part of the paper this issue is related to, such as the dataset description or experimental setup. This lack of grounding makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its critique of the dataset\"s class proportions, the absence of explicit grounding limits its usefulness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the dataset\"s class proportions, suggesting that the dataset might be easier rather than harder due to the imbalance in the number of observations for certain classes. The reviewer provides specific examples, such as the low number of observations for classes 9, 6, and 7, and argues that this imbalance might lead to an inaccurate assessment of the model\"s performance. However, the comment lacks detailed reasoning or references to support the claim that accuracy is not a good measure in this context. While the reviewer provides some evidence, the lack of comprehensive justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the dataset\"s class proportions, suggesting that the imbalance might make the dataset easier rather than harder. It provides specific examples of the imbalance, such as the low number of observations for certain classes, and argues that accuracy might not be a good measure of the quality in this case. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their evaluation metrics. While it identifies a potential problem, it lacks actionable advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the authors\" point about the importance of considering strategic aspects in prediction but expresses a lack of clarity regarding the \"main\" contribution of showing this. It also raises questions about the \"true\" payoff in Table 1, specifically whether it represents the test set payoff or the population empirical payoff. Additionally, the reviewer suggests exploring the work by Vapnik on teaching a learner with side information, noting a similarity to the authors\" approach. While the comment provides some guidance, it lacks explicit instructions on how to address these points or what specific actions the authors should take. The feedback is somewhat vague and could be more actionable if it included concrete steps or suggestions for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as clarifying the \"true\" payoff and exploring the work by Vapnik. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the \"main\" contribution of the paper, specifically questioning the novelty of showing that the task of prediction may have strategic aspects. It also asks for clarification on the \"true\" payoff in Table 1, whether it represents the test set payoff or the population empirical payoff, and suggests exploring the work by Vapnik on teaching a learner with side information. While the comment provides some context and questions, it lacks detailed reasoning or references to support the claims made about the novelty or relevance of the work. The feedback is 3 as it points out areas that need clarification but does not provide sufficient evidence or reasoning to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the authors\" point about the importance of considering strategic aspects in prediction but expresses a lack of clarity regarding the \"main\" contribution of showing this. It raises questions about the \"true\" payoff in Table 1, specifically whether it represents the test set payoff or the population empirical payoff, and suggests exploring the work by Vapnik on teaching a learner with side information. This feedback is 3 as it identifies areas where the authors could improve their explanation and provide additional context. However, the comment could be more actionable by offering specific suggestions or guidance on how to address these points. Overall, the comment provides some insight but lacks depth and clarity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method focuses solely on domainalignment methods and recommends exploring another UDA method based on selftraining. While the comment implies that the authors should consider expanding their approach to include selftraining methods, it does not provide explicit guidance on which specific selftraining methods to explore or how to integrate them into the current framework. The action is implicit and somewhat vague, as the authors need to infer the need for exploration and deduce the specific methods to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"selftraining is a prominent and effective approach within the field of unsupervised domain adaptation (UDA)\" and suggests exploring another UDA method based on selftraining. This provides clear guidance on which part of the paper the authors should consider expanding. The comment is also specific because it specifies the need to explore selftraining methods within the context of UDA, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that selftraining is a prominent and effective approach within the field of unsupervised domain adaptation (UDA) but suggests that the proposed method focuses solely on domainalignment methods. The comment implies that exploring another UDA method based on selftraining would be beneficial. However, it lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The comment is 3 as it provides a general suggestion but lacks detailed justification or evidence. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the proposed method by noting that it focuses solely on domainalignment methods, while selftraining is a prominent and effective approach within unsupervised domain adaptation (UDA). The comment suggests exploring another UDA method based on selftraining, which provides a clear direction for improvement. However, it lacks specific guidance on which selftraining methods to consider or how to integrate them into the current framework. While the feedback is 3, it could be more actionable with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the reliability of the accuracy vs. confidence plots, suggesting that the proposed methods might not appear better due to these plots. It raises concerns about pathologies observed in the plots, such as highaccuracy spikes in low confidence regimes, and asks whether these are due to dataset pathologies or the methods themselves. While the comment identifies a potential issue with the reliability of the plots, it does not provide explicit guidance on how to address this concern or improve the plots. The action is implicit, as the authors would need to infer that they should investigate and potentially revise the plots to address the identified issues. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the reliability diagrams (Fig 1, top)\" and \"accuracy vs confidence plots,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reliability of these plots, noting the presence of \"highaccuracy spikes in low confidence regimes\" and asking whether this is due to dataset pathologies or the methods themselves. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reliability of the accuracy vs. confidence plots, specifically noting \"highaccuracy spikes in low confidence regimes.\" While the comment identifies a potential issue with the plots, it does not provide specific examples or references to support the claim that these pathologies are due to dataset pathologies or the methods themselves. The reasoning is somewhat vague, as it lacks detailed evidence or examples to substantiate the claim. Therefore, the comment is considered 2, as it provides a basis for further investigation but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a critical question about the reliability of the accuracy vs. confidence plots, specifically noting the presence of \"highaccuracy spikes in low confidence regimes.\" This observation is significant because it challenges the interpretation of the proposed methods and suggests potential issues with the reliability of the results. The comment prompts the authors to investigate and potentially address these pathologies, which is a valuable piece of feedback. However, the comment could be more helpful if it provided suggestions on how to investigate or address these issues, such as suggesting specific analyses or visualizations that could reveal the underlying causes of the observed pathologies. Overall, the comment is 3 as it identifies a key area for improvement but lacks detailed guidance on how to proceed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper. First, it points out that the paper does not evaluate more advanced attacks, such as finetuning on a partial subset of the dataset D, which could still leave the backdoor active, making it difficult for customers to verify misbehaviors. Second, the paper only focuses on backdoor detection and does not discuss backdoor removal methods, which are a significant area of research. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback is 3 as it directs the authors to consider additional evaluations and discussions, but it lacks concrete details on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the paper by suggesting that it does not evaluate more advanced attacks, such as finetuning on a partial subset of the dataset D. It also points out that the paper only focuses on backdoor detection and does not discuss backdoor removal methods, which are a significant area of research. However, the comment does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is specific in its suggestions but lacks grounding as it does not provide clear references to the sections or parts of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate more advanced attacks, such as finetuning on a partial subset of the dataset D, which could still leave the backdoor active, making it difficult for customers to verify misbehaviors. It also suggests that the paper only focuses on backdoor detection and does not discuss backdoor removal methods, which are a significant area of research. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general idea of the issue but does not offer detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the evaluation of more advanced attacks and the discussion of backdoor removal methods. It points out that the paper does not consider scenarios where attackers might finetune on a partial subset of the dataset, potentially leaving the backdoor active, which is a significant concern for verifying misbehaviors. Additionally, the paper focuses solely on backdoor detection without discussing the existing methods for backdoor removal, a critical aspect of the field. While the comment highlights these gaps, it does not provide specific suggestions or guidance on how the authors might address these issues in their revised draft. The feedback is 3 as it directs the authors to consider expanding the scope of their evaluation and discussion, but it lacks detailed actionable advice, making it less impactful. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the use of the original adjacency matrix in the paper compared to the conventional GCN approach, which uses a normalized adjacency matrix with a renormalization trick. It questions the rationale behind not using the conventional graph convolutional operation and suggests that the authors might consider explaining or conducting an ablation study to address this concern. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the need for explanation or an ablation study. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of the original adjacency matrix in the paper compared to the conventional GCN approach, which uses a normalized adjacency matrix with a renormalization trick. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The comment is fully grounded in terms of identifying the area of concern, but it lacks specificity in detailing what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the use of the original adjacency matrix in the paper compared to the conventional GCN approach, which uses a normalized adjacency matrix with a renormalization trick. The comment questions the rationale behind not using the conventional graph convolutional operation. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the use of the original adjacency matrix is problematic or lacks justification. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a question about the use of the original adjacency matrix in the paper compared to the conventional GCN approach, which uses a normalized adjacency matrix with a renormalization trick. It questions the rationale behind not using the conventional graph convolutional operation, which could be a valuable point for clarification and further discussion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments or analyses could be conducted to justify their choice. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inconsistency in the provision of links for WMT\"15 and WMT\"14 training corpora. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes they should make to their draft. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the inconsistency in the provision of links for WMT\"14 and WMT\"15 training corpora. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is weakly grounded as it does not provide explicit references or guidance on where to address the issue. It is also specific in that it highlights a potential inconsistency in the paper, but without grounding, the authors cannot determine which part to focus on. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point raises a question about the inconsistency in the provision of links for WMT\"15 and WMT\"14 training corpora. However, it does not provide any claim, suggestion, or reasoning to support the observation. The comment lacks context or justification, making it difficult for the authors to understand the basis of the concern or how it might impact their work. Without additional information or explanation, the comment is 1.", "helpfulness_rationale": "The review comment raises a question about the inconsistency in the provision of links for WMT\"15 and WMT\"14 training corpora. However, it does not provide any suggestions or insights on how this inconsistency might affect the paper or what actions the authors should take to address it. The comment lacks depth and actionable guidance, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the necessity of knowing the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take. The comment lacks concrete guidance on how the authors can determine these bounds or how they might impact the selection of other hyperparameters. Without specific advice or examples, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the necessity of knowing the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this issue, leaving the authors without a clear path forward. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the necessity of knowing the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely a question, which does not offer any guidance or insight into the paper\"s content or methodology. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the necessity of knowing the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or what steps they should take. The comment lacks actionable feedback, leaving the authors without a clear path forward for improvement. Therefore, the comment is 2, as it identifies a potential area for clarification but does not offer any actionable advice or suggestions. This aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the novelty of the techniques used in the paper, suggesting that most were proposed and demonstrated before. It then asks for experimental results on the PDBbind dataset. While the comment identifies a potential issue with the novelty of the techniques, it does not explicitly instruct the authors to address this by providing experimental results on the PDBbind dataset. The action is implicit, as the authors would need to infer that they should include such results to demonstrate novelty. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the novelty of the techniques used in the paper, suggesting that most were proposed and demonstrated before. It then asks for experimental results on the PDBbind dataset. However, the comment does not specify which part of the paper discusses the novelty or the techniques used, making it weakly grounded. It is specific in questioning the novelty and suggesting the inclusion of experimental results on the PDBbind dataset, but without clear references to the sections or figures where these aspects are discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty of the techniques used in the paper, suggesting that most were proposed and demonstrated before. It then asks for experimental results on the PDBbind dataset. While the comment raises a valid concern about the novelty of the techniques, it lacks specific examples or references to support the claim that the techniques are not novel. The suggestion to include experimental results on the PDBbind dataset is clear and actionable, but the lack of detailed reasoning or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the novelty of the techniques used in the paper, suggesting that most were proposed and demonstrated before. It then asks for experimental results on the PDBbind dataset, which could help in demonstrating the novelty of the techniques. While the comment identifies a potential issue with the novelty, it does not provide specific guidance on how to address this concern or how to demonstrate the novelty effectively. The suggestion to include experimental results on the PDBbind dataset is 3, but it lacks depth and detail, making the feedback 4. The authors would need to infer that they should include such results to address the concern, but the comment does not provide a comprehensive or detailed response. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that adding error bars to the results comparing pairs of models would be beneficial to demonstrate that the observed differences are statistically significant and not due to random noise. This comment provides a clear and explicit action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The action is also concrete, as it gives precise guidance on how to implement the suggestion by adding error bars. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding error bars to the results comparing pairs of models, which is a specific and actionable suggestion. However, it does not specify which part of the paper this should be addressed in, making it weakly grounded. The comment is specific in its suggestion to improve the statistical significance of the results, but the lack of grounding makes it difficult for the authors to pinpoint the exact area where this improvement is needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that adding error bars to the results comparing pairs of models would strengthen the statistical significance of the findings. While the comment provides a clear rationale for the suggestion, it lacks specific examples or references to support the claim that error bars would effectively demonstrate the differences beyond noise. The authors would need to infer the need for error bars based on the reasoning provided, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the results section by adding error bars to the comparisons between pairs of models. This is a valuable piece of feedback as it helps the authors demonstrate the statistical significance of their findings, which is crucial for supporting their claims. By adding error bars, the authors can show that the observed differences are not due to random noise, thereby strengthening the validity of their results. This feedback is specific and actionable, making it 5 for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point on page 2, line 81, points out that the term \"full state\" is not defined properly, leaving the authors unsure of what is included in this term. While the comment highlights a specific issue, it does not provide any guidance on how the authors should define or clarify this term. The action is implicit, as the authors need to infer that they need to define \"full state\" to address the issue. However, the lack of explicit guidance or suggestions on how to define \"full state\" makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of definition for \"full state,\" providing a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point on page 2, line 81, highlights that the term \"full state\" is not defined properly, leaving the authors uncertain about what is included in this term. However, the comment does not provide any additional context, examples, or references to support the claim that the term is not defined properly. Without further explanation or evidence, the authors may find it challenging to understand the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue on page 2, line 81, where the term \"full state\" is not defined properly. This feedback is clear and actionable, as it directs the authors to a specific part of their draft where clarification is needed. However, the comment lacks broader context or suggestions on how to define \"full state\" or what aspects of the state should be included. While it provides a starting point for improvement, it could be more helpful if it offered additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is a good empirical study but lacks new proposals for neural architecture encoding. It implies that the authors should consider adding new proposals based on their analysis to enhance the paper. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the neural architecture encoding should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"This is a good empirical study\" and \"neural architecture encoding,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the lack of new proposals for neural architecture encoding and suggests that the paper should include new initial proposals based on the analysis. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is a good empirical study but lacks new proposals for neural architecture encoding. It suggests that a good empirical analysis should include new initial proposals based on the analysis. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that while it is a good empirical study, it lacks new proposals for neural architecture encoding. This feedback is 3 as it highlights an area for improvement, suggesting that the authors should consider adding new initial proposals based on their analysis. However, the comment could be more helpful if it provided specific guidance on how to develop these proposals or suggested particular areas of exploration. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive and actionable to fully assist the authors in enhancing their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach performs well in simulations but not in real data, questioning its practical advantage. It recommends including more real data analyses and comparisons to support the findings. However, the comment does not explicitly instruct the authors to conduct these analyses or provide specific guidance on how to incorporate them into the draft. The action is implicit and somewhat vague, as the authors need to infer that they should perform additional analyses and comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed approach performs well in simulations but not in real data, questioning its practical advantage. It recommends including more real data analyses and comparisons to support the findings. However, the comment does not specify which part of the paper discusses the simulations or the real data analysis, making it weakly grounded. The comment is specific in suggesting the need for additional real data analyses and comparisons, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach performs well in simulations but not in real data, questioning its practical advantage. While the comment suggests including more real data analyses and comparisons to support the findings, it lacks specific examples or references to the sections where these analyses should be included. This makes the claim 3, as the authors would need to infer the need for additional evidence but would not have a clear path to follow. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out that the proposed approach performs well in simulations but not in real data, which questions its practical advantage. It suggests that including more real data analyses and comparisons could help support the findings. This feedback is 3 as it highlights a specific area where the paper could be strengthened by providing additional evidence. However, the comment could be more helpful if it provided specific guidance on how to conduct these analyses or suggested particular types of comparisons that would be beneficial. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the authors\" solution has a low discrimination risk and improves fairness, but it also highlights that the underlying data distribution should be held after imputation to affect model effectiveness. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to implement these suggestions or what changes might be necessary. Without concrete steps or detailed reasoning, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" claim about the low discrimination risk and fairness of their solution, as well as the importance of holding the underlying data distribution after imputation for model effectiveness. However, it does not specify which part of the paper this claim is made or which sections or figures are being discussed. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment highlights the importance of holding the data distribution, it does not provide specific guidance on how to achieve this or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors\" solution has a low discrimination risk and improves fairness, but it also highlights the importance of holding the underlying data distribution after imputation for model effectiveness. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim regarding the fairness of their solution and the impact of imputation on model effectiveness. It highlights that the underlying data distribution should be held after imputation to ensure the effectiveness of the models. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their approach. While it points out a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors could potentially use more of the ReferIt data before moving on to other datasets. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the data or analysis would benefit from this approach. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors could use more of the ReferIt data before moving on to other datasets. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it lacks specific references or context, and it is also not specific about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors could potentially use more of the ReferIt data before moving on to other datasets. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors could potentially use more of the ReferIt data before moving on to other datasets. This feedback is 3 as it provides a direction for improvement, indicating that the authors could consider incorporating more data from ReferIt to enhance their analysis or results. However, the comment lacks specific details or suggestions on how to implement this idea, which limits its impact on guiding the authors in making improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies specific sections of the paper (243245 and 247) where the explanation is unclear and requests elaboration on certain aspects, such as the calculation of 5*3 versus 5*2, the choice of knn over other classifiers, and the values of k and the distance metric used. While the comment explicitly asks for clarification, it does not provide explicit instructions on how to elaborate or what specific details to include. The action is implicit, as the authors need to infer that they should provide more detailed explanations in those sections. However, the lack of concrete guidance on how to elaborate makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (243245 and 247), allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be clarified, such as the calculation of 5*3 versus 5*2, the choice of knn over other classifiers, and the values of k and the distance metric used. This level of detail provides clear guidance on what aspects require further explanation, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of explanations in specific sections of the paper, particularly regarding the calculation of 5*3 versus 5*2, the choice of knn over other classifiers, and the values of k and the distance metric used. While the comment does not contain subjective opinions or claims, it points out areas where the authors need to provide more detailed explanations or justifications. However, it lacks specific examples or references to support the need for clarification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas in the paper where the explanation is unclear, such as the calculation of 5*3 versus 5*2, the choice of knn over other classifiers, and the values of k and the distance metric used. It requests elaboration on these aspects, which is a valuable feedback for improving the clarity and understanding of the paper. However, the comment could be more helpful if it provided specific examples or suggestions for how to elaborate on these points. Overall, the feedback is 3 as it directs the authors to areas needing clarification, but it lacks depth and specificity, making it only partially beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. This is a clear and explicit action that the authors can take to improve their draft. By providing a detailed description of SAM, the authors can enhance the clarity and comprehensiveness of their paper. The comment is specific and concrete, as it directly instructs the authors to expand on the background of SAM. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this background is discussed in, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the content that needs to be addressed, it lacks grounding as it does not provide clear guidance on where in the paper this information is located. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. This is a specific and actionable piece of feedback that could significantly improve the clarity and comprehensiveness of the paper. By providing a detailed background, the authors can enhance the reader\"s understanding of the context and relevance of SAM. However, the comment could be more helpful if it included suggestions on how to describe the background or examples of what should be included. Overall, the comment is 4 as it identifies a clear area for improvement and provides a specific direction for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the experimental setup by noting the lack of comprehensive comparisons between languageassisted and visionassisted approaches. It suggests specific ways to enhance the evaluation by incorporating image guidance and coloraugmentation for the kNN baseline. However, the comment does not provide explicit instructions on how the authors should implement these suggestions or what specific aspects of the comparison need to be addressed. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the lack of comprehensive comparisons between languageassisted and visionassisted approaches. It suggests incorporating image guidance and coloraugmentation for the kNN baseline, which provides specific examples of how the comparison could be enhanced. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The specificity is high as it clearly specifies what needs to be addressed in the experimental setup. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental setup lacks comprehensive comparisons, particularly between languageassisted and visionassisted approaches. It suggests incorporating image guidance and coloraugmentation for the kNN baseline as ways to provide valuable insights. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that these comparisons are lacking or how they would enhance the evaluation of LAFT\"s efficacy. The lack of detailed justification makes the claim 3, as it is based on logical reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental setup by highlighting the lack of comprehensive comparisons between languageassisted and visionassisted approaches. It provides specific suggestions for enhancing the evaluation, such as incorporating image guidance and coloraugmentation for the kNN baseline. These suggestions are actionable and offer valuable insights into how the authors could strengthen their experimental design and analysis. By addressing these points, the authors can gain a clearer understanding of the strengths and limitations of their approach, ultimately improving the robustness and comprehensiveness of their work. Therefore, the comment is 4, as it provides clear guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing related work section, specifically mentioning \"a closely related line of work is collective entity linking that considers multiple mentions in the same document.\" It suggests that the proposed model is a special case of collective entity linking but notes that the paper does not mention this line of work. The comment implies that the authors should include this related work to provide a more comprehensive context for their research. However, it does not explicitly instruct the authors on how to incorporate this information into their draft, leaving the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a closely related line of work is collective entity linking that considers multiple mentions in the same document,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely the mention of this related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention a closely related line of work, specifically \"collective entity linking that considers multiple mentions in the same document.\" This claim is 3 as it identifies a specific area of related work that is not mentioned in the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a closely related line of work, specifically \"collective entity linking that considers multiple mentions in the same document.\" This is a valuable piece of feedback as it highlights an area where the authors could enhance their work by incorporating this related work. By mentioning this specific area, the reviewer provides the authors with a clear direction for improvement, suggesting that they should include this line of research to better contextualize their proposed model. However, the comment could be more helpful if it offered additional guidance on how to integrate this related work into the paper or suggested specific ways to compare the proposed model with existing approaches. Overall, the comment is 4 as it identifies a crucial aspect that needs attention, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of truncating the log likelihood function on the sensitivity of the model. It suggests that it would be interesting to see a comparison, but it does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. The comment is somewhat vague, as it does not offer concrete steps or suggestions for the authors to take. While it identifies a potential issue, the lack of detailed guidance makes it difficult for the authors to apply the feedback effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of truncating the log likelihood function on the sensitivity of the model, suggesting that it would be interesting to see a comparison. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment does not provide specific guidance on how to conduct the comparison or what aspects to focus on. While it identifies a potential area for improvement, the lack of grounding and specificity limits the authors\" ability to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the impact of truncating the log likelihood function on the sensitivity of the model, suggesting that it would be interesting to see a comparison. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of truncating the log likelihood function on the sensitivity of the model, suggesting that it would be interesting to see a comparison. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for improvement, it does not provide actionable advice or detailed insights that would help the authors enhance their work. The feedback is 3 as it points out a potential issue, but it could be more comprehensive with additional suggestions or guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of the method is limited to a small set of molecules from the MD17 dataset and recommends expanding the evaluation to a larger and more diverse dataset, including more complex molecules and materials. This feedback provides a clear and explicit action for the authors to take, which is to broaden the scope of their evaluation. The comment is specific in its suggestion, detailing what additional data should be included to enhance the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the evaluation of the method to a larger and more diverse dataset, including more complex molecules and materials. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine where the comment applies. The comment is specific in its suggestion to include more complex molecules and materials, but without a clear reference, it is difficult for the authors to understand which part of the paper needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation of the method is limited to a small set of molecules from the MD17 dataset and recommends expanding the evaluation to a larger and more diverse dataset, including more complex molecules and materials. This claim is 3 as it provides a logical suggestion for improvement, but it lacks specific examples or references to support the claim. The authors would need to infer the need for a more comprehensive evaluation based on the provided feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is based on a small set of molecules from the MD17 dataset. It suggests that expanding the evaluation to a larger and more diverse dataset, including more complex molecules and materials, would provide a more comprehensive assessment of the method\"s performance. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation. However, it could be more helpful if it included suggestions for specific datasets or materials to consider. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the StreamingLLM paper is similar to the current work and highlights a potential overlap in techniques, such as setting sink tokens and performing local attention. It also notes that the StreamingLLM paper has been recently uploaded, making a direct comparison less likely. The comment implies that the differences between the two papers should be clarified. However, it does not provide explicit guidance on how to clarify these differences or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"StreamingLLM paper\" and its relevance to the current work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the similarity in techniques, such as setting sink tokens and performing local attention, and suggests that the differences between the two papers should be clarified. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the StreamingLLM paper is similar to the current work, noting the use of sink tokens and local attention. It suggests that the differences between the two papers should be clarified. However, the comment lacks specific examples or detailed reasoning to support the claim of similarity or the need for clarification. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the claim is considered 2, as it provides some basis for the comment but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential similarity between the current work and the StreamingLLM paper, noting the use of sink tokens and local attention. It suggests that the differences between the two papers should be clarified, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to highlight these differences. Without additional details, the authors may struggle to fully understand and address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the qualitative results of the paper, suggesting that there is no significant improvement compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve their results or what specific aspects need to be revised. Without actionable feedback, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the qualitative results of the paper, specifically mentioning a lack of significant improvement compared to ConceptWeaver. However, it does not specify which part of the paper this comparison is made or which sections of the results are being discussed. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the issue of improvement, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no significant improvement in the qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the assertion that the results are not significantly improved. Without such evidence, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the qualitative results, suggesting that they do not show significant improvement compared to ConceptWeaver, which can handle more than two concepts. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve their results. It does not provide actionable feedback or guidance on what aspects of the paper need revision or enhancement. Without clear and detailed suggestions, the authors are left without a clear path to improve their draft, making the comment 3 but lacking depth and actionable value. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the problem is framed as subspace clustering with missing data, it could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete guidance on how the authors should approach this problem or implement the suggested solution. The action is implicit and vague, as it leaves the authors to infer the necessary steps and actions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that if the problem is framed as subspace clustering with missing data, it could be solved by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that if the problem is framed as subspace clustering with missing data, it could be solved by alternating between matrix completion and subspace clustering. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without additional context or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a suggestion for how the problem could be framed and solved, specifically mentioning subspace clustering with missing data and proposing alternating between matrix completion and subspace clustering. However, it lacks depth and does not offer detailed guidance or examples on how to implement this approach. While it identifies a potential area for improvement, the comment is 3 as it gives a direction for the authors to consider, but it could be more comprehensive with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the reliance of CCKTDet++ on the quality and alignment of teacher models, suggesting that limitations or biases in these models could affect performance and introduce unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors would need to infer that they should consider the impact of teacher model quality and alignment on their work. The lack of concrete details or actionable steps makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the reliance of CCKTDet++ on the quality and alignment of teacher models, suggesting that limitations or biases in these models could affect performance and introduce unintended biases. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it weakly grounded. The comment is specific in detailing the potential impact of teacher model limitations and biases, providing clear guidance on what needs to be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that CCKTDet++ is heavily reliant on the quality and alignment of teacher models, which could lead to performance issues and unintended biases if these models have limitations or biases. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification for the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reliance of CCKTDet++ on the quality and alignment of teacher models, suggesting that limitations or biases in these models could affect performance and introduce unintended biases. This feedback highlights a critical aspect of the model\"s performance and potential biases, which could be valuable for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might mitigate these issues or improve their draft. While it points out a significant concern, it does not provide actionable steps or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the selection of comparison objects in the experiment, noting that they are very old and that the performance has not improved. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific changes should be made to the comparison objects. The comment lacks concrete guidance on how to improve the selection or what new objects should be considered. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment highlights a concern regarding the selection of comparison objects in the experiment, noting that they are very old and that the performance has not improved. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the comparison objects, the absence of explicit grounding information limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the comparison objects selected in the experiment are very old and that the performance has not improved. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the selection of comparison objects in the experiment, noting that they are very old and that the performance has not improved. While this feedback highlights a specific area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue. The comment does not provide any recommendations or insights into what new comparison objects could be considered or how the experiment could be redesigned to yield better results. As a result, the feedback is 3, as it points out a potential weakness but does not offer a comprehensive or detailed response to guide the authors in improving their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how masks are handled in CNN layers, specifically within the representation block. While it identifies a potential area of confusion or lack of clarity, it does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to clarify this aspect in their paper, but the comment lacks concrete steps or detailed advice on how to do so. Therefore, the comment is 3, as it points out a specific area that needs attention but does not provide clear instructions on how to improve the draft.", "grounding_specificity_rationale": "The comment raises a question about how masks are handled in CNN layers, specifically within the representation block. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is specific in its focus on the handling of masks in CNN layers, but it lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about how masks are handled in CNN layers, specifically within the representation block. However, it does not contain any claims, opinions, or suggestions that require verification or justification. It is a factual question that seeks clarification on a specific aspect of the paper. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about how masks are handled in CNN layers, specifically within the representation block. This is a valid point that could help the authors clarify a potential area of confusion or lack of clarity in their paper. However, the comment does not provide any suggestions or guidance on how to address this issue, leaving the authors without actionable steps to take. The feedback is 3 as it identifies a specific area that needs clarification, but it lacks depth and does not offer constructive advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the reason for the larger training loss observed in the \"without dropout\" condition of Figure 8, specifically asking for an explanation. It also suggests that activation clipping might reduce the model capacity, which could be relevant to the issue. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the figure or the explanation. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for the larger training loss in the \"without dropout\" condition and suggests that activation clipping might reduce the model capacity, providing a clear direction for the authors to consider. This feedback is detailed and actionable, making it 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the larger training loss observed in Figure 8 when \"without dropout\" is used, suggesting that activation clipping might reduce the model capacity. However, it does not provide any specific reasoning, examples, or references to support the claim that activation clipping could be the cause of the larger training loss. Without detailed justification or evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 8, questioning why the \"without dropout\" condition has a larger training loss. It also suggests that activation clipping might reduce the model capacity, which could be relevant to the issue. However, the comment lacks detailed guidance or suggestions on how the authors might address this problem or improve the figure. While it points out a potential area for further investigation, it does not provide actionable steps or insights that would help the authors enhance their work. Therefore, the comment is 3, as it highlights a specific area of concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the significance of the paper in establishing largescale matting datasets, noting that this aspect is rarely mentioned in the paper. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the paper to better highlight this significance. The comment lacks explicit actions or concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the significance of the paper in establishing largescale matting datasets, noting that this aspect is rarely mentioned. However, it does not specify which part of the paper discusses this significance or how the authors might address it. The comment lacks grounding as it does not provide specific references or sections of the paper that need attention. It is also not specific because it does not detail what aspects of the paper need improvement or how the authors can enhance the discussion of largescale matting datasets. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the significance of the paper in establishing largescale matting datasets, noting that this aspect is rarely mentioned. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the significance of the paper in establishing largescale matting datasets, noting that this aspect is rarely mentioned. However, the comment lacks specific suggestions or actionable feedback on how the authors might address this issue or improve the paper to better highlight this significance. It does not provide guidance on what aspects of the paper need attention or how the authors can enhance the discussion of largescale matting datasets. Without concrete suggestions or detailed feedback, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that it is 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the number of adversarial examples used in the study is insufficient to demonstrate a certain distribution. However, it does not provide any specific guidance or action for the authors to take to address this issue. The comment lacks explicit instructions on how the authors might increase the number of adversarial examples or what specific distribution they are trying to demonstrate. Without concrete suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the number of adversarial examples is too small to demonstrate a certain distribution, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or figure is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what distribution is being demonstrated or how the number of adversarial examples should be increased. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the number of adversarial examples is too small to demonstrate a certain distribution. However, the comment lacks specific details or references to support this claim. It does not provide any examples or evidence to substantiate the assertion that the number of adversarial examples is insufficient. Without additional context or justification, the authors are left without a clear understanding of why this claim is important or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the number of adversarial examples used in the study is too small to effectively demonstrate a certain distribution. This feedback highlights a potential limitation in the experimental setup or the scope of the study. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as increasing the number of adversarial examples or expanding the scope of the study. Without actionable advice or detailed recommendations, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it identifies a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the appropriateness of the proposed channelsparse gradients, suggesting that they may not save time or memory in practice. It also points out that the analysis experiments or \"Qualitative Studies\" of Section 5.2 are conducted with a subset of common corruptions, and the findings may not generalize to the full set. The comment implies that the authors should consider using the full set of corruptions for thoroughness and comparability with other results. However, the action is implicit, as the authors need to infer that they should expand their experiments to include the full set of corruptions. The comment is 3 because it provides a clear direction for improvement, but it lacks explicit guidance on how to implement this change. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5), which is not appropriate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proposed channelsparse gradients, suggesting that they may not save time or memory in practice. Additionally, the comment points out that most frameworks only support dense gradients, which implies that zeroing out a particular channel may not alter the computation. The comment further critiques the \"Qualitative Studies\" of Section 5.2, noting that the experiments are conducted with a subset of common corruptions, and the findings may not generalize to the full set. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment is rated as 5.", "verifiability_rationale": "The review point critiques the appropriateness of the proposed channelsparse gradients, suggesting that they may not save time or memory in practice. It also questions the generalizability of the analysis experiments or \"Qualitative Studies\" of Section 5.2, which are conducted with a subset of common corruptions. The comment implies that the findings may not generalize to the full set of corruptions, suggesting that the authors should consider using the full set for thoroughness and comparability with other results. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the limitations of channelsparse gradients or the generalizability of the experiments. The comment is 3 as it provides a logical basis for the critique but could benefit from more detailed evidence or references to support the claims. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment provides valuable feedback by critiquing the appropriateness of the proposed channelsparse gradients, suggesting that they may not save time or memory in practice. It also questions the generalizability of the analysis experiments or \"Qualitative Studies\" of Section 5.2, which are conducted with a subset of common corruptions. The comment implies that the findings may not generalize to the full set of corruptions, suggesting that the authors should consider using the full set for thoroughness and comparability with other results. This feedback is 4 as it identifies specific areas for improvement and provides a clear direction for the authors to enhance the robustness and comprehensiveness of their experiments. However, it could be more helpful if it included suggestions on how to address the limitations or provide more detailed reasoning for the critique. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two main points. First, it questions the authors\" consideration of sparsity and lowrank properties in their proof, suggesting that the proof might be related to concentrationofmeasure and lowrank concepts. This implies that the authors should consider these properties in their analysis. However, the comment does not provide explicit guidance on how to incorporate these concepts or what specific steps to take. Second, the comment critiques the novelty of the results, suggesting that they might be simple extensions of existing results. This feedback is somewhat vague, as it does not offer concrete suggestions for how the authors might address this issue. Overall, the comment provides some implicit guidance but lacks explicit and detailed actions, making it 3.", "grounding_specificity_rationale": "The comment addresses two specific points in the review, but it does not explicitly mention which parts of the paper these points relate to. The first point questions the authors\" consideration of sparsity and lowrank properties in their proof, suggesting that the proof might be related to concentrationofmeasure and lowrank concepts. The second point critiques the novelty of the results, suggesting that they might be simple extensions of existing results. While the comment is specific in its critique of the claims and results, it lacks grounding as the authors cannot confidently determine which parts of the paper are being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two claims: first, that the authors do not consider sparsity or lowrank properties in their proof, which might be related to concentrationofmeasure and lowrank concepts, and second, that the results are simple extensions of existing work. The first claim is 3 as it provides a logical reasoning for why the authors might not have considered these properties, but it lacks specific examples or references to support the claim. The second claim is also 3 as it suggests that the results are not novel, but it does not provide detailed reasoning or references to substantiate this assertion. Overall, the comment is 3, as it provides some justification but lacks depth and specificity.", "helpfulness_rationale": "The review comment provides feedback on two main aspects of the paper. First, it questions the authors\" consideration of sparsity and lowrank properties in their proof, suggesting that the proof might be related to concentrationofmeasure and lowrank concepts. This implies that the authors should consider these properties in their analysis, but it does not offer specific guidance on how to do so. Second, the comment critiques the novelty of the results, suggesting that they might be simple extensions of existing work. This feedback is 3 as it highlights potential areas for improvement, but it lacks detailed suggestions or actionable advice. Overall, the comment provides some insight into the paper\"s weaknesses but could be more comprehensive and helpful if it offered more specific guidance or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. While it identifies a potential issue with the Limitations section, it does not provide explicit guidance on how to address this issue or what specific aspects of the Limitations section need to be expanded. The action is implicit, as the authors would need to infer that they should expand the Limitations section to match the detailed writing style of the main body. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the Limitations section, noting that it is too concise compared to the detailed writing style in the main body of the paper. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention the section or part of the paper where the Limitations section is located, which makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the Limitations section is considered too concise or how it should be expanded. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Limitations section, noting that it is too concise compared to the detailed writing style in the main body of the paper. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to expand the Limitations section or what specific aspects of conciseness need to be addressed. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of PatchCore with an added denoising process. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their method or what specific changes could be made to differentiate it from PatchCore. Without actionable steps or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the proposed method is weak and suggests it is a modified version of PatchCore with an added denoising process. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its critique of the novelty, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is weak and suggests it is a modified version of PatchCore with an added denoising process. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion that the method is merely a modification of PatchCore. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the novelty of the proposed method, suggesting it is a modified version of PatchCore with an added denoising process. While this observation highlights a concern about the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their method. The comment lacks actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it points out a problem but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for the authors to address the issue of unclear instructions for running the code. It suggests providing more details about each challenge, such as including them in an extensive version of Table 1 or in the appendix, similar to binpwn. Additionally, it recommends listing all the prompts used in the evaluation, either in the appendix or on the github. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. The comment is fully actionable, as it directly instructs the authors on what needs to be done to enhance the clarity and usability of their code. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the repository, providing clear guidance on what needs to be addressed. It suggests providing more details about each challenge, such as including them in an extensive version of Table 1 or in the appendix, similar to binpwn. Additionally, it recommends listing all the prompts used in the evaluation, either in the appendix or on the github. This level of detail and specificity allows the authors to understand exactly what changes are needed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors could not run the code due to a lack of clear instructions. It suggests providing more details about each challenge and listing all the prompts used in the evaluation. However, the comment does not provide any specific examples or references to support the claim that the instructions are unclear or missing. Without additional context or evidence, the authors may find it challenging to understand the exact issues they need to address. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the feedback.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the code, as the authors could not run it due to a lack of clear instructions. The comment provides specific suggestions for improvement, such as providing more detailed instructions about each challenge, including them in an extensive version of Table 1 or in the appendix, similar to binpwn, and listing all the prompts used in the evaluation. These suggestions are actionable and constructive, offering clear guidance on how the authors can enhance the clarity and usability of their code. By addressing these points, the authors can significantly improve the reproducibility and transparency of their work, making it more valuable to the research community. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the model ablation results and the major claim of the paper, suggesting that the global representation g_v is more crucial than other components. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to align the results with the paper\"s claim. The action is implicit and vague, as the authors are left to infer that they need to discuss or revise their claims to better reflect the findings. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment refers to \"the model ablation results in Table 3,\" which provides full grounding as the authors can accurately identify the specific part of the paper being addressed. It also specifies what is being discussed, namely the importance of the global representation g_v in grounded QA and its departure from the major claim of interpretable VQA. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model ablation results in Table 3 suggest that the global representation g_v is more crucial than other components, which slightly contradicts the major claim of the paper regarding interpretable VQA. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the discrepancy. Without additional context or evidence, the claim remains 3, as it is based on an observation that requires further explanation or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the model ablation results and the major claim of the paper, specifically noting that the global representation g_v is more crucial than other components, which contradicts the paper\"s focus on interpretable VQA. This feedback is 3 as it highlights a potential issue with the paper\"s claims or the interpretation of the results. However, it lacks detailed guidance on how the authors might address this discrepancy or what changes could be made to align the results with the paper\"s major claim. The comment provides a clear observation but does not offer actionable suggestions for improvement, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the ablation studies in Table 4 should include comparisons with stateoftheart RVQVAE models, such as MoMask [1]. This provides a clear and explicit action for the authors to take, as they need to add these comparisons to enhance the comprehensiveness of their analysis. The comment is specific and concrete, detailing exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for comparisons with stateoftheart RVQVAE models, such as MoMask [1], to provide a more comprehensive understanding of the model\u2019s relative effectiveness. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation studies in Table 4 should include comparisons with stateoftheart RVQVAE models, such as MoMask [1], to provide a more comprehensive understanding of the model\u2019s relative effectiveness. This claim is 3 as it suggests a specific comparison that could enhance the comprehensiveness of the analysis. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the ablation studies in Table 4 should include comparisons with stateoftheart RVQVAE models, such as MoMask [1]. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the comprehensiveness of the analysis. By comparing the proposed approach with existing models, the authors can better understand its relative effectiveness. This level of detail and specificity makes the comment 5 for guiding the authors in improving their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper, noting that the \"primarysecondary\" relationship is mentioned extensively but lacks clarity and precise definition, particularly in relation to nuclearity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects need clarification. The action is implicit, as the authors would need to infer that they should clarify the distinction between the \"primarysecondary\" relationship and nuclearity. While the comment identifies a need for clarification, it lacks concrete instructions on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"primarysecondary\" relationship, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity and precise definition of the \"primarysecondary\" relationship in relation to nuclearity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"primarysecondary\" relationship is mentioned extensively but lacks clarity and precise definition, particularly in relation to nuclearity. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically noting that the \"primarysecondary\" relationship is mentioned extensively but lacks clarity and precise definition, particularly in relation to nuclearity. This feedback is 3 as it highlights a need for clarification and precision in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting additional explanations or examples to enhance clarity. While it points out an area for improvement, the lack of actionable advice limits its overall helpfulness. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the effect of mask ratio across different datasets, suggesting that it may require more tuning. It also points out that the insight about the impact of mask ratio is missing in the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. However, the comment does not provide explicit instructions or concrete guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks detailed steps, making it 3.", "grounding_specificity_rationale": "The comment addresses the effect of mask ratio across different datasets, noting that it may require more tuning and that the insight about its impact is missing in the discussions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for an intuitive guide for choosing the mask ratio, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effect of mask ratio varies across different datasets, leading to more tuning, as mentioned in the limitations. However, it also notes that the insight about the impact of mask ratio is missing in the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the missing insights and the need for a guide. This makes the claim 3, as it is based on logical reasoning but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effect of mask ratio across different datasets, suggesting that it may require more tuning. It also points out that the insight about the impact of mask ratio is missing in the discussions, which could lead to a lack of guidance for choosing this ratio. The comment suggests that an intuitive guide for selecting the mask ratio would be beneficial. While the feedback highlights a specific area for improvement, it does not provide detailed guidance or suggestions on how to address the issue or what specific aspects of the discussion should be expanded. The comment is 3 as it points out a potential area for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from another round of proofreading and that several sections are difficult to follow. While it implies that the authors should proofread the paper, it does not provide specific guidance on which sections need attention or how to improve their clarity. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from another round of proofreading and that several sections are difficult to follow. However, it does not specify which sections of the paper are challenging to follow, leaving the authors uncertain about which parts require attention. The comment lacks specificity in identifying the sections that need improvement, making it weakly grounded. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper could benefit from another round of proofreading and that several sections are difficult to follow. However, it does not provide any specific reasoning or examples to support why these sections are challenging or how proofreading would address these issues. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from another round of proofreading and that several sections are difficult to follow. While it identifies a potential area for improvement, it lacks specific guidance on which sections need attention or how to enhance clarity. The feedback is 3 as it points out a general issue that could impact the paper\"s readability, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"STG layer\" in Figure 2 has not been mentioned in the manuscript, and the reviewer is uncertain about its reference to stochastic gates. While the comment identifies a potential issue with the consistency of terminology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors would need to infer that they should either clarify the term or remove it from the figure. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the term \"STG layer,\" which has not been mentioned throughout the manuscript, and the reviewer is uncertain about its reference to stochastic gates. This provides a clear and specific instruction for the authors to address the inconsistency in terminology. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the term \"STG layer\" in Fig. 2, noting that it has not been mentioned in the manuscript. The reviewer expresses uncertainty about whether the term refers to stochastic gates. However, the comment lacks specific examples or references to clarify the issue, making it difficult for the authors to understand the exact nature of the problem. Without additional context or explanation, the claim is considered 2, as it points out a potential inconsistency but does not provide sufficient evidence to fully substantiate the concern.", "helpfulness_rationale": "The review comment identifies a potential issue with the consistency of terminology in the manuscript, specifically regarding the term \"STG layer\" in Figure 2. It points out that this term has not been mentioned throughout the manuscript, and the reviewer is uncertain about its reference to stochastic gates. While the comment highlights a potential area for clarification, it does not provide specific guidance on how the authors might address this issue or what steps they should take to ensure consistency. The feedback is 3 as it directs the authors to a specific area that needs attention, but it lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements from the proposed methodology are limited in some instances and even underperform compared to the baseline in specific cases (FiQA and CONALA). However, it does not provide any explicit or implicit suggestions on how to address these limitations or improve the methodology further. The authors are left without guidance on what specific aspects of the methodology need to be revised or enhanced to achieve better performance. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It makes a general observation about the limitations of the proposed methodology and its underperformance compared to the baseline in specific cases. However, it does not provide specific details or suggestions on what needs to be addressed to improve the methodology. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements from the proposed methodology are limited and even underperform compared to the baseline in specific cases (FiQA and CONALA). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific data or examples, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methodology, noting that the improvements are limited and even underperform compared to the baseline in certain cases, specifically mentioning FiQA and CONALA. This feedback is 3 as it highlights a critical area for improvement, allowing the authors to focus on enhancing their methodology. However, the comment lacks detailed suggestions or guidance on how to address these limitations, which could make it less helpful overall. The authors would need to infer what specific aspects of the methodology need to be revised or enhanced to achieve better performance, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the comparisons with the work [1], specifically questioning the contributions and advantages beyond it. While the comment implies that the authors should clarify these aspects, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should elaborate on the differences and advantages of their work compared to [1]. However, the comment lacks concrete details on what specific aspects need clarification, making it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with [1], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear comparisons and asks for clarification on the contributions and advantages beyond the cited work. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of comparisons with a specific work, [1]. It does not contain a subjective claim or suggestion but rather points out a potential area for improvement in the paper. The comment is factual and descriptive, as it highlights a lack of clarity in the comparisons. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in comparisons with a particular work, [1]. It highlights the need for the authors to clarify the contributions and advantages of their work beyond the cited paper. This feedback is clear and actionable, as it directs the authors to address a specific gap in their discussion. However, the comment could be more helpful if it provided additional guidance on how to clarify these comparisons or suggested specific areas where the authors could elaborate. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the description of the rebalancing step method used in multimodal learning. It points out that the method is not well described and lacks analysis in the full text. The comment suggests that the authors should provide a more detailed explanation of why using the average feature of previous samples can stop the training of the unimodal branch. This feedback is explicit and provides a clear action for the authors to take, which is to improve the description of the method. However, the comment does not specify how to implement this action, such as providing specific examples or detailed explanations. Therefore, the action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the rebalancing step method used in multimodal learning, specifically noting that it is not well described and lacks analysis in the full text. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a more detailed explanation of why using the average feature of previous samples can stop the training of the unimodal branch. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rebalancing step method is not well described and lacks analysis in the full text. It suggests that the authors should provide a more detailed explanation of why using the average feature of previous samples can stop the training of the unimodal branch. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the rebalancing step method used in multimodal learning, noting that it is not well described and lacks analysis in the full text. It suggests that the authors should provide a more detailed explanation of why using the average feature of previous samples can stop the training of the unimodal branch. This feedback is clear and actionable, as it directs the authors to improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on how to enhance the description. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the differences and advantages of the \"Reduce\" part compared to EATA, as well as the possibility of using an entropy metric instead of an energy one. While it prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the paper. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the differences and advantages of the \"Reduce\" part compared to EATA, as well as the possibility of using an entropy metric instead of an energy one. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and suggests exploring the use of an entropy metric instead of an energy one. However, it does not provide any specific reasoning, examples, or references to support these claims or questions. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for these suggestions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the differences and advantages of the \"Reduce\" part compared to EATA, as well as the possibility of using an entropy metric instead of an energy one. While it prompts the authors to consider these aspects, it does not provide specific guidance or suggestions on how to address these questions or incorporate them into the paper. The feedback is 3 as it identifies areas for improvement, but it lacks depth and actionable advice, making it only partially beneficial for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might consider comparing their proposed method against deterministic control, given the popularity of deterministic policies. However, it does not provide explicit guidance on how to conduct this comparison or what aspects of the comparison would be relevant. The action is implicit, as the authors need to infer that they should perform a comparative analysis, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a general direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this comparison should be made or where the deterministic control methods are discussed. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the comparison, the lack of grounding makes it difficult for the authors to understand where to apply this feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might consider comparing their proposed method against deterministic control, given the popularity of deterministic policies. However, the comment lacks specific details or examples to support this suggestion, making it difficult for the authors to understand the basis for the recommendation. Without additional context or justification, the claim remains 3, as it lacks the necessary evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might consider comparing their proposed method against deterministic control, given the popularity of deterministic policies. This feedback is 3 as it provides a potential avenue for further exploration and comparison, which could enhance the paper\"s relevance and impact. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the comparison would be most relevant. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the naming of the 3rd column in Table 4, suggesting it should be ATE instead of Corr. It also implies that the reviewer understands the relationship between Corr and CauAnt. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes are necessary. The action is implicit, as the authors need to infer that the column name should be corrected, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the naming of the 3rd column in Table 4 and suggests that it should be ATE instead of Corr, providing a clear direction for improvement. The comment also implies an understanding of the relationship between Corr and CauAnt, which adds depth to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the naming of the 3rd column in Table 4, suggesting it should be ATE instead of Corr. It also implies that the reviewer understands the relationship between Corr and CauAnt. However, the comment lacks specific examples or references to support the claim that the naming is incorrect or inconsistent. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue in Table 4, questioning the naming of the 3rd column and suggesting it should be ATE instead of Corr. It also implies that the reviewer understands the relationship between Corr and CauAnt. While the comment points out a potential inconsistency in the naming convention, it does not provide detailed guidance on how the authors might address this issue or what changes could be made to improve the clarity of the table. The feedback is 3 as it highlights a specific area for attention, but it lacks depth and actionable suggestions, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment provides feedback on the clarity of the paper, specifically regarding the anchoring of the mechanism in prior work and the lack of clarity in the figures. It suggests that the authors should consider providing more context or examples to clarify these points. However, the comment does not explicitly instruct the authors on how to improve the clarity or provide specific guidance on what needs to be done. The feedback is somewhat vague, as it leaves the authors to infer the necessary actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the paper, specifically regarding the anchoring of the mechanism in prior work and the lack of clarity in the figures. It suggests that the authors should consider providing more context or examples to clarify these points. However, the comment does not specify which part of the paper is being addressed, such as the methods section or the figures themselves. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues with clarity, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the paper, specifically regarding the anchoring of the mechanism in prior work and the lack of clarity in the figures. The comment suggests that the authors should provide more context or examples to clarify these points. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the mechanism is not clearly anchored in prior work or that the figures lack clarity. This lack of detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some indication of the problem but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides feedback on the clarity of the paper, specifically regarding the anchoring of the mechanism in prior work and the lack of clarity in the figures. It suggests that the authors should consider providing more context or examples to clarify these points. However, the comment does not offer specific guidance on how to improve the clarity or provide detailed suggestions for enhancing the figures. While it identifies areas for improvement, the feedback lacks depth and actionable advice, making it 3. The authors would need to infer the necessary steps to address the issues, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the limited novelty of the paper, suggesting that the main contribution is the application of a pretrained mechanism to a fewshot graph learning task. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might enhance the novelty of their work or what specific aspects of the pretrained mechanism could be improved. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the limited novelty of the paper, specifically questioning the main contribution being the application of a pretrained mechanism to fewshot graph learning. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of novelty, the absence of grounding information makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the limited novelty of the paper, suggesting that the main contribution is the application of a pretrained mechanism to fewshot graph learning. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or detailed reasoning to substantiate the assertion that the contribution is not exciting or feels complicated. Without such evidence, the claim remains unsubstantiated, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a concern about the limited novelty of the paper, specifically questioning the main contribution as the application of a pretrained mechanism to fewshot graph learning. While the comment highlights a potential weakness in the paper\"s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it points out a critical area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper, noting that while it empirically validates the usefulness of certain setups and parameters for testtime training, it does not provide a theoretical understanding of why these setups do not collapse. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this gap or what theoretical frameworks could be used to explain the phenomenon. Without specific guidance or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the paper by pointing out a gap in the theoretical understanding of why certain setups or parameters do not collapse, despite empirical validation. However, it does not specify which part of the paper this issue is discussed or addressed. The authors may infer that it relates to the sections discussing empirical validation or the discussion of testtime training, but the lack of explicit mention makes it difficult to pinpoint the exact area. The comment is specific in identifying the need for theoretical understanding but lacks grounding as it does not provide clear guidance on where to address this gap. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper empirically validates which setups/parameters are useful for testtime training but does not provide theoretical understanding on why they do not collapse. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while it empirically validates the usefulness of certain setups and parameters for testtime training, it does not provide a theoretical understanding of why these setups do not collapse. This feedback highlights a crucial area for improvement, as a theoretical explanation would enhance the depth and comprehensiveness of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as proposing potential theoretical frameworks or suggesting additional experiments to explore the phenomenon. While it points out an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a significant area for improvement but does not provide detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the visual analysis in Section 4.4, specifically whether the results are from training or test images. While it identifies a potential issue with the clarity of the analysis, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the source of the visual analysis. However, the comment lacks concrete details on how to achieve this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the visual analysis in Section 4.4, which is a specific part of the paper. It questions whether the results are from training or test images, providing a clear and specific point of concern. The comment is fully grounded as it explicitly mentions the section where the issue arises, allowing the authors to accurately identify the part of the paper being addressed. The specificity is high because it clearly specifies what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the visual analysis in Section 4.4, specifically whether the results are from training or test images. While the comment identifies a potential ambiguity in the presentation, it does not provide any evidence or reasoning to support the claim that the analysis is unclear or requires clarification. The lack of supporting information makes it difficult for the authors to understand the basis of the concern, rendering the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the presentation of the visual analysis in Section 4.4, specifically questioning whether the results are derived from training or test images. This is a clear and actionable feedback that highlights a lack of clarity in the paper. By pointing out this ambiguity, the comment provides the authors with a specific area to address, which is crucial for improving the clarity and reproducibility of their work. However, the comment could be more helpful if it suggested ways to clarify the distinction between training and test images or provided examples of how to present the analysis more clearly. Overall, the comment is 3 as it identifies a significant issue that needs attention, but it lacks depth in terms of actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an interesting direction for future work by proposing the application of the DEER method to other methods like LEM or UnICORNN. It questions whether these methods would maintain the same performance and if better performance could be achieved with the DEER method due to its potential for faster training and hyperparameter tuning. However, the comment does not provide explicit guidance on how the authors should implement this exploration or what specific steps they should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an interesting direction for future work by proposing the application of the DEER method to other methods like LEM or UnICORNN. It questions whether these methods would maintain the same performance and if better performance could be achieved with the DEER method due to its potential for faster training and hyperparameter tuning. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. It is specific in suggesting an exploration of this idea, but without explicit references to sections or figures, the authors may need to infer the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting direction for future work by proposing the application of the DEER method to other methods like LEM or UnICORNN. It questions whether these methods would maintain the same performance and if better performance could be achieved with the DEER method due to its potential for faster training and hyperparameter tuning. However, the comment lacks specific examples or references to support the claim that these methods could be trained with the DEER method and whether they would maintain the same performance or achieve better performance. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment 2.", "helpfulness_rationale": "The review comment suggests an interesting direction for future work by proposing the application of the DEER method to other methods like LEM or UnICORNN. It questions whether these methods would maintain the same performance and if better performance could be achieved with the DEER method due to its potential for faster training and hyperparameter tuning. This feedback provides a clear and actionable suggestion for the authors to explore, which could strengthen the paper and broaden its impact. However, the comment could be more helpful if it included specific examples or references to support the claims about the potential performance improvements. Overall, the comment is 4 as it offers a valuable direction for future research but lacks some depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the presentation is hard to follow due to the excessive use of notations. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the presentation, such as suggesting alternative ways to present the information or reducing the number of notations used. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the presentation of the paper, noting that it is hard to follow due to the excessive use of notations. However, it does not specify which part of the paper is affected by this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is 1 as it does not provide clear references to specific sections, tables, or figures. Additionally, it lacks specificity in detailing what aspects of the notation usage are problematic. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation is hard to follow because too many notations are used. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without detailed examples or references, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the paper, noting that it is hard to follow due to the excessive use of notations. While this feedback highlights a potential area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue. Without specific advice on how to reduce the number of notations or improve the clarity of the presentation, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a problem but does not provide sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including results from GPT4V, noting that its API is not yet released but that quick experiments using ChatGPT\"s UI are sufficient. This provides a clear and explicit action for the authors to take, as they know exactly what additional results to include. The comment is specific in its suggestion and offers a practical approach to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including results from GPT4V, noting that its API is not yet released but that quick experiments using ChatGPT\"s UI are sufficient. However, the comment does not specify which part of the paper this suggestion relates to, such as a specific section or table. This makes it difficult for the authors to identify the exact area where the additional results should be included. While the suggestion is specific in its content, the lack of grounding makes it challenging for the authors to apply it effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including results from GPT4V, noting that its API is not yet released but that quick experiments using ChatGPT\"s UI are sufficient. However, the comment lacks specific details or references to support the claim that the authors should include these results. It does not provide a clear rationale for why these results are important or how they would enhance the paper. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment suggests including results from GPT4V, noting that its API is not yet released but that quick experiments using ChatGPT\"s UI are sufficient. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by incorporating additional results. However, the comment could be more helpful if it included a brief explanation of why these results are important or how they would contribute to the paper. Overall, the comment is 4 as it offers a clear and actionable suggestion, but it could be further improved with additional context or reasoning."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss more what the theoretical analysis means and why CoPur performs better than baselines. While the comment provides a clear direction for improvement, it lacks specific guidance on how to elaborate on the analysis or what aspects of the analysis should be discussed. The suggestion is explicit but somewhat vague, as it does not provide detailed examples or actionable steps for the authors to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss more what the theoretical analysis means and why CoPur performs better than baselines. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more detailed explanation and comparison with baselines, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss more what the theoretical analysis means and why CoPur performs better than baselines. However, the comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or references, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment provides a clear suggestion for improvement by asking the authors to elaborate on the theoretical analysis and explain why CoPur performs better than baselines compared to other methods. This feedback is actionable and offers a specific direction for the authors to enhance their paper by providing more context and detailed comparisons. However, the comment could be more helpful if it included examples or suggested specific areas for discussion. Overall, the feedback is 4 as it guides the authors towards a more comprehensive analysis, but it could be more detailed to fully empower the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the evaluation metrics used in the paper. It highlights that the metrics are mostly for 3D NVS and points out that the keypoint distance metric only assesses the magnitude of motion, not the quality of the motions. Additionally, the comment questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all frames when generating videos. This feedback is explicit and concrete, as it clearly directs the authors to address the limitations of the metrics and the need for a clearer evaluation protocol. The authors can directly apply these suggestions to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Result/eval,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the evaluation metrics, such as the focus on 3D NVS and the lack of clarity regarding the quality of motions assessed by keypoint distance. The comment is specific in detailing what needs to be addressed, including the need for additional metrics and clarification on the evaluation protocol. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reported metrics are mostly for 3D NVS and that the keypoint distance metric only assesses the magnitude of motion, not the quality of the motions. It also questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all frames when generating videos. The comment provides specific examples and questions that require the authors to address the limitations of their evaluation metrics and the need for a clearer protocol. However, it lacks detailed reasoning or references to support these claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the evaluation metrics used in the paper, noting that most metrics are focused on 3D NVS and that the keypoint distance metric only assesses the magnitude of motion, not the quality of the motions. It also raises a question about the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all frames when generating videos. This feedback is clear and actionable, as it directs the authors to address the limitations of their evaluation metrics and the need for a more comprehensive assessment of motion quality. However, the comment could be more helpful if it suggested specific improvements or additional metrics that could be included. Overall, the comment is 4, as it provides valuable insights for improvement but could be expanded to offer more detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern regarding the presentation of pretraining and regularization as incremental additions rather than naturally integrated components. It suggests that this disjointed presentation detracts from the coherence of the paper. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to integrate these components more effectively. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve the coherence of their paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the presentation of pretraining and regularization as incremental additions rather than naturally integrated components, suggesting that this disjointed presentation detracts from the coherence of the paper. However, it does not specify which part of the paper discusses these components or where the authors should make the necessary adjustments. The lack of specific references or sections makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is 1, as it does not provide clear guidance on which parts of the paper need revision. It is also not specific because it does not detail what needs to be addressed to integrate these components more effectively. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of pretraining and regularization as incremental additions detracts from the coherence of the paper. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of pretraining and regularization, suggesting that they are presented as incremental additions rather than naturally integrated components. This observation highlights a lack of coherence in the paper, which could detract from its overall impact. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or integrate these components more effectively. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it offers a clear observation but lacks depth and constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explanation regarding the importance of Renyi divergence, particularly for readers unfamiliar with differential privacy. While it points out a gap in the paper\"s explanation, it does not provide explicit guidance on how the authors should address this issue. The comment suggests that the authors should clarify the significance of Renyi divergence, but it does not specify which parts of the paper need to be revised or what specific actions should be taken to improve the explanation. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 3.", "grounding_specificity_rationale": "The comment highlights a lack of explanation regarding the importance of Renyi divergence, particularly for readers unfamiliar with differential privacy. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in its critique of the explanation but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the importance of Renyi divergence is not well explained, particularly for readers unfamiliar with differential privacy. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of why this is a significant issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a clearer explanation of the importance of Renyi divergence, especially for readers who may not be familiar with differential privacy. This feedback is valuable as it highlights a potential gap in the paper\"s explanation and suggests that the authors should elaborate on the significance of Renyi divergence. However, the comment could be more helpful if it provided specific guidance on how to explain this concept or included examples to illustrate its importance. Overall, the comment is 3 as it points out a need for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should focus on simplicity and clarity in their work, rather than relying on complex mathematical theories. While it provides a general direction for improvement, it does not specify which parts of the paper need to be revised or how the authors can achieve this. The suggestion is somewhat vague and lacks concrete details, making it difficult for the authors to understand exactly what changes are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should pay more attention to simplicity and clarity in their work, rather than relying on complex mathematical theories. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. This lack of grounding makes it challenging for the authors to identify the exact areas that need improvement. While the comment is specific in its suggestion to focus on simplicity and clarity, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should pay more attention to simplicity and clarity in their work, rather than relying on complex mathematical theories. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and specificity to guide the authors effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should focus on simplicity and clarity in their work, rather than relying on complex mathematical theories. This feedback is 3 as it provides a direction for improvement, encouraging the authors to consider making their work more accessible and easier to understand. However, the comment lacks specific guidance on which parts of the paper need attention or how the authors can achieve this. Without detailed suggestions or examples, the feedback is incomplete and may leave the authors uncertain about how to proceed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the ablation study is limited and recommends further studies on the impact of the predefined threshold \u03f5. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these additional studies or what specific aspects should be explored. The action is implicit, as the authors need to infer that they should perform further ablation studies to understand the impact of the threshold. However, the lack of concrete details on how to implement this action makes the comment 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the ablation study is limited and recommends further studies on the impact of the predefined threshold \u03f5. However, it does not specify which part of the paper the ablation study is located in, nor does it provide any details on what aspects of the threshold should be explored. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is specific in that it identifies a clear area for improvement, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the ablation study is limited and suggests further studies on the impact of the predefined threshold \u03f5. However, the comment lacks specific details or references to support this claim. It does not provide examples of what aspects of the threshold should be explored or how these studies would be conducted. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a limitation in the ablation study, specifically noting that the impact of the predefined threshold \u03f5 is not sufficiently explored. This feedback is valuable as it highlights an area where the authors could strengthen their analysis and provide a more comprehensive understanding of the model\"s behavior. However, the comment lacks specific guidance on how to conduct these additional studies or what aspects of the threshold should be investigated. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers insight but could be more comprehensive with additional guidance. This aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the evaluation methodology, noting that only RougeL is used, which may not be reliable, especially for classification tasks where it is not sensitive enough. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or what alternative evaluation methods could be considered. The lack of guidance on how to improve the evaluation process leaves the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"RougeL\" for evaluation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a limitation in the evaluation methodology, noting that only RougeL is used, which may not be reliable, especially for classification tasks where it is not sensitive enough. This provides clear guidance on what needs to be addressed in the evaluation process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that only RougeL is used for evaluation, which makes the evaluation less reliable, particularly for classification tasks where RougeL is not sensitive enough. While the comment identifies a potential issue with the evaluation methodology, it lacks specific examples or references to support the claim. The authors may infer that the lack of other evaluation metrics could affect the reliability of the results, but the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation methodology, specifically the use of only RougeL, which may not be reliable for classification tasks. This feedback is valuable as it highlights a potential issue with the evaluation process and suggests that alternative metrics could be considered to enhance the reliability of the results. However, the comment could be more helpful if it provided specific examples of tasks where RougeL is known to be less sensitive or suggested alternative evaluation methods. Overall, the comment offers a clear point of improvement but lacks depth in its suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the definitions of variables in the paper, specifically mentioning that the definitions do not match Equation 3 and that the variable n_k is not found in the equation. This provides a clear and direct action for the authors to take, which is to verify and correct the definitions of the variables to ensure they align with the formula. The comment is explicit and concrete, as it clearly specifies which part of the paper needs attention and what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 580588, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the issue with the definitions of variables not matching Equation 3 and the absence of n_k in the equation. This provides the authors with a clear understanding of what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definitions of variables do not properly match Equation 3 and that the variable n_k is not found in the equation. This claim is supported by the specific mention of lines 580588, which allows the authors to locate the relevant section of the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to independently verify the definitions and the equation to confirm the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the definitions of variables in the paper, noting that they do not align with Equation 3 and that the variable n_k is not present in the equation. This feedback is clear and actionable, as it directs the authors to a specific part of the paper where the definitions need to be corrected. By addressing this issue, the authors can improve the accuracy and consistency of their work. The comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive if it suggested specific ways to correct the definitions or provided examples of how the variables should be defined. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this approach might conflict with the samplespecific assumptions of the paper. It also mentions that some key experiments are missing. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to resolve them. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this approach might conflict with the samplespecific assumptions of the paper. It also mentions that some key experiments are missing. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue of a single vector strategy, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this approach might conflict with the samplespecific assumptions of the paper. It also mentions that some key experiments are missing. However, the comment lacks specific examples or references to support the claim about the conflict with samplespecific assumptions or the missing experiments. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this approach might conflict with the samplespecific assumptions of the paper. It also points out that some key experiments are missing. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or what changes could be made to the methodology or experiments. While it identifies potential weaknesses, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 2, as it offers limited insight and guidance for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a key limitation of the work, specifically the assumption of known intent classes during graph construction, and questions the comparability of the IntenDD experiments reported in Table 1 to the cited baselines. The comment suggests that the authors should clarify the intent discovery experiment setting to ensure fair comparison. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potentially make changes to the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a key limitation of the work, specifically the assumption of known intent classes during graph construction, and questions the comparability of the IntenDD experiments reported in Table 1 to the cited baselines. However, the comment does not specify which part of the paper discusses the graph construction or the intent discovery evaluation, making it weakly grounded. It is specific in identifying the issue with the assumption of known intent classes and questioning the comparability of the results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, specifically questioning whether the assumption of known intent classes during graph construction affects this comparability. While the comment identifies a potential issue, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for clarification and potentially make changes to the draft. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a key limitation of the work, specifically the assumption of known intent classes during graph construction, and questions the comparability of the IntenDD experiments reported in Table 1 to the cited baselines. This feedback is valuable as it highlights a potential issue that could affect the fairness of the comparison with existing methods. However, the comment could be more helpful if it provided additional guidance on how the authors might address this limitation or clarify the experimental setup. While it prompts the authors to consider the comparability of their results, it lacks detailed suggestions or actionable steps to improve the draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the rigor of the experimentation but questions the significance of the results, suggesting that the application of dseparation criteria in intervened graphs with known variables and causal relationships might be limited. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which could simplify the problem. However, the comment does not provide explicit or implicit suggestions on how to address these issues or improve the significance of the results. The authors are left without clear guidance on how to enhance their work, making the comment 1.", "grounding_specificity_rationale": "The comment acknowledges the rigor of the experimentation but questions the significance of the results, suggesting that the application of dseparation criteria in intervened graphs with known variables and causal relationships might be limited. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which could simplify the problem. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the results and the experimental setup but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the significance of the results, suggesting that the application of dseparation criteria in intervened graphs with known variables and causal relationships might be limited. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which could simplify the problem. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail and evidence.", "helpfulness_rationale": "The review comment acknowledges the rigor of the experimentation but questions the significance of the results, particularly regarding the application of dseparation criteria in intervened graphs with known variables and causal relationships. It suggests that this application might be limited. Additionally, the comment points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which could simplify the problem. However, the comment does not provide specific suggestions or guidance on how to address these issues or enhance the significance of the results. While it identifies areas for improvement, it lacks actionable advice, making it 3 as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the alignment of gradientbased saliency methods with the feature selection mechanisms in the human brain. While it raises a valid concern about the appropriateness of the chosen methods, it does not provide explicit guidance on how the authors should address this issue or what alternative methods might be more suitable. The comment lacks concrete suggestions or actions for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the alignment of gradientbased saliency methods with feature selection mechanisms in the human brain, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its critique of the methodological approach, suggesting that it may not align with the underlying mechanisms in the human brain. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the alignment of gradientbased saliency methods with feature selection mechanisms in the human brain. While it raises a valid concern about the appropriateness of the chosen methods, it does not provide specific examples or references to support the claim. The comment lacks detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the alignment of gradientbased saliency methods with feature selection mechanisms in the human brain. This critique highlights a potential limitation in the methodology used to evaluate the importance of feature map channels. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative methods could be considered. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to conduct further research or seek additional feedback to fully address the concern. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the model choice used in the paper, specifically noting that Pythia is not stateoftheart (SOTA) despite having available checkpoints. While the comment identifies a potential issue with the model choice, it does not provide explicit guidance on how the authors should address this concern or what alternative models might be considered. The action is implicit, as the authors would need to infer that they should explore more SOTA models or justify their choice of Pythia. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment addresses the model choice used in the paper, specifically mentioning that Pythia is not stateoftheart (SOTA) despite having available checkpoints. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or table. This makes it weakly grounded, as the authors cannot confidently determine where the comment applies. The comment is specific in that it identifies a potential issue with the model choice, suggesting that the authors should consider more SOTA models or justify their choice of Pythia. However, without explicit references to a specific part of the paper, the authors may need to infer the section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper uses Pythia, which is not stateoftheart (SOTA), despite having available checkpoints. This claim is 3 as it highlights a potential issue with the model choice, but it lacks specific examples or references to support the assertion that Pythia is not SOTA. The authors would need to provide additional context or evidence to fully understand the basis of this claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the model choice used in the paper, specifically noting that Pythia is not stateoftheart (SOTA) despite having available checkpoints. While the comment highlights a concern, it does not provide specific guidance or suggestions on how the authors might address this issue or consider alternative models. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for the authors to consider, such as providing more information to challenge the community on the image observation version of Franka Kitchen, exploring the reasons for the failure of existing works, and suggesting alternative data sources. However, the comment does not explicitly instruct the authors on how to address these points or what specific actions they should take. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and suggestions regarding the image observation version of Franka Kitchen, the reasons for the failure of existing works, and the potential for alternative data sources. However, it does not specify which part of the paper these questions or suggestions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is fully grounded in terms of whether it addresses a specific part of the paper, but it is not specific in terms of what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the image observation version of Franka Kitchen, the reasons for the failure of existing works, and the potential for alternative data sources. However, it does not provide any specific evidence, reasoning, or references to support these claims. The questions are openended and lack detailed explanations or examples, making it difficult for the authors to understand the basis of the feedback. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions for the authors to consider regarding the image observation version of Franka Kitchen, the reasons for the failure of existing works, and the potential for alternative data sources. While the comment identifies areas for improvement and exploration, it lacks specific guidance or actionable advice on how to address these points. The questions are openended and do not provide detailed feedback or suggestions for improvement, making it 3. The authors may gain some insights but would need to infer the necessary steps to implement the suggestions, which limits the comment\"s helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors to provide insight into why the multilingual model is \"noticeably weaker\" on specific evaluations. While it prompts the authors to explain this observation, it does not explicitly instruct them to provide specific details or actions to address this issue. The action is implicit, as the authors need to infer that they should provide an explanation for the observed weakness. However, the comment lacks concrete guidance on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment questions the authors to provide insight into why the multilingual model is \"noticeably weaker\" on specific evaluations (ET\u2192En and LV\u2192EN). However, it does not specify which part of the paper these evaluations are discussed in, making it difficult for the authors to pinpoint the exact section or table. The comment is specific in its request for explanation but lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors to provide insight into why the multilingual model is \"noticeably weaker\" on specific evaluations. However, it does not offer any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to infer the reasoning behind the observation, making the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the multilingual model on specific evaluations, noting that it is \"noticeably weaker\" compared to other evaluations. This feedback is valuable as it highlights a potential area for improvement or further investigation. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what steps they could take to enhance the model\"s performance. While it identifies a weakness, it does not provide detailed insights or recommendations for improvement, making it 3. The authors would need to infer that they should investigate the reasons behind the weaker performance and consider potential solutions, which limits the comment\"s helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on the meaning of numbers in brackets within tables 1 and 2. While it does not explicitly instruct the authors to provide this information, it implies that they should clarify this aspect to improve the readability and understanding of the tables. The action is implicit, as the authors need to infer that they should explain the meaning of the numbers in brackets. However, the comment lacks concrete guidance on how to clarify this aspect, such as suggesting specific ways to explain the numbers or providing examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"tables#1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of numbers in brackets within these tables, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the meaning of numbers in brackets within tables 1 and 2. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review comment is specific and directly addresses a question about the meaning of numbers in brackets within tables 1 and 2. It prompts the authors to clarify this aspect, which is crucial for understanding the data presented in the tables. However, the comment lacks broader context or suggestions on how to improve the clarity or presentation of the tables. While it provides a clear direction for improvement, it does not offer comprehensive guidance or insights that could enhance the overall quality of the paper. Therefore, the comment is 3, as it identifies a specific area for clarification but does not provide extensive feedback or actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions, particularly in the context of longterm fairness. While it acknowledges the understanding of the paper\"s focus on RDRO and convergence analysis, it does not provide explicit guidance on how to address this connection or how to parse the results in the context of longterm fairness. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the connection between the presented RDRO results and the listed limitations of previous fairness notions, particularly in the context of longterm fairness. However, it does not specify which part of the paper these limitations are discussed or how the results relate to them. The authors are left to infer that the comment pertains to the discussion of limitations, but without explicit references to sections or figures, the grounding is weak. The comment is specific in its request for clarification regarding the connection between the results and the limitations, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions, particularly in the context of longterm fairness. While the comment acknowledges the understanding of the paper\"s focus on RDRO and convergence analysis, it does not provide specific examples or references to support the claim that the results connect to the limitations. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the connection between the presented RDRO results and the listed limitations of previous fairness notions, particularly in the context of longterm fairness. It acknowledges the understanding of the paper\"s focus on RDRO and convergence analysis but raises a valid concern about how the results relate to the limitations discussed. However, the comment lacks detailed guidance or suggestions on how to address this connection or how to parse the results in the context of longterm fairness. While it points out a potential gap in the discussion, it does not provide actionable steps for the authors to take, making it 3. The feedback is clear but could be more comprehensive with additional suggestions or examples to enhance the authors\" understanding and improve the draft\"s clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the accuracy of the results, specifically questioning the 29 percent accuracy with table assembly tasks and the high Euclidean distance error units in Table 1. It suggests that the errors might be normalized per datapoint position and asks if an error of 5 cm with HDRIL is unreasonably high. While the comment identifies specific issues and questions, it does not provide explicit guidance on how the authors should address these concerns or what changes might be necessary. The action is implicit and somewhat vague, as the authors need to infer the need for further analysis or discussion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the accuracy of the results and the error units in Table 1, particularly questioning the 29 percent accuracy and the high Euclidean distance errors. It also asks for clarification on whether the errors are normalized per datapoint position. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is good as it clearly identifies the areas that need attention, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the accuracy of the results and the high error units in Table 1, questioning whether the errors are normalized per datapoint position. The comment provides specific examples and questions, which could be considered as a form of implicit feedback. However, it lacks detailed reasoning or references to support the claims, making it 3. The authors would need to infer the need for further analysis or discussion, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the accuracy of the results, noting that 29 percent accuracy with table assembly tasks is rather low. It also points out the high Euclidean distance error units in Table 1, questioning whether they are normalized per datapoint position. The comment raises a valid concern about the unreasonably high error of 5 cm with HDRIL, which could indicate a need for further analysis or clarification. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out specific areas that require attention, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the article provides a fresh perspective but does not reach a conclusion. It also implies that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment does not provide explicit guidance on what the authors should do to address this issue or how they might improve the article to reach a conclusion. The action is implicit and vague, as it does not specify what needs to be done to reach a conclusion or how the authors can address the claim about existing models. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the article provides a fresh perspective but does not reach a conclusion, implying that the authors should consider how to reach a conclusion. However, it does not specify which part of the paper this issue is related to, such as the conclusion section or a specific section where the authors discuss their findings or future directions. Additionally, the comment does not provide specific guidance on how to reach a conclusion or what aspects of the article need to be addressed to achieve this. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the article provides a fresh perspective but does not reach a conclusion, suggesting that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or examples, the claim remains 1, as it does not provide a clear path for the authors to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the article provides a fresh perspective but does not reach a conclusion, implying that the authors should consider how to reach a conclusion. It also points out that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences, which may indicate a need for further exploration or differentiation in the article\"s contribution. However, the comment lacks specific guidance on how the authors might address these issues or what changes could be made to the article to reach a conclusion. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm design is based on a predefined labeler strategy. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the theoretical results or algorithm design need to be improved. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the theoretical results, noting that they are not surprising and have limited contribution to the algorithm design. It also mentions that the algorithm design is based on a predefined labeler strategy. However, the comment does not specify which part of the paper contains the theoretical results or the algorithm design, making it difficult for the authors to pinpoint the exact sections being addressed. Additionally, while it provides some context, it lacks specific details on what aspects of the results or design need improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm design is based on a predefined labeler strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the results are not surprising or have limited contribution. Without concrete evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the theoretical results, suggesting that they are not surprising and have limited contribution to the algorithm design. It points out that the algorithm design is based on a predefined labeler strategy, which may limit its novelty. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address this issue or enhance the contribution of their work. While it raises a valid concern, the lack of detailed guidance or constructive suggestions makes it 3, as it provides a starting point for the authors to consider but does not fully support their improvement efforts. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper. First, it points out that the effectiveness of the reverse chain in multiAPI planning is not detailed, which could be a significant gap in the paper. Second, it critiques the paper for focusing on comparing tools or methods in API calling and planning, suggesting that this reduces the research contribution. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the paper. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two issues regarding the paper: first, it questions the detailed explanation of how the reverse chain proved effective in multiAPI planning, and second, it critiques the paper for focusing on comparing tools or methods in API calling and planning, suggesting that this reduces the research contribution. However, the comment does not specify which part of the paper discusses the reverse chain or the comparison of tools, making it difficult for the authors to pinpoint the exact sections that need attention. While the issues are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two claims: first, that the effectiveness of the reverse chain in multiAPI planning is not detailed, and second, that the paper focuses on comparing tools or methods, which reduces research contribution. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is vague and does not provide a clear explanation of why these issues are significant or how they impact the paper. As a result, the claim is barely verifiable, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: first, it questions the detailed explanation of how the reverse chain proved effective in multiAPI planning, and second, it critiques the paper for focusing on comparing tools or methods, which reduces the research contribution. While the comment highlights areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point recommends rejection of the paper based on the identified weaknesses, particularly in experimental rigour, content space, and degree. It also suggests that the significant editing required to address other issues may be unrealistic in terms of time and space. However, the comment does not provide explicit guidance on how the authors should address these weaknesses or what specific changes might be necessary. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment recommends rejection of the paper based on weaknesses in experimental rigour, content space, and degree. However, it does not specify which part of the paper these weaknesses are related to, making it difficult for the authors to pinpoint the exact issues. The comment is fully grounded in terms of identifying the area of concern, but it lacks specificity in detailing what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point recommends rejection of the paper based on weaknesses in experimental rigour, content space, and degree. However, it does not provide specific evidence or reasoning to support these claims. The comment lacks detailed explanations or references to substantiate the assertion that these weaknesses cannot be addressed within the constraints of time, space, or degree. Without concrete examples or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment recommends rejection of the paper based on identified weaknesses, particularly in experimental rigour, content space, and degree. It acknowledges that these issues may be difficult to address within the constraints of time, space, or degree, suggesting that the paper may not be suitable for acceptance. However, the comment does not provide specific guidance or suggestions on how the authors might address these weaknesses or what changes could be made to improve the paper. While it offers a clear rationale for rejection, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the competition between standalone Medusa and Medusa+ParallelSpec due to differences in their draft model architectures. It questions whether the speedup gain is due to the change in architecture or the parallel prediction of draft tokens. The comment suggests that a baseline should be provided where only the draft model architecture is altered, or the modified setting should be given a different name to avoid confusion. However, the comment does not explicitly instruct the authors to provide this baseline or clarify the naming of the modified setting. The action is implicit and somewhat vague, as the authors need to infer how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the fairness of the competition between standalone Medusa and Medusa+ParallelSpec, focusing on the differences in their draft model architectures. It highlights that the Medusa heads are organized in an MLPlike architecture in the original setup, while the adapted version uses a singlelayer Transformer model. The comment questions the extent to which the speedup gain is due to the change in architecture versus parallel prediction of draft tokens. It suggests providing a baseline where only the draft model architecture is altered or renaming the modified setting to avoid confusion. However, the comment does not explicitly mention specific sections or parts of the paper, making it weakly grounded. It is specific in detailing the issue and suggesting a solution, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the competition between standalone Medusa and Medusa+ParallelSpec due to differences in their draft model architectures. It questions whether the speedup gain is due to the change in architecture or the parallel prediction of draft tokens. The comment suggests that a baseline should be provided where only the draft model architecture is altered, or the modified setting should be given a different name to avoid confusion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide references or logical reasoning to support the assertion that the current setup might be unfair. As a result, the claim is 3, as it provides a basis for concern but lacks sufficient evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the competition between standalone Medusa and Medusa+ParallelSpec due to differences in their draft model architectures. It highlights that the original Medusa setup uses an MLPlike architecture, while the adapted version uses a singlelayer Transformer model. The comment questions whether the speedup gain is due to the change in architecture or the parallel prediction of draft tokens. It suggests providing a baseline where only the draft model architecture is altered or renaming the modified setting to avoid confusion. This feedback is 3 as it identifies a potential issue and offers a suggestion for improvement, but it could be more comprehensive if it provided more detailed guidance or examples of how to address the concern. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the focus on Masked Language Models (MLMs) and suggests that experiments might not have worked out with an autoregressive Language Model (LM). However, it does not provide explicit guidance or suggestions on how the authors should address these questions or what changes might be necessary. The comment lacks concrete actions or detailed feedback, leaving the authors uncertain about how to proceed. As a result, the comment is 1, as it does not offer clear or actionable steps for the authors to take to improve their draft. Therefore, it aligns with a score of 1.", "grounding_specificity_rationale": "The comment raises questions about the focus on Masked Language Models (MLMs) and suggests that experiments might not have worked out with an autoregressive Language Model (LM). However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors may need to infer that the comment relates to the introduction or methodology sections where the choice of model is discussed. The comment is specific in questioning the rationale behind the focus on MLMs, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the focus on Masked Language Models (MLMs) and suggests that experiments might not have worked out with an autoregressive Language Model (LM). However, it does not provide any specific reasoning, examples, or references to support these claims. The comment lacks detailed justification or evidence to substantiate the concerns raised, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises questions about the focus on Masked Language Models (MLMs) and suggests that experiments might not have worked out with an autoregressive Language Model (LM). However, it does not provide specific feedback or suggestions on how the authors might address these concerns or what changes could be made to improve the draft. The comment lacks actionable guidance, leaving the authors without clear direction on how to respond or enhance their work. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How is the map encoded?\" and \"Second, the authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" The first question is explicit and directly asks for clarification on the encoding process, providing a clear action for the authors to take. However, the second part of the comment is implicit, as it suggests that the authors should have included results on specific experiments from YNet but does not provide explicit guidance on how to address this issue. The action is partially explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment raises two questions: \"How is the map encoded?\" and \"Second, the authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" The first question is specific and directly relates to the encoding process, allowing the authors to identify the relevant part of the paper. However, the second part of the comment is vague and does not specify which experiments from YNet are being referred to, making it difficult for the authors to pinpoint the exact area that needs improvement. Therefore, the comment is weakly grounded but specific in the first part and underspecific in the second. This aligns with a score of 3.", "verifiability_rationale": "The review point raises two questions: \"How is the map encoded?\" and \"Second, the authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" The first question is a direct inquiry about a specific aspect of the paper, which is verifiable by examining the methodology section. The second part of the comment suggests that the authors should have included results on specific experiments from YNet, but it does not provide specific examples or references to support this claim. This makes the second part of the comment 3, as it lacks detailed justification or examples. Therefore, the overall comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises two key points that could help the authors improve their draft. First, it questions the clarity of how the map is encoded, which is a specific and actionable feedback that the authors can address by providing more detailed explanations or examples. Second, the comment suggests that the authors should have demonstrated the effectiveness of their method on the experiments proposed in YNet, which is a valuable piece of feedback that could enhance the paper\"s impact and credibility. However, the comment could be more helpful if it provided specific guidance on how to show the effectiveness of the method on these experiments. Overall, the feedback is 3 as it identifies important areas for improvement but lacks detailed suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their model. The comment lacks actionable information, leaving the authors without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"2), the proposed model is not more much better than MSA Transformer in terms of r2,\" but it does not specify which part of the paper this refers to. Without knowing the context of the paper, the authors cannot accurately identify the section being addressed. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the model or comparison are being discussed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide any examples, references, or detailed analysis to substantiate the assertion. As a result, the claim is 1 due to the absence of supporting information. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the proposed model is not significantly better than the MSA Transformer in terms of r2. While this observation highlights a potential weakness in the model\"s performance, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their model. The comment lacks actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 2, as it identifies a problem but does not offer constructive feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors need to provide more mathematical details to explain the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling of test error. This action is clear and direct, allowing the authors to understand exactly what needs to be addressed. The comment is specific in its request for additional mathematical details, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"top of page 6,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what the authors need to address: providing more mathematical details to explain the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling of test error. This level of detail helps the authors understand exactly what needs to be added to improve the clarity and depth of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to provide more mathematical details to explain the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling of test error. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors need to provide more mathematical details to explain the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling of test error. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation. However, the comment could be more helpful if it provided some initial guidance or examples of how to approach this explanation. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater depth and guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether the authors have tried using BlenderBot vs 2.0 with incorporated knowledge and suggests that it would be interesting to see how dialogs can be improved by using domain ontologies from the SGD dataset. While the comment implies that the authors should explore this suggestion, it does not provide explicit guidance on how to implement it or what specific aspects of the dialogs need improvement. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the authors have tried using BlenderBot vs 2.0 with incorporated knowledge and suggests that it would be interesting to see how dialogs can be improved by using domain ontologies from the SGD dataset. However, it does not specify which part of the paper this question or suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is 1 as it lacks specific references or context, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether the authors have tried using BlenderBot vs 2.0 with incorporated knowledge and suggests that it would be interesting to see how dialogs can be improved by using domain ontologies from the SGD dataset. However, the comment does not provide any specific reasoning, examples, or references to support the claim that this exploration would be beneficial. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether the authors have explored using BlenderBot vs 2.0 with incorporated knowledge and suggests that it would be interesting to see how dialogs can be improved by using domain ontologies from the SGD dataset. While the comment identifies an area for potential exploration and improvement, it lacks specific guidance or suggestions on how to implement this idea or what aspects of the dialogs might benefit from such an approach. The feedback is 3 as it points out a potential avenue for future work but does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the number of samples rated by GPT4 and whether they overlapped with the human evaluation samples. While it implies that the authors should clarify this information, the comment does not provide explicit instructions or suggestions on how to address this issue. The action is implicit, as the authors need to infer that they should provide more details about the samples used in the evaluation. However, the comment lacks concrete guidance on what specific information needs to be included or how to present it. Therefore, the comment is 3, as it identifies a gap in the paper but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the number of samples rated by GPT4 and whether they overlapped with the human evaluation samples. It implies that this information is important for the calculation of Krippendorff \u03b1, but it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. This makes it weakly grounded, as the authors may need to infer the relevant section. However, the comment is specific in detailing what needs to be clarified, namely the overlap between the samples used by GPT4 and human evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the number of samples rated by GPT4 and whether they overlapped with the human evaluation samples. While it implies that this information is important for calculating Krippendorff \u03b1, it does not provide any specific reasoning or evidence to support why this clarification is necessary. The comment lacks detailed justification or examples, making it difficult for the authors to understand the significance of the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the clarity of the number of samples rated by GPT4 and whether they overlapped with the human evaluation samples. This is important for calculating Krippendorff \u03b1, as the overlap is a crucial factor in assessing interrater reliability. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their methodology. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it 3. The authors would need to infer that they should clarify this information in their paper, but the comment does not offer specific steps or examples to enhance the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the consistency and accuracy of the paper, specifically questioning the difference between argwise consistency and accuracy. It provides an intuition that label annotation agreement should be lower given low predwise consistency. However, the comment does not offer explicit guidance on how the authors should address these issues or what specific actions they should take to improve the consistency and accuracy of their results. The feedback is somewhat vague and lacks concrete steps for the authors to follow, making it 3.", "grounding_specificity_rationale": "The comment raises concerns about the consistency and accuracy of the paper, specifically questioning the difference between argwise consistency and accuracy. It provides an intuition that label annotation agreement should be lower given low predwise consistency. However, the comment does not specify which part of the paper discusses these concepts, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The lack of specific guidance on what needs to be addressed in terms of consistency and accuracy leaves the authors uncertain about how to improve the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the consistency and accuracy of the paper, specifically questioning the difference between argwise consistency and accuracy. It provides an intuition that label annotation agreement should be lower given low predwise consistency. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the consistency and accuracy of the paper, specifically questioning the difference between argwise consistency and accuracy. It provides an intuition that label annotation agreement should be lower given low predwise consistency. However, the comment lacks detailed explanations or suggestions on how the authors might address these issues or improve the consistency and accuracy of their results. While it identifies a potential area for improvement, it does not provide actionable guidance or specific steps for the authors to take. Therefore, the comment is 3, as it highlights a critical aspect of the paper that needs attention but does not offer comprehensive feedback. The score aligns with a rating of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically how position embeddings are provided, could enhance reproducibility. It also recommends sharing the code of their implementation, which is considered the most crucial aspect for reproducibility. The comment explicitly suggests two actions: providing more details on the parametrization and sharing the code. These actions are concrete and direct, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing more details on the neural network parametrization of the reverse process, specifically how position embeddings are provided, to enhance reproducibility. It also recommends sharing the code of their implementation, which is considered the most crucial aspect for reproducibility. However, the comment does not specify which part of the paper discusses the neural network parametrization or the reverse process, making it weakly grounded. While it is specific in suggesting what needs to be addressed, the lack of grounding makes it difficult for the authors to identify the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, could enhance reproducibility. It also recommends sharing the code of their implementation, which is considered the most crucial aspect for reproducibility. However, the comment lacks specific examples or references to support the claim that these details are missing or insufficient. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the comment is considered 2, as it provides a suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the reproducibility of the paper. It suggests that providing more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, could enhance reproducibility. Additionally, it recommends sharing the code of their implementation, which is considered the most crucial aspect for reproducibility. These suggestions are actionable and directly address potential issues with reproducibility, offering clear guidance for the authors to improve their draft. However, the comment could be more helpful if it provided more specific examples or guidance on how to implement these suggestions. Overall, the feedback is 4, as it offers valuable insights and actionable advice for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that the first paragraph of section 3.3 contains a repeated paragraph. This is a clear and explicit action that the authors can take to address the issue. The comment specifies exactly what needs to be corrected, making it 5. The authors know precisely where the repetition occurs and can easily revise the paragraph to remove the redundancy. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a repeated paragraph in this section, providing a clear indication of what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of section 3.3 contains a repeated paragraph. This is a factual observation that does not require any additional evidence or reasoning to be considered valid. The comment is clear and specific, allowing the authors to understand the issue and take action to address it. Therefore, this comment is classified as \"3\" as it is factual but lacks explicit reasoning or references, yet it is clear enough to be considered verifiable.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely that the first paragraph of section 3.3 contains a repeated paragraph. This is a clear and actionable feedback that the authors can easily address by revising the paragraph to remove the redundancy. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reusability and sustainability of synthetic data, which is relevant to the topic of onthefly data generation. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete actions or detailed advice on how to improve the draft, leaving the authors without a clear path forward. As a result, the comment is 1, as it does not offer actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment raises a question about the reusability and sustainability of synthetic data, which is relevant to the topic of onthefly data generation. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is 1 as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity in addressing the question, as it does not provide detailed guidance or examples on how to improve the reusability and sustainability of synthetic data. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the reusability and sustainability of synthetic data, which is relevant to the topic of onthefly data generation. However, it does not provide any specific claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support the question. Therefore, it is classified as \"No\" because it lacks any claim or assertion that needs to be verified.", "helpfulness_rationale": "The review comment raises a pertinent question about the reusability and sustainability of synthetic data, which is relevant to the topic of onthefly data generation. This question highlights an important consideration for the authors to address, as it pertains to the practicality and longterm viability of their approach. However, the comment does not provide any suggestions or guidance on how the authors might improve their draft or address this issue. Without actionable advice or insights, the comment is 3 as it identifies a potential area for improvement but lacks depth and direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two specific areas where the authors could improve their work. First, it points out that the likelihood of alternative RNA structures being dictated by biological circumstances is not examined, which is a significant oversight. Second, it suggests that the authors should consider RNA abundance when building datasets. These suggestions are explicit and provide clear guidance on what needs to be addressed in the paper. The authors can directly apply these actions to enhance the completeness and accuracy of their work. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the introduction of the ProbTransfomer model and its application to solving the challenge of RNA folding. It highlights a specific issue regarding the likelihood of alternative RNA structures being dictated by biological circumstances, which the authors do not examine. Additionally, it suggests considering RNA abundance when building datasets. However, the comment does not specify which part of the paper discusses the introduction of the ProbTransformer model or the datasets used. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in identifying the issues, the absence of explicit references to the paper\"s sections limits its effectiveness. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors should consider RNA abundance when building datasets, as the likelihood of alternative RNA structures is dictated by biological circumstances. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without clear justification or evidence, the claim remains 3, as it lacks the necessary details to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the authors could improve their work. First, it points out that the likelihood of alternative RNA structures being dictated by biological circumstances is not examined, which is a significant oversight. Second, it suggests that the authors should consider RNA abundance when building datasets. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance the completeness and accuracy of their work. By addressing these points, the authors can strengthen their analysis and improve the robustness of their findings. Therefore, the comment is 5, as it offers detailed and constructive feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of a single entropic regularization coefficient in the numerical results, suggesting that it might be a weak regularization term leading to sparse couplings. The comment implies that this observation should be acknowledged in the paper, but it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit, as the authors need to infer that they should discuss the implications of using a single regularization coefficient and acknowledge it in the paper. However, the lack of concrete instructions on how to implement this suggestion makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a concern about the use of a single entropic regularization coefficient in the numerical results, suggesting that it might be a weak regularization term leading to sparse couplings. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the regularization coefficient, the absence of explicit references to the paper limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of a single entropic regularization coefficient in the numerical results, suggesting that it might be a weak regularization term leading to sparse couplings. The comment implies that this observation should be acknowledged in the paper, but it does not provide specific examples or references to support the claim that a single coefficient is insufficient. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the numerical results by pointing out that only a single entropic regularization coefficient is considered, which might be a weak regularization term leading to sparse couplings. The comment suggests that this observation should be acknowledged in the paper, implying that the authors should discuss the implications of using a single regularization coefficient. However, the comment lacks specific guidance on how to address this issue or what changes should be made to the paper. While it provides a clear observation, it does not offer actionable advice or detailed suggestions for improvement, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the information presented in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table claims the dataset has no evidence, while the paper mentions that sources were collected for the analysis. However, the comment does not provide explicit guidance on how the authors should address this inconsistency or what specific actions they should take to resolve it. The action is implicit and vague, as it leaves the authors to infer that they need to clarify or correct the information in Table 1. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the inconsistency between the information in Table 1 and the text regarding the Vlachos and Riedel 2014 dataset, specifying that the table claims the dataset has no evidence while the paper mentions sources were collected. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 incorrectly states that the Vlachos and Riedel 2014 dataset has no evidence, while the paper itself mentions that sources were collected for the analysis. This claim is 3 as it provides a specific example of an inconsistency between the table and the text, allowing the authors to understand the issue. However, it lacks detailed reasoning or references to support the claim fully, which could make it challenging for the authors to address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between the information presented in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table claims the dataset has no evidence, while the paper mentions that sources were collected for the analysis. This feedback is clear and actionable, as it highlights a factual discrepancy that needs to be addressed. However, the comment could be more helpful if it provided guidance on how the authors might correct or clarify the information in Table 1. Despite this, the comment is 4 as it directs the authors to a specific area of concern, allowing them to improve the accuracy and consistency of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include details about the parameters used for each simulator, such as whether they used the GPU or CPU pipeline, the substeps for physics simulation, and the number of total vertices. This provides a clear and explicit action for the authors to take, as they know exactly what information needs to be added to their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to include details about the parameters used for each simulator, such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices. This provides clear guidance on what information is missing and why it is important. The comment is also specific, as it clearly specifies the parameters that need to be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include details about the parameters used for each simulator, such as whether they used the GPU or CPU pipeline, the substeps for physics simulation, and the number of total vertices. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with a classification of \"No.\"", "helpfulness_rationale": "The review comment provides specific guidance on what information is missing in the draft, particularly regarding the parameters used for different simulators. It highlights the importance of including details such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices. This feedback is clear and actionable, as it directs the authors to add crucial details that could enhance the clarity and completeness of their work. By addressing this feedback, the authors can significantly improve the quality and reproducibility of their research. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the generalizability of the proposed loss function due to the empirical selection of hyperparameters $s$ and $k$ as 5 based on crossvalidation. It suggests that the choice of these hyperparameters is crucial for the effectiveness of the method. However, the comment does not provide explicit guidance on how the authors might address this issue or what steps they should take to improve the generalizability of their loss function. The action is implicit and vague, as it does not specify how the authors can make their choice of $s$ and $k$ more generalizable. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of the generalizability of the proposed loss function due to the empirical selection of hyperparameters $s$ and $k$ as 5 based on crossvalidation. It highlights that the choice of these hyperparameters is crucial for the effectiveness of the method. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the empirical selection, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the choice of hyperparameters $s$ and $k$ is crucial for the effectiveness of the proposed method but only provides an empirical selection based on crossvalidation in the supplementary material. This claim is 3 as it highlights a potential issue with the generalizability of the method due to the specific choice of hyperparameters. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the generalizability of the proposed loss function due to the empirical selection of hyperparameters $s$ and $k$ as 5 based on crossvalidation. It highlights that the choice of these hyperparameters is crucial for the effectiveness of the method, but the lack of a more generalizable approach reduces the robustness of the findings. While the comment points out a significant concern, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the generalizability of their method. The feedback is 3 as it directs the authors to consider the broader implications of their hyperparameter choices, but it lacks actionable advice for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the optimization times of their method with OpenTuner, which adaptively uses different search techniques. However, it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the optimization times should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors only use simulated annealing and suggests comparing optimization times with OpenTuner, which uses adaptive search techniques. This provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare the optimization times of their method with OpenTuner, which adaptively uses different search techniques. However, the comment lacks specific details or references to support this claim, such as examples of how the comparison should be conducted or why this comparison is necessary. Without these details, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered 2, as it provides a general direction but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors compare their optimization times with OpenTuner, which adaptively uses different search techniques. This feedback is actionable as it provides a clear direction for the authors to enhance their work by conducting a comparative analysis. However, the comment could be more helpful if it included specific guidance on how to perform the comparison or what aspects of the optimization times should be analyzed. Despite this, the comment offers valuable insight into a potential area for improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited novelty of the work, suggesting that it does not introduce a novel idea but rather applies existing concepts to a new area. It mentions specific examples of related works that have introduced diffusion models into anomaly detection, such as [1], [2], and [3]. The comment also notes that the work primarily adapts an existing model, NCSN, by combining popular techniques like time step embedding and finding a correspondence between anomaly scores and diffusion scores. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the novelty of their work. The action is implicit and vague, as the authors are left to infer what changes are needed to enhance the paper\"s originality. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limited novelty\" of the work and provides specific examples of related works that have introduced diffusion models into anomaly detection, such as [1], [2], and [3]. It also highlights that the work primarily adapts an existing model, NCSN, by combining popular techniques. This allows the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the limited novelty and the adaptation of NCSN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work is limited in novelty, as it does not introduce a novel idea but rather applies existing concepts to a new area. It provides specific examples of related works that have introduced diffusion models into anomaly detection, such as [1], [2], and [3]. The comment also notes that the work primarily adapts an existing model, NCSN, by combining popular techniques like time step embedding and finding a correspondence between anomaly scores and diffusion scores. However, the comment lacks detailed reasoning or references to support the claim about the limited novelty. While it provides some context, it does not fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited novelty of the work. It points out that many existing studies have already introduced diffusion models into the anomaly detection area, citing specific examples. This critique is valuable as it highlights the need for the authors to differentiate their work or provide a more compelling justification for its originality. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue, such as by exploring novel applications or techniques that distinguish their work from existing approaches. Without specific recommendations, the feedback is 3, as it provides a clear direction for improvement but lacks depth and actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the paper: the presence of grammar errors and the lack of labels on the axes of Figure 2. While it points out the specific instances of grammar errors, it does not provide explicit instructions on how to correct them or suggest specific ways to improve the writing. Similarly, the comment notes the missing labels on Figure 2\"s axes but does not offer guidance on how to add or label them. The feedback is somewhat vague, as it lacks concrete actions for the authors to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies two specific issues with the paper: the presence of grammar errors and the lack of labels on the axes of Figure 2. It provides explicit references to these issues, allowing the authors to accurately pinpoint the parts of the paper that need attention. However, the comment does not specify what needs to be addressed in terms of correcting the grammar errors or adding labels to the axes. While the authors can infer that they need to correct the grammar and add labels, the lack of specific guidance makes the comment somewhat grounded and specific. Therefore, it aligns with category 3.", "verifiability_rationale": "The review point claims that the paper has many grammar errors and that Figure 2\"s axes are not labeled. However, it does not provide any specific examples or references to support these claims. Without detailed examples or references, the authors may find it challenging to verify the accuracy of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the presence of numerous grammar errors and the lack of labels on the axes of Figure 2. While it points out these areas for improvement, it does not provide detailed guidance on how to correct the grammar errors or how to add labels to the axes. The feedback is 3 as it highlights areas that need attention, but it lacks depth and actionable suggestions, making it only marginally helpful for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the error analysis in section 5.2 is lacking and recommends a more quantitative approach. While the comment implies that the authors should consider adding a more quantitative error analysis, it does not explicitly instruct them to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the error analysis section with more quantitative data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the error analysis in section 5.2 is lacking and recommends a more quantitative approach. However, it does not specify which part of section 5.2 is problematic or what specific aspects of the error analysis need improvement. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the need for a more quantitative error analysis, but without further details, it is difficult for the authors to understand how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that a more quantitative approach would be beneficial. However, the comment lacks specific details or examples to support this claim. It does not provide any references or reasoning to justify why the current error analysis is inadequate or why a quantitative approach would be more effective. Without this additional information, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the error analysis in section 5.2, suggesting that it is lacking and recommending a more quantitative approach. While the comment points out a specific area for improvement, it does not provide detailed guidance or suggestions on how to enhance the error analysis. The feedback is 3 as it directs the authors to consider a more quantitative approach, but it lacks depth and specificity, making it incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using ProxyA distance in addition to tSNE for evaluating distribution alignment, referencing a specific paper [6]. It also points out a potential issue with Figures 6c and 6d, suggesting that the ProxyA distance might be close, implying a need for crosschecking. While the comment provides explicit guidance on what should be done (using ProxyA distance) and suggests a specific action (crosschecking the figures), it lacks detailed instructions on how to implement these suggestions or what specific aspects of the figures need to be examined. The action is somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment suggests using ProxyA distance in addition to tSNE for evaluating distribution alignment, referencing a specific paper [6]. It also points out a potential issue with Figures 6c and 6d, suggesting that the ProxyA distance might be close, implying a need for crosschecking. However, the comment does not explicitly mention which part of the paper discusses the evaluation of distribution alignment or the figures themselves. The authors can infer that it relates to the evaluation section and the figures, but this inference is not direct. The comment is specific in suggesting an additional metric and pointing out a potential issue with the figures, but it lacks full grounding as it does not explicitly mention the sections or figures being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using ProxyA distance in addition to tSNE for evaluating distribution alignment, referencing a specific paper [6]. It also points out a potential issue with Figures 6c and 6d, suggesting that the ProxyA distance might be close, implying a need for crosschecking. While the suggestion to use ProxyA distance is logical and aligns with common practices in evaluating distribution alignment, the comment lacks specific examples or detailed reasoning to fully support the claim. The reference to crosschecking the figures is also vague and does not provide clear guidance on how to perform this check. Therefore, the claim is 3, as it provides a basis for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the evaluation of distribution alignment by suggesting the use of ProxyA distance in addition to tSNE. It also points out a potential issue with Figures 6c and 6d, suggesting that the ProxyA distance might be close, implying a need for crosschecking. While the comment offers actionable advice and identifies a specific area for improvement, it could be more helpful if it provided more detailed guidance on how to implement the suggestion or what specific aspects of the figures need to be examined. Overall, the feedback is 3 as it directs the authors towards a more comprehensive evaluation approach, but it lacks depth and specificity in its recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and suggests exploring the performance of reinforcement algorithms for all phrases. While it prompts the authors to consider these aspects, it does not provide explicit guidance on how to address these questions or what specific actions should be taken. The actions are implicit and somewhat vague, as the authors are left to infer how to respond. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines L216217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and suggests exploring the performance of reinforcement algorithms for all phrases. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and suggests exploring the performance of reinforcement algorithms for all phrases. However, it does not provide any specific reasoning, examples, or references to support these claims. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises specific questions about the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and suggests exploring the performance of reinforcement algorithms for all phrases. This feedback is valuable as it prompts the authors to consider alternative approaches and potentially improve the robustness of their method. However, the comment lacks detailed guidance or suggestions on how to address these questions or what specific experiments or analyses might be needed. While it identifies an area for improvement, it does not provide comprehensive feedback that would fully enhance the authors\" understanding or actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the proposed crossmodality adaptation has been validated in BEVDepth [1] and 2DPASS [2], but the paper did not discuss these in the related work section. This feedback suggests that the authors should include a discussion of these works in the related work section to provide a more comprehensive context for their research. The action is explicit, as it clearly instructs the authors to address the missing discussion of related work. However, the comment lacks specific guidance on how to integrate these works into the discussion, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed crossmodality adaptation\" and provides specific references, \"BEVDepth [1]\" and \"2DPASS [2]\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies that the paper did not discuss these works in the related work section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper did not discuss the validation of the proposed crossmodality adaptation in the related work section, specifically mentioning BEVDepth [1] and 2DPASS [2]. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the paper did not include this discussion. Therefore, the claim is considered 2, as it provides some basis for the comment but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that the proposed crossmodality adaptation has been validated in BEVDepth [1] and 2DPASS [2], but the paper does not discuss these works in the related work section. This feedback is clear and actionable, as it directs the authors to include a discussion of these related works to provide a more comprehensive context for their research. By addressing this gap, the authors can enhance the depth and completeness of their paper, making it more informative and impactful. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more detailed with specific suggestions on how to integrate these works into the discussion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the presentation of results in Table 1, noting that it only includes test loss as a metric for performance degradation and lacks generation results like BLEU scores. This feedback is explicit and provides a clear action for the authors to take: they should include generation results such as BLEU scores to provide a more comprehensive assessment of the output quality. The comment is concrete, as it specifies exactly what needs to be added to the table to improve its comprehensiveness. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the table, noting that it only presents test loss as a metric for performance degradation and lacks generation results such as BLEU scores. This provides the authors with a clear understanding of what needs to be addressed to improve the comprehensiveness of the results presented in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 only presents test loss as a metric for performance degradation and lacks generation results such as BLEU scores. This claim is 3 as it provides a specific observation about the content of Table 1, but it does not offer detailed reasoning or examples to support why the inclusion of BLEU scores is necessary or how they would enhance the assessment of output quality. While the comment identifies a potential improvement, it lacks the depth needed for full verifiability. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only includes test loss as a metric for performance degradation and lacks generation results such as BLEU scores. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of BLEU scores to better assess the quality of the output. By addressing this issue, the authors can enhance the comprehensiveness and robustness of their results, making the paper more informative and impactful. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide experiments to validate their analysis, particularly for discussions on different regimes. However, it does not specify which regimes or how these experiments should be conducted. The comment lacks explicit guidance on what kind of experiments would be beneficial or how they should be integrated into the paper. While the authors understand the need for additional validation, the comment does not provide concrete steps or suggestions on how to achieve this. Therefore, the comment is 3, as it identifies a clear area for improvement but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the authors should provide experiments to validate their analysis, especially for discussions on different regimes. However, it does not specify which part of the paper these discussions are located in, making it difficult for the authors to pinpoint the exact areas that need validation. The comment is specific in its suggestion to include experiments, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide experiments to validate their analysis, particularly for discussions on different regimes. However, the comment lacks specific details or examples of how these experiments should be conducted or what kind of validation is needed. Without additional information or references, the claim is difficult to verify, making it 2. The authors would need to infer the need for more experimental validation, which limits the comment\"s effectiveness.", "helpfulness_rationale": "The review comment suggests that the authors should provide experiments to validate their analysis, especially for discussions on different regimes. This feedback is 3 as it identifies a specific area where the paper could be strengthened by including empirical evidence. However, the comment lacks specificity regarding which regimes or types of experiments would be most beneficial, making it 3 but not fully comprehensive. The authors would need to infer the need for additional validation, which limits the depth of the feedback. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not specify how these baselines should be implemented or what insights they should offer. The action is implicit, as the authors need to infer that they should add these baselines and provide detailed explanations of their implementation and expected outcomes. The lack of concrete guidance makes the action somewhat vague and challenging to execute. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or table. The authors may need to infer that this comment pertains to the experimental setup or results section, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of these baselines, but without grounding, the authors may struggle to identify the exact part of the paper to address. Therefore, this comment is 3, aligning with label 3.", "verifiability_rationale": "The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not provide any specific reasoning, examples, or references to support why these baselines are necessary or how they would offer valuable insights. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. While this feedback offers a potential direction for improving the paper by exploring additional baselines, it lacks specificity and depth. The comment does not explain why these baselines are necessary or how they would contribute to the overall understanding of the benchmark. Without detailed guidance or examples, the authors may struggle to incorporate these suggestions effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide comprehensive guidance for action."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the overall algorithm being cumbersome and having multiple stages, contrasting it with existing pruning methods that do not require finetuning. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might simplify the algorithm or make it more efficient. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall algorithm being cumbersome and having multiple stages, contrasting it with existing pruning methods that do not require finetuning. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or aspect being addressed. The comment is specific in its critique of the algorithm\"s complexity but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the overall algorithm is cumbersome and has multiple stages, contrasting it with existing pruning methods that do not require finetuning. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed evidence or comparisons, the claim remains 3, as it is based on a general observation without clear justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the overall algorithm being cumbersome and having multiple stages, contrasting it with existing pruning methods that do not require finetuning. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential weakness in the algorithm\"s design, but it does not provide actionable steps or detailed insights to help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the justification for the new quantile function (3) compared to the existing function (2), noting that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment does not provide explicit guidance on how the authors should address this issue or what data or reasoning should be included to support the claim. The action is implicit and vague, as the authors are left to infer that they need to provide supporting data or reasoning to justify the change. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the advantage of a new quantile function (3) compared to an existing one (2), specifically noting that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment does not specify which part of the paper discusses these functions or where the comparison is made, leaving the authors to infer that it relates to the methodology or results sections. The comment is specific in detailing the change and the issue with sensitivity, but it lacks grounding as it does not explicitly mention the section or part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is unjustified, as it changes the multiplicative factors into an additive term, making the function less sensitive to tail parameters when they are large. The comment provides a logical explanation of the change and its implications, but it lacks specific examples or references to support the claim that the reduced sensitivity is desired. Without additional evidence or reasoning, the claim is 3, as it is based on logical reasoning but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the new quantile function, noting that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. It questions the justification for this change, as the paper does not provide supporting data on why the reduced sensitivity is desired. This feedback is 3 as it highlights a potential gap in the paper\"s reasoning and suggests that the authors should provide more evidence or reasoning to support the change. However, the comment could be more helpful if it offered specific guidance on how to address this issue or what data could be included to justify the change. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two specific issues with the paper: the confusion of Figure 3 and the low contribution of the benchmark over SWEBench. It suggests that the authors should improve the clarity of Figure 3 and provide a more detailed explanation of the benchmark\"s contributions. However, the comment does not offer explicit guidance on how to improve the figure or elaborate on the contributions. The actions are implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the contribution over SWEBench, including the implicit testing of fault localization capabilities and the unnecessary use of LLMs for issue generation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is confusing and suggests that the contribution over SWEBench is low. It provides two reasons for this claim: (1) if a model can fix a bug, it inherently involves fault localization, making the repair benchmarks implicitly testing this capability, and (2) when a unit test fails, an LLM can be used to generate issues automatically, making the LLM\"s contribution for issue generation redundant. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims. The logical reasoning is present but could be strengthened with more detailed explanations or references. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the confusion of Figure 3 and the low contribution of the benchmark over SWEBench. It provides a detailed explanation of why the contribution might be low, suggesting that the implicit testing of fault localization capabilities in repair benchmarks and the unnecessary use of LLMs for issue generation might reduce the novelty of the benchmark. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as providing examples of how the benchmark could be improved or how the contribution could be better articulated. Overall, the comment is 3 as it highlights important areas for improvement but lacks actionable advice, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that some key descriptions are missing. It provides a clear question about the selection process for complementary attributes in topic control experiments. However, the comment does not offer any guidance or suggestions on how to address this issue or improve the clarity of the paper. The authors are left without any actionable steps to take, as the comment lacks explicit instructions or concrete advice. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue related to the selection of complementary attributes in topic control experiments, which is a part of the methodology section. However, it does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. The authors can infer that the comment pertains to the methodology section, but the lack of explicit mention or detailed guidance makes it difficult for them to pinpoint the exact part of the paper that needs improvement. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point highlights a specific issue regarding the selection of complementary attributes in topic control experiments, noting that some key descriptions are missing. However, the comment does not provide any evidence, reasoning, or references to support the claim that these descriptions are missing or that the selection process is unclear. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that some key descriptions are missing, particularly regarding the selection of complementary attributes in topic control experiments. This feedback is clear and actionable, as it points out a specific area where the paper lacks clarity and provides a clear question for the authors to address. However, the comment could be more helpful if it offered suggestions or guidance on how to improve the clarity of these descriptions. Overall, the comment is 3 as it highlights a specific area for improvement, but it lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the generalizability of the system identification method in simtoreal policy deployment, noting that the realworld manipulation only contains a single case. While the comment highlights a potential issue with the limited scope of the manipulation, it does not provide explicit guidance on how the authors might address this concern or what steps they should take to strengthen their claims. The action is implicit, as the authors need to infer that they should consider expanding the realworld manipulation or providing more evidence to support the generalizability of their method. However, the lack of concrete suggestions or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of realworld manipulation containing only a single case, which raises concerns about the generalizability of the system identification method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it clearly identifies the concern about the limited scope of realworld manipulation and its impact on the generalizability of the method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the system identification method based on the limited scope of realworld manipulation, which only contains a single case. This claim is 3 as it highlights a potential limitation in the experimental setup, but it lacks specific examples or references to support the claim. The authors could strengthen the comment by providing additional details or examples to substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the system identification method, noting that the realworld manipulation only contains a single case. This observation is important because it questions the robustness and applicability of the method in broader scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their claims. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should consider expanding their realworld manipulation or providing more evidence to support the generalizability of their method. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the quality of the ShortcutQA, specifically questioning whether the edits might introduce ambiguity, which could lead to performance degradation. It suggests that the authors provide details about the \"answerability\" of the distracted texts and request examples and qualitative results to support their claims. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to demonstrate the \"answerability\" of the distracted texts or how to provide qualitative results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors need to address, namely the potential introduction of ambiguity in the edits and the degradation in performance. The request for details about the \"answerability\" of distracted texts and examples of qualitative results provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the quality of the ShortcutQA, specifically questioning whether the edits might introduce ambiguity, potentially leading to performance degradation. The comment suggests that the authors provide details about the \"answerability\" of the distracted texts and request examples and qualitative results to support their claims. However, the comment lacks specific examples or references to substantiate the claim about the potential introduction of ambiguity. While it identifies a potential issue, it does not provide sufficient evidence or guidance for the authors to address it effectively. Therefore, the claim is 3, as it is based on a logical concern but lacks detailed support.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the ShortcutQA, specifically questioning whether the edits might introduce ambiguity, which could lead to performance degradation. It requests detailed information about the \"answerability\" of the distracted texts and asks for examples and qualitative results to support the claims. This feedback is 3 as it identifies a potential issue and provides a clear direction for the authors to address it. However, the comment could be more helpful if it offered specific guidance on how to demonstrate the \"answerability\" of the distracted texts or suggested methods for generating qualitative results. Overall, the comment provides a useful starting point for the authors to improve their draft, but it could be more comprehensive and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" This is an explicit action that the authors can readily understand and implement. The comment provides a clear direction for improvement, specifying exactly what needs to be added to enhance the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" However, it does not specify which part of the paper this definition is located in, making it difficult for the authors to identify the exact section that needs clarification. While the comment is specific about the need for a forward pointer, it lacks grounding as it does not provide enough context for the authors to locate the relevant part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" However, it does not provide any specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" This feedback is specific and actionable, as it provides a clear direction for improvement. By adding a forward pointer, the authors can enhance the clarity and readability of the paper, making it easier for readers to understand the concept being discussed. However, the comment could be more helpful if it provided additional context or examples of how this clarification would benefit the overall understanding of the paper. Despite this, the feedback is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a practical question about the number of archetypes k in the presented framework and suggests exploring model selection techniques to identify an appropriate k. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to perform model selection or what specific methods to use. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a practical question about the number of archetypes k in the presented framework and suggests exploring model selection techniques to identify an appropriate k. However, it does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide clear guidance on where to find the relevant information or how to implement the model selection process. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a practical question about the number of archetypes k in the presented framework and suggests exploring model selection techniques to identify an appropriate k. However, it does not provide any specific reasoning, examples, or references to support why this is a critical issue or how it might impact the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a practical question about the number of archetypes k in the presented framework and suggests exploring model selection techniques to identify an appropriate k. This feedback is 3 as it points out a potential area for improvement and encourages the authors to consider a more robust approach to determining the optimal number of archetypes. However, the comment lacks specific guidance or suggestions on how to implement model selection or what methods to use, which limits its impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly points out a missing element, Theorem 1, and notes that Theorem 2 is present at the beginning of page 6. It also suggests that the counting of assumptions, lemmas, and theorems should be separated. This feedback is clear and provides a direct action for the authors to take, which is to ensure that Theorem 1 is included and that the counting is separated. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"Theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the counting of assumptions, lemmas, and theorems, providing clear guidance on what needs to be separated. This level of detail ensures that the authors understand exactly what part of the paper requires attention and what specific issue needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Theorem 1 is missing from the paper, specifically noting that Theorem 2 is present at the beginning of page 6. While the comment identifies a factual error in the paper\"s content, it does not provide any additional reasoning, examples, or references to support the claim. The authors would need to independently verify the presence of Theorem 1 to fully understand the issue. Therefore, the claim is 3, as it is based on a factual observation but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Theorem 1 is missing, while Theorem 2 is present at the beginning of page 6. It also suggests that the counting of assumptions, lemmas, and theorems should be separated. This feedback is clear and actionable, providing the authors with a direct instruction to address the missing theorem and improve the organization of the paper. However, the comment could be more helpful if it offered additional guidance on how to separate the counting or suggested specific ways to improve the clarity of the paper. Overall, the comment is 4 as it highlights important areas for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, specifically in the context of long document summarization. While it raises a valid concern about the generalizability of this assumption, it does not provide explicit or implicit guidance on how the authors might address this issue or what changes could be made to their draft. The comment lacks concrete suggestions or actionable steps for the authors to consider, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, specifically in the context of long document summarization. However, it does not specify which part of the paper this assumption is made or where the authors discuss it. The comment is vague and does not provide any guidance on how the authors might address this issue or what changes could be made to their draft. As a result, the comment is 1 and lacks specificity, making it 1.", "verifiability_rationale": "The review point questions the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of long document summarization. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed justification or examples to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of long document summarization. While the comment questions the generalizability of this assumption, it does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their draft. The feedback is 3 as it identifies a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method is straightforward and that its novelty is marginal. It also points out a lack of clarity in certain aspects, specifically mentioning line 180 where multiple different graphs are mentioned. However, the comment does not provide explicit guidance on how to address these issues or improve the clarity of the method. The authors are left to infer that they need to clarify the method and address the concerns raised, but without specific instructions on what to do, the action is implicit and vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed method and its straightforward nature, suggesting that the novelty is marginal. It also points out a lack of clarity in certain aspects, specifically mentioning line 180 where multiple different graphs are discussed. However, the comment does not provide specific guidance on how to address these issues or improve the clarity of the method. The authors are left to infer that they need to clarify the method and address the concerns raised, but without explicit references to specific sections or detailed suggestions, the comment is weakly grounded. It is also specific in identifying the areas of concern, such as the straightforward nature of the method and the lack of clarity in line 180. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is straightforward and that its novelty is marginal, suggesting that some parts are not clear to the authors. It provides an example by questioning how multiple different graphs can be obtained if different weights are learned for an edge. However, the comment lacks specific examples or references to support the claim about the method\"s straightforwardness or the lack of clarity. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2, as it provides some basis for the claim but lacks sufficient detail or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the straightforward nature of the proposed method and the lack of clarity in certain aspects, particularly regarding the generation of multiple different graphs. It provides a specific example, questioning how multiple graphs can be obtained if different weights are learned for an edge, which highlights a potential issue with the method\"s complexity or parameter management. However, the comment does not offer detailed guidance or suggestions on how to address these concerns or improve the clarity of the method. While it points out areas for improvement, it lacks actionable advice, making it 3. The authors would need to infer how to address the issues raised, but the feedback is not comprehensive enough to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the scope of the experiments, noting that only two simulation experiments are conducted, one on a unit sphere and another on spiral curves. It suggests that a more complex example, such as learning the geometry of a more complicated manifold, would be beneficial. However, the comment does not provide explicit guidance on how to expand the experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more complex examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments conducted, including the unit sphere and spiral curves, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an example of learning the geometry of a more complicated manifold, providing clear guidance on what additional experiments would be beneficial. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited in scope, noting that only two simulation experiments are conducted, one on a unit sphere and another on spiral curves. It suggests that a more complex example, such as learning the geometry of a more complicated manifold, would be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the experiments are limited or how to address the suggested improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments conducted, noting that only two simulation experiments are presented, one on a unit sphere and another on spiral curves. It suggests that a more complex example, such as learning the geometry of a more complicated manifold, would be beneficial. This feedback is 3 as it points out a specific area for improvement, but it lacks detailed guidance on how to expand the experiments or what specific aspects to focus on. The authors are left to infer the need for additional experiments, which limits the actionable value of the comment. Therefore, it aligns with a score of 3, indicating that the comment provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the paper, noting that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of Large Language Models (LLMs). However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the template or how to demonstrate the full use of LLM capabilities. Without specific suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a weakness in the paper, noting that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of Large Language Models (LLMs). However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. While the comment identifies a general area of concern, it lacks specificity in terms of what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of Large Language Models (LLMs). However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of Large Language Models (LLMs). This feedback highlights an area where the authors could improve their work by enhancing the naturalness and effectiveness of their approach. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples of how to improve the template or demonstrating the full use of LLM capabilities. Without actionable advice, the authors may find it challenging to effectively address the identified weakness. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed guidance for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the number of baselines used in the study, suggesting that it is small and may limit the universality and generality of the results. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to increase the number of baselines or what specific baselines should be included to enhance the study\"s scope. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what is meant by \"a bit small\" or how this limitation affects the universality and generality of the results. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the number of baselines is small, which degrades the universality and generality of the results. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the number of baselines is small, which could limit the universality and generality of the results. While the comment highlights an important consideration for the authors to address, it lacks specific guidance or suggestions on how to increase the number of baselines or what additional baselines could be included to enhance the study\"s scope. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it provides a clear area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of information regarding the tokenizer training, specifically mentioning the absence of details about the mixture of corpus sizes used and the software stack. While it points out a missing element, it does not provide explicit guidance on what information should be included or how to address this gap. The action is implicit, as the authors would need to infer that they should provide details about the tokenizer training to improve the paper. However, the comment lacks concrete instructions on what specific information to include, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"tokenizer training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of information regarding the mixture of corpus sizes used and the software stack, which are crucial details for practical implementation. The comment provides clear guidance on what information is missing, making it 5.", "verifiability_rationale": "The review point claims that there is no information about the tokenizer training, specifically mentioning the absence of details about the mixture of corpus sizes used and the software stack. This claim is 3 as it highlights a missing element that could impact the reproducibility and practical application of the research. However, the comment lacks specific examples or references to support the claim, making it 3 rather than 5.", "helpfulness_rationale": "The comment identifies a significant gap in the paper by pointing out the lack of information regarding the tokenizer training, specifically mentioning the absence of details about the mixture of corpus sizes used and the software stack. This is a crucial piece of information for reproducibility and practical implementation, as the software stack and corpus size can significantly impact the results. However, the comment could be more helpful if it provided suggestions on what specific information should be included or how to address this gap. Overall, the feedback is 3 as it highlights a critical area for improvement, but it lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of the additional complexity in the proposed method, specifically regarding the cotraining, positive mining, and alternate optimization steps. It suggests that the paper does not adequately address whether these steps are essential. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for further analysis or justification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the comparison to a prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of the additional complexity and the contributions of the proposed method over prior work. However, the comment does not provide specific guidance on what needs to be addressed or how to address it, making it somewhat specific. Therefore, the comment is fully grounded and somewhat specific, aligning with category 4.", "verifiability_rationale": "The review point raises a question about the necessity of the additional complexity in the proposed method, specifically regarding the cotraining, positive mining, and alternate optimization steps. It suggests that the paper does not adequately address whether these steps are essential. However, the comment lacks specific examples or detailed reasoning to support the claim that the additional complexity is not warranted. Without further elaboration or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a critical question about the necessity of the additional complexity in the proposed method, specifically regarding the cotraining, positive mining, and alternate optimization steps. It suggests that the paper does not adequately address whether these steps are essential, leaving the authors uncertain about the value of the proposed method. While the comment identifies a significant gap in the paper\"s justification, it lacks specific guidance on how the authors might address this issue or what additional analysis could be conducted to strengthen the paper. The feedback is 3 as it points out a crucial area for improvement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the approach, specifically the computational cost of multimarginal OT and spline calculations, which could limit scalability for large datasets. It suggests that a more comprehensive discussion is required to address this issue. However, the comment does not provide explicit guidance on how to improve the discussion or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the discussion on computational cost. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational cost of multimarginal OT and spline calculations, suggesting that this limitation could affect the scalability of the approach for large datasets. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in identifying the problem but lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the computational complexity of multimarginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for realworld applications. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the approach, specifically the computational cost of multimarginal OT and spline calculations, which could limit scalability for large datasets. This is a relevant concern for realworld applications, as it highlights a potential bottleneck in the approach. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the discussion. While it points out a critical area for improvement, it does not provide actionable advice or detailed insights into potential solutions. Therefore, the comment is 3, as it raises an important concern but does not offer comprehensive guidance for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point claims that nonuniform label noise is not common in practice, but it contradicts this claim by referencing a specific paper that shows its widespread existence in realworld datasets like Clothing1M. This feedback highlights a potential inconsistency in the authors\" claim and suggests that it should be reconsidered. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and vague, as the authors are left to infer that they need to either revise their claim or provide evidence to support it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" claim about nonuniform label noise and provides a specific reference to a paper that contradicts this claim. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what the authors should consider, namely that nonuniform label noise is widely observed in realworld datasets, and suggests that their claim should be reconsidered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonuniform label noise is not common in practice, but it contradicts this claim by referencing a specific paper that shows its widespread existence in realworld datasets like Clothing1M. The comment provides a clear reference to support the claim, making it 5. This allows the authors to understand the basis of the claim and potentially address it in their draft. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the prevalence of nonuniform label noise. It points out that a specific paper contradicts this claim, suggesting that the authors should reconsider their assertion. This feedback is clear and actionable, as it provides a specific reference that challenges the authors\" claim and directs them to relevant literature. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or what additional evidence they could include to support their claim. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the evaluation methodology in Section 6.2, noting that the authors used only 10 samples. This observation suggests that the limited sample size might have led to biased findings. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or what steps they should take to improve their evaluation. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the limited sample size of 10 samples, which may have resulted in biased findings. This provides the authors with a clear understanding of what needs to be addressed in the evaluation methodology. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in Section 6.2 was based on only 10 samples, which may have resulted in biased findings. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this limited sample size could lead to biased findings. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation methodology in Section 6.2, noting that the authors used only 10 samples. This observation suggests that the limited sample size might have resulted in biased findings due to the small scale of the experiment. While the comment highlights a concern, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their evaluation methodology. Without actionable advice or detailed recommendations, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is 3, as it points out a potential weakness but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. While the authors acknowledge this limitation, the comment does not provide explicit guidance on how to address it or suggest specific actions to improve the method\"s generalizability. The feedback is somewhat vague, as it does not offer concrete steps or examples for the authors to consider. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the method is tailored to similar MILP tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this limitation may limit the method\"s generalizability to significantly different combinatorial optimization problems, which the paper acknowledges but does not address experimentally. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The comment acknowledges this limitation but does not provide specific examples or references to support the claim. While the authors are aware of this limitation, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks, which may restrict its generalizability to significantly different combinatorial optimization problems. While the authors acknowledge this limitation, the comment does not provide specific suggestions or guidance on how to address it or improve the method\"s generalizability. This feedback is 3 as it highlights an important area for consideration, but it lacks actionable advice or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the authors\" attempt to bridge a gap in the description of their baseline in the Results section, specifically mentioning the lack of clarity in understanding how these baselines work and their relation to InterFair. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the clarity of their description. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" attempt to bridge a gap in the description of their baseline in the Results section, specifically mentioning the lack of clarity in understanding how these baselines work and their relation to InterFair. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section. The comment is specific in its critique of the clarity of the description but lacks grounding as it does not provide explicit references to the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the description of the baselines in the Results section, specifically questioning how they work and their relation to InterFair. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the baselines are not sufficiently competitive. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the baselines in the Results section, particularly concerning their relation to InterFair and their competitiveness. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. It does not provide specific examples, detailed explanations, or actionable steps that the authors could take to improve the clarity of their description. As a result, the feedback is 3, as it highlights a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific guidance or suggestions on how the authors should improve this comparison. The comment lacks explicit actions or concrete details on what needs to be added or improved to make the comparison more comprehensive. As a result, the authors are left without a clear understanding of how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the authors are referring to when discussing the comparison to other baselines on cycle counting and ZINC. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is specific in that it identifies a lack of sufficiency in the comparison, but without grounding, the authors are left without a clear understanding of where to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the comparison is insufficient or how it could be improved. This lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the comparison to other baselines on cycle counting and ZINC is insufficient. However, the comment lacks depth and specificity, as it does not provide any suggestions or guidance on how the authors might address this issue. Without additional details or recommendations, the authors are left without actionable feedback on how to enhance the comparison. Therefore, the comment is 2, as it points out a problem but does not offer a comprehensive or constructive response."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. This comment implies that the authors should provide a detailed rationale for the effectiveness of this specific combination, which would enhance the clarity and understanding of the paper. However, the comment does not specify how to implement this suggestion, such as by adding a detailed explanation or analysis in the paper. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that it would benefit from a clearer explanation of why a particular combination of mask snippets is effective, while most similar ones are not. This feedback is valuable as it highlights a potential gap in the paper\"s explanation and provides a direction for the authors to enhance their work. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to address this issue or what aspects of the explanation need to be clarified. While it offers a starting point for improvement, the feedback could be more helpful if it included specific suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the performance of the SLQ method compared to the CRD method, noting that SLQ appears to be less competitive based on F1 score and conductance values. It also points out that in Figure 3, SLQ shows worse performance than CRD, and in Figure 4, the improvement of SLQ over ACL is minimal. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the performance of SLQ. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the SLQ method compared to the CRD method, specifically mentioning the F1 score and conductance values. It also refers to Figures 3 and 4, which are likely to contain the relevant data. However, the comment does not specify which parts of the paper these figures are located in, making it weakly grounded. The comment is specific in detailing the performance issues and the discrepancies observed in the figures, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of SLQ, as quantified by F1 score and conductance values, is limited compared to the CRD method. It also notes that in Figure 3, SLQ shows worse performance than CRD, and in Figure 4, the improvement of SLQ over ACL appears to be minimal. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the SLQ method compared to the CRD method, noting that SLQ appears to be less competitive based on F1 score and conductance values. It also points out discrepancies in the performance results presented in Figures 3 and 4. However, the comment does not provide detailed guidance on how the authors might address these performance issues or suggest specific improvements to the method. While it highlights an important area for attention, the feedback lacks actionable advice, making it 3. The authors would need to infer how to improve the performance of SLQ based on the feedback, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should add more baselines for robust performance comparisons, given the existence of ample work. However, it does not specify which baselines should be added or how they should be implemented. The action is implicit, as the authors need to infer that they should include more baselines, but it lacks concrete guidance on which baselines to add or how to ensure robust comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should add more baselines for robust performance comparisons, given the existence of ample work. However, it does not specify which baselines should be added or how they should be implemented. The comment lacks grounding as it does not mention specific sections or parts of the paper that need improvement. It is also not specific because it does not provide guidance on which baselines to add or how to ensure robust comparisons. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the selection of baselines is limited to naive/old models, despite the existence of ample work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed justification or evidence, the claim remains 3, as it lacks sufficient support to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the selection of baselines used for performance comparisons, noting that the authors have relied primarily on naive or old models. This feedback is valuable as it highlights a critical gap in the evaluation process, suggesting that the inclusion of more contemporary and robust baselines would enhance the credibility and depth of the study. However, the comment could be more helpful if it provided specific examples of recent or advanced models that could be included for comparison. Additionally, it could offer guidance on how to ensure the robustness of the performance comparisons. Despite these minor limitations, the comment provides actionable feedback that encourages the authors to improve their draft, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the choice of target structures in Table 2, specifically noting that only three structures (2816, 7680, 8) were used for evaluation. The comment suggests that this choice might limit the generalizability of the proposed method to other target structures with different dimensions. It implies that the authors should either justify this choice or provide additional experiments to demonstrate the method\"s adaptability to a variety of target structures. This feedback is explicit and provides a clear action for the authors to take, which is to either justify the choice of target structures or conduct additional experiments. The action is concrete, as it specifies exactly what needs to be done to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structures and suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\"s adaptability to a variety of target structures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the choice of target structures in Table 2, specifically questioning why only three structures were used for evaluation. It suggests that this choice might limit the generalizability of the proposed method to other target structures with different dimensions. The comment implies that the authors should either justify this choice or provide additional experiments to demonstrate the method\"s adaptability. However, the comment lacks specific examples or references to support the claim that the chosen structures are insufficient or that the method\"s generalizability is limited. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of target structures in Table 2, noting that only three structures were used for evaluation. This raises concerns about the generalizability of the proposed method to other target structures with different dimensions. The comment suggests that the authors should either justify their choice of target structures or provide additional experiments to demonstrate the method\"s adaptability to a variety of target structures. This feedback is clear and actionable, as it provides a specific direction for the authors to address the concern. By either justifying the choice or conducting additional experiments, the authors can strengthen the robustness and applicability of their method. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper\"s application scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would increase the paper\"s impact and relevance. However, the comment does not provide explicit guidance on how the authors should address this limitation or what specific steps they should take to incorporate more realistic scenarios. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limited application scope of the research, specifically mentioning the focus on the knapsack problem and the neglect of more realistic scenarios like medical diagnosis. However, it does not specify which part of the paper discusses the application scope or the knapsack problem, making it weakly grounded. The comment is specific in identifying the need to explore more realistic scenarios, such as medical diagnosis, to increase the paper\"s impact and relevance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. This claim is 3 as it highlights a limitation in the paper\"s application scope, but it lacks specific examples or references to support the claim. The authors could provide more detailed reasoning or examples to strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s application scope, noting that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. This feedback is valuable as it highlights a gap in the paper\"s exploration of realworld applications, suggesting that expanding the scope to include critical areas like healthcare could significantly increase the paper\"s impact and relevance. However, the comment could be more helpful if it provided specific guidance on how the authors might explore these additional applications or suggested potential areas of research. Overall, the comment is 3, as it offers a clear direction for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the method\"s robustness and sensitivity, suggesting that it does not improve upon the claimed advantages of using evolutionary methods. It also points out that the new method is noisier in two domains and performs equally as the competitors in the remaining areas. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to improve the method\"s robustness and sensitivity or how to revise the claims in the motivation. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the method\"s robustness and sensitivity, suggesting it does not improve upon the claimed advantages of using evolutionary methods. It also points out that the new method is noisier in two domains and performs equally as the competitors in the rest. However, the comment does not specify which part of the paper discusses the method or the results in Figure 3, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the issues with the method\"s performance, it lacks grounding as it does not provide clear references to the relevant sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method does not improve on robustness and sensitivity as claimed in the motivation, and that it is noisier in two domains compared to competitors. However, the comment lacks specific evidence or references to support these claims. It does not provide detailed reasoning or examples to substantiate the assertion that the method is noisier in two domains or equally noisy as competitors in the rest. Without such evidence, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the method\"s robustness and sensitivity, suggesting that it does not improve upon the claimed advantages of using evolutionary methods. It also points out that the new method is noisier in two domains and performs equally as the competitors in the rest, as shown in Figure 3. This feedback is valuable as it highlights a critical weakness in the method\"s performance, which could impact the overall effectiveness of the approach. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the method. Without specific recommendations or steps for improvement, the feedback is 3, as it provides a clear direction for the authors to consider but does not fully empower them to enhance their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the conclusion holds against more sophisticated or more aggressive removal methods. While it raises a valid concern about the robustness of the conclusion, it does not provide explicit guidance on how the authors should address this issue. The comment lacks specific suggestions or actions that the authors can take to investigate or revise their conclusions. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment questions whether the conclusion holds against more sophisticated or more aggressive removal methods, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the issue is being raised. This lack of grounding makes it difficult for the authors to address the concern effectively. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the robustness of the conclusion when considering more sophisticated or aggressive removal methods. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the question as a request for clarification or further investigation, but it lacks the necessary support to be considered verifiable. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the robustness of the conclusion when considering more sophisticated or aggressive removal methods. This is a valuable point that prompts the authors to critically evaluate their findings and potentially expand their analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments or analyses could be conducted to strengthen their conclusions. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable value, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the introduction\"s mention of explainable AI and the paper\"s focus on interpretable methods. It points out that the authors do not define interpretability or explain the difference between the two concepts. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific sections to clarify or expand upon. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context and explanation regarding the concepts of explainable and interpretable AI. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the discrepancy between the introduction mentioning explainable AI and the paper\"s focus on interpretable methods. It highlights that the authors do not define interpretability or explain the difference between the two concepts. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as defining interpretability and explaining the difference between explainable and interpretable AI. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, noting that the authors do not define interpretability or explain the difference between the two concepts. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is considered 2, as it provides some justification but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s introduction, noting that it mentions explainable AI while the paper\"s focus is on interpretable methods. It points out that the authors do not define interpretability or explain the difference between the two concepts, which is a critical oversight. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting additional sections or examples to clarify the concepts. While it highlights a key area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the training data used in the compositionality and transitivity experiments. While it prompts the authors to provide information, it does not explicitly instruct them on what to do with this information or how it should be presented. The action is implicit, as the authors can infer that they need to clarify the training data in their paper. However, the comment lacks concrete guidance on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment asks a question about the training data used in the compositionality and transitivity experiments, but it does not specify which part of the paper this information is relevant to. The authors can infer that it pertains to the methodology or experimental sections, but without explicit references, they cannot confidently determine the exact location. The comment is specific in its request for clarification but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the training data used in the compositionality and transitivity experiments. It does not contain a claim or assertion that requires verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the training data used in the compositionality and transitivity experiments, which is a critical aspect of the methodology. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their experimental design. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is 2, as it identifies a potential area for improvement but does not offer any constructive advice or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the meaning of \"not only the complete captions but also parts thereof\" and questions the unconvincing nature of the argument around why filling in the blanks is hard. It also suggests that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a specific paper [C]. However, the comment does not provide explicit guidance on how the authors should clarify the meaning or address the unconvincing argument. The suggestion to consider bidirectional beam search is vague and lacks detailed instructions on how to implement it. Therefore, the comment is not actionable, as it does not provide clear steps for the authors to take to improve their draft. The comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific part of the paper, as it refers to lines 133134, allowing the authors to accurately identify the section being discussed. It also specifies the issue by questioning the clarity of the term \"not only the complete captions but also parts thereof\" and the unconvincing nature of the argument regarding the difficulty of filling in the blanks. Additionally, the comment suggests that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a specific paper [C]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the clarity of the term \"not only the complete captions but also parts thereof\" and questions the unconvincing nature of the argument regarding the difficulty of filling in the blanks. The comment suggests that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a specific paper [C]. However, the claim lacks detailed reasoning or examples to fully support the assertion that the argument is unconvincing. The reference to bidirectional beam search is vague and does not provide specific guidance on how it could be applied. As a result, the comment is 3, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the meaning of \"not only the complete captions but also parts thereof\" and questions the unconvincing nature of the argument regarding the difficulty of filling in the blanks. It also suggests that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a specific paper [C]. This feedback is 3 as it points out a potential area for clarification and suggests an alternative approach, but it lacks detailed guidance on how to address the issue or incorporate the suggested method. The authors would need to further explore and clarify the meaning of the term and consider the implications of the suggested approach to fully benefit from this feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the use of reverse KL divergence in the training of flows, specifically questioning the assumption of differentiability of the function $g$ and the modeseeking nature of reverse KL. It suggests that this might be a limitation in applications where covering all modes of a density is crucial, such as in rare event sampling. The comment implies that the authors should comment on the realism of the differentiability assumption and discuss the implications of reverse KL being modeseeking. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take. The feedback is 3 as it identifies areas for discussion and consideration, but it lacks concrete suggestions or detailed guidance on how to implement the recommendations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of reverse KL divergence in training flows, specifically questioning the assumption of differentiability of the function $g$ and the modeseeking nature of reverse KL. It suggests that this might be a limitation in applications where covering all modes of a density is crucial, such as in rare event sampling. The comment references a recent line of work for normalizing flows, such as [3], to overcome this limitation. However, the comment does not explicitly mention specific sections or parts of the paper that need to be addressed, making it weakly grounded. It is specific in detailing the issues with reverse KL divergence, such as the differentiability assumption and modeseeking behavior, and suggests that the authors should comment on the realism of the differentiability assumption and discuss the implications of reverse KL being modeseeking. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of reverse KL divergence in training flows, specifically questioning the assumption of differentiability of the function $g$ and the modeseeking nature of reverse KL. It suggests that this might be a limitation in applications where covering all modes of a density is crucial, such as in rare event sampling. The comment references a recent line of work for normalizing flows, such as [3], to overcome this limitation. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims, making it 3. The authors would need to provide more context or evidence to fully understand and address the concerns raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important concerns about the use of reverse KL divergence in training flows, specifically questioning the assumption of differentiability of the function $g$ and the modeseeking nature of reverse KL. It suggests that this might be a limitation in applications where covering all modes of a density is crucial, such as in rare event sampling. The comment references a recent line of work for normalizing flows, such as [3], to overcome this limitation, providing a clear direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address these issues or incorporate the suggested work into their approach. Overall, the feedback is 4 as it identifies key areas for improvement and provides a basis for further discussion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that annotations in the visual event detection stage of ViStruct Suite might contain noise due to the use of an offtheshelf semantic role labeling system. It also implies that a detailed analysis of the curated dataset is necessary. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to address the potential noise. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ViStruct Suite\" and the \"visual event detection stage,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with annotations obtained by an offtheshelf semantic role labeling system, indicating that the authors need to analyze the curated dataset to address the potential noise. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that annotations in the visual event detection stage of ViStruct Suite might contain noise due to the use of an offtheshelf semantic role labeling system. While the comment suggests that a detailed analysis of the curated dataset is necessary, it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the annotations in the visual event detection stage of ViStruct Suite, specifically noting that they might contain noise due to the use of an offtheshelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset is necessary to address this concern. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how to conduct this analysis or what aspects of the dataset might be contributing to the noise. The feedback is 3 as it points out a potential issue, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural/behavioral parallels. It also notes that the sensitivity of the model with respect to n is not discussed. While the comment implies that the authors should provide a more detailed justification for the stopping rule and discuss its sensitivity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural/behavioral parallels. It also notes that the sensitivity of the model with respect to n is not discussed. However, the comment does not specify which part of the paper discusses the model implementation or the stopping rule, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issues with the stopping rule and sensitivity, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural/behavioral parallels. It also notes that the sensitivity of the model with respect to n is not discussed. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the stopping rule is arbitrary or lacks parallels. This lack of substantiation makes the claim 3, as the authors may find it challenging to understand the basis for the critique without further explanation or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the model implementation, namely the lack of justification for the stopping rule with n consecutive identical samples. It points out that the stopping rule seems arbitrary and lacks neural or behavioral parallels, which could be important for understanding its validity. Additionally, the comment notes that the sensitivity of the model with respect to n is not discussed, which is a significant oversight. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable advice, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper. First, it points out that the authors mention the maximum common subgraph detection problem is NPhard but do not provide a time complexity analysis or report the running time of the proposed algorithms. This suggests that the authors should include such analysis to provide a more comprehensive understanding of their method\"s performance. Second, the review point notes that the authors mention the use of a heuristic node pair selection policy in existing methods but claim that their proposed method is a \"learntosearch\" algorithm. It suggests that it would be interesting to see if the proposed method reduces search time compared to stateoftheart algorithms, especially as the number of nodes increases. While the comment identifies two distinct issues, it does not provide explicit guidance on how to address them or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues related to the paper: the lack of time complexity analysis for the proposed algorithms and the absence of a comparison with stateoftheart algorithms regarding search time. It mentions the NPhard nature of the maximum common subgraph detection problem and the use of a heuristic node pair selection policy in existing methods, contrasting it with the \"learntosearch\" algorithm proposed by the authors. The comment is fully grounded as it explicitly mentions the sections or parts of the paper where these issues are relevant, allowing the authors to accurately identify the areas needing attention. It is also specific because it provides clear guidance on what needs to be addressed, such as including time complexity analysis and comparing search time with stateoftheart algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide time complexity analysis or report the running time of the proposed method, despite mentioning the NPhard nature of the maximum common subgraph detection problem. It also suggests that the proposed method, being a \"learntosearch\" algorithm, might reduce search time compared to stateoftheart algorithms. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out that while the authors mention the maximum common subgraph detection problem is NPhard, they do not provide a time complexity analysis or report the running time of the proposed algorithms. This is a significant oversight, as it leaves the reader without a clear understanding of the computational efficiency of the proposed method. Second, the comment notes that the authors mention the use of a heuristic node pair selection policy in existing methods but claim that their proposed method is a \"learntosearch\" algorithm. It suggests that it would be interesting to see if the proposed method reduces search time compared to stateoftheart algorithms, especially as the number of nodes increases. This feedback is valuable as it provides specific areas for the authors to address and improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this analysis or comparison. Overall, the comment is 3, as it identifies important aspects that need attention but could be more detailed in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quality control or manual evaluation in the data collection process, which is conducted using an automatic modelbased approach. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment suggests that the authors should consider implementing quality control or manual evaluation, but it does not specify how to do so or what steps should be taken. Without concrete guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of quality control or manual evaluation in the data collection process, which is conducted using an automatic modelbased approach. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no quality control or manual evaluation of the data collected through an automatic modelbased approach. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the data collection process, specifically the lack of quality control or manual evaluation. This is a critical oversight that could impact the reliability and validity of the results presented in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as proposing specific methods for quality control or manual evaluation. Without actionable advice or examples, the authors may struggle to improve their draft effectively. Therefore, the comment is 3, as it highlights a crucial area for improvement but lacks depth and guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to compare a confidence interval from a small dev set with the Frechet bound. However, it does not provide explicit instructions or detailed guidance on how to conduct this comparison or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most tasks\" and \"a small set of labeled data,\" which are specific parts of the paper being addressed. It also specifies the suggestion to compare a confidence interval from a small dev set with the Frechet bound, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests comparing a confidence interval from a small dev set with the Frechet bound, which is a logical and wellestablished concept in machine learning. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the basis for this comparison, which could be improved by providing more detailed reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors could compare a confidence interval from a small dev set with the Frechet bound. This is a specific and actionable suggestion that could enhance the paper by providing a more comprehensive analysis of the model\"s performance. However, the comment could be more helpful if it provided additional context or guidance on how to conduct this comparison effectively. Overall, the feedback is 3 as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it is only applicable to problems with lowdimensional input spaces. The authors are informed that the largest dimensionality in the experiments is 3, which is attributed to the curse of dimensionality due to the use of finite points in the surrogate modeling of shape constraints. However, the comment does not provide any explicit or implicit suggestions on how to address this limitation or improve the method\"s applicability to higherdimensional problems. The authors are left without guidance on how to modify or enhance their approach to handle more complex scenarios. Therefore, the comment is 1 as it lacks any direction for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation of the proposed method being applicable only to problems with lowdimensional input spaces, which is supported by the fact that the largest dimensionality in the experiments is 3. This provides clear guidance on the scope of the method. However, the comment does not specify what needs to be addressed or how to improve the method\"s applicability to higherdimensional problems. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the proposed method is only applicable to problems with lowdimensional input spaces, citing the largest dimensionality in the experiments as 3. This claim is supported by the reasoning that the method\"s applicability is limited due to the curse of dimensionality, which is a wellknown issue in highdimensional spaces. The comment provides a logical explanation and a specific example to support the claim, making it 4. However, it could be strengthened by including references to specific literature on the curse of dimensionality or examples of how the method might be adapted for higherdimensional problems. Overall, the comment is 4.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method, specifically its applicability to problems with lowdimensional input spaces. It highlights that the experiments conducted have a maximum dimensionality of 3, which is attributed to the curse of dimensionality due to the use of finite points in the surrogate modeling of shape constraints. This feedback is valuable as it points out a critical constraint that the authors should consider when applying their method to more complex problems. However, the comment could be more helpful if it provided suggestions on how to address this limitation or how to extend the method to handle higherdimensional inputs. Despite this, the comment offers a clear insight into a key area that needs attention, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the results presented in Table 1 and Table 2, noting that they are usually within their standard deviations. The reviewer suggests that this observation might not support the claim that the presented method is significantly better than others. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to strengthen their claim. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results, noting that they are usually within their standard deviations and questioning the claim of significant superiority. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 1 and Table 2 are usually within their standard deviations, which might not support the claim that the presented method is significantly better than others. However, the comment lacks specific examples or detailed reasoning to substantiate this claim. It does not provide references or logical arguments to explain why the results being within standard deviations would undermine the claim of significant superiority. Without these details, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment raises a valid concern about the results presented in Table 1 and Table 2, noting that they are usually within their standard deviations. This observation challenges the claim that the presented method is significantly better than others. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their claim. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer what changes might be necessary to address the issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a nontrivial aspect of generating synthetic tabular data, noting that it is common for multiple entries in a table to be associated with the same entity, resulting in additional relationships. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they should consider to improve their work. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the challenge of generating synthetic tabular data, noting that it is nontrivial due to the presence of multiple entries associated with the same entity, leading to additional relationships. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it weakly grounded. It is specific in pointing out a challenge in generating synthetic data, but without clear references to sections or figures, the authors may find it difficult to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a nontrivial aspect of generating synthetic tabular data, specifically mentioning that it is common for multiple entries in a table to be associated with the same entity, resulting in additional relationships. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the significance of this point or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a nontrivial aspect of generating synthetic tabular data, specifically mentioning that it is common for multiple entries in a table to be associated with the same entity, resulting in additional relationships. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their work. It does not provide specific examples, detailed reasoning, or actionable steps for the authors to take. Without these elements, the comment is not particularly helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that it is 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the creation of the AmbiQT benchmark is valuable but questions the lack of broader context or validation on other datasets, which could affect its applicability and relevance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to ensure the benchmark\"s applicability and relevance. The action is implicit and vague, as it leaves the authors to infer the need for additional validation and context. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"AmbiQT benchmark,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of overemphasis on the benchmark without broader context or validation on other datasets, which could affect its applicability and relevance. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an overemphasis on the AmbiQT benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the AmbiQT benchmark, specifically that an overemphasis on this benchmark without broader context or validation on other datasets could raise questions about its applicability and relevance. This feedback is 3 as it highlights a concern that could impact the paper\"s conclusions. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as suggesting additional datasets for validation or discussing the limitations of the current benchmark. Without these details, the authors may struggle to fully understand and address the feedback effectively. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of annotation training details and guidelines, which is crucial for understanding how to handle nonstandard tasks in professional translation. It also mentions the lack of information about the tool used. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete guidance on how to address these issues. The authors are left with a general understanding of what needs to be improved but lack specific steps to take. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to implement them.", "grounding_specificity_rationale": "The comment addresses the lack of annotation training details and guidelines, which is important for professional translators, and mentions the absence of information about the tool used. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the content it critiques, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks annotation training details and guidelines, which are important for professional translators, especially for nonstandard tasks. It also notes the absence of information about the tool used. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains 3, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of annotation training details and guidelines, which are crucial for professional translators, especially when dealing with nonstandard tasks. It also notes the lack of information about the tool used, which is an important aspect for reproducibility and understanding the methodology. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address these gaps. The feedback is 3 as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the boldfacing of the results in Table 1 is appropriate and asks for clarification on the statistical significance of the difference between two values. While the comment implies that the authors should consider the statistical significance of the results, it does not explicitly instruct them to revise the table or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the bolding and statistical significance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the appropriateness of boldfacing in the table and asks for clarification on the statistical significance of the results presented. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the statistical significance of the results presented in Table 1, specifically questioning whether the difference between two values is statistically significant. However, it does not provide any evidence, reasoning, or references to support the claim that the results are not statistically significant. Without additional context or justification, the authors are left to make their own judgment, making the comment 1.", "helpfulness_rationale": "The review comment raises a specific question about the statistical significance of the results presented in Table 1, particularly concerning the boldfacing of the results. It challenges the authors to consider whether the difference between two values is statistically significant. While the comment identifies a potential issue with the presentation of results, it does not provide detailed guidance or suggestions on how to address the statistical significance or improve the table\"s clarity. The feedback is 3 as it prompts the authors to reconsider the presentation of their results, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the metric used in the video level supervision experiment, noting that it does not seem to be using trackletbased metrics, but the paper lacks details on this. While the comment identifies a potential issue with the clarity of the paper, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors would need to infer that they should clarify the metric used in the experiment. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the metric used in the video level supervision experiment, noting that it does not seem to be using trackletbased metrics, but the paper lacks details on this. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in identifying the need for clarification regarding the metric used, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the metric used in the video level supervision experiment, noting that it does not seem to be using trackletbased metrics, but the paper lacks details on this. The comment is factual and descriptive, as it points out a specific aspect of the paper that requires clarification. However, it does not provide any reasoning, examples, or references to support the claim that the paper lacks details on the metric used. Therefore, the comment is considered \"2\" as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the metric used in the video level supervision experiment is not clearly explained, despite the reviewer\"s observation that it does not seem to be using trackletbased metrics. This feedback is 3 as it highlights a potential area of confusion or lack of clarity in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as suggesting alternative metrics or providing more detailed explanations. Without actionable advice, the authors may find it challenging to improve their draft based on this feedback alone. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might learn personrelated features, which is undesirable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors would need to infer that they should investigate the impact of person blocking on the models and consider potential solutions. The action is vague because it does not specify how to conduct the investigation or what changes to make. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about why \"person blocking\" affects the models, as shown in Figure 4. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in that it identifies a potential issue with the models and suggests a possible explanation. However, without explicit mention of Figure 4 or a specific section, the authors may find it challenging to pinpoint the exact part of the paper to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might learn personrelated features, which is undesirable. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might learn personrelated features, which is undesirable. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what changes could be made to the models. While it identifies a potential area for improvement, it lacks actionable advice or detailed insights, making it 3. The authors would need to infer that they should investigate the impact of person blocking on the models and consider potential solutions, but the comment does not fully support this process. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks whether the authors have tried a specific combination of techniques (TFIDF and dense retrieval) for evidence sentence extraction. While it prompts the authors to consider this approach, it does not provide explicit instructions or suggestions on how to implement or improve their draft based on this feedback. The action is implicit, as the authors need to infer that they should explore this combination themselves. However, the comment lacks concrete guidance on how to proceed with this exploration, making it 3.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what the authors should do or why they should try the combination of TFIDF and dense retrieval. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively. Therefore, this comment is rated as \"1 and Not Specific,\" corresponding to a score of 1.", "verifiability_rationale": "The review point is a question asking whether the authors have tried a specific combination of techniques (TFIDF and dense retrieval) for evidence sentence extraction. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it poses a question about the authors\" exploration of a particular technique. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the authors have explored a specific combination of techniques (TFIDF and dense retrieval) for evidence sentence extraction. While it prompts the authors to consider this approach, it does not provide any guidance or suggestions on how to implement or improve their draft based on this feedback. The comment lacks depth and actionable advice, making it 2. The authors are left without a clear direction on how to address this potential improvement, which limits the comment\"s usefulness. Therefore, the comment is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include examples where timeseries prediction did not perform well, such as the COVID19 dataset where UK and Russia are highly correlated despite not being neighboring countries. It also asks about other countries where predictions were poor and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides specific examples and questions, it does not explicitly instruct the authors to add these elements to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should mention or provide examples where timeseries prediction did not perform well, specifically mentioning the COVID19 dataset and highlighting the correlation between UK and Russia despite them not being neighboring countries. It also asks about other countries where predictions were poor and how their trajectories relate to the top eigenvectors of the Laplacian. However, the comment does not specify which part of the paper this feedback should be addressed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing examples and asking questions about the performance of the model. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include examples where timeseries prediction did not perform well, such as the COVID19 dataset where UK and Russia are highly correlated despite not being neighboring countries. It also asks about other countries where predictions were poor and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides specific examples and questions, it lacks detailed reasoning or references to support why these examples are important or how they would enhance the paper. The feedback is 3 as it offers a clear direction for improvement but could be strengthened with more detailed explanations or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement by highlighting areas where the paper could be enhanced. It suggests including examples of timeseries prediction failures, such as the COVID19 dataset where UK and Russia are highly correlated despite not being neighboring countries. Additionally, it asks about other countries where predictions were poor and how their trajectories relate to the top eigenvectors of the Laplacian. These suggestions are actionable and provide clear directions for the authors to improve the paper. However, the comment could be more helpful if it offered more detailed guidance or examples of how to incorporate these suggestions. Overall, the feedback is 4 as it offers valuable insights for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. While the comment implies that the authors should clarify their claims, it does not provide explicit guidance on how to revise the draft to address this concern. The action is implicit, as the authors need to infer that they should clarify their claims and provide more detailed information about the proposed framework. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the authors\" claims of proposing a \"learning framework,\" suggesting that it is not a new framework but a modified loss and architecture. However, it does not specify which part of the paper this claim is made or which sections or figures might be relevant. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment provides some specificity by suggesting that the authors should clarify their claims, it does not offer detailed guidance on how to do so. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the authors\" claims of proposing a \"learning framework,\" suggesting that it is not a new framework but a modified loss and architecture. This comment implies that the authors should clarify their claims and provide more detailed information about the proposed framework. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or examples, the claim remains 3, as it lacks sufficient evidence to fully substantiate the authors\" claims.", "helpfulness_rationale": "The review comment questions the authors\" claims of proposing a \"learning framework,\" suggesting that it is not a new framework but a modified loss and architecture. This feedback is 3 as it points out a potential overstatement in the authors\" claims, which could help them refine their understanding of their contribution. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. It would be more helpful if the authors were given concrete advice on how to revise their claims or provide more detailed information about the proposed framework. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the current approach of using learned prompts, which are customized for specific transformerbased architectures. It suggests that this specificity might hinder crossmodel generalization, as separate training is required for each new architecture. The comment implies that exploring prompts with more universal features or optimizing them independently of model architecture could enhance broader applicability. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific steps the authors should take to address the issue. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of learned prompts being customized for individual transformerbased architectures, such as CLIP and DINOv2. It highlights that this specificity may limit crossmodel generalization, as separate training is required for each new architecture. The comment suggests exploring prompts with more universal features or optimizing them independently of model architecture to enhance broader applicability. However, the comment does not explicitly mention specific sections, tables, or figures of the paper that address this issue, making it weakly grounded. It is specific in detailing the problem and suggesting potential solutions, but without clear references, it is challenging for the authors to pinpoint the exact part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that learned prompts, which are customized for individual transformerbased architectures, may not translate effectively to other model types or slight architectural variations. This limitation could hinder crossmodel generalization, requiring separate training for each new architecture. The comment suggests exploring prompts with more universal features or optimizing them independently of model architecture to enhance broader applicability. However, the comment lacks specific examples or references to support the claim about the limitations of current approaches. While it provides a logical reasoning for the issue, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the approach of using learned prompts, which are customized for individual transformerbased architectures. It highlights that this specificity may hinder crossmodel generalization, as separate training is required for each new architecture. The comment suggests exploring prompts with more universal features or optimizing them independently of model architecture to enhance broader applicability. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included examples or suggestions for how to achieve this broader applicability. Overall, the comment is 4 as it offers valuable insights and guidance for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two main concerns: the absence of baselines and the use of an \"antiquated techniques\" model architecture. It suggests that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting compared to contemporary timeseries forecasting architectures. The comment provides specific examples of advanced timeseries forecasting models that could be evaluated on fMRI data, such as those available in the \"TimeSeries Library\" repository. This feedback is explicit and concrete, as it clearly directs the authors to address the issue by including relevant baselines and comparing their model to contemporary techniques. The authors are given specific suggestions for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"absence of baselines\" and the \"model architecture used in this paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the model architecture, suggesting that it is \"somewhat antiquated techniques\" and lacks comparisons to contemporary timeseries forecasting architectures. The comment provides specific examples of advanced timeseries forecasting models that could be evaluated on fMRI data, such as those available in the \"TimeSeries Library\" repository. This level of detail and specificity makes the comment highly informative and actionable for the authors.", "verifiability_rationale": "The review point claims that the absence of baselines raises a concern about the model architecture being somewhat antiquated, and that without comparisons to other models, there is no evidence of its effectiveness or novelty. The comment provides specific examples of advanced timeseries forecasting models that could be evaluated on fMRI data, such as those available in the \"TimeSeries Library\" repository. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to specific studies that demonstrate the limitations of the current approach. Overall, the comment is 4, as it is supported by logical reasoning and specific examples, but it could be more robust with additional evidence.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of baselines in the paper, which raises questions about the effectiveness and novelty of the proposed methodology. It suggests that the model architecture used appears somewhat outdated, and that comparisons to contemporary timeseries forecasting models are necessary to substantiate the claims made in the paper. The comment provides specific examples of advanced timeseries forecasting models that could be evaluated on fMRI data, such as those available in the \"TimeSeries Library\" repository. This feedback is 5, as it directs the authors to address the issue by including relevant baselines and comparing their model to contemporary techniques. By doing so, the authors can strengthen the validity and impact of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include at least one strong baseline in one of the tasks, given that the current baselines are standard MLPs. However, it does not provide explicit guidance on which tasks would benefit from a strong baseline or how to identify such baselines. The action is implicit, as the authors need to infer that they should add a strong baseline to improve the paper. While the suggestion is concrete in terms of the type of baseline needed, the lack of specific guidance on which tasks to focus on makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include at least one strong baseline in one of the tasks, given that the current baselines are standard MLPs. However, it does not specify which tasks would benefit from a strong baseline or how to identify such baselines. The comment lacks grounding as it does not provide specific guidance on which parts of the paper need improvement. It is also not specific because it does not detail what constitutes a \"strong baseline\" or how it should be implemented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should include at least one strong baseline in one of the tasks, given that the current baselines are standard MLPs. However, the comment lacks specific examples or references to what constitutes a \"strong baseline\" or how it should be implemented. It does not provide any logical reasoning or evidence to support the claim that the current baselines are insufficient. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the baselines used are standard MLPs, and it suggests that the inclusion of at least one strong baseline would enhance the paper. However, the comment lacks specificity in terms of which tasks would benefit from a strong baseline or how to identify such baselines. It does not provide detailed guidance or suggestions on how to improve the baselines or what criteria should be used to evaluate them. While the feedback is 3 in highlighting an area for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is similar to two prior works cited by the authors and recommends that the paper more clearly compare the proposed method to these prior works. It also suggests including these prior works for comparison in the tables of experimental results. However, the comment does not provide explicit guidance on how to compare the methods or how to include them in the tables. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two prior works cited by the authors, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to more clearly compare the proposed method to these prior works and include them in the tables of experimental results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is very similar to two prior works cited by the authors, specifically referencing works [3, 5]. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the tables of experimental results. However, the comment lacks specific examples or detailed reasoning to support the claim of similarity or to explain why a clearer comparison is necessary. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out that the proposed method is very similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the tables of experimental results. This feedback is actionable and provides a clear direction for the authors to improve the clarity and differentiation of their work. However, the comment could be more helpful if it offered specific guidance on how to compare the methods or how to include them in the tables. Despite this, the feedback is 4 as it directs the authors towards a crucial improvement in their paper."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that there are no visualization systems built for interpretable reinforcement learning that address the broader goals identified by the authors. It highlights the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the claim need clarification. The action is implicit and vague, as it does not specify how the authors should identify or define the broader goals. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim regarding the absence of visualization systems for interpretable reinforcement learning, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the lack of clarity regarding the \"broader goals\" identified by the authors, which are crucial for evaluating the claim. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that there do not exist visualization systems built for interpretable reinforcement learning that effectively address the broader goals identified by the authors. It highlights the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. However, the comment does not provide specific examples or references to support the claim, nor does it offer guidance on how the authors might address this issue. The feedback is 3 as it points out a potential issue but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that there are no visualization systems built for interpretable reinforcement learning that effectively address the broader goals identified by the authors. It questions the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the goals. While it highlights a potential area for improvement, it lacks actionable advice, making it 3. The feedback is valuable in pointing out a need for clarification but could be more helpful with detailed suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the independence of the introduced AAL and SLS and suggests that the improvements shown in Table (14) are slight. It questions whether applying AAL or SLS separately still provides a stable improvement. However, the comment does not explicitly instruct the authors to address these concerns or provide specific guidance on how to do so. The action is implicit, as the authors would need to infer that they should analyze the independence of AAL and SLS and reevaluate the stability of the improvements. The lack of concrete instructions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the independence of the introduced AAL and SLS and questions the stability of the improvements shown in Table (14). However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to pinpoint the exact issue. While the comment is specific in its questioning of the independence and stability of the improvements, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the independence of the introduced AAL and SLS and questions the stability of the improvements shown in Table (14). However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples to substantiate the concerns, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the independence of the introduced AAL and SLS and questions the stability of the improvements shown in Table (14). It suggests that applying AAL or SLS separately may not provide a stable improvement, which is a valid point that could help the authors refine their methodology or results. However, the comment lacks specific guidance or suggestions on how to address these concerns or what changes might be necessary. While it identifies an area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments are limited to sentiment classification and the SST2 dataset. It recommends exploring the effects on different tasks or utilizing multiple datasets for the same task. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct these experiments or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation of the experiments being limited to only one task (sentiment classification) and one dataset (SST2). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on how to improve the experiments by suggesting the exploration of different tasks or the utilization of multiple datasets for the same task. This detailed feedback helps the authors understand what needs to be addressed to enhance the depth and breadth of their experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to sentiment classification and the SST2 dataset, suggesting that exploring different tasks or utilizing multiple datasets would provide deeper insights. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim. The authors would need to infer the need for additional experiments based on the provided reasoning, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, noting that they are limited to sentiment classification and the SST2 dataset. It suggests that exploring the effects on different tasks or utilizing multiple datasets would provide deeper insights. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experiments. However, it could be more helpful if it included suggestions on how to implement these changes or examples of alternative tasks and datasets. Overall, the comment is 4, as it offers valuable guidance for improving the depth and breadth of the experiments."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of simulated data in the experiments, specifically questioning whether the data is realworld or simulated. It suggests that simulated data might be easier to fit, implying that the authors should consider using realworld data for their experiments. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider using realworld data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of simulated data in the experiments, specifically questioning whether the data is realworld or simulated. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its questioning of the data type, the absence of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether the experiments use realworld data or simulated data, suggesting that simulated data might be easier to fit. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of simulated data in the experiments, specifically questioning whether the data is realworld or simulated. It suggests that simulated data might be easier to fit, which could be a valuable insight for the authors to consider. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what changes could be made to their draft. While it identifies a potential area for improvement, it does not provide detailed feedback or specific recommendations, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a limitation of the study, specifically the absence of a dedicated image quality metric for evaluating image generation models. It suggests that the inclusion of metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. However, the comment does not provide explicit guidance on how the authors should implement this suggestion, such as which specific metrics to include or how to integrate them into the existing evaluation framework. While the action is implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment identifies a limitation of the study, specifically the absence of a dedicated image quality metric for evaluating image generation models. It suggests that the inclusion of metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in suggesting the inclusion of certain metrics, but without clear grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the absence of a dedicated image quality metric is a limitation of the study. It suggests that including metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed justification or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a significant limitation of the study, specifically the absence of a dedicated image quality metric for evaluating image generation models. It suggests that the inclusion of metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By recommending the inclusion of these metrics, the comment offers a concrete and constructive suggestion that could significantly enhance the study\"s evaluation framework. Therefore, the comment is 5, as it provides actionable and detailed guidance for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a question about the potential applicability of a mechanism in the context of vision transformers. While it raises an interesting point for discussion, it does not provide explicit or implicit actions for the authors to take. The authors are left to infer that they might need to explore or discuss the use of the mechanism in vision transformers, but there is no guidance on how to do so. Therefore, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment raises a question about the potential applicability of a mechanism in the context of vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it lacks specific references or context. Additionally, it does not provide specific guidance or suggestions on how to explore or discuss the use of the mechanism in vision transformers. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a question about the potential applicability of a mechanism in the context of vision transformers. It does not contain a claim or assertion that requires verification or justification. The comment is factual and descriptive, as it poses a question without providing any opinions, suggestions, or evidence. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the potential applicability of a mechanism in the context of vision transformers. While it prompts the authors to consider this possibility, it does not provide any specific guidance or suggestions on how to explore or discuss the use of the mechanism in vision transformers. The comment lacks depth and actionable advice, leaving the authors with limited insight into how to address the question. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the experimental results are lacking and questions the necessity of all modules. However, it does not provide explicit guidance on what specific aspects of the experimental results need improvement or how the authors should address the question of module necessity. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper the authors are referring to, making it difficult for them to identify the exact section being addressed. However, it is specific in its suggestion that the experimental results are lacking and that the authors should consider whether all modules are necessary. This provides a clear direction for improvement, but the lack of grounding makes it challenging for the authors to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results are \"a bit lacking\" and questions the necessity of all modules. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that they are \"a bit lacking\" and questioning the necessity of all modules. While it raises a valid concern about the comprehensiveness of the experimental setup, it lacks specific guidance or suggestions on how the authors might address this issue. The comment does not provide actionable advice or detailed feedback on what aspects of the experiments could be improved or expanded. As a result, the feedback is 3, as it highlights an area for improvement but does not offer comprehensive guidance for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explore the behavior of the network with a larger number of layers, specifically 32 and 64, given that many GNNs tend to oversmooth with more layers. However, the comment does not provide explicit guidance on how the authors should conduct this exploration or what specific aspects of the network\"s behavior should be analyzed. The action is implicit and vague, as it does not specify how the authors should implement this suggestion or what data or analysis would be required. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the number of layers considered by the authors, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of oversmoothing in GNNs with more layers and suggests exploring the behavior of the network with layers like 32 and 64. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should explore the behavior of the network with more layers, specifically 32 and 64, given that many GNNs tend to oversmooth with more layers. While the comment provides a logical reasoning based on the known tendency of GNNs to oversmooth, it lacks specific examples or references to support the claim. The suggestion is 3 as it offers a direction for further exploration but does not provide detailed guidance or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for further exploration by suggesting that the authors investigate the behavior of their network with a larger number of layers, specifically 32 and 64. This is relevant because it aligns with the known tendency of GNNs to oversmooth as more layers are added. The comment provides a clear direction for the authors to consider, suggesting that they explore how the network behaves with these additional layers. However, it does not offer specific guidance on how to conduct this exploration or what aspects of the network\"s behavior should be analyzed. While the comment is 3 in identifying an area for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the improvement of MT over ST is very limited and recommends performing significance tests to ensure the reliability of the experimental results. While the comment implies that the authors should conduct these tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform significance tests to validate their findings. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment suggests that the improvement of MT over ST is very limited and recommends performing significance tests to ensure the reliability of the experimental results. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to perform significance tests, which would help the authors address the issue of limited improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement of MT over ST is very limited and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or examples, the claim is 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically noting that the improvement of MT over ST is very limited. It suggests performing significance tests to ensure the reliability of the results. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on which significance tests to use or how to interpret the results. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that the proposed framework is modelagnostic, suggesting that it is only evaluated under different GCN architectures. The authors are curious about the framework\"s performance with other GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. While the comment implies that the authors should explore the framework\"s performance with these different GNN blocks, it does not provide explicit instructions on how to conduct this exploration or what specific results to expect. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and the specific areas to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the claim that the proposed framework is modelagnostic, suggesting that it is only evaluated under different GCN architectures. The authors are curious about the framework\"s performance with other GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. However, the comment does not specify which part of the paper discusses the evaluation of the framework, making it weakly grounded. It is specific in questioning the modelagnostic claim and suggesting additional experiments, but without clear references to the sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the proposed framework is modelagnostic, suggesting that it is only evaluated under different GCN architectures. The authors express curiosity about the framework\"s performance with other GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. However, the comment lacks specific examples or detailed reasoning to support the claim that the framework is truly modelagnostic. It does not provide references or evidence to substantiate the assertion that the framework\"s performance is consistent across different GNN architectures. As a result, the claim is not wellsupported, making the comment 1.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed framework is modelagnostic. It points out that the framework is only evaluated under different GCN architectures, specifically mentioning node and graph classification models that employ similar GCN blocks. The authors are curious about the framework\"s performance with other GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. This feedback is 3 as it highlights a potential gap in the evaluation and encourages the authors to explore the framework\"s performance across a broader range of GNN architectures. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what results to expect. Overall, the comment identifies an important area for further investigation, but it lacks detailed suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method has many moving parts and recommends including an error analysis to understand how the approach functions if one of the components makes a mistake. For example, it asks what happens if GPT4o misses some details. While the comment implies that an error analysis should be included, it does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method has many moving parts and recommends including an error analysis to understand how the approach functions if one of the components makes a mistake. It provides an example of what happens if GPT4o misses some details. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its suggestion to include an error analysis, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method has many moving parts and recommends including an error analysis to understand how the approach functions if one of the components makes a mistake. For example, it asks what happens if GPT4o misses some details. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method by noting that it has many moving parts, which could make it difficult to understand and analyze. It suggests that including an error analysis would be beneficial to understand how the approach functions if one of the components makes a mistake. For example, the reviewer asks what happens if GPT4o misses some details. This feedback is 3 as it points out a specific area for improvement and provides a clear example of how the analysis could be conducted. However, the comment could be more helpful if it offered more detailed guidance on how to perform the error analysis or suggested specific aspects to focus on. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing element in the paper, specifically the absence of an error analysis. While it points out the importance of such an analysis for understanding the limitations of SetCSE, it does not provide any explicit or implicit suggestions on how to include or conduct this analysis. The authors are left without guidance on how to address this gap, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the absence of an error analysis, which is crucial for understanding the limitations of SetCSE. However, it does not specify which part of the paper lacks this analysis, making it weakly grounded. The comment is specific in pointing out the need for an error analysis, but without a clear reference to the section or part of the paper, the authors may find it challenging to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no mention of an error analysis in the paper, which is important for understanding the limitations of SetCSE. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to verify or address the issue. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the lack of an error analysis, which is crucial for understanding the limitations of SetCSE. This feedback is valuable as it highlights a critical gap in the paper that could enhance its comprehensiveness and impact. However, the comment could be more helpful if it provided some guidance on how to conduct or include an error analysis. Despite this, the comment offers a clear direction for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that unintentional finetuning or other prompts might recover the model\"s ability to use a tool. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take to improve their methodology. The comment implies that the authors should consider alternative methods or prompts, but it lacks concrete details on how to implement these suggestions. Therefore, the comment is 3, as it identifies a potential issue but does not offer clear guidance on how to address it.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that unintentional finetuning or other prompts might recover the model\"s ability to use a tool. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the measurement method, the absence of explicit grounding makes it challenging for the authors to understand where to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that unintentional finetuning or other prompts might recover the model\"s ability to use a tool. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that unintentional finetuning or other prompts might recover the model\"s ability to use a tool. This feedback highlights a potential limitation in the methodology and prompts the authors to consider alternative approaches or prompts that could more effectively elicit toolknowledge. However, the comment lacks specific suggestions or guidance on how to address this issue or what alternative methods might be more effective. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the improvement of HA3C over baseline algorithms on MuJoCo control tasks is marginal and questions the effectiveness of HA3C. It proposes that the benefit of HA3C might depend on the complexity of the causal relationships, suggesting that MuJoCo tasks may not be suitable for demonstrating its effectiveness. The comment implies that the authors should consider finding other tasks, including artificial ones, to better showcase the effectiveness of HA3C. However, it does not provide explicit guidance on which tasks to choose or how to demonstrate the effectiveness of HA3C. The action is implicit and somewhat vague, as the authors need to infer the specific tasks to address the comment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically mentioning the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks. It suggests that the effectiveness of HA3C might depend on the complexity of causal relationships, questioning the suitability of MuJoCo tasks for demonstrating its effectiveness. The comment implies that the authors should consider finding other tasks, including artificial ones, to better showcase the effectiveness of HA3C. However, the comment does not explicitly mention specific sections or parts of the paper, making it weakly grounded. It is specific in detailing the issue with the experimental results and suggesting alternative tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a subjective opinion about the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks, questioning whether this indicates ineffectiveness. It suggests that the benefit of HA3C might depend on the complexity of causal relationships, implying that MuJoCo tasks may not be suitable for demonstrating its effectiveness. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that HA3C is ineffective or that MuJoCo tasks are unsuitable. Without further elaboration or evidence, the claim remains somewhat subjective and lacks strong justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed analysis of the experimental results, specifically highlighting the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks. It questions the effectiveness of HA3C, suggesting that the benefit might depend on the complexity of causal relationships and that MuJoCo tasks may not be suitable for demonstrating its effectiveness. The comment offers a constructive suggestion to the authors to consider finding other tasks, including artificial ones, to better showcase the effectiveness of HA3C. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included suggestions for alternative tasks or a discussion of the limitations of the current experimental setup. Overall, the comment is 4, as it guides the authors towards addressing a specific weakness in their experimental results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper does not fully address the aspect of novelty, particularly in terms of insights derived from the data. It suggests that the authors should focus on presenting key takeaways beyond the general message that LLM performance does not align with human abilities. The comment implies that the authors should include some key insights or takeaways that are generalizable and hold broader significance for the community. However, it does not provide specific guidance on how to derive or present these insights, leaving the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of novelty and the focus on insights derived from the data, which is a specific part of the paper. It clearly specifies what needs to be addressed, namely the lack of key takeaways beyond the general message about LLM performance not aligning with human abilities. The comment requests that the authors include some key insights or takeaways that are generalizable and hold broader significance for the community. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not fully address the aspect of novelty, particularly in terms of insights derived from the data. It suggests that the authors should focus on presenting key takeaways beyond the general message that LLM performance does not align with human abilities. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the novelty does not lie in the dataset itself but rather in the insights derived from the data. It critiques the paper for primarily reporting aggregate numbers without providing clear key takeaways or generalizable insights that could be valuable for the broader community. The comment suggests that the authors should focus on presenting key takeaways that are beyond the general message about LLM performance not aligning with human abilities. This feedback is 4 as it provides a clear direction for improvement, encouraging the authors to enhance the depth and significance of their findings. However, it could be more helpful if it offered specific examples or guidance on how to derive and present these key takeaways. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the claim \"GAN has been the de facto choice for vocoders\" is false and highlights the existence of other popular vocoder choices like WaveNet, WaveRnn, and diffusionbased approaches. This provides a clear and direct action for the authors to take, which is to correct the inaccurate claim and acknowledge the existence of alternative vocoder choices. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Sec 3.1,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies that the claim \"GAN has been the de facto choice for vocoders\" is false and highlights other popular vocoder choices like WaveNet, WaveRnn, and diffusionbased approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"GAN has been the de facto choice for vocoders\" is a false claim and highlights the existence of other popular vocoder choices like WaveNet, WaveRnn, and diffusionbased approaches. While the comment identifies a factual error, it lacks specific references or detailed reasoning to support the claim that GANs are the de facto choice. The authors would need to conduct further research to verify this claim, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a factual error in the paper, specifically that \"GAN has been the de facto choice for vocoders\" is an inaccurate claim. It highlights the existence of other popular vocoder choices, such as WaveNet, WaveRnn, and diffusionbased approaches, which are not mentioned in the paper. This feedback is clear and actionable, as it directs the authors to correct the inaccurate claim and acknowledge the diversity of vocoder choices. However, the comment could be more helpful if it provided specific examples or references to support the claim that GANs are not the de facto choice. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified. It provides an example of the choice of token similarity metric. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations and empirical justifications for their design choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"More generally,\" which implies a broad scope, and it refers to \"above,\" which suggests a specific part of the paper where design choices are discussed. This allows the authors to identify the relevant sections. The comment is also specific because it highlights the issue of design choices not being fully explained or empirically justified, particularly mentioning the choice of token similarity metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, the comment lacks specific examples or references to support these claims. Without detailed explanations or empirical evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach, specifically noting that while it is straightforward and sensible, some design choices are not fully explained or empirically justified. The example provided, such as the choice of token similarity metric, highlights a specific area where the authors could improve their work. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address these issues. While it points out a potential area for improvement, it does not offer comprehensive advice or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a starting point for the authors to consider but does not fully support their needs for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights inconsistencies in the notation used in the paper, specifically pointing out issues with Equation (4) and Equation (6). It notes that the lefthand side (LHS) of Equation (4) contains variables T and W, while the righthand side (RHS) does not. Similarly, it mentions that the formulas for the mean and variance in Equation (6) have a variable j on the LHS but not on the RHS. While the comment identifies specific inconsistencies, it does not provide explicit guidance on how the authors should address these issues or what changes are needed to resolve them. The action is implicit and somewhat vague, as the authors are left to infer the necessary corrections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (4 and 6) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the inconsistencies in the notation, such as the presence of variables T and W on the LHS of Equation (4) but not on the RHS, and the inclusion of variable j on the LHS of Equation (6) but not on the RHS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point highlights inconsistencies in the notation used in the paper, specifically pointing out issues with Equation (4) and Equation (6). It notes that the lefthand side (LHS) of Equation (4) contains variables T and W, while the righthand side (RHS) does not. Similarly, it mentions that the formulas for the mean and variance in Equation (6) have a variable j on the LHS but not on the RHS. While the comment identifies specific inconsistencies, it does not provide any reasoning or justification for why these inconsistencies are problematic or how they might affect the paper\"s conclusions. The lack of supporting evidence or explanation makes the claim 3, as the authors may need to infer the significance of these inconsistencies. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific inconsistencies in the notation used in the paper, particularly in Equations (4) and (6). It points out that the lefthand side (LHS) of Equation (4) contains variables T and W, while the righthand side (RHS) does not, and similarly notes that the formulas for the mean and variance in Equation (6) have a variable j on the LHS but not on the RHS. This feedback is clear and actionable, as it provides specific examples of where the notation is inconsistent, allowing the authors to correct these issues. By addressing these inconsistencies, the authors can improve the clarity and accuracy of their paper, making it easier for readers to understand the mathematical formulations. Therefore, the comment is 5, as it offers clear guidance on how to enhance the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the evaluation of the paper: the limited number of models constructed (less than 20) and the lack of evaluation regarding the distortion of images after warping. It also points out the absence of a discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take to enhance their evaluation. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of insufficient evaluation, noting that only less than 20 models were constructed, which is not enough to demonstrate the effectiveness of the approach. It also mentions the lack of evaluation regarding the distortion of images after warping and the absence of a discussion on potential countermeasures. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as expanding the number of models, evaluating image distortion, and discussing countermeasures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks sufficient evaluation, as only less than 20 models were constructed during the evaluations. This is a subjective assessment of the evaluation\"s comprehensiveness. The comment also notes the absence of evaluation regarding the distortion of images after warping and the lack of discussion on potential countermeasures against the proposed approach. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 2, as it lacks sufficient evidence or justification to fully substantiate the authors\" concerns.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper\"s evaluation, noting that only less than 20 models were constructed, which is insufficient to demonstrate the effectiveness of the approach. It also points out the lack of evaluation regarding the distortion of images after warping and the absence of a discussion on potential countermeasures against the proposed approach. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it directs the authors to areas that need attention, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify whether the discourse particles in Table A3 are standalone or include imported vocabulary. It also recommends separating them into different tables and providing glosses. While the comment provides explicit guidance on what needs to be clarified and how to present the information, it lacks specific details on which parts of the table need to be separated or how glosses should be formatted. The action is somewhat explicit but could be more detailed, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified regarding the discourse particles and suggests a way to improve the presentation by separating them into different tables and providing glosses. This level of detail helps the authors understand exactly what changes are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question that seeks clarification about the content of Table A3, specifically whether the discourse particles are standalone or include imported vocabulary. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The comment provides a specific question about the content of Table A3, asking whether the discourse particles are standalone or include imported vocabulary. It suggests that if the latter is the case, the authors should consider separating them into different tables and providing glosses. This feedback is clear and actionable, as it directly addresses a potential ambiguity in the presentation of the data. However, it could be more helpful if it included suggestions for how to improve the clarity or organization of the table. Overall, the comment is 4, as it offers valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about the rationale behind formula (4), specifically questioning why the maximum is taken over all possible pieces for unoccupied squares. While the comment highlights a lack of understanding, it does not provide explicit guidance on how the authors should clarify or address this issue. The action is implicit, as the authors would need to infer that they should seek clarification or explanation for the formula. However, the comment lacks concrete details on how to achieve this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment expresses confusion about the rationale behind formula (4), specifically questioning why the maximum is taken over all possible pieces for unoccupied squares. However, it does not specify which part of the paper this formula is located in, making it difficult for the authors to pinpoint the exact issue. The comment is 1 as it does not provide explicit references to sections, tables, or figures. Additionally, it lacks specificity as it does not detail what aspects of the formula or its application are unclear. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about the rationale behind formula (4), specifically questioning why the maximum is taken over all possible pieces for unoccupied squares. This is a subjective opinion or criticism of the paper\"s explanation, as it highlights a lack of clarity in the reasoning behind the formula. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the explanation is unclear or problematic. Without additional context or justification, the claim is considered 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a specific point of confusion regarding formula (4), questioning the rationale behind taking the maximum over all possible pieces for unoccupied squares. This feedback is 3 as it identifies a potential area where the authors may need to clarify their reasoning or provide additional context. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the feedback is limited in its ability to help the authors improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a deficiency in the experiments by noting the absence of comparisons to stateoftheart subset selection methods. While it identifies a gap in the evaluation, it does not provide explicit guidance on how the authors should address this issue or what specific methods to compare against. The action is implicit, as the authors need to infer that they should include such comparisons in their experiments. However, the lack of concrete suggestions or detailed guidance on how to implement these comparisons makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a deficiency in the experiments by noting the absence of comparisons to stateoftheart subset selection methods. However, it does not specify which part of the paper this issue pertains to, such as the experimental section or a specific figure/table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the need for comparisons, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments lack the comparison to stateoftheart subset selection methods. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this comparison is necessary or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the experiments by pointing out the absence of comparisons to stateoftheart subset selection methods. This feedback is valuable as it highlights a critical area for improvement, specifically the lack of benchmarking against existing methods. However, the comment could be more helpful if it provided suggestions on which specific methods to compare against or how to conduct these comparisons effectively. While it identifies a clear need for improvement, the lack of detailed guidance limits its impact on the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the novelty of the paper is somewhat vague and needs to be more concise. It also mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the novelty need to be clarified. The action is implicit and vague, as it does not specify how the authors can make the novelty more concise or how they should differentiate their work from previous studies. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the novelty of the paper is somewhat vague and needs to be more concise. It also mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which part of the paper discusses the novelty or how the authors can address this issue. The lack of specific references or sections makes it difficult for the authors to understand which part of the paper needs revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is somewhat vague and needs to be more concise. It also mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, suggesting that it is somewhat vague and could be more concise. It also points out that the primary components of the paper integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific suggestions or guidance on how the authors can address this issue or enhance the novelty of their work. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be important to use evaluation benchmarks of user simulators to demonstrate how smaller models perform as user simulators. This provides a clear and explicit action for the authors to take, which is to incorporate such benchmarks into their work. The comment is specific in its suggestion and offers a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests using evaluation benchmarks of user simulators to show how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs improvement. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that it would be important to use evaluation benchmarks of user simulators to show how smaller models perform as user simulators. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without additional context or references, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment suggests that it would be important to use evaluation benchmarks of user simulators to demonstrate how smaller models perform as user simulators. This feedback is clear and actionable, providing a specific direction for the authors to improve their work by incorporating such benchmarks. However, the comment could be more helpful if it included examples of existing benchmarks or guidance on how to implement them. Overall, the feedback is 4 as it offers a clear and actionable suggestion, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the impact of openset detectors on the performance of the proposed method. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this issue or what changes could be made to their work. As a result, the authors are left without a clear understanding of what to do next, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of openset detectors on the performance of the proposed method, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this issue, leaving the authors without a clear direction for improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the impact of openset detectors on the performance of the proposed method. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the question, making it difficult to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of openset detectors on the performance of the proposed method. While it identifies a potential area for further investigation, it does not provide any specific guidance or suggestions on how the authors might address this issue or what changes could be made to their work. The comment lacks actionable insights and detailed feedback, leaving the authors with limited direction for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the interpretation of symbols in Table 1 and Table 5. It asks for clarification on the meaning of the star (*) next to \"oracle goals\" in Table 1 and for clarification on whether \"fromscratch\" in Table 5 implies random initialization or continued pretraining. While the comment explicitly asks for clarification, it does not provide any guidance on how the authors should address these questions or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should clarify these points, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the interpretation of the star (*) symbol in Table 1 and the \"fromscratch\" setting in Table 5, requesting clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the interpretation of symbols in Tables 1 and 5, specifically the star (*) symbol in Table 1 and the \"fromscratch\" setting in Table 5. While the comment does not contain subjective opinions or claims, it requests clarification from the authors, which is a logical request for improvement. However, the comment lacks specific examples or references to support the need for clarification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas of confusion in the paper, particularly regarding the interpretation of symbols in Table 1 and the meaning of \"fromscratch\" in Table 5. It requests clarification from the authors, which is a valuable piece of feedback that can help them improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided some guidance on how the authors might clarify these points, such as suggesting specific sections or examples to include. Overall, the comment is 3 as it highlights important areas for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the expected outcome of increased transferability with higher noise intensity, suggesting that it might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. It lacks concrete actions or detailed feedback on what needs to be done to make the results more exciting or to clarify the unexpected findings. As a result, the authors are left without a clear path to improve their work, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the unexpected increase in transferability with higher noise intensity and suggests an alternative explanation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the expected outcome of increased transferability with higher noise intensity, suggesting that it might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. However, the comment does not provide any specific evidence, examples, or references to support this claim. It lacks detailed reasoning or justification, making it difficult for the authors to understand or address the issue. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the unexpected increase in transferability with higher noise intensity, questioning whether it aligns with the expected behavior of the system. It suggests that the results might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. This feedback highlights a potential area for further exploration or clarification in the paper. However, the comment lacks specific guidance on how the authors might address this issue or what additional experiments could be conducted to provide a more comprehensive understanding of the results. While it identifies a meaningful aspect of the research, it could be more helpful with additional suggestions or detailed feedback on how to improve the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding ablation studies with only importance weighting or rejection to better understand their effects. It also points out issues with the font size in figures and specific concerns about the results in Fig. 6 (a), such as the rapid increase and subsequent decrease of the reward. The comment implies that these issues need to be addressed, but it does not provide explicit guidance on how to conduct the ablation studies or explain the observed results in detail. While the action is somewhat explicit, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests adding ablation studies with only importance weighting or rejection, which is a specific action related to the methodology. It also points out issues with the font size in figures and specific concerns about the results in Fig. 6 (a), such as the rapid increase and subsequent decrease of the reward. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The specificity of the comment is good as it clearly identifies the issues that need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding ablation studies with only importance weighting or rejection to better understand their effects, which is a logical suggestion for improving the paper. However, it does not provide specific examples or references to support the claim that such ablation studies would be beneficial. The comment also mentions issues with the font size in figures and specific concerns about the results in Fig. 6 (a), such as the rapid increase and subsequent decrease of the reward, but lacks detailed reasoning or examples to substantiate these claims. Therefore, the comment is 3, as it provides some justification but lacks depth and specific evidence.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper, such as adding ablation studies with only importance weighting or rejection to better understand their effects. It also points out issues with the font size in figures and specific concerns about the results in Fig. 6 (a), such as the rapid increase and subsequent decrease of the reward, and asks for an explanation of this phenomenon. These suggestions are actionable and provide clear guidance for the authors to enhance their draft. However, the comment could be more helpful if it included more detailed reasoning or examples to support the claims. Overall, the feedback is 4, as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the technical clarity of the paper, specifically mentioning that the main learning framework, Equation (18), is not explained. It also asks for clarification on how to implement the balancing term and the penalty term. While the comment identifies a specific area needing improvement, it does not provide explicit instructions on how to address the issue or what specific aspects of the explanation should be included. The authors are left to infer that they need to provide a more detailed explanation of Equation (18) and the implementation of the balancing and penalty terms. This lack of explicit guidance makes the action somewhat vague and leaves the authors with limited direction on how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the technical clarity of the paper, particularly regarding the explanation of the main learning framework, Equation (18). It also asks for clarification on how to implement the balancing term and the penalty term. However, the comment does not specify which part of the paper contains Equation (18) or any other specific elements, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that requires attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical clarity is weak, specifically mentioning that the main learning framework, Equation (18), is not explained. It also asks for clarification on how to implement the balancing term and the penalty term. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper: the lack of technical clarity, particularly regarding the explanation of the main learning framework, Equation (18). It also raises questions about the implementation of the balancing term and the penalty term, which are crucial for understanding the methodology. While the comment highlights an area that needs improvement, it does not provide specific guidance or suggestions on how to address these issues. The authors are left with a clear indication of what needs to be clarified but are not given detailed instructions on how to do so. This feedback is 3 as it points out a critical area for improvement, but it lacks depth and actionable advice, making it a 3 out of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the decision boundary generation process, specifically questioning the consistency of projection results and Voronoi tessellation across multiple rounds. It suggests that these results should be updated as feature vectors change during training and that the use of 2D projections to represent highdimensional decision boundaries is problematic due to potential variations based on the selected method and parameters. While the comment identifies specific issues, it does not provide explicit guidance on how to address these concerns or what actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about decision boundary generation, specifically questioning the consistency of projection results and Voronoi tessellation across multiple rounds. It highlights the issue that these results should be updated as feature vectors change during training. However, the comment does not specify which part of the paper discusses the decision boundary generation or the figures that present the results. This lack of grounding makes it difficult for the authors to identify the exact section or figure being addressed. While the comment is specific in detailing the concerns about the consistency of results, the absence of explicit references to the paper limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the consistency of projection results and Voronoi tessellation across multiple rounds, suggesting that these results should be updated as feature vectors change during training. It also questions the use of 2D projections to represent highdimensional decision boundaries, noting that results can vary significantly based on the selected method and parameters. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the consistency of projection results and Voronoi tessellation across multiple rounds, suggesting that these results should be updated as feature vectors change during training. It also questions the use of 2D projections to represent highdimensional decision boundaries, noting that results can vary significantly based on the selected method and parameters. While the comment identifies specific areas that need clarification, it lacks detailed guidance on how the authors might address these concerns or what specific changes could be made to improve the draft. The feedback is 3 as it points out potential issues that could impact the accuracy and reliability of the results, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of an ablation study and a comparison to methods from the past decade. While it points out these missing elements, it does not provide explicit instructions or suggestions on how the authors should conduct these analyses or include them in their draft. The comment implies that these elements are important for a comprehensive evaluation, but it lacks concrete guidance on how to implement them. Therefore, the comment is 3, as it identifies a gap in the draft but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment highlights the absence of an ablation study and a comparison to methods from the past decade. However, it does not specify which part of the paper these elements should be included in or how they should be addressed. The authors cannot confidently determine which sections or aspects of the paper are missing these elements, making the comment weakly grounded. Additionally, the comment is specific in identifying the need for an ablation study and a comparison to past methods, but it lacks detailed guidance on how to conduct these analyses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study and a comparison to methods from the past decade. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why these elements are missing or how they should be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two significant areas for improvement in the paper: the absence of an ablation study and the lack of comparison to methods from the past decade. These are critical aspects that enhance the robustness and comprehensiveness of the research. However, the comment does not provide specific guidance or suggestions on how the authors might conduct these analyses or include the necessary comparisons. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out critical gaps but does not offer detailed guidance on how to address them."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include more theoretical results on more complicated models, particularly those related to Support Vector Classification (SVC). However, it does not provide explicit guidance on which specific models or results should be included, nor does it offer any suggestions on how to approach this expansion. The comment lacks concrete details and actionable steps for the authors to take, making it difficult for them to understand what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include more theoretical results on more complicated models, particularly those related to Support Vector Classification (SVC). However, it does not specify which part of the paper this suggestion pertains to, nor does it provide any guidance on how to achieve this. The authors cannot confidently determine which section or aspect of the paper needs improvement, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include more theoretical results on more complicated models, but it lacks detailed examples or references to specific areas where these results could be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include more theoretical results on more complicated models, particularly those related to Support Vector Classification (SVC). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed examples or references, the claim is not 5, as it does not provide a clear path for the authors to improve their work. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the paper should include more theoretical results on more complicated models, particularly those related to Support Vector Classification (SVC). This feedback is 3 as it identifies a potential area for improvement in the paper, specifically in expanding the theoretical analysis. However, the comment lacks specificity and does not provide detailed guidance on which models or results should be included, nor does it offer any suggestions on how to approach this expansion. Without concrete examples or actionable advice, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. However, it does not specify which aspects of the DA Inversion should be ablated or how these additional studies would be conducted. The comment implies that the authors should perform more experiments to substantiate the claim, but it lacks concrete guidance on what specific ablation studies to include or how to interpret the results. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, referencing existing results in Fig. 11. However, it does not specify which part of the paper Fig. 11 corresponds to or provide details on what aspects of the DA Inversion should be ablated. This makes it difficult for the authors to pinpoint the exact section or figure being addressed, resulting in weak grounding. The comment is specific in its suggestion to include more ablation studies, but the lack of grounding makes it challenging for the authors to understand where to focus their efforts. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, referencing existing results in Fig. 11. However, the comment lacks specific details or examples of what aspects of the DA Inversion should be ablated or how these additional studies would be conducted. Without further elaboration or references, the claim remains 3, as the authors may need to infer the necessary information to address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, referencing existing results in Fig. 11. However, the comment lacks specific guidance on which aspects of the DA Inversion should be ablated or how these additional studies would be conducted. While it identifies a potential area for improvement, it does not provide detailed suggestions or examples, making it 3. The authors would need to infer the necessary steps to address the comment, which limits its impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of clustering in the second phase of training (section 3.3) when a linear regressor is used for evaluation. It suggests that the authors should provide a clear ablation study to demonstrate the impact of this clustering. The comment is explicit in its request for an ablation study, which is a concrete action that the authors can take to address the concern. However, the comment does not specify how to conduct the ablation study or what specific results should be presented, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the necessity of clustering in the second phase of training (section 3.3) and suggests that the authors should provide a clear ablation study. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. The comment is specific in its request for an ablation study, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of clustering in the second phase of training (section 3.3) when a linear regressor is used for evaluation. It suggests that the authors should provide a clear ablation study to demonstrate the impact of this clustering. However, the comment lacks specific details or examples to support the claim that the clustering is necessary or how it affects the evaluation. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of clustering in the second phase of training, particularly when a linear regressor is used for evaluation. It suggests that the authors should provide a clear ablation study to demonstrate the impact of this clustering. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to conduct a thorough analysis. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation study or what results should be presented. Overall, the comment offers a clear direction for improvement, making it a 3 comment."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider the impact of their work on figures, specifically mentioning Fig2a. It notes that the forgetting effect is not as drastic as in class incremental and that a slight increase is observed near epoch 150. However, the comment does not provide explicit guidance on how the authors should address this observation or what changes might be necessary. The action is implicit and vague, as it does not specify which aspects of the figures need to be revised or how the authors should interpret the results. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed observation about the forgetting effect in Fig2a, noting that it is not as drastic as in class incremental and that a slight increase is seen near epoch 150. This level of detail helps the authors understand what aspect of the figure needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the forgetting effect in Fig2a is not as drastic as in class incremental, noting a slight increase near epoch 150. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to verify the claim or understand its implications. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific observation regarding the forgetting effect in Fig2a, noting that it is not as drastic as in class incremental and that a slight increase is seen near epoch 150. While the comment identifies an area that requires attention, it lacks actionable guidance on how the authors might address this issue or what changes could be made to the figures or the analysis. The feedback is 3 as it highlights a potential area for improvement, but it does not provide detailed suggestions or steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum, in the abstract. While the comment provides a clear action\u2014highlighting this information\u2014it does not specify how to present this information or where exactly it should be placed in the abstract. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum, in the abstract. However, it does not specify which part of the paper this should be highlighted in, making it weakly grounded. The comment is specific in its suggestion to include this information, but the lack of grounding makes it difficult for the authors to know exactly where to address this. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum, in the abstract. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional context or examples to understand the significance of this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment provides a specific suggestion for improvement by recommending that the authors highlight the datadependent nature of their approximation results, particularly mentioning the covariance spectrum, in the abstract. This feedback is actionable and offers a clear direction for enhancing the presentation of the results. However, it could be more helpful if it included additional guidance on how to effectively present this information or examples of how to integrate it into the abstract. Despite this, the comment is 4 as it directs the authors towards a specific area of improvement, making it a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification on the meaning of RMSD in Figure 3, specifying whether it refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This direct request provides a clear and explicit action for the authors to take, as they need to clarify this aspect in their paper. The comment is specific and concrete, giving the authors precise guidance on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: the meaning of RMSD in the context of Figure 3, distinguishing between RMSD and consensus. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the meaning of RMSD in Figure 3. It does not contain a subjective claim or suggestion that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides a clear and specific question that helps the authors clarify the meaning of RMSD in Figure 3. By asking whether RMSD refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus, the comment directs the authors to a critical point of clarification that is essential for the accuracy and understanding of their results. This feedback is actionable and constructive, enabling the authors to improve the clarity and precision of their presentation. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It also poses a question about whether a smooth regret scaling, without phase transitions, could still hold the proven bounds. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate this into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on this aspect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to address the necessity of phase transitions and to consider a smooth regret scaling without phase transitions. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section or part of the paper to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It poses a question about whether a smooth regret scaling, without phase transitions, could still hold the proven bounds. This claim is 3 as it raises a question that could be addressed with further analysis or discussion, but it lacks specific examples or references to support the suggestion. The authors would need to provide more detailed reasoning or evidence to fully address this point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It poses a question about whether a smooth regret scaling, without phase transitions, could still hold the proven bounds. This feedback is 3 as it highlights a potential gap in the analysis and encourages the authors to consider alternative scenarios. However, the comment could be more actionable by providing specific guidance on how to address this issue or by suggesting additional experiments or analyses that could be conducted. Overall, the comment offers valuable insights but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include a comparison to previous robust RL methods, such as RARL, and asks if either GAD or EG already include these prior works. While the comment implies that the authors should add this comparison, it does not provide explicit instructions on how to do so or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add a comparison section and address the specific works mentioned. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a comparison to previous robust RL methods, such as RARL, and asks if either GAD or EG already include these prior works. However, it does not specify which part of the paper this comparison should be made or which sections should be referenced. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the need for a comparison, it lacks specificity in terms of what aspects of the comparison should be included. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper seems to be missing a comparison to previous robust RL methods, such as RARL, despite citing them. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of why the comparison is missing or how it would enhance the paper. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that a comparison to previous robust RL methods, such as RARL, is missing despite being cited. It also asks if either GAD or EG already include these prior works, which could help the authors ensure that their work is properly contextualized within the existing literature. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects of the comparison should be included. While it offers a clear direction for improvement, the feedback could be more helpful if it included specific examples or suggestions for the comparison. Therefore, the comment is 3, as it provides a clear area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This feedback is explicit and concrete, as it directly instructs the authors to include additional information that would enhance the clarity and comprehensibility of the paper. The authors know exactly what aspects of the paper need more detail, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for more information, but without clear references to specific sections or parts of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This feedback is clear and actionable, as it directly points out an area where the paper could be improved by offering more context and explanation. By addressing these points, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific examples or guidance on what kind of details should be included. Overall, the comment is 4, as it identifies a clear area for improvement but lacks some depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what changes could be made to clarify the relationship. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the question is specific, as it seeks clarification on a particular relationship within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not provide any claim, suggestion, or reasoning to support or address this question. The comment lacks any evidence or justification, making it 1. Therefore, it does not provide any guidance or insight for the authors to improve their work.", "helpfulness_rationale": "The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, specifically questioning why HIS is proportional to the negative inverse of mean response time. While this question highlights a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback, as it does not offer any insights or suggestions for improvement. Therefore, it is 2, as it identifies a potential area for clarification but does not provide any actionable advice to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions regarding the choice of the sparse representation learning method and the comparison of baselines in the experiments. It asks for a reason for the choice of the method, suggests including FTA as a baseline, and questions the comparison between supervised learning (SL) and reinforcement learning (RL) settings. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how to address these points. The authors are left to infer the necessary steps, making the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the choice of a sparse representation learning method and the comparison of baselines in the experiments, specifically mentioning the omission of FTA in a reinforcement learning (RL) setting while including it in a supervised learning (SL) setting. However, it does not specify which part of the paper discusses the choice of the method or the experimental setup. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in detailing the issue with the baseline comparison and the lack of validation across different learning settings. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the choice of the sparse representation learning method and the comparison of baselines in the experiments. It questions the rationale behind the choice of the method and suggests including FTA as a baseline. The comment also points out the inconsistency in comparing baselines in supervised learning (SL) and reinforcement learning (RL) settings, questioning the validity of the performance comparison. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the reasoning and provide additional evidence to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points regarding the choice of the sparse representation learning method and the comparison of baselines in the experiments. It questions the rationale behind the method selection and suggests including FTA as a baseline, which is a relevant and practical suggestion. The comment also highlights the inconsistency in comparing baselines in supervised learning (SL) and reinforcement learning (RL) settings, pointing out that the performance on an SL setting does not validate another. This feedback is clear and actionable, providing the authors with specific areas to improve their experimental design and analysis. However, the comment could be more helpful if it offered additional guidance on how to address these issues or suggested specific experiments to conduct. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific instance on page 4, line 154 where the authors make a claim about the appropriateness of a particular choice of shift and scaling. However, it does not provide any explicit or implicit guidance on how the authors should address this claim or why it is more appropriate. The comment lacks concrete suggestions or actions for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"p.4, l.154,\" allowing the authors to accurately identify the section being addressed. It is also specific because it points out a lack of explanation regarding the choice of shift and scaling, which the authors made without providing justification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors neglect to explain why a particular choice of shift and scaling is more appropriate. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the authors make a claim about the appropriateness of a particular choice of shift and scaling without providing any explanation or justification. This feedback is clear and actionable, as it directs the authors to address the lack of reasoning behind their choice. However, the comment could be more helpful if it suggested specific ways to justify or explain the choice, such as providing additional context or examples. Overall, the comment is 4 as it highlights a critical gap in the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern with the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that this term should be revised. However, it does not provide any specific guidance or suggestions on how the authors should revise the term or what aspects of the term need to be addressed. The action is implicit, as the authors would need to infer that they should revise the term, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and elsewhere, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology, suggesting that the authors should revise it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern with the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that this term should be revised. However, the comment does not provide any specific reasoning, examples, or references to support why this terminology is problematic or how it should be revised. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the term \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that it should be revised. This feedback is clear and actionable, as it points out a potential inconsistency or inaccuracy in the terminology used. However, the comment could be more helpful if it provided suggestions on how the authors might revise the term or what aspects of the term need to be addressed. Despite this, the comment offers valuable guidance for improving the clarity and accuracy of the paper, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only measures BERTScore to illustrate the similarity of the newly generated text. It suggests that there are other matrices that could measure the stealthiness of the generated content, which are not discussed in the paper. However, the comment does not provide explicit guidance on which other matrices should be considered or how they could be integrated into the analysis. The action is implicit, as the authors would need to infer that they should explore and discuss other metrics for evaluating stealthiness. While the suggestion is concrete, the lack of explicit guidance on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue: the paper only measures BERTScore and suggests that other matrices could be used to measure the stealthiness of the generated content, which is not discussed. This provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only measures BERTScore to illustrate the similarity of the newly generated text, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other matrices that could measure the stealthiness of the generated content, making it difficult for the authors to understand the basis of the critique. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only measures BERTScore to illustrate the similarity of the newly generated text. It suggests that there are other matrices that could measure the stealthiness of the generated content, which are not discussed in the paper. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and actionable guidance on which alternative matrices to consider or how to integrate them into the analysis. The comment provides a clear direction for the authors to enhance their evaluation of the generated content, but it could be more helpful with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues that need to be addressed in the paper, such as the convenience of applications, the need to clarify issues with existing estimators, the lack of defined basic notation, and the difficulty in understanding certain elements like the dimensionality p, unit ball S p, outer product (v) \u2297 2, constraint set \u0398, constant d 2, and the heuristic nature of Algorithm 2. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses issues related to the convenience of applications and the need to clarify issues with existing estimators. It also points out that the basic notation is not defined, making it difficult for the authors to understand certain elements such as the dimensionality p, unit ball S p, outer product (v) \u2297 2, constraint set \u0398, constant d 2, and the heuristic nature of Algorithm 2. However, the comment does not specify which part of the paper these issues are discussed, making it weakly grounded. The specificity of the comment is moderate as it identifies several areas that need clarification, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the clarity and completeness of the paper, including the convenience of applications, issues with existing estimators, the lack of defined basic notation, and the difficulty in understanding certain elements such as the dimensionality p, unit ball S p, outer product (v) \u2297 2, constraint set \u0398, constant d 2, and the heuristic nature of Algorithm 2. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors may need to infer the issues based on the provided information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, such as the convenience of applications, the need to clarify issues with existing estimators, and the lack of defined basic notation. It also points out specific elements that are not clearly explained, such as the dimensionality p, unit ball S p, outer product (v) \u2297 2, constraint set \u0398, constant d 2, and the heuristic nature of Algorithm 2. However, the comment lacks detailed guidance on how the authors should address these issues or what specific actions they should take to improve the clarity and completeness of the paper. While it provides some direction, the feedback could be more comprehensive and actionable to fully assist the authors in enhancing their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experimental results: first, it notes that the results do not show significant improvement in reallife datasets, similar to many GNN papers. Second, it points out that the comparison on the ZINC dataset is lacking, referencing Table 5 in [1]. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the experimental setup or results. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results section, specifically mentioning the lack of significant improvement in reallife datasets and the inadequacy of the comparison on the ZINC dataset. It references Table 5 in [1], which provides specific evidence for the claim about the ZINC dataset. This allows the authors to accurately identify the parts of the paper being discussed, making the comment fully grounded. The comment is also specific as it details the issues with the experimental results, such as the lack of improvement and the inadequate comparison on the ZINC dataset. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results do not show significant improvement in reallife datasets, similar to many GNN papers, and that the comparison on the ZINC dataset is lacking, referencing Table 5 in [1]. The claim is supported by the reference to common practices in GNN papers and the specific mention of the ZINC dataset, which provides a basis for the authors to understand the issue. However, the comment could be more verifiable by providing more detailed reasoning or examples of how the results lack improvement or how the comparison is lacking. Overall, the claim is 4, as it is supported by logical reasoning and references, but it could benefit from additional depth and examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, noting that they do not demonstrate substantial improvement in reallife datasets, a common observation in many GNN papers. It also points out that the comparison on the ZINC dataset is lacking, referencing Table 5 in [1]. This feedback is valuable as it highlights areas where the authors could strengthen their experimental evaluation. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the experimental setup or results to address these issues. Without actionable advice, the authors may find it challenging to effectively address the feedback. Therefore, the comment is 3, as it identifies important weaknesses but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that the performance of smaller language models (SLM) might be convincing due to limited data availability, suggesting that larger models generally perform better. It provides specific examples from Figure 3 (b) to support this claim, mentioning that LucaOne outperforms BSM models and that the BSM270M model performs better than the BSM110M model. However, the comment does not offer any actionable suggestions or guidance on how the authors might address this issue or improve their draft. The authors are left without any specific steps to take to enhance their work, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3 (b)\" and provides specific examples of model performance, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the performance of different models, such as LucaOne and BSM models, and highlights the trend of larger models outperforming smaller ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that larger models generally perform better than smaller models, providing specific examples from Figure 3 (b) to support this claim. It mentions that LucaOne outperforms BSM models and that the BSM270M model performs better than the BSM110M model. This claim is supported by logical reasoning and specific examples, making it 4. However, the comment could be strengthened by including a broader discussion or justification for why this trend is observed, which would enhance its verifiability.", "helpfulness_rationale": "The review comment critiques the claim that smaller language models (SLM) might perform better due to limited data availability, suggesting that larger models generally perform better. It provides specific examples from Figure 3 (b) to support this claim, noting that LucaOne outperforms BSM models and that the BSM270M model performs better than the BSM110M model. However, the comment does not offer actionable suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, it lacks depth and does not provide specific steps for the authors to take. Therefore, the comment is 3, as it highlights a critical point but does not fully assist the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights inconsistencies in the notation used throughout the paper, specifically mentioning the use of \"nu\" and the changes in notation between Figures 2 & 3 and Page 4 & Figure 4. While the comment identifies a potential issue with the consistency of notation, it does not provide explicit guidance on how the authors should address this inconsistency. The authors are left to infer that they need to ensure consistency in their notation, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is 3, as it points out a specific issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment highlights inconsistencies in the notation used throughout the paper, specifically mentioning the use of \"nu\" and the changes in notation between Figures 2 & 3 and Page 4 & Figure 4. However, it does not specify which parts of the paper these inconsistencies are present in, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment identifies a specific issue, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation is inconsistent, particularly with the use of \"nu,\" and provides examples of discrepancies between Figures 2 & 3 and Algorithm 1, as well as changes in notation on Page 4 and Figure 4. However, the comment does not offer any specific examples or references to support the claim of inconsistency. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, noting inconsistencies in the use of \"nu\" and changes in notation across different sections and figures. While the comment highlights a potential problem with the clarity and consistency of the notation, it does not provide any suggestions or guidance on how the authors might address this issue. Without actionable advice or examples of how to improve the notation, the authors may find it challenging to make meaningful improvements to their draft. Therefore, the comment is 2, as it points out a problem but lacks depth and constructive suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more experiments should be conducted in more challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This provides a clear and explicit action for the authors to take, as they can directly address the need for additional experiments in these challenging tasks. The comment is specific in its suggestion, detailing the type of experiments that should be conducted and providing a link to a relevant paper for context. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments in challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more challenging experiments, but without clear references to specific sections or figures, the authors may find it difficult to pinpoint the exact areas where these experiments should be conducted. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting more experiments in challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. While the comment provides a specific example of a challenging task and a link to a relevant paper, it lacks detailed reasoning or justification for why these additional experiments are necessary or how they would enhance the validation of the method. The suggestion is 3 as it offers a clear direction for improvement but could benefit from more detailed explanation or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting more experiments in challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This feedback is specific and actionable, providing a clear direction for the authors to enhance their experimental validation. By recommending additional experiments in a challenging area, the comment offers a concrete way to strengthen the paper\"s claims and demonstrate the robustness of the proposed method. However, the comment could be more helpful if it provided more detailed guidance on how to design these experiments or what specific metrics to use. Overall, the comment is 4 as it identifies a clear area for improvement and offers a specific suggestion, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the fairness of the summary of previous works, suggesting that some of the papers assume linear separability, which is a stronger assumption than the one presented in the paper. It also asks whether the authors are referring to orthogonally separable data, providing a specific example and a link for clarification. This comment is explicit in its request for clarification and provides a concrete action for the authors to take, which is to address the discrepancy in the assumptions and provide a clear reference. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section where the summary of previous works is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the fairness of the summary, pointing out that some papers assume linear separability, which is a stronger assumption than the one presented in the paper. The comment also asks for clarification regarding the reference to orthogonally separable data, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the fairness of the summary of previous works, specifically mentioning that some papers assume linear separability, which is a stronger assumption than the one presented in the paper. The comment provides a specific example of orthogonally separable data and includes a link to a resource for clarification. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by explicitly referencing the specific sections of the paper being discussed or providing more detailed reasoning about why the assumption of linear separability is a stronger assumption. Overall, the comment is 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the summary of previous works, specifically questioning the fairness of the assumption of linear separability. It points out that some papers assume this stronger assumption, which might not be consistent with the one presented in the paper. The comment also asks for clarification regarding the reference to orthogonally separable data, providing a specific example and a link for further explanation. This feedback is clear and actionable, as it directs the authors to address the discrepancy in assumptions and seek clarification, which could improve the accuracy and consistency of their work. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper\"s persample weight tuning method, specifically the use of influence functions. It highlights a limitation of the method, noting that the theoretical approximation of each sample\"s contribution is only valid when the upweight is close to 0. The comment suggests that if the weights are far from 0 during training, the influence function might not accurately reflect each sample\"s influence, potentially leading to unreliable weights. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or adjustments to the method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the persample weight tuning method and its reliance on influence functions, specifically highlighting a limitation regarding the validity of the theoretical approximation when upweights are far from 0. It provides a detailed explanation of the issue, making it specific to the part of the paper discussing this method. However, it does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is fully specific as it clearly specifies what needs to be addressed regarding the limitations of the influence function approximation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the paper\"s persample weight tuning method, specifically the use of influence functions. It highlights a limitation of the method, noting that the theoretical approximation of each sample\"s contribution is only valid when the upweight is close to 0. The comment suggests that if the weights are far from 0 during training, the influence function might not accurately reflect each sample\"s influence, potentially leading to unreliable weights. However, the comment does not provide specific examples or references to support this claim, making it 3. The reasoning is logical, but the lack of detailed evidence or examples weakens the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper\"s persample weight tuning method, specifically focusing on the limitations of the influence function when the upweights are far from 0. It highlights a critical issue with the theoretical approximation, suggesting that the method might not accurately reflect each sample\"s influence in such cases, potentially leading to unreliable weights. This feedback is valuable as it identifies a specific area where the paper\"s methodology could be improved. However, the comment could be more helpful if it offered suggestions on how the authors might address this limitation or what alternative approaches could be considered. Overall, the comment is 3 as it points out a significant issue that needs attention, but it lacks detailed guidance on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the applicability of centering as a canonicalization method for partial shapes or scenes, suggesting that it may not be welldefined in such cases. It also points out that the experiment with up to 50% missing points is presented as an augmentation, but this may not be the case in general training scenarios. The comment implies that the authors should address this issue, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of centering in partial shapes and scenes, suggesting that it may not be welldefined for such cases. It also critiques the experiment with up to 50% missing points, noting that it is presented as an augmentation but may not be the case in general training scenarios. However, the comment does not specify which part of the paper discusses centering or the experiment with missing points, making it weakly grounded. The comment is specific in detailing the issue with centering and the potential misinterpretation of the experiment, but without explicit references to sections or figures, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the applicability of centering as a canonicalization method for partial shapes or scenes, suggesting that it may not be welldefined in such cases. It also critiques the experiment with up to 50% missing points, noting that it is presented as an augmentation but may not be the case in general training scenarios. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general critique but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the applicability of centering as a canonicalization method for partial shapes or scenes, suggesting that it may not be welldefined in such cases. It also critiques the experiment with up to 50% missing points, noting that it is presented as an augmentation but may not be the case in general training scenarios. While the comment identifies potential issues with the methodology, it lacks specific guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider adding negative samples that share texture semantics with anchor images, similar to a previous work. It also recommends ensembling models trained with these negative augmentations and without them to see if this could improve performance. While the comment provides a clear direction for the authors to explore, it does not specify which parts of the paper should be addressed or how to implement this ensembling process. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper proposed to learn less about texture semantics by adding negative samples that only share texture semantics with anchor images. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it suggests trying to ensemble models trained with the proposed negative augmentations and without them to see if this could improve performance. This provides clear guidance on what needs to be done. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could benefit from ensembling models trained with and without the proposed negative augmentations. While the suggestion is logical and based on the idea that ensembling can improve performance, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to justify why ensembling would be beneficial in this context. Therefore, the claim is 3, as it is based on a reasonable suggestion but lacks sufficient detail or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors consider ensembling models trained with and without the proposed negative augmentations. This is a constructive and actionable piece of feedback that could potentially enhance the performance of the models. However, the comment could be more helpful if it provided additional context or guidance on how to implement the ensembling process or why this approach might be beneficial. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of the sampling method in the partitioning process and claims that the sample efficiency of Equation 7 is not guaranteed. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of the sampling method in the partitioning process and claims that the sample efficiency of Equation 7 is not guaranteed. It references specific sections of the paper, such as page 6 and Appendix B, which provides some grounding. However, the comment does not specify what needs to be addressed or how the authors should approach the issue. The lack of specificity makes it difficult for the authors to understand the exact parts of the paper that require attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the sufficiency of the sampling method in the partitioning process and claims that the sample efficiency of Equation 7 is not guaranteed. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the sufficiency of the sampling method in the partitioning process and claims that the sample efficiency of Equation 7 is not guaranteed. It also references specific sections of the paper, such as page 6 and Appendix B, which could provide context for the critique. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the authors form clusters for tokens in Figure 1, specifically noting that it is unclear in Section 3. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify the process. The action is implicit, as the authors need to infer that they should clarify the clustering process in Section 3. However, the comment lacks concrete details on how to achieve this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about how the authors form clusters for tokens in Figure 1, specifically noting that it is unclear in Section 3. However, it does not provide any specific guidance or suggestions on how to address this issue or what changes might be needed. The comment lacks grounding as it does not explicitly mention the section or figure being discussed, making it difficult for the authors to pinpoint the exact part of the paper that needs clarification. Additionally, the comment is not specific because it does not provide any details on what aspects of the clustering process are unclear or how the authors might improve the clarity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about how the authors form clusters for tokens in Figure 1, specifically noting that it is unclear in Section 3. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely descriptive, asking for clarification on a specific aspect of the paper. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the clustering of tokens in Figure 1, noting that it is unclear in Section 3. This feedback is valuable as it highlights a potential issue with the clarity of the paper, which could hinder understanding and interpretation. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. While it points out a problem, it does not provide any specific steps or advice on how to improve the clarity of the clustering process. Therefore, the comment is 3, as it identifies a weakness but does not offer comprehensive guidance for improvement. The score of 3 aligns with this assessment."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This significantly increases the complexity and time cost of experiments, limiting its potential application for large language models in realworld settings. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the method. It lacks concrete guidance on potential solutions or actions the authors could take to mitigate the complexity or time cost associated with manual hyperparameter adjustment. As a result, the authors are left without a clear path forward for addressing this limitation, making the comment 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted, increasing the complexity and time cost of experiments. This makes the comment fully grounded as it explicitly mentions the SimNPO method. However, it lacks specificity in detailing what aspects of the method or experiments need to be addressed to mitigate this issue. The comment does not provide specific suggestions or examples of how the authors might handle this complexity or time cost, making it somewhat specific. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that SimNPO introduces two additional hyperparameters that must be manually adjusted, significantly increasing the complexity and time cost of experiments. This claim is 3 as it provides a logical reasoning for why this might be a limitation, but it lacks specific examples or references to support the claim fully. The authors could benefit from additional evidence or examples to strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation of the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This significantly increases the complexity and time cost of experiments, which limits the potential application of this method for large language models in realworld settings. While the comment highlights a valid concern, it does not provide any suggestions or guidance on how the authors might address this issue or improve the method. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice or specific recommendations, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work is overemphasizing affordance prompting and suggests that the Pick&place example does not adequately demonstrate its advantage. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should either reduce the emphasis on affordance prompting or provide a more compelling example that showcases its benefits. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"affordance prompting\" and provides an example (\"Pick&place example\") to illustrate the issue. It specifies that the work is overemphasizing affordance prompting and suggests that the Pick&place example does not adequately demonstrate its advantage. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work is overemphasizing affordance prompting and suggests that the Pick&place example does not adequately demonstrate its advantage. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that it overemphasizes affordance prompting, which is presented as overengineered. The reviewer provides an example, the Pick&place task, to illustrate this point, suggesting that the example does not adequately demonstrate the advantage of affordance prompting. This feedback is 3 as it highlights a specific area for improvement and provides a concrete example to support the claim. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or provide additional examples to better showcase the benefits of affordance prompting. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. While it implies that the authors should conduct these studies, it does not provide explicit instructions on how to perform them or what specific aspects to ablate. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not specify which parts of the pipeline are being referred to, nor does it provide any guidance on how to conduct these studies. The lack of specific information about the parts of the pipeline being ablated makes it difficult for the authors to understand the exact scope of the suggested action. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not provide any specific reasoning, examples, or references to support why these studies are essential. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific need for ablation studies to demonstrate the necessity of each part of the proposed algorithmic pipeline. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it lacks specific guidance on which parts of the pipeline should be ablated or how to conduct these studies effectively. While the comment is 3, it could be more comprehensive by offering additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of the instructiontuning stage in MoE models, suggesting that the performance improvement might be due to additional training costs. However, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to demonstrate the necessity of the instructiontuning stage. The comment implies that the authors should consider the additional training costs and provide evidence to support their claims, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a potential issue but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the necessity of the instructiontuning stage in MoE models, questioning whether the performance improvement is due to additional training costs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the necessity of the instructiontuning stage and its potential impact on performance, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the instructiontuning stage in MoE models, suggesting that the performance improvement might be due to additional training costs. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and support to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of the instructiontuning stage in MoE models, questioning whether the performance improvement is due to additional training costs. It suggests that the authors should consider the impact of these costs and provide evidence to support their claims. However, the comment lacks specific guidance on how the authors might address this concern or what additional experiments or analyses could be conducted to demonstrate the necessity of the instructiontuning stage. While it identifies a potential issue, it does not provide detailed suggestions or actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the evaluation setup is outdated and recommends testing the approach on more challenging and representative finetuning datasets, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is fully actionable, as it specifies the exact steps the authors should follow to address the issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation setup\" and suggests improvements to it. It also specifies the models used in the evaluation, such as Llama1 and Mistralv0.1, which were released more than a year ago. The comment further suggests testing the approach on more challenging and representative finetuning datasets, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets. This provides clear guidance on what needs to be addressed in the paper, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation setup is outdated, as the models used (Llama1 and Mistralv0.1) were released more than a year ago, while current models have advanced significantly. The suggestion to test the approach on more challenging and representative finetuning datasets, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets, is logical and provides a clear rationale for the claim. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation setup, noting that the models used (Llama1 and Mistralv0.1) are outdated, as they were released more than a year ago. It correctly points out that current models have advanced dramatically in terms of quality. The comment suggests testing the approach on more challenging and representative finetuning datasets, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets, to better assess the efficacy of SparseMeZO. This feedback is clear, actionable, and provides a specific direction for improvement, making it 5 for the authors to enhance their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while many related works are presented in the second section, the lack of logical coherence makes the content somewhat disorganized. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the content need improvement. The action is implicit, as the authors would need to infer that they should reorganize the content to improve its logical flow. The comment is vague and lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies the issue of logical coherence and disorganized content, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second section of the paper lacks logical coherence, resulting in a somewhat disorganized content. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the second section of the paper, noting the lack of logical coherence and the resulting disorganized content. This feedback is clear and actionable, as it provides the authors with a specific area to address. However, the comment could be more helpful if it offered suggestions on how to improve the logical flow or organization of the content. While it identifies a problem, it lacks depth in terms of guidance on how to resolve it, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment requests that the authors specify the language used to retrieve the Reddit posts. This is a clear and explicit action that the authors can easily understand and implement. The comment provides a specific instruction on what information needs to be included, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment requests that the authors mention the language used to retrieve the Reddit posts. However, it does not specify which part of the paper this information should be included in or provide any guidance on how to determine the language used. This makes the comment weakly grounded, as the authors cannot confidently identify the specific part of the paper being addressed. Additionally, the comment is specific in its request for information but lacks context or examples, making it somewhat specific. Therefore, this comment is rated as 3.", "verifiability_rationale": "The review point requests that the authors mention the language used to retrieve the Reddit posts. This is a factual request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment requests that the authors specify the language used to retrieve the Reddit posts. This is a clear and actionable suggestion that provides a specific piece of information needed for the authors to improve their draft. By mentioning the language, the authors can ensure that their analysis is comprehensive and accurate. This feedback is helpful as it directly addresses a potential gap in the paper and provides a clear direction for improvement. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparisons with recent works, specifically mentioning \"[1]\". However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this issue, as they are not given any suggestions or instructions on how to include comparisons with recent works. Therefore, the comment is 1, as it lacks any direction for the authors to improve their draft.", "grounding_specificity_rationale": "The comment identifies a lack of comparisons with recent works, specifically mentioning \"[1]\". However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the type of comparison needed, it lacks grounding as it does not provide clear guidance on where to make these comparisons. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks comparisons with recent works, specifically mentioning \"[1]\". However, the comment does not provide any evidence or reasoning to support this claim, such as examples of missing comparisons or references to specific sections where these comparisons are absent. Without additional context or justification, the authors are left without a clear understanding of why this claim is important or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparisons with recent works, specifically mentioning \"[1]\". This feedback is valuable as it highlights an area where the authors could enhance the paper\"s relevance and impact by including comparisons with contemporary research. However, the comment lacks specificity in terms of which parts of the paper need these comparisons or how the authors might approach them. While it provides a clear direction for improvement, the lack of detailed guidance or suggestions limits its helpfulness. Therefore, the comment is 3, as it offers a meaningful insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method, TSG, in diffusion models that do not embed class labels into timesteps, such as UViT. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or incorporate it into their work. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timesteps, such as UViT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its inquiry about the applicability of TSG, but it lacks grounding as it does not provide explicit references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of TSG in diffusion models that do not embed class labels into timesteps, such as UViT. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely a question, which does not offer any guidance or insight for the authors to address. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the applicability of the proposed method, TSG, in diffusion models that do not embed class labels into timesteps, such as UViT. This question is relevant as it challenges the authors to consider the limitations of their method in different contexts. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or incorporate it into their work. While it identifies an area for further consideration, it lacks actionable feedback, making it 3. The authors would need to infer the need for additional discussion or experimentation to fully benefit from this feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a significant issue with the reproducibility of the paper, noting that the authors need to release their training code, dialogue dataset, and model checkpoints to allow reviewers to verify the claims and try out the model. The comment explicitly suggests releasing these resources via anonymous repositories, providing a clear and concrete action for the authors to take. This feedback is detailed and actionable, as it guides the authors on exactly what steps to follow to enhance the reproducibility of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reproducibility and suggests releasing the training code, dialogue dataset, and model checkpoints. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be done to improve reproducibility, including the specific resources that should be released. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks reproducibility due to the absence of training code, dialogue dataset, and model checkpoints. The comment suggests releasing these resources via anonymous repositories to allow reviewers to verify claims and try out the model. However, the comment does not provide specific examples or references to support the claim that these resources are essential for reproducibility. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the reproducibility of the paper, which is a significant concern for the scientific community. It highlights the importance of releasing the training code, dialogue dataset, and model checkpoints to allow reviewers to verify the claims and try out the model themselves. This feedback is 5 as it provides specific and concrete steps the authors can take to enhance the reproducibility of their work. By releasing these resources, the authors can ensure that their findings are verifiable and that the model can be tested by others, which is essential for the credibility and impact of the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify or expand upon their results to make them more impactful or less obvious. Without specific suggestions or guidance, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or result being discussed. Additionally, the comment lacks specificity in explaining why the result is considered obvious or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main result is \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the result is considered obvious or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main result is considered obvious because it aligns with the known behavior of gradient boosting, which minimizes objectives in functional space. While this observation highlights a potential lack of novelty or depth in the result, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The comment is 3 as it identifies a potential area for improvement, but it lacks actionable advice or detailed feedback, making it less impactful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the contribution of the work is insufficient and not explicitly expressed, suggesting that the paper appears incomplete. It highlights that the details provided do not adequately explain the specifics of the proposed model, and there is limited related work mentioned with no appropriate analysis. While the comment identifies several issues, it does not provide explicit or concrete actions for the authors to take to address these concerns. The authors are left to infer what needs to be done, such as expanding the explanation of the model, including more related work, and providing a detailed analysis. Therefore, the comment is 3, as it provides a clear indication of what needs to be addressed but lacks specific guidance on how to implement these actions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the contribution of the work being insufficient and not explicitly expressed within the paper. It also points out that the details provided do not adequately explain the specifics of the proposed model, and there is limited related work mentioned with no appropriate analysis. This allows the authors to accurately identify the parts of the paper that need attention. The comment is specific in detailing what needs to be addressed, such as expanding the explanation of the model and including more related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the work is insufficient and not explicitly expressed, suggesting the paper appears incomplete. It also notes that the details provided do not adequately explain the specifics of the proposed model, and there is limited related work mentioned with no appropriate analysis. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the lack of detailed evidence or examples makes it challenging to fully verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the contribution is insufficient and not explicitly expressed. It also points out that the details provided do not adequately explain the specifics of the proposed model, and there is limited related work mentioned with no appropriate analysis. This feedback is clear and actionable, as it directs the authors to address these weaknesses by expanding the explanation of the model, including more related work, and providing a detailed analysis. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for the authors to clarify the xaxis labels in Figure 2b, specifying that it should refer to either \"outerloop iterations\" or \"raw experience.\" It also suggests that Figure 2a should be presented with iterations or training steps as the xaxis. These instructions are clear and detailed, allowing the authors to directly implement the changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the xaxis labels in Figure 2b and the presentation of Figure 2a with iterations or training steps as the xaxis. This provides clear guidance on how to improve the clarity of the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are given in walltime and training steps, but it does not provide any specific reasoning or examples to support this claim. The comment suggests that the xaxis labels in Figure 2b are unclear and should be clarified, but it does not offer any evidence or references to support this assertion. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Figure 2, noting that the xaxis labels are unclear and inconsistent across the two subfigures. It provides clear suggestions for improvement, such as clarifying the xaxis labels in Figure 2b and ensuring that Figure 2a also uses iterations or training steps as the xaxis. This feedback is actionable and constructive, as it directly addresses a lack of clarity in the presentation of results, which is crucial for understanding the experimental findings. By providing specific guidance on how to improve the figures, the comment empowers the authors to enhance the clarity and interpretability of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of cost metrics for different devices, suggesting that using the same cost for all devices might be more appropriate. However, it does not provide explicit guidance or suggestions on how to implement this change or what specific aspects of the cost metrics should be considered. The action is implicit, as the authors need to infer that they should explore using a consistent cost metric across devices. The comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of cost metrics for different devices, specifically questioning why different metrics like flops, latency, and 1/FPS are used instead of a consistent cost. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its questioning of the cost metrics, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of cost metrics used in the paper, specifically questioning why different metrics like flops, latency, and 1/FPS are used instead of a consistent cost. While the question is valid and prompts a discussion on the rationale behind the chosen metrics, it does not provide any specific evidence, reasoning, or references to support the claim. The comment lacks depth and does not offer a clear justification for the choice of metrics, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of cost metrics used in the paper, specifically questioning why different metrics like flops, latency, and 1/FPS are used instead of a consistent cost. This is a valid point that could help the authors improve the clarity and consistency of their cost analysis. However, the comment does not provide any suggestions or guidance on how to address this issue or what specific aspects of the cost metrics should be considered. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer that they should explore using a consistent cost metric across devices, but the comment does not offer detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the maximum number of iterations set in the experiment and whether these iterations might significantly slow down the training speed. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address it or what changes might be necessary. The action is implicit, as the authors need to infer that they should investigate the impact of iterations on training speed. However, the comment lacks concrete details on how to implement this investigation or what specific steps to take. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"twodimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the concern about the maximum number of iterations and their potential impact on training speed, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the maximum number of iterations set in the experiment and whether these iterations might significantly slow down the training speed. While it does not contain a direct claim, it prompts the authors to consider the impact of iterations on training speed, which is a relevant aspect of the paper. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the concern.", "helpfulness_rationale": "The review comment raises a question about the maximum number of iterations set in the experiment and whether these iterations might significantly slow down the training speed. This is a relevant concern, as it pertains to the efficiency and practicality of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what steps they could take to optimize their training process. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer that they should investigate the impact of iterations on training speed and consider potential optimizations, but the comment does not offer detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a major weakness in the paper, specifically the lack of theoretical support for the soundness of the method. It suggests that the method resembles a heuristic rather than a theoretically sound approach. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen the theoretical foundation of their method. The feedback is somewhat vague and lacks concrete details on how to improve the theoretical underpinnings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the soundness of the method, particularly the teacher policy\"s approach to distribution matching. It mentions the lack of theoretical results and suggests that the method resembles a heuristic. However, the comment does not specify which part of the paper discusses the teacher policy or the distribution matching process, making it weakly grounded. The comment is specific in detailing the issue with the method\"s soundness, but the lack of grounding makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks theoretical support for the soundness of the method, specifically regarding the teacher policy\"s approach to distribution matching. The reviewer suggests that the method resembles a heuristic rather than a theoretically sound approach. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains 3, as it lacks the necessary depth and clarity to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of theoretical support for the soundness of the method. It highlights that the teacher policy\"s approach to distribution matching lacks theoretical backing, making the method appear more like a heuristic. The reviewer suggests that the authors should provide theoretical results to strengthen the paper\"s foundation. This feedback is clear and actionable, as it directs the authors to address a critical gap in their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to develop these theoretical results. Overall, the comment is 4, as it effectively points out an area for improvement and encourages the authors to enhance the theoretical rigor of their approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method does not perform well in some classes and that the reasons should be analyzed and discussed. While the comment implies that the authors should analyze and discuss the reasons for the poor performance, it does not provide explicit guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should analyze and discuss the reasons for the poor performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors should analyze and discuss the reasons for the proposed method\"s poor performance in some classes. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not perform well in some classes and suggests that the reasons should be analyzed and discussed. However, the comment lacks specific details or examples to support this claim. It does not provide any evidence or references to substantiate the assertion that the method performs poorly in certain classes. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that it does not perform well in some classes. It suggests that the reasons for this poor performance should be analyzed and discussed. While the comment highlights a potential area for improvement, it lacks depth and specificity. It does not provide detailed guidance on how to analyze the reasons for the poor performance or what aspects of the method should be discussed. As a result, the feedback is 3, as it points out a weakness but does not offer comprehensive suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. It also suggests that the experimental results could be further discussed or explained, noting the variation of model behavior under different datasets and settings. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to conduct the additional experiments and discuss the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of experimental settings not being rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. It also suggests that the experimental results could be further discussed or explained, noting the variation of model behavior under different datasets and settings. However, the comment does not specify which part of the paper discusses the experimental settings or results, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on unseen tasks and discussing the variation of model behavior. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. It also suggests that the experimental results could be further discussed or explained, noting the variation of model behavior under different datasets and settings. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. The reasoning is vague and does not provide clear evidence or guidance on how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental design, noting that some settings are not rigorously designed and suggesting that MTT should be tested on unseen tasks. It also points out that the experimental results could be further discussed or explained, highlighting the variation of model behavior under different datasets and settings. While the comment provides some guidance on areas for improvement, it lacks detailed suggestions or specific examples of how to address these issues. The feedback is 3 as it directs the authors to consider additional testing and a more thorough discussion of their results, but it could be more comprehensive with additional guidance on how to conduct these improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the data collection process for the 5 layouts, specifically whether it was randomized. It suggests that the data might have been collected in the same order, potentially introducing learning effects. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure randomization. The action is implicit and vague, as it leaves the authors to infer the need for randomization and the specific steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the data collection process for the 5 layouts, specifically whether it was randomized. It suggests that the data might have been collected in the same order, which could introduce learning effects. However, the comment does not specify which part of the paper this issue relates to, making it weakly grounded. The comment is specific in identifying the potential issue with the data collection process, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the data collection for the 5 layouts was randomized, suggesting that the data might have been collected in the same order, potentially introducing learning effects. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the potential for learning effects in the data collection process for the 5 layouts. It questions whether the data was collected randomly or if there was a consistent order, which could introduce bias. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure randomization. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer the need for further investigation and improvement, which limits the comment\"s overall impact."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the necessity of considering node ordering in the composition space, suggesting that it might not be relevant. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or clarify their reasoning. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the relevance of node ordering in the composition space, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on what needs to be addressed or how the authors might clarify their reasoning. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point questions the relevance of node ordering in the composition space, suggesting that it might not be necessary. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the relevance of node ordering in the composition space, suggesting that it might not be necessary. However, the comment lacks specific details or suggestions on how the authors might address this concern or clarify their reasoning. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not provide sufficient assistance for the authors to address it effectively."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is detracted by a previous work [5], which also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the novelty of their work. It lacks concrete guidance on what specific aspects of the previous work could be discussed or differentiated to enhance the paper\"s contribution. As a result, the authors are left without actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment references a previous work [5] that also presents a dexterous manipulation benchmark with musculoskeletal hands, suggesting that it detracts from the novelty of the current work. However, the comment does not specify which part of the paper discusses the novelty or how the authors should address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of novelty or how to differentiate the current work from the previous one. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is detracted by a previous work [5], which also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed evidence or logical reasoning to substantiate the assertion that the previous work detracts from the novelty of the current work. Without such support, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the work, suggesting that a previous work [5] also presents a dexterous manipulation benchmark with musculoskeletal hands. This observation could impact the authors\" claims of novelty. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or differentiate their work to enhance its novelty. Without actionable feedback or detailed reasoning, the comment is 2, as it provides only a vague observation that may require further clarification or discussion from the authors. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the selection of datasets should be made clearer, specifically asking for details on the pool of datasets and the selection process. It also mentions that the selection of datasets, splitting procedures, and split ratios seem adhoc and lack detail. The comment provides a clear action for the authors to take, which is to clarify these aspects. However, it does not offer concrete guidance on how to implement this action, such as suggesting specific methods or examples for improving clarity. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the selection of datasets, splitting procedures, and split ratios, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on what needs to be clarified, such as the pool of datasets and the selection process, and suggests examples of works that could serve as references. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the selection of datasets, splitting procedures, and split ratios in the paper are not detailed and could be clearer. It suggests that the authors should provide more information on these aspects, referencing examples from other works. However, the comment lacks specific examples or detailed reasoning to fully support the claim. While it provides a general idea of what needs to be addressed, it does not offer a comprehensive explanation or evidence to justify the claim. Therefore, the comment is 3, as it provides a basis for improvement but requires further elaboration or evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the clarity of the dataset selection process, splitting procedures, and split ratios. It provides detailed suggestions for enhancing this aspect, such as specifying the pool of datasets and the selection criteria. Additionally, it references examples of other works that could serve as a basis for improving clarity, such as the OpenML100 and OpenML CC18 datasets. This feedback is clear, actionable, and provides concrete guidance for the authors to improve the transparency and reproducibility of their work. However, the comment could be more helpful if it included specific examples or detailed instructions on how to implement the suggestions. Overall, the comment is 4, as it effectively guides the authors in addressing a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the ablation study, noting that it lacks a critical comparison to a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment suggests that this comparison would be valuable to determine if the proposed method outperforms conventional baselines under the same computational constraints. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion, such as which parts of the draft need to be revised or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing in the study, namely the lack of a critical comparison to a baseline where an unconditional diffusion model is refined using efficient architectural changes before consistency or progressive distillation. This provides clear guidance on what needs to be addressed in the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study lacks a critical comparison, specifically suggesting the inclusion of a baseline where an unconditional diffusion model is refined using efficient architectural changes before consistency or progressive distillation. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the comparison and how it would be implemented. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the ablation study, noting that it lacks a critical comparison to a baseline where an unconditional diffusion model is first refined using efficient architectural changes before consistency or progressive distillation. This feedback is valuable as it provides a clear direction for improvement, suggesting that the authors should include such a comparison to better evaluate the effectiveness of their proposed method. By highlighting this specific area for enhancement, the comment offers actionable guidance that could significantly improve the draft\"s comprehensiveness and impact. However, the comment could be more helpful if it provided additional details or examples of how to conduct this comparison. Overall, the feedback is 4, as it directs the authors towards a meaningful improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks in the paper are based on grasping and that their difficulties are too homogeneous. It recommends referring to projects [1] and [2] to design more tasks. However, the comment does not provide explicit guidance on how to address the issue of homogeneous difficulty or how to design more diverse tasks. The authors are left to infer that they need to consider designing more varied tasks, but the lack of concrete steps or examples makes the action vague and difficult to implement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the tasks in the paper are based on grasping and that their difficulties are too homogeneous. It recommends referring to projects [1] and [2] to design more tasks. However, the comment does not specify which part of the paper discusses the tasks or their difficulty levels, making it difficult for the authors to identify the exact section or part that needs revision. While the suggestion to design more diverse tasks is specific, the lack of grounding makes it challenging for the authors to understand where to apply the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the tasks in the paper are based on grasping and that their difficulties are too homogeneous. It suggests referring to projects [1] and [2] to design more tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the tasks are homogeneous or how the suggested projects could address this issue. Without concrete evidence or references, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the tasks in the paper, suggesting that they are too homogeneous and based on grasping. It recommends referring to projects [1] and [2] to design more diverse tasks. While the comment points out a specific area for improvement, it lacks detailed guidance on how to address the issue of homogeneous difficulty or how to design more varied tasks. The suggestion to refer to specific projects provides a starting point, but it does not offer concrete steps or examples for the authors to follow. Therefore, the comment is 3, as it provides a direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the comparison in Table 2, suggesting that the LEPA training data might be larger than the \"Without Plan/Without SelfReflection\" settings. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the data or experimental setup. The action is implicit, as the authors need to infer that they should investigate the data size difference and potentially adjust their comparison to ensure fairness. The comment is 3 because it identifies a potential problem but lacks concrete steps for resolution. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is: the comparison in Table 2 is unfair due to the potential size difference in the LEPA training data compared to the \"Without Plan/Without SelfReflection\" settings. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with a score of 5.", "verifiability_rationale": "The review point claims that the comparison in Table 2 is unfair due to the potential size difference in the LEPA training data compared to the \"Without Plan/Without SelfReflection\" settings. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the comparison is unfair or how to address the issue. Therefore, the claim is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison in Table 2, specifically questioning whether the LEPA training data is larger than the \"Without Plan/Without SelfReflection\" settings. While the comment points out a potential concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or what specific changes could be made to ensure a fair comparison. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors\" decision to only use synthetic datasets and suggests using real datasets from the GLUE benchmark and realworld diversity datasets. While the comment implies that the authors should consider using these datasets, it does not explicitly instruct them to do so or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should include results with real datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the authors\" decision to use only synthetic datasets and suggests using real datasets from the GLUE benchmark and realworld diversity datasets. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in suggesting the use of real datasets and providing examples, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" decision to only use synthetic datasets and suggests using real datasets from the GLUE benchmark and realworld diversity datasets. While the comment implies that the authors should consider using these datasets, it does not provide specific reasoning or evidence to support why this would be beneficial. The suggestion is based on common practices in the field, but without detailed justification or examples, the claim is 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of results using real datasets, specifically suggesting the use of datasets from the GLUE benchmark and realworld diversity datasets. This feedback is actionable as it provides a clear direction for the authors to enhance their experimental evaluation. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or why realworld datasets are crucial for the study. Overall, the comment is 4 as it identifies a significant gap in the current draft and provides a clear path for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add details on how to solve the optimization in the main paper. This is a clear and explicit action that the authors can readily follow. The comment provides a specific direction for improvement by indicating what needs to be added, making it 5. The authors know exactly what information is missing and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should add details on how to solve the optimization in the main paper. However, it does not specify which part of the paper this optimization is discussed or where the details should be added. This makes it difficult for the authors to identify the exact section or part of the paper that needs improvement. While the comment is specific about the type of information needed, it lacks grounding as it does not provide clear guidance on where to add these details. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should add details on how to solve the optimization in the main paper, noting that this information is currently lacking. However, the comment does not provide any specific examples, references, or reasoning to support why this information is important or how it should be addressed. Without additional context or justification, the claim remains somewhat vague and lacks sufficient evidence to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should add details on how to solve the optimization in the main paper. This is a clear and actionable piece of feedback that provides the authors with a specific direction for enhancing their draft. By highlighting the importance of this information, the comment helps the authors understand what additional content is needed to strengthen their paper. However, the comment could be more helpful if it provided more guidance on how to solve the optimization or suggested specific ways to present the additional details. Overall, the feedback is 4 as it directs the authors towards a concrete improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the exclusion of LLaVAseries and QwenVL from the evaluation, suggesting that these models are commonly adopted LVLMs. It implies that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the comment does not explicitly instruct the authors to include these models or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these models to their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the exclusion of LLaVAseries and QwenVL from the evaluation, suggesting that these models are commonly adopted LVLMs. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. While the comment is specific in its suggestion to include these models, the lack of grounding makes it challenging for the authors to understand where to make the necessary changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the exclusion of LLaVAseries and QwenVL from the evaluation, suggesting that these models are commonly adopted LVLMs. The comment implies that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the claim lacks specific examples or references to support the assertion that these models are commonly adopted or why their inclusion would enhance the evaluation. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential gap in the evaluation by questioning the exclusion of LLaVAseries and QwenVL, which are commonly adopted Large VisionLanguage Models (LVLMs). The suggestion to include these models would provide a more comprehensive comparison across different LVLM architectures and training approaches, enhancing the depth and breadth of the evaluation. However, the comment lacks specific guidance on how to incorporate these models or what aspects of the evaluation would benefit from their inclusion. While it offers a valuable suggestion, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should include captions or descriptions for certain parts of the paper and should also consider using OCRheavy datasets. However, it does not specify which parts of the paper need captions or descriptions, nor does it provide guidance on how to incorporate OCRheavy datasets. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should include captions or descriptions for certain parts of the paper and consider using OCRheavy datasets. However, it does not specify which parts of the paper need captions or descriptions, nor does it provide guidance on how to incorporate OCRheavy datasets. The comment lacks specific details about which sections or figures require captions or descriptions, making it difficult for the authors to identify the exact areas that need improvement. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include captions or descriptions for certain parts of the paper and consider using OCRheavy datasets. However, it does not provide any specific reasoning, examples, or references to support why these suggestions are necessary or beneficial. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the recommendations. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include captions or descriptions for certain parts of the paper and consider using OCRheavy datasets. However, the comment lacks specificity and does not provide detailed guidance on which parts of the paper need captions or descriptions, nor does it explain why OCRheavy datasets are relevant or how they might be incorporated. This feedback is vague and lacks actionable advice, making it difficult for the authors to understand how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between Assumption 3.1 and equation 7 regarding the loss of TKD compared to IYOR. It points out that the assumption contradicts the evidence presented in the equation. However, the comment does not provide explicit guidance on how the authors should address this inconsistency or what specific changes need to be made to align the assumption with the evidence. The action is implicit, as the authors are expected to infer that they need to reconcile the assumption with the equation. While the action is somewhat vague, it is clear that the authors need to address the inconsistency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to \"Assumption 3.1\" and \"equation 7,\" which are specific parts of the paper. This allows the authors to accurately identify the sections being addressed, providing full grounding. The comment highlights a discrepancy between the assumption and the equation, specifying what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between Assumption 3.1 and equation 7 regarding the loss of TKD compared to IYOR. While the comment points out this inconsistency, it does not provide specific examples or references to support the claim that the assumption contradicts the evidence presented in the equation. This lack of detailed explanation or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Assumption 3.1 and equation 7 regarding the loss of TKD compared to IYOR. This observation highlights a potential issue in the paper that needs to be addressed. However, the comment does not provide detailed guidance or suggestions on how the authors might resolve this discrepancy or what specific changes should be made to align the assumption with the evidence presented in the equation. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a problem but does not offer comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of whether question 3, which is mentioned as a weakness, indicates other limitations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to clarify the point. As a result, the authors are left without any actionable feedback, making this comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It refers to \"question 3\" and \"weakness 2 and 4,\" which are not explicitly mentioned in the paper, making it difficult for the authors to identify the exact section or part being discussed. Additionally, the comment is not specific because it does not provide details on what is unclear or needs clarification. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the clarity of whether question 3, which is mentioned as a weakness, indicates other limitations. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any new information or reasoning to support the authors in addressing the issue. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The comment raises a question about the clarity of whether question 3, which is mentioned as a weakness, indicates other limitations. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the point. The feedback is vague and lacks actionable advice, making it difficult for the authors to improve their draft based on this comment. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not provide any explicit or implicit guidance on how the authors should address this concern or what changes they should make to their draft. The comment lacks specific suggestions or actions for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail why the authors should consider middle layers or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. This feedback is 3 as it identifies a potential area for improvement and prompts the authors to consider alternative approaches. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what changes could be made to their draft. Without actionable advice or detailed reasoning, the comment provides limited value to the authors, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the motivation behind using GUE for determining tokenization, model architecture, and training objective for a generative model. It suggests that the representations learned might be optimized for a narrow set of tasks in GUE, limiting their generalizability. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the motivation. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to respond or improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the motivation behind using GUE for determining tokenization, model architecture, and training objective for a generative model. It highlights that the representations learned might be optimized for a narrow set of tasks in GUE, limiting their generalizability. However, the comment does not specify which part of the paper discusses these choices or tasks, making it difficult for the authors to pinpoint the exact section being addressed. While the issue is specific, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the motivation behind using GUE for determining tokenization, model architecture, and training objective for a generative model. It suggests that the representations learned might be optimized for a narrow set of tasks in GUE, potentially limiting their generalizability. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the motivation behind using GUE for determining tokenization, model architecture, and training objective for a generative model. It highlights that the representations learned might be optimized for a narrow set of tasks in GUE, potentially limiting their generalizability. This feedback is valuable as it points out a potential issue with the motivation and suggests that the authors should consider the broader applicability of their model. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as exploring alternative datasets or tasks to enhance the generalizability of the model. Overall, the comment is 3, as it raises an important point but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant issue with the paper\"s readability, specifically due to grammar and spelling errors. However, it does not provide any explicit or implicit suggestions on how to address these issues. The authors are left without guidance on what specific changes to make or how to improve the writing quality. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment identifies a general issue with the paper\"s readability due to grammar and spelling errors, but it does not specify which part of the paper is affected or provide any details on what needs to be addressed. The authors cannot confidently determine which section or aspect of the paper requires revision. Therefore, the comment is 1, as it lacks specific information about the part of the paper being addressed. It is also not specific because it does not detail what needs to be improved. This comment aligns with a score of 1 and Not Specific.", "verifiability_rationale": "The review point claims that the paper reads clunkily due to significant grammar and spelling errors, requiring a major editing pass. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the nature of the errors and how to address them. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s readability, specifically due to grammar and spelling errors. However, it lacks specific details or suggestions on how to address these issues. The authors are left without guidance on what specific changes to make or how to improve the writing quality. While the comment highlights a critical area for improvement, it does not provide actionable feedback or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function used in the regression, particularly concerning the convergence of SGD and potential issues arising from the minibatch loss function. However, the comment does not provide explicit guidance or suggestions on how the authors might address these questions or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function used in the regression, particularly concerning the convergence of SGD and potential issues arising from the minibatch loss function. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections or elements being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function used in the regression, particularly concerning the convergence of SGD and potential issues arising from the minibatch loss function. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are openended and lack depth, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function used in the regression, particularly concerning the convergence of SGD and potential issues arising from the minibatch loss function. However, the comment does not provide any suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is primarily critical and lacks actionable advice, making it 2 to the authors. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation where the method might struggle to shift focus to a new target due to constraints from previous masks. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the method. The action is implicit, as the authors would need to infer that they should investigate the method\"s ability to handle multiple objects and consider potential solutions. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OIS\" and \"Objectlevel Understanding,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the ability of OIS to handle interactive segmentation for multiple objects simultaneously, highlighting a potential limitation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It suggests that the method might struggle to shift focus to a new target due to constraints from previous masks, potentially reducing its practical utility. The comment references a specific paper [1] to support the claim, providing a basis for the authors to understand the context and potential limitations. However, the reasoning could be more detailed, and the suggestion for improvement is somewhat vague. Overall, the claim is 4, as it is supported by a reference but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific limitation of the Objectlevel Understanding (OIS) method, particularly its ability to handle interactive segmentation for multiple objects simultaneously. It highlights a potential issue where the method might struggle to shift focus to a new target due to constraints from previous masks, which could reduce its practical utility. The comment references a specific paper [1] to support the claim, providing context and suggesting that the authors should consider this limitation. However, the feedback could be more helpful if it offered suggestions on how to address this limitation or potential improvements to the method. Overall, the comment is 3 as it points out a critical issue that needs attention, but it lacks depth and actionable guidance, making it only partially beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the realism of the assumption that anomalies align with concepts, particularly in scenarios where the type of anomalies is unknown. It provides an example of intrusion and fraud detection systems that use anomaly detectors without aligning them with concepts. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to align their system with concepts. While the authors might infer that they need to discuss the limitations of their assumption, the action is implicit and somewhat vague, as it lacks concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to anomaly detection systems, particularly focusing on the assumption that anomalies align with concepts. It provides an example of intrusion and fraud detection systems that do not align anomalies with concepts, highlighting the potential issue with the proposed system. However, the comment does not explicitly mention a specific part of the paper, such as a section or figure, making it weakly grounded. It is specific in detailing the issue and suggesting that the authors consider the realism of their assumption and the implications of aligning anomalies with concepts. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the realism of the assumption that anomalies align with concepts in anomaly detection systems. It provides an example of intrusion and fraud detection systems that do not align anomalies with concepts, suggesting that the proposed system\"s assumption might be unrealistic. However, the comment lacks specific evidence or references to support the claim that aligning anomalies with concepts is unrealistic or impractical. Without detailed reasoning or examples, the claim remains 3, as it is based on a logical argument but lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the realism of the assumption that anomalies align with concepts in the proposed system. It provides a clear example of intrusion and fraud detection systems that do not rely on this assumption, highlighting a potential limitation. However, the comment could be more helpful by offering suggestions or guidance on how the authors might address this issue or consider alternative approaches. While it identifies a significant area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of discussion on the limitations and challenges of HLOP and the experimental design, making it difficult for the authors to assess the tradeoffs between using HLOP and other approaches. It suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. However, the comment does not provide explicit guidance on how to address these issues or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the current limitations/challenges of HLOP and the experimental design, making it difficult to judge the tradeoffs between using HLOP versus other approaches. It suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. However, the comment does not specify which part of the paper this issue is discussed, leaving the authors to infer that it pertains to the introduction or related work sections. The comment is specific in its suggestion to include a discussion on the downsides of HLOP and the limitations of the evaluation process, but it is weakly grounded as it does not explicitly mention the sections where these discussions should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is almost no discussion on the current limitations/challenges of HLOP and the experimental design, making it hard to judge the tradeoffs between using HLOP versus other approaches. The comment suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is 3, as it provides a general observation but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the lack of discussion on the current limitations and challenges of HLOP, as well as the experimental design. This omission makes it difficult for the authors to understand the tradeoffs between using HLOP and other approaches. The comment suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is 3 as it highlights an important area for improvement, but it could be more comprehensive with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the effectiveness of their proposed gating scheme on more recent language models, such as FlanT5 and Llama, which have not been studied in the work. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to enhance the contribution of their paper. The comment is specific in its recommendation and offers concrete guidance on how to improve the evaluation of the proposed gating scheme. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the effectiveness of the proposed gating scheme on more recent language models, such as FlanT5 and Llama, which have not been studied in the work. This provides a clear and specific direction for the authors to enhance their contribution. However, the comment does not explicitly mention which part of the paper discusses the gating scheme or where these models are mentioned. This makes it somewhat challenging for the authors to pinpoint the exact sections that need revision. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that many more language models have been released after GPT2, such as FlanT5 and Llama, which have not been studied in this work. The comment suggests evaluating the effectiveness of the proposed gating scheme on these recently proposed LMs to make the contribution more prominent. However, the comment lacks specific examples or references to support the claim about the release of these models and their absence in the study. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the study by pointing out that many recent language models, such as FlanT5 and Llama, have not been evaluated in the context of the proposed gating scheme. This feedback is valuable as it suggests expanding the evaluation to include these more recent models, which could enhance the contribution and relevance of the work. By recommending this additional evaluation, the comment provides a clear and actionable direction for the authors to improve their study. However, the comment could be more helpful if it offered specific guidance on how to conduct the evaluation or what aspects of the gating scheme should be considered. Overall, the comment is 4, as it highlights an important area for improvement and encourages the authors to broaden their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some recent works might be highly correlated with the proposed method and should be cited and compared against. It provides an example of a specific work that might share similarity with the proposed method and needs to be discussed in context. However, the comment does not explicitly instruct the authors to cite or compare against these works, nor does it provide detailed guidance on how to incorporate this comparison into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should address these works in their discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that some recent works might be highly correlated with the proposed method and should be cited and compared against, providing an example of a specific work that might share similarity with the proposed method. However, the comment does not specify which part of the paper this comparison should be made or where the authors should discuss the similarities. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper needs attention. The comment is specific in suggesting the need for comparison and citation, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some recent works might be highly correlated with the proposed method and should be cited and compared against, providing an example of a specific work that might share similarity with the proposed method. However, the comment lacks specific details or references to support the claim that these works are highly correlated or relevant. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 2, as it provides some basis for action but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should cite and compare against some recent works that might be highly correlated with the proposed method. It provides a specific example of a relevant work, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation  Wang et al. cvpr2020,\" which shares some similarity with the proposed method. This feedback is 3 as it directs the authors to consider additional relevant literature and comparisons, which could enhance the paper\"s context and robustness. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these comparisons or suggested specific ways to address the similarities. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests adding more detail about how UNKs are handled by the neural decoder or citing a dictionarybased replacement strategy. While the comment provides a clear action\u2014either adding more detail or citing a strategy\u2014it does not specify exactly what needs to be added or how to implement it. The action is explicit but somewhat vague, as it leaves the authors to infer the specific details to be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more detail about how UNKs are handled by the neural decoder or citing a dictionarybased replacement strategy. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific about the content to be addressed, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding more detail about how UNKs are handled by the neural decoder or citing a dictionarybased replacement strategy. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors add more detail about how UNKs are handled by the neural decoder or cite a dictionarybased replacement strategy. This feedback is actionable and directly addresses a potential area of confusion or lack of clarity in the paper. By providing a clear direction for improvement, the comment empowers the authors to enhance the completeness and transparency of their work. However, the comment could be more helpful if it included additional guidance on how to implement the suggested changes or provided examples of relevant literature. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that other stateoftheart code summarization methods, such as those using pretrained models, should be compared in the experiments. This provides a clear and explicit action for the authors to take, as they need to include these comparisons in their experimental setup. The comment is specific in its suggestion and provides concrete guidance on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that other stateoftheart code summarization methods, such as those using pretrained models, should be compared in the experiments. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this suggestion. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of recommending comparisons, it lacks detailed guidance on how to implement these comparisons or what specific methods should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other stateoftheart code summarization methods, such as those using pretrained models, should be compared in the experiments. However, the comment does not provide any specific reasoning, examples, or references to support why these methods should be included or how they might impact the results. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the paper should include comparisons with other stateoftheart code summarization methods, particularly those using pretrained models, in the experiments. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their experimental evaluation. By comparing their method with other SOTA approaches, the authors can better demonstrate the effectiveness and novelty of their work. However, the comment could be more helpful if it provided additional guidance on which specific methods to compare or how to analyze the results. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the results presented in Table 3, specifically regarding the performance of Scheduled Bernoulli compared to AttendOut. It asks for the reason behind AttendOut having lower variance and the statistical significance value when comparing the two. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how to address these questions or improve the draft. The authors are left to infer that they need to provide explanations and statistical significance values to address the concerns raised. Therefore, the comment is 3, as it provides implicit guidance but lacks concrete details on how to implement the suggestions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues raised, such as the unexpected result of Scheduled Bernoulli being better than AttendOut and the need for an explanation regarding AttendOut\"s lower variance and the statistical significance value. This provides the authors with clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the results presented in Table 3, specifically regarding the performance of Scheduled Bernoulli compared to AttendOut. It asks for the reason behind AttendOut having lower variance and the statistical significance value when comparing the two. While the comment identifies areas that need clarification, it does not provide any supporting evidence, reasoning, or references to justify the claims. The authors are left to interpret the questions and potentially seek additional information or clarification independently. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the results presented in Table 3, where the performance of Scheduled Bernoulli is better than AttendOut, and questions the reason for AttendOut\"s lower variance and the statistical significance of the comparison. This feedback is clear and actionable, as it prompts the authors to provide additional explanations and statistical analysis to address the concerns. By highlighting these specific areas for improvement, the comment guides the authors in enhancing the clarity and rigor of their results. However, it could be more helpful if it suggested specific methods for calculating statistical significance or provided examples of how to explain the results. Overall, the comment is 4, as it effectively points out areas that need further attention and improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the results presented in Equation 1, specifically questioning the reasonableness of the difference between confidence and accuracy for a single sample. However, it does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary. The comment lacks concrete guidance on how the authors should investigate or resolve this concern, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for improvement.", "grounding_specificity_rationale": "The comment raises a concern about the reasonableness of the difference between confidence and accuracy for one sample in Equation 1. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being discussed. The comment is 1 as it lacks specific references to the paper, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reasonableness of the difference between confidence and accuracy for one sample in Equation 1. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the reasonableness of the difference between confidence and accuracy for one sample in Equation 1. While it points out a potential concern, it does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to the results. The comment lacks actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a problem but does not offer any constructive feedback or suggestions for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the method when the sample is shifted from the data distribution. It suggests that the current approach may fail in such settings and asks if there is a way to adapt the method to account for the shift. While the comment identifies a potential issue with the method\"s applicability, it does not provide explicit guidance on how to address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore alternative methods or adapt the current approach to handle the shift. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the method when the sample is shifted from the data distribution, suggesting that the current approach may fail in such settings. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the issue needs to be addressed. While the comment is specific in its questioning of the method\"s applicability, the absence of explicit grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the method when the sample is shifted from the data distribution, suggesting that the current approach may fail in such settings. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the method when the sample is shifted from the data distribution, suggesting that the current approach may fail in such settings. It prompts the authors to consider whether there is a way to adapt the method to account for this shift. While the comment identifies a potential limitation or area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The feedback is 3 as it highlights a potential area for further exploration, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the contextdependent nature of word replacement and suggests that replacing words independently could lead to incoherent text. It implies that the authors should consider replacing whole phrases instead. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the text. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific question about word replacement in the text, referencing lines 076079. It highlights a potential issue with replacing words independently, suggesting that it could create incoherent text. The comment is fully grounded as it explicitly mentions the lines being discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with independent word replacement and suggests an alternative approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the contextdependent nature of word replacement and suggests that replacing words independently could lead to incoherent text. It provides an example to illustrate the issue, but it does not offer a detailed explanation or justification for why this is a problem. The comment lacks specific references or logical reasoning to fully support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the contextdependent nature of word replacement, noting that replacing words independently could lead to incoherent text. It provides an example to illustrate the issue, suggesting that replacing whole phrases might be a better approach. This feedback is clear and actionable, as it identifies a potential problem with the text and offers a constructive suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to implement the suggested change or what specific aspects of the text need to be revised. Overall, the comment is 4, as it provides valuable insights and direction for the authors to enhance the coherence of their text."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to include a runtime comparison of different deep learningbased methods. However, it does not provide any explicit instructions or guidance on how to conduct this comparison or what specific aspects should be included. The action is implicit, as the authors would need to infer that they should add a section or subsection detailing the runtime performance of various deep learning methods. This lack of specificity makes the action somewhat vague and challenging to implement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a runtime comparison of different deep learningbased methods, but it does not specify which methods or aspects of the comparison should be included. This makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is fully grounded in terms of identifying the area of the paper that could be improved, but it lacks specificity in detailing what needs to be addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including a runtime comparison of different deep learningbased methods, which is a reasonable and practical suggestion for improving the paper. However, it lacks specific details or examples of how this comparison could be conducted or what aspects of the comparison should be included. Without additional guidance or examples, the authors may find it challenging to understand how to implement this suggestion effectively. Therefore, the comment is 3, as it provides a general direction but lacks the necessary depth and specificity to be fully actionable.", "helpfulness_rationale": "The review comment suggests including a runtime comparison of different deep learningbased methods, which is a practical and actionable suggestion for improving the paper. By providing this feedback, the reviewer offers a clear direction for the authors to enhance their work. However, the comment lacks specific details or examples of how to conduct this comparison, which could make it challenging for the authors to implement. While the feedback is 3, it could be more comprehensive if it included suggestions on what aspects of the runtime comparison should be included or how to present the results effectively. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the ECG encoder, which currently uses only 1D CNN layers and average pooling, should be improved by exploring ECGspecific architectures using SSL or transformerbased methods. It also implies that these architectures should be compared and explored similarly to how different methods were explored for the other two parts of the framework. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be addressed and how to implement it. The comment is fully actionable, as it gives specific guidance on how to enhance the ECG encoder.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the three parts of the MEIT framework: the ECG encoder, modality alignment, and LLM backbone. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides detailed feedback on the ECG encoder, suggesting that it should use more sophisticated architectures like SSL or transformerbased methods, which are not currently explored. This guidance is clear and specific, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the ECG encoder, which currently uses only 1D CNN layers and average pooling, should be improved by exploring ECGspecific architectures using SSL or transformerbased methods. The comment suggests that these architectures should be compared and explored similarly to how different methods were explored for the other two parts of the framework. However, the comment lacks specific examples or references to support the claim that these architectures are more effective or could significantly improve the current approach. Without detailed examples or references, the claim is 3, as it provides a direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the ECG encoder within the MEIT framework, noting that it currently uses only 1D CNN layers and average pooling. It suggests that exploring ECGspecific architectures using SSL or transformerbased methods could significantly improve the performance of the encoder. This feedback is actionable as it offers a clear direction for the authors to enhance their model. By recommending the exploration of more advanced architectures, the comment provides valuable guidance on how to potentially improve the model\"s capabilities. However, it could be more helpful if it included specific examples of such architectures or a detailed explanation of why these methods are expected to be more effective. Overall, the comment is 4, as it identifies a specific area for improvement and offers a clear direction for action, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to rephrase the abstract to accurately reflect the paper\"s focus on a modelagnostic explainability technique for deep neural networks, rather than a defense methodology. This provides a clear and direct action for the authors to take, making the comment 5. The comment is specific in its suggestion and offers a concrete direction for improvement, allowing the authors to understand exactly what needs to be done. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the abstract, which inaccurately suggests a defense methodology is proposed, while the paper actually presents a modelagnostic explainability technique. This provides the authors with a clear understanding of what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract inaccurately suggests a defense methodology is proposed, while the paper presents a modelagnostic explainability technique. This claim is supported by the reviewer\"s assertion that the abstract is misleading, providing a clear and logical basis for the critique. However, the comment lacks specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it identifies a critical issue with the abstract, specifically that it inaccurately suggests a defense methodology is proposed, while the paper actually presents a modelagnostic explainability technique. This feedback is clear and actionable, providing the authors with a specific direction to improve the accuracy and clarity of their abstract. By rephrasing the abstract to reflect the correct focus, the authors can avoid confusion and enhance the overall understanding of their work. The comment is detailed and provides a clear path for improvement, making it highly valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that it lacks comparisons to recent methods that propose new activation functions for INRs. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to include comparisons with these recent methods, but the lack of detailed instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s comparison with earlier methods and highlights the lack of comparisons with recent methods like FINER, Incode, and SL2AINR. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue by mentioning the absence of comparisons with these recent methods, which propose new activation functions for INRs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparisons to recent methods that propose new activation functions for INRs, specifically mentioning FINER, Incode, and SL2AINR. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or references, the authors are left to question the validity of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the lack of comparisons with recent methods that propose new activation functions for INRs. This feedback is valuable as it highlights an area where the paper could be strengthened by including more comprehensive comparisons. However, the comment could be more helpful if it provided specific examples of these recent methods or suggested how the authors might address this gap in their analysis. While it offers a clear direction for improvement, the lack of detailed guidance limits its impact. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, provided that the models are finetuned. However, it does not provide explicit guidance on how to improve the evaluation setting or what specific changes should be made. The action is implicit, as the authors would need to infer that they should consider the suggested method and its implications for their evaluation. The comment lacks concrete details on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, provided that the models are finetuned. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting that the evaluation setting can be improved, but without explicit guidance on how to do so, it remains somewhat specific. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that a straightforward method works well in practice and challenges the value of research on length extrapolation, provided that the models are finetuned. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the straightforward method is effective or how it impacts the value of length extrapolation research. Without these elements, the claim is difficult to verify, making the comment 1.", "helpfulness_rationale": "The review comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, provided that the models are finetuned. This feedback provides a clear insight into a potential issue with the evaluation setting, suggesting that the authors should consider the implications of using a straightforward method and its impact on the value of their research. However, the comment lacks specific guidance on how to improve the evaluation setting or what changes could be made to address this concern. While it offers a valuable observation, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification regarding the training and testing environments used in the autoencoder training process described in Section 2.4. It also suggests that the authors consider performing crossvalidation to demonstrate the robustness of their results. While the comment provides a clear action\u2014asking for clarification and suggesting an improvement\u2014it does not offer specific guidance on how to address the question or implement the suggestion. The action is explicit but somewhat vague in terms of providing detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding the training and testing environments used in the autoencoder training process, and suggests that the authors consider performing crossvalidation to demonstrate the robustness of their results. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the training and testing environments used in the autoencoder training process described in Section 2.4. It suggests that the authors consider performing crossvalidation to demonstrate the robustness of their results. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would improve the paper. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper, Section 2.4, where the training and testing environments of an autoencoder are mentioned. It raises a question about which environment is used for training and which for testing, and suggests that the authors consider performing crossvalidation to demonstrate the robustness of their results. This feedback is clear and actionable, as it directly points out a lack of clarity in the description and provides a concrete suggestion for improvement. However, it could be more helpful if it included specific guidance on how to implement the crossvalidation or what metrics to use. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison to demonstrate how refinement during inference improves generation quality. It mentions that the statistic of the number of refinements only approves the change but does not provide evidence of improvement. While the comment implies that the authors should include a comparison to substantiate the claim, it does not explicitly instruct them to add this comparison or specify how it should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison to show the improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. While it specifies the issue of comparison, it lacks specificity in terms of how this comparison should be made or what data should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to demonstrate how refinement during inference improves generation quality. It suggests that the inclusion of a comparison would substantiate the claim of improvement. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some indication of the need for comparison but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of a comparison to demonstrate how refinement during inference improves generation quality. While the comment acknowledges the inclusion of statistics on the number of refinements, it argues that this only approves the change rather than providing evidence of improvement. This feedback is 3 as it highlights a critical area for improvement, suggesting that the authors should include a comparison to substantiate their claims about the effectiveness of the refinement process. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what data to include. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions: one about the missing threshold for PMI and another about whether the partitions were done randomly. While the questions are specific and direct, they do not provide explicit instructions on how the authors should address these issues. The authors are left to infer that they need to clarify the missing threshold and the randomness of the partitions. However, the lack of explicit guidance on how to address these issues makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (336 and 371) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, namely the missing threshold for PMI and the randomness of the partitions. This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the missing threshold for PMI and whether the partitions were done randomly. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, lacking any reasoning or evidence to support it. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises two specific questions about the paper: one regarding the missing threshold for PMI and another about whether the partitions were done randomly. While these questions highlight potential areas for clarification, they do not provide actionable feedback or suggestions on how the authors might address these issues. The comment lacks depth and does not offer guidance on improving the draft, making it 2. Therefore, the comment is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the MDP compared to ImageNet pretraining and individual dataset finetuning. While it prompts the authors to provide this comparison, it does not explicitly instruct them to include it in the draft or suggest where to add it. The action is implicit, as the authors can infer that they need to address this comparison in their paper. However, the comment lacks concrete guidance on how to present or discuss this comparison, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the training time of the MDP compared to ImageNet pretraining and individual dataset finetuning. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its request for a comparison, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the training time of the MDP compared to ImageNet pretraining and individual dataset finetuning. However, it does not contain any claims or opinions that require verification. The comment is purely factual and descriptive, asking for a comparison that the authors may or may not provide. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the training time of the MDP compared to ImageNet pretraining and individual dataset finetuning. This question highlights a potential area for clarification or additional information that could enhance the understanding of the methodology. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or incorporate it into their work. While it identifies a relevant aspect, it does not provide specific advice or steps for improvement, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the author\"s claim about GPDE being an intentional design leveraging the advantages of spike ODE and graph ODE is questionable, suggesting that GPDE is an incremental improvement over GraphCON, with a static encoder replaced by SNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to align with the feedback. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the author\"s claim about GPDE being an intentional design leveraging the advantages of spike ODE and graph ODE, suggesting that it is an incremental improvement over GraphCON, where the static encoder is replaced by SNN. However, the comment does not specify which part of the paper this claim is made or which section discusses GPDE. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. While the comment is specific in its critique of the design, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author\"s assertion about GPDE being an intentional design leveraging the advantages of spike ODE and graph ODE is questionable, suggesting that it is an incremental improvement over GraphCON, with a static encoder replaced by SNN. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the claim remains 1, as the authors cannot confidently assess the validity of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the author\"s claim regarding the design of GPDE, suggesting that it might be an incremental improvement over GraphCON rather than an intentional design leveraging the advantages of spike ODE and graph ODE. This feedback is 3 as it points out a specific area that needs clarification or further justification. However, the comment lacks depth and does not provide detailed guidance on how the authors might address this issue or what specific aspects of their design need to be reconsidered. Without actionable suggestions or examples, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific instances where the proposed method does not outperform Jiang et al. significantly, particularly in Penetration(Dep), CR, and SimDisp(Mean). However, it does not provide explicit guidance or suggestions on how the authors might address these performance gaps or improve their method. The comment lacks actionable steps, leaving the authors uncertain about what changes to make to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides specific details about the performance of the proposed method compared to Jiang et al. in different metrics, such as Penetration(Dep), CR, and SimDisp(Mean). It highlights instances where the proposed method does not outperform Jiang et al. significantly, particularly in Penetration(Dep) and CR, and even performs worse in SimDisp(Mean). This level of detail allows the authors to identify the specific areas where the proposed method underperforms, making the comment fully grounded. The comment is also specific as it clearly specifies the metrics and the performance differences, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not outperform Jiang et al. significantly, particularly in Penetration(Dep), CR, and SimDisp(Mean). The comment provides specific numerical comparisons, such as Ours(100.00%) outperforming Jiang et al.(99.97%) by only 0.03% in Penetration(Dep) and CR, and being worse in SimDisp(Mean). These specific numerical comparisons provide clear evidence to support the claim, making it 4. However, the comment could be strengthened by including a brief explanation of why these differences are significant or by referencing relevant literature to provide context. Overall, the claim is 4.", "helpfulness_rationale": "The review comment provides specific numerical comparisons of the proposed method\"s performance against Jiang et al. across different metrics, such as Penetration(Dep), CR, and SimDisp(Mean). It highlights instances where the proposed method does not outperform Jiang et al. significantly, particularly in Penetration(Dep) and CR, and even performs worse in SimDisp(Mean). This feedback is 3 as it identifies areas where the proposed method needs improvement. However, it lacks actionable suggestions or guidance on how the authors might address these performance gaps or enhance their method. The comment could be more helpful if it provided specific recommendations or suggestions for improvement, such as potential modifications to the method or additional experiments to conduct. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the paper. First, it points out that the term \"vFSAD\" is not clearly defined and that there is a large body of work on OOD detection in timeseries data that is not mentioned or compared with. The reviewer provides an example of a relevant work, \"CODiT: Conformal OutofDistribution Detection in TimeSeries Data,\" to illustrate this point. Second, the reviewer criticizes the related work subtitles of \"Policy\" and \"Evaluation tasks\" for being descriptive and seemingly unrelated to the actual content of the paper. While the comment identifies two distinct issues, it does not provide explicit guidance on how the authors should address these problems. The actions are implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two distinct issues. First, it critiques the lack of comparison with existing work on OOD detection in timeseries data, specifically mentioning the absence of discussion and comparison with relevant works like Kaur et al. \"CODiT: Conformal OutofDistribution Detection in TimeSeries Data.\" This part of the comment is fully grounded as it explicitly mentions the specific work being referred to, allowing the authors to identify the relevant section. Second, the comment critiques the related work subtitles of \"Policy\" and \"Evaluation tasks,\" noting that they are not descriptive and seem unrelated to the actual content of the paper. However, the comment does not specify what aspects of these subtitles need to be improved or how the authors should revise them. This makes the comment weakly grounded but specific regarding the first issue and somewhat grounded and specific regarding the second. Overall, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the term \"vFSAD\" is not clearly defined and that there is a large body of work on OOD detection in timeseries data that is not mentioned or compared with. The reviewer provides an example of a relevant work, \"CODiT: Conformal OutofDistribution Detection in TimeSeries Data,\" to support this claim. However, the comment lacks detailed reasoning or specific examples beyond the one provided, making it 3. The authors would need to infer the missing comparisons and understand the relevance of the example to fully grasp the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out that the term \"vFSAD\" is not clearly defined and that there is a significant amount of work on OOD detection in timeseries data that is not mentioned or compared with. The reviewer provides an example of a relevant work, \"CODiT: Conformal OutofDistribution Detection in TimeSeries Data,\" to illustrate this point. This feedback is 3 as it highlights a gap in the related work section and suggests that the authors should include a more comprehensive comparison with existing literature. However, the comment could be more helpful if it provided specific guidance on how to incorporate or compare with these works. Second, the comment critiques the related work subtitles of \"Policy\" and \"Evaluation tasks,\" noting that they are not descriptive and seem unrelated to the actual content of the paper. While this feedback is valuable, it lacks detailed suggestions on how the authors should revise these subtitles to better reflect the content of the paper. Overall, the comment provides some insights but could be more actionable and detailed to fully assist the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the effect of memory size is ambiguous and recommends adding an ablation study to justify the memory size selection. This provides a clear and explicit action for the authors to take, which is to conduct an ablation study. The comment is specific in its suggestion, detailing what needs to be done to address the ambiguity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding an ablation study to address the ambiguity of the effect of memory size. However, it does not specify which part of the paper discusses the effect of memory size, making it difficult for the authors to identify the exact section or figure that needs revision. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper is being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the effect of memory size is ambiguous or how an ablation study would address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the effect of memory size and suggests adding an ablation study to justify the memory size selection. This feedback is clear and actionable, providing a specific direction for the authors to improve their draft. By recommending an ablation study, the comment offers a concrete way to address a potential weakness in the paper, enhancing its clarity and robustness. However, the comment could be more helpful if it provided more details on how to conduct the ablation study or what specific results would be expected. Overall, the comment is 4 as it offers a clear and actionable suggestion, but it could be further enhanced with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the placement of the abbreviation GNN and its full definition. It notes that the abbreviation is mentioned at the end of page 1, while the full definition appears much later in Section 2, at the end of page 2. This feedback is explicit and provides a clear action for the authors to take: they should ensure that the full definition of GNN is provided earlier in the paper, ideally when the abbreviation is first introduced. The comment is specific and actionable, as it directs the authors to a particular part of the paper that needs attention. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the placement of the abbreviation GNN and its full definition within the paper, allowing the authors to accurately identify the specific part being addressed. It is also specific because it clearly specifies the issue: the abbreviation is mentioned before its full definition is provided, which could lead to confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a factual observation about the placement of the abbreviation GNN and its full definition within the paper. It notes that the abbreviation is mentioned before its full definition is provided, which could lead to confusion for the reader. However, the comment does not provide any additional context, reasoning, or references to support this observation. As a result, the claim is 3, as it is based on a clear observation but lacks sufficient evidence or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the placement of the abbreviation GNN and its full definition within the paper. It points out that the abbreviation is mentioned at the end of page 1, while the full definition \"Graph Neural Network (GNN)\" appears much later in Section 2, at the end of page 2. This feedback is clear and actionable, as it directs the authors to ensure that the full definition of GNN is provided earlier in the paper, ideally when the abbreviation is first introduced. By addressing this issue, the authors can improve the clarity and readability of their paper. Therefore, the comment is 4, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the performance of baseline methods on the DAVIS dataset, noting that it is lower than stateoftheart results. It also suggests that the effectiveness of the proposed loss function might not guarantee its effectiveness on topperforming algorithms. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting improvements or providing additional data. The authors are left without guidance on how to address this issue or what steps to take to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of baseline methods on the DAVIS dataset, referencing a specific result from a cited paper. It highlights a concern about the effectiveness of the proposed loss function in comparison to stateoftheart results. However, the comment does not specify which part of the paper discusses the performance on the DAVIS dataset or the effectiveness of the loss function. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of low performance and the comparison with stateoftheart results, it lacks grounding as it does not clearly identify the sections being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of baseline methods on the DAVIS dataset is rather low, comparing it with stateoftheart results. It provides a specific example, citing a paper that reports a 65.6% J mean on 2019val. The comment also suggests that the effectiveness of the proposed loss function might not guarantee its effectiveness on topperforming algorithms. However, the claim lacks detailed reasoning or examples to fully substantiate the assertion about the low performance and the limitations of the proposed loss function. The absence of a clear explanation or additional evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of baseline methods on the DAVIS dataset, noting that it is lower than stateoftheart results. It provides a reference to a specific paper that reports a 65.6% J mean on 2019val, which helps contextualize the performance of the proposed method. However, the comment does not offer actionable suggestions or insights into how the authors might address this issue or improve their results. While it highlights a potential area for improvement, it lacks depth and guidance, making it 3. The authors would need to infer how to address the issue based on the feedback, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reporting of results for the proposed twostep decoding method and asks for clarification on whether the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference if the twostep method is not used. While the comment identifies a specific area of confusion and asks for clarification, it does not provide explicit instructions or suggestions on how to address this issue. The authors would need to infer that they should check the paper for the reporting of results and clarify the methodology. Therefore, the comment is 3, as it points out a specific issue but lacks detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment raises a question about the reporting of results for the proposed twostep decoding method and asks for clarification on whether the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference if the twostep method is not used. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification and detailed information, but without explicit references to sections or tables, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reporting of results for the proposed twostep decoding method and asks for clarification on whether the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference if the twostep method is not used. However, the comment does not provide any evidence, reasoning, or references to support the claim that the results are missing or unclear. Without additional context or justification, the authors are left to assume the claim is valid, making it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the reporting of results for the proposed twostep decoding method and asks for clarification on whether the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference if the twostep method is not used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it highlights a specific area that needs clarification, but it lacks depth and actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the small font size in the figures, and provides a direct action for improvement: increasing the font size. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the font size in the figures is too small, which could hinder readability. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the font size is an issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures, noting that the font size is too small, which could affect readability. It provides a clear and actionable suggestion for improvement by instructing the authors to increase the font size. This feedback is direct and helpful, as it guides the authors on what needs to be addressed to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it suggested alternative font sizes or provided guidance on how to increase the font size effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that only synthetic problems are considered in the experiments. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the experiments need to be addressed or how the authors should modify their approach to include realworld problems. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that only synthetic problems are considered in the experiments, but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in pointing out a potential limitation in the experimental setup, as it highlights the absence of realworld problems. This provides clear guidance on what needs to be addressed, making the comment somewhat specific. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only synthetic problems are considered in the experiments. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to verify or address the issue. Without additional information or context, the authors may struggle to understand the scope of the experiments or how to incorporate realworld problems. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that only synthetic problems are considered in the experiments, which is a specific observation that could indicate a limitation in the scope of the study. However, the comment lacks actionable guidance or suggestions for the authors to address this issue. It does not provide any insight into how the authors might expand their experiments to include realworld problems or what specific aspects of the current experiments need to be modified. Without further elaboration or suggestions, the comment is 3 as it identifies a potential area for improvement, but it does not provide a comprehensive or detailed response. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the authors\" draft, noting that they have only compared their explainer to feature attribution methods and have not included comparisons with other Natural Language Explanations (NLE) interpretability tools. While the comment identifies a gap in the evaluation, it does not provide explicit guidance on which specific NLE tools should be included or how to compare them. The action is implicit, as the authors need to infer that they should add comparisons with other NLE tools to their evaluation. However, the lack of concrete suggestions or detailed guidance on which tools to include makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"NLE baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors have only compared their explainer to feature attribution methods and have not included comparisons with other NLE interpretability tools. This provides a clear direction for the authors to improve their evaluation by including additional comparisons. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have only compared their explainer to feature attribution methods and have not included comparisons with other Natural Language Explanations (NLE) interpretability tools. This claim is 3 as it highlights a gap in the evaluation, but it lacks specific examples or references to support the suggestion of including other NLE tools. The authors would need to provide more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the authors\" work by pointing out the absence of comparisons with other Natural Language Explanations (NLE) interpretability tools. This is a crucial oversight, as it limits the comprehensiveness of the evaluation. By highlighting this issue, the comment provides the authors with a clear direction for improvement, suggesting that they should include comparisons with other NLE tools to strengthen their analysis. This feedback is actionable and constructive, as it guides the authors to enhance the depth and scope of their evaluation. Therefore, the comment is 4, as it offers a clear and actionable suggestion for improvement, though it could be more comprehensive with additional details on specific NLE tools to consider."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with Equation (5), noting that it only uses one pertinent positive data point despite the existence of many that satisfy Equations (1) and (2). The authors are informed that these data points contribute equally to Equation (3) but have different perturbation directions. The comment suggests that Equation (5) does not include an exhaustive test over the diversity of all these data points. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (5)\" and other equations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the use of only one data point in Eq. (5) while suggesting that there are many data points that satisfy other equations and contribute equally but with different perturbation directions. The comment implies that an exhaustive test over the diversity of these data points is needed, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Equation (5) only uses one pertinent positive data point, despite the existence of many that satisfy Equations (1) and (2). It argues that these data points contribute equally to Equation (3) but have different perturbation directions, and that Equation (5) does not include an exhaustive test over the diversity of all these data points. The comment provides a logical reasoning by explaining the issue with the limited data point usage and suggests that a more comprehensive test is needed. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation (5), noting that it only uses one pertinent positive data point despite the existence of many that satisfy Equations (1) and (2). The authors are informed that these data points contribute equally to Equation (3) but have different perturbation directions. The comment highlights that Equation (5) does not include an exhaustive test over the diversity of all these data points, which is a critical oversight. This feedback is clear and actionable, as it provides a specific example of a deficiency in the paper and suggests that the authors should consider a more comprehensive test to address this issue. By pointing out this gap, the comment helps the authors improve the robustness and comprehensiveness of their analysis. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the results should be compared with a supervised retriever, as the current comparison lacks this aspect. It also implies that the authors should explore how document augmentation can enhance the performance of existing supervised retrievers. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps should be taken to compare the results with a supervised retriever. The action is implicit and vague, as it does not specify how to conduct the comparison or what data should be used. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the results with a supervised retriever, which implies that the authors should consider this aspect of their work. However, it does not specify which part of the paper this comparison should be made or what specific results should be compared. The comment is weakly grounded as it does not provide clear guidance on which section or part of the paper needs attention. It is also specific in suggesting that the authors should explore how document augmentation can enhance the performance of existing supervised retrievers, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the results should be compared with a supervised retriever, which implies that the current comparison is incomplete. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed justification or evidence makes the claim 3, as it lacks the necessary depth to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the comparison of results, suggesting that the authors should consider comparing their findings with a supervised retriever. This is a valuable suggestion as it could provide additional context and insights into the effectiveness of the document augmentation techniques. However, the comment lacks specific guidance on how to implement this comparison or what data should be used. While it points out an important area for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, as it offers a clear direction for enhancing the draft but does not fully address the need for actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the discussion of the cache hierarchy, specifically mentioning that the order of the three dimensions, their potential data sharing, and how they are applied together are not discussed. While the comment points out that the individual levels are discussed in detail, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should discuss the application of the dimensions together, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"cache hierarchy\" and the \"three dimensions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the discussion of the cache hierarchy, specifically mentioning the lack of information on the order of dimensions, potential data sharing, and how they are applied together. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not discuss the cache hierarchy, specifically the order of the three dimensions, potential data sharing, and how they are applied together. It argues that while the individual levels are discussed in detail, the integration and application of these dimensions are not adequately addressed, contradicting the initial hierarchy claim. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides a general observation but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion of the cache hierarchy, specifically noting that the order of the three dimensions, their potential data sharing, and how they are applied together are not adequately addressed. While the individual levels are discussed in detail, the integration and application of these dimensions are not clearly explained, which contradicts the initial hierarchy claim. This feedback is 3 as it highlights a specific area where the authors need to improve their discussion, but it could be more helpful with additional guidance on how to address these issues. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of forward passes required before backpropagation and how the authors managed GPU memory to avoid outofmemory (OOM) issues during pretraining. While it prompts the authors to clarify their methodology, it does not provide explicit instructions or suggestions on how to address the issue. The action is implicit, as the authors need to infer that they should explain their memory management strategy. However, the comment lacks concrete guidance on how to implement this explanation, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the number of forward passes required before backpropagation and how the authors managed GPU memory to prevent OOM issues during pretraining. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the number of forward passes required before backpropagation and how the authors managed GPU memory to prevent OOM issues during pretraining, referencing Figure 2. However, it does not contain any subjective opinions, suggestions, or claims that require verification. The comment is purely factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the number of forward passes required before backpropagation and how the authors managed GPU memory to prevent outofmemory (OOM) issues during pretraining. It references Figure 2, which suggests that the authors need to clarify this aspect. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what strategies they could employ to manage GPU memory effectively. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the abstract is not wellwritten and difficult to understand the contributions. It recommends rewriting the abstract to better present the contributions. While the comment provides a clear action\u2014rewriting the abstract\u2014it does not specify which parts of the abstract need improvement or how to achieve this rewriting effectively. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the abstract is not wellwritten and difficult to understand the contributions, recommending a rewrite. However, it does not specify which part of the abstract is problematic or what aspects need improvement. The authors cannot confidently determine which section of the paper is being addressed, as the comment is general and does not point to a specific part of the abstract. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the abstract is not wellwritten and difficult to understand the contributions, suggesting that it should be rewritten. However, the comment lacks specific examples or reasoning to support this claim. It does not provide any evidence or references to back up the assertion that the abstract is unclear or poorly written. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it is not wellwritten and difficult to understand the contributions. It provides a clear recommendation to rewrite the abstract to better present the contributions. However, the comment lacks specific guidance on how to rewrite the abstract or what aspects should be improved. While it offers a direction for improvement, the feedback is somewhat limited in its depth and actionable nature, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the dataset ADE, used for Image parsing, might be biased across different scenes, potentially favoring the performance of the proposed method. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to mitigate the bias. The comment implies that the authors should consider the potential bias in their dataset and its impact on the results, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential issue but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the issue of potential bias in the ADE dataset, which is used for Image parsing. However, it does not specify which part of the paper discusses the dataset or the results related to it. The authors cannot confidently determine which section or figure the comment pertains to, making it weakly grounded. The comment is specific in identifying the potential bias in the dataset, but without clear grounding, the authors may struggle to understand which part of the paper needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset ADE, used for Image parsing, might be biased across different scenes, potentially favoring the performance of the proposed method. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the concern raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset ADE, which is used for Image parsing. It suggests that the dataset might be biased across different scenes, potentially favoring the performance of the proposed method. While the comment highlights a potential weakness in the dataset, it does not provide specific guidance or suggestions on how the authors might address this bias or improve the dataset. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of two matrices to represent each relation (edge type) in section 2.1.2. It suggests that the two matrices might be the same and that many matrices are not used in the following text. While the comment implies that the authors should clarify why two matrices are used, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the rationale behind the use of two matrices and ensure consistency with the following text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of two matrices to represent each relation (edge type) and suggests that the matrices might be the same, implying a need for clarification. The comment also points out that many matrices are not used in the following text, which provides a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the two matrices might be the same. It also implies that many matrices are not used in the following text. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the matrices are the same or why they are used. Without further explanation or evidence, the authors are left to infer the reasoning behind the use of two matrices, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the use of two matrices to represent each relation (edge type) in section 2.1.2. It questions whether the two matrices are the same and suggests that many matrices are not used in the following text. This feedback is clear and actionable, as it prompts the authors to clarify the rationale behind the use of two matrices and ensure consistency with the rest of the paper. By addressing this issue, the authors can improve the clarity and coherence of their work. However, the comment could be more helpful if it provided specific examples or suggestions for how to clarify the use of matrices. Overall, the comment is 4, as it directs the authors to a specific area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of a specific statement in the paper, \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or clarify the statement. The comment lacks concrete guidance on what needs to be done to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a lack of understanding regarding the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This provides the authors with a clear idea of what needs to be clarified or explained. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of a specific statement in the paper, \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance for the authors. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any suggestions or guidance on how the authors might address this confusion or clarify the statement. Without actionable feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but lacks depth and direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is necessary to clarify the differences between the proposed method and other methods for predicting user personality, such as the method described in [1]. However, it does not provide explicit guidance on how to clarify these differences or what specific aspects need to be addressed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that it is necessary to clarify the differences between the proposed method and other methods for predicting user personality, such as the method described in [1]. However, it does not specify which part of the paper this clarification should be made in, nor does it provide any guidance on how to achieve this clarification. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what aspects of the methods need clarification. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that it is necessary to clarify the differences between the proposed method and other methods for predicting user personality, such as the method described in [1]. However, the comment does not provide any specific reasoning, examples, or references to support why this clarification is necessary or how it would benefit the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a need to clarify the differences between the proposed method and other methods for predicting user personality, specifically referencing a relevant paper [1]. This feedback is 3 as it highlights an area where the authors could improve the clarity and context of their work. However, the comment lacks specific guidance on how to clarify these differences or what aspects of the methods need to be compared. Without detailed suggestions or examples, the authors may find it challenging to address this feedback effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the theoretical basis of LoRA tuning and the necessity of step size tuning in experiments. It does not provide explicit instructions or suggestions on how to address these issues or improve the paper. The authors are left to infer that they need to clarify the theoretical basis and explore the impact of step size tuning. While the comment identifies areas for improvement, it lacks concrete guidance on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment addresses issues related to LoRA tuning, specifically questioning the theoretical basis of imposing B as the basis and A as coordinate for acceleration. It also mentions the theoretical equivalence of $X$ spaces and the need for step size tuning in experiments. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the areas needing clarification and suggests potential improvements, but it lacks explicit references to specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the theoretical basis of LoRA tuning and the necessity of step size tuning in experiments. It does not contain any subjective opinions or claims that require verification. The comment is purely descriptive, stating observations and areas for further exploration. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises several important questions and points of clarification regarding the theoretical basis of LoRA tuning and the necessity of step size tuning in experiments. It questions the rationale behind imposing B as the basis and A as coordinate for acceleration, noting that theoretically, they should cover the same X space. The comment also suggests that vanilla LoRA parameters might have more freedom to change compared to constraining B to be orthogonal. Additionally, it points out that while the authors show constant step size is sufficient, step size tuning is still needed for the experiments. These questions and suggestions provide valuable insights for the authors to clarify and improve their work. However, the comment could be more helpful if it offered specific guidance on how to address these issues or provide additional context. Overall, the feedback is 3 as it identifies areas for improvement but lacks detailed actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct more ablation studies or analyses on problems other than shortest path problems to make their experimental environments more convincing. While the comment implies that the authors should perform additional experiments, it does not provide specific guidance on which problems to include or how to conduct these studies. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the design of the architecture (PathGNN) and its bias towards the shortest path problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting more ablation studies or analysis on problems other than shortest path problems, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should conduct more ablation studies or analysis on problems other than shortest path problems to make their experimental environments more convincing. While the comment implies that the authors should perform additional experiments, it does not provide specific examples or references to support why this would be beneficial. The lack of detailed reasoning or evidence makes the claim 3, as the authors may need to infer the necessity of the suggested action. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental design, noting that most environments are related to the shortest path problem, while the architecture (PathGNN) is biased towards this type of problem. The comment suggests that conducting more ablation studies or analysis on problems other than shortest path problems would make the experimental environments more convincing. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included suggestions on which specific problems to consider or how to conduct the additional analysis. Overall, the comment is 4 as it offers a clear and actionable suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English. While it implies that the authors should consider adding these models, it does not provide explicit instructions or detailed guidance on which specific models to include or how to integrate them into the comparison. The action is implicit and somewhat vague, as the authors need to infer the need for additional comparisons and may struggle to determine the exact models to add. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could include more recent models, especially in multilingual settings or other languages beyond English. However, it does not specify which parts of the paper this suggestion relates to, such as specific sections or tables. The comment is vague in terms of what needs to be addressed, as it does not provide detailed guidance on which models to include or how to compare them. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could include more recent models, especially in multilingual settings or other languages beyond English. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English. This feedback is 3 as it identifies a potential area for improvement in the paper\"s comparison with baselines. However, the comment lacks specificity and does not provide detailed guidance on which models to include or how to integrate them into the comparison. Without additional context or suggestions, the authors may struggle to effectively address this feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of visualization of the learned context token, which could provide a clearer understanding of the differences between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and analysis of the insights of the approach. However, the comment does not provide explicit guidance on how to visualize the context token or how to address the lack of novelty and analysis. The authors are left with a general idea of what needs to be improved but without specific steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete guidance on how to achieve them.", "grounding_specificity_rationale": "The comment addresses the lack of visualization of the learned context token, which is a specific aspect of the paper. It also mentions the simplicity and effectiveness of the approach, as well as the limited novelty and absence of analysis. However, the comment does not explicitly mention which part of the paper discusses the visualization of context tokens or where the analysis of novelty and insight is presented. This makes it challenging for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, it lacks full grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks visualization of the learned context token, which could provide a clearer understanding of the differences between context tokens of different groups. It also suggests that the paper is simple and effective but lacks novelty and analysis of the insights of the approach. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of visualization of the learned context token, which could enhance the understanding of the differences between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and analysis of the insights of the approach. However, the comment does not provide detailed guidance or suggestions on how to address these issues, such as specific ways to visualize the context tokens or how to enhance the novelty and analysis of the approach. While the feedback highlights important areas for improvement, it lacks actionable and constructive suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the experimental section, noting that the results show only small benefits over the baseline model. It suggests that the paper would be stronger if the authors reported results for other models than MetaOptNet, which would emphasize the generality of the method and convincingly demonstrate its improvement over baseline models. The comment explicitly states the action of reporting results for other models, making it clear and concrete. However, it does not provide specific guidance on which other models to include or how to present the results effectively. While the action is clear, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment addresses the experimental section, specifically mentioning the results showing only small benefits over the baseline model. It suggests reporting results for other models than MetaOptNet to emphasize the generality of the method and convincingly demonstrate its improvement over baseline models. However, the comment does not specify which other models should be included or how the results should be presented. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting the need for additional results, but the lack of detail regarding the specific models or presentation makes it somewhat specific. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results show only small benefits over the baseline model, suggesting that reporting results for other models would strengthen the paper. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the experimental results, noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and convincingly demonstrating its improvement over baseline models. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their experimental section. However, the comment could be more helpful if it offered additional guidance on which models to include or how to present the results effectively. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could benefit from a more extensive comparison by including wellestablished methods such as FTML[1] and LFW[2]. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific comparisons to include or how to analyze the results. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a more extensive comparison by including wellestablished methods such as FTML[1] and LFW[2]. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this suggestion. The lack of specific guidance makes it difficult for the authors to understand where to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from a more extensive comparison by including wellestablished methods such as FTML[1] and LFW[2]. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without additional context or justification, the claim remains 3, as it is based on a logical suggestion but lacks concrete evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the authors have made comparisons with recent baselines but could benefit from a more extensive comparison with wellestablished methods such as FTML[1] and LFW[2]. This feedback is clear and actionable, as it provides specific suggestions for improvement. By including these additional comparisons, the authors can offer a more comprehensive evaluation of their proposed method, thereby strengthening the paper. The comment is 4 as it guides the authors to enhance the depth and breadth of their comparisons, which is crucial for a thorough evaluation of the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus of the paper on modeling this task using a CRF (local and global context) should be downgraded. Additionally, the comment points out that location embeddings provide additional information on the main dataset but not in the extra dataset (Appendix D), suggesting that they might be useful for specific types of datasets only. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance of CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue of underperformance and suggests downgrading the focus on CRF modeling. It also points out the lack of discussion regarding the utility of location embeddings across different datasets, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed CRF variants underperform the hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This claim is supported by the observation that location embeddings provide additional information on the main dataset but not in the extra dataset, suggesting that they might be useful for specific types of datasets only. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors are left to infer the full extent of the issue and its implications, which could be improved with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This observation is supported by the claim that location embeddings provide additional information on the main dataset but not in the extra dataset, suggesting that they might be useful for specific types of datasets only. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. While the feedback highlights a critical area for improvement, it does not provide actionable guidance on how the authors might address this issue or what specific changes could be made to enhance the paper. As a result, the comment is 3, as it points out a significant weakness but does not offer comprehensive suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a lack of clarity regarding the impact of trainingtesting inconsistency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify or address this concern, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for improvement.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the impact of trainingtesting inconsistency, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently identify where the issue is addressed. This makes the comment weakly grounded, as it does not provide full grounding. However, the comment is specific in identifying the need for clarification regarding the impact of trainingtesting inconsistency. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a lack of clarity regarding the impact of trainingtesting inconsistency. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of clarity regarding the impact of trainingtesting inconsistency. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or specific recommendations, the comment is not particularly helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the paper: the condition for y membership being unclear and the lack of backing for some claims, specifically mentioning the second line after Equation 1. While the comment identifies two distinct issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the condition for y membership and provide backing for the claims. However, the lack of specific instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the condition for y membership being unclear and the lack of backing for some claims, specifically mentioning the second line after Equation 1. However, it does not specify which part of the paper this issue pertains to, such as a particular section or paragraph. This makes it weakly grounded, as the authors cannot confidently determine the exact area being addressed. The comment is specific in identifying the issues with the clarity of the condition and the lack of backing for claims, but without explicit references, it is difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition for y membership is unclear and that some claims are not backed up, specifically mentioning the second line after Equation 1. However, the comment does not provide any reasoning, examples, or references to support these claims. Without additional context or evidence, the authors are left to question the validity of the claims, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of clarity regarding the condition for y membership and the absence of backing for some claims, particularly the second line after Equation 1. While the comment points out these areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify the condition for y membership and provide backing for the claims, but without specific examples or actionable steps, the feedback is somewhat limited in its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that certain key references are not compared or explained. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include comparisons and explanations for these references, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, noting that certain key references are not compared or explained. However, it does not specify which part of the paper these references are discussed in, making it weakly grounded. The comment is specific in identifying the need for comparison and explanation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that require attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that certain key references are not compared or explained, which is a subjective observation. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the criticism. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that certain key references are not compared or explained. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how the authors might approach the comparison or explanation of these references. Despite this, the comment offers a clear direction for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of SCL in section 5.2 regarding fewshot ability, noting that the results in Figure 7(c) and (d) do not align with the authors\" claims. It suggests that COCOLM achieves significant improvements with fewer labels, and the improvements diminish with more labels. The comment also recommends checking if COCOLM brings benefits to sentence retrieval tasks with learned anisotropy text representations. While the comment identifies a specific area for improvement and provides a suggestion, it does not explicitly instruct the authors on how to address the issue or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer the need for further analysis and exploration of COCOLM\"s benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the analysis of SCL in section 5.2 regarding fewshot ability, specifically mentioning the results in Figure 7(c) and (d). It highlights that COCOLM achieves significant improvements with fewer labels, and the improvements diminish with more labels, questioning the authors\" claims about the benefits of a more regularized representation space by SCL. The comment also suggests checking if COCOLM brings benefits to sentence retrieval tasks with learned anisotropy text representations. However, the comment does not explicitly mention which part of the paper it addresses, making it weakly grounded. It is specific in detailing the issue with the analysis and suggesting further exploration, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the analysis of SCL in section 5.2 regarding fewshot ability, noting that the results in Figure 7(c) and (d) do not align with the authors\" claims. It highlights that COCOLM achieves significant improvements with fewer labels, and the improvements diminish with more labels, questioning the effectiveness of the proposed approach. The comment suggests that the authors may need to reevaluate their claims and consider additional experiments or analyses to support their conclusions. However, the comment lacks specific examples or references to external works that could provide further context or justification for the critique. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the analysis of SCL in section 5.2 regarding fewshot ability, pointing out that the results in Figure 7(c) and (d) do not align with the authors\" claims. It suggests that COCOLM achieves significant improvements with fewer labels, and the improvements diminish with more labels, questioning the effectiveness of the proposed approach. The comment also recommends checking if COCOLM brings benefits to sentence retrieval tasks with learned anisotropy text representations. While the comment identifies a specific area for improvement and provides a suggestion, it lacks depth and does not offer detailed guidance on how to address the issue or what specific experiments could be conducted to validate the claims. The feedback is 3 as it highlights a potential weakness in the analysis and suggests a direction for further exploration, but it could be more comprehensive with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that conducting more experiments on other Large Language Models (LLMs) would better demonstrate the generalization of the proposed framework. While it provides a clear direction for improvement, it does not specify which other LLMs should be used or how the additional experiments should be designed. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not specify which other LLMs should be included or how the additional experiments should be designed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper it addresses. Additionally, the comment lacks specificity, as it does not provide detailed guidance on what experiments should be conducted or how they should be structured. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it lacks specific details or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. This feedback is 3 as it identifies a potential area for improvement in terms of the breadth of the experimental validation. However, the comment lacks specificity regarding which other LLMs should be used or how the additional experiments should be designed. This limits the actionable guidance provided to the authors, making the feedback 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to clarify what constitutes a short versus a long video to determine which layers should be downsampled. It also requests an appleapple comparison of stateoftheart VLM/VideoLLM outputs for the qualitative examples added. However, the comment does not provide explicit guidance on how to clarify the distinction between short and long videos or how to conduct the comparison. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors need to clarify what constitutes a short versus a long video to determine which layers should be downsampled, referencing line 223. However, it does not specify which part of the paper discusses downsample layers or how the distinction between short and long videos is made. Additionally, the comment requests an appleapple comparison of SOTA VLM/VideoLLM outputs for qualitative examples, but it does not specify which examples are being compared or how this comparison should be conducted. The lack of specific guidance makes it difficult for the authors to address the comment effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises two distinct issues: the need for clarification on short versus long videos to determine downsample layers and the request for an appleapple comparison of SOTA VLM/VideoLLM outputs for qualitative examples. While the first part is somewhat vague, the second part is more specific, as it requests a comparison that would help in evaluating the qualitative examples. However, the comment lacks detailed reasoning or references to support the need for such a comparison, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it requests clarification on what constitutes a short versus a long video, which is crucial for determining which layers should be downsampled. This is important for the authors to address as it could impact the effectiveness of their model. Second, the comment suggests an appleapple comparison of stateoftheart VLM/VideoLLM outputs for the qualitative examples added, which would provide a more robust evaluation of the paper\"s contributions. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, making it 3. The feedback is clear but could be more actionable with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. While it identifies a concern, it does not provide explicit guidance on how the authors might address this issue or suggest specific improvements. The action is implicit, as the authors would need to infer that they should consider optimizing the generation process or discussing the implications of this limitation in more detail. However, the comment lacks concrete details on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s discussion on the efficiency of generating multiple objects, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential limitation in terms of efficiency, particularly for scenes with a high number of objects or complex interactions. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that generating multiple objects takes longer, depending on the number of objects, which indicates a potential limitation in terms of efficiency. However, the comment does not provide specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains 3, as the authors may need to infer the basis for this assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This observation is important as it highlights a critical aspect of the paper that could impact its practical applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the efficiency of their approach. While it points out a valid concern, it does not provide actionable advice or detailed insights into potential solutions, making it 3. The authors would need to infer that they should consider optimizing the generation process or discussing the implications of this limitation in more detail. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the technical contribution of the paper is thin and that the proposed algorithm may be considered incremental due to the use of interpolative decomposition, which is not proposed by the paper. It recommends the authors to focus on finding additional applications and to deeply evaluate the approach to identify additional properties of the representation that could be emphasized in future versions. This feedback provides a clear and explicit action for the authors to take, including specific suggestions for improvement. The comment is detailed and concrete, offering a clear path for the authors to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is thin and that the proposed algorithm may be considered incremental due to the use of interpolative decomposition, which is not proposed by the paper. It recommends the authors to focus on finding additional applications and to deeply evaluate the approach to identify additional properties of the representation that could be emphasized in future versions. This feedback is fully grounded as it explicitly mentions the technical contribution and the algorithm, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it provides clear suggestions for improvement, such as finding additional applications and evaluating the approach to uncover additional properties of the representation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is thin and suggests that the proposed algorithm may be considered incremental due to the use of interpolative decomposition, which is not proposed by the paper. The comment recommends the authors to focus on finding additional applications and to deeply evaluate the approach to identify additional properties of the representation that could be emphasized in future versions. However, the comment lacks specific examples or references to support the claim about the incremental nature of the algorithm or the suggestions for additional applications. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s technical contribution, suggesting that the proposed algorithm may be considered incremental due to the use of interpolative decomposition, which is not proposed by the paper. It provides actionable feedback by recommending that the authors focus on finding additional applications and to deeply evaluate the approach to uncover additional properties of the representation that could be emphasized in future versions. This feedback is clear and constructive, offering specific suggestions for improvement that could enhance the manuscript\"s value. However, the comment could be more helpful if it provided more detailed guidance on how to find additional applications or how to evaluate the approach effectively. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the neural network library used for implementation but does not provide any guidance or suggestions on how the authors might address this issue. It lacks explicit instructions or concrete advice on what needs to be done to improve the draft. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the neural network library used for implementation but does not specify which part of the paper this information should be included in. It lacks grounding as the authors cannot confidently determine which section or part of the paper is being addressed. Additionally, the comment does not provide specific guidance on what needs to be addressed or how to improve the draft. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the neural network library used for implementation but does not provide any claim or suggestion that requires verification. It is a factual inquiry that does not challenge the authors to make any judgments or provide evidence. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the neural network library used for implementation, noting the lack of details in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment is vague and lacks actionable advice, leaving the authors without a clear path forward. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that some descriptions are unclear, specifically mentioning undefined math notations and missing details in Figure illustrations. However, it does not provide explicit instructions or suggestions on how the authors should address these issues. The comment implies that the authors should clarify the undefined notations and provide additional details in the figures, but it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies the need for clarification but does not offer detailed steps on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some math notations are undefined\" and \"some details in Figure illustrations are missing,\" allowing the authors to accurately identify the parts of the paper that need clarification. It is also specific because it provides examples of what is unclear, such as undefined math notations and missing details in figures. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some descriptions are unclear, specifically mentioning undefined math notations and missing details in Figure illustrations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples or justifications, the authors are left without guidance on how to address these issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be clearer, such as the use of math notations and details in Figure illustrations. However, it lacks actionable suggestions or detailed guidance on how the authors might improve these aspects. While it points out areas for improvement, it does not provide specific steps or examples for the authors to follow, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9. It suggests that the model might be underfit due to the accuracy of pseudolabels, which could explain why positive learning performs better. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment refers to \"appendix A.4\" and \"positive learning from Eq 9,\" which provides full grounding as the authors can accurately identify the specific parts of the paper being addressed. It also specifies the issue by questioning the performance of noise robust loss on pseudolabels compared to positive learning and suggests that the model might be underfit due to the accuracy of pseudolabels. This level of detail makes the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9, based on findings in appendix A.4. However, it does not provide any specific evidence, reasoning, or references to support the claim that the model might be underfit due to the accuracy of pseudolabels. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9, as presented in appendix A.4. It suggests that the model might be underfit due to the accuracy of pseudolabels, which could explain why positive learning performs better. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for further exploration, it lacks actionable advice, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a claim made in the paper, specifically regarding the impact of an extra exponentiation on the runtime. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this confusion or clarify the claim. The comment lacks guidance on how the authors might respond or what steps they should consider to resolve the issue. As a result, the authors are left without any actionable feedback, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (L248) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies what the authors are confused about, namely the claim about the impact of an extra exponentiation on the runtime. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point expresses confusion about a claim made in the paper, specifically regarding the impact of an extra exponentiation on the runtime. However, it does not provide any evidence, reasoning, or references to support the claim that an extra exponentiation would noticeably increase the runtime to the point that it is a consideration for the attacker. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific concern about a claim made in the paper, noting that the authors are confused about why an extra exponentiation would significantly increase the runtime to the point of consideration for an attacker. This feedback is 3 as it identifies a potential area of confusion or a point that requires clarification. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could include specific questions or suggestions for the authors to consider when revising the paper. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the improvements to the proposed methods and suggests that the experiments are lacking in comparison with stateoftheart (SOTA) methods. However, it does not provide explicit guidance on how the authors should address these issues or what specific improvements they should make. The comment implies that the authors should compare their methods with SOTA methods, but it lacks concrete suggestions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the improvements to the proposed methods and suggesting a comparison with stateoftheart methods. This provides clear guidance on how the authors should enhance their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the improvements to the proposed methods and suggests that the experiments are lacking in comparison with stateoftheart (SOTA) methods. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 2, as it provides some basis for the claim but lacks depth and clarity in its reasoning.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by questioning the lack of comparison with stateoftheart (SOTA) methods. It raises important questions about the improvements to the proposed methods and suggests that the experiments are lacking in comparison with SOTA methods. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or what kind of comparisons would be beneficial. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear direction for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the proposed method enhances performance due to the introduction of more learnable parameters, specifically the temperature, which has been shown to be effective in previous works. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this point or what changes could be made to the draft. As a result, the authors are left without any actionable steps to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what is surprising or what needs to be addressed. The comment is vague and lacks clarity, leaving the authors unsure of how to respond or improve their work. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments show the proposed method enhances performance, but it is not surprising because it introduces more learnable parameters, such as the temperature, which have been shown to be effective in previous works. However, the comment lacks specific examples or references to support the claim that the introduction of these parameters is not surprising. Without detailed evidence or examples, the claim remains 3, as it is based on general reasoning but lacks thorough justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the experiments demonstrate the proposed method\"s enhanced performance, which is not surprising due to the introduction of more learnable parameters, such as the temperature, that have been shown to be effective in previous works. While the comment provides a brief observation about the expected outcome, it does not offer specific suggestions or guidance on how the authors might address this point or improve their draft. The feedback is 3 as it highlights an area for consideration, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, which makes the main work distracting. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes might be necessary. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, which makes the main work distracting. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making the main work distracting. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the inspiration from neuroscience research, suggesting that it is simple and unnecessary to the main processing pipeline of the main work, which may make the work distracting. However, the comment lacks specific details or actionable suggestions on how to address this issue or what changes might be necessary. Without concrete guidance or examples, the authors may find it challenging to understand the implications of the feedback or how to improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide sufficient depth or actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to update the caption of Table 3 to include information about the source dataset used. This provides a clear and direct action for the authors to take, making the comment 5. The comment also suggests that the captions should contain all necessary information, which further clarifies the expected content. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the source dataset used in the table and the requirement for the captions to contain all necessary information. This provides the authors with precise guidance on how to improve the clarity and completeness of their paper. Therefore, this comment is rated as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that it is unclear from the caption of Table 3 what source dataset is used. The comment suggests updating the caption to include this information and implies that the captions should contain all necessary information for the reader to understand the experiment without having to search in the main text. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the need for this information, which could be improved with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with Table 3, namely the lack of clarity regarding the source dataset used. It provides a clear and actionable suggestion to update the caption to include this information, which would significantly improve the readability and understanding of the paper. The comment also suggests that the captions should contain all necessary information, which is a helpful piece of advice for ensuring that readers do not have to search for critical details in the main text. However, the comment could be more comprehensive by offering additional suggestions or examples of how to improve the clarity of the captions. Overall, the feedback is 4, as it addresses a specific concern and provides actionable guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explicit description of the specific architectures used in the paper, such as value networks, policy networks, and uncertaintyaware networks. This omission makes it challenging for readers to replicate and evaluate the approach. However, the comment does not provide any guidance or suggestions on how the authors might address this issue, such as suggesting specific architectures or providing more detailed descriptions. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific architectures of value networks, policy networks, and uncertaintyaware networks used in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely the explicit description of these architectures, which is crucial for replicating and evaluating the approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an explicit description of the specific architectures of value networks, policy networks, and uncertaintyaware networks used. This is a valid observation, as the absence of such details makes it difficult for readers to replicate and evaluate the approach. However, the comment does not provide specific examples or references to support this claim, which could enhance its verifiability. Therefore, the comment is 3, as it is supported by logical reasoning but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out the lack of explicit description of the specific architectures used, such as value networks, policy networks, and uncertaintyaware networks. This omission makes it challenging for readers to replicate and evaluate the approach presented in the paper. While the comment highlights a critical gap in the paper\"s clarity, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors to a specific area that needs improvement, but it lacks depth and actionable advice, which could be expanded to enhance its helpfulness."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the relationship between explicitness, size, and the dataset, as well as the capacity requirements in the third paragraph. It suggests that the evaluation of disentanglement should consider the capacity and training time, and that factors like training time, cost, and learning rate may influence the final value of DCI. However, the comment does not provide explicit guidance on how the authors should address these points or what specific actions they should take to improve their draft. The suggestions are somewhat vague and lack concrete details, making it difficult for the authors to know exactly how to respond. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relationship between explicitness, size, and the dataset, as well as the capacity requirements in the third paragraph. It suggests that the evaluation of disentanglement should consider the capacity and training time, and that factors like training time, cost, and learning rate may influence the final value of DCI. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specificity by mentioning the relationship between explicitness, size, and dataset, it lacks full grounding as it does not explicitly mention the section or paragraph being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the relationship between explicitness, size, and the dataset, as well as the capacity requirements in the third paragraph. It suggests that the evaluation of disentanglement should consider the capacity and training time, and that factors like training time, cost, and learning rate may influence the final value of DCI. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how it should be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions regarding the relationship between explicitness, size, and the dataset, as well as the capacity requirements in the third paragraph. It suggests that the evaluation of disentanglement should consider the capacity and training time, and that factors like training time, cost, and learning rate may influence the final value of DCI. However, the comment lacks specific guidance on how the authors should address these points or what actions they should take to improve their draft. While it identifies areas for improvement, it does not provide detailed feedback or actionable steps, making it 3. The feedback is 3 as it points out potential areas for clarification and improvement, but it could be more comprehensive with detailed suggestions or examples."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper title does not need to include abbreviations. This is a clear and explicit action that the authors can take to improve their draft. By removing abbreviations from the title, the authors can enhance the clarity and readability of their paper. The comment provides a specific and actionable instruction, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper title does not need to include abbreviations. However, it does not specify which part of the paper the title is located in, nor does it provide any guidance on how to revise the title or what specific changes should be made. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is specific in its suggestion to remove abbreviations, but without context, it is difficult for the authors to understand the full scope of the change. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper title does not need to include abbreviations. This is a subjective opinion, as it is a recommendation for improvement rather than a factual claim requiring verification. The comment does not provide any specific reasoning or evidence to support why abbreviations should or should not be included in the title. Therefore, it is classified as \"No\" because it lacks a claim that needs verification.", "helpfulness_rationale": "The review comment suggests that the paper title does not need to include abbreviations. This is a specific and actionable piece of feedback that could help the authors improve the clarity and readability of their paper. By removing abbreviations, the authors can make the title more accessible to a broader audience. However, the comment does not provide any guidance on how to revise the title or what specific changes should be made, which limits its helpfulness. Overall, the comment is 3 as it identifies a potential improvement but lacks depth and detail."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two questions about the discriminator\"s ability to transfer to other tasks and domains without further training, and whether it can be effectively trained with very little data. It also suggests that the authors should mention the insight that the discriminator can be small, as shown at L400. However, the comment does not provide explicit guidance on how the authors should address these questions or incorporate the insight into their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L400,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the ability of the discriminator to transfer to other tasks and domains without further training and the effectiveness of training with very little data. Additionally, it highlights an important insight about the discriminator being small, as shown at L400. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the discriminator\"s ability to transfer to other tasks and domains without further training and whether it can be effectively trained with very little data. It also suggests mentioning the insight that the discriminator can be small, as shown at L400. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The feedback is 3 as it provides a general direction but lacks the necessary depth and evidence to fully guide the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two important questions about the discriminator\"s ability to transfer to other tasks and domains without further training and whether it can be effectively trained with very little data. It also suggests mentioning the insight that the discriminator can be small, as shown at L400. However, the comment lacks specific guidance or suggestions on how the authors might address these questions or incorporate the insight into their draft. While it identifies areas for improvement, it does not provide actionable steps or detailed reasoning, making it 3. The feedback is incomplete and could be more comprehensive to fully assist the authors in enhancing their work. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the current stateoftheart GNNQE should be included in the baselines for comparison. It provides a clear and direct action for the authors to take, which is to add and compare against this baseline. The comment is specific and concrete, as it clearly indicates what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the current SOTA GNNQE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that this baseline should be added and compared, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current stateoftheart GNNQE is omitted from the baselines, despite being the closest work in terms of components to the approach. However, the comment does not provide any specific reasoning or evidence to support this claim, such as examples of why the omission is significant or how the omission affects the evaluation of the proposed approach. Without this additional context, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant omission in the baselines used for comparison, specifically the stateoftheart GNNQE. By pointing out that this baseline is the closest in terms of components to the approach being evaluated, the comment provides a clear and actionable suggestion for improvement. It encourages the authors to include this baseline in their comparisons, which would strengthen the evaluation and provide a more comprehensive understanding of the proposed approach relative to existing work. This feedback is detailed and constructive, making it 5 for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of pretraining data for GPT2 and questions the reasonableness of the setting. It suggests that the authors should address these concerns to prove the correctness of their findings. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the use of pretraining data for GPT2 and questions the reasonableness of the setting. It suggests that the authors should address these concerns to prove the correctness of their findings. However, the comment does not specify which part of the paper these concerns relate to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its critique of the use of pretraining data, it is 1 because it does not provide clear references to the relevant sections of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of pretraining data for GPT2 and questions the reasonableness of the setting. It suggests that the authors should address these concerns to prove the correctness of their findings. However, the comment lacks specific examples, detailed reasoning, or references to support the claims made. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the use of pretraining data for GPT2 and questions the reasonableness of the setting, suggesting that the authors should address these concerns to prove the correctness of their findings. While the comment identifies a potential issue with the methodology, it does not provide specific guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it highlights an important aspect of the paper that needs further clarification or justification, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of thorough explanation for the proposed method, specifically mentioning the missing computation of some terms in equation (4) and the optimization algorithm used to calculate $p(x_k|d)$. While the comment identifies specific areas where the explanation is lacking, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more detailed explanations for these terms and the optimization process. This lack of explicit action makes the comment 3, as it points out the areas needing improvement but does not offer concrete steps on how to do so. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and equation (4), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing in the explanation, namely the computation of some terms in equation (4) and the optimization algorithm used to calculate $p(x_k|d)$. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of some terms in equation (4) and the optimization algorithm used to calculate $p(x_k|d)$. The reviewer suggests that if the idea is expressed using mathematical formulas, every term should be clearly explained, except for cases where it is extremely obvious. However, the comment lacks specific examples or references to support the claim that the explanation is indeed lacking or that the suggested approach is not followed. Without detailed examples or references, the claim remains 3, as it is based on an assumption rather than concrete evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the proposed method lacks thorough explanation, particularly concerning the computation of terms in equation (4) and the optimization algorithm used to calculate $p(x_k|d)$. It provides a clear example of what is missing, suggesting that the authors should ensure all terms are clearly explained, especially when using mathematical formulas. This feedback is actionable and constructive, as it directs the authors to improve the clarity and completeness of their method description. However, the comment could be more helpful if it offered additional guidance on how to address these issues or provided specific suggestions for improvement. Overall, the comment is 4, as it effectively highlights areas for enhancement and encourages the authors to provide a more detailed explanation of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It also notes that the lack of these details makes the experimental results not reproducible and difficult to assess the fairness of comparisons. The comment suggests that a thorough description of the implementation details is needed to address these issues. While the comment identifies the need for more information, it does not provide specific guidance on what aspects of the implementation details should be included or how to ensure reproducibility. The action is explicit but somewhat vague, as it lacks concrete steps for the authors to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It also highlights the issue of reproducibility and the difficulty in assessing the fairness of comparisons due to the lack of implementation details. However, the comment does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the implementation details of the RAMP algorithm, the discretization used, and the algorithms compared. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments makes the experimental results not reproducible and difficult to assess the fairness of comparisons. The comment suggests that a thorough description of the implementation details is needed to address these issues. However, the claim lacks specific examples or references to support the assertion that the absence of these details hinders reproducibility and fairness. The reasoning is logical but could be strengthened with more detailed explanations or references. Therefore, the comment is 3, as it provides a clear rationale but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the lack of implementation details for the RAMP algorithm, the compared algorithms, the discretization method used in the state coverage metric, and other aspects of the experiments. It highlights that this omission makes the experimental results not reproducible and difficult to assess the fairness of comparisons, which weakens the overall contribution of the paper. The comment suggests that a thorough description of the implementation details is needed to address these issues. While the feedback is clear and identifies a significant problem, it lacks specific guidance on what aspects of the implementation details should be included or how to ensure reproducibility. This makes the comment 3, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the concept of employing a mixture of experts (MoE) for a task, noting that it is not unusual given its extensive applications in various tasks like general LLM, summarization, and machine translation. It also acknowledges that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. However, the comment does not provide any specific suggestions or actions for the authors to take to improve their draft. The feedback lacks actionable guidance, leaving the authors without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of employing a mixture of experts (MoE) for a task, noting that it is not unusual given its extensive applications in various tasks such as general LLM, summarization, and machine translation. It acknowledges that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. However, the comment does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section being addressed. While the comment provides some context, it lacks specific guidance on what aspects of the paper need improvement. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the novelty of employing a mixture of experts (MoE) for a task, noting that it is not unusual given its extensive applications in various tasks such as general LLM, summarization, and machine translation. While the application of MoE in text detection is relatively new, the comment does not provide specific examples or references to support this claim. The lack of detailed evidence makes it difficult for the authors to understand the basis of the critique and how it applies to their work. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment critiques the novelty of employing a mixture of experts (MoE) for a task, noting that it is not unusual given its extensive applications in various tasks such as general LLM, summarization, and machine translation. While the application of MoE in text detection is relatively new, the comment does not provide specific suggestions or actionable feedback on how the authors might address this issue or enhance their work. The critique lacks depth and does not offer constructive guidance for improvement, making it 3. The authors may gain some insight into the need for more innovative approaches, but the feedback is not comprehensive or detailed enough to be fully beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a claim made by the authors regarding the performance improvement of SpaceTGN compared to other baselines. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should provide a statistical analysis to support their claim of significance, but it does not specify how to conduct this analysis or what data should be included. Without concrete guidance, the authors are left without a clear path to address the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SpaceTGN\" and its performance improvement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of statistical analysis to support the claim of significance. This provides the authors with a clear understanding of what needs to be addressed to substantiate the claim. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors did not provide a statistical analysis to support the claim of SpaceTGN achieving significant performance improvement compared to other baselines. However, the comment does not offer any specific examples, references, or detailed reasoning to substantiate this claim. Without additional information or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" claim regarding the performance improvement of SpaceTGN compared to other baselines. It points out that the authors did not provide a statistical analysis to support their claim of significance, which is a critical oversight. However, the comment lacks actionable guidance on how the authors might address this issue or what kind of statistical analysis would be appropriate. While it highlights a significant gap in the paper, it does not offer specific suggestions or steps for improvement, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the clarity of the paper, specifically regarding the excerpting versus reproduction of certain scores. However, it does not provide any explicit or implicit guidance on how the authors should address this confusion. The comment lacks concrete suggestions or actions that the authors can take to clarify the distinction, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps for the authors to improve their draft.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the paper regarding the excerpting versus reproduction of certain scores. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the clarity of the paper regarding the excerpting versus reproduction of certain scores. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the paper, specifically regarding the excerpting versus reproduction of certain scores. However, it does not provide any specific guidance or suggestions on how the authors might address this confusion. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to improve their draft. As a result, the comment is 2, as it highlights a problem but does not offer any constructive or actionable feedback to the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the method, suggesting that it is simply applying consistency models in place of other generative models. It implies that the authors should comment more on how consistency models achieve something that previous generative models cannot. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need to be clarified. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the method, suggesting that it is simply applying consistency models in place of other generative models. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The comment is weakly grounded because the authors cannot confidently determine which part of the paper is being addressed. It is also specific in that it highlights a lack of novelty and suggests that the authors should comment on how consistency models achieve something unique compared to previous generative models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the novelty of the method, suggesting that it is simply applying consistency models in place of other generative models. While the comment provides a logical argument for the critique, it lacks specific examples or references to support the claim that consistency models offer unique advantages over previous generative models. Without detailed examples or references, the claim is 3, as it is based on a logical argument but lacks sufficient evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the method, suggesting that it is simply applying consistency models in place of other generative models. This critique provides a clear and actionable feedback point for the authors to consider, highlighting a potential weakness in the paper\"s contribution. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. While the feedback is 3, it could be improved to provide more detailed insights and actionable advice, making it more comprehensive and impactful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the evaluation metric used in the paper, noting that the Mean Squared Error (MSE) in Table 2 does not adequately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what alternative metrics could be used. The comment lacks concrete guidance on how to improve the evaluation, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the evaluation metric, stating that MSE is insufficient for reflecting the accuracy of nowcasting. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation metric MSE in Table 2 does not adequately reflect the accuracy of nowcasting. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why MSE is insufficient for evaluating nowcasting accuracy. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation metric used in the paper, noting that the Mean Squared Error (MSE) in Table 2 does not adequately reflect the accuracy of nowcasting. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests that the authors should consider alternative metrics or methods to better assess the accuracy of their nowcasting approach. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as recommending alternative metrics or explaining why MSE is insufficient. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the ablation study of ENGINE is incomplete and recommends adding specific components (CapCapNEClipNEEA and CapCapNEClipNENEEA) based on the overview model of ENGINE. It also suggests that the authors should provide more detailed analysis of the ablation results. While the comment explicitly mentions the components to be added and the need for more detailed analysis, it does not provide specific guidance on how to conduct the analysis or what aspects of the results should be discussed. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the ablation study of ENGINE is incomplete and recommends adding specific components (CapCapNEClipNEEA and CapCapNEClipNENEEA) based on the overview model of ENGINE. It also suggests that the authors should provide more detailed analysis of the ablation results. However, the comment does not specify which part of the paper the ablation study is located in, making it weakly grounded. The suggestion to add specific components and the need for more detailed analysis are specific, but the lack of grounding makes it 3. Therefore, this comment aligns with the label 3.", "verifiability_rationale": "The review point claims that the ablation study of ENGINE is incomplete and suggests adding specific components and providing more detailed analysis. However, the comment lacks specific examples or references to support the claim that the ablation study is incomplete or that the suggested components are necessary. Without detailed reasoning or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study of ENGINE, noting that it is incomplete and suggests adding specific components to the model. It also recommends providing more detailed analysis of the ablation results. This feedback is 3 as it points out a clear area for improvement and provides a direction for the authors to take. However, the comment could be more helpful if it included specific examples of what aspects of the analysis should be detailed or suggestions for how to conduct the analysis. Overall, the comment offers actionable guidance but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the discrepancy in mode coverage between GAN optimization and different methods (GDIM and DDGAN). It suggests that the authors should provide results on more challenging highresolution datasets like LSUN and ImageNet to make their findings more convincing. The comment implies that the authors should conduct additional experiments or include results on these datasets, but it does not specify which datasets to use or how to present the results. While the action is implicit, it is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the discrepancy in mode coverage between GAN optimization and different methods (GDIM and DDGAN). It suggests that the authors should provide results on more challenging highresolution datasets like LSUN and ImageNet to make their findings more convincing. However, the comment does not specify which part of the paper discusses the mode coverage or the methods used, making it weakly grounded. It is specific in suggesting the need for results on more challenging datasets, but without explicit references to sections or figures, the authors may find it difficult to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the discrepancy in mode coverage between GAN optimization and different methods (GDIM and DDGAN). It suggests that the authors should provide results on more challenging highresolution datasets like LSUN and ImageNet to make their findings more convincing. The comment implies that the authors should conduct additional experiments or include results on these datasets, but it does not provide specific examples or references to support the claim. While the reasoning is somewhat logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the discrepancy in mode coverage between GAN optimization and different methods (GDIM and DDGAN). It suggests that the authors should provide results on more challenging highresolution datasets like LSUN and ImageNet to make their findings more convincing. This feedback is 3 as it identifies a potential area for improvement and provides a direction for the authors to enhance their results. However, it lacks specific guidance on which datasets to use or how to present the additional results, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of the statement \"Each attribute of the table feature represents a scene\" in Section 5.1. While it does not explicitly instruct the authors to clarify this statement, it implies that the authors should provide a clearer explanation of what this statement means. The action is implicit, as the authors need to infer that they should clarify the statement. However, the action is vague because it does not specify how to clarify the statement or what aspects of the statement need clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors need to clarify: the meaning of the statement \"Each attribute of the table feature represents a scene.\" This provides a clear and precise indication of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking for clarification on a specific statement in the paper, rather than making a claim or suggestion. It does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a specific statement in the paper, which could be helpful for the authors to clarify their understanding. However, it does not provide any suggestions or feedback on how to address the issue or improve the clarity of the statement. The comment is vague and lacks actionable guidance, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It questions the effectiveness of logsumexp aggregation compared to direct addition, providing an example of basic prototype comparison with reweighted averages. The comment also suggests that the token reweighting scheme is compatible with existing tokentotoken classifiers but does not specify how the logsumexp aggregator compares. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how to conduct the ablation study or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme, which is a specific aspect of the paper. It also questions the effectiveness of logsumexp aggregation compared to direct addition, providing an example of basic prototype comparison with reweighted averages. This allows the authors to identify the specific part of the paper that needs improvement. However, the comment does not specify which section or part of the paper discusses these methods, making it weakly grounded. The comment is specific in detailing what is missing and what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about the lack of an ablation study comparing token reweighting with the logsumexp aggregation scheme. It suggests that the authors should provide evidence to support the claim that logsumexp aggregation is more effective than direct addition. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. The lack of supporting evidence makes the claim 3, as the authors would need to conduct additional research or experiments to address the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study comparing token reweighting with the logsumexp aggregation scheme. It questions the effectiveness of logsumexp aggregation compared to direct addition, providing a clear example of how this comparison could be made. This feedback is valuable as it highlights a specific area where the authors could strengthen their analysis and provide a more comprehensive understanding of their methods. However, the comment could be more helpful if it suggested specific ways to conduct the ablation study or provided guidance on how to compare the two approaches. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the number of datasets used to evaluate the effectiveness of ECGs, suggesting that largerscale datasets from specific references should be considered. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to incorporate these datasets. The comment implies that the authors should expand their evaluation to include more datasets, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a clear area for improvement but does not provide detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the issue of limited datasets used to evaluate the effectiveness of ECGs, suggesting that largerscale datasets from specific references should be considered. However, it does not specify which part of the paper discusses the evaluation of ECGs or the datasets used. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of dataset limitations, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper uses limited datasets to evaluate the effectiveness of ECGs, suggesting that largerscale datasets from specific references should be considered. The comment provides references to two papers, [1] and [2], which are relevant to the topic of largescale datasets. However, the reasoning provided is somewhat vague, as it does not explicitly explain why the current datasets are insufficient or how the suggested datasets would address this limitation. While the references offer context, the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the use of a limited number of datasets to evaluate the effectiveness of ECGs. It suggests that incorporating largerscale datasets from specific references would enhance the evaluation. This feedback is clear and actionable, providing the authors with a specific direction to improve their work. However, the comment could be more helpful if it offered additional guidance on how to select or implement these larger datasets. Despite this, the feedback is 4 as it directs the authors towards a crucial improvement area."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should acknowledge the limitation of only analyzing fully connected ResNets, as ResNets typically use convolutional layers in practice. It also recommends including this limitation in the Broader Impact section. While the comment explicitly suggests an action\u2014acknowledging the limitation and including it in the Broader Impact section\u2014it does not provide specific guidance on how to implement this action. The authors are left to infer that they need to address this limitation and include it in the Broader Impact section. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the paper only analyzes fully connected ResNets, which is a common practice in practice, and suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only analyzes fully connected ResNets, which is a limitation as ResNets typically use convolutional layers in practice. The comment suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue effectively. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that it only analyzes fully connected ResNets, which is not representative of typical ResNet usage in practice. It suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. This feedback is clear and actionable, providing the authors with a specific area to address and improve the paper. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate this limitation into the Broader Impact section or suggested specific ways to enhance the discussion. Overall, the comment is 4 as it highlights a critical aspect that needs attention and provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides a critique of training a student model on the training set, particularly when using a mediumsized model like ResNet18. It mentions specific performance metrics on datasets like MNIST, SVHN, and CIFAR10, and compares the performance of standard Knowledge Distillation (KD) methods with reported results. However, the comment does not offer explicit or implicit suggestions on how to address the issue or improve the model. It lacks concrete guidance on what changes or actions the authors should take to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training of a student model on the training set and provides specific examples of performance metrics on datasets like MNIST, SVHN, and CIFAR10. It also references specific methods like Early KD and FitNets, which helps the authors understand the context and the issues being discussed. However, the comment does not specify what needs to be addressed in this part, such as potential improvements or alternative approaches. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that training a student model on the training set, especially with a mediumsized model like ResNet18, is problematic, citing specific performance metrics on datasets like MNIST, SVHN, and CIFAR10. It references Early KD methods such as (Hinton et al., 2015) and FitNets (Romero et al., 2015) as examples of standard KD methods that have surpassed reported KD performance. However, the comment lacks detailed reasoning or specific examples to fully support the claim, making it 3. The authors would benefit from a more thorough explanation of why this approach is problematic and how it impacts the model\"s performance.", "helpfulness_rationale": "The review comment critiques the practice of training a student model on the training set, particularly when using a mediumsized model like ResNet18. It provides specific performance metrics on datasets like MNIST, SVHN, and CIFAR10, and references standard Knowledge Distillation (KD) methods such as (Hinton et al., 2015) and FitNets (Romero et al., 2015) as examples of methods that have surpassed reported KD performance. This feedback highlights a potential issue with the approach and offers a comparison to existing methods, which could help the authors understand the limitations of their current approach and consider alternative strategies. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the identified issue or improve the model. Overall, the comment is 3 as it identifies a potential problem and provides context, but it lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the causal graph assumption in the proposed framework, specifically questioning whether the assumption holds for certain GCN variants like Geniepath and Gated GNN, where message and passing routes are learned in a coupled way. While the comment implies that the authors should consider this scenario, it does not provide explicit guidance on how to address this issue or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the causal graph assumption in the proposed framework, specifically questioning whether the assumption holds for certain GCN variants like Geniepath and Gated GNN, where message and passing routes are learnt in a coupled way. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the question is specific about the potential impact on the causal graph assumption, the lack of grounding makes it challenging for the authors to understand the context and relevance of the comment. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the causal graph assumption in the proposed framework, specifically questioning whether the assumption holds for certain GCN variants like Geniepath and Gated GNN, where message and passing routes are learnt in a coupled way. The comment does not provide any evidence, reasoning, or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the causal graph assumption in the proposed framework, specifically questioning whether it holds for certain GCN variants like Geniepath and Gated GNN, where message and passing routes are learned in a coupled way. This is a valuable point as it challenges the authors to consider the limitations of their framework and explore potential scenarios where the assumption might not hold. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what changes could be made to the framework. While it identifies a potential area for improvement, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should consider preprocessing and postprocessing layers in addition to messagepassing layers when evaluating the importance of messagepassing in Graph Neural Networks (GNNs). It also recommends providing the performance of stateoftheart (SOTA) algorithms on each dataset discussed in Table 1 to help readers understand the gap between NAS models and humanengineered SOTA architectures. The comment is clear and provides specific actions for the authors to take, such as including these additional layers and comparing performance with SOTA algorithms. This level of detail makes the comment 5, as it guides the authors on exactly what needs to be addressed to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"preprocessing, messagepassing, and postprocessing,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the consideration of messagepassing layers and the suggestion to include the performance of SOTA algorithms in each dataset discussed in Table 1. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should consider preprocessing and postprocessing layers in addition to messagepassing layers when evaluating the importance of messagepassing in Graph Neural Networks (GNNs). It argues that since different tasks adopt different pre/postprocessing modules, it is not convincing to directly state that messagepassing is the most important. The comment suggests that the authors should list the performance of stateoftheart (SOTA) algorithms in each dataset discussed in Table 1 to help readers understand the gap between NAS models and humanengineered SOTA architectures. However, the comment lacks specific examples or references to support the claim about the importance of messagepassing or the need for performance comparisons with SOTA algorithms. This makes the claim 3, as it provides a rationale but lacks detailed evidence or references to substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the draft, highlighting the need to consider preprocessing and postprocessing layers in addition to messagepassing layers when evaluating the importance of messagepassing in Graph Neural Networks (GNNs). It also suggests that the authors should include the performance of stateoftheart (SOTA) algorithms in each dataset discussed in Table 1 to help readers understand the gap between NAS models and humanengineered SOTA architectures. This feedback is clear and actionable, as it directs the authors to specific areas for improvement and provides concrete suggestions for enhancing the draft. However, the comment could be more helpful if it included more detailed guidance on how to incorporate these suggestions or examples of how to present the additional information. Overall, the comment is 4, as it offers valuable insights and actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the usefulness of learning the advantage directly using the proposed method. It suggests that while the paper argues for the importance of the advantage as a quantity of interest, there is a lack of evidence supporting why learning it directly is important compared to other methods. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific evidence they could include to strengthen their argument. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional evidence and guidance on how to present it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the usefulness of learning the advantage directly, suggesting that while the paper argues for the importance of the advantage as a quantity of interest, there is a lack of evidence supporting why learning it directly with the proposed method is important compared to other methods. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its request for evidence, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the usefulness of learning the advantage directly, suggesting that while the paper argues for the importance of the advantage as a quantity of interest, there is a lack of evidence supporting why learning it directly with the proposed method is important compared to other methods. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 3, as it offers a question but requires more detailed support to be fully substantiated.", "helpfulness_rationale": "The review comment raises a pertinent question about the usefulness of learning the advantage directly, which is a critical aspect of the paper\"s argument. It points out that while the paper makes a case for the advantage being a quantity of interest, it lacks evidence to support why learning it directly with the proposed method is important compared to other methods. This feedback is valuable as it highlights a gap in the paper\"s argumentation and encourages the authors to provide more detailed evidence or reasoning to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as suggesting additional experiments or analyses that could provide the necessary evidence. Overall, the comment is 3, as it identifies an important area for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more detailed explanations for the meaning of variable symbols used in the appended algorithms, such as \u03c2, r_i, and \u03b1_i. While the comment implies that these explanations are necessary for clarity, it does not explicitly instruct the authors to add these explanations or specify which parts of the algorithms require them. The action is implicit and somewhat vague, as the authors need to infer that they should add these explanations but do not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more detailed explanations for the meaning of variable symbols used in the appended algorithms, such as \u03c2, r_i, and \u03b1_i. However, it does not specify which part of the paper these algorithms are located in, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its suggestion to add explanations but lacks grounding as it does not pinpoint the specific part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed explanations for the meaning of variable symbols used in the appended algorithms, such as \u03c2, r_i, and \u03b1_i. However, the comment does not provide any specific reasoning, examples, or references to support why these explanations are necessary or how they would improve the clarity of the algorithms. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more detailed explanations for the meaning of variable symbols used in the appended algorithms, such as \u03c2, r_i, and \u03b1_i. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensibility of their work. By adding these explanations, the authors can ensure that readers can better understand the algorithms and the significance of the variable symbols. However, the comment could be more helpful if it provided specific examples or guidance on how to explain these symbols effectively. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method lacks innovation and may only represent incremental changes to established methods, based on the limited performance gains observed. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment implies that the authors should consider enhancing the method\"s innovation or exploring alternative approaches, but it does not offer concrete guidance on how to do so. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3 The limited performance gains further suggest that the method lacks the innovation needed to advance the field meaningfully and may merely represent incremental changes to established methods.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the method\"s innovation and suggests that it may only represent incremental changes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method lacks innovation and may only represent incremental changes to established methods, based on the limited performance gains observed. However, the comment does not provide specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the method lacks innovation and may only represent incremental changes to established methods, based on the limited performance gains observed. This feedback is 3 as it highlights an area for improvement, but it lacks depth and specificity. The comment does not provide detailed suggestions or guidance on how the authors might address this issue, such as exploring alternative approaches or enhancing the method\"s innovation. While it prompts the authors to consider the significance of their work, the feedback could be more actionable with additional insights or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. While it provides a clear direction for improvement, it does not specify which methods or systems should be compared, nor does it offer guidance on how to conduct this analysis. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this analysis should be conducted in, nor does it provide any guidance on how to perform the comparison. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs improvement. Additionally, the comment is specific in suggesting the need for a comparative analysis, but it lacks details on which methods or systems to compare. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is 3 as it provides a logical reasoning for why such an analysis would be beneficial, but it lacks specific examples or references to support the suggestion. The authors would need to conduct additional research to fully understand the basis of this claim and how it applies to their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is valuable as it provides a clear direction for improvement, highlighting the need for a more comprehensive evaluation of the proposed system. However, the comment lacks specific details or suggestions on which methods or systems should be compared, making it 3. The authors would need to conduct additional research to fully understand the basis of this suggestion and how to implement it effectively. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that the target of these algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their comparison. The comment lacks concrete guidance on what changes could be made to the draft to make the comparison more appropriate or fair. As a result, the authors are left without a clear understanding of how to respond to this critique or incorporate it into their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that the target of these algorithms is not to find an equilibrium. However, it does not specify which part of the paper this comparison is made, nor does it provide any guidance on how the authors might address this issue. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue with the comparison, but it lacks guidance on how to improve it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents because the target of those algorithms is not to find an equilibrium. This claim is based on the understanding of the objectives of offline RL algorithms, which are typically focused on learning from a fixed dataset rather than finding an equilibrium. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to further elaborate on why this comparison is unfair to fully understand the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed algorithm with offline RL algorithms for single agents, noting that the target of these algorithms is not to find an equilibrium. This critique highlights a specific aspect of the comparison that may need clarification or adjustment. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their comparison. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to respond to this critique or incorporate it into their work. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the overlap between the tasks discussed in the paper and prior benchmarks, suggesting that the authors should clarify the unique contributions of their methodology and purpose. While the comment implies that the authors need to address this overlap, it does not provide explicit guidance on how to do so. The suggestion to clarify the unique contributions and provide detailed comparisons to similar works is vague and lacks concrete steps for the authors to take. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the overlap of tasks with prior benchmarks, specifically mentioning \"unanswerable, inconsistent, and counterfactual\" tasks. However, it does not specify which part of the paper discusses these tasks or how the authors should clarify their unique contributions. The lack of explicit mention of sections, tables, or figures makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the tasks being discussed, it is weakly grounded because it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper could clarify its unique contributions in methodology and purpose, given the overlap with prior benchmarks. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed comparisons to similar works, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1 due to the absence of sufficient evidence or justification. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out the overlap of the tasks discussed with prior benchmarks. It suggests that the authors should clarify the unique contributions of their methodology and purpose, referencing similar works [14]. This feedback is 3 as it highlights an area where the authors could strengthen their paper by providing more detailed comparisons and clarifications. However, the comment lacks specific guidance on how to address the overlap or how to differentiate the paper\"s contributions from existing work, which limits its impact. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper primarily discusses MiPKD\u2019s performance in SR tasks but does not specify that MiPKD is not specially designed for these tasks. It encourages the authors to show the applicability of the method to other CV tasks and suggests additional experiments on a broader range of tasks to enhance the method\u2019s perceived generalizability. While the comment provides a clear direction for improvement, it lacks specific guidance on which tasks to include or how to demonstrate the method\u2019s applicability. The action is somewhat explicit but vague, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MiPKD\u2019s performance in SR tasks\" and suggests that the authors should show the applicability of the method to other CV tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of applicability to other CV tasks, and suggests additional experiments to enhance the method\u2019s perceived generalizability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper primarily discusses MiPKD\u2019s performance in SR tasks but suggests that MiPKD is not specifically designed for these tasks. The comment encourages the authors to show the applicability of the method to other CV tasks and suggests additional experiments on a broader range of tasks to enhance the method\u2019s perceived generalizability. However, the comment lacks specific examples or references to support the claim that MiPKD is not specifically designed for SR tasks. Without further evidence or examples, the claim remains 3, as it is based on an assumption that the authors might need to explore further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s focus on SR tasks, suggesting that MiPKD might not be specifically designed for these tasks. It encourages the authors to demonstrate the applicability of the method to other CV tasks and suggests additional experiments on a broader range of tasks to enhance the method\u2019s perceived generalizability. This feedback is 3 as it provides a clear direction for improvement, but it lacks specific guidance on which tasks to include or how to demonstrate the method\u2019s applicability. The comment could be more helpful if it provided examples of other CV tasks or suggested specific experiments to conduct. Overall, the comment offers valuable insights but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Equations 21 and 22 describe an alternative scheme that is not actually used and may be omitted without affecting the flow of the section. While the comment implies that the equations should be removed, it does not provide explicit instructions or detailed guidance on how to implement this action. The authors are left to infer that the equations are unnecessary and can be removed, but the lack of concrete steps or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the equations describe an alternative scheme that is not actually used and suggests that they may be omitted without affecting the flow of the section. This provides the authors with clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Equations 21 and 22 describe an alternative scheme that is not actually used and suggests that they may be omitted without affecting the flow of the section. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to understand why the equations might be omitted. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of Equations 21 and 22, suggesting that they describe an alternative scheme that is not actually used and may be omitted without affecting the flow of the section. While the comment points out a specific aspect of the paper that could be improved, it lacks detailed guidance or suggestions on how to determine the actual usage of these equations or how their omission might impact the overall understanding of the paper. The feedback is 3 as it directs the authors to consider the relevance of these equations, but it could be more actionable with additional insights or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the optimization module uses a simple iteration strategy to optimize two loss functions and that the overall model is similar to traditional approaches, making it seem incremental. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed to improve the model. The action is implicit, as the authors would need to infer that they should consider more sophisticated optimization strategies or discuss the limitations of the current approach. The comment lacks concrete details on how to implement or improve the optimization process, making it 3.", "grounding_specificity_rationale": "The comment addresses the optimization module and its strategy for optimizing two loss functions, suggesting that it uses a simple iteration approach. It also implies that the overall model is similar to traditional approaches and seems incremental. However, the comment does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in identifying the issue with the optimization strategy, but without explicit references to sections or figures, the authors may need to infer the exact part being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the optimization module applies a simple iteration strategy to optimize two loss functions, and the reviewer expresses the opinion that the overall model is similar to traditional approaches and seems incremental. However, the comment lacks specific evidence or examples to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the reviewer\"s point.", "helpfulness_rationale": "The review comment identifies a potential weakness in the optimization module, noting that it uses a simple iteration strategy to optimize two loss functions. The reviewer expresses the opinion that the overall model is similar to traditional approaches and seems incremental. While the comment highlights a specific aspect of the methodology, it lacks detailed suggestions or guidance on how the authors might address this issue or improve the model. The feedback is 3 as it points out a potential area for enhancement, but it does not provide actionable steps or specific recommendations for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing of the paper can be improved, specifically regarding the choice of F(X) for the E(d) case. It questions the clarity of the explanation of which 2^d O(d) matrices are being referred to and requests more detailed elaboration on one example in the main paper, with the other two examples to be discussed in the appendix. While the comment provides a clear action\u2014asking for more detail and elaboration\u2014it does not specify exactly which part of the paper needs improvement or how the authors should address it. The action is somewhat vague, as it leaves room for interpretation on which example to elaborate in detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the writing of the paper can be improved, particularly regarding the choice of F(X) for the E(d) case. It questions the clarity of the explanation of which 2^d O(d) matrices are being referred to and requests more detailed elaboration on one example in the main paper, with the other two examples to be discussed in the appendix. However, the comment does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the need for more detail and elaboration, the lack of explicit grounding makes it challenging for the authors to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the writing of the paper can be improved, particularly regarding the choice of F(X) for the E(d) case. It questions the clarity of the explanation of which 2^d O(d) matrices are being referred to and requests more detailed elaboration on one example in the main paper, with the other two examples to be discussed in the appendix. However, the comment lacks specific examples or references to support the claim that the writing is unclear or needs improvement. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies an area for improvement in the paper\"s writing, specifically regarding the clarity of the choice of F(X) for the E(d) case. It questions the explanation of which 2^d O(d) matrices are being referred to and requests more detailed elaboration on one example in the main paper, with the other two examples to be discussed in the appendix. This feedback is 3 as it points out a specific area where the authors can improve the clarity and detail of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on how to elaborate on the explanation. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implicit assumptions made in the paper regarding the success of fewshot learning. It suggests that the authors might be familiar with common assumptions like metadistribution or distributioncloseness assumptions. However, the comment does not provide explicit guidance or suggestions on how the authors should address or clarify these assumptions in their paper. The action is implicit, as the authors need to infer that they should discuss these assumptions, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the implicit assumptions made in the paper regarding the success of fewshot learning, specifically mentioning metadistribution and distributioncloseness assumptions. However, it does not specify which part of the paper these assumptions are discussed or how they relate to the content. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment is specific in questioning the assumptions, it does not provide detailed guidance on how to address or clarify these assumptions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the implicit assumptions made in the paper regarding the success of fewshot learning, specifically mentioning metadistribution and distributioncloseness assumptions. However, it does not provide any evidence, reasoning, or references to support the claim that these assumptions are implicit or how they might impact the paper. Without specific examples or references, the claim is difficult to verify, making the comment 1. Therefore, the comment is labeled as 1.", "helpfulness_rationale": "The review comment raises a question about the implicit assumptions made in the paper regarding the success of fewshot learning, specifically mentioning metadistribution and distributioncloseness assumptions. This is a relevant point as it highlights a potential gap in the paper\"s discussion of the underlying assumptions that might influence the effectiveness of fewshot learning. However, the comment does not provide any suggestions or guidance on how the authors might address or clarify these assumptions in their work. While it identifies an area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, and by providing results for more standard benchmarks. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these suggestions. The authors are left to infer that they should expand their comparison to include additional tasks, models, and benchmarks. This lack of explicit guidance makes the action somewhat vague, aligning with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, and by providing results for more standard benchmarks. However, it does not specify which parts of the paper these comparisons should be made, nor does it provide specific examples of tasks or benchmarks that would enhance the comparison. The comment is fully grounded in terms of identifying the need for a more thorough comparison, but it lacks specificity in terms of what needs to be addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, and by providing results for more standard benchmarks. However, the comment does not provide specific examples or references to support these suggestions, making it difficult for the authors to understand how to implement the recommendations. The lack of detailed guidance or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, and by providing results for more standard benchmarks. This feedback is 3 as it identifies a specific area for improvement, namely the depth of the comparison to prior work. However, the comment lacks detailed guidance on how to expand the comparison or what specific benchmarks or tasks should be included. Without concrete suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the manuscript is more akin to an experimental discovery paper and that the proposed method is similar to a traditional removal method. It also expresses a belief that the contribution of the manuscript could be improved. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks specific guidance on how to enhance the contribution or what aspects of the method could be improved. Without actionable steps, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this comparison is intended to address, making it difficult for the authors to pinpoint the exact section or aspect being discussed. The comment is vague in its description of the method and does not provide specific guidance on how to improve the contribution. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it lacks specific details or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the manuscript, suggesting that it resembles an experimental discovery paper and that the proposed method is similar to a traditional removal method. This observation raises concerns about the novelty and contribution of the work. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve the manuscript. Without actionable feedback or guidance, the authors may find it challenging to understand the implications of this critique and make necessary revisions. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies three claimed benefits of understanding an agent\"s performance posttraining but critiques them for being difficult to grasp. It specifically mentions that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. The comment provides explicit feedback on the issues with the benefits, such as their abstractness and lack of support. However, it does not offer concrete suggestions on how to improve the clarity or contextual detail of the benefits, nor does it provide guidance on how to address the unsupported claims. Therefore, the comment is 3, as it highlights areas for improvement but lacks detailed guidance on how to implement these suggestions.", "grounding_specificity_rationale": "The comment addresses the three claimed benefits of \"understanding the agent\u2019s performance posttraining from the learning process of the policy and the sequences of training tasks.\" It critiques the abstractness of Benefit 1 and the lack of contextual detail, and it points out that Benefit 3 includes broad statements without references. However, the comment does not specify which part of the paper these benefits are discussed in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issues with the benefits but lacks detailed guidance on how to address them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the abstractness and lack of contextual detail of the three claimed benefits of \"understanding the agent\u2019s performance posttraining from the learning process of the policy and the sequences of training tasks.\" It specifically mentions that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references, such as \"which can not deal with the big and complex problems that can not be seen in the real world.\" The comment provides logical reasoning by pointing out the issues with the benefits, but it lacks specific examples or references to substantiate the claims. Therefore, the comment is 3, as it offers a clear critique but requires additional evidence or references to fully support the claims.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the paper, particularly regarding the abstractness and lack of contextual detail of the three claimed benefits of understanding an agent\u2019s performance posttraining. It critiques the abstractness of Benefit 1 and the lack of support for the broad claims made in Benefit 3, such as the statement that \"which can not deal with the big and complex problems that can not be seen in the real world.\" This feedback is 3 as it highlights areas where the paper could be improved in terms of clarity and depth. However, it could be more helpful if it provided suggestions on how to address these issues or offer more detailed explanations of the benefits. Overall, the comment provides a clear direction for improvement but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that only qualitative results are provided. It also critiques the paper as being borderline but leans towards acceptance. While the comment identifies a potential issue with the lack of quantitative results, it does not provide explicit guidance on how the authors should address this gap or what specific steps they should take to include quantitative results. The action is implicit and vague, as it does not specify how the authors should conduct the quantitative analysis or present the results. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that only qualitative results are provided. It critiques the paper as being borderline but leans towards acceptance. However, the comment does not specify which part of the paper discusses the Human Shape Bases Synchronization problem or where the results are presented. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the issue of lacking quantitative results, it is 1 because it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that only qualitative results are provided. It critiques the paper as being borderline but leans towards acceptance. However, the comment lacks specific examples or references to support the claim that the lack of quantitative results makes it difficult to judge the effectiveness of the approach. Without detailed reasoning or evidence, the claim remains 3, as it is based on an observation but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that only qualitative results are provided. This observation is important because it limits the ability to judge the effectiveness of the proposed approach. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing additional experiments or metrics to include quantitative results. While it identifies a potential weakness, it lacks actionable advice, making it 3. The feedback is clear but could be more comprehensive if it provided suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the categorization of the paper under the Fairness/Accountability/Transparency category, asking if the authors are missing something. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this categorization or what specific aspects they should consider. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the categorization of the paper under the Fairness/Accountability/Transparency category, but it does not specify which part of the paper this categorization is related to. The authors cannot confidently determine which section or aspect of the paper is being questioned, making the comment weakly grounded. Additionally, the comment does not provide specific details or suggestions on how the categorization might be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the categorization of the paper under the Fairness/Accountability/Transparency category, asking if the authors are missing something. However, the comment does not provide any evidence, reasoning, or references to support why this categorization might be incorrect or missing. It lacks specific details or examples to substantiate the claim, making it difficult for the authors to understand the basis of the question. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency category, specifically asking if the authors are missing something. While this question highlights a potential area for clarification, it does not provide any actionable feedback or suggestions on how the authors might address this categorization or what aspects they should consider. The comment lacks depth and does not offer any guidance on how the authors can improve their draft or address the categorization issue. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison to baselines should include machine learning 2step baselines to address the concern that the improvement might be due to the different class of algorithm rather than the authors\" assertion. While the comment implies that the authors should consider adding these baselines, it does not provide explicit instructions on how to implement this suggestion or what specific baselines to include. The action is implicit and somewhat vague, as the authors need to infer the need for additional baselines and the specific type of baselines to add. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of comparing NaviFormer to baselines, suggesting the inclusion of machine learning 2step baselines. However, it does not specify which part of the paper this comparison is made or which sections should be revised. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is specific in suggesting the inclusion of machine learning 2step baselines to address the concern about the improvement being due to the algorithm class. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison to baselines should include machine learning 2step baselines to address the concern that the improvement might be due to the different class of algorithm rather than the authors\" assertion. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the suggestion, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of NaviFormer to baselines, suggesting that the inclusion of machine learning 2step baselines could provide a more comprehensive evaluation. This feedback is 3 as it highlights a specific area for improvement and offers a potential solution. However, the comment could be more helpful if it provided more detailed guidance on how to implement the suggested baselines or why they are necessary. Overall, the comment offers a clear direction for enhancing the evaluation, but it lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the reason for the improved results compared to other methods, suggesting that the better image generative model might be the cause. It recommends a fair comparison by applying the planning and layering method to images generated by other models. However, the comment does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a fair comparison by applying the planning and layering method to images generated by other image generative models. However, it does not specify which part of the paper this comparison should be made or which results are being questioned. The authors cannot confidently determine which section or figure this comment refers to, making it weakly grounded. The comment is specific in suggesting a way to improve the comparison, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the reason for the improved results compared to other methods, suggesting that the better image generative model might be the cause. It recommends a fair comparison by applying the planning and layering method to images generated by other models. However, the comment lacks specific examples or references to support the claim that the results are indeed better due to the image generative model. Without detailed evidence or examples, the claim remains 3, as the authors may need to conduct further analysis to substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the results of the proposed method and other compared methods. It questions whether the improved results are due to the better image generative model rather than the effectiveness of the planning and layering method. The comment suggests a fair comparison by applying the planning and layering method to images generated by other image generative models. This feedback is 3 as it identifies a potential issue with the comparison and provides a direction for improvement. However, it could be more helpful if it included specific examples or suggested additional experiments to validate the claim. Overall, the comment offers a clear and actionable suggestion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method should be compared with stateoftheart (SOTA) methods, such as those mentioned by the authors (Ma et al., 2021b; Tran et al., 2017; Chen & Zhang, 2020; Liu et al., 2021; Suo et al., 2019). The comment also criticizes the authors for not justifying their claim that the method does not effectively exploit information from modalitymissing data. However, the comment does not provide explicit guidance on how the authors should conduct this comparison or address the critique. The action is implicit, as the authors need to infer that they should include SOTA methods in their comparison and address the claim. The action is somewhat vague, as it lacks specific details on how to implement the comparison or how to justify the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to compare the proposed method with stateoftheart (SOTA) methods, such as those cited (Ma et al., 2021b; Tran et al., 2017; Chen & Zhang, 2020; Liu et al., 2021; Suo et al., 2019). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the need for comparison with these particular SOTA methods and critiques the authors\" claim about the exploitation of modalitymissing data. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors did not justify their claim about the method not effectively exploiting information from modalitymissing data. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional evidence or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of comparison with stateoftheart (SOTA) methods. It suggests that the authors should include comparisons with specific SOTA methods such as those mentioned (Ma et al., 2021b; Tran et al., 2017; Chen & Zhang, 2020; Liu et al., 2021; Suo et al., 2019). This feedback is valuable as it highlights a critical gap in the evaluation of the proposed method. However, the comment could be more helpful if it provided specific guidance on how to conduct the comparison or how to justify the claim about the exploitation of modalitymissing data. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the clarity of the discussion regarding the dataset used in the paper. It questions whether the terms \"opinion holder\" and \"opinion targets\" are relevant to the experiments conducted and suggests that they should not be mentioned if they are not pertinent. While the comment implies that the authors should clarify the relevance of these terms, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the relevance of these terms in the context of their experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 329334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, questioning the relevance of terms like \"opinion holder\" and \"opinion targets\" to the experiments. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of certain terms (\"opinion holder\" and \"opinion targets\") in the context of the experiments described in lines 329334. While the comment does not provide specific examples or references to support the claim that these terms are not relevant, it does suggest that they should not be mentioned if they are not pertinent to the experiments. This lack of detailed justification or examples makes the claim 3, as the authors may need to infer the relevance of these terms themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion of the dataset used in the paper, noting that the terms \"opinion holder\" and \"opinion targets\" are confusing and may not be relevant to the experiments conducted. This feedback is clear and actionable, as it directs the authors to clarify the relevance of these terms in the context of their experiments. By addressing this issue, the authors can improve the clarity and accuracy of their discussion, making the paper more understandable. The comment provides a direct and constructive suggestion for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should reconsider the restriction on capsule networks and provides a specific example of an experiment where the group CapsNet is deeper than the simple CapsNet. It also notes the absence of the number of parameters for the group CapsNet, which is crucial for evaluating the benefit of enforcing equivariance. However, the comment does not explicitly instruct the authors to provide the number of parameters or to analyze the impact of the deeper network. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Continuing the previous comment,\" indicating a specific part of the paper being addressed. It also specifies the issue by mentioning \"capsule networks\" and \"group CapNet\" and the lack of information regarding the number of parameters in the group CapNet. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should reconsider the restriction on capsule networks and provides a specific example of an experiment where the group CapsNet is deeper than the simple CapsNet. It notes the absence of the number of parameters for the group CapsNet, which is crucial for evaluating the benefit of enforcing equivariance. However, the comment lacks detailed reasoning or references to support the claim that the deeper network is unnecessary or how it affects the evaluation of equivariance. The authors are left to infer the reasoning, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the experimental setup, specifically questioning the necessity of restricting capsule networks. It highlights a potential issue with the depth of the group CapsNet compared to the simple CapsNet and points out the absence of parameter information for the group CapsNet. This feedback is valuable as it challenges the authors to reconsider their experimental design and provides a specific example for further analysis. However, the comment could be more helpful if it offered suggestions on how to address the issue or how to interpret the results of the deeper network. Overall, the comment is 4, as it identifies a significant area for improvement and encourages the authors to consider additional analysis."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the challenge of obtaining meaningful gradients with respect to noisy images and mentions that this issue has been addressed in previous work, specifically referencing DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1). However, it does not provide explicit or implicit actions for the authors to take. The comment suggests that the authors should consider these approaches but does not offer detailed guidance on how to implement or address the issue. As a result, the authors are left without clear instructions on what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the challenge of obtaining meaningful gradients with respect to noisy images, specifically mentioning DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1). However, it does not specify which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in detailing the approaches mentioned, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the challenge of obtaining meaningful gradients with respect to noisy images has been addressed in previous work, specifically mentioning DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1). The comment provides specific references to these works, which allows the authors to verify the claim. However, it could be more robust if it included a brief summary or explanation of how these approaches address the issue. Overall, the claim is 4, as it is supported by references but lacks some depth in explanation.", "helpfulness_rationale": "The review comment identifies a specific challenge in the paper, namely the difficulty of obtaining meaningful gradients with respect to noisy intermediate images. It acknowledges that this issue has been addressed in previous work, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which is a valuable piece of information for the authors to consider. However, the comment does not provide actionable guidance or suggestions on how the authors might address this challenge or incorporate these approaches into their work. While it highlights an important aspect of the paper, it lacks depth and does not offer constructive feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out a relevant issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include an evaluation of inference speed on the hardware. This is a clear and explicit action that the authors can readily follow. It provides a specific direction for improvement, indicating that the authors should consider adding this evaluation to their draft. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include an evaluation of inference speed on the hardware. However, it does not specify which part of the paper this evaluation should be included in or which sections of the paper are relevant to this evaluation. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on how to conduct the evaluation or what aspects of inference speed should be considered. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include an evaluation of inference speed on the hardware. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or beneficial. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the authors should include an evaluation of inference speed on the hardware. This is a specific and actionable suggestion that could enhance the completeness and practical relevance of the paper. By providing this feedback, the authors are given a clear direction for improvement, which can help them strengthen their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the evaluation or what aspects of inference speed should be considered. Overall, the comment is 4 as it identifies a specific area for improvement and encourages the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors to provide the SDP formulation for the modified problem, which is convex and can be solved via an SDP. However, it does not explicitly instruct the authors to include the formulation or provide guidance on how to derive it. The action is implicit and vague, as the authors are left to infer that they need to add the SDP formulation. This lack of explicitness and detail makes the comment 3, as the authors can deduce the need for the formulation but do not know how to implement it. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"This modified problem is convex and can be solved via an SDP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to provide the SDP formulation, which is a clear and actionable instruction. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point questions the authors to provide the SDP formulation for a modified problem that is convex and can be solved via an SDP. However, it does not offer any justification or explanation for why this is necessary or how it relates to the paper\"s content. The comment lacks supporting evidence or reasoning, making it difficult for the authors to understand the basis for the request. As a result, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific request for the authors to provide the SDP formulation for a modified problem that is convex and can be solved via an SDP. This feedback is clear and actionable, as it directs the authors to include the formulation, which is essential for understanding and replicating the results. However, the comment could be more helpful if it provided additional context or guidance on how to derive or implement the SDP formulation. Despite this, the feedback is 4 as it directs the authors to a critical aspect of their work that needs clarification and completion. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions two issues: the lack of information on the number of new task combinations used to evaluate compositional generalizability and the limited number of test results in Table 7. It provides clear guidance on what information is missing and what needs to be addressed. The authors are directed to include this information to improve the transparency and comprehensiveness of their evaluation. The comment is explicit and concrete, as it directly instructs the authors on what to do to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing: the number of new task combinations used for evaluating compositional generalizability and the number of test results in Table 7. This provides the authors with clear guidance on what needs to be addressed to improve the clarity and comprehensiveness of their evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper did not specify how many new task combinations were used to evaluate compositional generalizability and that the test results in Table 7 are based on only 30 composite instructions. This claim is 3 as it highlights a specific issue with the transparency and comprehensiveness of the evaluation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully understand the implications of this feedback.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the authors did not specify how many new task combinations were used to evaluate compositional generalizability. Additionally, it points out that the test results in Table 7 are based on only 30 composite instructions. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the transparency and comprehensiveness of their evaluation. By addressing these points, the authors can improve the clarity and robustness of their findings, making the comment 4. However, it could be more helpful if it suggested specific ways to include this information or examples of how to do so."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper, particularly the figures, is not wellformatted. However, it does not provide any specific guidance or suggestions on how the authors should improve the layout of the figures. The comment lacks explicit instructions or concrete details on what aspects of the layout need adjustment, such as the arrangement of figures, their size, or the use of specific formatting tools. Without these details, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the paper, especially the figures, is not wellformatted. However, it does not specify which figures or sections of the paper are affected, nor does it provide any details on what aspects of the layout need improvement. This lack of specificity makes it difficult for the authors to understand which parts of the paper require attention and how to address the issue. As a result, the comment is 1, as the authors cannot confidently identify the specific part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be improved. Therefore, this comment aligns with category 1 and Not Specific.", "verifiability_rationale": "The review point claims that the paper, especially the figures, is not wellformatted. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of why the figures are not wellformatted or how they should be improved. This lack of substantiation makes the claim 1, as the authors cannot confidently address the issue based on the provided information.", "helpfulness_rationale": "The review comment points out that the paper, particularly the figures, is not wellformatted. However, it lacks specific details or suggestions on how the authors might improve the layout of the figures. Without actionable guidance or examples of what constitutes a good layout, the authors are left without a clear path to enhance the presentation of their work. This makes the comment 3, as it identifies a potential area for improvement but does not provide sufficient detail to guide the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the paper\"s contributions, suggesting that they may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be clarified or expanded upon. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s contributions being perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific in its critique, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s contributions, suggesting that they may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. This feedback highlights a critical issue that could affect the paper\"s reception and perceived value within the NLP community. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional comparisons or clarifying the novelty of their approach. While it raises an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear critique but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks the authors to explain why the baseline results in Table 2 are different from those in Table 3 of reference [3]. While the comment prompts the authors to provide an explanation, it does not explicitly instruct them to make any changes or corrections to their draft. The action is implicit, as the authors need to infer that they should address the discrepancy in the results. However, the comment lacks concrete guidance on how to explain the difference or what aspects of the results need to be clarified. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment requests an explanation for the difference in baseline results between Table 2 and Table 3 of reference [3]. However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to identify the exact section being referenced. Additionally, the comment does not provide any specific guidance on what aspects of the results need to be clarified or how the authors should address the discrepancy. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point requests an explanation for the difference in baseline results between Table 2 and Table 3 of reference [3]. However, it does not provide any specific reasoning, examples, or references to support why these results might differ. Without additional context or justification, the authors are left to make their own interpretation, making the claim 1. Therefore, the comment is labeled as 1.", "helpfulness_rationale": "The review comment requests an explanation for the discrepancy in baseline results between Table 2 and Table 3 of reference [3]. While this feedback identifies a potential issue with the consistency of the results, it does not provide any guidance or suggestions on how the authors might address or resolve this discrepancy. The comment lacks actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a problem but does not offer any constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a misleading use of the term \"execution feedback\" in the title and Figure 2, suggesting that no actual execution feedback is used in the work. It provides specific examples, such as the assumption that perturbations result in a failure (EF = 0) and the definition of EF in terms of test suite pass/fail results. The comment implies that the authors should clarify the use of \"execution feedback\" and provide a more accurate description of how it is used in the work. While the action is explicit, it lacks concrete guidance on how to implement the correction, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of \"execution feedback,\" noting that no actual execution feedback is used, and that it is approximated based on structural perturbations in the AST. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of \"execution feedback\" is misleading because no actual execution feedback is used in the work. It provides specific examples, such as the assumption that perturbations result in a failure (EF = 0) and the definition of EF in terms of test suite pass/fail results. However, the comment lacks detailed reasoning or references to support the claim that the use of \"execution feedback\" is misleading. While the examples provide some context, they do not fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it identifies a significant issue with the use of the term \"execution feedback\" in the paper. It provides specific examples, such as the assumption that perturbations result in a failure and the definition of execution feedback in terms of test suite pass/fail results. This feedback is actionable, as it directs the authors to clarify the use of \"execution feedback\" and provide a more accurate description of how it is used in the work. By addressing this issue, the authors can improve the clarity and accuracy of their paper, making the feedback highly valuable for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific areas where the authors need to provide more information. First, it mentions the lack of clarity regarding the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model. Second, it notes the absence of detail on how many games are sampled to demonstrate the severity of the bias problem. While the comment identifies specific gaps in the paper, it does not provide explicit guidance on how the authors should address these issues or what actions they should take to clarify these points. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses issues related to the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model, as well as the lack of detail on how many games are sampled to demonstrate the severity of the bias problem. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the use of target words and dots and providing information on the number of games sampled. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity and detail provided in the paper regarding the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model, as well as the lack of information on how many games are sampled to demonstrate the severity of the bias problem. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of substantiation makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity and detail, such as the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model, and the absence of information on how many games are sampled to demonstrate the severity of the bias problem. While the comment highlights these issues, it does not provide actionable suggestions or guidance on how the authors might address these gaps. The feedback is 3 as it points out areas needing improvement, but it lacks depth and specificity, making it challenging for the authors to fully understand and implement the suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experiments conducted in the paper: the use of simple datasets and the assumption of uniformly random missing data. However, it does not provide any explicit or implicit suggestions on how the authors might address these issues. The comment lacks concrete guidance on what changes could be made to the datasets or the experimental setup to improve the robustness and realism of the results. Without specific actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the experiments, such as the use of simple datasets and the unrealistic assumption of uniformly random missing data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are conducted on simple datasets and that the assumption of uniformly random missing data is unrealistic in practice. While the comment provides a logical reasoning for why these issues might be problematic, it lacks specific examples or references to support the claim. Without detailed evidence or references, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is 3, as it provides a basis for further investigation but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies two key issues with the experiments conducted in the paper: the use of simple datasets and the assumption of uniformly random missing data. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues to improve the robustness and realism of their experiments. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice or detailed suggestions, which could leave the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that Figure 4 should include legends for the plots to improve interpretability. It also implies that the authors should clarify what each data point or plot corresponds to. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment is specific in its suggestion and provides concrete guidance on how to improve the figure. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the lack of legends and the need to clarify what each data point or plot corresponds to. This provides the authors with a clear understanding of what needs to be addressed to improve the figure. Therefore, this comment is rated as 5, corresponding to category 5.", "verifiability_rationale": "The review point claims that Figure 4 lacks legends, making it hard to interpret, and suggests that the authors should include what each data point or plot corresponds to. This claim is 3 as it points out a specific issue with the figure\"s presentation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for legends and clarification based on the comment, which could be improved with additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it lacks legends, which makes the plots difficult to interpret. It suggests that the authors should include legends and clarify what each data point or plot corresponds to. This feedback is clear and actionable, providing the authors with a direct and constructive suggestion to improve the clarity and interpretability of their figure. By addressing this issue, the authors can enhance the presentation of their data and make it more accessible to readers. Therefore, the comment is 5, as it offers a clear and actionable improvement that directly addresses a significant weakness in the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the paper is specifically concerned with sequencetosequence models, suggesting that the general quantization aware training strategy might be applicable to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits sequencetosequence models, implying that the authors should highlight this. While the comment is explicit in its request for clarification and suggests a specific area for attention, it does not provide detailed guidance on how to address these points or what specific aspects of the paper should be highlighted. The action is somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the paper is specifically concerned with sequencetosequence models, suggesting that the general quantization aware training strategy might be applicable to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits sequencetosequence models, implying that the authors should highlight this. However, the comment does not specify which part of the paper discusses sequencetosequence models or the robustnessaware quantization scheme, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its request for clarification, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the paper is specifically concerned with sequencetosequence models and suggests that the general quantization aware training strategy might be applicable to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits sequencetosequence models, implying that the authors should highlight this. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the paper is focused on sequencetosequence models or that the robustnessaware quantization scheme is particularly beneficial for them. Without these details, the claim is difficult to verify, making the comment 2.", "helpfulness_rationale": "The review comment raises a question about whether the paper is specifically concerned with sequencetosequence models and suggests that the general quantization aware training strategy might be applicable to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits sequencetosequence models, implying that the authors should highlight this. While the comment identifies a potential area for clarification and suggests a specific aspect of the paper that could be further emphasized, it lacks depth and does not provide actionable feedback on how the authors might address this concern. The comment is 3 as it points out a potential area for improvement but does not offer detailed guidance or suggestions for enhancing the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks for more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. While it does not explicitly instruct the authors to conduct these studies, it implies that they should perform them to better understand the impact of lambda. The action is somewhat explicit, as it directs the authors to explore a specific aspect of their algorithm. However, the comment lacks concrete guidance on how to conduct the ablation studies, such as specifying which metrics to analyze or which experiments to perform. Therefore, the action is 3, as it provides a clear direction but lacks detailed instructions. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point asks for more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. While it does not contain a subjective claim or suggestion, it requests additional analysis and experiments to better understand the impact of lambda. The comment is factual and descriptive, as it outlines a specific request for further investigation. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment requests more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. This feedback is specific and actionable, as it directs the authors to conduct additional experiments to better understand the impact of the hyperparameter. By providing a clear direction for improvement, the comment helps the authors enhance the robustness and comprehensiveness of their analysis. However, the comment could be more helpful if it suggested specific metrics or experimental designs for the ablation studies. Overall, the feedback is 4, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the base encoder of the proposed model or whether the authors train the model from scratch. While it prompts the authors to clarify these aspects, it does not provide explicit instructions or suggestions on how to address these questions or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify these details in their paper. However, the lack of concrete guidance on how to implement this clarification makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises questions about the base encoder of the proposed model and whether the authors train the model from scratch. However, it does not specify which part of the paper these questions relate to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area they need to address. Additionally, the comment does not provide any specific guidance or suggestions on how to clarify these aspects. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point poses questions about the base encoder of the proposed model and whether the authors train the model from scratch. These are factual inquiries that do not contain subjective opinions, judgments, or suggestions. The comment is purely descriptive and does not require any verification or evidence to be understood. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises questions about the base encoder of the proposed model and whether the authors train the model from scratch. While it prompts the authors to clarify these aspects, it does not provide specific guidance or suggestions on how to address these questions or what changes might be necessary. The feedback is 3 as it identifies areas where the authors could improve their clarity, but it lacks depth and actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the Ethical Statement should be extended to include a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to the ethical statement. The comment is specific in its suggestions, detailing which aspects of the ethical discussion need to be expanded. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests extending the Ethical Statement with a more concrete discussion of challenges not addressed in the dataset, specifically mentioning gender beyond the binary, races other than Black, and other sources of social bias. However, the comment does not specify which part of the paper the Ethical Statement is located in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to precisely identify the section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Ethical Statement should be extended to include a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment provides a clear direction for improvement, it lacks specific examples or references to support the claim. The authors would need to infer the need for such an extension, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the ethical statement. It suggests that the statement should be extended to include a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the ethical discussion. However, the comment could be more helpful if it included examples or references to support the suggested additions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the length of the minibatches, tau_t, which may be nonintegers. It suggests that the authors should clarify this to avoid potential side effects and questions about the validity of the analysis. The comment implies that the authors should address this issue by providing a detailed explanation of how the analysis holds when tau_t is noninteger and what happens if tau_t is much smaller than 1. However, the action is implicit, as the authors need to infer that they should clarify the length of the minibatches and provide a detailed explanation. The action is somewhat vague, as it does not specify exactly how to address the issue or what specific aspects of the analysis need clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the length of the minibatches, tau_t, which may be nonintegers. It suggests that the authors should clarify this to avoid potential side effects and questions about the validity of the analysis. However, the comment does not explicitly mention a specific part of the paper where this issue is discussed, making it weakly grounded. It is specific in detailing the concern about the length of minibatches and the potential impact of tau_t being much smaller than 1. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the length of the minibatches, tau_t, which may be nonintegers. It suggests that the authors should clarify this to avoid potential side effects and questions about the validity of the analysis. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the analysis might be affected by noninteger lengths of minibatches. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the length of the minibatches, tau_t, which may be nonintegers. It raises a concern about potential side effects and questions about the validity of the analysis if tau_t is much smaller than 1. While the comment highlights a potential area for clarification, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model. However, it does not provide any specific guidance or suggestions on how to address this issue or what aspects of the model should be analyzed to determine the inference cost. The comment lacks explicit instructions or concrete details on how the authors can improve their draft by considering this aspect. As a result, the authors are left without a clear understanding of what steps to take to address the issue of inference cost. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the computational cost associated with the inference process of the SCALE model, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses the SCALE model or the inference process, making it weakly grounded. The comment is specific in identifying the need to examine the computational cost, but it lacks detailed guidance on how to do so. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model. However, it does not provide any specific reasoning, examples, or references to support why this is a critical aspect to consider. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the inference cost of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. While the comment highlights the importance of examining the computational cost associated with the inference process, it does not provide specific guidance or suggestions on how to address this issue or what aspects of the model should be analyzed to determine the inference cost. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the article: the use of a subset of the complete dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in Table 2. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to include the full dataset, conduct performance comparisons, or explain the unusual results. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of a subset of the complete dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. It also mentions some peculiar experimental results, such as the unsupervised result outperforming the supervised result in Table 2. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the dataset usage and the unusual experimental results, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the article only uses a subset of the complete dataset and lacks performance comparisons with stateoftheart models, making it difficult to demonstrate the effectiveness of the proposed methods. It also notes some peculiar experimental results, such as the unsupervised result outperforming the supervised result in Table 2. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the article: the use of a subset of the complete dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in Table 2. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their experimental setup. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the use of the phrase \"lacks inherent semantic meaning,\" noting that it is not further elaborated upon. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the draft to clarify the meaning of the phrase. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. Additionally, the comment is not specific because it does not provide detailed guidance on what is meant by \"lacks inherent semantic meaning\" or how this issue can be addressed. Without specific examples or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the context or address the issue. Without additional information or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"lacks inherent semantic meaning,\" noting that it is not further elaborated upon. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the meaning of the phrase. Without actionable feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the authors\" approach: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment identifies specific areas where the authors need to provide more detail or justification, it does not explicitly instruct the authors on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of a large number of hidden units and an additional elementwise function, as well as the treatment of unobserved ratings as zeros. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the approach, but without explicit references to sections or figures, the authors may need to infer the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function, and that treating unobserved ratings as zeros may introduce bias, which is not justified. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies two key issues with the authors\" methodology: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment highlights these areas, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the motivation regarding MathGLM\"s accuracy is not robust. It provides a specific example, stating that MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, but these calculations can be done with 100% accuracy using other tools. However, the comment does not explicitly instruct the authors to revise their motivation or provide specific guidance on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to strengthen their motivation or provide a more robust justification for their approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim regarding motivation, specifically questioning the robustness of the motivation for using MathGLM. It provides a factual statement about MathGLM\"s accuracy and suggests that other tools can achieve 100% accuracy for the same calculations. However, the comment does not specify which part of the paper this issue is discussed or how it relates to the overall argument. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, while it raises a point about the motivation, it does not provide specific guidance on how to improve the motivation or address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation regarding MathGLM\"s accuracy is not robust, suggesting that other tools can achieve 100% accuracy for the same calculations. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is not 5, as it relies on the authors\" interpretation of the data presented. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation section of the paper, specifically questioning the robustness of the claim regarding MathGLM\"s accuracy. It points out that while MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, other tools can achieve 100% accuracy for the same calculations. This feedback highlights a gap in the paper\"s argument and suggests that the motivation could be strengthened by providing a more robust justification for the use of MathGLM. However, the comment lacks specific guidance on how to address this issue or improve the motivation, leaving the authors with limited actionable feedback. Therefore, the comment is 3, as it identifies a critical area for improvement but does not provide detailed suggestions or directions for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant weakness in the paper, noting that the authors rely on synthetic datasets and evaluate eventbased optical flow in realworld settings, which does not accurately reflect eventbased dense tracking. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their evaluation methodology. The authors are left without guidance on how to enhance their approach to better align with the actual eventbased dense tracking task. As a result, the comment lacks actionable feedback, making it 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the evaluation methodology of the paper, noting that the reliance on synthetic datasets and realworld settings does not accurately reflect eventbased dense tracking. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the evaluation methodology, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" reliance on synthetic datasets and realworld settings for evaluating eventbased optical flow does not accurately reflect eventbased dense tracking. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and clarity to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the authors\" reliance on synthetic datasets and realworld settings for evaluating eventbased optical flow does not accurately reflect eventbased dense tracking. This is a critical point that could impact the validity of the paper\"s conclusions. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their evaluation methodology. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their work, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the paper\"s motivation, suggesting that it opposes a common understanding without strong justification. It also points out that the experiments are weak due to limited dataset and LLM size, making the results unconvincing. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the motivation or the experiments. The feedback is somewhat vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the paper, suggesting that it opposes a common understanding without strong justification. However, it does not specify which part of the paper discusses the motivation, making it weakly grounded. The comment is specific in detailing the issues with the motivation and the experiments, as it mentions the lack of clarity, the limited dataset and LLM size, and the unconvincing results. This provides clear guidance on what needs to be addressed, making the comment somewhat grounded and specific. Therefore, it aligns with category 3.", "verifiability_rationale": "The review point claims that the motivation of the paper is unclear and that it opposes a common understanding without strong justification. It also criticizes the experiments for being weak due to limited dataset and LLM size, making the results unconvincing. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the claim is not 5 without additional evidence or context. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s motivation, noting that it contradicts established understanding without providing strong justification. It also critiques the experiments, highlighting the limitations of the dataset and LLM size, which makes the results unconvincing. This feedback is valuable as it points out areas where the authors need to strengthen their arguments and provide more robust evidence. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as suggesting additional experiments or providing more detailed justifications for the chosen methodology. Overall, the comment is 3, as it highlights important weaknesses but lacks depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the absence of confidence intervals in Table 3, specifically regarding the substitution ASR. While it identifies a potential issue with the presentation of results, it does not provide any explicit guidance or suggestions on how the authors should address this concern. The comment lacks concrete actions or detailed instructions on how to incorporate confidence intervals into the table or what specific changes are needed. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of confidence intervals in the substitution ASR, providing a clear and direct request for clarification or improvement. This feedback is actionable and provides a clear direction for the authors to enhance their presentation of results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the absence of confidence intervals in Table 3, specifically regarding the substitution ASR. While it identifies a potential issue with the presentation of results, it does not provide any supporting evidence or reasoning to justify the claim. The comment lacks specific examples or references that would help the authors understand why confidence intervals are important or how they should be included. Without additional context or justification, the claim remains 1, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting the absence of confidence intervals for the substitution ASR. This is a clear and actionable feedback that highlights a potential area for improvement in the presentation of results. By pointing out the missing confidence intervals, the comment encourages the authors to enhance the clarity and rigor of their data presentation. However, the comment could be more helpful if it provided additional guidance on how to incorporate or interpret these intervals. Despite this, the feedback is 3 as it directs the authors to a specific area that needs attention, allowing them to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding how to obtain or estimate the mean element mu_g for different kernel spaces. While it points out a potential issue with the paper, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps might be necessary. As a result, the authors are left without a clear understanding of what to do to resolve this ambiguity. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how to obtain or estimate the mean element mu_g for different kernel spaces. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its critique, the absence of explicit grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of how to obtain or estimate the mean element mu_g for different kernel spaces. However, it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might impact the paper. Without additional context or justification, the claim remains vague and lacks sufficient evidence for the authors to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the clarity of how to obtain or estimate the mean element mu_g for different kernel spaces. This is a crucial point that could impact the reproducibility and understanding of the paper. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. It does not provide any specific steps, examples, or references that could help the authors clarify this aspect. As a result, while the comment highlights an important area for improvement, it does not provide sufficient direction for the authors to make meaningful changes. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the paper would benefit from this consideration. The action is implicit and vague, as it leaves the authors to infer the exact steps needed to address the comment. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include additional datasets, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, the comment lacks specific reasoning or examples to support why this suggestion is beneficial or how it would enhance the paper. Without detailed justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. This feedback is 3 as it provides a direction for improvement by suggesting a specific type of dataset that could enhance the paper\"s comprehensiveness. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of the paper would benefit from this consideration. The authors may find it challenging to fully understand and address the feedback without additional context or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the suitability of cosine similarity score over Euclidean distance for computing Decidability in the context of biometric verification. While it suggests that cosine similarity is more commonly used, it does not provide explicit guidance or actionable steps for the authors to take. The comment implies that the authors should consider experimenting with cosine similarity, but it lacks detailed instructions or suggestions on how to implement this change or what results to expect. Therefore, the comment is 3, as it provides a direction for improvement but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment raises a question about the suitability of cosine similarity score over Euclidean distance for computing Decidability, particularly in the context of biometric verification. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the question should be addressed. While the comment is specific in its inquiry about the choice of similarity measure, the absence of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the suitability of cosine similarity score over Euclidean distance for computing Decidability in biometric verification. It does not contain a claim that requires verification or justification. The comment is purely a question seeking clarification or guidance, which aligns with the classification of \"No\".", "helpfulness_rationale": "The review comment raises a question about the suitability of cosine similarity score over Euclidean distance for computing Decidability in the context of biometric verification. While it prompts the authors to consider experimenting with cosine similarity, it does not provide specific guidance or suggestions on how to approach this comparison or what results to expect. The comment is 3 as it identifies a potential area for improvement and encourages further exploration, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the experiments conducted in the paper, stating that they are weak and only include a toy experiment and an experiment on a realworld dataset. It also notes that the proposed method lacks comparison with other counterpart methods and that the experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not provide explicit or implicit suggestions on how to improve the experiments, such as what additional experiments should be conducted or how to compare the proposed method with other methods. The lack of specific guidance leaves the authors uncertain about how to address the identified weaknesses, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the experiments conducted in the paper, noting that they are weak and only include a toy experiment and an experiment on a realworld dataset. It also points out that the proposed method lacks comparison with other counterpart methods and that the experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to identify the exact sections that need improvement. The lack of specific references to sections, tables, or figures makes the comment weakly grounded. While it provides some specificity by mentioning the need for more comprehensive experiments and comparisons, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are weak, noting that the paper only includes a toy experiment and an experiment on a realworld dataset. It also criticizes the lack of comparison with other counterpart methods and the insufficient experimental results to validate the effectiveness of the proposed method. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The absence of evidence or justification makes it difficult for the authors to understand the basis of the critique, leaving them uncertain about how to address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the experiments are weak and lack comparison with other counterpart methods. It also notes that the experimental results are insufficient to validate the effectiveness of the proposed method. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to improve the experiments or address the lack of comparison. The feedback is 3 as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This feedback is explicit and provides a clear action for the authors to take: they should ensure that these figures are properly referenced in the appendix. The comment is specific in identifying which figures need attention and what part of the paper they should be referenced in. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures related to completion errors\" and specifies that they are not referenced in the relevant analysis sections of the appendix. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly details what needs to be addressed, namely the lack of reference for these figures in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a factual observation that requires no further verification or reasoning to be understood. The comment is clear and specific, providing a direct observation about the missing references. Therefore, it is classified as \"3\" as it is factual but lacks explicit reasoning or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By ensuring that these figures are properly referenced, the authors can enhance the clarity and completeness of their paper. The comment is specific and provides a clear direction for the authors to follow, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the consistency of validation sets used for measuring perplexity across different levels. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to ensure consistency. The comment lacks concrete guidance on how to implement the suggested action, leaving the authors without a clear path forward. As a result, the comment is 1, as it does not offer any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment raises a question about the consistency of validation sets used for measuring perplexity across different levels. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure where this consistency is discussed. Additionally, the comment does not provide specific guidance or examples on how to address this issue, leaving the authors without a clear understanding of what needs to be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the consistency of validation sets used for measuring perplexity across different levels. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a basis for addressing the question or understanding its implications. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the consistency of validation sets used for measuring perplexity across different levels. This is a valid concern that could impact the reliability and comparability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what steps they should take to ensure consistency. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion about the originality of the setting and algorithm, suggesting they might seem incremental combinations of existing methods. However, it also acknowledges that the algorithm for graph labelings is efficient and different from existing ones. While the comment provides some insight into the perceived lack of originality, it does not offer explicit or implicit actions for the authors to take to address this concern. The authors are left to infer what changes might be needed to enhance the originality of their work. Therefore, the comment is barely actionable, as it lacks concrete guidance on how to improve the originality of the setting and algorithm.", "grounding_specificity_rationale": "The comment expresses an opinion about the originality of the setting and algorithm, suggesting they might seem incremental combinations of existing methods. However, it does not specify which part of the paper this opinion is based on, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is vague in its critique, as it does not provide specific examples or suggestions for improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the originality of the setting and algorithm, suggesting they might seem incremental combinations of existing methods. However, it does not provide specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment expresses an opinion about the originality of the setting and algorithm, suggesting they might seem incremental combinations of existing methods. However, it also acknowledges that the algorithm for graph labelings is efficient and different from existing ones. While the comment provides some insight into the perceived lack of originality, it does not offer specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. The feedback is 3 as it identifies a potential area for improvement but lacks actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using the stateaction of the current policy in the target environment as regularization can harm learning. It provides a specific example, stating that a suboptimal policy would result in suboptimal stateaction distribution used for regularization. However, the comment does not offer explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, as it does not provide concrete steps or suggestions for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the use of stateaction pairs in regularization, suggesting that it can harm learning. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential harm and providing an example, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using the stateaction of the current policy in the target environment as regularization can harm learning, citing the potential for a suboptimal policy to result in suboptimal stateaction distribution used for regularization. While the reasoning is logical and provides a specific example, it lacks detailed explanation or references to support the claim fully. The comment is 4 as it offers a clear rationale but could be strengthened with additional evidence or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of stateaction pairs in regularization, suggesting that it could harm learning. It provides a specific example, stating that a suboptimal policy would result in suboptimal stateaction distribution used for regularization. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential problem, it lacks actionable advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential negative impact of the feature compactness loss and sharpnessaware minimization on the model\u2019s performance on base classes. It suggests that if such degradation occurs, the authors should discuss how to mitigate it to maintain performance. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to mitigate the potential negative impact. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the objective of the feature compactness loss and sharpnessaware minimization, specifically questioning whether this operation could negatively impact the model\u2019s performance on base classes. However, it does not specify which part of the paper this issue is discussed or addressed, making it weakly grounded. The comment is specific in detailing the concern about the potential negative impact and the need to discuss mitigation strategies. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential negative impact of feature compactness loss and sharpnessaware minimization on the model\u2019s performance on base classes. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the feature compactness loss and sharpnessaware minimization, specifically questioning whether it could negatively impact the model\u2019s performance on base classes. It highlights the importance of discussing how such degradation could be mitigated to maintain performance. However, the comment lacks specific guidance or suggestions on how to address this concern or what actions the authors should take to mitigate the potential negative impact. While it points out a potential area for improvement, it does not provide detailed feedback or actionable advice, making it 3. The authors would need to infer the necessary steps to address the issue, which limits the comment\u2019s effectiveness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the insights from the work and how to prevent attention collapse in CL. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the work need to be addressed or how to approach the problem of attention collapse. Without concrete suggestions or directions, the authors are left without a clear understanding of how to respond to the comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the insights from the work and how to prevent attention collapse in CL, but it does not specify which part of the paper these questions relate to. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the questions are general and do not provide specific guidance on what needs to be addressed or how to approach the problem. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about the insights from the work and how to prevent attention collapse in CL, but it does not contain any claims or opinions that require verification. It is a question posed to the authors, seeking clarification or guidance. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the insights from the work and how to prevent attention collapse in CL, which are relevant areas for discussion and improvement. However, it lacks specific guidance or suggestions on how to address these issues or what aspects of the work need to be clarified. The comment is 3 as it identifies areas for improvement but does not provide actionable feedback or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the clarity of how the CHC model affects the capabilities of MLLMs. It asks for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit and suggests the inclusion of case studies or pilot experiments to illustrate this influence. While the comment implies that the authors should provide more detail, it does not explicitly instruct them to add specific sections or content. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the impact of the CHC model on MLLMs and provide supporting evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CHC model\" and its relevance to the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding how the CHC model affects the capabilities of MLLMs, and it requests additional details such as specific attributes, behaviors, and case studies or pilot experiments. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of how the CHC model affects the capabilities of MLLMs, specifically asking for details on specific attributes, behaviors, and case studies or pilot experiments. While the comment does not contain a direct claim, it implies a need for clarification and additional evidence, which can be considered a form of implicit feedback. However, without explicit guidance or examples, the authors may find it challenging to fully understand the implications of the comment. Therefore, the comment is rated as 2, as it provides some context but lacks detailed justification or references.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by providing more clarity on the impact of the CHC model on MLLMs. It asks for specific attributes, behaviors, and case studies or pilot experiments that would illustrate this influence. This feedback is clear and actionable, as it directs the authors to enhance the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it provided examples of what specific attributes or behaviors might be relevant or suggested some potential case studies. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the pretraining model used, PreGNN, is relatively old and recommends considering more uptodate models. It encourages the authors to integrate these newer models to better showcase the significance and practical usage of their approach. The comment provides a clear action for the authors to take, which is to explore and integrate more recent pretraining models. However, it does not specify which models to consider or how to integrate them, leaving the authors with a general direction but lacking concrete guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the pretraining model, PreGNN, and suggests considering more uptodate models. It also provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which helps the authors understand the context and relevance of the suggested models. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand the specific issues being raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the pretraining model, PreGNN, is relatively old and suggests considering more uptodate models. It provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which are relevant and recent. This level of detail supports the claim and provides a clear basis for the authors to understand the relevance of the suggested models. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the pretraining model, PreGNN, is relatively old and recommends considering more uptodate models. It provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which are relevant to the field. This feedback is actionable as it encourages the authors to enhance the significance and practical usage of their approach by integrating more recent models. However, the comment could be more helpful if it offered additional guidance on how to integrate these models or why they are particularly relevant. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential engineering challenge in the model\"s input, noting that taking the difference between current object pose and target object pose as input can be difficult due to the complexities of object segmentation and pose tracking in the real world. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It suggests that the authors have documented their approach well in Section A.3, but it does not offer guidance on how to mitigate the engineering challenge or improve the model. As a result, the authors are left without clear instructions on how to address this concern, making the comment 1.", "grounding_specificity_rationale": "The comment addresses a potential engineering challenge in the model\"s input, specifically mentioning the difference between current object pose and target object pose. It acknowledges that this approach can be difficult due to the complexities of object segmentation and pose tracking in the real world. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the challenge and suggesting that the authors have documented their approach well in Section A.3, but it does not provide detailed guidance on how to address the challenge. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model takes the difference between current object pose and target object pose as input, which can bring significant engineering challenges due to the difficulties of object segmentation and pose tracking in the real world. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. While the reasoning is logical, the lack of detailed evidence or examples weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential engineering challenge in the model\"s input, specifically mentioning that taking the difference between current object pose and target object pose can be difficult due to the complexities of object segmentation and pose tracking in the real world. While the comment acknowledges that the authors have documented their approach well in Section A.3, it does not provide specific suggestions or guidance on how to address this challenge or improve the model. The feedback is 3 as it highlights a potential issue that could impact the model\"s performance, but it lacks actionable advice for the authors to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential application. It also indicates that the authors have addressed most of the previous comments and suggestions. However, the comment does not provide explicit guidance on how to conduct these evaluations or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential application. It also indicates that the authors have addressed most of the previous comments and suggestions. However, the comment does not specify which part of the paper discusses the downstream applications or where the authors should include these evaluations. This makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific about the type of evaluation (downstream performance and style transfer), it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential application. It also indicates that the authors have addressed most of the previous comments and suggestions. However, the comment lacks specific examples or detailed reasoning to support the claim that more downstream performance evaluations are needed. While the suggestion is logical, it does not provide a clear justification or evidence to convince the authors to include these evaluations. Therefore, the claim is 3, as it is based on a reasonable suggestion but lacks detailed support.", "helpfulness_rationale": "The review comment suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential application. It also indicates that the authors have addressed most of the previous comments and suggestions. However, the comment lacks specific guidance on how to conduct these evaluations or what aspects to focus on, leaving the authors with limited actionable feedback. While it points out an area for improvement, it does not provide detailed suggestions or examples to enhance the draft. Therefore, the comment is 3, as it identifies a need for more evaluation but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses confusion about the availability of labels for the test set performance on GLUE datasets. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify or resolve this confusion, leaving them without a clear path forward. As a result, the comment is 1, aligning with a score of 1.", "grounding_specificity_rationale": "The comment raises a question about the availability of labels for the test set performance on GLUE datasets, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this question pertains to, making it weakly grounded. The comment is specific in identifying the issue, as it questions the availability of labels, which is a crucial detail for reproducibility and understanding the experimental setup. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses confusion about the availability of labels for the test set performance on GLUE datasets. However, it does not provide any specific reasoning, examples, or references to support why this confusion might exist or how it could be addressed. The comment lacks detailed justification or context, making it difficult for the authors to understand or address the issue. As a result, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a question about the availability of labels for the test set performance on GLUE datasets, which is a crucial aspect for reproducibility and understanding the experimental setup. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the situation. Without actionable feedback or specific advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 3.2 could be shortened because many equations are already known in the community and not proposed by this work. It implies that the authors should consider removing these equations to save space for more important details. However, the comment does not provide explicit guidance on which equations to remove or how to determine which ones are already known. The action is implicit and somewhat vague, as the authors need to infer the specific equations to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 3.2 could be shortened because many equations are already known in the community and not proposed by this work. It implies that the authors should consider removing these equations to save space for more important details. However, the comment does not specify which part of the paper this refers to, making it weakly grounded. It is specific in suggesting that the equations should be removed, but without explicit references to the equations or sections, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Section 3.2 could be shortened because many equations are already known in the community and not proposed by this work. While the comment implies that the equations are not novel contributions, it does not provide specific examples or references to support this claim. Without detailed justification or examples, the authors may find it difficult to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that Section 3.2 could be shortened. The reasoning provided is that many equations in this section are already known in the community and not proposed by the authors, which could save space for more important details. However, the comment lacks specific guidance on which equations should be removed or how to determine which ones are already known. This makes the feedback 3, as it provides a direction for improvement but does not offer detailed actionable steps. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on which evaluation method was used between automatic and human evaluation in specific figures and tables. While it prompts the authors to provide this information, it does not explicitly instruct them to include it in their draft or suggest where to add it. The action is implicit, as the authors can infer that they need to clarify this information, but it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, namely Figure 3, Table 3, and Figure 5, allowing the authors to accurately identify the sections being addressed. It is also specific because it requests clarification on the evaluation method used between automatic and human evaluation in these sections. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification on the evaluation methods used in specific figures and tables. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is specific and requests clarification on the evaluation methods used in specific figures and tables (Figure 3, Table 3, and Figure 5). This feedback is actionable as it directs the authors to provide more detailed information about their evaluation process, which could enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested specific ways to present or discuss this information, such as including it in the methodology or results sections. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth in terms of actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the reviewer\"s understanding of a specific aspect of the paper, specifically the coverage rate and its relation to the bound mentioned in Theorem 1. It also suggests that the authors consider additional assumptions to achieve the desired coverage rate. While the comment implies an action\u2014correcting the understanding or providing additional assumptions\u2014it does not explicitly instruct the authors on how to do so. The action is somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, referencing \"1 > 0.9, t=5: 0.9 > 1, \u2026\" and \"Theorem 1\". This allows the authors to accurately identify the section being discussed. The comment is also specific because it details the issue with the coverage rate, explaining that it is larger than the bound and questioning the reviewer\"s understanding. It suggests that the authors consider additional assumptions to achieve the desired coverage rate, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reviewer\"s understanding of a specific aspect of the paper, particularly the coverage rate and its relation to the bound mentioned in Theorem 1. It provides a logical reasoning by explaining that the average coverage rate is 0.5, which is larger than the bound, and asks for clarification or additional assumptions to achieve the desired coverage rate. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning and provide additional context to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the reviewer\"s understanding of a specific aspect of the paper, particularly the coverage rate and its relation to the bound mentioned in Theorem 1. It points out that the average coverage rate is 0.5, which is larger than the bound, and asks for clarification or additional assumptions to achieve the desired coverage rate. This feedback is 3 as it identifies a potential misunderstanding or area for clarification, but it lacks depth and does not provide specific guidance on how to address the issue or what additional assumptions might be necessary. The authors would need to infer the exact steps to take, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using one translator per language might not be sufficient for producing annotations, implying that multiple translators could provide more comprehensive coverage. However, it does not explicitly instruct the authors to use multiple translators or provide any guidance on how to implement this suggestion. The action is implicit and vague, as the authors are left to infer that they should consider using multiple translators. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of using one translator per language for annotations, suggesting that this might not be sufficient. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. The comment is vague and lacks specificity, as it does not provide detailed guidance on how to address the issue or what changes might be necessary. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that using one translator per language might not be sufficient for producing annotations, implying that multiple translators could provide more comprehensive coverage. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without detailed justification or evidence, the claim remains 3, as it is based on a logical argument but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of using one translator per language for annotations, suggesting that multiple translators might be necessary to provide comprehensive coverage. However, the comment does not offer specific guidance or suggestions on how to address this issue or what changes might be needed in the annotation process. While it identifies a potential area for improvement, it lacks actionable advice or detailed recommendations, making it 3. The authors would need to infer that they should consider using multiple translators, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the directionality of the statement \"people wear a hat and play guitar not viceversa.\" It asks why this directionality is not considered. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks specific guidance on how the authors might address this issue or what changes could be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It raises a question about the directionality of a statement but does not provide any context or reference to a specific section, table, or figure. Therefore, the authors cannot confidently determine which part of the paper the comment pertains to, making it weakly grounded. Additionally, the comment is not specific because it does not detail what needs to be addressed or why the directionality is important. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the directionality of a statement, \"people wear a hat and play guitar not viceversa,\" and asks why this directionality is not considered. However, it does not provide any claim, suggestion, or reasoning to support why this directionality is important or how it might be addressed. The comment lacks any evidence or justification, making it 1. Therefore, it does not provide any actionable feedback for the authors to improve their draft.", "helpfulness_rationale": "The review comment raises a question about the directionality of a statement, specifically questioning why the authors chose to present the information as \"people wear a hat and play guitar not viceversa\" rather than the reverse. However, the comment does not provide any suggestions or insights on how this directionality might be addressed or why it is important. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that 2000 examples may be insufficient for the model to learn a transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might increase the number of examples or what other strategies could be employed to improve the model\"s learning. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that 2000 examples may be insufficient for the model to learn a transformation correctly. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what might be insufficient or how the authors could address this issue. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that 2000 examples may be insufficient for the model to learn a transformation correctly. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this claim is valid or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that 2000 examples may be insufficient for the model to learn a transformation correctly. While this observation highlights a potential limitation in the dataset size, it does not provide any specific suggestions or guidance on how the authors might address this issue. The comment lacks actionable advice, such as recommendations for increasing the dataset size or exploring alternative strategies to improve the model\"s learning. Without concrete suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difference between Algorithm 1 and variational inference, specifically noting that Algorithm 1 approximates the target distribution with a Gaussian distribution. However, it does not provide any explicit or implicit suggestions on how the authors should address this question or what changes might be needed in their draft. The comment lacks guidance on how to clarify the distinction or discuss the advantages of the approach. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the difference between Algorithm 1 and variational inference, specifically noting that Algorithm 1 approximates the target distribution with a Gaussian distribution. However, it does not specify which part of the paper Algorithm 1 is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its inquiry about the method and its relation to variational inference, the lack of grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between Algorithm 1 and variational inference, specifically noting that Algorithm 1 approximates the target distribution with a Gaussian distribution. However, it does not provide any claims or suggestions that require verification or justification. The comment is purely descriptive and does not offer any new information or insights that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the difference between Algorithm 1 and variational inference, specifically noting that Algorithm 1 approximates the target distribution with a Gaussian distribution. This question highlights a potential area for clarification and deeper understanding in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this question or what improvements could be made to their work. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and direction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the entailment exercise lacks basic details and is difficult to assess the efficacy of the technique based on the information provided in the paper. It recommends either removing the exercise or providing more empirical and analyzed information. While the comment implies that the authors should provide more details, it does not explicitly instruct them to do so. The action is somewhat vague, as it leaves the authors to infer that they need to add more information or remove the exercise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the entailment exercise lacks basic details and is difficult to assess the efficacy of the technique based on the information provided in the paper. It recommends either removing the exercise or providing more empirical and analyzed information. However, the comment does not specify which part of the paper the entailment exercise is located in, making it weakly grounded. It is specific in suggesting that the authors should either remove the exercise or provide more detailed information, but without explicit references to the section or table, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the entailment exercise lacks basic details and is difficult to assess the efficacy of the technique based on the information provided in the paper. It suggests either removing the exercise or providing more empirical and analyzed information. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leaving them uncertain about how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the entailment exercise, noting that it lacks basic details and is difficult to assess the efficacy of the technique based on the information provided in the paper. It suggests either removing the exercise or providing more empirical and analyzed information. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to address the issue or what specific empirical data or analysis would be necessary. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify or resolve the ambiguity, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps for the authors to improve their draft. Therefore, it aligns with the label 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (225 and 227) in the paper where the mathematical expression of the Gaussian distribution is ambiguous. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly identifies the issue as the ambiguity in the mathematical expression, providing a clear direction for the authors to address this concern. Therefore, this comment is 5, aligning with label 5.", "verifiability_rationale": "The review point claims that the mathematical expression of the Gaussian distribution in lines 225 and 227 is ambiguous. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1, as it lacks sufficient justification to be helpful.", "helpfulness_rationale": "The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. This feedback is clear and actionable, as it directs the authors to a specific part of their draft where clarification is needed. However, the comment does not provide any suggestions or guidance on how to resolve the ambiguity, which limits its helpfulness. While it highlights an area for improvement, it lacks depth and could be more helpful if it offered suggestions for clarification or resolution. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current testing is insufficient because it only uses certain tokens. It implies that additional types of responses should be considered. However, the comment does not provide explicit guidance on what specific types of responses should be included or how they should be incorporated into the testing framework. The action is implicit, as the authors need to infer that they should expand their testing to include more diverse responses. While the suggestion is concrete in terms of the need for additional responses, the lack of specific examples or guidance on how to implement this makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the current testing is insufficient because it only uses certain tokens. It implies that additional types of responses should be considered. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its suggestion to include additional types of responses, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the current testing is insufficient because it only uses certain tokens. It implies that additional types of responses should be considered. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or examples, the claim is 3, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the testing methodology, suggesting that the current use of tokens is insufficient and that additional types of responses should be considered. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to expand the testing framework or what specific types of responses would be beneficial. This feedback is 3 as it points out a potential weakness in the evaluation process, but it does not provide actionable steps or examples for the authors to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing in removing privacy information. It suggests that relying solely on temperature manipulation may not be sufficient for text sanitization. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their privacy protection mechanisms. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing in removing privacy information. It suggests that relying solely on temperature manipulation may not be sufficient for text sanitization. However, the comment does not specify which part of the paper discusses the privacy protection mechanism or where the critique is being made. This lack of grounding makes it challenging for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its critique of the privacy protection method, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the privacy protection capability is not sufficient, specifically questioning the effectiveness of using chatGPT for text paraphrasing in removing privacy information. It suggests that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and support to fully substantiate the authors\" concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the privacy protection capabilities of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing in removing privacy information. It highlights that relying solely on temperature manipulation may not be sufficient for text sanitization. This feedback is valuable as it points out a potential weakness in the paper\"s approach to privacy protection. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as exploring alternative methods for privacy protection or providing more detailed explanations of the current approach. Without specific recommendations, the comment is 3, as it highlights an important area for improvement but lacks actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the approach used in the manuscript, suggesting that it is not significant enough. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their approach. The comment lacks explicit actions or concrete details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach used in the manuscript, specifically mentioning the use of word embeddings to define the weight of lexicon terms. However, it does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what specific issues need to be addressed. The comment is also not specific in detailing what aspects of the approach lack novelty. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the manuscript described an approach in sentimental analysis using a relatively new method of word embeddings to define the weight of lexicon terms, but it does not provide any specific evidence or reasoning to support this claim. Without detailed examples or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the approach used in the manuscript, specifically mentioning the use of word embeddings to define the weight of lexicon terms. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The comment lacks actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This comparison would help readers understand how the proposed method stands in relation to conventional methods and the extent of its advantages. The comment provides a clear and explicit action for the authors to take, which is to include a comparison with nonNeRF methods. It also specifies the tasks where this comparison should be made, making the action concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. However, it does not specify which part of the paper this comparison should be made or which tasks are being referred to. This lack of specificity makes it difficult for the authors to understand exactly where and how to implement the suggested comparison. As a result, the comment is 1, as the authors cannot confidently determine which part of the paper it addresses. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This feedback is valuable as it provides a clear direction for improvement, helping the authors understand how their method stands in relation to conventional methods and the extent of its advantages. By including such a comparison, the authors can better contextualize their work and highlight its contributions. However, the comment could be more helpful if it provided specific examples or tasks where this comparison would be particularly relevant. Overall, the comment is 4 as it offers actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" use of the term \"NLU\" in light of the fact that some lowerlevel tasks might be considered syntactic tasks. It does not provide explicit instructions or suggestions on how the authors should address this concern, such as clarifying the terminology or providing examples. The action is implicit and vague, as the authors are left to infer that they need to clarify their use of \"NLU\" in the context of the paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections of the paper (178:181), allowing the authors to accurately identify the part being addressed. It is also specific because it questions the use of the term \"NLU\" in light of the rich literature on morphological and syntactic probing tasks, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of the term \"NLU\" in the paper, specifically questioning whether lowerlevel tasks should be considered syntactic tasks. While the comment provides a reference to the literature on morphological and syntactic probing tasks, it does not offer a detailed explanation or justification for why the authors\" use of \"NLU\" might be problematic or inconsistent. The lack of specific examples or reasoning makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is 3, as it provides some basis for discussion but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"NLU\" in the paper, specifically questioning whether some lowerlevel tasks might be considered syntactic tasks. This raises a valid concern about the consistency and clarity of terminology throughout the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as clarifying the terminology or providing examples of the tasks being discussed. While it highlights an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should discuss the relationship of their idea to traditional motion trajectory segmentation methods, particularly those using Eulerian vs. Lagrangian views. It implies that this discussion would enhance the theoretical and academic value of their approach without compromising the technical contribution. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which sections of the paper to discuss or what specific aspects to address. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of longterm motion trajectories, a traditional idea in computer vision, and provides a specific reference to support this claim. It also suggests discussing the relationship of the authors\" idea to these traditional attempts, which is a clear and specific request for improvement. The comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using longterm motion trajectories is a traditional idea in computer vision, especially for motion segmentation, and provides a reference to support this claim. It also suggests that discussing the relationship of the authors\" idea to these traditional attempts would strengthen the theoretical and academic value of their approach. The claim is supported by a specific reference, making it 4. However, the comment could be more robust if it provided additional examples or elaborated on the specific aspects of the traditional methods that are relevant to the authors\" work.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the use of longterm motion trajectories is a traditional idea in computer vision, particularly in motion segmentation. It suggests that the authors should briefly discuss the relationship of their idea to these traditional attempts, which could enhance the theoretical and academic value of their approach. While the comment provides a clear direction for improvement, it lacks specific guidance on how to integrate this discussion into the paper or what aspects of the traditional methods to address. This makes the feedback 3, as it offers a valuable suggestion but does not fully guide the authors in implementing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the problem formalization section, specifically noting that it focuses on formalizing challenges rather than describing the specific task types addressed on graph data. The comment implies that the authors should clarify the task objectives to align with the section\"s intended purpose. However, it does not provide explicit guidance on how to achieve this clarification or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the problem formalization section, which is a specific part of the paper. It highlights a lack of clarity in describing the specific task types addressed on graph data, instead focusing on formalizing the challenges faced. This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the problem formalization section lacks a clear description of specific task types on graph data, instead focusing on formalizing challenges. This claim is 3 as it identifies a specific area where the paper could be improved, but it lacks detailed examples or references to support the claim fully. The authors would need to infer the need for clarification based on the comment, which could be improved with more explicit guidance or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. Instead, it focuses on formalizing the challenges faced, which makes the purpose of the section unclear. This feedback is actionable as it provides a clear direction for improvement, suggesting that the authors should clarify the task objectives to align with the section\"s intended purpose. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the clarity of the task descriptions. Overall, the comment is 4, as it provides a clear and actionable feedback that guides the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. It suggests that these techniques could benefit other models and that the lack of an ablation study makes it difficult to assess their impact and compare YOSO\"s performance with other models. However, the comment does not provide explicit guidance on how the authors should conduct or implement this ablation study. While it implies the need for such an analysis, the lack of detailed instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the types of training techniques mentioned, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. It suggests that these techniques could benefit other models and that the absence of an ablation study makes it difficult to assess their impact and compare YOSO\"s performance with other models. However, the comment does not provide specific examples or references to support the claim that these techniques are valuable or how the lack of an ablation study affects the paper\"s conclusions. This lack of detailed reasoning or evidence makes the claim 3, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. This is a valuable piece of feedback as it highlights the absence of a critical analysis that could provide insights into the effectiveness of these techniques. By emphasizing the importance of such an ablation study, the comment encourages the authors to conduct a thorough evaluation of their training methods, which could enhance the robustness and comparability of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation study or suggested alternative approaches. Overall, the feedback is 4 as it directs the authors towards an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the paper: the limited content and the presence of redundant descriptions, specifically mentioning the overlap between two paragraphs that cover the motivation and work approach already discussed in the introduction. It also suggests that the authors should present a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. The comment provides explicit actions for the authors to take, such as identifying redundant descriptions and conducting a validation experiment. However, it lacks specific guidance on how to identify and address the redundant descriptions or how to design the validation experiment. The actions are clear but could be more detailed, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the introduction and the paragraphs from line 229 to line 272, allowing the authors to accurately identify the sections being addressed. It also specifies the issue of redundant descriptions and suggests a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. This provides clear guidance on what needs to be addressed and how, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the actual content of the paper is limited and contains redundant descriptions, specifically mentioning the overlap between two paragraphs that cover the motivation and work approach already discussed in the introduction. The reviewer suggests that the authors should present a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. While the claim about redundant descriptions is supported by the mention of specific lines, the suggestion for a validation experiment lacks detailed reasoning or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key issues with the paper: the limited content and the presence of redundant descriptions, specifically pointing out the overlap between two paragraphs that cover the motivation and work approach already discussed in the introduction. It also suggests that the authors should present a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, the comment could be more helpful if it offered more detailed guidance on how to identify and address the redundant descriptions or how to design the validation experiment. Overall, the comment is 4 as it directs the authors towards important improvements but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the theoretical contributions are too abstract and unclear in their connection to the proposed method. It provides a specific example, mentioning that the use of segregated feature vectors for backdoored vs. clean data seems artificial and not directly related to EigenGuard. The comment implies that the authors should rewrite the section to clarify these connections. However, it does not provide detailed guidance on how to rewrite the section or what specific aspects need clarification. The action is explicit but somewhat vague, as it leaves the authors to infer the exact steps needed to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical contributions,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the clarity of the connection between the theoretical contributions and the proposed method. The comment is specific in detailing the issue with the abstract nature of the theoretical contributions and the lack of clarity in their connection to the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical contributions are too abstract and unclear in their connection to the proposed method. It provides a specific example, stating that the use of segregated feature vectors for backdoored vs. clean data seems artificial and not directly related to EigenGuard. However, the comment lacks detailed reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without specific evidence or references, the claim is 3, as it provides a general observation but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical contributions, noting that they are too abstract and lack clarity in their connection to the proposed method. The reviewer provides a specific example, mentioning that the use of segregated feature vectors for backdoored vs. clean data seems artificial and not directly related to EigenGuard. This feedback is clear and actionable, as it directs the authors to rewrite the section to clarify the connections between the theoretical contributions and the proposed method. However, the comment could be more helpful if it provided additional guidance on how to rewrite the section or suggested specific aspects that need clarification. Overall, the comment is 4, as it offers valuable feedback that can guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of whether the code will be released, particularly concerning the reproducibility of the GCN implementation. While it acknowledges that the author\"s descriptions are detailed and more information is available in the supplement, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the release plans or provide additional details to ensure reproducibility, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential issue but does not offer detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the code will be released, particularly regarding the reproducibility of the GCN implementation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper is being addressed. While it is specific in its critique of the reproducibility issue, the lack of grounding makes it difficult for the authors to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of whether the code will be released, particularly regarding the reproducibility of the GCN implementation. It suggests that the authors should clarify the release plans or provide additional details to ensure reproducibility. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the code release is unclear or difficult to reproduce. Without additional context or evidence, the claim is 3, as it highlights a potential issue but lacks sufficient justification for the authors to address it fully.", "helpfulness_rationale": "The review comment raises a concern about the clarity of whether the code will be released, particularly regarding the reproducibility of the GCN implementation. It notes that while the author\"s descriptions are detailed, the lack of original code makes it difficult to reproduce the results. This feedback is 3 as it identifies a potential issue that could affect the reproducibility and impact of the work. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as offering additional details or plans for releasing the code. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors for not using differential functions directly in Equations (9) and (10) instead of using secondorder Taylor expansions. While it implies that the authors should consider using the differential functions themselves, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors are left to infer that they should replace the Taylor expansions with the differential functions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind using secondorder Taylor expansions instead of the differential functions themselves, providing a clear and direct request for clarification or justification. This feedback is precise and actionable, making it 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors for not using differential functions directly in Equations (9) and (10) instead of using secondorder Taylor expansions. While the comment raises a valid point about the potential benefits of using differential functions, it does not provide any specific reasoning or evidence to support why the authors chose to use Taylor expansions. The lack of justification or explanation makes the claim 3, as the authors are left to infer the reasoning behind the choice. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the use of secondorder Taylor expansions in Equations (9) and (10) instead of directly using differential functions. It prompts the authors to consider why they chose to use Taylor expansions and whether the differential functions themselves could be used. This feedback is clear and actionable, as it directly addresses a potential area for improvement in the methodology or mathematical formulation. However, it could be more helpful if it provided additional context or suggestions on how to implement this change or why the authors might have opted for Taylor expansions. Overall, the comment is 4, as it identifies a specific area for consideration and encourages the authors to reflect on their approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue in Table 3, noting that the encs BPE to character results are missing the recall on lemmas/forms seen in training. It also provides references to support the claim, suggesting that the authors should include this information. The comment is explicit in identifying the missing information and provides concrete guidance on what needs to be added to the table. This allows the authors to directly address the issue and improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely the recall on lemmas/forms seen in training. The references provided further enhance the specificity of the comment, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that encs BPE to character results in Table 3 are missing the recall on lemmas/forms seen in training. It provides references to support this claim, citing relevant works that discuss the importance of recall on lemmas/forms in training. The references help to substantiate the claim, making it 4. However, the comment could be more robust if it included a brief explanation of why the recall on lemmas/forms is important in this context, enhancing the clarity and depth of the justification. Overall, the comment is 4.", "helpfulness_rationale": "The review comment identifies a specific issue in Table 3, noting that the encs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to support the claim, suggesting that the authors should include this information. This feedback is clear and actionable, as it directs the authors to a specific area of the paper that needs improvement. By addressing this issue, the authors can enhance the completeness and accuracy of their results. The comment is 4 because it provides a clear direction for improvement, but it could be more comprehensive if it offered additional guidance on how to incorporate the missing information or why it is important. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that better wordalignment improves manytomany translation, specifically noting that the proposed method does not impact the MLSC setup (Table 3). While the comment implies that the authors should provide an explanation for this discrepancy, it does not explicitly instruct them to do so or offer guidance on how to address it. The action is implicit, as the authors need to infer that they should explain why the proposed method does not affect the MLSC setup. However, the comment lacks concrete details on how to implement this explanation, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the claim that better wordalignment improves manytomany translation, specifically focusing on why the proposed method does not impact the MLSC setup (Table 3). It references Section 4, which touches on this point, but does not provide a clear explanation. The comment is fully grounded as it explicitly mentions the section where the issue is raised, allowing the authors to accurately identify the part of the paper being addressed. However, it is somewhat specific because it does not provide detailed guidance on how to address the issue or what changes might be necessary. Therefore, this comment is classified as fully grounded and somewhat specific, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that better wordalignment improves manytomany translation, specifically noting that the proposed method does not impact the MLSC setup (Table 3). While the comment implies that the authors should provide an explanation for this discrepancy, it lacks specific examples or references to support the claim. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2, as it provides a basis for discussion but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the claim about better wordalignment improving manytomany translation is not adequately supported by the proposed method, which does not impact the MLSC setup (Table 3). While the comment highlights a potential gap in the paper\"s explanation, it does not provide detailed guidance or suggestions on how the authors might address this issue or strengthen their argument. The feedback is 3 as it points out a specific area that requires further clarification, but it lacks depth and actionable advice, making it a 3 comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the method, noting that it requires precollected offline datasets and cannot be applied in an online setting. This observation is clear and provides a specific area for improvement, suggesting that the authors should consider how to adapt their method for online applications. The comment is explicit in identifying the issue and provides a direct action for the authors to take, which is to address the limitation in the context of online settings. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the method, noting that it requires precollected offline datasets and cannot be applied in an online setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded. It also specifies the issue, indicating that the authors should consider how to adapt their method for online applications. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method requires precollected offline datasets and cannot be applied in an online setting. This is a logical observation based on the description of the method. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of this claim, which could be improved by providing more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the method, noting that it requires precollected offline datasets and cannot be applied in an online setting. This observation is clear and provides a specific area for improvement, highlighting the restriction of the method to offline applications. The comment suggests that the authors should consider how to adapt their method for online settings, which is a valuable piece of feedback. However, the comment could be more helpful if it provided additional guidance on how to address this limitation or suggested alternative approaches. Overall, the comment is 4 as it points out a critical issue that needs to be addressed, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the evaluation of the learned representation, noting that it was only assessed in a linear evaluation setting. The comment suggests that other downstream tasks, such as finetuning, detection, and segmentation, could provide a more comprehensive evaluation. However, it does not explicitly instruct the authors to include these tasks in their evaluation or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their evaluation to include these additional tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the learned representation, specifically noting that it was only assessed in a linear evaluation setting. This provides some grounding as the authors can infer that the part of the paper being addressed is related to the evaluation methodology. However, the comment does not specify which section or part of the paper discusses the evaluation, making it weakly grounded. The comment is specific in suggesting that other downstream tasks, such as finetuning, detection, and segmentation, could be used for a more comprehensive evaluation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 4.", "verifiability_rationale": "The review point claims that the quality of the learned representation was only evaluated in a linear setting, which is insufficient to draw a clear conclusion. The comment suggests that other downstream tasks, such as finetuning, detection, and segmentation, could provide a more comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that these additional tasks would provide a more thorough evaluation. While the reasoning is logical, the absence of detailed examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the learned representation, noting that it was only assessed in a linear setting. This is a valid concern, as it suggests that the evaluation might not be comprehensive enough to draw a clear conclusion. The comment provides a specific suggestion for improvement by recommending the inclusion of other downstream tasks, such as finetuning, detection, and segmentation, which are commonly used in the literature. This feedback is actionable and constructive, as it guides the authors to consider expanding their evaluation methodology. However, the comment could be more helpful if it provided more detailed guidance on how to implement these additional tasks or suggested specific tasks that would be particularly relevant. Overall, the comment is 4, as it offers clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the paper is low because the authors use stagewise and progressive training, which have been widely used in the past. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks concrete guidance on how the authors might enhance the novelty of their work. Without explicit or implicit actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the paper is low because stagewise and progressive training have been used for a long time and are widely applied. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint where the issue lies and how to address it. Additionally, the comment does not provide specific suggestions or examples to improve the novelty of the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is low because stagewise and progressive training have been used for a long time and are widely applied. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, suggesting that the use of stagewise and progressive training, which are wellestablished techniques, does not demonstrate any new or unique contributions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed examples, the authors may find it challenging to improve their draft based on this critique. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the generalizability of the analysis to more general cases, specifically mentioning Markov chains, FFN, and nonlinearity. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or extend their analysis. The comment lacks concrete guidance on what actions the authors should take to address these concerns, leaving them without a clear path forward. As a result, the comment is 1 because it does not offer actionable steps for the authors to take to improve their draft. Therefore, it aligns with a score of 1.", "grounding_specificity_rationale": "The comment raises questions about the generalizability of the analysis to more general cases, specifically mentioning Markov chains, FFN, and nonlinearity. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact section or aspect being addressed. The comment is 1 because it lacks specific references to parts of the paper. It is also not specific as it does not detail what needs to be addressed or how the analysis should be extended. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the generalizability of the analysis to more general cases, specifically mentioning Markov chains, FFN, and nonlinearity. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support its points. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the generalizability of the analysis to more general cases, specifically mentioning Markov chains, FFN, and nonlinearity. This feedback highlights potential areas for improvement and suggests that the analysis could be extended to handle more complex scenarios. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or what additional experiments or analyses could be conducted to explore these extensions. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors discuss [19] in section 3.1, specifically noting that it is not clear if [19] uses the same Fine state automaton or if there is a difference. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The action is implicit, as the authors would need to infer that they should clarify the discussion of [19] in section 3.1 and address the question about the Fine state automaton. The action is vague because it does not specify how to clarify the discussion or what specific aspects of the discussion need to be addressed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors should clarify whether [19] uses the same Fine state automaton or if there is a difference. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the discussion regarding the use of the same Fine state automaton in relation to [19]. It does not contain a subjective claim or suggestion but rather points out a lack of clarity in the paper. The comment is factual and requires no additional evidence or reasoning to be understood. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the discussion of [19] in section 3.1. It highlights that it is not clear whether [19] uses the same Fine state automaton as the authors or if there is a difference. This feedback is 3 as it points out a potential area of ambiguity that the authors should clarify. However, the comment does not provide specific guidance on how to address this issue or what changes might be necessary. The lack of actionable suggestions limits the comment\"s impact on guiding the authors towards improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the memory requirements of the auto_weight scheme in Algorithm 1, specifically mentioning the need for intermediate gradients for each domain. It provides references to two papers, [1] FedGP: Bufferbased Gradient Projection for Continual Federated Learning. Dai et al. 2023, and [2] FLamby: Datasets and Benchmarks for CrossSilo Federated Learning in Realistic Healthcare Settings. Terrail et al. 2022, which suggests that the memory requirements might be a concern. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to mitigate it. The action is implicit, as the authors need to infer that they should consider the memory requirements and potentially explore alternative approaches. The comment is 3 because it identifies a potential issue but lacks concrete guidance on how to address it. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the auto_weight scheme requires intermediate gradients for each domain, which might lead to high memory usage. The comment provides references to two relevant papers, [1] FedGP: Bufferbased Gradient Projection for Continual Federated Learning. Dai et al. 2023, and [2] FLamby: Datasets and Benchmarks for CrossSilo Federated Learning in Realistic Healthcare Settings. Terrail et al. 2022, which further supports the claim by providing context and examples. This level of detail makes the comment specific and helpful for the authors to understand the issue and its implications. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the auto_weight scheme in Algorithm 1 requires intermediate gradients for each domain, which might necessitate a significant amount of memory. It provides references to two papers, [1] FedGP: Bufferbased Gradient Projection for Continual Federated Learning. Dai et al. 2023, and [2] FLamby: Datasets and Benchmarks for CrossSilo Federated Learning in Realistic Healthcare Settings. Terrail et al. 2022, which are relevant to the issue of memory requirements in federated learning. The references support the claim by highlighting the importance of managing gradients in these contexts. However, the comment could be more verifiable by explicitly explaining how the memory requirements might be a concern or by providing additional context or examples. Overall, the claim is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the memory requirements of the auto_weight scheme in Algorithm 1, specifically noting that it requires intermediate gradients for each domain. This could lead to significant memory usage, which is a valid concern. The comment provides references to two relevant papers, [1] FedGP: Bufferbased Gradient Projection for Continual Federated Learning. Dai et al. 2023, and [2] FLamby: Datasets and Benchmarks for CrossSilo Federated Learning in Realistic Healthcare Settings. Terrail et al. 2022, which further supports the claim by highlighting the importance of managing gradients in federated learning. However, the comment could be more helpful by offering specific suggestions or guidance on how the authors might address the memory issue, such as exploring alternative approaches or optimizing the algorithm. While it identifies a problem, it lacks detailed actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the backbone is constrained to a double LSTM and does not include popular transformers. It also mentions that the application of the method to more extensive model structures remains a concern, although this is noted in Section 6. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific changes they should make to their draft. The action is implicit and vague, as it does not specify how the authors can improve their work to include transformers or explore more extensive model structures. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper by mentioning the backbone being constrained to a double LSTM and the absence of popular transformers. It also notes that the application of the method to more extensive model structures remains a concern, although this is mentioned in Section 6. However, the comment does not provide specific guidance on what needs to be addressed or how the authors should improve their draft to include transformers or explore more extensive model structures. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in identifying the issue with the backbone and the lack of exploration of more extensive model structures, but it lacks actionable guidance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the backbone is constrained to a double LSTM and does not include popular transformers, which is a valid observation. However, the comment lacks specific examples or references to support this claim, making it 3. The authors are informed about a limitation in their approach but are not provided with detailed reasoning or evidence to substantiate the claim. This lack of detailed justification makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically that the backbone is constrained to a double LSTM and does not include popular transformers. It also notes that the application of the method to more extensive model structures remains a concern, although this is mentioned in Section 6. However, the comment does not provide specific guidance or suggestions on how the authors might address these limitations or incorporate transformers into their work. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the contribution and novelty of the paper are limited, as the model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for model parameter learning. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty or contribution of the paper. Without actionable feedback, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the contribution and novelty of the paper are limited, as the model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for model parameter learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in detailing the combination of existing techniques, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution and novelty of the paper are limited, as the model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for model parameter learning. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s contribution and novelty, suggesting that the model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, along with variational inference for model parameter learning. While this feedback highlights a specific area for improvement, it lacks actionable guidance or suggestions on how the authors might address this limitation. Without concrete recommendations or examples of how to enhance the novelty or contribution of the paper, the authors may find it challenging to incorporate these insights into their work. Therefore, the comment is 3, as it points out a potential issue but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of knowing unimodal optimal learning rates in advance for the MSLR method. It suggests an alternative approach of directly tuning a latefusion model with separate learning rates for each modality, especially considering a similar or less compute budget. However, the comment does not provide explicit guidance on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should explore this alternative approach and compare it with the current method. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MSLR\" and \"latefusion model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for comparison, asking the authors to consider how the MSLR method compares to directly tuning a latefusion model with separate learning rates for each modality, especially with a similar or less compute budget. This provides a concrete direction for the authors to enhance their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of knowing unimodal optimal learning rates in advance for the MSLR method, suggesting an alternative approach of directly tuning a latefusion model with separate learning rates for each modality. While the comment does not provide specific evidence or references to support the claim, it offers a logical reasoning based on the current method\"s requirements. However, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of knowing unimodal optimal learning rates in advance for the MSLR method. It suggests an alternative approach of directly tuning a latefusion model with separate learning rates for each modality, especially considering a similar or less compute budget. This feedback is valuable as it prompts the authors to explore and compare different tuning strategies, potentially leading to more efficient and effective model training. However, the comment could be more helpful if it provided specific guidance on how to implement this comparison or what aspects of the model to focus on. Overall, the comment is 3, as it identifies an area for improvement and offers a direction for further exploration, but it lacks detailed actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind representing the input using 8 bits, suggesting that 8bit batch normalization has been proposed before in the literature, which could undermine the novelty of the work. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their work. It lacks concrete actions or detailed feedback on how to revise the paper to address the concern about novelty. As a result, the authors are left without clear direction on how to respond to this critique, making the comment 1.", "grounding_specificity_rationale": "The comment questions the rationale behind representing the input using 8 bits, suggesting that 8bit batch normalization has been proposed before in the literature, which could undermine the novelty of the work. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. While the comment is specific in its critique regarding novelty, the lack of grounding makes it challenging for the authors to understand where to focus their response. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind representing the input using 8 bits, suggesting that 8bit batch normalization has been proposed before in the literature, which could undermine the novelty of the work. The comment provides a specific reference to a paper (https://arxiv.org/pdf/1805.11046.pdf) that discusses 8bit batch normalization, offering a basis for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the cited work to fully understand the implications of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the work, specifically questioning the rationale behind representing the input using 8 bits, given that 8bit batch normalization has been previously proposed in the literature. This critique is important as it challenges the authors to justify their approach and address potential overlaps with existing work. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it identifies a potential weakness, it does not provide actionable steps or insights for improvement, making it 3. The authors would need to conduct further research and engage with the cited literature to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the practical relevance of the proposed framework given the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the framework\"s practical relevance or how they could better position it within the context of GNNs. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the practical relevance of the proposed framework given the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this concern pertains to, such as a particular section, table, or figure. The authors cannot confidently determine which aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue of practical relevance, but it lacks detailed guidance on how to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concern about the practical relevance of the proposed framework given the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practical relevance of the proposed framework in light of the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. This feedback highlights a potential gap in the paper\"s positioning and suggests that the authors may need to better articulate the framework\"s practical applications or relevance. However, the comment lacks specific guidance or suggestions on how the authors might address this issue. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it identifies a relevant concern but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of including $X$ in the calculation of $M_t$ and suggests that an experiment should be added to demonstrate this. While the comment implies that the authors should conduct an additional experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to conduct the experiment or what results to expect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of including $X$ in the calculation of $M_t$ and suggests that an experiment should be added to demonstrate this. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. The authors may infer that this relates to the methodology or experimental setup, but without explicit mention, they cannot confidently determine the exact area to address. The comment is specific in its suggestion to add an experiment, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the necessity of including $X$ in the calculation of $M_t$ and suggests that an experiment should be added to demonstrate this. However, it does not provide any specific reasoning, examples, or references to support why this experiment is necessary or how it would demonstrate the necessity of $X$. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of including $X$ in the calculation of $M_t$ and suggests that an additional experiment should be added to demonstrate this. While the comment identifies a potential area for improvement in the experimental design, it lacks specific guidance on how to conduct the experiment or what results would be expected. This feedback is 3 as it points out a potential weakness in the methodology, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the complexity of problems involving MLPs is not surprising compared to those involving FBDDs and perceptrons. However, it does not provide any specific action or suggestion for the authors to improve their draft. Without explicit guidance on what needs to be addressed or how to enhance the paper, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It makes a general statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons, but it does not provide any specific details or references to the sections or parts of the paper that need attention. Therefore, the comment is 1 and does not specify what needs to be addressed, making it unspecific. This aligns with a score of 1 and Not Specific.", "verifiability_rationale": "The review point expresses an opinion that the complexity of problems involving MLPs is not surprising compared to those involving FBDDs and perceptrons. However, it lacks any supporting evidence, reasoning, or references to substantiate this claim. Without any justification or examples, the authors are left without a basis to understand or address the comment. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the complexity of problems involving MLPs is not surprising compared to those involving FBDDs and perceptrons. However, it does not provide any specific feedback or suggestions on how this observation might impact the paper or what improvements could be made. The comment lacks actionable insights and does not offer any guidance on how the authors might address this point. As a result, it is not helpful to the authors in enhancing their draft. Therefore, the comment aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should discuss the generalizability of their observations, particularly those in Figure 4. It provides examples of various hyperparameters that could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and learning stages. However, the comment does not explicitly instruct the authors on how to discuss the generalizability or what specific aspects of the discussion should be included. While the suggestion is clear, it lacks concrete guidance on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests discussing the generalizability of observations, particularly those in Figure 4, and provides examples of various hyperparameters that could influence implicit biases in the algorithm. However, it does not specify which part of the paper Figure 4 is located in, making it weakly grounded. The comment is specific in its suggestion to discuss the generalizability of the observations, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the generalizability of their observations, particularly those in Figure 4, and provides examples of various hyperparameters that could influence implicit biases in the algorithm. However, the comment lacks specific examples or references to support the claim that these hyperparameters could indeed influence the observations. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment provides a helpful suggestion for improving the paper by discussing the generalizability of the observations, particularly those in Figure 4. It highlights the potential influence of various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, on implicit biases in the algorithm. This feedback is valuable as it encourages the authors to consider the broader implications of their findings and to explore how different hyperparameters might affect the results. However, the comment could be more helpful if it provided specific guidance on how to discuss the generalizability or included examples of how to analyze the impact of these hyperparameters. Overall, the comment is 3, as it offers a clear direction for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper is not wellorganized and uses nonstandard terminology, specifically mentioning the term \"semihonst\" in section 4. It suggests that the authors should use \"honestbutcurious\" instead. While the comment identifies a specific issue and provides a suggestion, it does not explicitly instruct the authors on how to address the organization or terminology issues. The action is implicit, as the authors need to infer that they should reorganize the paper and replace the terminology. However, the comment lacks concrete guidance on how to improve the organization or terminology, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of using nonstandard terminology and provides a concrete example of the term \"semihonst\" and suggests an alternative term, \"honestbutcurious.\" This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and uses nonstandard terminology, specifically mentioning the term \"semihonst\" in section 4. It suggests that the authors should use \"honestbutcurious\" instead. While the comment identifies a specific issue and provides a suggestion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the basis for the claim, which could be challenging. Therefore, the comment is 3, as it provides a basis for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not wellorganized and uses nonstandard terminology, specifically mentioning the term \"semihonst\" in section 4. It suggests that the authors should use \"honestbutcurious\" instead. This feedback is clear and actionable, providing the authors with a specific area to improve the organization and terminology of their paper. However, the comment could be more helpful if it offered additional guidance on how to reorganize the paper or suggested alternative terms beyond \"honestbutcurious.\" Overall, the comment is 4 as it highlights important areas for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several missing details in the experimental section, specifically asking for the optimizer, initialization, and PPOzero. While the comment identifies the areas where information is lacking, it does not provide explicit guidance on how the authors should address these omissions. The authors are left to infer that they need to include these details in their draft, but the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental details that are missing, such as the optimizer, initialization, and PPOzero. This allows the authors to accurately identify the parts of the paper where these details are lacking. The comment is also specific because it clearly specifies what information is missing, guiding the authors on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights missing experimental details, such as the optimizer, initialization, and PPOzero. However, it does not provide any reasoning, examples, or references to support why these details are important or how their omission affects the paper. Without additional context or justification, the authors may find it challenging to understand the significance of the missing information. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several missing experimental details, including the optimizer, initialization, and PPOzero. This feedback is specific and actionable, as it directs the authors to include these crucial details in their draft. By providing clear examples of what is missing, the comment helps the authors improve the completeness and clarity of their experimental section. However, the comment could be more helpful if it suggested specific ways to include or address these details, such as recommending particular methods or sources for initialization. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the efficiency and complexity of the proposed method, specifically mentioning the use of two image encoders (LaVIT and EvaCLIP) and a detector in the decoding process. It suggests that other existing works do not require such additional components and implies that a detailed comparison of efficiency metrics, such as total model parameters, FLOPs, and memory usage, is needed. While the comment identifies a potential issue and suggests a comparison, it does not provide explicit guidance on how to conduct this comparison or what specific aspects should be analyzed. The action is implicit and somewhat vague, as the authors need to infer the need for a detailed comparison and understand the specific metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the efficiency and complexity of the proposed method, specifically mentioning the use of two image encoders (LaVIT and EvaCLIP) and a detector in the decoding process. It suggests that other existing works do not require such additional components and implies the need for a detailed comparison of efficiency metrics, including total model parameters, FLOPs, and memory usage. However, the comment does not specify which part of the paper discusses the method or the results that need to be compared. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in its suggestion for a detailed comparison, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires two image encoders and a detector, which is more complex than other existing works. It suggests that a detailed comparison of efficiency metrics, such as total model parameters, FLOPs, and memory usage, is needed to justify the complexity. However, the comment lacks specific examples or references to support the claim about the complexity of other existing works or the need for a detailed comparison. Without concrete evidence or detailed reasoning, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the use of two image encoders and a detector, which may increase the complexity and require a detailed efficiency analysis. It suggests that other existing works do not require such additional components, implying that a comparison of efficiency metrics, such as total model parameters, FLOPs, and memory usage, is necessary. This feedback is 3 as it points out a potential area for improvement and highlights the need for a detailed comparison. However, the comment could be more helpful if it provided specific guidance on which aspects of the efficiency analysis should be included or suggested alternative approaches to address the complexity. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of evidence to support the claim that extrapolation error is a major issue in MARL, and it questions the relevance of the proposed techniques to this issue. However, it does not provide explicit guidance on how the authors should address this concern or what evidence they should include to substantiate their claim. The comment is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of extrapolation error in MARL and the lack of evidence supporting the claim. It also specifies the two proposed techniques and their relevance to bias/variance reduction, questioning their connection to mitigating extrapolation error. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks evidence to support the assertion that extrapolation error is a major issue in MARL. It also questions the relevance of the proposed techniques to this issue, suggesting that they are for bias/variance reduction rather than directly addressing extrapolation error. However, the comment does not provide specific examples or references to substantiate these claims, making it difficult for the authors to verify the validity of the critique. The lack of detailed evidence or reasoning weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of evidence to support the claim that extrapolation error is a major problem in MARL. It also questions the relevance of the proposed techniques to this issue, suggesting that they are more focused on bias and variance reduction. This feedback is valuable as it highlights a critical gap in the paper\"s argumentation and provides a clear direction for the authors to address. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might strengthen their claims or provide evidence to support their argument. Overall, the comment is 4, as it points out a crucial area for improvement but could be more comprehensive with actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that while SCHEME demonstrates theoretical complexity advantages, its ondevice efficiency is underexploited. It points out that only limited throughput comparisons are presented in Tables 4 and 8. The comment suggests that including detailed ondevice results across ablation and comparison studies would substantiate claims about SCHEME\u2019s efficiency over conventional FFNs. It also emphasizes the need for details on the benchmark configurations, hardware, and input shapes to ensure fair comparisons. The comment provides explicit guidance on what additional information and results are needed to strengthen the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SCHEME\" and refers to \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of underexplored ondevice efficiency and suggests including detailed ondevice results across ablation and comparison studies to substantiate claims. Additionally, it requests details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that SCHEME shows theoretical complexity advantages but lacks detailed ondevice efficiency comparisons. It suggests that including detailed ondevice results across ablation and comparison studies would substantiate claims about SCHEME\u2019s efficiency over conventional FFNs. The comment also emphasizes the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is 4 as it provides a clear rationale for the need for additional information and results, but it could be strengthened by including specific examples or references to support the claim. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while SCHEME demonstrates theoretical complexity advantages, its ondevice efficiency is underexplored. It points out that only limited throughput comparisons are presented in Tables 4 and 8, and suggests that including detailed ondevice results across ablation and comparison studies would substantiate claims about SCHEME\u2019s efficiency over conventional FFNs. Additionally, the comment emphasizes the need for details on the benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is 4 as it provides clear and actionable suggestions for improving the paper by addressing the underexplored aspect of ondevice efficiency and ensuring fair comparisons. However, it could be more comprehensive if it included specific examples or references to support the claims. Overall, the comment offers valuable guidance for the authors to enhance the depth and rigor of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" because it might be misleading due to its similarity to Long Short Term Memory (LSTM). However, the comment does not provide any explicit or implicit guidance on how the authors should reconsider the name or what alternative names might be more appropriate. It lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its similarity to Long Short Term Memory (LSTM). However, it does not specify which part of the paper this comment is related to, such as a section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting that the name might be misleading, but it does not provide detailed guidance on how to reconsider the name or what alternative names might be more appropriate. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" because it might be misleading due to its similarity to Long Short Term Memory (LSTM). However, the comment lacks specific reasoning or examples to support why this similarity could be problematic. It does not provide any references or detailed explanations to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" because it might be misleading due to its similarity to Long Short Term Memory (LSTM). This feedback is 3 as it identifies a potential issue with the naming of the strategy, which could lead to confusion or misinterpretation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might reconsider the name or what alternative names could be more appropriate. Without actionable advice or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the proposed method is not the best performer in terms of robustness and fidelity, based on the experiments results. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve their method or what specific changes could be made to enhance its performance. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the experiments results are referring to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it identifies a problem with the proposed method, noting that it is not the best performer in terms of robustness and fidelity. However, without grounding, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments results show the proposed method is not the best performer in terms of robustness and fidelity. However, the comment lacks specific details or references to support this claim. Without additional information or evidence, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments results, noting that the proposed method is not the best performer in terms of robustness and fidelity. While this feedback highlights a potential weakness in the method\"s performance, it does not provide any suggestions or guidance on how the authors might address this issue or improve their method. The comment lacks actionable advice, leaving the authors without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a problem but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the motivation and logical connection between three key concepts: isometry, OT (optimal transport), and disentanglement. The authors claim that adding geometrical constraints (isometry) can help disentanglement, but this connection is not wellexplained, making it difficult for the reader to understand how disentanglement relates to isometry. Additionally, the review points out that the necessity of OT for isometry is not clear, suggesting that the authors should provide a more detailed explanation of these connections. The comment implies that the authors should clarify these connections, but it does not specify how to do so, leaving the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the motivation and logical connection between three key concepts: isometry, OT (optimal transport), and disentanglement. It highlights that the paper does not adequately explain how isometry can help disentanglement, making it difficult for readers to understand the connection. The comment also questions the necessity of OT for isometry, suggesting that the authors should clarify these connections. However, the comment does not specify which part of the paper discusses these concepts or where the explanation of the connections is lacking. This makes it challenging for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation and logical connection between isometry, OT, and disentanglement are not clear, and the paper does not adequately explain how isometry can help disentanglement or why OT is required for isometry. The reviewer suggests that the authors should provide a more detailed explanation of these connections. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the motivation and logical connections between key concepts in the paper, specifically isometry, OT (optimal transport), and disentanglement. It highlights that the paper does not adequately explain how isometry can help disentanglement or why OT is required for isometry, making it difficult for readers to understand the connections. The reviewer suggests that the authors should provide a more detailed explanation of these connections to improve the clarity and coherence of the paper. This feedback is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance their draft. However, it could be more helpful if it included specific suggestions or examples to guide the authors in improving the explanation of these connections. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the relevance of the results on regular languages to explaining how and why realworld language models work. While it identifies a potential gap in the paper, it does not provide explicit guidance on how to address this issue or what specific aspects of the results need to be clarified. The action is implicit, as the authors would need to infer that they should discuss the connection between regular languages and realworld language models. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the relevance of the results on regular languages to explaining how and why realworld language models work. However, it does not specify which part of the paper discusses these results or how they are presented. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the relevance of the results, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of the results on regular languages to explaining how and why realworld language models work. While it raises a valid concern about the connection between these two areas, it does not provide specific examples, references, or detailed reasoning to support the claim. The comment lacks depth and specificity, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the relevance of the results on regular languages to explaining how and why realworld language models work. This is a valuable point that could help the authors better contextualize their findings and enhance the overall impact of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples or discussing potential connections. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the novelty of the paper in relation to the Venom paper [1]. It asks whether the differences between the two papers are clear and whether the V:N:M model was proposed in the Venom paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or clarify the differences. The action is implicit, as the authors need to infer that they should compare their work with the Venom paper and clarify the novelty. The action is vague because it does not specify how to compare the papers or what aspects of the differences need to be addressed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M model was proposed in the Venom paper. However, it does not specify which part of the paper this comparison should be made or which sections are relevant. The authors cannot confidently determine which part of the paper the comment addresses, making it weakly grounded. The comment is specific in that it asks for clarification on the differences between the two papers, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M model was proposed in the Venom paper. However, it does not provide any evidence, reasoning, or references to support the claim that the V:N:M model was proposed in the Venom paper. Without additional context or justification, the authors are left to make their own judgments, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M model was proposed in the Venom paper. This question highlights a potential area of confusion or lack of clarity for the authors, as it challenges them to compare their work with a specific existing paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the differences between their work and the Venom paper. Without actionable advice or additional context, the authors may struggle to understand how to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about the qualitative intuitiveness of the attribution maps in Figure 2. It highlights specific issues with the attended areas not aligning with the task, such as the 3D worth pixels not being attended in 3D tasks, and the presence of clusters of attended pixels without clear semantic meaning. The reviewer acknowledges that the analysis using these maps is quantitative and works, but questions the qualitative value. However, the comment does not provide explicit or implicit suggestions on how to address these issues or improve the clarity of the attribution maps. The authors are left without guidance on how to enhance the qualitative understanding of the maps, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the attribution maps, such as the attended areas not aligning with the task and the presence of clusters without clear semantic meaning. The comment also acknowledges the quantitative value of the analysis but questions the qualitative value, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the qualitative intuitiveness of the attribution maps in Figure 2, specifically questioning whether the attended areas align with the actual task. It provides examples, such as the 3D worth pixels not being attended in 3D tasks, and the presence of clusters of attended pixels without clear semantic meaning. However, the comment does not offer any specific examples or references to support the claim that the attribution maps are not qualitatively intuitive. Without detailed reasoning or evidence, the claim remains 3, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the attribution maps in Figure 2, noting that the attended areas do not seem to align with the actual task, such as the 3D worth pixels not being attended in 3D tasks. It also points out the presence of clusters of attended pixels without clear semantic meaning. While the comment acknowledges that the analysis using these maps is quantitative and works, it questions the qualitative value of the attribution maps. This feedback is 3 as it highlights a potential area for improvement in the clarity and interpretability of the attribution maps. However, it could be more helpful if it provided suggestions on how to address these issues or improve the qualitative understanding of the maps. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title overclaims the contribution of the paper, as it does not include results from large language models like Llama270b, which are mentioned in the text. The comment implies that the authors should consider adding these results to the title for accuracy. It also suggests that the authors should ensure consistency in the term used for RoBERTa throughout the paper. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the title and ensure consistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue with the title, noting that it overclaims the contribution by not including results from large language models like Llama270b, which are mentioned in the text. The comment requests empirical justification for the scalability of the proposed method to LLMs, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the title overclaiming the contribution of the paper, specifically noting the absence of results from large language models like Llama270b. The comment suggests that the authors should consider adding these results to the title for accuracy. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for additional results to address the concern, which limits the claim\"s verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the title of the paper, suggesting that it overclaims the contribution by not including results from large language models like Llama270b. The comment requests empirical justification for the scalability of the proposed method to these models, which is a valuable suggestion for improving the paper. However, the comment could be more helpful by providing specific examples or guidance on how to demonstrate the scalability. Additionally, the minor comment about the consistency of the term \u201cROBERTA\u201d is also noted but could be expanded upon. Overall, the comment is 4 as it highlights an important area for improvement and provides a clear direction for the authors to follow, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of motivation for choosing date and country as spurious correlating variables with gender, beyond the speculation that they could show spurious correlations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their motivation. The comment lacks concrete guidance on what specific aspects of the motivation need to be clarified or expanded upon. As a result, the authors are left without a clear understanding of how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for choosing date and country as spurious correlating variables with gender, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the need for a stronger motivation for the choice of variables. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not provide a particular motivation for choosing date and country as spurious correlating variables with gender, beyond speculation. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as it is based on an assumption rather than a wellsupported argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks motivation, namely the choice of date and country as spurious correlating variables with gender. It points out that the paper speculates on the possibility of spurious correlations but does not provide a clear rationale for this choice. This feedback is 3 as it highlights a potential weakness in the paper\"s argumentation, but it lacks depth and does not offer specific suggestions on how the authors might address this issue or strengthen their motivation. The comment could be more helpful if it provided guidance on how to develop a stronger motivation or alternative justifications for the chosen variables. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises concerns about the novelty of the contribution, specifically questioning whether exchanging channels is an incremental advancement. It also critiques the rationale of Theorem 1, suggesting that it is based on existing work and appears to be a simple fact. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the novelty of the contribution, specifically questioning whether exchanging channels is an incremental advancement. It also critiques the rationale of Theorem 1, suggesting that it is based on existing work and appears to be a simple fact. However, the comment does not specify which part of the paper discusses exchanging channels or Theorem 1, making it difficult for the authors to pinpoint the exact areas that need attention. The lack of specific references or sections limits the authors\" ability to address the feedback effectively. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the novelty of the contribution, specifically questioning whether exchanging channels is an incremental advancement. It also critiques the rationale of Theorem 1, suggesting that it is based on existing work and appears to be a simple fact. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without clear evidence or justification, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the novelty of the contribution, specifically questioning whether exchanging channels is an incremental advancement. It also critiques the rationale of Theorem 1, suggesting that it is based on existing work and appears to be a simple fact. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. It does not provide actionable feedback or detailed insights into what aspects of the paper need revision. As a result, the comment is 2, as it identifies potential issues but does not offer a clear path for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the depth of studies needed to establish the contribution of the work, particularly in relation to secondorder methods. It also asks for clarification on the meaning of K, specifically whether it denotes firstorder or secondorder methods (K=NC). While the comment provides a clear question for clarification, it does not offer explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the depth of studies needed to establish the contribution of the work, particularly in relation to secondorder methods. It also asks for clarification on the meaning of K, specifically whether it denotes firstorder or secondorder methods (K=NC). However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. While the question is specific about the need for indepth studies, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the depth of studies needed to establish the contribution of the work, particularly in relation to secondorder methods. It also asks for clarification on the meaning of K, specifically whether it denotes firstorder or secondorder methods (K=NC). While the comment is based on logical reasoning and common knowledge about the need for thorough analysis in research, it lacks specific examples or references to support the claim that more indepth studies are necessary. The question about the meaning of K is clear and specific, but the overall comment is 3 due to the lack of detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the depth of studies needed to establish the contribution of the work, particularly in relation to secondorder methods. It also asks for clarification on the meaning of K, specifically whether it denotes firstorder or secondorder methods (K=NC). While the comment identifies a potential area for improvement in the depth of analysis, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a need for more indepth studies, but it does not provide detailed advice or examples to help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically mentioning the impact of these parameters on the running time. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be analyzed. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests an indepth analysis of the parameters k and N in the ablation study, which could enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, particularly the impact of these parameters on the running time. However, the comment does not specify which part of the paper this analysis should be conducted on, making it weakly grounded. The comment is specific in suggesting what analysis should be performed, but the lack of grounding makes it difficult for the authors to know exactly where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, particularly the impact of these parameters on the running time. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically mentioning the impact of these parameters on the running time. However, the comment lacks specific guidance on how to conduct this analysis or what aspects should be analyzed, making it 3. The feedback provides a direction for improvement but does not offer detailed suggestions or examples, which could be more beneficial for the authors. Therefore, the comment aligns with a score of 3, as it identifies areas for enhancement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific questions about the details in Appendix B, which state that results are averaged over 10 runs. The first question asks why there is no indication of standard deviation, and the second question seeks clarification on whether the 10 runs were conducted with random hyperparameter configurations for all baselines or with the best selected hyperparameter values. These questions are explicit and direct, providing clear guidance for the authors to address the missing information and clarify the experimental setup. The actions are concrete, as the authors know exactly what needs to be added or clarified in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing or needs clarification, namely the absence of standard deviation and the details of the 10 runs, including whether they were conducted with random hyperparameter configurations or the best selected values. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the details in Appendix B, specifically regarding the averaging of results over 10 runs and the absence of standard deviation. While the comment does not contain subjective opinions or claims, it points out a potential issue with the clarity and completeness of the information presented. However, it lacks specific examples or references to support the claim that the absence of standard deviation or the details of the 10 runs is a significant oversight. Without additional context or justification, the claim is considered 2, as it highlights an area that could be improved but does not provide a clear basis for action.", "helpfulness_rationale": "The review comment identifies specific areas where the authors could improve their draft by providing additional details. It questions the absence of standard deviation in the results presented in Appendix B and asks for clarification on the experimental setup, specifically whether the 10 runs were conducted with random hyperparameter configurations or the best selected values. This feedback is clear and actionable, as it directs the authors to add crucial information that would enhance the transparency and reproducibility of their results. By addressing these points, the authors can significantly improve the clarity and completeness of their paper, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that more details about the task generation process should be included in the main text, rather than in the appendix. This provides a clear and explicit action for the authors to take, which is to move the relevant details from the appendix to the main text. The comment is specific in its suggestion, detailing exactly where the information should be placed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more details about the task generation process should be included in the main text, rather than in the appendix. This provides a clear indication of which part of the paper the authors should focus on, making the comment fully grounded. Additionally, it specifies what needs to be addressed, namely the inclusion of task generation details in the main text. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that more details about the task generation process should be included in the main text, rather than in the appendix. This claim is 3 as it implies that the current presentation of the task generation process is insufficient for readers to fully understand the experimental setup. However, the comment lacks specific examples or references to support why the task generation process is critical for understanding the paper. Without additional context or evidence, the authors may find it challenging to fully grasp the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that more details about the task generation process be included in the main text instead of the appendix. This is a specific and helpful feedback that would enhance the clarity and comprehensiveness of the paper, allowing readers to better understand the experimental setup. By addressing this suggestion, the authors can significantly strengthen the presentation of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests a way to connect tokens beyond local windows by forming new groups across previous local windows. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes need to be made to the draft. The action is implicit, as the authors can infer that they need to explore and potentially implement this idea, but the lack of concrete details makes it difficult to know exactly how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a way to connect tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. Additionally, the comment lacks specificity in explaining how this connection should be made or what benefits it might provide. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests a way to connect tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it could be implemented. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a way to connect tokens beyond local windows by forming new groups across previous local windows. However, it lacks specific details or examples, making it difficult for the authors to understand how to implement this suggestion or what benefits it might offer. The comment is vague and does not provide actionable guidance, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO) risk, specifically noting the use of entropy as a distance metric. It suggests that the authors should provide a more comprehensive illustration of the advantages of this specific distance metric compared to others used in DRO, such as $f$divergence, Wasserstein distance, and MMD distance. The comment implies that the authors should elaborate on why this specific metric leads to better generalization performance. However, the action is implicit, as the authors need to infer that they should provide a more detailed explanation and comparison. The suggestion is concrete, but the lack of explicit guidance on how to implement it makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO) risk, specifically highlighting the use of entropy as a distance metric. It suggests that the authors should provide a more comprehensive illustration of the advantages of this specific distance metric compared to others used in DRO, such as $f$divergence, Wasserstein distance, and MMD distance. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it provides clear guidance on what needs to be addressed, namely the advantages of the specific distance metric. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO) risk, specifically noting the use of entropy as a distance metric. It suggests that the authors should provide a more comprehensive illustration of the advantages of this specific distance metric compared to others used in DRO, such as $f$divergence, Wasserstein distance, and MMD distance. The comment implies that the authors should elaborate on why this specific metric leads to better generalization performance. However, the claim lacks specific examples or detailed reasoning to fully substantiate the suggestion, making it 3. The comment provides a logical basis for the suggestion but could benefit from additional evidence or references to support the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO) risk. It highlights the use of entropy as a distance metric and suggests that the authors provide a more comprehensive illustration of the advantages of this specific metric compared to others used in DRO, such as $f$divergence, Wasserstein distance, and MMD distance. The comment is 4 as it provides a clear direction for the authors to enhance their work by expanding on the rationale behind their choice of distance metric. However, it could be more helpful if it included specific examples or references to support the claim, which would further guide the authors in their revisions. Overall, the feedback is valuable and actionable, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the nature of the TREx dataset, specifically whether it is distantly supervised with no human labels. It then suggests evaluating the model over annotated datasets like TACRED or FewRel. While the comment implies that the authors should consider evaluating their model on annotated datasets, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should evaluate their model on annotated datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the nature of the TREx dataset, specifically whether it is distantly supervised with no human labels. It then suggests evaluating the model over annotated datasets like TACRED or FewRel. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to evaluate the model on annotated datasets, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the nature of the TREx dataset and suggests evaluating the model on annotated datasets like TACRED or FewRel. However, it does not provide any evidence or reasoning to support the claim that TREx is a distantly supervised dataset with no human labels. The suggestion to evaluate on annotated datasets is a reasonable suggestion for improvement but lacks specific justification or examples. Therefore, the comment is considered 2, as it provides some basis for the suggestion but lacks detailed support.", "helpfulness_rationale": "The review comment raises a question about the nature of the TREx dataset, specifically whether it is distantly supervised with no human labels. It then suggests evaluating the model on annotated datasets like TACRED or FewRel, which could provide a more comprehensive evaluation. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the evaluation or what aspects of the model should be considered. The suggestion is 3 as it points out a potential limitation and offers a direction for further evaluation, but it could be more actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take, such as proofreading the appendix and addressing the specific issues mentioned in the text. It also suggests that the authors should expand on the discussion of potential negative societal impacts. These actions are concrete and detailed, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the formatting of the appendix, suggesting a proofread, and points out specific issues in the text, such as the use of \"poster mean\" and \"piecewiselinear\". Additionally, it suggests expanding on the discussion of potential negative societal impacts, which is a clear and actionable recommendation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point contains claims that the appendix is not using NeurIPS 2021 style files and that it should be proofread. It also suggests that the authors should expand on the discussion of potential negative societal impacts. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3 as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the formatting of the appendix, noting that it does not adhere to the NeurIPS 2021 style files. It suggests proofreading the appendix, which is a clear and actionable step for the authors to take. Additionally, the comment points out specific instances in the text, such as the use of \"poster mean\" and \"piecewiselinear,\" which could be improved for clarity. The suggestion to expand on the discussion of potential negative societal impacts is also valuable, as it highlights an area where the authors could enhance their analysis. Overall, the comment offers clear and constructive feedback that guides the authors in improving their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include training and validation curves for different losses and ask if the model can simultaneously minimize these losses. It also inquires about tricks related to weighing these losses. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to generate or analyze these curves. The action is implicit, as the authors can infer that they need to include these elements in their draft. However, the comment lacks concrete guidance on how to generate or analyze the curves, making it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests including training and validation curves for different losses and asks if the model can simultaneously minimize these losses. It also inquires about tricks related to weighing these losses. However, the comment does not specify which part of the paper these curves or discussions should be included in, nor does it provide any guidance on how to generate or analyze them. The authors cannot confidently determine which section or part of the paper this comment addresses, making it weakly grounded. Additionally, while the comment is specific in its request for information, it lacks detailed guidance on how to incorporate this information into the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including training and validation curves for different losses and asks if the model can simultaneously minimize these losses, along with inquiries about tricks related to weighing these losses. However, the comment does not provide any specific reasoning, examples, or references to support why these suggestions are beneficial or how they would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including training and validation curves for different losses, which could provide valuable insights into the model\"s performance and stability. It also asks if the model can simultaneously minimize these losses and inquires about tricks related to weighing these losses. While the comment identifies an area for improvement by suggesting the inclusion of specific visualizations and analysis, it lacks detailed guidance on how to generate or interpret these curves or how to address the question about loss balancing. The feedback is 3 as it points out a specific area for enhancement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue regarding the claim of NPhardness for computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof, merely stating that it is NPhard due to a binary constraint without providing sufficient justification. The comment also questions the validity of this claim, suggesting that it might not hold for all assignment problems and that the assumption of access to the optimal assignment matrix limits the applicability. While the comment identifies a significant gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen their argument. The feedback is 3 as it directs the authors to consider the validity of the NPhardness claim and the implications of assuming access to the optimal assignment matrix. However, it lacks detailed suggestions or concrete steps for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the NPhardness claim regarding the GOSPA metric, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the validity of the claim and suggesting that it might not hold for all assignment problems. The comment further highlights the assumption of access to the optimal assignment matrix, which limits the applicability of the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a rigorous theoretical argument or proof for the NPhardness of computing the GOSPA metric, merely stating that it is NPhard due to a binary constraint without providing sufficient justification. The comment questions the validity of this claim, suggesting that it might not hold for all assignment problems and that the assumption of access to the optimal assignment matrix limits the applicability. However, the comment does not provide specific examples or references to support the claim that the NPhardness is generally true for assignment problems. This lack of detailed reasoning or evidence makes the claim 3, as it leaves the authors with some uncertainty about the validity of the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by questioning the claim that computing the GOSPA metric is NPhard. It points out that the paper lacks a rigorous theoretical argument or proof, merely stating that it is NPhard due to a binary constraint without providing sufficient justification. The comment also questions the validity of this claim, suggesting that it might not hold for all assignment problems and that the assumption of access to the optimal assignment matrix limits the applicability. This feedback is 4 as it highlights a critical gap in the paper\"s argumentation and provides a clear direction for the authors to address the issue. However, it could be more helpful if it offered specific suggestions or guidance on how the authors might strengthen their theoretical argument or provide a more robust proof. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. This comment provides a clear and explicit action for the authors to take, which is to include an algorithmic writeup. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. Without this context, the authors may find it challenging to identify where to make the suggested improvement. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or necessary. Without additional context or justification, the authors may find it difficult to understand the basis for this recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be helpful to include an algorithmic writeup of the solution to the pricing problem. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the clarity and depth of the paper. However, the comment lacks detail on how the algorithmic writeup should be structured or what specific aspects of the pricing problem it should address. While it offers a valuable direction for improvement, the comment could be more helpful if it provided additional guidance or examples. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward, suggesting that the policy needs to explore intelligently and update gradually. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or improve their draft. The comment lacks concrete suggestions or detailed explanations, leaving the authors uncertain about how to respond. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward, suggesting that the policy needs to explore intelligently and update gradually. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or figure being addressed. While the comment is specific in its critique of the tradeoff, it lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward, suggesting that the policy needs to explore intelligently and update gradually. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward, suggesting that the policy needs to explore intelligently and update gradually. However, it does not provide specific guidance or suggestions on how to address this issue or improve the draft. The comment lacks actionable insights and detailed explanations, leaving the authors with limited understanding of how to enhance their work. As a result, the feedback is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. This provides a clear and explicit action for the authors to take, as they can directly incorporate this suggestion into their draft. The comment is specific in its suggestion, detailing what additional discussion could enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests a discussion regarding a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a discussion regarding a possible generalization with a different distribution for the size of the batches. However, it does not provide any specific reasoning, examples, or references to support why this generalization is important or how it could be discussed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by expanding on the discussion of batch sizes. However, the comment could be more helpful if it offered additional guidance on how to approach this generalization or what aspects of the discussion might be relevant. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth in its suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the analysis, noting that it only considers the case of batch size = 1 and lacks clarity on how batch size affects the effective initialization scale. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify the impact of batch size. The action is implicit and vague, as it does not specify how the authors should conduct additional analysis or what data they should include to address the concern. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis, noting that it only considers the case of batch size = 1 and lacks clarity on how batch size affects the effective initialization scale. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis only considers the case of batch size = 1 and does not clarify how batch size affects the effective initialization scale. This is a specific observation about a limitation in the analysis. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis, noting that it only considers the case of batch size = 1 and lacks clarity on how batch size affects the effective initialization scale. This feedback is clear and actionable, as it highlights a gap in the analysis that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how the authors might approach this issue or what additional data could be included to clarify the impact of batch size. Despite this, the comment offers valuable guidance for improving the draft, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the results presented in Figure 7, specifically asking why more data leads to lower results on the ImageNet linear evaluation. It provides an example, noting that sampling 50% of the data seems to yield better results than sampling 100%. However, the comment does not offer any explicit or implicit suggestions for addressing this issue or improving the results. The authors are left without guidance on how to investigate or resolve this discrepancy. Therefore, the comment is 1 as it does not provide any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment questions the results presented in Figure 7, specifically asking why more data leads to lower results on the ImageNet linear evaluation. It provides an example, noting that sampling 50% of the data seems to yield better results than sampling 100%. However, the comment does not specify which part of the paper Figure 7 is located in, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the results being questioned, it lacks grounding as it does not clearly identify the section or figure being referenced. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the results presented in Figure 7, specifically asking why more data leads to lower results on the ImageNet linear evaluation. It provides an example, noting that sampling 50% of the data seems to yield better results than sampling 100%. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation might occur. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a question about the results presented in Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. It provides an example, noting that sampling 50% of the data seems to yield better results than sampling 100%. However, the comment does not offer any suggestions or insights on how to address this issue or improve the results. It lacks actionable guidance for the authors, leaving them without a clear path to resolve the discrepancy. Therefore, the comment is 2, as it identifies a potential problem but does not provide any constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of comprehensive evaluation by the authors, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. It suggests that including FVD would enhance the paper\u2019s credibility and comparability to other video generation methods. However, the comment does not provide explicit guidance on how the authors should incorporate FVD into their evaluation or what specific steps they should take to address this issue. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of VBench as the primary evaluation benchmark and highlights the lack of quantitative results on mainstream metrics like FVD. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of limited evaluation metrics, suggesting the inclusion of FVD to enhance the paper\u2019s credibility and comparability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide quantitative results on mainstream metrics such as FVD, which is widely recognized and robust for evaluating temporal video prediction. The comment suggests that including FVD would enhance the paper\u2019s credibility and comparability to other video generation methods. However, the claim lacks specific examples or references to support the assertion that the absence of FVD results is a significant issue. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation by pointing out the lack of quantitative results on mainstream metrics like FVD. It suggests that including FVD would enhance the paper\u2019s credibility and comparability to other video generation methods. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of a widely recognized evaluation metric. However, the comment could be more helpful by offering additional suggestions or guidance on how to incorporate FVD into the evaluation process. Overall, the comment is 4, as it effectively highlights a critical area for improvement and provides a clear path for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the technical details in section 2.2 are hard to follow. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the clarity of the technical details or what specific changes could be made. Without concrete suggestions or actions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper the authors are referring to, making it difficult for them to identify the exact section or section 2.2. However, it is specific in its feedback, as it points out that the technical details in section 2.2 are hard to follow. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical details in section 2.2 are hard to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the technical details are hard to follow or how to address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the technical details in section 2.2 are hard to follow. This feedback is clear and actionable, as it highlights a potential area for improvement in the paper\"s clarity and presentation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it points out a problem, it does not offer a comprehensive solution or detailed advice on how to improve the clarity of the technical details. Therefore, the comment is 3, as it provides a clear indication of an area for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the improvements offered by EVA over backbone models like OTFlow, particularly in the context of motifcoupling on the RFDiffusion benchmark. It asks whether the addition of geometry information and motifinterpolation benefits over prior backbones. However, the comment does not provide explicit guidance or suggestions on how the authors might address these questions or what specific improvements they should consider. The action is implicit and vague, as it does not offer concrete steps or detailed feedback on how to enhance the paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Improvement over OTFlow\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the improvements offered by EVA over backbone models, particularly in the context of motifcoupling on the RFDiffusion benchmark. The comment specifies what needs to be addressed, such as the benefits of adding geometry information and motifinterpolation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the improvements offered by EVA over backbone models like OTFlow, specifically in the context of motifcoupling on the RFDiffusion benchmark. It asks whether the addition of geometry information and motifinterpolation benefits over prior backbones. However, the comment does not provide any specific evidence, reasoning, or references to support these claims. The questions posed are openended and lack detailed justification or examples, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the improvements offered by EVA over backbone models, specifically in the context of motifcoupling on the RFDiffusion benchmark. It asks whether the addition of geometry information and motifinterpolation benefits over prior backbones. However, the comment does not provide any specific suggestions or guidance on how the authors might address these questions or what improvements they should consider. While it identifies an area for further discussion, it lacks actionable feedback that would help the authors enhance their draft. Therefore, the comment is 2, as it provides limited insight and guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the presence of too many identical sentences in the Abstract, Introduction, and Conclusion. While it identifies a specific issue, it does not provide any explicit guidance or suggestions on how to address this problem. The authors are left without a clear understanding of what needs to be done to resolve the issue of identical sentences. Therefore, the comment is 1, as it lacks concrete steps or guidance for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Abstract, Introduction, and Conclusion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue of too many identical sentences, providing a clear direction for the authors to take action. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not provide any specific examples or references to support this claim. Without concrete evidence or examples, the authors may find it difficult to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, noting the presence of too many identical sentences in the Abstract, Introduction, and Conclusion. This is a clear and actionable feedback that highlights a potential redundancy in the writing. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the overall coherence of the paper. While it points out a problem, it does not offer guidance on how to resolve it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the reward function used in the ablation studies, specifically whether it is sEH. While it prompts the authors to clarify this aspect, it does not provide explicit instructions or suggestions on how to address this question or what changes might be needed. The action is implicit, as the authors need to infer that they should clarify the reward function used in the ablation studies. However, the comment lacks concrete guidance on how to implement this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact location of the information they need to address. While the comment is specific about the content of the question, it lacks grounding as it does not provide clear references or context. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. However, it does not provide any context, explanation, or references to support the claim or question. Without additional information or justification, the authors are left to interpret the question, making it difficult to understand the basis of the inquiry. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. This is a relevant and specific inquiry that could help the authors clarify a key aspect of their methodology. However, the comment lacks actionable guidance or suggestions on how the authors might address this question or what changes might be necessary. While it identifies an area for improvement, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of selfgenerated code as a fair comparison to previous work, noting that it samples the model twice for each generation. It also mentions that the placeholder code was intended to generate the code itself once. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and vague, as it does not specify how the authors should adjust their comparison or what specific aspects of their code need to be revised. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of selfgenerated code as a fair comparison to previous work, noting that it samples the model twice for each generation. It also mentions that the placeholder code was intended to generate the code itself once. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the use of selfgenerated code as a fair comparison to previous work, noting that it samples the model twice for each generation. It also mentions that the placeholder code was intended to generate the code itself once. However, the comment does not provide specific examples or references to support the claim that this approach is not fair or how it affects the comparison with previous work. The reasoning is somewhat vague and lacks detailed justification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology of using selfgenerated code for comparison with previous work. It highlights that this approach samples the model twice for each generation, which may not be a fair comparison. The comment also suggests that the use of a placeholder code was intended to generate the code itself once, implying that the current approach might be unfair. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to their draft. While it raises a valid concern, the feedback lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the paper\"s structure, suggesting that Sections 3 and 4, which feel like they should be the main contributions, are too short and lack detailed mathematical definitions. It points out that the absence of these definitions in the main text makes it difficult for the authors to follow the content. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting where to add the definitions or how to expand the sections. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Sections 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the issue of missing precise mathematical definitions for the quantum states in Eq (4), which are crucial for understanding the content. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Sections 3 and 4, which are considered main contributions, are too short and lack detailed mathematical definitions, making it difficult for the authors to follow the content. The comment provides a specific example of missing definitions for quantum states in Eq (4), which serves as evidence to support the claim. However, the reasoning could be more detailed, and the claim could benefit from additional examples or references to strengthen its persuasiveness. Overall, the comment is 4, as it provides some justification but lacks depth in explanation or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s structure, noting that Sections 3 and 4, which are considered main contributions, are too short and lack detailed mathematical definitions. The reviewer provides a concrete example, mentioning the absence of precise definitions for quantum states in Eq (4), which makes it difficult for the authors to follow the content. This feedback is actionable and provides a clear direction for improvement, suggesting that the authors should expand these sections to include the necessary mathematical details. However, the comment could be more helpful if it offered additional guidance on how to integrate these definitions or suggested specific areas where the definitions could be added. Overall, the comment is 4 as it highlights a critical issue and provides a clear starting point for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of the results with respect to underrepresented groups, specifically mentioning potential discrimination against females or blacks by LLMs. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific actions the authors should take to ensure fairness. The comment lacks concrete guidance on how to evaluate or improve the fairness of the results, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of the results with respect to underrepresented groups, specifically mentioning potential discrimination against females or blacks by LLMs. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of fairness, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of the results with respect to underrepresented groups, specifically mentioning potential discrimination against females or blacks by LLMs. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the fairness of the results concerning underrepresented groups, specifically questioning whether the recommendations of LLMs may discriminate against certain groups like females or blacks. This is a significant concern that could impact the validity and ethical implications of the study. However, the comment lacks actionable guidance or suggestions on how to address this issue or ensure fairness. While it identifies a crucial area for improvement, it does not provide the authors with a clear path forward or specific steps to take. Therefore, the comment is 3, as it highlights an important aspect of the research but does not offer comprehensive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several minor comments that suggest improvements to the paper. It mentions that the paragraph describing covariance in Section 1 is long and reduces legibility, suggesting that it could be shortened. It also points out that the generation of two types of longtailed datasets is only illustrated with two examples, implying that more details should be added to support the claims. Additionally, the reviewer notes that the tables and figures are dense and suggests using more pages for the experiments on longtailed datasets, which are considered more important for the paper. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes. The actions are somewhat vague, as the authors need to infer how to shorten the paragraph, add more details to the dataset generation, and potentially expand the sections on longtailed datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as Section 1, the paragraph describing covariance, and the sections related to the generation of longtailed datasets. It also refers to the tables and figures, indicating a clear understanding of which parts of the paper need attention. The comment is specific because it provides detailed feedback on the length of the covariance paragraph, the limited examples for longtailed dataset generation, and the density of tables and figures, suggesting that more detail and potentially more pages should be used for the experiments on longtailed datasets. This allows the authors to precisely identify the areas that need improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of minor comments that suggest improvements to the paper. It mentions that the paragraph describing covariance in Section 1 is long and reduces legibility, implying that it could be shortened. It also notes that the generation of two types of longtailed datasets is only illustrated with two examples, suggesting that more details should be added to support the claims. Additionally, the comment points out that the tables and figures are dense, and the authors should consider using more pages for the experiments on longtailed datasets, which are considered more important for the paper. While the comment provides specific suggestions for improvement, it lacks detailed reasoning or references to support the claims fully. The feedback is 3 as it offers clear directions for improvement but could be strengthened with additional justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper, which can help the authors improve their draft. It suggests that the paragraph describing covariance in Section 1 is too long and could be shortened to enhance legibility. Additionally, the comment points out that the generation of two types of longtailed datasets is only illustrated with two examples, implying that more details should be added to support the claims. The reviewer also notes that the tables and figures are dense and suggests using more pages for the experiments on longtailed datasets, which are considered more important for the paper. While the comment is clear and identifies areas for improvement, it could be more helpful if it provided specific guidance on how to add more details or expand the sections. Overall, the feedback is 4 as it offers valuable insights for enhancing the paper, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the necessary changes to make ECDiffusers work on realworld data. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes might be required. Without concrete advice or examples, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the necessary changes to make ECDiffusers work on realworld data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide specific guidance or context. It is also not specific because it does not detail what changes are needed or how to approach them. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the necessary changes to make ECDiffusers work on realworld data. However, it does not provide any specific claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, lacking any assertion or guidance that would need to be substantiated. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the necessary changes to make ECDiffusers work on realworld data. However, it does not provide any specific suggestions, guidance, or insights on how to address this issue. The comment lacks actionable feedback, leaving the authors without a clear understanding of what steps they should take to improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. While it prompts the authors to consider this aspect, it does not provide explicit instructions or detailed guidance on how to conduct such a study or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to conduct the human study or what aspects of the evaluation protocol need to be considered. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, it does not provide any specific reasoning, examples, or references to support the claim that the evaluation is unreliable or lacks a human study. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. This feedback is valuable as it highlights a potential area for improvement in the paper, specifically regarding the robustness and validity of the evaluation methodology. However, the comment lacks detailed guidance or suggestions on how to conduct such a study or what specific aspects of the evaluation protocol need to be considered. While it identifies an important issue, it does not provide actionable steps for the authors to address it, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the novelty of the work, specifically comparing it to prior work by mentioning \"von Kugelgen et al. 2021\" and \"Daunhawer et al. 2023.\" However, it does not specify which part of the paper this concern pertains to, such as a particular section or methodology. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue of novelty but lacks detailed suggestions on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. However, it does not provide specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the work, suggesting that the technical contribution is somewhat incremental compared to prior work. While this feedback highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The comment is 3 as it identifies a critical aspect of the paper that needs attention, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance of PromptMix depends on the quality of questions and answers generated by the LLM, emphasizing the need for a highquality model. It also proposes an analysis of which opensource LLMs would work with this approach and suggests a potential LLM parameter count cutoff to maintain performance. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the analysis or identify the relevant LLMs. The action is explicit but somewhat vague, as it does not offer detailed steps or examples for implementation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the performance of PromptMix, emphasizing its dependence on the quality of questions and answers generated by the LLM. It suggests an analysis of which opensource LLMs would work with this approach and proposes a potential LLM parameter count cutoff to maintain performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what needs to be addressed, such as the analysis of opensource LLMs and the parameter count cutoff. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of PromptMix depends on the quality of questions and answers generated by the LLM, and suggests an analysis of which opensource LLMs would work with this approach. It also proposes a potential LLM parameter count cutoff to maintain performance. However, the comment lacks specific examples or references to support the claim about the dependence of performance on LLM quality. While it provides a logical reasoning for the suggestion, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of PromptMix, specifically its dependence on the quality of questions and answers generated by the LLM. It suggests that a highquality model is essential for the success of the task and proposes an analysis of which opensource LLMs would work with this approach, as well as a potential LLM parameter count cutoff to maintain performance. This feedback is clear and actionable, providing the authors with specific areas to investigate and improve their work. However, it could be more helpful if it included examples or suggested specific methods for conducting the analysis. Overall, the comment is 4, as it offers valuable insights and directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm and scales with N^5 as mentioned in Appendix D.4. It suggests that the authors should comment on the feasibility of this approach and ask about the runtimes of simulations for large models in Section 6. While the comment implies that the authors should address the feasibility, it does not provide explicit instructions on how to do so, such as suggesting specific analyses or comparisons. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the submodularity approach subroutine, specifically mentioning the SATURATE algorithm and its scaling with N^5 as described in Appendix D.4. It suggests that the authors should comment on the feasibility of this approach and ask about the runtimes of simulations for large models in Section 6. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. It is specific in detailing what needs to be addressed, such as the feasibility of the approach and the runtimes of simulations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm and scales with N^5 as mentioned in Appendix D.4. It suggests that the authors should comment on the feasibility of this approach and ask about the runtimes of simulations for large models in Section 6. However, the comment lacks specific examples or detailed reasoning to support the claim that the approach is feasible or infeasible. It does not provide references or logical arguments to substantiate the assertion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm and scales with N^5 as mentioned in Appendix D.4. It suggests that the authors should comment on the feasibility of this approach and ask about the runtimes of simulations for large models in Section 6. This feedback is 3 as it points out a potential area for further discussion and analysis, but it lacks depth and specificity. The comment does not provide detailed guidance on how the authors might address the feasibility or what specific analyses could be conducted to evaluate it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the explanation of inference at test time is brief and suggests that it would benefit from more details. This provides a clear and explicit action for the authors to take, which is to expand the explanation. The comment is specific in its suggestion, as it directs the authors to enhance the explanation of inference at test time. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"594,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies that the explanation of inference at test time is brief and suggests that it would benefit from more details. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanation of inference at test time is brief and suggests that it would benefit from more details. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the explanation is brief or how to improve it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the explanation of inference at test time is brief and suggests that it would benefit from more details. This feedback is specific and actionable, as it directs the authors to enhance the clarity and depth of their explanation. By providing a clear suggestion for improvement, the comment empowers the authors to address a specific aspect of their work, making it 4. However, the comment could be more helpful if it offered additional guidance on how to expand the explanation or provided examples of what additional details might include. Overall, the comment is 4 as it identifies a specific area for improvement and encourages the authors to enhance their explanation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the correctness and soundness of the paper, including the evaluation of modality and reusability of programs generated by CodeChain, the effectiveness of submodule generation, and the performance drop in the 5th iteration of selfrevisions. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the evaluation, demonstrate the effectiveness of submodule generation, or analyze the performance drop. Without specific suggestions or steps, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment raises several concerns about the correctness and soundness of the paper, including the evaluation of modality and reusability of programs generated by CodeChain, the effectiveness of submodule generation, and the performance drop in the 5th iteration of selfrevisions. However, it does not specify which part of the paper these issues are discussed or addressed. The authors cannot confidently determine which sections or aspects of the paper are being questioned, making the comment weakly grounded. While the comment is specific in detailing the issues, the lack of grounding makes it difficult for the authors to focus their responses. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the correctness and soundness of the paper, including the evaluation of modality and reusability of programs generated by CodeChain, the effectiveness of submodule generation, and the performance drop in the 5th iteration of selfrevisions. However, the comment does not provide any specific evidence, reasoning, or references to support these claims. Without detailed explanations or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several concerns about the correctness and soundness of the paper, specifically questioning the evaluation of modality and reusability of programs generated by CodeChain, the effectiveness of submodule generation, and the performance drop in the 5th iteration of selfrevisions. While the comment identifies areas that need clarification or further analysis, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out potential weaknesses, but it does not provide actionable steps or detailed insights to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the interpretation of the authors\" claim regarding the accuracy of deferring classifiers. It does not provide explicit instructions or suggestions on how the authors should address this question or incorporate it into their draft. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 306307 of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue with the interpretation of the claim regarding the accuracy of deferring classifiers and questions the implications for fairness. The comment provides clear guidance on what needs to be addressed, making it 5.", "verifiability_rationale": "The review point raises a question about the interpretation of the authors\" claim regarding the accuracy of deferring classifiers. It asks whether the higher overall accuracy at a given minimum subgroup accuracy (MSA) implies that the error rates are more evenly distributed across subgroups for the deferring classifier, potentially indicating less fairness. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the interpretation of the authors\" claim regarding the accuracy of deferring classifiers. It challenges the assumption that higher overall accuracy at a given minimum subgroup accuracy (MSA) implies that the error rates are more evenly distributed across subgroups, potentially indicating less fairness. This feedback is valuable as it prompts the authors to reconsider their interpretation and potentially refine their claims or provide additional context. However, the comment could be more helpful if it offered suggestions on how to address this issue or provide evidence to support the claim. Overall, the comment is 3 as it identifies a significant point for consideration, but it lacks depth and actionable guidance, making it a 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly claims that the relational embedding module significantly improves object classification but does not provide any results to support this claim. It suggests that reporting the improvement on object classification directly would strengthen the paper. This feedback is clear and provides a direct action for the authors to take, which is to include results on object classification. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions L107, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors should report the improvement on object classification directly, in addition to the overall scene graph results. This provides a clear direction for the authors to improve their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relational embedding module significantly improves object classification but does not provide any results to support this claim. It suggests that reporting the improvement on object classification directly would strengthen the paper. However, the comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand how to substantiate it. The feedback is 3 as it points out a gap in the evidence but does not provide detailed guidance on how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module significantly improving object classification is not supported by any results. It suggests that the authors should report the improvement on object classification directly to strengthen the paper. This feedback is clear and actionable, providing a direct suggestion for improvement that would enhance the paper\"s credibility and impact. By recommending the inclusion of specific results, the comment guides the authors in addressing a critical gap in their analysis. Therefore, the comment is 5, as it offers a clear and constructive direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the manuscript but points out that the novelty is relatively small due to the addition of selfsupervised learning on top of existing work. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty or scope of their work. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper being discussed, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback by pointing out that the novelty of the manuscript is relatively small due to the addition of selfsupervised learning on top of existing work. This feedback is clear and specific, guiding the authors on how to enhance the novelty of their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the manuscript is relatively small due to the addition of selfsupervised learning on top of existing work, specifically referencing a CVPR 2020 paper. However, the comment lacks detailed reasoning or examples to substantiate this claim. It does not provide specific evidence or comparisons to support the assertion that the novelty is small. As a result, the claim is not 5, making the comment 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the manuscript, suggesting that the addition of selfsupervised learning on top of existing work does not significantly enhance the novelty. It references a specific paper to support this claim, providing a basis for comparison. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. While it provides some insight, it lacks actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the difficulty of finding intuitive attention examples, as seen in Figure 4. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could consider to improve the clarity of their examples. Without specific advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment asks a question about the difficulty of finding intuitive attention examples as seen in Figure 4. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is 1 as it does not provide clear guidance on which part of the paper needs attention. Additionally, the comment is specific in its request for clarification but lacks grounding, making it 3. Therefore, this comment aligns with the label 3.", "verifiability_rationale": "The review point is a question asking about the difficulty of finding intuitive attention examples as seen in Figure 4. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, asking for clarification rather than making an opinion or suggestion. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding intuitive attention examples, as seen in Figure 4. While it identifies a potential area for improvement in terms of clarity and accessibility of examples, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment lacks actionable advice, making it 3 as it highlights a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the difference between two elements in Figure 1. While it prompts the authors to clarify the distinction, it does not provide explicit instructions or suggestions on how to address this issue in the paper. The action is implicit, as the authors need to infer that they should clarify the difference in the figure. However, the comment lacks concrete guidance on how to implement this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper Figure 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is not specific because it does not provide any guidance or suggestions on how to address the question about the difference between 01 and 10. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for clarification about the difference between two elements in Figure 1. It does not contain a claim or suggestion that requires verification or justification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the difference between two elements in Figure 1, specifically asking \"what\u2019s the difference between 01 and 10?\". This question highlights a potential area of confusion or lack of clarity in the figure, which could hinder the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the figure. Without actionable feedback or suggestions, the comment is 2, as it identifies a problem but does not offer a path for resolution. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper dedicates significant space to describing the rules and data augmentation methods used in constructing the benchmark, but it lacks clarity in presenting the overall process and rationale for construction. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to clarify the overall process or rationale. The action is implicit, as the authors can infer that they need to provide a clearer explanation of the benchmark construction process. However, the comment lacks concrete guidance on how to achieve this clarity, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s focus on describing rules and data augmentation methods used in constructing the benchmark, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity in presenting the overall process and rationale for construction. This provides the authors with a clear understanding of what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper dedicates significant space to describing the rules and data augmentation methods used in constructing the benchmark but lacks clarity in presenting the overall process and rationale for construction. This claim is 3 as it highlights a potential area for improvement in the paper\"s presentation. However, it does not provide specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that while it dedicates significant space to describing the rules and data augmentation methods used in constructing the benchmark, the overall process and rationale for construction are not presented clearly. This feedback is valuable as it highlights a potential gap in the paper\"s presentation, suggesting that the authors could enhance the clarity and coherence of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the clarity of the benchmark construction process. Overall, the comment is 3, as it points out a meaningful area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant lack of content in the paper, specifically mentioning the absence of literature reviews on recent advances in active learning, particularly Bayesian learning. It provides specific examples, such as Bayesian Coreset, which is directly relevant to the work and ignored in the literature review. The comment also suggests that there have been multiple works discussing similar directions, such as combining uncertainty with Coreset, and questions how the current setup is more advanced than related studies. While the comment identifies a clear gap in the literature review and suggests specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out the need for more comprehensive literature review and discussion, but it lacks detailed instructions on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of content and the need for a more comprehensive literature review, specifically highlighting the absence of recent advances in active learning, particularly Bayesian learning. It provides specific examples, such as Bayesian Coreset, which is directly relevant to the work and ignored in the literature review. The comment also suggests that there have been multiple works discussing similar directions, such as combining uncertainty with Coreset, and questions how the current setup is more advanced than related studies. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks content, specifically mentioning the absence of literature reviews on recent advances in active learning, particularly Bayesian learning. It provides specific examples, such as Bayesian Coreset, which is directly relevant to the work and ignored in the literature review. The comment also suggests that there have been multiple works discussing similar directions, such as combining uncertainty with Coreset, and questions how the current setup is more advanced than related studies. While the claim is supported by specific examples and references, the reasoning could be more detailed to fully substantiate the argument. Therefore, the comment is 4, as it provides a clear basis for the claim but lacks some depth in explanation or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of content, specifically mentioning the absence of literature reviews on recent advances in active learning, particularly Bayesian learning. It provides specific examples, such as Bayesian Coreset, which is directly relevant to the work and ignored in the literature review. The comment also suggests that there have been multiple works discussing similar directions, such as combining uncertainty with Coreset, and questions how the current setup is more advanced than related studies. This feedback is 4 as it highlights specific areas where the paper could be improved by expanding its literature review and providing a more comprehensive discussion of related studies. However, it could be more helpful if it offered more detailed guidance on how to address these issues or suggested specific actions the authors could take to enhance the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies issues with Figure 2, specifically mentioning the difficulty in understanding the trends due to the \"onetomany relationship\" and the presence of noise. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve the clarity of the plot or reduce the noise. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plot, such as the difficulty in understanding the \"onetomany relationship\" and the presence of noise. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is difficult to understand due to the \"onetomany relationship\" and contains a considerable amount of noise. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with Figure 2, noting that the \"onetomany relationship\" makes it difficult to understand the trends and that the plots contain a significant amount of noise. While the comment highlights these weaknesses, it does not provide actionable suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it lacks depth and specificity, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer due to the lack of deep optimization in these methods. It suggests that a direct comparison might be unfair and questions whether DFSSATTEN supports training from scratch, a significant direction given the popularity of pretraining. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the speedup provided by DFSSATTEN, specifically mentioning that it is mostly due to lowlevel optimization and hardware support. It then critiques the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, noting that these methods are often not deeply optimized. The comment also raises a question about whether DFSSATTEN supports training from scratch, a significant direction in the field. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concerns about the comparison and the lack of support for training from scratch, but without clear references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that these methods are often not deeply optimized. It questions whether DFSSATTEN supports training from scratch, a significant direction in the field. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general critique but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that these methods are often not deeply optimized. It questions whether DFSSATTEN supports training from scratch, a significant direction given the popularity of pretraining. The comment provides a clear critique of the comparison and highlights a potential gap in the paper\"s exploration of training from scratch. However, it could be more helpful if it offered specific suggestions or guidance on how the authors might address these concerns or expand their work to include training from scratch. Overall, the comment is 3 as it identifies important areas for improvement but lacks detailed actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that the method was examined on a blackbox setting when evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes might be necessary. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"VMISITIDIFDSM\" and \"blackbox setting\" in the context of evaluating a defended model. However, it does not specify which part of the paper this information is related to, making it difficult for the authors to identify the exact section or aspect being addressed. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved regarding the evaluation of the defended model in a blackbox setting. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point mentions that \"VMISITIDIFDSM\" was examined on a blackbox setting when their method was evaluated on a defended model. However, the comment does not provide any context, explanation, or references to support this claim. Without additional information or justification, the authors are left without a basis to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the method was examined on a blackbox setting when evaluated on a defended model. However, it does not provide any specific feedback or suggestions on how this evaluation might be improved or what aspects of the method could be enhanced. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to address the issue or what changes might be necessary. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the clarity of the proposed method\"s description could be improved. It references a \"questions section\" for details, which implies that the authors should address these questions to enhance the clarity of their method description. However, the comment does not provide explicit instructions on how to improve the clarity or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the questions raised in the \"questions section\" to improve the clarity of their method description. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the clarity of the proposed method\"s description could be improved, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the method description needs clarification. Additionally, the comment does not provide specific guidance on what aspects of the description require improvement. As a result, the comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with the label \"1 and Not Specific.\"", "verifiability_rationale": "The review point suggests that the clarity of the proposed method\"s description could be improved. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left to infer that the comment is valid, but the lack of detailed explanation makes it difficult to fully understand or address the issue. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the proposed method\"s description, suggesting that it could be improved. However, the comment lacks specific details or actionable suggestions on how to enhance the clarity. Without further guidance or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide comprehensive or detailed advice. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the independence of pruning strategies across different layers in a Graph Neural Network (GNN). It suggests that if an edge is pruned in one layer, it might be expected to be pruned in other layers as well. The comment implies that the authors should consider whether such correlations are observed in empirical evaluations or provide an explanation for why they are not considered. However, the comment does not explicitly instruct the authors to address this question or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the independence of pruning strategies across different layers in a GNN, suggesting that if an edge is pruned in one layer, it might be expected to be pruned in other layers as well. It implies that the authors should consider whether such correlations are observed in empirical evaluations or provide an explanation for why they are not considered. However, the comment does not specify which part of the paper discusses the pruning strategy or the empirical evaluations, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its questioning, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the independence of pruning strategies across different layers in a GNN, suggesting that if an edge is pruned in one layer, it might be expected to be pruned in other layers as well. The comment implies that the authors should consider whether such correlations are observed in empirical evaluations or provide an explanation for why they are not considered. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the question or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as it is based on an intuitive observation but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the independence of pruning strategies across different layers in a Graph Neural Network (GNN). It suggests that if an edge is pruned in one layer, it might be expected to be pruned in other layers as well, and it questions whether such correlations are observed in empirical evaluations or if the authors can explain why they are not considered. This feedback is 3 as it identifies a potential area for further exploration or clarification in the paper. However, the comment could be more actionable by providing specific guidance on how the authors might investigate or address this issue, such as suggesting additional experiments or analyses. Without concrete suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalizability of the experimental results to other indistribution datasets. It suggests that the authors should consider whether the conclusions would hold for different datasets or if some nuances should be addressed. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to investigate the generalizability of their results. The action is implicit and vague, as it does not offer concrete suggestions or detailed instructions on how to conduct further experiments or analyses. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the generalizability of the experimental results to other indistribution datasets, specifically mentioning CIFAR10/100. However, it does not specify which part of the paper this question pertains to, such as the experimental setup or results section. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the generalizability of the results, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the generalizability of the experimental results to other indistribution datasets, specifically mentioning CIFAR10/100. While the authors acknowledge that the results are strong in this case, they express uncertainty about whether these conclusions would hold for other datasets. However, the comment lacks specific examples or references to support the claim that the conclusions might not generalize. Without additional context or evidence, the authors may find it challenging to fully understand the implications of this question. Therefore, the comment is considered 2, as it provides some basis for questioning the generalizability but lacks sufficient detail or supporting evidence.", "helpfulness_rationale": "The review comment raises a question about the generalizability of the experimental results to other indistribution datasets, specifically mentioning CIFAR10/100. While the authors acknowledge that the results are strong in this case, they express uncertainty about whether these conclusions would hold for other datasets. This feedback highlights a potential limitation in the scope of the experimental validation and suggests that the authors should consider expanding their analysis to include a broader range of indistribution datasets. However, the comment lacks specific guidance on how to address this issue or what additional experiments might be necessary. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a relevant area for further exploration but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alphadivergence to provide insights. This is a clear and explicit action that the authors can readily follow. The comment specifies exactly what needs to be done, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alphadivergence, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alphadivergence to provide insights. This is a suggestion for improvement, but it lacks specific reasoning or examples to support why this would be beneficial. The comment does not provide a detailed explanation of how showing this ratio would enhance the paper or why it is necessary. As a result, the claim is 3, as it is based on a logical suggestion but lacks sufficient justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results presented in Table 8, specifically noting that AlphaNets trained with alphadivergence do not benefit from the proposed method. It suggests that the authors should show the gradient conflicts ratio to provide additional insights into this observation. This feedback is clear and actionable, as it directly points out a specific area where the authors could enhance their analysis and provide more context. By suggesting the inclusion of the gradient conflicts ratio, the comment offers a concrete and constructive suggestion for improvement, empowering the authors to address a potential weakness in their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
