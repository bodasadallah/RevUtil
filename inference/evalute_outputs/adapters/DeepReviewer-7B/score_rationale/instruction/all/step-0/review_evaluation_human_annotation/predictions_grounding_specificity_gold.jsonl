{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" choice of operators, specifically the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min, which correspond to union and intersection. The comment implies that the authors should have considered these alternatives and provides a reason for not doing so. However, it does not explicitly instruct the authors to include or discuss these operators in their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider these operators. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" choice of operators and suggesting that they might have considered alternatives like the or operator or elementwise max, which correspond to union and intersection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" choice of operators, specifically the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min, which correspond to union and intersection. The comment implies that the authors should have considered these alternatives and provides a reason for not doing so. However, it does not offer any specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed explanation or evidence makes the claim 3, as the authors are left to infer the reasoning without clear justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors may have overlooked certain operators, namely the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min, which correspond to union and intersection. The comment provides a clear rationale for why these alternatives might have been better options, but it does not offer specific guidance on how the authors should incorporate or discuss these operators in their draft. While the feedback is 3 in pointing out a potential oversight, it lacks detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors may have selected sentences from raw data sources, which contradicts the claim that the data already contains syntactic information. It implies that the data selected is a subset of Li et al. (2019a)\u2019s dataset. The comment provides an implicit action by suggesting that the authors revise the description to clarify this point, but it does not explicitly instruct them to do so. The action is somewhat vague, as the authors need to infer that they should revise the description to make it clear and precise. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (226238 and 242244), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the discrepancy in the description of the data selection process and the suggestion to revise the description to mention Li et al. (2019a) earlier. This provides clear guidance on how to improve the clarity and precision of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors may have selected sentences from raw data sources, which contradicts the claim that the data already contains syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\u2019s dataset and recommends revising the description to clarify this point. The comment provides a logical reasoning by pointing out the inconsistency in the description of the data selection process. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the description of the data selection process, specifically regarding the use of raw data versus the presence of syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\u2019s dataset and recommends revising the description to clarify this point. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on how to revise the description or examples of how to make it clearer. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify the purpose of the average duration. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and the specific areas that require attention. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. While it provides some specificity by asking about the purpose and inclusion of waiting time, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. This comment raises a valid point about the clarity and completeness of the explanation provided in the paper. However, it lacks specific examples or references to support the claim that the explanation is missing or unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of explanation for the average duration reported in Table 1. It questions the purpose of this metric and asks whether it includes waiting time for the model to generate a response. This feedback is 3 as it identifies a potential area for clarification and improvement in the paper. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or suggested additional context that could enhance the clarity of the table. Without such guidance, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ, NVSB with GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should interpret these results or what steps they should consider to address the observed comparability or overlap. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the results in Table 3 are discussed. The authors cannot confidently determine which section or table is being addressed, making it difficult to understand the context of the questions. Additionally, the comment is not specific because it does not provide detailed guidance on how to interpret the results or what actions should be taken. Therefore, this comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ, NVSB with GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support the interpretation of the results. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ, NVSB with GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any guidance or suggestions on how the authors should interpret these results or what actions they should take to address the observed comparability or overlap. Without actionable feedback or detailed reasoning, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential area for clarification but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any explicit or implicit suggestions on how to address this issue, such as recommending a consistent formatting approach or providing examples of how to format the data correctly. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistency in the presentation of data, noting that some items have spaces between accuracy and standard deviation while others do not, which affects the visual appeal and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any specific examples, reasoning, or references to support why this inconsistency is problematic or how it impacts the paper. Without additional context or justification, the authors may find it challenging to understand the significance of the comment and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of data in Table 2 and Table 3, noting inconsistencies in the presentation of accuracy and standard deviation values. This observation is clear and actionable, as it points out a potential issue with the visual appeal and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting approach or providing examples of how to format the data correctly. While the feedback is 3 in identifying a problem, it lacks depth and actionable suggestions, making it only marginally helpful for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. The comment is explicit in pointing out the missing antecedent and provides concrete guidance on how to address the issue by checking the references for specific formatting details. This allows the authors to directly apply the feedback and improve the formatting of their references. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section of the paper where the issue is located, specifically \"both tasks\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be done, such as checking the references for format, capitalization, and bibliographic details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. While the comment provides a clear instruction for improvement, it lacks specific examples or references to support the claim that the references are missing or need correction. This makes the claim 3, as the authors can infer the need for correction but may require additional guidance to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the formatting of their references. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it provided additional guidance on how to check the references or examples of correct formatting. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the explanations for lexical features and sentencelevel features in Section 3.2 are somewhat intertwined and confusing. It provides a clear action for improvement: organizing the section with separate paragraphs for each type of feature. This action is concrete and specific, as it clearly indicates how the authors should restructure the section to enhance clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the organization of the section by suggesting separate paragraphs for lexical and sentencelevel features. This level of detail helps the authors understand exactly what needs to be done to enhance the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are somewhat intertwined and confusing, implying that the section could be more coherently organized. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without detailed reasoning or examples, the claim is 3, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of explanations in Section 3.2, noting that the features are somewhat intertwined and confusing. It provides a clear suggestion for improvement by recommending a more coherent organization of the section with separate paragraphs for lexical and sentencelevel features. This feedback is actionable and constructive, as it directly addresses a potential weakness in the paper and offers a concrete solution for the authors to consider. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the clarity of the explanations. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" However, it does not explicitly instruct the authors to include this example or provide guidance on how to do so. The action is implicit, as the authors would need to infer that they should add an example to the abstract to address the inconsistency. While the comment is 3, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests improving the abstract by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" This guidance is clear and actionable, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. Without additional context or examples, the claim is considered 1. Therefore, the label is 1.", "helpfulness_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" This feedback is 3 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their abstract. However, the comment lacks depth and does not offer additional suggestions or guidance on how to implement this improvement effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific instructions for the authors to address certain aspects of their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. It also questions why the term \"latent in verbs\" is not mentioned. These instructions are explicit and provide clear guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment does not explicitly mention sections, tables, or figures, making it weakly grounded. The instructions are specific in terms of what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. These instructions are clear and provide actionable guidance, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully support the suggestions. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on areas that need improvement in the draft. It instructs the authors to discuss the results for the task of inferring knowledge on objects and to include results for model (B), which are important for a comprehensive understanding of the work. Additionally, it suggests using consistent terminology for the model in Tables 1 and 2, which is a practical and helpful suggestion. The comment also questions why the term \"latent in verbs\" is not mentioned, prompting the authors to consider this aspect. Overall, the feedback is clear, specific, and actionable, making it 5 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggests an alternative phrasing. The comment is explicit in pointing out the error and provides a clear suggestion for improvement. However, it does not offer detailed guidance on how to implement the suggested change or what specific aspects of the sentence need to be revised. While the action is clear, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a factual error in the description of the GRU model and suggests an alternative, more accurate phrasing. This provides clear guidance on what needs to be corrected or revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests an alternative phrasing. While the comment provides a specific example and suggests a correction, it lacks detailed reasoning or references to support the claim. The authors would need to independently verify the correctness of the sentence and the suggested alternative phrasing. Therefore, the claim is 3, as it provides a basis for correction but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggests an alternative phrasing. This feedback is clear and actionable, providing the authors with a specific point of improvement. However, the comment could be more helpful if it offered additional guidance on how to revise the sentence or suggested alternative phrasing. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, allowing them to enhance the accuracy and clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models used in the paper. First, it points out that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. This suggests that the authors should include this comparison to provide a more comprehensive evaluation of their models. Second, the comment notes that the authors do not compare their models to other domain adaptation methods, such as those mentioned in Section 8. This implies that the authors should include these comparisons to strengthen their analysis. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to implement these suggestions, such as which specific models to compare or how to conduct the comparisons. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Campos et al. (2020)\" and \"other domain adaptation methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the lack of comparison to these specific baselines. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests that the authors should compare their models to Campos et al. (2020) and other domain adaptation methods. The comment provides specific examples of missing comparisons, such as the omission of Campos et al. (2020) and the lack of comparison with methods cited in Section 8. However, the reasoning behind why these comparisons are necessary or how they would strengthen the paper is not fully elaborated. While the claim is 3 due to the specific examples provided, it lacks a detailed explanation or justification for the suggested comparisons. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the baseline models used are weak. It specifically mentions the absence of comparisons to Campos et al. (2020) and other domain adaptation methods, which are relevant to the study. This feedback is valuable as it directs the authors to include additional comparisons to strengthen their analysis and provide a more comprehensive evaluation of their models. However, the comment could be more helpful if it provided specific suggestions on which models to compare or how to conduct these comparisons. Despite this, the feedback is 4 as it highlights important areas for improvement and guides the authors toward a more thorough evaluation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the yaxis label in Figure 5 might use \"Exact Match ratio\" directly. This is a specific and actionable suggestion that the authors can easily address by either correcting the label or providing a rationale for its use. The comment is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the yaxis label in Figure 5 may use \"Exact Match ratio\" directly. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the yaxis label in Figure 5 may use \"Exact Match ratio\" directly. This is a specific and factual observation, as it points out a potential issue with the labeling of the figure. However, it does not provide any reasoning or justification for why this is a problem or how it might affect the interpretation of the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 2, as it provides some information but lacks depth and clarity in its justification.", "helpfulness_rationale": "The review comment points out a potential issue with the labeling of the yaxis in Figure 5, suggesting that it may use \"Exact Match ratio\" directly. This is a specific and actionable feedback that the authors can easily address by correcting the label or providing a rationale for its use. The comment is clear and provides a direct suggestion for improvement, making it 4. However, it could be more helpful if it included additional context or guidance on why this labeling might be problematic or how it affects the interpretation of the results. Overall, the feedback is 4 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the lack of strong baselines in Table 3, specifically mentioning the baselines in [1]. It requests the authors to justify their choice of baselines. While the comment implies that the authors should include more baselines, it does not provide explicit guidance on how to do so or what specific baselines should be added. The action is implicit and somewhat vague, as the authors need to infer that they should add more baselines and justify their selection. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to justify the reason for the absence of strong baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of strong baselines in Table 3, specifically mentioning the baselines in [1]. However, it does not provide any justification or reasoning for why these baselines are missing or why the authors chose not to include them. The comment lacks supporting evidence or logical reasoning, making it difficult for the authors to understand the basis for the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting the absence of strong baselines and suggesting that the authors should include additional baselines from [1]. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it included specific examples of the missing baselines or a rationale for why the authors chose not to include them. Overall, the comment is 4 as it guides the authors to address a critical aspect of their work, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider adding information about the use of word embeddings in the BiLSTMCRF model, similar to Lample et al. It also questions the labeling of KNs in the source language or in English, given that mentions have been translated to English. The comment implies that these additions would improve the clarity and consistency of the paper. However, it does not provide explicit instructions on how to implement these suggestions, such as where to add the information or how to clarify the labeling. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as adding information about word embeddings and clarifying the labeling of KNs. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should consider adding information about the use of word embeddings in the BiLSTMCRF model, similar to Lample et al., and that the labeling of KNs in the source language or in English should be clarified. However, the comment does not provide any specific reasoning or evidence to support these claims, such as examples or references to similar practices in the literature. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement, such as adding information about the use of word embeddings in the BiLSTMCRF model, similar to Lample et al., and clarifying the labeling of KNs in the source language or in English. These suggestions are actionable and could help the authors enhance the clarity and consistency of their paper. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how to improve the labeling. Overall, the feedback is 3 as it offers clear directions for improvement, but it could be more comprehensive to fully assist the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with lines 102106, stating that the term \"such distribution\" is misleading because it does not align with the discussion in the preceding text. However, the comment does not provide any explicit guidance on how the authors should revise or clarify this section. The action is implicit, as the authors would need to infer that they need to address the misleading use of the term \"such distribution\" in the specified lines. While the action is clear, the lack of concrete instructions on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 102106, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a misleading use of the term \"such distribution\" in the context of the discussion. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity and accuracy of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the term \"such distribution\" does not align with the preceding discussion. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the term is misleading or how to address it. Therefore, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with lines 102106, noting that the term \"such distribution\" is misleading because it does not align with the preceding discussion. This feedback is clear and actionable, as it directs the authors to a particular section of the paper that needs clarification. However, the comment could be more helpful if it provided suggestions on how to revise or clarify the use of the term \"such distribution\" to ensure consistency and accuracy. While it offers a starting point for improvement, the feedback is 4 as it highlights a critical area for revision."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that some claims in the paper would benefit from more indepth analysis. However, it does not specify which claims need more analysis or provide any guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to delve deeper into the analysis of certain claims. Without explicit instructions or concrete examples, the authors are unable to understand what specific aspects require more detailed analysis. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some claims in the paper would benefit from more indepth analysis. However, it does not specify which claims or sections of the paper are being referred to, nor does it provide any guidance on how to conduct this analysis. The lack of specific information makes it difficult for the authors to identify the exact parts of the paper that need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some claims in the paper would benefit from more indepth analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the comment, making it difficult to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some claims in the paper would benefit from more indepth analysis. However, it lacks specificity and does not provide any guidance on which claims need more analysis or how to conduct this analysis. The comment is vague and does not offer actionable feedback, leaving the authors with limited insight into how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific issues regarding the presentation of the model. It asks for clarification on the pooling method used for embedding features, referencing line 397, and questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC. The comment also suggests that the lefthand side of the equation might be a conditional probability. While the comment identifies two areas for clarification, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the pooling method and the definition of E_i, as well as the nature of the lefthand side of Equation (7). Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (397 and 472) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the presentation of the model, such as the pooling method used for embedding features and the clarity of Equation (7). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises two specific questions about the presentation of the model, focusing on the pooling method used for embedding features and the clarity of Equation (7). The first question asks for clarification on the pooling method referenced in line 397, which is a factual request for information. The second question questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC, and suggests that the lefthand side of the equation might be a conditional probability. While the comment provides a clear request for clarification, it lacks specific examples or references to support the claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the presentation of the model could be improved. It asks for clarification on the pooling method used for embedding features, referencing line 397, and questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC. The comment also suggests that the lefthand side of the equation might be a conditional probability. While the feedback is clear and points out specific issues that need clarification, it lacks detailed guidance on how the authors should address these concerns. The comment is 3 as it provides actionable feedback but could be more comprehensive with additional suggestions or examples to guide the authors in improving their presentation. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but it does not mention these hypotheses again in the draft. The reviewer suggests that the paper should either test these hypotheses as given or explore them in more depth. However, the comment does not provide explicit guidance on how to test the hypotheses or how to delve deeper into them. The action is implicit and vague, as the authors are left to infer that they need to address the lack of testing or deeper exploration of the hypotheses. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper by referencing specific lines (078086) where two hypotheses are raised. This provides full grounding as the authors can accurately identify the part of the paper being discussed. The comment also specifies that the paper does not actually study these hypotheses, which are mentioned but not discussed again, and suggests that the paper should either test them or explore them in more depth. This specificity is clear, as it provides detailed feedback on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not actually study these hypotheses or discuss them further. The reviewer suggests that the paper should either test these hypotheses or explore them in more depth. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed. This makes the claim 3, as it provides a basis for improvement but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper by pointing out that the hypotheses raised in lines 078086 are not actually studied or discussed further in the draft. This feedback is valuable as it highlights a gap in the paper\"s exploration of the core ideas. However, the comment could be more helpful by providing specific suggestions on how the authors might address these hypotheses, such as suggesting additional experiments or analyses that could be conducted. Without concrete guidance, the authors may find it challenging to improve their draft based solely on this feedback. Therefore, the comment is 3, as it identifies a significant area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F1. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F1. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it lacks specific references or context, and it is also not specific about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F1. However, it lacks detailed reasoning or examples to support why this comparison is necessary or how it would be beneficial. The comment does not provide specific references or logical reasoning to justify the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F1. While this provides a potential improvement or area for further exploration, the comment lacks detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The feedback is 3 as it identifies a potential area for improvement, but it does not offer comprehensive advice or detailed instructions, leaving the authors with limited actionable insights. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a clear and explicit action that provides specific guidance on what needs to be included in the paper. The authors know exactly what information is missing and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: stating the maximum number of tasks done by any annotator. This provides the authors with a clear understanding of the issue and how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a factual suggestion that requires no further verification or reasoning. The comment is clear and specific, providing a clear instruction for the authors to include in their paper. Therefore, it is classified as \"3\" as it is clear but lacks some depth in terms of why this information is important or how it impacts the paper.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by asking the authors to include the maximum number of tasks done by any annotator. This is a clear and actionable piece of feedback that directly addresses a potential omission in the paper. By providing this information, the authors can enhance the transparency and completeness of their work, making it more informative and useful for readers. The comment is specific and actionable, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a clear and explicit action that the authors can readily implement by adding the suggested element to their table. The comment provides a concrete instruction on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in its suggestion to include the hard prompt baseline, but the lack of grounding makes it difficult for the authors to accurately identify the section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a suggestion for improvement, but it does not provide any specific reasoning, examples, or references to support why this inclusion would be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a specific and actionable suggestion that could enhance the clarity and comprehensiveness of the paper. By providing this feedback, the reviewer offers a clear direction for improvement, allowing the authors to address a potential gap in their analysis. However, the comment could be more helpful if it provided additional context or explanation about why this baseline is important or how it would impact the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of numerical results in the paper, specifically questioning how the proposed method can be applied to popular algorithms and how its performance compares to existing DP algorithms. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include numerical results and conduct comparisons with existing algorithms. However, the action is implicit and somewhat vague, as it does not specify which algorithms to use or how to perform the comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and questions the application of the proposed method to popular algorithms, specifically comparing its performance with existing DP algorithms. However, it does not specify which algorithms are considered \"popular\" or provide any details on how the comparison should be conducted. The comment is 1 as it does not mention specific sections, tables, or figures that might contain numerical results or comparisons. It is also not specific because it lacks details on the algorithms or the nature of the comparison. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks numerical results and questions how the proposed method can be applied to popular algorithms and compared with existing DP algorithms. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and the absence of comparisons with existing DP algorithms. This feedback is valuable as it highlights a critical area where the authors can strengthen their work by providing empirical evidence and demonstrating the practical applicability of their method. However, the comment could be more helpful if it suggested specific algorithms or methods for comparison or provided guidance on how to conduct these comparisons. Despite this, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so or provide detailed guidance on how to implement these tests. The action is implicit and somewhat vague, as the authors need to infer that they should perform the suggested experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are not enough and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, it does not specify which part of the paper these comparisons are made or which sections of the paper need to be revised. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the need for additional experiments, it lacks specificity in terms of how these experiments should be conducted or what results are expected. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experimental comparisons are not enough and suggests testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, the comment lacks specific reasoning or examples to support why these additional comparisons are necessary or how they would enhance the paper. Without detailed justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental comparisons by suggesting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback is 3 as it points out an area for improvement in the experimental setup, which could potentially strengthen the paper. However, the comment lacks depth and does not provide specific guidance on how to conduct these additional experiments or what results to expect. The authors would need to infer that they should perform these tests, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit instructions for correcting the placement of a callout in Table 5 to Table 3 and for improving the clarity of the callout in Figure 6. These actions are concrete and specific, allowing the authors to directly apply the corrections. The comment is clear and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout in Figure 6, indicating that the authors need to improve the clarity of the callout. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point consists of factual observations about the placement of callouts in the paper. It specifies that the callout to Table 5 should be in Table 3 and that the callout for Figure 6 is not directing properly. While the comment is accurate, it does not provide any reasoning or justification for why these corrections are necessary or how they would improve the paper. The lack of explanation or evidence makes the claim 3, as the authors can infer the need for correction but may require additional context to fully understand the reasoning behind it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the placement of callouts in the paper, noting that the callout for Table 5 should be in Table 3 and that the callout for Figure 6 is not directing properly. This feedback is clear and actionable, as it directly points out areas where the paper could be improved for better clarity and accuracy. By addressing these specific issues, the authors can enhance the overall quality and readability of their work. The comment is 4 as it offers clear guidance on how to improve the draft, though it could be more comprehensive by suggesting additional improvements or providing more detailed reasoning. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the experiments, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to address the lack of explanation for the selfcomparisons or to include comparisons with SketchRNN. The action is implicit and somewhat vague, as the authors need to infer how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the issue of only reporting selfcomparisons and the lack of explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. However, the comment does not specify which part of the experiments section this issue is discussed, making it weakly grounded. The comment is specific in identifying the problem with the experiments and suggesting an improvement, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact area of concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only reports selfcomparisons and lacks explanation for this choice, which adds to the poor motivation problem. It suggests that comparisons with SketchRNN could be performed. However, the comment does not provide specific examples or references to support the claim about the lack of explanation or the suggestion to include comparisons with SketchRNN. This makes the claim 3, as it lacks detailed reasoning or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the experiments section, specifically noting that the paper only reports selfcomparisons without providing adequate explanation. This lack of explanation is linked to a poor motivation problem, which is a critical issue for the paper\"s impact and clarity. The comment also suggests that comparisons with SketchRNN could be performed to address this limitation. While the comment highlights a specific area for improvement and provides a clear suggestion, it lacks detailed guidance on how to conduct these comparisons or what specific aspects of SketchRNN should be compared. This makes the feedback 3, as it points out a crucial weakness but does not fully address the authors\" needs for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more analysis and comments are needed regarding the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It disagrees with the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The comment provides specific observations about the performance of DeiT models on different datasets, noting that DeiTB does not outperform DeiTT and DeiTS on APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment does not explicitly instruct the authors on how to conduct this additional analysis or what specific aspects to focus on. While the authors can infer that they need to provide more analysis, the lack of explicit guidance on the methodology or specific areas to explore makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed observations about the performance trends of DeiT models compared to CNNs, highlighting discrepancies in their performance across different datasets. The authors are given specific data points and observations to consider, making the comment both 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" viewpoint regarding the performance trends of increasing model capacity for ViT (DeiT) is incorrect. It provides specific observations from Figure 3, noting that DeiTB does not outperform DeiTT and DeiTS on certain datasets, while CNNs show more consistent improvements. However, the comment lacks detailed reasoning or references to support these claims, making it 3. The authors would need to rely on the provided observations to understand the basis of the critique, but additional evidence or explanation would enhance the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed analysis of the performance trends of increasing model capacity for ViT (DeiT) in Figure 3, disagreeing with the authors\" viewpoint that both CNNs and ViTs benefit similarly. It offers specific observations, such as the performance of DeiTB not outperforming DeiTT and DeiTS on certain datasets, while CNNs show more consistent improvements. This feedback is 3 as it highlights areas where the authors\" claims might be inaccurate and suggests that more analysis is needed. However, the comment could be more helpful if it provided guidance on how to conduct this additional analysis or what specific aspects to focus on. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that don\"t. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion in their draft. The comment is specific in its recommendation, detailing exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates the frozen model and those that don\"t, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that do not. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this distinction is important or how it would improve the paper. Without additional context or justification, the claim is 3, as it is based on a logical suggestion but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors make a distinction between hard prompt work updates the frozen model and those that do not. This feedback is clear and actionable, as it directs the authors to a specific area where they can enhance their work. However, the comment could be more helpful if it provided additional context or examples to support the suggestion, or if it offered guidance on how to implement the distinction effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. While the comment provides a clear action\u2014conducting an ablation study\u2014it does not specify how to implement this action or what data to use for the study. The suggestion is somewhat vague, as it lacks detailed guidance on the methodology or expected results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment does not specify which part of the paper discusses the visDial dataset or the proposed model, making it difficult for the authors to identify the exact section or figure being referenced. While the comment is specific about the experiment of interest, the lack of grounding makes it challenging for the authors to understand the context and relevance of the suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment lacks detailed reasoning or justification for why this ablation study is necessary or how it would strengthen the validation of the model. It does not provide specific examples or references to support the claim, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It highlights a particular experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. This feedback is actionable and constructive, as it directs the authors to a specific area for further investigation and provides a clear goal for their work. However, the comment could be more helpful if it included additional guidance on how to conduct the ablation study or what specific metrics to consider. Overall, the comment is 4, as it offers valuable insights and directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should try to explain why the Wavelet Packet Analysis (WPA) works, particularly with np.ones input, and what the model predicts in this case. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is crucial for future research directions. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it lacks concrete guidance, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors should do, namely, to explain why WPA works with np.ones input, what the model predicts, and why Gaussian noise input does not work as well as WPA. This provides a clear direction for the authors to improve their understanding and presentation of the work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of WPA, particularly with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or logical arguments to substantiate the assertion that WPA fails with Gaussian noise input. Without additional evidence or explanation, the claim remains 3, as it lacks the necessary depth and support to fully substantiate the authors\" concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of explanation regarding why WPA works, especially with np.ones input. It questions the effectiveness of Gaussian noise input compared to WPA and suggests that the authors should provide more insights into how WPA functions. This feedback is valuable as it highlights an area where the paper could be strengthened to offer deeper understanding and potential future research directions. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting additional experiments or analyses that could be conducted. Overall, the comment is 4, as it directs the authors to an important aspect of their work that needs further exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by pointing out that while the end of Section 2 discusses important parameters (minimum cluster size and conductance threshold), the experimental section (Section 3) does not mention or discuss how these parameters are set or how sensitive the performance is to them. This feedback is explicit and provides a clear action for the authors to take, which is to address this gap by including details on parameter setting and sensitivity analysis in the experimental section. The comment is specific and actionable, as it directly instructs the authors on what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 2 and the experimental section (Sec. 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of mention or discussion of how the two important parameters (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a gap in the paper by pointing out that while the end of Section 2 discusses important parameters (minimum cluster size and conductance threshold), the experimental section (Section 3) does not mention or discuss how these parameters are set or how sensitive the performance is to them. This feedback is clear and provides a logical reasoning for why the experimental section lacks these details. However, it does not provide specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that while the end of Section 2 discusses important parameters (minimum cluster size and conductance threshold), the experimental section (Section 3) does not mention or discuss how these parameters are set or how sensitive the performance is to them. This feedback is clear and actionable, as it provides the authors with a specific area to address in their experimental section. By including details on parameter setting and sensitivity analysis, the authors can enhance the completeness and rigor of their experimental evaluation. The comment is 4 as it offers a clear direction for improvement, though it could be further enhanced by suggesting specific methods for parameter setting or sensitivity analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the approach. The comment lacks concrete guidance on what specific aspects of the model or task need to be revised or enhanced to mitigate the potential weakness. As a result, the authors are left without a clear understanding of how to proceed with the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors cannot confidently determine which aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its critique of the approach but lacks detailed suggestions on how to address the potential weakness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it provides a subjective opinion but lacks sufficient justification.", "helpfulness_rationale": "The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how to address this concern or improve the approach. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the implementation of the bilinear layer, asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the comment provides specific questions that the authors should address, it does not offer explicit guidance on how to clarify these points or what specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address the questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions L290, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs clarification, such as the differences between the bilinear layer and other approaches, the dimensionality of embeddings, and the swapping of the bilinear layer with Hadamard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still applied. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the implementation of the bilinear layer, specifically asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the questions are logical and require the authors to provide detailed explanations, the comment lacks specific examples or references to support the claims. The authors would need to infer the basis for these questions, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises several questions about the implementation of the bilinear layer, specifically asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the comment identifies areas where the authors could provide more detail, it lacks specific guidance on how to address these questions or what additional information would be beneficial. The feedback is 3 as it points out areas for clarification but does not offer detailed suggestions or actionable steps for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider alternative ways to illustrate the results, such as directly showing the latter loss term of Eqn 13. While the comment is 3, it lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment refers to \"Fig. 3 e,\" which is a specific figure in the paper. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment also specifies the issue with the use of cosine similarity to illustrate the results of the latter loss term of Eqn 13, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, the comment does not provide any specific reasoning, examples, or references to support why cosine similarity is an appropriate choice in this context. Without additional justification or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the use of cosine similarity to illustrate the results of the latter loss term of Eqn 13. It questions the rationale behind this choice, noting that the preactivation values of two networks are the same membrane potentials, which might lead to a high cosine similarity. The comment suggests an alternative approach, such as directly illustrating the results of the latter loss term of Eqn 13, which could provide a more direct and clear representation of the results. However, the comment does not provide detailed guidance on how the authors should implement this suggestion or what specific changes they should make to their draft. While it identifies a potential issue, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. It suggests that such a comparison should be made based on experimental results to demonstrate the superiority of data processing over model parameter adjustment. The comment provides an explicit action: \"To address this gap, the authors should include a comparison with TTA methods, such as [AB], and provide experimental results to support the claim that data processing is superior to model parameter adjustment.\" This action is concrete and specific, as it clearly outlines what needs to be done to improve the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of robustness in video action recognition and highlights the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. It suggests that these TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not specify which part of the paper discusses robustness or TTA methods, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with testtime adaptation (TTA) methods, such as [AB], which are relevant to the topic of robustness in video action recognition. The comment suggests that these TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not provide specific examples or detailed reasoning to support the claim that such a comparison is necessary or beneficial. While the reasoning is somewhat logical, the lack of detailed examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of a comparison with testtime adaptation (TTA) methods, which are relevant to the topic of robustness in video action recognition. It suggests that these TTA methods, such as [AB], aim to adapt to outofdistribution data when the input data is disturbed by noise. The comment proposes that the paper should include a comparison between data processing and model parameter adjustment, emphasizing the need for experimental results to support the claim that data processing is superior to model parameter adjustment. This feedback is clear and actionable, providing a specific direction for the authors to improve their draft by addressing the missing comparison. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the comparison. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. This direct feedback allows the authors to identify the specific issue and correct the expression in their draft. The action is explicit and concrete, as it clearly indicates what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the first expression for J(\u03b8) is incorrect and provides the correct expression, making the comment 5. This level of detail enables the authors to understand exactly what needs to be addressed and how to correct it. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. While the comment is specific about the section and the expression, it lacks detailed reasoning or references to support why the expression is incorrect. The authors would need to independently verify the correctness of the expression, which could be timeconsuming. However, the comment does provide a clear direction for correction, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific error in Section 3.2.1, pointing out that the first expression for J(\u03b8) is incorrect and providing the correct expression. This feedback is clear and actionable, allowing the authors to directly address the issue and improve the accuracy of their work. By correcting the expression, the authors can enhance the reliability and credibility of their results. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific examples of capitalization errors in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also mentions specific publications, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020, along with a reference to p. 13, supplement, Fig. This explicit instruction to correct capitalization errors in the references provides clear guidance for the authors to address the issue. The action is concrete and directly actionable, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections and references, such as \"p.8\" and \"p. 13, supplement, Fig.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed examples of capitalization errors in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. Additionally, it lists specific publications and their venues, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020. This level of detail provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point provides specific examples of capitalization errors in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also mentions specific publications and their venues, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020. These examples provide clear evidence of the capitalization issues that need to be addressed. The comment is 5 as it offers specific references and examples to support the claim, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the capitalization errors in the references. By pointing out the inconsistencies in capitalization, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers, the comment guides the authors to correct these issues. Additionally, the comment lists specific publications and their venues, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020, providing clear examples of where these errors occur. This detailed feedback is comprehensive and actionable, enabling the authors to improve the accuracy and consistency of their references. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the lack of clarity regarding parameter values and their selection process. It explicitly asks for the model parameters for task 1, the lambda value for the Boltzmann policy, and how these parameters were chosen, specifically mentioning maximum likelihood estimates. While the comment identifies areas where the paper lacks detail, it does not provide explicit guidance on how to address these issues or what actions the authors should take to improve their draft. The actions are implicit and somewhat vague, as the authors are left to infer how to provide the necessary information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the lack of clarity regarding parameter values and their selection process, specifically mentioning the model parameters for task 1 and the lambda value for the Boltzmann policy. However, it does not specify which part of the paper these parameters are discussed or how they were chosen. The comment is fully grounded in that it mentions specific elements of the paper, but it is not specific in detailing what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about the lack of clarity regarding parameter values and their selection process, specifically asking for the model parameters for task 1 and the lambda value for the Boltzmann policy. It also questions how these parameters were chosen, suggesting that maximum likelihood estimates were used. However, the comment does not provide any evidence or reasoning to support these claims, leaving the authors without guidance on how to address the issue. The lack of specific examples or references makes the claim 3, as the authors are left to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises specific questions about the lack of clarity regarding parameter values and their selection process, particularly for task 1 and the Boltzmann policy. It asks for the model parameters and the lambda value, as well as how these parameters were chosen, suggesting that maximum likelihood estimates were used. This feedback is 3 as it identifies areas where the paper lacks detail and encourages the authors to provide more information. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or completeness of the paper, such as providing a detailed explanation of the parameter selection process or including a table summarizing the parameters. Without these additional details, the authors are left with a clear indication of what needs to be addressed but without a clear path forward, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Normalization (CBN) is applied to different layers. It asks the authors to provide some insight into why this might be happening. While the comment prompts the authors to explain the observed performance difference, it does not explicitly instruct them on how to address this issue or what changes to make. The action is implicit, as the authors need to infer that they should provide an explanation or justification for the performance difference. However, the comment lacks concrete guidance on how to improve the model or what specific aspects to focus on. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with applying Conditional Batch Norm (CBN) to layer 2 compared to layers 3 and 4, and it asks for an explanation of why this might be happening. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Normalization (CBN) is applied to different layers. It asks the authors to provide some insight into why this might be happening. While the comment prompts the authors to explain the observed performance difference, it does not provide any specific evidence, reasoning, or references to support the claim. The authors are left to infer the reasoning behind the performance deterioration, which may be challenging. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the GuessWhat?! model when Conditional Batch Normalization (CBN) is applied to different layers. It points out that applying CBN to layer 2 in addition to layers 3 and 4 results in a performance deterioration compared to applying it to layers 4 and 3 only. The comment asks the authors to provide some insight into why this might be happening, which is a valuable question for understanding the model\"s behavior. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address this issue or improve their model. While it identifies a potential area for improvement, it does not provide concrete steps or insights that would help the authors enhance their draft. Therefore, the comment is 3, as it highlights a specific area for further investigation but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel or simple patterns by Gu et al. (2019). However, the comment does not explicitly instruct the authors to address this similarity or provide specific guidance on how to improve their draft based on this observation. While the authors might infer that they should discuss or differentiate their spurious features from existing backdoor triggers, the lack of explicit action or detailed guidance makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples of how these triggers have been used in previous work. This allows the authors to understand what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel or simple patterns by Gu et al. (2019). This claim is supported by logical reasoning and references to specific examples, making it 4. The authors can understand the basis of the claim and how it relates to their work, allowing them to address it effectively. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel or simple patterns by Gu et al. (2019). This observation is insightful and could help the authors better understand the nature of their spurious features and how they relate to existing concepts. However, the comment does not offer specific guidance on how the authors might address this similarity or incorporate it into their work. While it provides a valuable insight, it lacks actionable suggestions, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between weak and semisupervised training of the proposed method. It provides specific examples, such as renaming a column in Table 1 to \u201cFully supervised\u201d and suggests a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These instructions are clear and concrete, providing the authors with explicit actions to take. The comment is fully actionable as it offers precise guidance on how to improve the clarity and organization of the paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to clarify the distinction between weak and semisupervised training, suggesting renaming a column and offering a more detailed categorization of training data. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point provides specific suggestions for improving the clarity of the paper, such as renaming a column in Table 1 and offering a more detailed categorization of training data. These suggestions are logical and actionable, as they directly address the need for better organization and understanding of the proposed method. However, the comment lacks references or detailed reasoning to fully substantiate the claims. While the suggestions are clear and provide a path for improvement, the lack of additional evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the clarity of the distinction between weak and semisupervised training of the proposed method. It suggests renaming a column in Table 1 to \u201cFully supervised\u201d and proposes a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These suggestions are specific and provide the authors with concrete steps to improve the organization and understanding of their work. The comment is 4 as it offers detailed guidance that can significantly enhance the clarity and coherence of the paper. However, it could be further improved by including additional examples or references to support the claims, making it even more comprehensive. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or RL is not used. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors would need to infer that they should include these cases in the tables to provide a more comprehensive comparison. The lack of concrete instructions makes the action somewhat vague, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the discrepancy in performance and the missing cases in the tables. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without the dependency tree, and that the two tables do not list the cases where either dependency tree or reinforcement learning is not used. This claim is 3 as it highlights a specific issue in the ablation experiment results, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the missing cases to understand the full context of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either dependency tree or reinforcement learning is not used. This feedback is clear and actionable, as it highlights a potential gap in the experimental results and suggests that the authors should include these cases in the tables for a more comprehensive comparison. By addressing this issue, the authors can improve the clarity and completeness of their experimental analysis, making the comment 4. However, it could be more helpful if it provided specific guidance on how to include these cases in the tables. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It highlights that the results are presented only on the CIFAR10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment does not provide explicit guidance on how the authors should expand their experiments or what specific datasets or model types they should consider. While the action is implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely that they are limited to the CIFAR10 dataset and do not consider other datasets from federated learning benchmarks. The comment provides specific examples of relevant datasets and suggests considering additional works for details on different datasets and model types. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments section is a main weakness of the paper, as the results are presented only on the CIFAR10 dataset and do not consider other datasets from federated learning benchmarks. The comment suggests considering datasets from the LEAF benchmark and recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to infer the need for a more comprehensive evaluation based on the provided information, which limits the verifiability of the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It points out that the results are presented only on the CIFAR10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is 4 as it provides clear guidance on how the authors can enhance the comprehensiveness of their experimental evaluation, which is crucial for addressing the main weakness of the paper. However, it could be more helpful if it included specific suggestions on which datasets or model types to consider. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It implies that the authors need to clarify how these clean manifolds are constructed, particularly when the exemplar manifolds are derived from stochasticity. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It questions how these manifolds are constructed when the exemplar manifolds are derived from stochasticity. However, the comment does not provide any evidence, reasoning, or references to support the claim that the construction of clean manifolds for nonstochastic networks is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the construction of clean exemplar manifolds for nonstochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. It points out a potential inconsistency in the description of how these manifolds are constructed, as the paper mentions both adversarial perturbations and stochasticity in the construction of exemplar manifolds. This feedback is 3 as it identifies a potential area of confusion and encourages the authors to clarify their methodology. However, it could be more helpful if it provided additional context or guidance on how to address this issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the clarity of the notation used in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a specific area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the clarity of notation in the paper, particularly the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the variables S and Xt, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the problem. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment highlights a specific area that could be improved, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks depth and actionable advice, leaving the authors with limited direction on how to improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that INRs operate on a perdatainstance basis, arguing that this is not an advantage and that such a model would be almost useless. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors might infer that they need to reconsider the framing of their argument or provide a more nuanced perspective on the utility of perdatainstance operations. The comment lacks concrete details on how to implement this feedback, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the claim about INRs operating on a perdatainstance basis is true but not an advantage, and that such a model would be almost useless. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR\" is true but argues that it is not an advantage. The comment provides a logical reasoning by suggesting that a model capable of handling only a single timeseries instance is almost useless. However, it lacks specific examples or references to support this claim, making it 3. The authors would need to provide more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper, stating that INRs operate on a perdatainstance basis, and argues that this is not an advantage. The reviewer provides a logical reasoning by suggesting that such a model would be almost useless. While the comment highlights a potential weakness in the paper\"s argument, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out an area that needs clarification or further discussion, but it lacks actionable advice for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the experiments are limited to RoBERTabase and raises concerns about the generalizability of the results to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. It also recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2 in Figure 2. This provides clear and explicit guidance on what needs to be addressed and how to do so, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most of the experiments\" and \"Section 4.1.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of limited experiments, the need to generalize results to other models with learnable APEs, and suggests including more analysis for GPT2, particularly referencing Figure 2. This provides detailed guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and suggests that the results may not be generalizable to other models with learnable APEs. It recommends including more analysis and discussion for models like GPT2, specifically mentioning the inclusion of results for Figure 2. While the comment provides a clear rationale for the suggestion, it lacks specific examples or references to support the claim about the generalizability of the results. However, the reasoning is logical and understandable, making the claim 4.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experiments, noting that most of the experiments are conducted using only the RoBERTabase model. It highlights the concern that the results may not be generalizable to other models that adopt learnable APEs, such as those with different model sizes, objective functions, or architectures. The comment suggests including more analysis and discussion, particularly for GPT2, and requests the inclusion of results for Figure 2. This feedback is clear, actionable, and provides specific guidance on how the authors can address the identified limitation. However, it could be more helpful if it included suggestions for additional experiments or analyses that could further strengthen the paper. Overall, the comment is 4, as it effectively directs the authors to areas for improvement and provides a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not provide explicit guidance on how to conduct this exploration or what specific steps the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to explore generalizability across different architectures and tasks, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment lacks specific examples or references to support the claim that the parameters are only applicable to image data and ViT. Without detailed reasoning or evidence, the claim remains 3, as it is based on an assumption that could be further substantiated with additional information or analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. This feedback is 3 as it points out a potential limitation in the scope of the study and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what additional experiments might be necessary. Overall, the comment offers a valuable insight into the limitations of the current study, but it could be more actionable with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This provides a clear and explicit action for the authors to take, as they know exactly what additional experiments to conduct to strengthen their paper. The comment is concrete, as it specifies the exact area of evaluation and the method to use (WILDS). Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the performance of TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This provides a clear and explicit reference to a specific area of the paper, allowing the authors to accurately identify the part that needs improvement. The comment is also specific, as it specifies the exact benchmark (WILDS) and the type of evaluation (more conditions of natural distribution shift). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should evaluate their TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This claim is 3 as it provides a specific example of a benchmark that could strengthen the paper. However, it lacks detailed reasoning or references to support why this additional evaluation would be beneficial. The authors would need to infer the importance of this suggestion, which could be improved with more explicit justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of TTA methods, specifically noting that using nonstandard benchmarks can break popular TTA methods. It suggests that the authors should consider evaluating their TTA methods on more conditions of natural distribution shift, such as WILDS [9], to strengthen the paper. This feedback is clear and actionable, providing a specific direction for the authors to improve their work. However, it could be more helpful if it included additional suggestions or considerations for the evaluation process. Overall, the comment is 4 as it offers a clear and actionable improvement for the authors to consider."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the use of unlabeled data, noting that the data is perfectly balanced and may not be practical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This comment provides a clear and explicit action for the authors to take, which is to consider using a more realistic setting for their experiments. The suggestion is concrete and offers a specific example of how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"preprocessed Amazon review dataset (Blitzer version)\" and the \"2000 unlabeled data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear rationale for the issue, suggesting that the authors should consider using a more convincing setting as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This provides a specific example of how the authors could address the issue, making the comment 5.", "verifiability_rationale": "The review point claims that the use of unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications because it is perfectly balanced. The reviewer suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This claim is 3 as it provides a logical reasoning for the issue and references a specific example of a more convincing setting. However, it lacks detailed explanation or examples to fully support the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of unlabeled data, specifically noting that the data from the preprocessed Amazon review dataset is perfectly balanced, which may not be practical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This feedback is 4 as it provides a clear and actionable suggestion for the authors to consider, offering a specific example of how to address the issue. However, it could be more helpful if it included additional guidance or suggestions for alternative approaches. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what changes should be made to the paper. The action is implicit and vague, leaving the authors without a clear understanding of how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 removes the modal subset of all instances, which may not be appropriate. However, the comment does not specify which part of the paper this issue is discussed or how it relates to the overall content. The authors cannot confidently determine which section or figure this comment addresses, making it weakly grounded. The comment is specific in that it identifies a potential issue with the contribution of different modalities and instances, but without explicit grounding, the authors are left to infer the relevance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also questions the appropriateness of Equation 3, which removes the modal subset of all instances. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the contribution of different modalities varies. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also questions the appropriateness of Equation 3, which removes the modal subset of all instances. However, the comment does not provide specific guidance or suggestions on how to address this issue or what changes should be made to the paper. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer the implications and make their own decisions, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for the target domain \tau is unlabeled, which contrasts with the original MFDA paper (Yue et al., 2021a), where the target data is unlabeled. The comment questions whether unlabeled data from source domains is used during training, as in the original paper. This feedback is explicit and provides a clear action for the authors to take: they should clarify the notation and address the discrepancy with the original paper. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the MFDA setting, particularly the confusion regarding the notation for the target domain \tau and the use of unlabeled data from source domains during training. This provides a clear direction for the authors to address the problem. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the description of the MFDA setting in the first paragraph of the Method Section, specifically regarding the notation for the target domain \tau and the use of unlabeled data from source domains during training. While the comment identifies a potential inconsistency with the original MFDA paper (Yue et al., 2021a), it does not provide detailed reasoning or examples to fully support the claim. The lack of specific evidence or references makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue in the description of the MFDA setting within the Method Section, particularly concerning the notation for the target domain \tau and the use of unlabeled data from source domains during training. It highlights a discrepancy with the original MFDA paper (Yue et al., 2021a), which could confuse the authors. The comment is clear and actionable, providing a direct suggestion for the authors to clarify the notation and address the inconsistency. However, it could be more helpful if it offered additional guidance on how to improve the clarity of the description or suggested specific ways to align the paper with the original work. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that epochwise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It proposes specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. However, the comment does not provide explicit guidance on how the authors should implement or conduct this analysis. While it offers a direction for improvement, the lack of detailed instructions or examples leaves the authors uncertain about how to proceed. Therefore, the comment is 3, as it provides a general idea but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis, especially for finite sum settings, could provide insights into the behavior of optimization algorithms. It provides specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. This guidance is clear and specific, as it outlines potential areas for further analysis and investigation. However, the comment does not explicitly mention which part of the paper this analysis should be conducted in, making it weakly grounded. Despite this, the specific suggestions for analysis and investigation make the comment somewhat specific. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis, especially for finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It proposes specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion or how to implement it. As a result, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment suggests that epochwise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It proposes specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. While the comment offers a direction for improvement by highlighting potential areas for further investigation, it lacks specific guidance on how the authors should conduct this analysis or what specific aspects of the algorithms to focus on. The feedback is 3 as it provides a general idea of what could be explored but does not offer detailed instructions or examples to enhance the authors\" understanding and implementation of the suggested analysis. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the issue. It questions the annotators\" consideration of local regulations and their impact on zeroshot crosscountry classification. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the distinction between the two types of speech. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Paper Summary,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. The comment is specific in detailing what needs to be addressed, including the need for clearer differentiation and clarification regarding the impact of local regulations on annotations and classification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the distinction between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. It also questions the role of local regulations in the annotations and their impact on zeroshot crosscountry classification. However, the comment lacks specific examples or references to support the claim that the distinction is difficult to make or that local regulations are not adequately considered. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the differentiation between derogatory and exclusionary extreme speech, which is a crucial aspect of the paper. It provides an example from the sample data file to illustrate the confusion, making the feedback more concrete and actionable for the authors. However, the comment could be more helpful if it offered suggestions on how to improve the distinction or clarify the role of local regulations in the annotations. Despite this, the feedback is 4 as it directs the authors to an area that needs attention and provides a clear example to guide their revision efforts."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a critical limitation in the study of sequential ensembling, specifically the lack of consideration for noise accumulation in homomorphic encryption. It points out that this omission prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to sequential ensembling and noise accumulation in the context of homomorphic encryption. It highlights a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that for sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. It argues that this omission prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument. Without detailed reasoning or evidence, the claim remains 3, as it provides a general observation but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the study of sequential ensembling, particularly the lack of consideration for noise accumulation in the context of homomorphic encryption. It highlights that this omission prevents the use of even single deep neural networks on homomorphically encrypted data, which is a critical issue for the field. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve their draft. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it provides a clear observation but lacks depth and actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison to assess the impact of mean teacher regularization. The comment is specific in its suggestion and provides a concrete action for the authors to implement, making it 5.", "grounding_specificity_rationale": "The comment suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit reference to a specific part of the paper, allowing the authors to accurately identify the section where the comparison should be made. The comment is specific in its suggestion, detailing what needs to be added to the graph to facilitate a comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3 to compare its performance. This claim is 3 as it provides a specific suggestion for comparison, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the reasoning behind this suggestion, which could be improved by providing more context or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the inclusion of a learning curve for a model without mean teacher or pi regularization in Figure 3. This addition would allow the authors to compare the performance of their model with and without these regularizations, providing valuable insights into the impact of these techniques. The comment is clear, actionable, and directly addresses a potential area for further analysis, making it 4. However, it could be more helpful if it included additional guidance on how to interpret the results or what specific aspects of the learning curve to focus on. Overall, the feedback is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the objective equation. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proposed objective equation, which is mentioned in line 128. It highlights that the equation requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. However, the comment does not specify what the authors should do to address this issue or how it relates to prior work, such as AlignFlow. While the authors can infer that the issue pertains to the objective equation, the lack of explicit guidance makes the comment weakly grounded. The comment is also specific in identifying the need for a discussion on the number of parameters compared to prior work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed objective equation requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S, and it notes that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it leaves room for the authors to question the validity of the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \u03c6 and the shared model \u03b8_S. It highlights that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. This feedback is 3 as it points out a potential area for improvement in the paper, specifically regarding the clarity and depth of the discussion on the objective equation. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or expanded on the comparison with prior work. Overall, the comment offers a clear direction for improvement, but it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between equations 4 and 3, specifically whether the improvement of the designed solutions in Table 5 is significant. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not offer explicit guidance on how the authors should address this issue or what specific actions they should take to improve the significance of their results. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the relationship between equations 4 and 3, specifically questioning whether the improvement of the designed solutions in Table 5 is significant. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not specify which part of the paper contains the equations or the table, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of marginal improvement, it lacks grounding as it does not clearly identify the relevant parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between equations 4 and 3 and provides an example of marginal improvement in the results presented in Table 5. It questions whether the improvement of the designed solutions is significant, particularly on the OfficeHome dataset. However, the comment lacks detailed reasoning or references to support the claim that the improvement is marginal. It does not provide specific examples or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a question about the relationship between equations 4 and 3, specifically questioning the significance of the improvement in the designed solutions presented in Table 5. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This feedback highlights a potential area for improvement in the paper, suggesting that the authors should consider whether the observed improvements are substantial enough to warrant further discussion or analysis. However, the comment lacks detailed guidance on how the authors might address this issue or what specific actions they should take to strengthen their results. While it identifies a potential weakness, it does not offer comprehensive suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues related to the paper\"s content. First, it notes that the range of ID and OOD does not change much after sparsification, as seen in Figure 4. Second, it points out that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not change much after sparsification, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much after sparsification, as seen in Figure 4, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment lacks specific examples or references to support the claim that these conditions are crucial for DICE. Without detailed reasoning or evidence, the claim is difficult to verify, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the lack of change in the range of ID and OOD after sparsification, as shown in Figure 4, and the insufficient discussion of Lemma 2\"s requirements, particularly the need for approximately identical means for DICE. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. While the feedback highlights areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The comment is 3 as it points out specific weaknesses but does not offer comprehensive advice or detailed steps for improvement, leaving the authors with a clear direction but limited actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs. While the question about the integration of environments is clear and specific, the suggestion to break the bolded sections into paragraphs is also concrete and provides a clear action for the authors to take. The comment is explicit and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs. While the question about the integration of environments is clear and specific, the suggestion to break the bolded sections into paragraphs is also concrete and provides a clear action for the authors to take. However, the comment does not explicitly mention page 6 or the bolded sections, making it weakly grounded. The authors can infer that it refers to a specific part of the paper, but the lack of explicit mention reduces the grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs. While the question about the integration of environments is clear and specific, the suggestion to break the bolded sections into paragraphs is also concrete and provides a clear action for the authors to take. However, the comment lacks detailed reasoning or references to support the claim that breaking the sections into paragraphs would improve readability. The authors are left to infer the benefit, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs to improve readability. While the comment identifies a potential issue with the presentation of the text, it does not provide specific guidance or suggestions on how to address the problem. The feedback is 3 as it points out an area for improvement, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, including questions about the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to strengthen their experiments, include missing baselines, and discuss limitations and societal impacts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the strength and fairness of the experiments, questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. However, the comment does not specify which part of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several concerns about the strength and fairness of the experiments, specifically questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out important aspects that need attention, but it could be more comprehensive with additional suggestions or examples to guide the authors in enhancing their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the temperature \u03c4 is missing from the derivation and suggests that it should be shown rigorously or mentioned in the paper. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown rigorously or mentioned in the paper. This claim is 3 as it points out a specific issue in the derivation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the missing information and understand why it is important to include the temperature \u03c4. However, the comment provides a clear direction for improvement, making it 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the omission of the temperature \u03c4 in the derivation from Eqn. 3 to Eqn. 4. It suggests that the temperature should be shown rigorously or mentioned in the paper to address this gap. This feedback is clear and actionable, providing the authors with a specific direction to improve the rigor and completeness of their work. By addressing this issue, the authors can enhance the clarity and accuracy of their derivation, making the paper more robust and understandable. Therefore, the comment is 5 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a citation on differential privacy should be added to line 156 to benefit the reader. The comment is explicit in its suggestion to include a citation, and it provides a specific example of where the citation should be added. This allows the authors to directly apply the action by adding the citation at the specified line. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. This feedback is actionable and provides a clear path for the authors to enhance their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy to line 156. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this addition would be beneficial. The authors may infer that adding a citation would enhance the reader\"s understanding, but the comment does not provide a clear rationale or evidence to justify the claim. Therefore, the comment is 3, as it offers a suggestion but lacks sufficient justification.", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests adding a citation on differential privacy to line 156. This addition would enhance the reader\"s understanding and provide context for the discussion. However, the comment could be more helpful if it offered additional guidance on how to choose the appropriate citation or why it is relevant. Despite this, the feedback is clear and provides a valuable suggestion for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two distinct points. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This critique is 3 as it provides a specific example of a potential overstatement and suggests that the assumption is natural for many settings. However, it does not offer concrete guidance on how to address this issue or what specific assumptions need to be clarified. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to an inequality on line 227. This is a clear and actionable critique that provides specific feedback on a factual error, allowing the authors to correct the issue. Overall, the comment is 3 due to the clear feedback on a factual error, but the critique of the claim is less actionable due to the lack of specific guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the claim about \"significant additional assumptions\" and the error in the inequality sign. This provides clear guidance on what aspects of the paper require attention and how to address them. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point contains two claims: one questioning the claim that \"this methodology requires significant additional assumptions\" and another pointing out an error in the sign of an inequality. The first claim is 3 as it provides a specific example of a potential overstatement, suggesting that the assumption is natural for many machine learning settings. However, it lacks detailed reasoning or references to support the claim fully. The second claim is 5 as it points out a factual error in the sign of an inequality, providing a clear and logical basis for the critique. Overall, the comment is 4 due to the clear justification for one claim and the factual nature of the other, but it could be strengthened with more detailed reasoning for the first claim.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This critique is 3 as it challenges the authors to reconsider the significance of their assumptions and provides a specific example of a common assumption in machine learning. However, it does not offer detailed guidance on how to address this issue or what specific assumptions need to be clarified. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to an inequality on line 227. This is a clear and actionable critique that allows the authors to correct a factual error in their paper. Overall, the comment is 3 as it provides one actionable suggestion and raises a critical point that requires further consideration, but it could be more comprehensive with additional guidance on addressing the assumption concern."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific guidance or suggestions on how the authors should address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to resolve the identified issues. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is 1 as it does not provide specific references or sections of the paper that need attention. Additionally, it lacks specificity in detailing the nature of the writing issues, such as examples of unclear sentences or specific grammatical errors. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific examples or references to support these claims. Without detailed examples or references, the authors may find it challenging to understand the nature and extent of the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it lacks specific details or suggestions on how the authors might address these issues. While it highlights areas for improvement, the comment does not provide actionable guidance or examples of how to correct the identified problems. This limits the authors\" ability to effectively improve their draft, making the comment 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit instructions for the authors to address specific issues in their figures and tables. It instructs them to run experiments for untrained networks and add these results to the figures and Table 1. Additionally, it requests clarification on whether the figures show results for networks trained on random data or unaltered data, and whether the nonrandom data is normalized. The comment also suggests showing examples of random data in the appendix. These instructions are clear and provide concrete guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3) mentioned above,\" which implies a specific part of the paper being addressed. It also specifies what needs to be addressed, such as running experiments for untrained networks and adding results to figures and Table 1. The request for clarification regarding random data and normalization further specifies the issues to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and additional information regarding the figures and tables, specifically about the training of networks and the normalization of data. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the figures and tables, instructing the authors to include results for untrained networks and to clarify the training of networks and the normalization of data. It also suggests showing examples of random data in the appendix. This detailed guidance helps the authors address specific issues and improve the clarity and completeness of their presentation. The comment is 4 as it offers clear directions for improvement, though it could be further expanded to include additional suggestions or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. It does not provide an explicit action or suggestion for the authors to take, such as clarifying the definition of \"100 steps\" or providing additional context. The comment is vague and lacks concrete guidance on how the authors should address this issue. Therefore, it is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a factual question that requires clarification but does not contain any subjective opinions or claims that need verification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a clear and actionable feedback that helps the authors clarify a potential ambiguity in their methodology or experimental setup. By identifying this specific point of confusion, the comment provides a clear direction for the authors to improve the clarity and precision of their description. However, the comment could be more helpful if it suggested alternative interpretations or provided additional context to help the authors understand the significance of this clarification. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the improvement over previous methods is small, around 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The authors are advised to repeat the experiments and conduct statistical significance analysis. However, the comment does not provide explicit guidance on how to repeat the experiments or conduct the statistical analysis, leaving the authors to infer the necessary steps. The suggestion to reject the paper is a direct action, but the lack of detailed guidance on implementation makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the improvement over previous methods, noting that it is small, around 0.2%1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis. However, the comment does not specify which part of the paper contains the results in Table 1 and Fig. 5, making it weakly grounded. The comment is specific in detailing the issues with the results and suggesting improvements, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis. However, the claim lacks specific examples or references to support the assertion about the small improvement or the missing statistical information in the figures. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the improvement over previous methods is marginal, around 0.2%1%. It also points out that the results in Table 1 and Fig. 5 lack the reporting of mean and standard deviation, making it difficult to assess the statistical significance of the findings. The comment suggests repeating the experiments and conducting statistical significance analysis, which are actionable steps for the authors to take. However, the comment could be more helpful if it provided specific guidance on how to conduct the statistical analysis or suggested alternative methods for evaluating the significance of the results. Despite this, the feedback is 4 as it directs the authors towards improving the rigor and clarity of their experimental results. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach section is missing in the main paper, which is a clear indication of an action the authors should take. It also suggests that the supplementary material should be used as additional information rather than an extension of the paper. This feedback provides a direct and concrete action for the authors to improve their draft by ensuring all necessary sections are included and properly integrated. The comment is fully actionable as it clearly specifies what needs to be addressed and how to do it. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part being addressed. It also specifies that the supplementary material should be used as additional information rather than an extension of the paper, providing clear guidance on what needs to be addressed. This level of detail ensures that the authors understand exactly what part of the paper requires revision and how to do it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The comment lacks detailed reasoning or evidence, which could be improved by providing specific examples or references. Therefore, the claim is considered 2, as it is somewhat supported but lacks key elements for full verification.", "helpfulness_rationale": "The review comment identifies a significant issue with the draft, specifically noting the absence of an \"approach section\" in the main paper. It also suggests that the supplementary material should be treated as additional information rather than an extension of the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it included suggestions for how to integrate the supplementary material or clarify its role in the paper. Overall, the comment is 4 as it highlights a critical oversight and offers a clear path for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should revise the statement or what specific changes are needed to make it more robust. While the authors can infer that they should strengthen the statement, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not specify which part of the introduction contains this statement, making it difficult for the authors to pinpoint the exact area that needs revision. While the authors can infer that the critique applies to the introduction, the lack of explicit grounding makes the comment weakly grounded. The comment is specific in its critique of the statement\"s weakness, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, suggesting that it is widely accepted that backpropagation is biologically implausible. This claim is 3 as it provides a logical reasoning based on the common understanding of backpropagation\"s biological plausibility. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the statement regarding the biological plausibility of backpropagation is too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it provides a direct critique and suggests a more robust statement. However, it could be more helpful if it offered specific guidance on how to revise the statement or what evidence could be included to strengthen the argument. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment identifies a potential issue with the paper, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The suggestion is implicit, as it implies that the authors should explore the connection between generalization bounds and the constructions of ReLU networks. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of the connection between memorization and generalization, the absence of explicit grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. The comment suggests that the paper does not clearly address this connection, implying that the authors should explore the relationship between generalization bounds and the constructions of ReLU networks. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. It does not provide a clear explanation of why this is a significant issue or how it could be addressed. As a result, the claim is 3, as it is based on a logical inference but lacks sufficient evidence to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. This is a significant concern that could impact the paper\"s conclusions. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. It does not provide specific advice on what experiments or analyses could be conducted to clarify the connection between memorization and generalization. Without concrete recommendations or a detailed discussion of potential solutions, the comment is 3 as it highlights a crucial area for improvement but does not provide the authors with a clear path forward. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should mention recent findings on untrained neural networks (NNs) in the context of OOD experiments, particularly in imaging. It also recommends comparing the current method with these approaches. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to add this information or compare their method with the suggested class of methods. The action is implicit and somewhat vague, as the authors need to infer how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments\" and \"imaging in the recent few years,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests mentioning recent findings on untrained NNs and comparing the current method with them, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should mention recent findings on untrained neural networks (NNs) in the context of OOD experiments, particularly in imaging, and suggests comparing the current method with these approaches. The comment provides a specific suggestion for improvement, indicating that the authors should consider incorporating this information. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the need for comparison and the relevance of the suggested methods, which could be improved with more explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides valuable feedback by highlighting the interesting aspect of the trained network\"s strong OOD generalization. It suggests that the paper should acknowledge recent findings on untrained neural networks (NNs) in the context of OOD experiments, particularly in imaging, and recommends comparing the current method with these approaches. This feedback is clear and actionable, as it guides the authors to enhance the paper\"s context and relevance by incorporating recent advancements in the field. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to compare the methods. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, making the motivation of Algorithm 1 unclear. However, it does not provide explicit guidance on how the authors should reformulate the subproblem or how this reformulation would clarify the motivation of Algorithm 1. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proxlinear subproblem in Eq.(1) and suggests that it can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This provides a clear and specific reference to the part of the paper being discussed, allowing the authors to accurately identify the section being addressed. The comment is fully grounded as it explicitly mentions the equation and algorithm, and it is specific because it details the suggestion for reformulation and its implications for the motivation of Algorithm 1. Therefore, this comment is classified as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This claim is 3 as it provides a specific suggestion for reformulation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to understand the implications of this reformulation to fully grasp the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem in Eq.(1) could be reformulated using the conjugate function to align with the subproblem in Algorithm 1. This observation raises a concern about the clarity of the motivation, which could be a valuable point for the authors to address. However, the comment lacks specific guidance on how the authors might reformulate the subproblem or how this reformulation would enhance the motivation of Algorithm 1. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to provide an explanation for the degradation in performance of the FBN results when additional information is included. While it prompts the authors to address this issue, it does not explicitly instruct them on how to do so or provide specific guidance on what aspects to consider. The action is implicit, as the authors need to infer that they should analyze and explain the performance degradation. However, the comment lacks concrete details on how to approach this analysis, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to provide an explanation for the degradation in performance when additional information is included, which is a clear and actionable request. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the degradation in FBN results when additional information is included. However, it does not provide any specific reasoning, examples, or references to support why this degradation might occur. The comment lacks detailed justification or explanation, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results, noting that the performance degrades when additional information is included. This observation is clear and highlights a potential area for further investigation or clarification. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their results. While it points out a problem, it does not provide detailed insights or recommendations for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific sections of the paper that are difficult to read due to a lack of clear explanation of previous approaches. It provides examples of unclear sentences, such as the one in line 43 regarding the conversion of a stacked LSTM to a sequential LSTM, and the one in line 96 about \"our lower hierarchical layers zoom in time.\" While the comment highlights areas needing clarification, it does not provide explicit instructions on how to improve the explanation or address the specific questions raised. The action is implicit, as the authors need to infer that they should clarify the explanations and provide more detailed descriptions. However, the lack of concrete guidance on how to address these issues makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of unclear sentences and questions that need clarification, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of \"our lower hierarchical layers zoom in time.\" This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises specific questions about the clarity of certain sections in the paper, particularly regarding the conversion of a stacked LSTM to a sequential LSTM and the meaning of \"our lower hierarchical layers zoom in time.\" However, it does not provide any evidence, reasoning, or references to support these claims. The comment lacks detailed explanations or examples that would help the authors understand the issues being raised. As a result, the claim is not verifiable, and the comment does not provide sufficient guidance for the authors to address the concerns effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies specific sections of the paper that are difficult to read due to a lack of clear explanation of previous approaches. It provides concrete examples of unclear sentences, such as the one in line 43 regarding the conversion of a stacked LSTM to a sequential LSTM and the one in line 96 about \"our lower hierarchical layers zoom in time.\" This feedback is 4 as it highlights areas where the authors need to improve the clarity and readability of their paper. However, it could be more helpful if it provided suggestions on how to clarify these sections or address the specific questions raised. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper argues that the proposed method finds flat minima but lacks an analysis of flatness. It highlights that minimizing the averaged loss across noiseinjected models does not guarantee flatness. The comment suggests that to claim the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noiseinjected models after training is required. This provides a clear and explicit action for the authors to take, which is to conduct an analysis on the losses of the noiseinjected models. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the analysis about flatness is missing, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue: the paper argues that the proposed method finds flat minima, but the analysis about flatness is missing. The comment further elaborates on the issue by explaining that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima, and it suggests that an analysis on the losses of the noiseinjected models after training is required. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the paper argues that the proposed method finds flat minima but lacks an analysis of flatness. It highlights that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima. The comment suggests that to claim the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noiseinjected models after training is required. This claim is 4 as it provides a logical reasoning for why the analysis is missing and suggests a specific area for improvement. However, it could be more robust with additional references or examples to support the claim. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that while the paper argues that the proposed method finds flat minima, it lacks an analysis of flatness. The reviewer provides a clear explanation of why this analysis is missing, specifically noting that minimizing the averaged loss across noiseinjected models does not guarantee flatness. The comment suggests that to claim the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noiseinjected models after training is required. This feedback is 5 as it provides a specific and actionable suggestion for the authors to address the gap in their analysis, enhancing the rigor and depth of their work. The comment is detailed and constructive, guiding the authors on what additional analysis is needed to strengthen their claims."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It also recommends improving the presentation, possibly by referencing the supplement. The comment further suggests replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft. The actions are clear and detailed, allowing the authors to understand exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation, possibly by referencing the supplement. The suggestion to replace natural language descriptions with notation and add breakout diagrams to illustrate attention mechanisms is also provided. However, the comment does not specify which part of section 4 is particularly challenging or where the complexity lies, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the suggestions for improvement, the lack of grounding makes it challenging for the authors to fully understand the scope of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation, possibly by referencing the supplement, and suggests replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment provides some guidance on how to improve the presentation, it lacks specific examples or detailed reasoning to fully substantiate the claim that the model is complicated or that the presentation requires careful reading. The suggestions for improvement are somewhat vague and could benefit from more detailed explanations or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the model and suggests ways to improve its presentation in section 4. It recommends replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms, which could enhance clarity and understanding. While the comment provides specific suggestions for improvement, it could be more helpful if it included additional guidance on how to effectively implement these changes or why these improvements are necessary. Overall, the feedback is 4 as it offers actionable advice, but it could be more comprehensive to fully assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a specific issue with the figure, it does not provide explicit guidance on how to address the question or what changes should be made to the figure. The action is implicit, as the authors would need to infer that they need to clarify the source of the test data and the presence of a ground truth. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line in Figure 3, asking about the source of the test data and whether there is a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. This is a factual question that requires clarification but does not contain any subjective opinions or claims that need verification. The comment is a normal statement, as it seeks to understand the source of the test data and the presence of a ground truth, which is essential for the authors to address. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, questioning the source of the test data and the presence of a ground truth. This feedback is clear and actionable, as it directs the authors to clarify the figure\"s content and ensure that the data is properly explained. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific ways to improve the clarity of the figure. Despite this, the feedback is 4 as it highlights a critical area for improvement, allowing the authors to enhance the clarity and completeness of their paper. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the goal of the paper, suggesting that the authors should clarify whether the work aims to develop a foundation model or to demonstrate a proof of concept. It also points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the method\"s benefit over these existing approaches. The comment implies that the authors should provide a clearer explanation of their goal and demonstrate the utility of their method through additional experiments or justifications. However, the comment does not explicitly instruct the authors to address these issues, leaving the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically mentioning the existence of DAS earthquake detectors and the lack of comparison or justification against them. It also suggests clarifying whether the work aims to develop a foundation model or demonstrate a proof of concept and recommends showing or justifying future useful applications. However, the comment does not specify which part of the paper discusses the goal or the comparison with existing methods, making it weakly grounded. The specificity of the comment is good as it clearly identifies the issues that need to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the method\"s benefit over these existing approaches. The comment suggests that the authors should clarify whether the work aims to develop a foundation model or demonstrate a proof of concept and provide additional evidence or justification. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to provide more evidence or justification to address the concern effectively.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s goal and the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors should clarify whether the work aims to develop a foundation model or demonstrate a proof of concept and provide additional evidence or justification for the benefit of their method over existing approaches. This feedback is 4 as it provides clear guidance on what needs to be addressed to strengthen the paper\"s contribution and impact. However, it could be more helpful if it included specific suggestions or examples of how to demonstrate the benefit of the method. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what the ablation studies of MCT without the adaptive metrics entail. While the questions prompt the authors to investigate and clarify these aspects, they do not provide explicit instructions on how to address them or what specific actions to take. The authors are left to infer that they need to align the results and conduct ablation studies, but without concrete guidance on how to do so, the feedback remains somewhat vague. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment raises two questions regarding the results presented in Table 6 and Table 1, specifically questioning why the results are not aligned and what the ablation studies of MCT without adaptive metrics entail. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections being addressed. The comment is specific in its questions but lacks grounding as it does not provide clear references or context for the tables. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the alignment of results in Table 6 with Table 1 and the relevance of ablation studies for MCT without adaptive metrics. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, lacking any assertion or guidance that would need to be substantiated. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises two questions regarding the alignment of results in Table 6 with Table 1 (MCTpair) and the relevance of ablation studies for MCT without adaptive metrics. While these questions highlight potential areas of concern or confusion, they do not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it identifies areas that need clarification, but it lacks actionable advice or detailed explanations, leaving the authors with limited direction on how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the paper. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the paper need to be addressed to incorporate this idea. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126\" and the section \"Further Questions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the paper. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it aligns with the paper\"s content. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the paper. However, it lacks specific guidance on how to implement this suggestion or what aspects of the paper need to be addressed to incorporate this idea. The comment is vague and does not provide actionable feedback, making it 2. The authors are left without clear direction on how to improve their draft based on this feedback. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It provides examples of where these definitions are missing, which helps the authors understand the specific areas that need clarification. However, the comment does not offer explicit guidance on how the authors should define these terms or where to place the definitions. While the action is somewhat explicit, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific instances in the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation, which provides clear guidance on what needs to be addressed. The inclusion of references to specific papers further enhances the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined, specifically mentioning \"NE\" on L73 and the superscript notation in Eq 6, which is only defined later in the paper. The comment provides examples of where these definitions are missing, such as L166. However, it does not offer specific examples or detailed reasoning to fully support the claim. The lack of detailed explanation or references makes it 3, as the authors can infer the need for clarification but may require additional context to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. By pointing out these areas, the comment provides the authors with clear feedback on where the paper could be improved for clarity and understanding. However, the comment could be more helpful if it offered suggestions on how to define these terms or where to place the definitions for better readability. Overall, the feedback is 3 as it highlights important areas for improvement, but it lacks depth and actionable guidance, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, suggesting that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This implies that the authors should revise their statement to accurately reflect the capabilities of the Walkman algorithm. Second, the comment points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which could lead to confusion for the readers. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to revise the statements or clarify the references. The actions are somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, namely the Related Work section (Page 2, second paragraph) and Section 3, first paragraph. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed feedback on the accuracy of a statement regarding the Walkman algorithm and the clarity of a reference, offering concrete suggestions for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point contains two claims. The first claim critiques the accuracy of a statement regarding the related work, specifically mentioning the Walkman algorithm and its solutions using ADMM. This claim is 3 as it provides a specific example of a discrepancy in the paper\"s description, allowing the authors to verify the claim by examining the cited work. The second claim points out a lack of clarity in a reference in Section 3, first paragraph, which is also 3 as it highlights a potential issue with the paper\"s referencing. Overall, the comment is 3, as it provides some justification but lacks detailed reasoning or references to fully support the claims.", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, pointing out that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This feedback is valuable as it helps the authors refine their claims and ensure accuracy. Second, the comment highlights a lack of clarity in a reference in Section 3, first paragraph, where the term \"it\" is used without a clear reference, which could lead to confusion. While the comment identifies areas for improvement, it could be more helpful if it provided specific suggestions on how to revise the statements or clarify the references. Overall, the comment is 3, as it offers actionable feedback but could be more comprehensive in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is fully actionable because it is explicit and provides detailed guidance on how to implement the suggested changes. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results being reported on the dev set instead of the test set, and it suggests presenting average results on the test set with error bars. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it suggests a specific improvement to the presentation of results, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would need to infer the need for such improvements based on the feedback, which could be more effective with additional justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Tables 1 and 2, noting that the best results are reported on the dev set despite hyperparameter search and model selection also being performed on the dev set. This is a valid concern as it questions the robustness and generalizability of the findings. The comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds, which is a constructive and actionable suggestion. By providing this feedback, the reviewer offers the authors a clear direction for improving the clarity and reliability of their results. Therefore, the comment is 4, as it addresses a specific weakness and provides actionable guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. While the comment explicitly asks for these details, it does not provide any guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors without clear instructions on how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any additional context, reasoning, or references to support the need for these details. The questions are clear and specific, but the lack of supporting evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve their draft. While the questions are clear and specific, the lack of actionable feedback limits the comment\"s helpfulness. Therefore, the comment is rated as 2, as it identifies areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this approach differs from Figure 4 due to the coadaptation between the discriminator and the generator, which might lead to a local optimum. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to train the discriminator. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the need to train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias. This provides clear guidance on how the authors should proceed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that training a discriminator on generations from the learned model is needed to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this approach differs from Figure 4 due to the coadaptation between the discriminator and the generator, which might lead to a local optimum. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. The absence of clear justification or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the claim of reducing exposure bias requires further validation through training a discriminator on generated data, similar to Figure 1. It also highlights a difference between this approach and Figure 4, explaining that the discriminator is coadapting with the generator, which might lead to a local optimum. This feedback is clear and actionable, as it provides a specific suggestion for improvement and highlights a potential issue with the current methodology. However, it could be more helpful if it included additional guidance on how to implement the suggested training or what specific metrics to use for validation. Overall, the comment is 4, as it offers valuable insights and actionable feedback that the authors can use to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the organization and formatting of the prompts, it does not provide explicit guidance on how to improve the organization or formatting. The authors are left to infer that they need to reorganize the prompts and adjust the formatting to prevent sentences from being squeezed. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on how to implement the changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the organization of the prompts and the formatting of the sentences, providing clear guidance on what needs to be improved. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the formatting of the prompts, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for improvement but are not provided with specific guidance or references to support the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Table 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides the authors with a specific area to improve the formatting of their paper. However, the comment could be more helpful if it offered suggestions on how to reorganize the prompts or adjust the formatting to prevent sentences from being squeezed. While the feedback is valuable, it lacks depth and could be expanded to provide more comprehensive guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights issues with the clarity of the figures, specifically mentioning that Figure 2 is confusing due to the relationship between its subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should clarify the relationships between the subfigures and label the missing modules. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on implementation. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the figures, specifically mentioning Figure 2 and pointing out issues with the relationship between subfigures and the lack of labels for certain modules. However, it does not specify which part of the paper the figures are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the relationships between subfigures and labeling missing modules. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning confusion in Figure 2 due to the relationship between subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references, the authors are left to question the validity of the feedback, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the figures, particularly in Figure 2, where the relationship between subfigures is confusing and certain modules are not labeled. This feedback is clear and actionable, as it provides the authors with specific areas to improve the presentation of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or labeling of the figures, such as proposing specific design changes or providing examples of clearer labeling practices. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It also points out that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. The authors are directed to consider and address these concerns, making the comment 5.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear direction for the authors to address these concerns. However, the comment does not specify which part of the paper discusses these design choices or how they are controlled, making it weakly grounded. The specificity of the comment is good as it clearly identifies the issue and asks for clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of perplexity as a measure of semantic information retention after finetuning, questioning its relevance to domain drift. It asks how such factors are controlled, which implies a need for clarification and further explanation. However, the comment lacks specific examples or references to support the claim that perplexity is insufficient for capturing domain drift. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for discussion but lacks depth. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perplexity as a measure of semantic information retention after finetuning, specifically questioning its relevance to domain drift. It asks how such factors are controlled, which provides a clear direction for the authors to address these concerns. However, the comment could be more helpful by offering specific suggestions or examples of how to control for domain drift or by suggesting alternative measures that might be more appropriate. While it prompts the authors to consider these aspects, it lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of longcontext language models. It mentions specific areas, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The comment is clear and specific, offering concrete guidance on what needs to be included in the Related Work section. This allows the authors to directly address the feedback and improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the section by discussing specific methods and their limitations, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail helps the authors understand exactly what needs to be added or improved in the Related Work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of longcontext language models. It suggests including specific methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The claim is wellsupported by specific examples and references, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the Related Work section. It identifies a significant area for improvement by noting the lack of detail and suggesting specific methods and their limitations that should be included. The references provided, such as [1, 2, 3, 4, 5, 6, 7], offer concrete examples of existing approaches that the authors could incorporate to enhance the comprehensiveness of the Related Work section. This detailed guidance empowers the authors to significantly improve the depth and relevance of their paper, making the comment highly valuable. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors should improve them. The comment lacks concrete actions or suggestions, leaving the authors without a clear path to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to address these issues. The authors cannot confidently determine which sections or points require clarification, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the writing are unclear or how the authors should improve them. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it lacks specific details or actionable feedback on which aspects of the writing are unclear or how the authors can address these issues. The comment is vague and does not provide guidance on what needs to be improved or how the authors can enhance the clarity of their paper. As a result, it is 2, as it offers a general direction but lacks depth and specificity to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing and annotations in the paper are difficult to follow, but it does not provide any specific guidance or suggestions on how to improve the writing or annotations. The authors are left without any actionable steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment is not specific, as it does not detail what aspects of the writing or annotations are hard to follow. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are \"poor\" and \"hard to follow.\" However, it does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the writing and annotations in the paper, specifically noting that they are \"poor\" and \"hard to follow.\" However, it lacks specificity and does not provide any suggestions or guidance on how the authors might improve the clarity or readability of their writing or annotations. Without actionable feedback or detailed examples, the authors may find it difficult to address the issue effectively. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the results presented in Table 2. The first question asks why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method. The second question inquires about the discrepancy in F1 scores between the overall setting and individual types in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the performance of the proposed method and the discrepancy in F1 scores. This provides clear guidance on what aspects of the results require further explanation or analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the results presented in Table 2, specifically regarding the number of evaluation metrics achieving SOTA performances and the discrepancy in F1 scores between the overall setting and individual types. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies specific areas in the results that require further explanation or clarification. It questions the performance of the proposed method in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. Additionally, it highlights a discrepancy in F1 scores between the overall setting and individual types in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment points out these issues, it does not provide detailed guidance or suggestions on how the authors might address these concerns or improve their results. The feedback is 3 as it directs the authors to specific areas that need attention, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this incremental nature or how they could improve upon it. Without specific suggestions or guidance, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not specify which part of the paper this comment is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what needs to be addressed. Additionally, the comment is vague and does not provide specific suggestions or guidance on how to improve the solution. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. While it identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this incremental nature or enhance their solution. The comment is vague and does not provide actionable feedback that would empower the authors to make meaningful improvements to their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which figures to revise or how to add the scatter plot. While the action is somewhat inferred, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not specify which parts of the paper these figures are located in, making it weakly grounded. The suggestion to highlight best results in tables is also vague and lacks specific guidance on how to implement it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The suggestion to highlight best results in tables is also vague and lacks detailed guidance. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or depth to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies areas for improvement in the results presentation, specifically mentioning the ambiguity of the yaxis labels in Figures 2 and 3 and the absence of runtime representation. It suggests a scatter plot with runtime and performance axes as a way to enhance the reader\"s understanding and interpretation of the results. Additionally, it proposes highlighting the best results in tables, which could improve clarity. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific steps or examples. While it provides some actionable feedback, it could be more helpful with additional details or suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the setting, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique, leaving them uncertain about how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the \"Unsupervised Online Adaptation\" setting, specifically questioning whether the inclusion of labels in the training set aligns with the definition of unsupervised learning. This critique is clear and provides a specific point of concern that the authors should consider. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what changes could be made to the setting. While it highlights a potential weakness, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are presented in a convoluted manner and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. It also notes that the reason for this presentation is unclear. While the comment identifies a potential issue with the clarity of the results and the omission of safety violations, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the presentation and include the safety violations in their results. This lack of explicit action makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results being presented in a convoluted way and specifically points out the omission of safety violations in the first 1000 episodes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the convoluted presentation of results and the disregard for safety violations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. The comment also states that the reason for this presentation is unclear. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are convoluted or why the omission of safety violations is a significant issue. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that they are convoluted and that the safety violations of the agent in the first 1000 episodes are disregarded. The comment also points out that the reason for this presentation is unclear. This feedback is 3 as it highlights a potential area for improvement in the clarity and completeness of the results section. However, it lacks detailed guidance on how the authors might address these issues or what specific changes could be made to improve the presentation. The comment provides a starting point for the authors to consider, but it could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies specific instances of writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment highlights these errors, it does not provide explicit guidance on how the authors should correct them or what specific changes need to be made. The action is implicit, as the authors can infer that they need to revise these parts of the paper to improve clarity and accuracy. However, the lack of detailed instructions or examples makes the action somewhat vague and challenging to execute. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not specify which sections or parts of the paper these errors are located in, making it difficult for the authors to pinpoint the exact areas that need correction. While the comment is specific about the nature of the errors, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point highlights specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide any reasoning, examples, or references to support why these errors are problematic or how they impact the paper. The lack of detailed explanation or justification makes it difficult for the authors to understand the significance of these errors and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment points out these issues, it does not provide any suggestions or guidance on how the authors might address these errors or improve the clarity of their writing. The feedback is specific in identifying the errors but lacks actionable advice, making it 3. The authors are aware of the issues but are left without clear steps to take for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques a statement on line 134, which claims that the sigmoid function is only true for standard sigmoid and depends on the maximum slope. It then references Theorem 4.1 and suggests that the authors elaborate more in the main text why this holds, specifically mentioning that the RNN, unlike the URNN, will converge to the nearest fixed point. The comment is explicit in its request for elaboration and provides a clear direction for the authors to improve their draft by adding more context and explanation. However, it does not specify exactly how the elaboration should be done, leaving some room for interpretation. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors elaborate more in the main text why the statement holds, particularly by explaining the convergence of RNNs to the nearest fixed point compared to URNNs. This provides clear guidance on what changes are needed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques a statement on line 134, which claims that the sigmoid function is only true for standard sigmoid and depends on the maximum slope. It then references Theorem 4.1 and suggests that the authors elaborate more in the main text why this holds, specifically mentioning that the RNN, unlike the URNN, will converge to the nearest fixed point. The comment is 3 as it provides a logical reasoning for why the statement might be true, but it lacks specific examples or references to support the claim. The suggestion to elaborate on the convergence of RNNs to the nearest fixed point is clear, but the lack of detailed explanation or evidence makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques a specific statement on line 134, which claims that the sigmoid function is only true for standard sigmoid and depends on the maximum slope. It then references Theorem 4.1 and suggests that the authors elaborate more in the main text why this holds, particularly by explaining the convergence of RNNs to the nearest fixed point compared to URNNs. This feedback is clear and actionable, as it provides a specific area for improvement by requesting additional explanation and context. However, the comment could be more helpful if it included examples or further elaboration on the reasoning behind the suggestion. Overall, the comment is 4, as it guides the authors to enhance their draft by providing a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. The comment suggests that the proposed method may be difficult to generalize to a new dataset without ground truth summary. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their method. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the planbased method, specifically noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also highlights the lack of comparability between learned plan methods and methods with predefined plans, as suggested by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with the planbased method, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to methods with predefined plans, as indicated by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the limitations of the planbased method. The absence of references or detailed explanations makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or detail to fully support it.", "helpfulness_rationale": "The review comment identifies a significant limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. This observation raises concerns about the generalizability of the proposed method to new datasets without ground truth summaries. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the method\"s applicability. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should report results for multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. It acknowledges that this might be timeconsuming due to the size of the datasets but encourages the authors to carry out this exercise. The comment is explicit in its suggestion and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should report results for multiple train/test splits or folds, which is a specific and actionable suggestion. However, it does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its recommendation to use a number of train/test splits or folds, which aligns with standard practice in the field. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the results should be reported for multiple train/test splits or folds, which is a standard practice in many papers on Gaussian Processes. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors are encouraged to consider this suggestion, but the lack of detailed reasoning or evidence weakens the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential improvement in the experimental methodology by suggesting that the authors should report results for multiple train/test splits or folds instead of relying on a single heldout test set. This is a valuable suggestion as it aligns with standard practices in many papers on Gaussian Processes, which often use multiple splits to provide a more robust and accurate illustration of the method\"s performance. The comment is clear and actionable, offering a specific direction for the authors to enhance their experimental results. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or discussed the potential tradeoffs involved. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that could significantly improve the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how the authors might simplify the method or identify the simpler principle. The action is implicit and vague, as it leaves the authors to infer the need for simplification and the potential underlying principle. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to simplify the method or identify a simpler principle, but without grounding, the authors may struggle to apply it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without additional context or evidence, the claim remains 3, as it is based on an observation without clear justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While the comment identifies a potential area for simplification, it lacks specific guidance or suggestions on how the authors might approach this simplification. The feedback is 3 as it points out a potential issue with the method\"s complexity, but it does not provide actionable steps or examples for the authors to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these points. The authors would need to infer that they should correct the potential error in the algorithm, discuss the asymptotic performance, and provide additional experimental results. The action is somewhat explicit but could be more concrete. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to Algorithm 1, Line 8, suggesting a potential error in using s_t instead of s_n. It also raises questions about the asymptotic performance of the proposed method and requests additional results with more environment steps. However, the comment does not explicitly mention which part of the paper Algorithm 1 is located in, making it weakly grounded. The comment is specific in detailing the issue with the algorithm and the request for additional results, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies areas for clarification and improvement, it lacks specific reasoning or references to support the claims. The authors would need to infer the basis for these suggestions, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about a potential error in Algorithm 1, Line 8, suggesting that s_n should be used instead of s_t. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies an area for improvement and provides a clear question, it lacks detailed guidance on how to address these points or what specific changes might be necessary. The feedback is 3 as it points out a potential issue and suggests further analysis, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the definition of uncertainty could be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution, and that upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion to improve the clarity of their paper. The comment is specific and concrete, offering detailed guidance on how to enhance the explanation of uncertainty. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides detailed feedback on how the definition could be clarified, suggesting that the authors should update the explanation to include the representation of epistemic model uncertainty in the prior distribution and the updating of beliefs in the posterior distribution. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the definition of uncertainty could be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This claim is 3 as it provides a logical reasoning for why the suggestion could improve clarity, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional evidence or references to substantiate the suggestion, making it more robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by clarifying the definition of uncertainty. It suggests that the authors should update their explanation to specify that the epistemic model uncertainty is represented in the prior distribution and that upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback is clear, actionable, and provides a concrete direction for the authors to enhance the clarity of their paper. However, it could be more helpful if it included additional examples or references to support the suggestion. Overall, the comment is 4 as it offers a clear and actionable improvement for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also questions the authors\" claim about COCOLM being parameterefficient, noting that the conclusion would be applicable to the related works. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the authors\" claim about COCOLM being parameterefficient, noting that the conclusion would be applicable to related works. However, the comment does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section being addressed. While the comment provides some specificity in questioning the authors\" claims, it lacks full grounding as it does not explicitly mention the sections or parts of the paper being discussed. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment questions the authors\" claim about COCOLM being parameterefficient, noting that the conclusion would be applicable to related works. However, the comment lacks specific examples or detailed reasoning to support its claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general critique but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the authors\" claim about COCOLM being parameterefficient, noting that the conclusion would be applicable to related works. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it lacks depth and detail, making it 3. The authors would benefit from additional guidance on how to strengthen their claims or address the concerns raised, but the feedback is not comprehensive enough to fully assist them in improving their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the analysis presented in lines 128 to 149, noting that it is not convincing enough. It highlights a specific observation from a histogram in Figure 3, where the GSP50 model is claimed to have smaller class selectivity scores, suggesting that it shares more features with ResNet50, which learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how to improve the analysis or address the concerns raised. While it identifies a potential issue with the analysis, it lacks actionable steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It provides a detailed explanation of the observation, noting that the GSP50 model has smaller class selectivity scores, which implies it shares more features with ResNet50, while ResNet50 learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. The comment is fully grounded as it explicitly mentions the specific section and figure being addressed. It is also specific because it provides a detailed explanation of the observation and the reasoning behind the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It claims that the GSP50 model has smaller class selectivity scores, suggesting it shares more features with ResNet50, which learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide any specific examples or detailed reasoning to support the claim that this observation indicates GSP50 learns better representations. While the reasoning is somewhat logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It highlights a potential issue with the analysis, noting that the GSP50 model has smaller class selectivity scores, which suggests it shares more features with ResNet50, while ResNet50 learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the analysis. While it identifies a potential area for improvement, it lacks actionable advice, making it 2. Therefore, the comment is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsalfree continual learning, where featurereplay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue of conclusions not being convincing is discussed, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed by suggesting that the authors explore the impact of different combination methods, particularly in rehearsalfree continual learning, and consider more recent works like [R3]. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsalfree continual learning, where featurereplay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would benefit from a more detailed explanation of how the suggested methods could address the issue of noise accumulation, providing a clearer path for improvement.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s conclusions, specifically questioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" It provides examples of related work, such as rehearsalfree continual learning and featurereplay methods, suggesting that the authors explore these areas to strengthen their claims. However, the comment lacks detailed guidance on how to address these concerns or what specific actions the authors should take to improve their draft. While it offers some direction, the feedback could be more comprehensive and actionable to fully assist the authors in enhancing their work. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it lacks explicit guidance on how to address them. The comment suggests exploring other bit operations, provides feedback on Figure 5a, asks for clarification on handling DVS input, and suggests analyzing energy consumption as in reference [15]. However, it does not provide concrete steps or detailed guidance on how to implement these suggestions. The actions are implicit and vague, making it difficult for the authors to know exactly what to do. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions and suggestions for improvement, but it does not specify which part of the paper these issues relate to. The references to \"Fig. 5 a\" and \"input is aer format\" are vague and do not clearly identify the sections or elements being discussed. The comment lacks specificity in addressing the issues, making it difficult for the authors to understand what needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and analyzing energy consumption. However, it lacks specific reasoning or references to support these claims. The feedback is somewhat vague and does not provide detailed guidance or evidence to help the authors address these issues. Therefore, the comment is rated as 3, as it offers some justification but lacks key elements for full clarity and support.", "helpfulness_rationale": "The review comment raises several points for improvement, including suggestions to explore other bit operations, provide more explanations for Figure 5a, and analyze energy consumption as done in reference [15]. These suggestions are 3 as they offer directions for enhancing the paper\"s content and rigor. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to implement these suggestions or address the issues comprehensively. The feedback is 3, as it provides some insights but could be more detailed and actionable to fully assist the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the first two bullet points about contributions in the introduction could be combined. This is a clear and explicit action that the authors can easily understand and implement. The comment provides specific guidance on how to improve the draft by merging the contributions, which is concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the first two bullet points about contributions in the introduction could be combined. However, it does not specify which part of the paper these bullet points are located in, making it difficult for the authors to identify the exact section to address. While the comment is specific about the action to be taken, the lack of grounding makes it challenging for the authors to understand the context and apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the first two bullet points about contributions in the introduction could be combined. This is a suggestion for improvement, but it does not contain any claims or opinions that require verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the first two bullet points about contributions in the introduction could be combined. This is a specific and actionable suggestion that provides clear guidance for the authors to improve the structure and clarity of their paper. By merging these points, the authors can enhance the flow and coherence of the introduction, making it more concise and impactful. This feedback is clear and constructive, offering a direct path for improvement, thus aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and explicit action that the authors can readily take by adding a definition to the figure captions or the main text. The comment is specific and provides a direct instruction on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment requests the authors to define the dashed lines in figures 2AB and 4B. While it does not explicitly mention which part of the paper these figures are located in, the authors can infer that they are referring to specific sections or figures mentioned in the paper. The comment is specific in its request to define the dashed lines, but it lacks full grounding as the authors need to infer the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point requests the authors to define the dashed lines in figures 2AB and 4B. This is a factual request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The comment requests the authors to define the dashed lines in figures 2AB and 4B. This is a straightforward and actionable suggestion that directly addresses a specific aspect of the paper that needs clarification. By defining these lines, the authors can improve the clarity and understanding of their figures, which is crucial for effective communication. However, the comment could be more helpful if it provided additional context or guidance on how to define these lines effectively. Overall, the feedback is 3 as it identifies a specific area for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it is a key factor in performance gain, especially compared to other modules. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the pretraining method need to be discussed. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining in the main paper and suggests that it is more important than other modules. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor on the performance gain, as indicated by the data in Table 4. However, it lacks detailed discussion on this topic in the main paper, which might be a problem. The comment suggests that the unsupervised pretraining is more important than other modules, as evidenced by the comparison with the ablation study in Table 5. While the claim is supported by the data in the tables, the reasoning could be more explicit and detailed, providing a clearer justification for the suggestion. Therefore, the comment is 4, as it provides some support but could be strengthened with more detailed reasoning or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the unsupervised pretraining method is a key factor in performance gain, as indicated by the data in Table 4. However, the main paper lacks a detailed discussion of this aspect, which could be a problem. The reviewer suggests that the authors should focus more on the pretraining method in the main paper, as it is more important than other modules compared to the ablation study in Table 5. This feedback is clear and actionable, providing a specific direction for improvement. However, it could be more helpful if it included suggestions on how to address the lack of discussion or what specific aspects of the pretraining method should be elaborated upon. Overall, the comment is 4, as it offers valuable guidance for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide any specific guidance or suggestions on how to simplify the writing or what aspects of the writing are particularly challenging. The comment lacks concrete actions or detailed feedback on what needs to be improved, leaving the authors with no clear direction on how to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to specific sections, tables, figures, or unique aspects of the paper, the authors cannot confidently identify the areas that need improvement. The comment is vague and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear or challenging, the authors may find it difficult to understand the basis of the feedback or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the writing, noting that it is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific details or actionable suggestions on how to improve the writing clarity. While it highlights a general area for improvement, it does not provide the authors with concrete guidance on what aspects of the writing need to be revised or how to achieve the suggested simplification. This lack of specificity and actionable advice makes the comment 3, as it points out a critical issue but does not fully empower the authors to address it effectively. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on how to determine which $P^*$ to fix. While the comment provides some direction for improvement, it lacks explicit instructions on how to incorporate this intuition or guidance into the paper. The authors are left to infer the exact actions needed, making the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the need for more intuition regarding the proof of Theorem 1, specifically concerning the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently identify the exact part of the paper being addressed. The comment is specific in its suggestions for improvement, such as providing intuition and practical guidance, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the intuition behind the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on determining which $P^*$ to fix. While the questions are relevant and could provide valuable insights, the comment lacks specific examples or references to support these claims. The authors would need to infer the basis for these questions, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a need for more intuition regarding the proof of Theorem 1, particularly concerning the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$, which could provide valuable guidance for the authors. However, the comment lacks specific suggestions or detailed explanations on how to incorporate this intuition or guidance into the paper. While it points out areas for improvement, it does not offer actionable advice or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the equations. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of different variables in equations (7) and (10), specifically asking why they are not analogous. However, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The authors are left without a clear understanding of what part of the paper needs revision or improvement. The comment is 1 as it does not specify which section or part of the paper is being addressed, and it is not specific because it does not offer any suggestions or guidance. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any claim, suggestion, or judgment that requires verification. The comment is purely analytical and does not offer any evidence or reasoning to support its assertion. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. This feedback is 3 as it points out a potential inconsistency or area of confusion in the equations. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve the clarity of the equations. Without actionable advice or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. While the comment highlights a specific issue, it does not provide explicit guidance on how the authors should address this conflict or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to resolve the conflict. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the definition of minimal conditional dependence and the equations, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. The comment provides a clear logical reasoning by pointing out the inconsistency between the definition and the equation. However, it lacks specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It highlights a discrepancy between the theoretical expectation and the equation presented, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This feedback is clear and actionable, as it points out a specific area where the authors need to address a potential inconsistency. However, the comment could be more helpful if it provided guidance on how to resolve the conflict or what changes might be necessary. Overall, the comment is 4, as it directs the authors to a critical issue that needs to be addressed for the paper to be accurate and consistent."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete guidance on how to update the archetypes. The comment is vague and lacks actionable steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the update mechanism of archetype positions after initialisation, providing a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it seeks clarification on a specific aspect of the algorithm. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It points out a lack of clarity regarding how these positions are updated, which could hinder the understanding and implementation of the algorithm. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the algorithm. As a result, the feedback is 3, as it identifies a potential area for improvement but lacks actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several areas where additional information is missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are explicit and provide clear guidance on what information needs to be included to improve the paper. The authors can directly apply these actions to enhance the completeness and clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for additional information in the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what specific aspects of the study need to be addressed, allowing the authors to accurately identify the parts of the paper that require improvement. The comment is specific in detailing what information is missing and what should be included, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of several claims that are supported by logical reasoning and specific examples. It suggests that the authors should include information about recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. Additionally, it recommends mentioning the number of regions in the parcellation in the main text. These suggestions are clear and provide specific guidance on what information is missing, making the claim 5. The comment is wellsupported and provides actionable feedback for the authors to improve their draft.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on areas where the empirical study is lacking. It highlights the need for additional information such as recording parameters for the MRI, preprocessing steps, the condition of the restingstate recording (eyesopen or eyesclosed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are clear and detailed, offering the authors concrete guidance on how to enhance the completeness and clarity of their draft. The feedback is 4 as it provides a comprehensive overview of the necessary improvements, though it could be further expanded to include more specific examples or detailed explanations. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a significant risk of methods exploiting relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, mentioning that AU6 can occur in both expressions of pain and happiness, and that this cooccurrence differs in datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The comment is explicit in identifying the issue and provides a clear action for the authors to take, which is to conduct crossdataset experiments. This makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"action units\" and \"datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by highlighting the differences in cooccurrences of action units across datasets, such as SEMAINE and UNBC pain dataset. The comment suggests a specific way to test the generalization of the work by performing crossdataset experiments, which is a clear and actionable suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units can lead to different cooccurrences across datasets, such as AU6 in pain and happiness, and that this difference is evident in Figure 1. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. While the claim is supported by the observation of different cooccurrences in Figure 1, the reasoning could be more detailed, and the suggestion to perform crossdataset experiments is clear and actionable. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the variability of these relationships across different datasets. It provides a clear example, noting that AU6 can occur in both expressions of pain and happiness, and that this cooccurrence differs significantly between datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. This feedback is clear, actionable, and provides a specific direction for the authors to improve their work by addressing the issue of dataset variability. Therefore, the comment is 5, as it offers valuable insights and constructive suggestions for enhancing the robustness and generalizability of the research."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statement about overparametrization leading to overfitting and worse performance, suggesting that overparametrization can be beneficial in practice. It also mentions theoretical work supporting the benefits of overparametrization. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific changes to their draft or addressing the issue. The feedback lacks concrete guidance on how the authors might address this point or incorporate the theoretical work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by pointing out the critique of overparametrization and suggesting that it can be beneficial in practice, referencing theoretical work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the statement about overparametrization leading to overfitting and worse performance, suggesting that overparametrization can be beneficial in practice. It references theoretical work supporting this claim, providing a basis for the critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would benefit from a more detailed explanation or examples to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques a statement about overparametrization, suggesting that it can be beneficial in practice, which contrasts with the initial critique that it leads to overfitting and worse performance. The comment references theoretical work that supports the benefits of overparametrization, providing a balanced perspective. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue in their draft. While it identifies a potential area for improvement, it lacks detailed actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and MPHATE in Figure 3. Additionally, the comment questions the purpose of examining the learning curves, asks about the accuracy of the models, and whether worseperforming models always lead to structural collapse. While the comment provides several specific actions, it lacks explicit instructions on how to implement these suggestions, such as what kind of additional sentences to add or how to explain the correspondence. The actions are somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and MPHATE in Figure 3. However, the comment does not specify which part of the paper these explanations should be added to, making it weakly grounded. The comment is specific in its suggestions regarding the need for more detailed explanations and questions about the learning curves, accuracy, and structural collapse. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point contains several claims and questions that require justification or clarification. For instance, it questions the purpose of examining learning curves and asks about the accuracy of the models, whether worseperforming models always result in structural collapse, and what the accuracy number is. These questions are logical and require the authors to provide detailed explanations and justifications. However, the comment lacks specific examples or references to support these claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several suggestions for improvement, such as adding more sentences to explain the experimental setting for continual learning and clarifying the correspondence between learning curves and MPHATE in Figure 3. It also raises questions about the purpose of examining learning curves, the accuracy of the models, and whether worseperforming models always lead to structural collapse. While the comment offers some actionable feedback, it lacks depth and specificity, as it does not provide detailed guidance on how to address these issues or what specific changes should be made. The suggestions are 3, as they point out areas where the authors can improve their draft, but they could be more comprehensive and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the fairness of the experimental comparison with other methods. It points out that the proposed method was pretrained before the finetuning stage, making it unclear if the compared methods were initialized with the same or similar pretrained models. The comment suggests that if the compared methods were not initialized with the same pretrained model, the proposed method without SSL performs worse than most compared methods. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experimental setup. While it identifies a potential problem, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental comparison with other methods, specifically noting that the proposed method was pretrained before the finetuning stage. This provides some grounding as the authors can infer that the part of the paper being addressed is the experimental section. However, the comment does not specify which part of the experimental section is being discussed, such as the methodology or results. Additionally, it mentions that the compared methods may not have been initialized with the same pretrained model, which is a specific issue that needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental comparison with other methods is unfair due to the proposed method being pretrained before finetuning, while the compared methods may not have been initialized with the same pretrained model. The comment provides a logical reasoning by suggesting that this discrepancy could affect the fairness of the comparison. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the basis for the claim, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the experimental comparison, noting that the proposed method was pretrained before finetuning, while the compared methods may not have been initialized with the same pretrained model. This observation is supported by the mention of Table 1, which shows that the proposed method without SSL performs worse than most compared methods. However, the comment does not provide specific guidance on how the authors should address this issue or what steps they should take to ensure a fair comparison. While it highlights a critical aspect of the experimental setup, the feedback lacks actionable suggestions, making it 3. The authors would need to infer the implications and make decisions on how to improve their experimental design, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset. It provides a specific reference to a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which suggests that better metadata embeddings are available. The comment also indicates that the authors should update their paper with this suggestion. This feedback is explicit and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results of zeroshot learning on CUB dataset\" and \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering better metadata embeddings and provides a reference to a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which helps the authors understand the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the metadata used in the zeroshot learning results on the CUB dataset are \"attribute,\" which is good for fair comparison. However, it suggests that better metadata embeddings options are available and recommends exploring their performance. The comment provides a reference to a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which supports the suggestion. This provides a logical reasoning and specific reference, making the claim 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the results of zeroshot learning on the CUB dataset, noting that the metadata used is \"attribute,\" which is good for fair comparison. However, it suggests that better metadata embeddings options are available and recommends exploring their performance. The comment also references a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides context for the suggestion. This feedback is 4 as it offers actionable insights and a reference for further exploration, guiding the authors to improve their work. However, it could be more comprehensive if it included a detailed discussion of the potential impact of using better metadata embeddings or suggested specific experiments to evaluate this. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a plot comparing the flexibility of SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is explicit and detailed, guiding the authors on how to implement the suggested improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SGC\" and \"LoRA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a concrete action: including a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed, making the comment highly specific and grounded. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point claims that PEFT methods typically target computeconstrained scenarios, where finegrained control may require extra tuning, thus reducing practicality. It suggests including a plot comparing SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. While the claim about PEFT methods is generally accepted, the suggestion to include a plot is specific and provides a clear direction for the authors to improve their paper. However, the comment lacks detailed reasoning or references to support the claim about PEFT methods, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the applicability of SGC, suggesting that PEFT methods, such as LoRA, are more suitable for computeconstrained scenarios. It provides a specific suggestion to include a plot comparing SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This feedback is clear and actionable, offering a concrete way for the authors to address the identified issue. However, the comment could be more helpful if it included additional suggestions or considerations for the plot, such as specific metrics or data points to include. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the shorter training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time, as evidenced by the similar performance of ERM and plugin to Kearns et al. The comment implies that the authors should consider the rationale behind the training time differences and provide a justification for it. However, it does not explicitly instruct the authors to address this question or provide a detailed explanation of why the shorter training time is reasonable. The suggestion to publish the code is a concrete action, but the lack of explicit guidance on addressing the training time question makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the shorter training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time, as evidenced by the similar performance of ERM and plugin to Kearns et al. The comment implies that the authors should consider the rationale behind the training time differences and provide a justification for it. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in that it identifies a potential issue with the experimental setup and suggests a possible action for the authors to take, such as providing a justification for the training time differences. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reasonableness of the shorter training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time, as evidenced by the similar performance of ERM and plugin to Kearns et al. However, the comment does not provide any specific reasoning, examples, or references to support the claim that shorter training times are reasonable or why the computational time advantage is significant. Without detailed justification or evidence, the claim is difficult to verify, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the shorter training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It suggests that the main advantage of the method is its computational time, as evidenced by the similar performance of ERM and plugin to Kearns et al. The comment implies that the authors should consider the rationale behind the training time differences and provide a justification for it. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional experiments could be conducted to clarify the training time differences. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline\"s performance and the claim made in the abstract. It points out that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the draft. The action is implicit, as the authors need to infer that they should clarify the discrepancy in the human baseline\"s performance and the abstract\"s claim. The action is somewhat vague, as it does not specify how to address the issue or what changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the human baseline by pointing out that it is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also mentions the abstract, where the authors claim that the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources.\" This suggests that the abstract\"s claim might be misleading given the discrepancy in the recording duration. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the human baseline and the misleading claim in the abstract, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also points out that the abstract claims the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources,\" which is misleading given the discrepancy in recording duration. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim and seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the human baseline\"s performance, noting that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also highlights a misleading claim in the abstract, where the authors mention that the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources.\" This discrepancy is significant and could mislead readers about the relative performance of the human baseline. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to the draft. While it identifies a critical issue, it lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific questions and suggestions for the authors to address. It asks for an example of synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests explicitly writing down the model used in the appendix. These actions are clear and direct, allowing the authors to understand exactly what needs to be done to improve their draft. The comment is fully actionable as it provides concrete guidance on how to address the issues raised. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear questions and suggestions for the authors to clarify and improve their work, such as asking for an example of synthetic data and explaining the terms used in Figure 1. The suggestion to explicitly write down the model used in the appendix further enhances the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for the authors to clarify and improve their paper. It does not contain any subjective opinions or claims that require verification. The questions are factual and seek clarification, which aligns with the \"No\" category.", "helpfulness_rationale": "The review comment provides specific questions and suggestions for the authors to address, such as asking for an example of synthetic data, clarifying the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggesting explicitly writing down the model used in the appendix. These actions are clear and actionable, offering the authors concrete guidance on how to improve their draft. However, the comment could be more helpful if it included additional suggestions or elaborated on the implications of these changes. Overall, the feedback is 4 as it provides a good starting point for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. The comment is explicit in its request for clarification and provides a specific direction for improvement. It instructs the authors to explain how the spatial arrangement of sensors might influence the process, which is a concrete action they can take to enhance the clarity of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to elucidate the EEG token quantization process and to understand the role of the spatial arrangement of EEG sensors in this process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This is a constructive suggestion that provides a clear direction for improvement. However, the comment lacks specific examples or references to support the claim that the spatial arrangement of sensors plays a role in the process. While the suggestion is logical and actionable, the lack of detailed examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of ambiguity in the paper, namely the interpretation of Figure 3, which presents EEG topography plots for both input and output during the EEG token quantization process. The authors are advised to elucidate this procedure in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, providing a specific direction for improvement that could enhance the clarity and understanding of the paper. By addressing this suggestion, the authors can significantly improve the interpretability of their results and strengthen the overall presentation of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not provide explicit guidance or suggestions on how the authors might address the problem in a more direct way. The comment lacks concrete actions or detailed feedback on how to improve the approach. As a result, the authors are left without a clear understanding of what changes are needed to align with the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the approach but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is problematic or how it fails to address the problem in a direct way. Without additional context or justification, the claim remains 1, as the authors are left without a clear understanding of the issue being raised. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem, implying that the authors should consider alternative methods or approaches that more directly tackle the issue. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what alternative approaches they could explore. While it identifies a potential weakness in the methodology, it does not provide actionable feedback or detailed advice on how to improve the approach. Therefore, the comment is 3, as it highlights an area for improvement but does not offer comprehensive guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by NguyenTang et al. (AAAI\u201921). It implies that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide explicit guidance on how the authors should incorporate this information or where in the paper this discussion should be added. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, lines 2230, where the discussion on distributional RL takes place. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue: the lack of relevant literature on using moment matching for DRL, particularly referencing the work by NguyenTang et al. (AAAI\u201921). This provides a clear direction for the authors to improve their draft by including this discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by NguyenTang et al. (AAAI\u201921). The comment suggests that this discussion should be included when discussing various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide specific examples or detailed reasoning to support why moment matching is relevant or how it differs from quantile regression. While the suggestion is logical, the lack of detailed justification or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where additional literature could be discussed, particularly regarding the use of moment matching in distributional reinforcement learning. It provides a specific reference to a relevant work (NguyenTang et al. AAAI\u201921) that could enhance the paper\"s discussion on various approaches to DRL. However, the comment could be more helpful by offering more detailed guidance on how the authors should incorporate this information or where in the paper this discussion should be placed. While it provides a clear direction for improvement, the feedback is somewhat limited in its depth and specificity, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. While it points out that the authors may be assuming the reader understands the concept of tumour growth, it does not provide explicit guidance on how to address this issue. The comment suggests that the authors should clarify the modelling process, but it does not offer specific steps or examples on how to do so. As a result, the authors are left with a vague understanding of what action to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of clarity regarding what is being modelled in the context of modelling curves, particularly in the second paragraph of the introduction. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction is unclear about what is being modelled, specifically mentioning tumour growth. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modelling curves but lacks clarity on what is being modelled, particularly in the context of tumour growth. While the comment points out a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, making the feedback 3. It could be more helpful if it offered specific suggestions or examples of how to improve the clarity of the modelling process described in the introduction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio of these minima under certain assumptions. However, it does not provide explicit guidance on how to conduct this analysis or what specific steps the authors should take. The comment implies that the authors should consider adding this analysis, but it lacks concrete details on how to implement it. Therefore, the comment is 3, as it identifies a potential improvement but does not provide detailed instructions on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the analysis of the quality of local minima, including the approximation ratio under certain assumptions. This provides clear guidance on what aspects of the paper require improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggested improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that while the paper analyzes the convergence of Algorithm 1 to permutations as local minima, it lacks an analysis of the quality of these local minima. The comment suggests that the authors should consider analyzing the approximation ratio of these local minima under certain assumptions, which is a valuable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or examples of relevant literature. Overall, the feedback is 3 as it points out a clear area for improvement and offers a direction for further analysis, but it lacks detailed instructions for implementation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, specifically referencing a sentence in the paper. It does not provide explicit instructions or suggestions on how to address this question or improve the paper. The comment is vague and lacks concrete guidance, leaving the authors uncertain about what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any evidence, reasoning, or references to support the claim or question raised. The comment lacks clarity and does not offer any guidance or justification for the inquiry, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any suggestions or insights on how to address this question or improve the paper. The comment lacks actionable feedback, leaving the authors without guidance on how to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to their draft. The comment is specific in its request for additional experiments, which helps the authors understand exactly what needs to be done to strengthen their claims. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides the authors with a clear understanding of what additional experiments are required to support their claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This claim is 3 as it provides a clear direction for the authors to take, but it lacks specific examples or references to support the need for such experiments. While the suggestion is logical, the comment could be strengthened by providing more detailed reasoning or examples to justify the need for these additional experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include experimental results of excluding the mixup technique from their proposed method. This is a clear and actionable suggestion that directly addresses a potential gap in the paper\"s claims regarding the pure contribution of the proposed method. By providing this feedback, the comment helps the authors strengthen their experimental validation and demonstrate the necessity of the mixup technique. The comment is 4 as it offers a specific and constructive suggestion for improvement, though it could be further expanded to include more detailed reasoning or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether an error in the initial calibration steps of the algorithm might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to investigate or correct the error. The comment lacks concrete guidance on how to proceed, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" which provides full grounding as the authors can accurately identify the section being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. This feedback is 3 as it identifies a potential issue that could impact the results, prompting the authors to investigate and address it. However, the comment lacks specific guidance on how to identify or correct the error, making it incomplete. The authors would need to conduct further analysis or seek additional information to fully address the concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to explicitly specify the labels for each dataset in section 4.1, including their source. It questions whether the labels are derived from the dataset itself or from additional information, particularly for caspealr1 and mugshot. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so or offer guidance on how to present the labels. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the labels and their sources. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions section 4.1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is needed: the labels for each dataset in section 4.1, including their source (from the dataset itself or from additional information). This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning the source of these labels (from the dataset itself or additional information). This is a request for clarification and does not contain a subjective claim or suggestion that requires verification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the labels used in section 4.1. It prompts the authors to clarify the source of these labels, whether they are derived from the dataset itself or from additional information. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the labels, which could improve the clarity and understanding of the paper. However, the comment could be more helpful if it offered suggestions on how to present this information or addressed the specific concerns about caspealr1 and mugshot. Overall, the comment provides a valuable insight that could guide the authors in improving their draft, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the clarity of the explanation. The authors are left to infer that they need to clarify the calculation of \u03bb and provide a clearer explanation of the ELLA\"s sample efficiency in COMBO environments. This lack of explicit and concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (Page 9, lines 310313 and Page 8, lines 281285), allowing the authors to accurately identify the parts being addressed. It also specifies what the authors need to understand, namely the process of calculating \u03bb and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. Additionally, the comment references specific papers [1], [2], and [3], which provides context and suggests further reading. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment lacks specific details or references to support these claims, making it difficult for the authors to understand the basis of the concern. The absence of detailed reasoning or examples makes the claim 3, as the authors may need to infer the basis of the concern themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and questions the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment, referencing specific papers to provide context. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the clarity of the explanation. While it identifies areas for improvement, it does not provide actionable steps or specific advice, making it 3. The authors would need to infer the need for clarification and additional context, which limits the comment\"s overall impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies specific areas of concern, it does not provide explicit guidance on how the authors should address these issues or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or modifications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of lower bound double qlearning, specifically mentioning the MsPacman environment in Figure 2 and noting a slight performance decrease compared to Clipped DDQN. It also highlights convergence to the same solutions in other environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that the algorithm overestimates the true maximum value. However, the comment does not specify which part of the paper discusses these environments or the algorithm, making it weakly grounded. The specificity of the comment is moderate as it provides some context but lacks detailed guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in other environments such as WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in other environments such as WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies potential issues with the algorithm\"s performance and convergence, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve the algorithm. The feedback is 3 as it highlights areas that need further investigation or refinement, but it lacks actionable advice, making it difficult for the authors to take concrete steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches from below rather than above. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit, as the authors need to infer that they should clarify the performance discrepancy and provide an explanation. While the action is somewhat vague, it is clear that the authors need to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA compared to vanilla DNN when lambda is small, and it provides a specific observation about the expected behavior. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches from below rather than above. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the performance is expected to approach from above. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It points out that the performance is worse and suggests that the authors should clarify why it approaches from below rather than above. This feedback is 3 as it identifies a potential area of confusion or inconsistency in the results. However, it lacks detailed guidance on how the authors might address this issue or what specific changes could be made to improve the clarity of the results. The comment could be more helpful if it provided suggestions or examples of how to clarify the performance discrepancy. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper by noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not comparing with stateoftheart systems, they have compared their results to earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific comparisons would be beneficial. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional comparisons and the specific areas where they should focus. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison of results with earlier research work from 2020, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by highlighting the lack of comparison with stateoftheart systems and suggesting comparisons with earlier systems like Taghipour and Ng (2016). This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not comparing with stateoftheart systems, they have compared their results to earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide a clear explanation of why the comparison with earlier work is important or how it would enhance the paper\"s contribution. As a result, the claim is 3, as it is based on the authors\" own reasoning but lacks sufficient evidence or examples to fully support the assertion.", "helpfulness_rationale": "The comment identifies a gap in the paper by noting the absence of comparisons with earlier research work from 2020. While the authors have explained their reasons for not comparing with stateoftheart systems, the comment highlights the need for such comparisons to provide a more comprehensive evaluation of the paper\"s contributions. However, the feedback could be more helpful if it suggested specific comparisons or provided guidance on how to address this issue. The comment is 3 as it points out an important area for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should elaborate on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. It implies that the current explanation is insufficient and that the authors should provide more detail to clarify this point. The action is explicit, as it directly instructs the authors to elaborate on the conditions for Hoeffding\"s inequality to hold. However, the comment lacks specific guidance on how to elaborate, such as suggesting additional details or examples. Therefore, the action is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely lines 124125. This allows the authors to accurately identify the section being discussed. The comment is also specific because it provides a clear request for elaboration on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. This guidance is detailed and specific, allowing the authors to understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should elaborate on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. The comment provides a logical reasoning by explaining that the bound holds under specific conditions, such as independent samples, and that stochastic algorithms further guarantee its validity. However, it lacks specific examples or references to support the claim, making it 3. The authors would benefit from additional details or examples to fully understand and address the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors could provide more elaboration, particularly regarding the conditions under which Hoeffding\"s bound holds. It suggests that the authors should elaborate on how stochastic algorithms guarantee the validity of the inequality. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it offered additional guidance on what kind of elaboration would be beneficial or suggested specific areas where the authors could expand their discussion. Overall, the comment is 4, as it directs the authors to a specific area for improvement but lacks some depth in terms of guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on whether the authors should include these models in their comparison or provide a rationale for their exclusion. As a result, the authors are left without a clear understanding of what action to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some other representative panoptic segmentation models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies which models are missing from the comparison, namely \"PanopticFPN\" and \"Mask2Former.\" This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanations or references to justify why these models are not included or why their absence is a significant omission. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the comparison of panoptic segmentation models, noting the absence of models like PanopticFPN and Mask2Former. This feedback is valuable as it highlights an area where the authors could enhance their work by including a broader range of models in their comparison. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what additional models they should consider. While it points out a relevant area for improvement, it does not offer actionable suggestions or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to proofread the paper and fix language problems, providing specific examples of language issues that need correction. This direct instruction allows the authors to understand exactly what needs to be done, making the comment 5. The feedback is clear and concrete, as it specifies the language issues and the action to be taken. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific instances in the paper where language issues need to be addressed, such as \"we typically considers\" in the above of (7), \"two permutation\" in the above of Theorem 1, and \"until converge\" in the above of (14). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear examples of language problems that need to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of minor comments on language usage, such as \"we typically considers\" in the above of (7), \"two permutation\" in the above of Theorem 1, and \"until converge\" in the above of (14). These comments are specific and provide clear examples of language issues that need to be addressed. However, the comment lacks a broader context or justification for why these language issues are significant or how they impact the paper\"s overall quality. While the feedback is somewhat specific, it could be more verifiable with additional reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific instances of language issues in the paper, such as \"we typically considers\" in the above of (7), \"two permutation\" in the above of Theorem 1, and \"until converge\" in the above of (14). It also provides a clear instruction to proofread the paper and fix all language problems. This feedback is actionable and actionable, as it gives the authors specific areas to address and a clear task to complete. However, the comment could be more helpful if it provided additional guidance on how to correct these language issues or suggested specific ways to improve the clarity of the writing. Overall, the comment is 4, as it offers valuable feedback that the authors can use to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluative framework is somewhat limited in scope, as it only considers three QuestionAnswering tasks and two language models. The comment expresses reservations about the method\"s broader applicability, particularly regarding its potential to generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance on how the authors might address these limitations or expand the framework. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve the framework. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework\"s limited scope, specifically mentioning that it considers only three QuestionAnswering tasks and two language models. This provides some grounding as the authors can infer that the comment is related to the evaluation section of the paper. However, the comment does not specify which part of the paper discusses the evaluation framework, making it weakly grounded. The comment is specific in that it highlights the limitation of the scope, suggesting that the framework should be expanded to include other reasoning or generation tasks and more advanced models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is somewhat limited in scope, as it only considers three QuestionAnswering tasks and two language models. This claim is 3 because it provides a specific example of the limited scope, but it lacks detailed reasoning or references to support the claim fully. The authors could benefit from additional context or examples to better understand the limitations and how they might be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. This observation raises concerns about the method\"s broader applicability and suggests that it may not be generalizable to other reasoning or generation tasks or more advanced models like vicunna or alpaca. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address these limitations or expand the framework. The feedback is 3 as it points out a critical aspect of the evaluation that needs attention, but it lacks depth and actionable advice, making it only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. While the comment provides a clear direction for improvement, it lacks specific guidance on which aspects of the experiments need to be expanded or what types of additional experiments would be beneficial. The authors are aware of the need for more experiments but are not given concrete steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment does not specify which part of the paper the experiments are related to, making it weakly grounded. It is specific in suggesting the need for more experiments, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas that require improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are not sufficient and suggests that more empirical or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment lacks specific details or examples to support the claim that the current experiments are insufficient. It does not provide a clear rationale for why more experiments are necessary or how they would address the identified gaps. Without additional context or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the experiments are not sufficient to fully validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that additional empirical or toy experiments, particularly for the simplified selfattention model considered in the theoretical analysis, are necessary. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft. However, the comment could be more helpful if it included suggestions for the types of additional experiments or how these experiments could be designed to address the identified gaps. Overall, the comment is 4 as it highlights a critical area for improvement and encourages the authors to expand their empirical validation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a specific way to present the performance of the model as a function of the distance of initialization from the ground truth. It provides a clear and concrete action for the authors to take, which is to vary the distance of initialization and report the performance accordingly. This guidance is explicit and detailed, allowing the authors to understand exactly how to implement the suggested improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests a specific way to present the performance of the model as a function of the distance of initialization from the ground truth. It provides a clear and detailed action for the authors to take, which is to vary the distance of initialization and report the performance accordingly. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion, as it provides a concrete method for improving the presentation of the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a specific way to present the performance of the model as a function of the distance of initialization from the ground truth. It provides a clear and detailed action for the authors to take, which is to vary the distance of initialization and report the performance accordingly. This suggestion is logical and wellsupported, as it aligns with the expected behavior of the model. However, it does not provide specific examples or references to support the claim, which could enhance its verifiability. Therefore, the comment is 4, as it is logically sound but lacks some depth in terms of supporting evidence.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of the model\"s performance by varying the distance of initialization from the ground truth. It suggests a method to present the results as a function of this distance, which could help in understanding the sensitivity of the model to initialization. However, the comment lacks depth and does not offer alternative approaches or detailed guidance on how to implement this suggestion effectively. While it provides a clear direction for improvement, it could be more helpful if it included additional insights or suggestions for further analysis. Therefore, the comment is 3, as it identifies an area for improvement but does not fully address the authors\" needs for comprehensive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This comment provides a specific and explicit action for the authors to consider, as they can verify whether the operation is indeed necessary. The suggestion is clear and concrete, allowing the authors to understand exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the definition of the Frobenius norm, suggesting that the absolute value operation is not needed since tensor entries are real numbers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This claim is logical and verifiable as it is based on the understanding that the Frobenius norm is typically defined for realvalued tensors, where the absolute value is not necessary. The comment provides a clear reasoning for the suggestion, making it 5. Therefore, the comment aligns with a score of 5.", "helpfulness_rationale": "The review comment identifies a minor issue in the definition of the Frobenius norm, specifically noting that the absolute value operation is not needed because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific point for the authors to consider and potentially address in their draft. By highlighting this detail, the comment helps the authors refine their understanding of the Frobenius norm and ensures accuracy in their work. However, the comment could be more helpful if it suggested alternative ways to present the norm or provided additional context. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while FIDs are still used, there are flaws associated with them and the Inception network. It recommends using DinoV2 Frechet Distances for comparisons, in addition to FID. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the draft need to be addressed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIDs\" and \"Inception network,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear recommendation to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This guidance is detailed and actionable, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that there are flaws associated with FIDs and the Inception network, suggesting the use of DinoV2 Frechet Distances for comparisons. However, the comment lacks specific examples or references to support the claim about the flaws of FIDs and the Inception network. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of FIDs and the Inception network, suggesting that there are flaws associated with them. It recommends using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the rigor and comprehensiveness of the evaluation. However, the comment could be more helpful if it included additional context or examples to support the claim about the flaws of FIDs and the Inception network. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. It recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit, as the authors can infer that they need to revise the figure to address the issue. However, the comment lacks concrete details on how to implement this suggestion, such as specific examples of how to use a second yaxis or another visualization. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, which is not physically accurate. The suggestion to use a second yaxis or another visualization is a concrete and actionable step that the authors can take to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward and implies negative rates, which is not physically accurate. The reviewer suggests using a second yaxis or another visualization for better clarity. However, the comment lacks specific examples or references to support the claim about the figure\"s accuracy. Without additional context or evidence, the claim is difficult to verify, making it 2. The authors would need to infer the basis of the claim, which limits its verifiability.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not physically accurate. The reviewer suggests using a second yaxis or another visualization to improve the figure\"s clarity and accuracy. This feedback is clear and actionable, providing the authors with a specific direction to improve the presentation of their data. However, the comment could be more helpful if it included examples of how to implement the suggested changes or if it offered additional guidance on choosing the most appropriate visualization. Overall, the comment is 4 as it highlights a clear area for improvement and provides a concrete suggestion, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to GAN models to avoid overfitting. It provides a counterargument based on the reviewer\"s experience with highdimensional LSTMs and suggests that the baseline models might not be properly regularized. The comment implies that the authors should investigate the regularization techniques used in their models, specifically questioning whether dropout is applied to the hidden states as well. However, the comment does not explicitly instruct the authors to conduct this investigation or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the regularization techniques and potentially adjust their models accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim made in that section, suggesting that the baseline models might not be properly regularized and that the authors should investigate whether dropout is applied to the hidden states. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the regularization techniques used in the baseline models, specifically questioning whether dropout is applied to the hidden states. The reviewer provides a counterargument based on their experience with highdimensional LSTMs, suggesting that the baseline models might not be properly regularized. However, the comment lacks specific examples or references to support the claim that the baseline models are not properly regularized. While the reviewer provides a logical argument, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the supplemental section D.4, questioning the claim that smaller architectures are necessary for language models (LMs) compared to GAN models to avoid overfitting. It provides a counterargument based on the reviewer\"s experience with highdimensional LSTMs, suggesting that the baseline models might not be properly regularized. The comment also raises a question about whether dropout is applied to the hidden states, which is a relevant point for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to investigate the regularization techniques or suggested specific experiments to address the issue. Overall, the feedback is 3 as it highlights a potential area for improvement and encourages the authors to explore further, but it lacks depth and actionable suggestions for addressing the concern."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in its critique of the contribution of multilingual chainofthought being incremental compared to villa chainofthought, but without grounding, the authors cannot determine where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the incremental nature of the contribution of multilingual chainofthought compared to the villa chainofthought. While it identifies a potential weakness in the paper\"s contribution, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The comment lacks actionable advice, making it 3 as it highlights an area for improvement but does not offer a comprehensive or detailed response. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the comparability of Geffect values across different unlearning objectives and approaches, given that the study examines each objective in isolation. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the comparability of Geffect values, but it does not offer specific guidance on how to do so. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the concern regarding the comparability of Geffect values across different unlearning objectives and approaches, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, noting that the study examines each objective in isolation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparability of Geffect values across different unlearning objectives and approaches, as the study examines each objective in isolation. This feedback highlights a concern that could impact the validity and comparability of the results presented in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it points out a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer how to address the concern, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. However, the comment does not offer explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly what to do. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of the UNIFORM procedure\"s advantage over other methods, specifically noting that the results are not always clear, especially in the 1shot setting. However, it does not specify which part of the paper this issue is discussed in, such as a particular table or section. The comment is specific in its critique of the results but lacks grounding as it does not provide clear references to the sections or figures where the issue is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting. It notes that the results are not always clear and suggests that the authors should provide a theory to explain this. However, the comment lacks specific examples or references to support the claim that the results are not always clear or that the authors should provide a theory. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting. It points out that the results are not always clear, which suggests that the authors should provide a theory to explain this discrepancy. This feedback is 3 as it highlights a potential area for improvement in the paper, specifically regarding the clarity and consistency of the results. However, the comment could be more helpful if it provided more detailed guidance on how to address this issue or suggested specific experiments that could be conducted to clarify the results. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive to fully assist the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this, implying that adding such theory would strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it does not specify how to conduct this exploration or what specific theories to consider. The action is explicit but somewhat vague in terms of implementation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. This provides full grounding as the authors can accurately identify the sections where the issue is being addressed. The comment is also specific, as it asks the authors to consider existing linguistic theories that could explain the phenomenon, providing clear guidance on what needs to be explored. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this phenomenon. While the comment provides a direction for the authors to explore, it lacks specific examples or references to existing theories, making it 3. The authors would need to conduct further research to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by asking the authors to consider the reason why information value is a stronger predictor for dialogue, referencing specific sections of the paper. It also prompts the authors to explore existing linguistic theories that could explain this phenomenon, suggesting that adding such theories would strengthen the paper. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work. However, it could be more helpful if it provided more detailed guidance on which theories to consider or how to integrate them into the paper. Overall, the comment is 4 as it identifies a meaningful area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This suggests that the authors may need to ensure that all terms are defined before they are used in the paper. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting where the definition should be placed or how to clarify its usage. The action is implicit and somewhat vague, as the authors need to infer that they should define T_a(t) before using it in Section 3.1. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out that the term T_a(t) is used in Section 3.1 but only defined in Section 4, highlighting a clear issue that needs to be addressed. This provides the authors with a clear understanding of what part of the paper requires attention and what specific problem needs to be resolved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This observation is factual and requires no additional evidence or reasoning to be understood. The comment is a normal statement, as it describes a factual observation about the paper\"s structure and content. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the term T_a(t) is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper\"s structure and content. While the comment points out a specific area that needs attention, it does not provide detailed guidance or suggestions on how to address this issue. The authors are left with a clear indication of a problem but without actionable steps to resolve it. Therefore, the comment is 3, as it provides a clear observation but lacks depth and specificity in terms of actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the confusion regarding the empirical analysis in Figure 3 and the large spacing in Equations (9) and (10). For the first concern, the authors are asked to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This action is explicit and concrete, as it clearly instructs the authors to provide detailed explanations. However, the comment does not specify how to address the confusion, leaving the authors to infer the necessary steps. For the second concern, the authors are asked to explain why the adjustments are effective in enhancing the model\"s performance, which is also an explicit and concrete action. The comment is 4 as it provides clear guidance on what needs to be addressed, but it could be more helpful if it included specific suggestions or examples of how to clarify the analysis or improve the presentation of the equations. Overall, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the confusion regarding the empirical analysis in Figure 3 and the large spacing in Equations (9) and (10). It explicitly mentions these parts of the paper, providing full grounding. The comment also specifies what needs to be clarified, such as the impact of adjustments on model prediction accuracy and the effectiveness of these adjustments. This level of specificity allows the authors to understand exactly what aspects require attention and how to address them. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two questions: one about the confusion regarding the empirical analysis in Figure 3 and another about the large spacing in Equations (9) and (10). The first question prompts the authors to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a request for explanation and clarification, which is a subjective claim. The second question asks for an explanation of why these adjustments are effective in enhancing the model\"s performance, which is also a subjective claim. The comment does not provide any evidence or reasoning to support these claims, making them 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies two main areas for improvement in the paper. First, it highlights confusion regarding the empirical analysis in Figure 3, specifically questioning how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This feedback is 3 as it points out a specific area that needs clarification, but it does not provide detailed guidance on how to address the confusion or what specific aspects of the analysis require further explanation. Second, the comment notes the large spacing in Equations (9) and (10) from the preceding text, which could hinder readability. While this feedback is actionable, it lacks depth and specificity, as it does not suggest how to improve the spacing or what impact it has on the overall presentation. Overall, the comment is 3 as it identifies areas for improvement but could be more comprehensive and detailed to fully assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work with the recent related work CoCoOp [1] in the experiments. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors need to infer that they should add a comparison with CoCoOp to their experiments. However, the comment lacks specific guidance on how to implement this comparison, such as which aspects of the work should be compared or what data should be used. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the recent related work CoCoOp [1]\" and suggests comparing it with the authors\" work in the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need to compare with CoCoOp, which is a CVPR\"22 work published after the NeurIPS deadline. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp [1] should be compared in the experiments. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide a detailed explanation of why CoCoOp is relevant or how its comparison would enhance the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should compare their work with the recent related work CoCoOp [1] in the experiments. This is a valuable suggestion as it highlights a relevant comparison that could enhance the paper\"s context and contribution. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to conduct this comparison or what aspects of the work should be compared. While it offers a clear direction for improvement, the feedback could be more helpful if it included specific suggestions or examples. Therefore, the comment is 3, as it provides a meaningful but incomplete critique that could guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not provide explicit instructions or detailed guidance on how to improve the figure. The authors are left to infer that they need to enhance the figure\"s clarity and detail, but without specific steps or examples, the action remains somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to Figure 1, specifically mentioning the need to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what aspects of the figure need improvement, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide specific examples, references, or detailed reasoning to support why these improvements are necessary or how they would enhance the figure. Without additional context or evidence, the claim remains 3, as the authors may need to infer the need for improvement based on their own understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving Figure 1, which could enhance the clarity and detail of the processing pipeline described in the paper. By suggesting that the figure should include elements such as prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring, the comment offers actionable feedback that could help the authors improve the visual representation of their work. However, the comment could be more helpful if it provided additional guidance on how to implement these suggestions or included examples of how the figure could be improved. Overall, the feedback is 3 as it identifies areas for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This comment provides a clear and explicit action for the authors to take: they should remove or define the abbreviations in the section header. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that abbreviations like \"MoCo\" should not appear in the section header, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This claim is 3 as it provides a logical reasoning for why the inclusion of such abbreviations could be problematic. However, it lacks specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of abbreviations in the section header, noting that readers might not understand them. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By recommending that abbreviations like \"MoCo\" should not appear in the section header, the comment helps the authors enhance the clarity and accessibility of their paper. However, the comment could be more helpful if it provided additional guidance on how to define or remove abbreviations effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the analysis need to be clarified. The comment lacks explicit instructions or concrete examples, making it difficult for the authors to understand what needs to be improved. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact issue. The comment is 1 as it does not provide specific references or sections of the paper that need attention. It is also not specific because it does not detail what aspects of the analysis are standard or how they relate to the technical contribution. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the technical contribution of the paper, suggesting that it is unclear and that most of the analysis is standard. However, the comment lacks specific details or actionable suggestions on how the authors might address this issue. It does not provide guidance on what aspects of the analysis need clarification or how the authors can strengthen their technical contribution. Without concrete feedback or suggestions, the authors may find it challenging to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide explicit guidance on what specific evidence or arguments are needed to establish this contribution as significant. The comment implies that the authors should provide more detailed evidence or arguments, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a need for more evidence but does not offer specific guidance on how to achieve this.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs to be addressed. The comment is specific in its critique of the contribution, but it lacks grounding as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains unsubstantiated, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. While it highlights this point, it does not provide specific feedback or suggestions on how the authors might address this issue or strengthen their contribution. The comment lacks actionable guidance, making it 3 as it points out a potential area for improvement but does not offer detailed advice or constructive feedback. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the action is implicit, as the authors need to infer that they should provide more details to address the question. The action is vague because it does not specify exactly what additional details are needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. It suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the authors cannot confidently determine which part of the paper this comment refers to, as it is not explicitly mentioned. The comment is specific in its critique of the parameter count in the S2D structure, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. This reasoning is clear and logical, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the S2D structure, questioning why the number of parameters does not change when the kernel height and width remain the same. It provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The reviewer acknowledges that efficiency could be improved due to the quadratic nature of FLOPs on activation side length but emphasizes the need for more details regarding parameters. This feedback is clear and actionable, as it directs the authors to provide additional information or clarification on the parameter count in the S2D structure. However, it could be more helpful if it suggested specific areas where more details are needed or provided examples of how to address the issue. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the presentation of the simulation study is not effective in supporting the authors. It specifically notes that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to the bandit feedback and not the use of information about the form of the cost function. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their presentation. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comment on why the GPC (benchmark) performs better than BPC (the authors\" method) and suggests that this difference is due to bandit feedback and not the use of information about the cost function form. This provides a clear direction for the authors to improve their presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not effective in supporting the authors, specifically noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to bandit feedback and not the use of information about the cost function form. However, the comment lacks specific examples or detailed reasoning to substantiate this claim, making it 3. The authors would need to infer the basis for the claim, which limits its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) performs better than BPC (their method). It suggests that the difference is due to bandit feedback and not the use of information about the cost function form. This feedback is clear and actionable, as it provides a specific area for improvement and a clear rationale for why the authors should address this issue. However, the comment could be more helpful if it offered suggestions on how to reiterate this point or provide additional context. Overall, the comment is 4, as it guides the authors to improve their presentation but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim, leaving the action somewhat vague. The authors are left to infer that they need to provide more detail or evidence to support the claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly mention which part of the paper this claim is made, making it weakly grounded. The comment is specific in suggesting that the authors should provide more detail or evidence to support the claim. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The authors are left to infer the basis of the claim, which could be improved with more explicit justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed guidance on how to quantify or clarify the claim, leaving the authors with limited actionable feedback. While it points out a potential area for improvement, it does not offer specific suggestions or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It also asks for clarification on how the perplexity was calculated. While the comment identifies a potential issue with the reported perplexity values and requests clarification on the calculation method, it does not provide explicit guidance on how to address the issue or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the discrepancy and provide a detailed explanation of the perplexity calculation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexity values, noting that they are over 30 and contradict better BLEU scores. The comment requests clarification on how the perplexity was calculated, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It requests clarification on how the perplexity was calculated. While the comment identifies a potential issue with the reported perplexity values, it lacks specific examples or references to support the claim that the perplexity is unusually high or contradictory to the BLEU scores. The authors are left to infer the basis of the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It also requests clarification on how the perplexity was calculated. This feedback is 3 as it points out a discrepancy that needs to be addressed, but it lacks specific guidance on how to resolve the issue or what steps the authors should take to improve their results. The comment provides a clear area for improvement but does not offer detailed suggestions or actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, it does not provide explicit guidance on what specific aspects of the paper need further explanation or elaboration. The suggestion to give more explanations is vague and lacks concrete details on how the authors should expand on this point. As a result, the authors are left without a clear understanding of what specific sections or arguments require additional clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the issue of consistency between training and inference is discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies that the authors should provide more explanations on this consistency, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to understand or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the consistency between training and inference is discussed, noting that it can be easily satisfied due to the smoothness of neural models. The reviewer suggests that the paper would benefit from providing more detailed explanations on this point. This feedback is 3 as it highlights a potential area for improvement, but it lacks specificity regarding which sections or aspects of the discussion need more elaboration. The authors would need to infer that the suggestion applies to the sections mentioned (Line 9597 and Line 308310), which limits the actionable nature of the comment. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be improved by including some failure cases and related discussion. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate it. The action is implicit and somewhat vague, as the authors are left to infer that they need to add this information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would be improved by including some failure cases and related discussion. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors cannot confidently determine which part of the paper needs revision based on this comment alone. While the comment is specific in its suggestion to include failure cases, the lack of grounding makes it difficult for the authors to understand where to address this feedback. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would be improved by including some failure cases and related discussion. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would be improved by including some failure cases and related discussion. While this feedback is relevant and could enhance the paper\"s comprehensiveness, it lacks specific guidance on how to incorporate these failure cases or what aspects of the discussion would be beneficial. The comment is 3 as it identifies a potential area for improvement, but it does not provide detailed suggestions or examples, leaving the authors with limited actionable insights. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors do not adequately discuss the computational complexity of counting homomorphomorphisms. It notes that the authors make brief statements, such as \"Better still, homomorphism counts of small graph patterns can be efficiently computed even on large datasets,\" but suggests that it would be beneficial to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. While the comment identifies an area for improvement and provides a direction for action, it does not specify exactly how the authors should address this issue, such as whether they should include a section on computational complexity or provide specific examples of how to compute these bounds. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue of computational complexity is discussed, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on the computational complexity of counting homomorphisms and suggests adding upper bounds and elaborating on empirical runtimes. This provides the authors with clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, noting that the paper makes brief statements but suggests that it would be beneficial to explicitly add the upper bounds of counting and elaborate on empirical runtimes. The comment provides a logical reasoning by highlighting the lack of detailed discussion on computational complexity, which is a valid concern. However, it does not offer specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of discussion on the computational complexity of counting homomorphisms. It suggests that the authors should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to approach the discussion of computational complexity or provided specific examples of how to compute these bounds. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention, making it a valuable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the text, noting that the first \"f\" should be \"g\" and that there is an extra \".\" in the middle of a sentence. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment explicitly points out the error and raises a question, it does not provide explicit guidance on how to correct the error or address the question. The action is implicit, as the authors would need to infer that they should correct the error and consider the impact of early learner cutting. However, the feedback is 3 as it provides clear guidance on what needs to be addressed. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be corrected, such as the typo in \"f\" and \"g\" and the extra period. Additionally, it raises a question about the convergence of networks in a baseline MCL with deep learning, which is a specific issue that needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues in the text, such as a potential error in the form of a sentence and a question about the convergence of networks in a baseline MCL with deep learning. While the comment points out these areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need attention, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not provide explicit instructions or suggestions on how to address these issues, such as suggesting alternative indexing or revisiting the calculation. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the indexing of the input x and the calculation of the sum of squares of the second layer weights, specifying exactly what needs to be clarified or corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not contain any subjective opinions or claims that require verification. The questions are factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment identifies specific issues in the proof of Theorem A.3, particularly questioning the indexing of the input x and the calculation of the sum of squares of the second layer weights. It points out that the input is a vector, not a matrix, and questions the correctness of the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d , instead of d. While the comment highlights potential errors in the proof, it does not provide detailed guidance or suggestions on how to correct these issues. The feedback is 3 as it directs the authors to specific areas that need attention, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in the description of results, specifically questioning the accuracy of the generated logical forms. It highlights a concern that only 77% of the results list contains the ground truth logical forms and asks for clarification on how the authors ensure the correctness of the entities and relationships when they are replaced. The comment implies that the authors should provide more details on the accuracy of the generated results and the process of ensuring the correctness of the entities and relationships. However, it does not explicitly instruct the authors to provide additional data or analysis to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the accuracy of the results and the process of ensuring the correctness of the entities and relationships. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the concern regarding the use of terms like \"somewhat\" and \"good generative ability\" in the description, questioning the accuracy of the generated logical forms. The comment requests clarification on how the authors ensure the correctness of the entities and relationships when they are replaced, which is a specific and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the accuracy of the generated logical forms, specifically questioning the percentage of results containing the ground truth. It suggests that the authors should clarify how they ensure the correctness of the entities and relationships when they are replaced. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the accuracy is only 77%. This lack of evidence makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the accuracy of the generated logical forms, specifically questioning the percentage of results containing the ground truth. It highlights a potential issue with the use of terms like \"somewhat\" and \"good generative ability\" in the description, which may lead to confusion or misinterpretation. The comment requests clarification on how the authors ensure the correctness of the entities and relationships when they are replaced, which is a pertinent question for improving the reliability of the results. However, the comment could be more helpful if it provided specific guidance or suggestions on how to address this issue, such as suggesting additional metrics or analysis to assess the accuracy of the generated forms. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the dependence of FedPCL\"s performance on the selection of pretrained models, noting that this limits its applicability to a broader range of areas. It also mentions that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of FedPCL and its reliance on pretrained models, noting that this limits its applications to a broader range of areas. It also mentions that the model accuracy is sensitive to the choice of pretrained models, as evidenced by the results in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment does not specify which part of the paper discusses the limitations or the development of the framework, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of pretrained model selection, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, which limits its applications to a broader range of areas. It also notes that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. The comment suggests that the authors have adequately addressed these limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the limitations and the effectiveness of the proposed framework. The comment provides a general overview but does not offer a comprehensive explanation or evidence to support the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation in the performance of FedPCL, which is heavily dependent on the selection of pretrained models. This limits its applicability to a broader range of areas. The comment also notes that the model accuracy is sensitive to the choice of pretrained models, as evidenced by the results in Table 4. While the comment acknowledges that the authors have adequately addressed these limitations, it does not provide specific suggestions or guidance on how the authors might improve their work to overcome these challenges. The feedback is 3 as it highlights an important issue that needs attention, but it lacks depth and actionable advice, making it difficult for the authors to fully address the concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides minor comments and suggestions for improving the organization of the paper. It suggests that the main contributions, which involve introducing two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. However, the comment does not explicitly instruct the authors on how to implement these suggestions, such as where to add the separate sections or how to reference the tricks. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the organization of the paper by recommending the separation of the description of two types of attention for deep VAEs and tricks like normalization or feature scaling. It suggests that these descriptions should be placed in separate sections before discussing the generative and inference models. However, the comment does not explicitly mention specific sections, tables, or figures, making it weakly grounded. The suggestions are specific and provide clear guidance on how to improve the paper, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of minor comments and suggestions for improving the organization of the paper. It suggests that the main contributions, which involve introducing two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. However, the comment lacks specific examples or detailed reasoning to support these suggestions, making it difficult for the authors to understand the rationale behind the recommendations. The feedback is 3 as it provides a general direction for improvement but lacks detailed justification or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides minor suggestions for improving the organization of the paper. It suggests that the main contributions, which involve introducing two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. This would help improve the clarity and flow of the paper. Additionally, the comment recommends referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper\"s completeness and coherence. However, the feedback lacks depth and specificity, as it does not provide detailed guidance on how to implement these suggestions or address other potential weaknesses. While the comments offer some actionable advice, they are somewhat vague and could be more helpful if they included specific examples or detailed instructions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. It provides a specific reason for this suggestion, indicating that the histogram should include the multiplicities of labels. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should revise the definition of \"X\" and consider the implications for the histogram representation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and detailed explanation of why the term \"X\" should be a multiset instead of a set, emphasizing the need to include multiplicities of labels for accurate histogram representation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a logical reasoning by explaining that including the multiplicities of labels is necessary for the histogram to honestly represent such graphs. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in section 4, suggesting that the term \"X\" should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and actionable, as it provides a specific suggestion for improvement. However, it could be more helpful if it included additional guidance on how the authors might implement this change or why it is necessary. Despite this, the comment offers valuable insight into a potential area of improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing could be improved and recommends drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks for justification regarding the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides explicit suggestions for improvement, such as drawing a table and justifying assumptions, it lacks concrete guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be done but without specific steps or examples, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weaknesses/feedback\" and \"section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the writing quality, suggesting improvements such as drawing a table to compare CoT prompting methods and questioning the assumption about error clusters. The comment also asks for justification regarding the selection criteria, which is a clear and specific request for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the writing could be improved and suggests drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks for justification regarding the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides some reasoning and questions, it lacks detailed examples or references to support the claims fully. The authors would need to infer the reasoning behind the suggestions, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies areas for improvement in the paper, specifically suggesting that the writing could be enhanced by drawing a table to compare different CoT prompting methods across various dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and requests justification for the selection criteria in section 4.2, particularly why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides some actionable feedback, it lacks detailed guidance on how to implement the suggestions or address the questions comprehensively. The feedback is 3 as it points out specific areas for improvement but could be more detailed to fully assist the authors in enhancing their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This omission is serious, as it could lead to misinterpretations and incorrect conclusions. The comment suggests that this issue must be addressed for publication and implies that it would be straightforward to fix. However, the comment does not provide specific guidance on how to revise the sections to include this information, leaving the authors with a general idea of what needs to be done but lacking concrete steps. The action is explicit but somewhat vague, as it does not detail the exact changes required. Therefore, the comment is 4, aligning with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections of the paper where the issue of results being for unsupervised random forests is not explained, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the problem, which is the lack of explanation regarding the results being for unsupervised random forests. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper does not explain that the results are for unsupervised random forests, which is a significant omission that could lead to misinterpretations. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or examples, the claim is 3, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a significant omission that could lead to misinterpretations and incorrect conclusions, as casual readers might misremember the findings. The comment suggests that this issue must be addressed for publication, implying that it would be straightforward to fix. However, the comment lacks specific guidance on how to revise the sections to include this information, leaving the authors with a general idea of what needs to be done but lacking concrete steps. While the feedback is clear and highlights a crucial oversight, it could be more helpful if it provided detailed suggestions or examples of how to address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of significance testing to support the claims made about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT4, and suggests that the authors should conduct significance testing to substantiate their claims. However, the comment does not provide explicit guidance on how to perform the significance testing or what specific statistical methods should be used. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines of the paper (line 486) and provides examples of claims made in the draft. It specifies what needs to be addressed by suggesting the inclusion of significance testing to support the claims about the differences between various methods. This provides clear guidance on how the authors can improve their draft, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should conduct significance testing to support their claims about the differences between various methods, such as ChatGPT and GPT4. It provides specific examples and numerical data to illustrate the differences in scores. However, the comment lacks detailed reasoning or references to justify why significance testing is necessary or how it should be conducted. The authors are left to infer the need for such testing, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the lack of significance testing to support claims about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT4, and highlights the minimal differences in scores, making it difficult to determine if these differences are significant without proper testing. The comment suggests that the authors should conduct significance testing, including checking the distribution and accounting for multiple comparisons, to substantiate their claims. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a clear path for addressing the issue. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 5 is difficult to comprehend and suggests that the authors should provide more details about the two baselines presented in the figure. It also notes that the study is limited to Englishcentric datasets and suggests that the authors could extend CATER to other languages in the future. While the comment explicitly mentions the need for more details about the baselines and suggests a potential future direction, it does not provide specific guidance on how to enhance the comprehensibility of Figure 5 or how to extend CATER to other languages. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the comprehensibility of Figure 5 and the need for more details about the two baselines presented in the figure. Additionally, the comment suggests extending CATER to other languages, which provides a clear direction for future work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests providing more details about the two baselines presented in the figure. It also notes that the study is limited to Englishcentric datasets and suggests extending CATER to other languages. While the comment provides a logical reasoning for the comprehensibility issue and suggests a potential future direction, it lacks specific examples or references to support the claim about the comprehensibility of Figure 5. The suggestion to extend CATER to other languages is clear but could be more detailed. Overall, the claim is 3, as it is supported by logical reasoning but lacks detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and lacks details about the two baselines presented. It also points out that the study is limited to Englishcentric datasets, which is a valid observation. The comment suggests extending CATER to other languages, providing a clear direction for future work. While the feedback is somewhat detailed, it could be more comprehensive by offering specific suggestions on how to improve the comprehensibility of Figure 5 or how to extend CATER to other languages. Overall, the comment is 4 as it provides actionable feedback and insights for the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for improvement in the literature review, specifically mentioning that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. While the comment suggests that the paper should provide a more explicit and comparative analysis of related work, it does not provide specific guidance on what aspects of the literature review need to be improved or how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to expand the literature review to include a clearer comparison with existing work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for improvement in the literature review, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be addressed, namely, the clarity of the main contribution and the distinction from existing work, particularly in relation to GFlowNet for sequence generation. This provides clear guidance on how the authors should enhance their literature review. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and needs improvement, specifically regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact areas that need improvement. Without detailed examples or references, the claim is 3, as it provides a general direction but lacks the necessary depth to guide the authors effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of clarity in the literature review. It highlights that the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation, are not adequately addressed. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to improve the literature review. Despite this, the feedback is 4 as it directs the authors towards a critical area for improvement, allowing them to enhance the clarity and depth of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, implying that readers are likely to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how the authors should eliminate this section or what specific content should be removed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, implying that readers are likely familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of the paper section 3.2 corresponds to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment does not provide specific guidance on what content should be removed or how the elimination would impact the paper. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are likely familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any specific reasoning or evidence to support this claim, such as examples or references to similar sections in other papers. Without detailed justification, the authors may find it challenging to understand why this section can be eliminated or how it impacts the overall coherence of the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated, arguing that readers are likely familiar with the GumbelSoftmax/Concrete distribution. This feedback is 3 as it points out a potential area for simplification in the paper. However, it lacks specific guidance on which parts of section 3.2 could be removed or how the elimination would affect the paper\"s overall coherence. The comment does not provide actionable advice or detailed suggestions, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific actions for the authors to take: first, to explain the link between IP and the terms/equations more explicitly and prominently, and second, to include labels for subfigures in Figures 3 and 4 instead of just stating it in the captions. These actions are explicit and concrete, as they clearly instruct the authors on what needs to be done. The authors know exactly how to apply these actions to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Figures 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done: explaining the link between IP and the terms/equations more explicitly and prominently, and including labels for subfigures in Figures 3 and 4. This level of detail helps the authors understand exactly what revisions are necessary. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: first, it suggests that the link between IP and the terms/equations could be explained more explicitly and prominently, and second, it recommends including labels for subfigures in Figures 3 and 4. While the first part is 3 as it implies the need for clearer explanation, the second part is 5 as it provides specific guidance on how to improve the presentation of figures. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the link between IP and terms/equations. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two key areas that need improvement in the paper. It suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a valuable piece of advice for enhancing the clarity and understanding of the paper. Additionally, the comment recommends including labels for subfigures in Figures 3 and 4, which would improve the visual presentation and make it easier for readers to follow the content. These suggestions are clear and constructive, providing the authors with concrete steps to take to improve their draft. Therefore, the comment is 4, as it offers actionable and specific guidance that can significantly enhance the paper."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. This comment is explicit in its suggestion to conduct ablation experiments, which directly informs the authors on what action to take. It is also concrete, as it specifies the exact action to be performed, namely, to conduct ablation experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. However, the comment does not specify which part of the paper the ablation experiments should be conducted on or how these experiments would validate the model performance. This lack of specificity makes it difficult for the authors to understand exactly what needs to be addressed. The comment is fully grounded in that it mentions a specific section of the paper, but it is not specific in detailing the nature of the ablation experiments or how they would validate the model performance. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications mentioned in Section 3.4 were used. However, the comment lacks specific details or references to support why these ablation experiments are necessary or how they would validate the model performance. Without additional context or justification, the claim remains 3, as it lacks the necessary depth and specificity to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is clear and actionable, as it directly points out a specific area where the authors can enhance their work by conducting additional experiments. By providing ablation experiments, the authors can better understand the impact of the modifications and validate their effectiveness. This feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it included suggestions on how to design the ablation experiments or what specific aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the content and purpose of Appendix A and Appendix B, specifically questioning the clarity of Proposition B.1 and the absence of a \"proof.\" It suggests that the authors should clarify the purpose of these appendices and provide a more detailed explanation or proof. However, the comment does not explicitly instruct the authors to add content or provide a specific action to take, such as expanding the appendices or clarifying the purpose of Proposition B.1. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the content of Appendix A and Appendix B, specifically questioning the purpose of Proposition B.1 and the absence of a \"proof.\" It does not explicitly mention specific sections or parts of the paper, making it weakly grounded. However, it provides clear guidance on what needs to be addressed, such as clarifying the purpose of Proposition B.1 and providing a detailed explanation or proof. This makes the comment specific in its suggestions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the content and purpose of Appendix A and Appendix B, specifically questioning the clarity of Proposition B.1 and the absence of a \"proof.\" It suggests that the authors should clarify the purpose of these appendices and provide a more detailed explanation or proof. However, the comment lacks specific examples or references to support the claim that the purpose of Proposition B.1 is unclear or that the \"proof\" is missing. Without detailed reasoning or examples, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies specific issues with the content and purpose of Appendix A and Appendix B, particularly questioning the clarity of Proposition B.1 and the absence of a \"proof.\" It suggests that the authors should clarify the purpose of these appendices and provide a more detailed explanation or proof. This feedback is 3 as it points out areas where the authors need to improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting additional content or a more detailed explanation of Proposition B.1. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 to reassure readers that it is not a real concern. The comment implies that the authors should provide more detail or justification to address this concern, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the vulnerability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of approximations introduced in the paper, specifically mentioning \"several approximations (i iii)\" and suggesting that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110. However, the comment does not specify which part of the paper these approximations are discussed or where the vulnerability is addressed. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of approximations and vulnerability, it lacks grounding as it does not provide clear references to the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors introduce several approximations, which leaves loose ends, and suggests that the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 needs to be expanded to reassure readers. The comment provides a logical reasoning by pointing out the potential vulnerability and suggesting that it should be addressed. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107110 to reassure readers that it is not a real concern. This feedback is 3 as it highlights a specific area that needs clarification or expansion, but it lacks depth and does not provide detailed guidance on how to address the issue. The authors would benefit from a more comprehensive explanation of the approximations and the rationale behind the vulnerability, which would enhance the clarity and robustness of the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any specific suggestions or actions for the authors to take to address this concern. The comment lacks explicit guidance on how the authors might enhance the contribution or make the model more significant. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the limited contribution and incremental nature of the proposed model, but it does not specify which part of the paper this opinion pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific evidence or reasoning to support this claim. Without detailed examples or references to other works that might challenge the authors\" assessment, the claim remains subjective and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. While it identifies a potential weakness in the paper, it does not provide specific suggestions or actionable feedback on how the authors might address this issue or enhance the contribution of their work. The comment lacks depth and guidance, making it 3 as it highlights an area for improvement but does not offer a comprehensive solution. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the experimental setup, noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. While the comment identifies a potential issue with the experimental design, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the evaluation methods. The action is implicit, as the authors need to infer that they should consider the differences between the two sets of benchmarks and potentially adjust their experimental design accordingly. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment addresses the experimental part of the paper, specifically mentioning Figure 4 and Figure 5, which contain different evaluation methods. However, it does not specify which sections of the paper these figures are located in, making it weakly grounded. The comment is specific in that it highlights a discrepancy in the experimental setup, suggesting that the differences between the two sets of benchmarks are significant. This provides clear guidance on what needs to be addressed, but the lack of explicit section references makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between two sets of evaluation methods used in the experimental part of the paper, specifically mentioning Figure 4 and Figure 5. While the comment highlights a potential issue with the experimental design, it does not provide any specific evidence, reasoning, or references to support the claim that the differences are significant or problematic. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the concern, rendering the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the experimental part of the paper, specifically noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. This observation raises a question about the consistency and comparability of the results across different evaluation methods. While the comment points out a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this discrepancy or improve their experimental design. The feedback is 3 as it highlights a potential issue that the authors should consider, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be addressed. The comment is specific in its request for discussion and comparison, offering concrete guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for discussion and comparison, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. This is a suggestion for improvement, but it does not provide specific reasoning, examples, or references to support why this discussion is important or how it would benefit the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to improve their draft by discussing the iteration cost of their proposed method and comparing it with related methods, including baseline methods. This feedback is specific and offers a concrete direction for the authors to enhance the paper by addressing a critical aspect of computational efficiency. By highlighting the importance of iteration cost, the comment guides the authors to provide a more comprehensive analysis of their method\"s performance. This feedback is 4 as it directs the authors towards a specific area of improvement, but it could be more comprehensive if it included additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific suggestions for improvement in the experimental section. It suggests that the authors should report average results over multiple runs to make the results more robust and easier to compare. It also recommends discussing the decision boundaries in Section 3.1 and clarifying the information presented in Figure 9. These suggestions are explicit and concrete, providing clear guidance on what actions the authors should take to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improvement in the experimental section, including the need to report average results over multiple runs, discussing decision boundaries in Section 3.1, and clarifying the information in Figure 9. These suggestions are fully grounded as they explicitly mention the sections where changes are needed, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in each part. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three parts, each providing specific suggestions for improvement in the experimental section. The first part suggests reporting average results over multiple runs, which is a standard practice in experimental evaluations. The second part recommends discussing decision boundaries in Section 3.1, which would provide valuable insights into the model\"s behavior. The third part asks for clarification on the information presented in Figure 9, which is a request for additional explanation. While the suggestions are logical and common, they lack specific examples or references to support the claims. Therefore, the comment is 3, as it provides some justification but could be more robust with additional details or references.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement in the experimental section, such as reporting average results over multiple runs to enhance the robustness and comparability of the results. It also suggests discussing the decision boundaries in Section 3.1, which could offer valuable insights into the model\"s behavior. Additionally, the comment requests clarification on the information presented in Figure 9, which would help the authors better understand and explain their findings. These suggestions are clear and actionable, providing the authors with concrete guidance on how to improve their draft. However, the comment could be more helpful if it included additional details or examples to further enhance the authors\" understanding. Overall, the comment is 4, as it offers valuable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 8082. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and then determine how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the use of the center correlation in Figure 4 A&B despite its stated lack of insight for discriminating model defenses. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the authors\" reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 8082. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the center correlation is useful in this context. This lack of detailed explanation makes the claim 3, as the authors would need to infer the reasoning and provide their own justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of the center correlation in Figure 4 A&B, despite the authors\" claim that it was not insightful for discriminating model defenses. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to reconsider their approach and provide a more detailed explanation of why they chose to use this metric. By identifying this inconsistency, the comment encourages the authors to improve the clarity and coherence of their presentation, making it 3. However, the comment could be more helpful if it provided specific guidance on how to address the issue or what additional context might be needed. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the experimental evaluation, particularly regarding the ablation study and the comparison on the CIFAR dataset. It highlights that the paper claims a distinction in the \"picking\" step but does not ablate it, which is a clear and explicit action for the authors to address. Additionally, it points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. The comment is fully actionable as it provides concrete guidance on what needs to be addressed, including the inclusion of an ablation study and a more comprehensive comparison with the same setup as the DEN paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the ablation study, the limited comparison on CIFAR, and the lack of clarity in the use of the DEN approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study for the \"picking\" step, which is a subjective observation. It also criticizes the comparison on the CIFAR dataset, stating that it is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is 3, as it lacks sufficient evidence or justification to fully substantiate the critique.", "helpfulness_rationale": "The review comment provides specific feedback on the experimental evaluation section, particularly regarding the ablation study and the comparison on the CIFAR dataset. It highlights that the paper claims a distinction in the \"picking\" step but does not ablate it, which is a clear and actionable point for the authors to address. Additionally, it points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. The comment suggests that the authors should use the same setup as in the DEN paper to ensure a fair and correct comparison. This feedback is 4 as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not provide explicit guidance on how the authors should implement this change or any other specific actions they should take. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not specify which part of the paper this critique refers to, such as a particular figure or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the labeling method, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. This feedback is specific and identifies a potential improvement in the clarity of the plot labeling. However, the comment does not provide any suggestions or guidance on how the authors might implement this change or what other aspects of the plot could be improved. While it offers a clear observation, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for nonlinear RNN models exhibiting emergent behavior. The comment implies that the authors should provide a clearer explanation of how their work offers additional insights or explanations beyond what is already known. However, the comment does not explicitly instruct the authors to provide this clarification or explanation, nor does it offer concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the scientific insight and provide a clearer explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding the scientific insight gained from the model and formalism compared to prior taskoptimized approaches, and it questions the model\"s role as a prototype approximation for nonlinear RNN models. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for nonlinear RNN models exhibiting emergent behavior. The comment implies that the authors should provide a clearer explanation of how their work offers additional insights or explanations beyond what is already known. However, the comment lacks specific examples or references to support the claim that the model does not serve as a prototype approximation. Without detailed reasoning or evidence, the claim remains 3, as the authors are left to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically points out that the model, as described in Section 2.3, is not shown to be a prototype approximation for nonlinear RNN models that exhibit emergent behavior. This raises concerns about whether the work provides any additional explanation or insight into how these nonlinear models attain solutions through optimization. The comment is 3 as it identifies a significant gap in the paper\"s explanation and encourages the authors to clarify the scientific contribution of their work. However, it could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as suggesting additional experiments or analyses that could strengthen the explanation. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are explicit and concrete, as they clearly indicate what changes need to be made to the paper. The authors can directly apply these actions to improve the visual presentation of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are fully grounded as they explicitly mention specific parts of the paper, such as legends, axis labels, and captions, allowing the authors to accurately identify the sections that need improvement. The comment is also specific as it details what needs to be changed in these parts, such as increasing the font size. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are based on common practices for enhancing visual presentation and are generally verifiable. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. While the suggestions are logical and align with common knowledge, the lack of specific examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the readability of the paper, particularly focusing on the font size in legends and axis labels. It suggests that the text in these elements should be larger, and that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are actionable and directly address potential issues with the visual presentation of the paper, which can enhance its clarity and impact. However, the comment could be more helpful if it included additional guidance on how to implement these changes or why these specific adjustments are necessary. Overall, the feedback is 4 as it offers clear and actionable advice, but it could be further enhanced with additional context or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments, specifically mentioning Figure 2 of [1] which demonstrates a larger effect of removing highscoring images. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a comparison against Journey TRAK, particularly referencing Figure 2 of [1], which highlights a significant effect of removing highscoring images. This provides clear guidance on what needs to be addressed in the counterfactual experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a comparison against Journey TRAK in the counterfactual experiments, referencing Figure 2 of [1] which shows a larger effect of removing highscoring images. However, the comment lacks specific details on how this comparison should be implemented or what aspects of the comparison are crucial. It does not provide a clear rationale or examples to support the claim, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending a comparison against Journey TRAK in the counterfactual experiments. It highlights a particular aspect of the comparison, referencing Figure 2 of [1], which demonstrates a larger effect of removing highscoring images. This feedback is actionable as it directs the authors to include a specific comparison that could enhance the depth and rigor of their experiments. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific results should be included. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the experimental results, suggesting that replacing normal convolutions with adaptive convolutions is not always beneficial. It points out that the ACNNv3 model, which uses adaptive convolutions across all layers, performed worse than ACNNv2, which uses adaptive convolutions only in the last layer. The comment implies that the placement of adaptive convolutions is important but notes the absence of analysis or discussion on this aspect. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the impact of adaptive convolution placement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the ACNNv3 model performed worse than ACNNv2, suggesting that the placement of adaptive convolutions is important. However, the comment does not provide specific guidance on how the authors should analyze or address this issue. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, based on the experimental results presented in Table3. It highlights that ACNNv3, which uses adaptive convolutions across all layers, performed worse than ACNNv2, which uses adaptive convolutions only in the last layer. This observation suggests that the placement of adaptive convolutions is important. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the authors can infer that the placement of adaptive convolutions is important, the lack of detailed explanation or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It points out that the ACNNv3 model, which uses adaptive convolutions across all layers, performed worse than ACNNv2, which uses adaptive convolutions only in the last layer. This observation suggests that the placement of adaptive convolutions is important, but the comment does not provide any analysis or discussion on this aspect. While the feedback highlights a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or what specific experiments could be conducted to further analyze the impact of adaptive convolution placement. Therefore, the comment is 3, as it provides a clear observation but requires the authors to take additional steps to address the identified issue."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tradeoff between computational efficiency and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors need to infer that they should consider the implications of this tradeoff and potentially discuss it in their paper. The action is vague because it does not specify how to address the issue or what changes might be needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the tradeoff between computational efficiency and information loss when using ancestral graphs compared to DAGs, referencing a specific paper [10]. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment is fully grounded as it explicitly mentions the paper [10] and the specific aspect of the method being discussed. It is also specific because it clearly specifies the issue of information loss and the tradeoff between computational efficiency and information richness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method reduces computation time by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment questions how much information of a DAG is encoded in its corresponding ancestral graph. However, the claim lacks specific examples or detailed reasoning to support the assertion about the information loss. While the logic is somewhat inferable, the absence of concrete evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that while it reduces computation time by reducing the search space to ancestral graphs, this comes at the cost of less information compared to the richer search space of DAGs. The comment questions the tradeoff between computational efficiency and information richness, which is a relevant point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the method, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3, as it provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the discussion section could benefit from a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, it does not explicitly instruct the authors to include this discussion or provide detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion and understand the specific aspects to address. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach, and provides specific examples to consider. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach, and provides specific examples to consider. However, it lacks detailed reasoning or references to support why this discussion is necessary or how it would enhance the paper. The comment is 3 as it provides a general direction but lacks specific evidence or examples to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by suggesting that the discussion section could benefit from a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach. It offers specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals, which could guide the authors in enhancing their discussion. However, the comment could be more helpful if it provided additional guidance on how to incorporate this discussion or suggested specific areas where this motivation could be explored. Overall, the comment is 3 as it offers a clear direction for improvement but lacks depth and detail in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of the definitions, it does not provide explicit guidance on how the authors should address this concern or clarify the definitions. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the definitions in the paper. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. It suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment does not specify which part of the paper contains these definitions or where the confusion arises. The authors cannot confidently determine which section or table is being addressed, making the comment weakly grounded. Additionally, while it highlights a potential issue with clarity, it does not provide specific guidance on how to clarify the definitions or address the lack of motivation. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment lacks specific examples or detailed reasoning to support the claim that the definitions are unclear or that the motivation is weak. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the clarity of definitions in Table 1, specifically questioning the distinction between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of the definitions, it does not provide specific suggestions or detailed guidance on how the authors might address this concern. The feedback is 3 as it highlights an area that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics\". This provides a clear and direct action for the authors to take, which is to correct the caption. The comment is specific and concrete, as it identifies the exact figure and the correct caption, allowing the authors to know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption from \"Node Dynamics\" to \"Edge Dynamics\". This provides the authors with precise guidance on how to improve the figure caption. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a factual correction based on the content of the figure caption. However, the comment does not provide any reasoning or evidence to support why the caption is incorrect or why the suggested correction is appropriate. Without additional context or justification, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the caption of Figure 7, which is a factual mistake. It provides a clear and actionable suggestion to correct the caption from \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is precise and directly addresses a minor but important detail that could improve the clarity and accuracy of the paper. By correcting this error, the authors can enhance the overall quality and readability of their work. Therefore, the comment is 4, as it offers a clear and actionable improvement that the authors can easily implement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also points out that the improvement brought by SoRA compared to the baseline might be due to random fluctuations. The comment suggests that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are actual improvements due to the SoRA method. This feedback is explicit and provides a clear action for the authors to take, namely to clarify the experimental results and provide a more detailed analysis of the improvements. The action is concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section of the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue with the lack of standard deviation information and suggests that the authors should clarify which effects are within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to the conclusion that the improvement brought by SoRA compared to the baseline is due to random fluctuations. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional evidence or context, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also suggests that the improvement brought by SoRA compared to the baseline might be due to random fluctuations, and recommends clarifying which effects fall within the range of standard deviation fluctuations and which are actual improvements. This feedback is clear and actionable, providing the authors with a specific direction to improve their experimental analysis and results presentation. By addressing this issue, the authors can enhance the rigor and clarity of their findings, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and presentation of the paper, such as the font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the exact issues and provides examples, such as the small font size and the incorrect placement of figures and tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and the layout is rushed, citing specific issues such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. These claims are supported by specific examples, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims about the figures and tables. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. These observations are specific and actionable, providing the authors with clear feedback on areas that need improvement. However, the comment could be more helpful if it suggested specific ways to address these issues, such as recommending a particular font size or providing guidance on how to ensure figures are drawn explicitly. Despite this, the feedback is 4 as it directs the authors to areas requiring attention and improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the clarity and consistency of the paper. It questions the definition of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need to be explained better. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. The comment implies that moving the definition of \"p\" would improve the paper, but it does not provide specific guidance on how to address the issues with the \"upper faces\" or the projection \u03c0. While the authors can infer that they need to clarify these concepts, the lack of explicit instructions or detailed guidance makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises specific issues regarding the clarity of certain concepts in the paper, such as the \"upper faces\" of the convex hull and the variable \"p\" in the context of decision boundaries of neural networks. It suggests that the dual subdivision and projection \u03c0 need to be explained better, and that the variable \"p\" is not explicitly defined, which could lead to confusion. However, the comment does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the issues, it lacks grounding as it does not provide clear references to the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises specific questions about the clarity of certain concepts in the paper, such as the \"upper faces\" of the convex hull and the variable \"p\" in the context of decision boundaries of neural networks. It suggests that the dual subdivision and projection \u03c0 need to be explained better, and that the variable \"p\" is not explicitly defined, which could lead to confusion. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved, such as the clarity of the \"upper faces\" of the convex hull and the definition of the variable \"p\". It points out that the dual subdivision and projection \u03c0 need to be explained better, which is crucial for understanding the paper\"s content. Additionally, the comment suggests that the variable \"p\" should be moved to a specific section, indicating a need for better organization and clarity. However, the comment lacks detailed guidance on how to address these issues or what specific changes should be made. While it provides some actionable feedback, it could be more helpful if it included more detailed suggestions or examples of how to improve the clarity and organization of the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. While the comment identifies a specific issue and provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this evaluation or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which consists of two major components: a generative shape model and a word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain. The reviewer suggests evaluating the proposed approach separately against baseline detection and parsing techniques to better support the claim. However, the comment does not specify which part of the paper discusses the proposed method or the evaluation of the components. This makes it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the issue of evaluating the components, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. However, the comment does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would strengthen the claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key issue with the proposed method, specifically the lack of clarity regarding which component contributes to the performance gain. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation and strengthen their claims. However, the comment could be more helpful if it included additional suggestions or guidance on how to conduct the evaluation effectively. Overall, the comment is 4, as it addresses a significant aspect of the paper and provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind two specific design choices in Figure 1: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide explicit or implicit suggestions on how the authors should address these questions or provide further justification for their design choices. The comment lacks concrete guidance on what needs to be done or how to improve the draft. As a result, the authors are left without actionable feedback, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the rationale behind two specific design choices: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. This provides clear guidance on what aspects of the paper require further explanation or justification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or reasoning to support the questions posed. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While it identifies areas that could be clarified or better explained, it does not provide actionable feedback or suggestions on how the authors might address these questions or improve the clarity of the paper. The comment lacks depth and does not offer constructive guidance, making it 3 as it points out areas for improvement but does not fully address the authors\" needs. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that Table 4 is incomplete and suggests that it should include results for all four datasets. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to the table. The comment is specific and concrete, detailing the exact issue and the necessary action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely the results for all four datasets. This provides the authors with a clear understanding of what needs to be added to improve the completeness of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and suggests it should include results for all four datasets. While the comment identifies a specific issue with the table, it does not provide any reasoning or evidence to support why this is a problem or how the inclusion of results for all four datasets would address this issue. The lack of detailed explanation or justification makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct instruction on what needs to be addressed to improve the completeness and accuracy of the table. By specifying the exact issue and the necessary addition, the comment offers a clear path for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on what aspects of the writing are jumbled or how the authors can improve the clarity and organization of their presentation. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not specify which part of the paper is affected by this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment lacks specificity in identifying the sections or aspects of the paper that are jumbled, and it does not provide any guidance on how to address this issue. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the writing and presentation of the paper, noting that it is \"jumbled at times.\" This is a subjective assessment and lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might improve the clarity or organization of their writing. Without concrete advice or examples, the authors are left without a clear path to address the issue, making the comment 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors\" claim about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. It provides a specific correction, indicating that these heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. The comment is fully actionable because it provides a direct and concrete instruction for the authors to address the issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the base IOI circuit\" and the specific heads (\"Induction, Duplicate Token, and Previous Token heads\") being discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect in the authors\" claim, pointing out that these heads are active at the S2 token but do not primarily attend to it. This provides a clear direction for the authors to correct their understanding and potentially revise their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to external literature, which provides a basis for verification. However, the comment could be more verifiable by including a brief summary or explanation of the relevant section in Wang et al., 2023, to enhance clarity and understanding. Overall, the comment is 4, as it provides a clear basis for the authors to address the issue.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" claim regarding the primary attention of certain heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. By providing a specific correction and referencing external work, the comment offers valuable guidance for improving the accuracy and clarity of the paper. Therefore, the comment is 5, as it addresses a concrete issue and provides actionable advice for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the work, suggesting that it is incremental and lacks novelty. However, it does not specify which part of the paper this critique refers to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what specific issues need to be addressed. Additionally, the comment is somewhat specific in its critique of the pipeline being a \"pack of tricks,\" but without clear examples or suggestions for improvement, it remains vague. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, the comment lacks specific evidence or references to support this claim. It does not provide examples of similar work or detailed reasoning to substantiate the assertion that the pipeline is merely a collection of tricks. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the technical contribution of the work, suggesting that it is incremental and lacks novelty, consisting of a pack of tricks to improve defense evaluation. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice or detailed suggestions, making it incomplete. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific feedback on the vagueness of the statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at L1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it does not offer explicit or concrete actions for the authors to take. The feedback is 3 as it directs the authors to clarify the vague statement and reconsider the reinforcement learningagent analogy, but it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific parts of the paper, as it refers to lines 15, 1618, and later sections (229 to 253). This provides clear grounding for the authors to identify the relevant sections. The comment also specifies what needs to be addressed, such as clarifying the vagueness of the statement at L15 and reconsidering the reinforcement learningagent analogy at L1618. Additionally, it suggests that generalization capabilities are better illustrated by examples later in the paper. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point includes a claim that the statement at L15 is too vague, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. The comment also critiques the reinforcement learningagent analogy at L1618, suggesting it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. The claim about the vagueness of the statement is supported by the reference to the literature on natural language inference and the SNLI leaderboard, which provides evidence for the claim. However, the critique of the reinforcement learningagent analogy lacks specific examples or detailed reasoning, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the vagueness of a statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learningagent analogy at L1618, suggesting that it is outofplace and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it lacks detailed guidance on how the authors might address these issues or what specific changes should be made. The feedback is 3 as it directs the authors to clarify the vague statement and reconsider the reinforcement learningagent analogy, but it does not offer a comprehensive or actionable plan for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: first, it notes that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not discuss this observation further. Second, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide a more detailed discussion of the observation and a theoretical justification for the algorithm. This lack of explicit action makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proposed sensitivelayer selection and the lack of mathematical or theoretical justification for Algorithm.1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that the authors do not further discuss this observation. It also notes the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The authors are left to infer the significance of the observation and the need for theoretical justification, which could be challenging. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not provide a detailed discussion of this observation. This feedback highlights a gap in the analysis and suggests that the authors should elaborate on the implications of their findings. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm.1, which is a critical aspect that needs to be addressed for the paper to be more robust and credible. By pointing out these specific areas, the comment provides clear guidance for the authors to enhance the depth and rigor of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to strengthen the theoretical justification. Overall, the comment is 4 as it identifies important areas for improvement and encourages the authors to expand on their analysis and theoretical framework."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This provides a specific and explicit action for the authors to take, as they can directly address this suggestion by revising the notation to better reflect the tuple structure. The comment is clear and concrete, offering a direct and actionable improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that triples denoted as $(e_1, r, e_2)$ should be represented to show their tuplelike structure instead of sets. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This is a specific and actionable suggestion that could improve the clarity of the paper. However, the comment does not provide any reasoning or examples to support why this change would be beneficial or how it would enhance the understanding of the triples. Without additional context or justification, the claim is 3, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that triples denoted as $(e_1, r, e_2)$ would be clearer if they were represented to show their tuplelike structure instead of sets. This feedback is actionable and directly addresses a potential area for clarification in the paper. By suggesting a change in notation, the comment empowers the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it included additional context or examples to illustrate why this change would be beneficial. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a counterexample, noting that RBF kernels have an infinitedimensional RKHS, which would require an infinitely wide neural network to represent. The comment suggests that the limitation of neural networks in representing such kernels should be made clearer. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific sections to revise or examples to include. The action is implicit and somewhat vague, as the authors are left to infer how to improve the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, line 104, allowing the authors to accurately identify the section being addressed. It also provides specific feedback by pointing out a counterexample to the claim that every kernel can be described by a feature space parameterized by a neural network, particularly for RBF kernels with infinitedimensional RKHSs. This specificity helps the authors understand what needs to be addressed and how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is trivially not true, providing a counterexample with RBF kernels and their infinitedimensional RKHSs. The comment suggests that this limitation should be made clearer. However, the reasoning is logical and provides a specific example to support the claim, making it 4. The comment is clear and provides sufficient evidence for the reviewer to understand and address the issue. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with a claim made in the paper, noting that the assertion that every kernel can be described by a feature space parameterized by a neural network is not entirely accurate. It provides a counterexample using RBF kernels, which have an infinitedimensional Reproducing Kernel Hilbert Space (RKHS), and explains that representing such kernels with neural networks would require an infinitely wide network. This critique highlights a potential misunderstanding or oversimplification in the paper, suggesting that the limitation of neural networks in representing certain kernels should be made clearer. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue, such as suggesting additional details or examples to include in the paper. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the analysis presented in Figure 4. It questions whether GPI with noise added could reproduce the data similarly well and suggests exploring other measures to demonstrate that GPI cannot have as good a fit with behavioral data, such as behavioral trajectories or time to goal. Additionally, the comment suggests that the approach seems suitable for modeling pattern separation tasks, which have behavioral data available, and recommends including a discussion on this. While the comment provides several specific suggestions, it does not explicitly instruct the authors to address these points in their draft. The actions are somewhat implicit, as the authors need to infer how to incorporate these suggestions into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as questioning the reproducibility of GPI with noise and suggesting additional measures to demonstrate the fit with behavioral data. The comment further suggests discussing the suitability of the approach for modeling pattern separation tasks, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise and suggests exploring additional measures to demonstrate the fit with behavioral data. It also recommends discussing the suitability of the approach for modeling pattern separation tasks. While the comment provides some guidance, it lacks specific examples or detailed reasoning to fully substantiate the claims. The suggestions are somewhat vague and could benefit from more detailed explanations or references to support the claims. Therefore, the comment is rated as 3, as it provides some basis for understanding but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises several important points that could enhance the paper. It questions the reproducibility of GPI with noise and suggests exploring additional measures to demonstrate the fit with behavioral data, such as behavioral trajectories or time to goal. This feedback provides a clear direction for the authors to consider in their analysis and presentation. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, which could offer valuable insights and context for the work. While the comment is somewhat general, it offers actionable suggestions that could guide the authors in improving their draft. Therefore, the comment is rated as 3, as it provides some guidance but could be more detailed to fully assist the authors."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation regarding the performance gains of the proposed approach compared to a baseline. It notes that the difference in metrics between the baseline and the best approach is less than 1%, which is not considered significant. However, the comment does not provide any explicit or implicit suggestions for improvement or action. The authors are left without guidance on how to address this issue or enhance the performance of their approach. Therefore, the comment is 1 as it lacks any direction for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance gains of the proposed approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the metrics used for comparison, providing clear guidance on what needs to be addressed. However, the comment does not offer specific suggestions or detailed feedback on how to improve the performance gains, making it somewhat specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% on most metrics. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it difficult to assess the validity of the claim or understand its implications. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific observation regarding the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% on most metrics. This observation is important as it suggests that the performance gains may not be significant enough to warrant the complexity of the proposed approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the performance of their approach. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors would need to infer that they should consider alternative approaches or further refine their method to achieve more substantial performance gains. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. While it prompts the authors to consider the value of this information, it does not provide explicit guidance on how to address this question or what actions should be taken. The comment is somewhat vague, as it does not specify how the authors should analyze the performance or what kind of analysis would be beneficial. Therefore, the comment is 3, as it provides a direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its inquiry about the performance of the feedback network, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is important or how it might affect the feedback network. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. This question is relevant as it seeks to understand the value of the information provided in the feedback network. However, the comment does not provide any suggestions or guidance on how the authors might address this question or what actions they could take to improve their draft based on this feedback. While it identifies an area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. While it identifies a potential issue with the current analysis, it does not provide explicit guidance on how to address this concern or what actions the authors should take. The comment is somewhat vague, as it leaves the authors to infer the need for further investigation or experimentation. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment addresses the performance boost due to additional parameters, referencing specific tables (Tab 1, 2, 3) and a baseline comparison with [14]. It questions whether a better Unary baseline might still yield a performance boost. However, the comment does not explicitly mention which part of the paper these tables or the baseline comparison are located in, making it weakly grounded. The comment is specific in detailing the issue with the performance boost and the comparison with a different neural network, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references specific tables (Tab 1, 2, 3) and a baseline comparison with [14], which provides some context for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the reasoning and provide additional evidence to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references specific tables (Tab 1, 2, 3) and a baseline comparison with [14], which provides context for the concern. However, the comment does not offer actionable suggestions or detailed guidance on how the authors might address this issue or what experiments could be conducted to clarify the performance boost. While it identifies a potential area for further investigation, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment requests clarification on the final learning rates used for the deep models, specifically mentioning CIFAR10 and CIFAR100. It also notes that the authors only searched four different learning rates, which could be a concern if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the robustness of their results. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment requests clarification on the final used learning rates for deep models, particularly for CIFAR10 and CIFAR100. It also mentions that the authors only searched four different learning rates, which could be a concern if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not specify which part of the paper discusses the learning rates or the experimental setup. This makes it difficult for the authors to identify the exact section or part of the paper that needs clarification. While the comment is specific about the issue of learning rates, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the final learning rates used for deep models, particularly CIFAR10 and CIFAR100, and expresses concern about the limited search of only four different learning rates. It suggests that if the optimal learning rate for the baseline is outside the tested interval, it could potentially affect the results. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that this limitation could impact the results. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it provides some context but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the limited number of learning rates tested for the deep models, particularly CIFAR10 and CIFAR100. It points out that the authors only searched four different learning rates, which could be a limitation if the optimal learning rate for the baseline is outside the tested interval. This feedback is 3 as it highlights a potential issue with the experimental setup and suggests that the authors should consider expanding their search to include a wider range of learning rates to ensure the robustness of their results. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested alternative approaches to ensure the validity of the results. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the proposed approaches only outperform the baselines in one out of three setups, and there is no consistent trend in the results. It suggests that the results are insufficient to prove the benefits of the proposed methods and recommends additional experiments or more indepth analysis. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments or perform more detailed analysis to strengthen the paper. The comment is concrete, as it specifies exactly what needs to be done to improve the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend, making the results insufficient to prove the benefits of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims, providing clear guidance for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It provides specific evidence, such as the fact that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by providing additional examples or references to further substantiate the claim. Overall, the feedback is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This observation is significant because it questions the sufficiency of the current results to support the claims made in the paper. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the benefits of the proposed methods. This feedback is clear, actionable, and provides a clear direction for the authors to improve their draft by conducting further experiments or analysis. Therefore, the comment is 5, as it offers specific and constructive guidance for enhancing the paper\"s claims and results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that some figures are not selfexplanatory, specifically mentioning Figure 4 where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. While the comment identifies a specific issue with the figures, it does not provide explicit guidance on how the authors should improve the figures to make them selfexplanatory. The authors are left to infer that they need to add more detailed explanations or labels to the figures. This lack of explicit action makes the comment 3, as it points out a clear area for improvement but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. While the comment identifies a potential issue with the clarity of the figures, it lacks specific examples or detailed reasoning to support the claim. The authors are left to infer the exact nature of the problem, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures, noting that some figures are not selfexplanatory. It provides a concrete example, mentioning Figure 4, where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it directs the authors to improve the clarity and selfexplanatory nature of their figures. However, the comment could be more helpful if it suggested specific ways to enhance the figures, such as adding more detailed labels or explanations. Despite this, the comment provides a valuable insight that the authors can use to improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of the sampling method for convergence to the optimum but notes that this aspect is not experimentally evaluated beyond a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to conduct a more thorough experimental evaluation or what specific aspects of the sampling method should be explored. The action is implicit and somewhat vague, as the authors are left to infer how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of the sampling method for convergence to the optimum, noting that it is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. However, the comment does not specify which part of the paper discusses the sampling method or the benchmarks used, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of experimental evaluation, it lacks grounding as it does not provide clear references or guidance on which parts of the paper to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum but notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. The comment provides some evidence by mentioning the comparison to uniform sampling, but it lacks detailed reasoning or references to support the claim that this aspect is not adequately evaluated. The authors are left to infer the need for a more thorough evaluation, which could be helpful but lacks full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental evaluation of the sampling method used to obtain different initializations, which is crucial for convergence to the optimum. It points out that the evaluation is not thorough, as it only compares the sampling method to sampling from a uniform distribution in Table 1 of the supplementary material. This feedback highlights a gap in the experimental analysis and suggests that the authors should consider a more comprehensive evaluation of the sampling method\"s impact on convergence. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct a more thorough evaluation, such as exploring different sampling techniques or conducting additional experiments. Overall, the comment is 3 as it identifies an important area for improvement but lacks detailed guidance, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. The comment implies that the authors should provide a clearer explanation of the logic and comparisons, but it does not offer specific guidance on how to address these issues. The feedback is 3 as it identifies areas for improvement, but it lacks concrete suggestions or detailed guidance on how to implement the changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the logic and comparisons between the proposed method and specific references [9] and [16]. It also questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. However, the comment does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its questioning of the logic and comparisons, but without explicit grounding, it is difficult for the authors to focus their responses. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. However, the comment does not provide any specific reasoning, examples, or references to support these claims. The questions are raised as observations, but without detailed justification or evidence, they are difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to references [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. This feedback highlights areas where the authors could improve the clarity and depth of their comparisons, but it lacks specific guidance or suggestions on how to address these issues. While the comment identifies potential weaknesses in the paper, it does not provide actionable advice or detailed explanations to help the authors improve their work. Therefore, the comment is 3, as it points out areas for improvement but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide explicit guidance on how to address this question or what aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should compare their PL condition with the one mentioned in the reference. However, the lack of detailed guidance on how to perform this comparison makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific reference, \"\u00e2\u0080\u009cGlobal Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions\u00e2\u0080\u009d, arXiv:1709.03014,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the comparison of the PL condition used in the paper with the PL conditions proposed in the reference, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it does not contain a subjective claim or suggestion, it prompts the authors to consider this comparison, which could be relevant for understanding the novelty and context of their work. However, the comment lacks detailed reasoning or references to support the comparison, making it 3. The authors would need to infer the relevance of the comparison themselves, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. This is a relevant point for the authors to consider, as it could provide insights into the novelty and context of their work. However, the comment lacks detailed guidance or suggestions on how to approach this comparison or what aspects of the comparison should be highlighted. While it identifies an area for improvement, it does not provide actionable feedback or specific advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline [31, 33, *]. However, the comment does not specify how the authors should conduct this analysis or what specific aspects of the computational effort need to be addressed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a complete lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This is a crucial aspect that needs to be addressed for a fair comparison with the baseline. However, the comment lacks specific guidance on how the authors should conduct this analysis or what specific aspects of the computational effort need to be addressed. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but could be more comprehensive with actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the analysis. While the authors can infer that they need to clarify the analysis and provide theoretical evidence, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, but it does not specify which part of the paper this analysis is discussed. The authors cannot confidently determine which section or figure this analysis is related to, making the comment weakly grounded. However, the comment is specific in detailing the issue of the lack of clarity and the absence of theoretical evidence, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, noting that the trend is not clear across different model architectures and that no theoretical evidence is provided. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It highlights that the analysis is underwhelming and points out that the trend is not clear across different model architectures, with no theoretical evidence provided to support the correlation. This feedback is valuable as it directs the authors to a specific aspect of their work that needs further clarification and theoretical grounding. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of how to strengthen the analysis. Overall, the comment is 3, as it offers a clear direction for improvement but lacks depth in terms of actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It also questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for selfsupervised learning (SSL) algorithms. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to mitigate the potential trap or clarify the implications for SSL algorithms. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the experiments conducted in Section 4.2, particularly the use of AutoAugment as a stronger augmentation strategy. It raises a concern about potential information leakage due to the supervised training on ImageNet, which is a specific aspect of the paper. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about information leakage and its implications for the conclusions drawn in the paper, particularly regarding the pretraining dataset matching the target dataset for linear classification and its relevance to SSL algorithms. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for selfsupervised learning (SSL) algorithms. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a significant issue. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how it might impact their results. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for selfsupervised learning (SSL) algorithms. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the implications for SSL algorithms. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) could be moved to the supplementary materials. This is an explicit action that the authors can take to improve their draft. The comment provides a clear direction on where to place the objective, making it actionable. However, it does not specify how this placement would benefit the paper or what aspects of the supplementary materials would be relevant. The action is explicit but somewhat vague in terms of its impact, as it does not provide detailed guidance on what to include in the supplementary materials. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests moving the empirical version of the objective (3) to the supplementary materials. However, it does not specify which part of the paper this objective is located in, making it difficult for the authors to identify the exact section to address. The comment is specific in its suggestion regarding the placement of the objective, but it lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be appropriate to put in the supplementary materials. This is a suggestion for improvement, but it lacks specific reasoning or examples to support why this placement would be beneficial. Without further explanation or justification, the claim is 3, as it provides a potential action but does not fully substantiate the reasoning behind it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the empirical version of the objective (3) could be moved to the supplementary materials. This is a specific and actionable suggestion that could help the authors improve the organization and clarity of their paper. By providing a clear direction for where to place the objective, the comment offers valuable guidance for the authors to enhance the presentation of their work. However, it could be more helpful if it included additional context or reasoning for why this placement would be beneficial. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific claim about Corollary 10, stating that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their draft. It lacks concrete guidance on what changes could be made to clarify or strengthen the argument. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" which allows the authors to accurately identify the specific part of the paper being addressed. It also specifies what the issue is: that Corollary 10 only shows uncertainty sampling moving in descent directions of the expected 01 loss, which does not necessarily mean it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This claim is 3 as it provides a logical reasoning based on the interpretation of the corollary. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to understand the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Corollary 10, noting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily imply that it is minimizing the expected convex surrogate. This feedback is clear and actionable, as it points out a potential misunderstanding or gap in the interpretation of the corollary. However, the comment could be more helpful if it provided additional context or suggestions on how the authors might address this issue or clarify their argument. Overall, the comment is 3, as it provides a clear point of improvement but lacks depth in terms of actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the significance of the performance improvement of the proposed methods, as shown in Figure 3, where the improvement is only ~0.02. It also suggests that using tables to directly show key improvements could be more intuitive and detailed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider the significance of the improvement and potentially use tables to present it more effectively. While the comment is 3, it lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the significance of the performance improvement and the suggestion to use tables for better presentation. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, with the biggest improvement being only ~0.02. It also suggests that using tables to directly show key improvements would be more intuitive and detailed. However, the comment lacks specific examples or references to support the claim about the significance of the improvement. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the improvement shown in Figure 3 is not significant, with the largest increase being only ~0.02. It also suggests that using tables to directly present key improvements would be more intuitive and detailed. This feedback is 3 as it highlights a potential area for improvement in the presentation of results. However, the comment could be more helpful if it provided specific guidance on how the authors might address the issue or what changes could be made to the tables to better illustrate the improvements. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the experimental validation, including the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their experimental validation or positioning, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the experimental validation of the paper, specifically mentioning the limitation of considering only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific because it details the issues with the experimental validation and positioning. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, citing the limited depth of the networks considered (2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, specifically the consideration of layer redundancy in the context of network pruning, providing a specific example. The claim is 3 as it provides some justification for the criticism, but it lacks detailed reasoning or references to support the specific issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several weaknesses in the experimental validation of the paper, specifically noting the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. While the comment highlights these areas for improvement, it does not offer detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas for enhancement, but it lacks depth and actionable advice, making it a 3 out of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any specific suggestions or guidance on how the authors might address this limitation or enhance their work. Without explicit instructions or concrete advice, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the technical contribution are limited or how the authors might address this limitation. Without specific references or detailed feedback, the authors cannot effectively respond to the comment. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the crossdomain recommendation setting. However, the comment lacks specific details or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the lack of technical contribution and extension based on a typical model for the crossdomain recommendation setting. This feedback is clear and actionable, as it highlights a critical area where the authors could enhance their work. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this limitation or improve their technical contribution. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, allowing them to focus on enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion by adding the baselines to the table. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be added to the table to improve understanding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim. The authors would need to infer the need for such baselines to enhance the understanding of the gap between full supervision and SSL. Therefore, the comment is 3, as it provides a logical basis but lacks detailed justification or references.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their draft by including additional baselines. By adding these baselines, the authors can gain a more comprehensive understanding of the performance differences between fully supervised and SSL approaches. This feedback is valuable and directly addresses a potential area for improvement in the paper, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the components of the approach are not novel, as they have been used in previous works. It mentions specific examples of weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies that are similar to existing methods. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to enhance the novelty of their approach. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the approach by pointing out that the weak predictors used (MLP, Regression Tree, Random Forest) and the sampling strategy are similar to existing methods. It references specific works [2, 3, 7] and [5] to support the claim. However, the comment does not specify which part of the paper discusses the approach or the results in Table 2 of Appendix C. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the components of the approach, such as weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies, are not novel and have been used in previous works. It provides specific references [2, 3, 7] and [5] to support the claim, citing prior studies that have used similar methods. The comment also notes that the results of the proposed WeakNAS are almost the same as those of BRPNAS, as shown in Table 2 of Appendix C. This provides a clear basis for the authors to understand the novelty of their approach and how it compares to existing methods. The claim is wellsupported with specific references and examples, making it 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the approach, specifically pointing out that the weak predictors and sampling strategies used are similar to those in existing works. It provides specific references to support this claim, such as [2, 3, 7] and [5], which helps the authors understand the context and the limitations of their approach. However, the comment could be more helpful if it suggested specific ways the authors could differentiate their work or enhance its novelty. While it highlights a critical area for improvement, the feedback is 4 as it directs the authors to address the lack of novelty in their approach. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the OT sample selection process in section 2.4.3, specifically regarding whether it runs once or iteratively with the EP module updates during training. It also asks about the iterative conduct of optimizing the loss of equation (10) and solving OT in equation (3). Additionally, the comment requests more details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment provides explicit questions and requests for clarification, it does not offer concrete suggestions on how to address these issues or improve the draft. The actions are implicit and somewhat vague, as the authors need to infer how to incorporate the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the OT sample selection process in section 2.4.3, which is fully grounded as it explicitly mentions the section. It also requests more details and a flow chart to clarify the process, which is specific to the topic of OT sample selection. However, the comment does not specify what is missing or needs to be addressed in detail, making it somewhat specific. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, specifically whether it runs once or iteratively with EP module updates during training. It also asks about the iterative conduct of optimizing the loss of equation (10) and solving OT in equation (3). Additionally, it requests more details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment provides specific questions and requests for clarification, it lacks detailed reasoning or references to support the claims. The authors would need to infer the need for more information and a flow chart to improve their understanding of the process. Therefore, the comment is barely verifiable, as it lacks sufficient evidence or justification to fully support the claims.", "helpfulness_rationale": "The review comment raises several important questions about the OT sample selection process in section 2.4.3, specifically regarding whether it runs once or iteratively with the EP module updates during training. It also asks about the iterative conduct of optimizing the loss of equation (10) and solving OT in equation (3). Additionally, the comment requests more details and a flow chart to clarify the process, as well as the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. These questions and requests provide valuable feedback to the authors, guiding them to clarify and improve the clarity of their methodology. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the feedback is 3 as it identifies key areas for improvement and encourages the authors to provide more detailed explanations and visual aids."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the experimental evaluation of the continuous task setting, noting that while the authors discuss how KG handles continuous tasks, there are no experiments to support this discussion. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks for a comparison of their empirical performance with ConBO. The comment implies that the authors should include experiments with continuous tasks and compare the performance of entropy methods, but it does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of how KG handles continuous tasks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization, asking for a comparison of their empirical performance with ConBO. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of experiments with continuous tasks and the comparison of entropy methods for conditional optimization with ConBO. It does not contain a subjective claim or opinion but rather poses a question that requires the authors to provide justification or evidence. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a gap in the experimental evaluation of the paper, specifically noting that while the authors discuss how KG handles continuous tasks, there are no experiments to support this discussion. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks for a comparison of their empirical performance with ConBO. This feedback is 4 as it highlights a specific area where the authors could strengthen their experimental evaluation and provide a clear direction for future work. However, it could be more helpful if it included suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment provides valuable insights that would guide the authors in improving their draft, making it a 4 feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the methodology used to calculate precision, recall, and F1score for a 4class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity would be more informative for comparing model performance. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the methodology used to calculate precision, recall, and F1score for a 4class classification of breast density, and suggests that reporting AUC with sensitivity and specificity would be more informative for comparing model performance. However, the comment does not specify which part of the paper discusses the classification of breast density or where the calculations are detailed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific in suggesting improvements, the absence of grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the methodology used to calculate precision, recall, and F1score for a 4class classification of breast density and suggests that reporting AUC with sensitivity and specificity would be more informative for comparing model performance. While the comment provides a clear rationale for the suggestion, it lacks specific examples or references to support the claim that AUC with sensitivity and specificity is a more informative metric. The authors are left to infer the reasoning, which could be improved with additional justification or examples. Therefore, the comment is 3, as it provides a basis for improvement but lacks detailed support.", "helpfulness_rationale": "The review comment raises specific questions about the methodology used to calculate precision, recall, and F1score for a 4class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity would be more informative for comparing model performance. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific changes the authors should make to their draft. The feedback is 3 as it points out potential areas for enhancement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the Transformer in the context of machine learning, suggesting that the authors\" modification, while claimed, does not provide significant insight. It also questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the paper or what specific changes should be made to enhance the novelty and significance of the work. As a result, the authors are left without clear direction on how to respond to the feedback, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the Transformer in the field of machine learning, suggesting that its adoption is no longer novel. It also questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific in its critique of the novelty and the significance of the results, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the novelty of the Transformer in the field of machine learning, suggesting that its adoption is no longer novel. It questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the lack of detailed evidence or references makes it challenging to fully assess the validity of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the Transformer in the field of machine learning, suggesting that its adoption is no longer novel. It questions the significance of the ablation study results, noting that the selfcross attention brings limited improvement. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve the paper\"s contribution. While it identifies areas for improvement, it lacks depth and guidance, making it 3. The authors would need to infer what changes to make, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider conducting experiments on other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a clear and explicit action for the authors to take, which is to expand their experiments to include more types of sentence pair tasks. This action is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation in the experiments conducted by the authors, specifically noting that they only evaluate sentence similarity and open domain QA tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for additional experiments on sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This provides a clear direction for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited, as the authors only conduct evaluations on sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. While the comment identifies a limitation in the scope of the experiments, it lacks specific examples or references to support the claim that these additional tasks are necessary or would enhance the paper\"s contribution. The reasoning is somewhat clear but could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to conduct these additional experiments or why these tasks are important. Overall, the comment is 4 as it highlights a significant area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the prompt should be included in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, it does not provide any explicit or implicit actions for the authors to take, such as where to include the prompt or how to access the supplement. The comment lacks concrete guidance on how to address this issue, making it 1. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, it does not specify which part of the paper the prompt is intended for or how it relates to the content of the paper. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on what needs to be addressed or how to include the prompt effectively. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, the comment does not provide any specific guidance or suggestions on how to include the prompt or where to place it effectively. It lacks actionable advice, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback provides a clear and explicit action for the authors to consider, as it highlights a potential oversight in the introduction. The comment is specific in identifying which part of the introduction needs to be addressed and provides a concrete suggestion for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment critiques the introduction by pointing out that the claim \"these shape constraints do not require tuning a free parameter\" is technically true but overlooks the fact that the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is fully grounded as it explicitly mentions the part of the introduction being addressed, allowing the authors to accurately identify the section being discussed. The comment is also specific, as it clearly specifies what needs to be addressed in the introduction by highlighting the oversight in the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is 4 as it provides a logical reasoning for why the claim might be misleading, suggesting that the authors should consider the hyperparameter aspect of constraint choice. However, it could be more robust with additional examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It points out that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it provides a specific suggestion for the authors to consider in their introduction. By highlighting a potential oversight, the comment helps the authors refine their claims and ensure they accurately represent the technical aspects of their work. Therefore, the comment is 5, as it offers a clear and constructive critique that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the triviality of the convergence proof, suggesting that it lacks substantial novelty and rigor. It provides a specific example of how the proof could be adapted based on a previous modification in the appendix. However, the comment does not explicitly instruct the authors to address this issue or provide detailed guidance on how to improve the proof. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising the proof to enhance its novelty and rigor. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Triviality of Convergence Proof\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, explaining that it lacks substantial novelty and rigor due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The comment provides clear guidance on how the authors might address this issue by suggesting that previous theorems can be adapted with straightforward modifications. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial, as it relies on the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The reviewer suggests that the proof lacks substantial novelty and rigor, and that previous theorems can be adapted with straightforward modifications. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof of convergence, noting that it appears trivial due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The reviewer suggests that the proof lacks substantial novelty and rigor, and that previous theorems can be adapted with straightforward modifications. This feedback is clear and actionable, providing the authors with a specific area to address and improve their work. However, the comment could be more helpful if it offered additional guidance on how to enhance the proof\"s novelty or rigor. Overall, the comment is 4, as it effectively highlights a critical weakness and suggests a path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential conflict in the paper regarding the performance of the multienvironment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this conflict or clarify the statements. The action is implicit, as the authors need to infer that they should clarify the conflicting claims. The action is vague because it does not specify how to clarify the statements or what aspects of the claims need to be addressed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the conflicting claims made in the paper about the performance of the multienvironment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not specify which part of the paper contains these conflicting statements, making it weakly grounded. The comment is specific in identifying the issue, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point identifies a potential conflict in the paper regarding the performance of the multienvironment model. It highlights that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this conflict or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential conflict in the paper regarding the performance of the multienvironment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. While the comment highlights an inconsistency in the paper\"s claims, it does not provide any guidance or suggestions on how the authors might address this conflict or clarify the statements. The feedback is 3 as it points out an issue that needs attention, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment identifies these areas, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to motivate the applications and consider using streaming datasets. However, the lack of specific suggestions or examples makes the action vague and difficult to implement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective of designing fast label aggregation algorithms for a streaming setting, noting that it lacks motivation for the applications. It also points out that the empirical analysis uses static datasets, which limits the paper\"s usefulness. However, the comment does not specify which part of the paper discusses the motivation or the datasets used, making it weakly grounded. The comment is specific in identifying the issues with motivation and the use of static datasets, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting and that the empirical analysis uses static datasets, limiting the paper\"s usefulness. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the scope of the study is underspecified, suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the scope of the study and the missing CoT baselines for incontext learning of Large Language Models. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of additional relevant CoT baselines for incontext learning of Large Language Models in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is 3, as it provides a basis for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a potential issue with the scope of the study, suggesting that it focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of additional relevant CoT baselines for incontext learning of Large Language Models in Table 2 and 3, referencing a question for clarification. This feedback is 3 as it highlights a potential area for improvement and suggests the inclusion of additional baselines. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested additional relevant baselines. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit suggestions on how the authors might address this connection or incorporate it into their work. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the connection between the statement about the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for clarification or further discussion, it does not provide specific suggestions or guidance on how the authors might address this connection. The comment lacks actionable insights, making it 3 as it highlights a potential area for improvement but does not offer detailed feedback or suggestions for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue and suggests a direction for improvement, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and discusses the performance of the method with an increasing number of identities, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of scalability and suggests a potential solution by presetting the capacity to a small number. The comment provides a clear direction for the authors to consider how to scale up the method without compromising performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to preset the capacity to a small number is a reasonable suggestion, but the lack of detailed explanation or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It provides a specific example from Table 3 (a) to illustrate this issue, which is valuable for the authors to understand the limitations of their method. The comment also suggests a potential solution by presetting the capacity to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. This feedback is actionable and provides a clear direction for the authors to address a significant weakness in their work. However, the comment could be more helpful if it offered additional guidance on how to scale up the method or explored alternative solutions. Overall, the comment is 4, as it identifies a critical issue and provides a starting point for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or explanation of how their approach is NLPspecific. This feedback is implicit, as the authors need to infer that they need to clarify the NLPspecific aspects of their approach. However, the action is vague because it does not provide specific guidance on what needs to be clarified or how to demonstrate the NLPspecificity of their approach. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made or which sections or figures might contain this information. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what aspects of the approach are NLPspecific, leaving the authors uncertain about how to address the feedback. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any specific evidence or reasoning to support this claim, nor does it offer examples or references to substantiate the assertion. Without detailed justification or supporting evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or explanation of how their approach is NLPspecific, which is a critical aspect for a paper focused on NLP. This feedback is 3 as it highlights a potential gap in the authors\" claim and encourages them to clarify the NLPspecificity of their approach. However, the comment could be more helpful if it provided specific guidance on how to demonstrate the NLPspecificity of their work. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that several curriculum learning methods have been discussed in Section 1, but it does not provide explicit guidance on how to address the need for designing a new curriculum learning method for text graphs. While the comment implies that the authors should justify the need for a new method, it lacks concrete suggestions or detailed instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on why existing methods cannot be applied. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that several curriculum learning methods have been discussed in Section 1 but does not provide a clear justification for why a new method is needed for text graphs. It highlights a research gap by noting that the paper does not discuss why existing methods cannot be applied. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the reasoning behind the need for a new method. The absence of detailed reasoning or examples makes the claim 3, as it leaves the authors with a general understanding but without a clear path to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while several curriculum learning methods have been discussed, the need for designing a new method for text graphs is not justified. It highlights a research gap, specifically noting that the paper does not discuss why existing methods cannot be applied. This feedback is 3 as it directs the authors to address a critical aspect of their work that needs further justification. However, the comment could be more helpful if it provided specific examples or suggestions for how to justify the need for a new method. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive and actionable to fully assist the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how to improve the writing or suggest specific actions to take. The authors are left to infer that they need to clarify the definition, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of clarity in the definition of \"relevant\" auxiliary model weights, providing a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. However, the comment does not provide any specific examples, reasoning, or references to support why this is a problem or how it could be improved. Without additional context or justification, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the writing could be improved, namely the clarity of the definition of \"relevant\" auxiliary model weights in definition 2.1. This feedback is actionable as it points out a potential issue with the clarity of the writing, which could hinder the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or examples of how to make the definition more understandable. Overall, the comment is 3 as it highlights an area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the quantitative evaluation results, noting that they only reflect middle outputs and not final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\u2019s superiority to competitors. The comment implies that the authors should consider a quantitative comparison on the final outputs, but it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the final outputs should be evaluated. While the action is implied, it is vague and lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the quantitative evaluation results and the comparison of final outputs. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the quantitative evaluation results, specifically questioning whether they only reflect middle outputs rather than final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\u2019s superiority to competitors and asks if a quantitative comparison on the final outputs is possible. While the comment identifies a potential issue with the evaluation, it does not provide specific examples or references to support the claim that the current evaluations are insufficient. The lack of detailed reasoning or evidence makes the claim 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results, noting that they only reflect middle outputs rather than final outputs. This observation is crucial because it questions the persuasiveness of the current evaluations in confirming ModelAngelo\"s superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be necessary to strengthen the claims. However, it does not provide detailed guidance on how to conduct this comparison or what specific aspects of the final outputs should be evaluated. While the comment highlights a significant weakness, it lacks actionable suggestions or detailed feedback, making it 3. The authors would need to infer the need for a more comprehensive evaluation, which could be improved with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experimentbased evidence, confusing figures (e.g., \"sample count\" in Figure 2), and the lack of error bars or pvalues in statistical inferences. While the comment identifies these areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they need to add more details, figures, and statistical measures, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses issues with the qualitative nature of explanations and the lack of detail in simulation or experimentbased evidence, specifically mentioning figures and statistical inferences. However, it does not specify which parts of the paper these issues are present in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as adding more details to the figures and including error bars or pvalues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the explanations are qualitative and that procedures are described minimally or not at all, especially in simulation or experimentbased evidence. It also notes that some figures are confusing, such as the \"sample count\" in Figure 2, and that more details are needed to understand what was done in each simulation. Additionally, the comment suggests that statistical inferences should include error bars and/or pvalues. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claims. Therefore, the claim is 3, as it offers some basis for improvement but could be more robust with additional evidence or references.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the qualitative nature of explanations, the lack of detail in simulation or experimentbased evidence, confusing figures, and the absence of error bars or pvalues in statistical inferences. It provides specific examples, such as the confusion surrounding the \"sample count\" in Figure 2, and suggests that adding more details, figures, and statistical measures would enhance the paper\"s clarity and rigor. However, the comment could be more helpful if it offered additional guidance on how to improve these aspects or suggested specific ways to enhance the figures and statistical analyses. Overall, the feedback is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. While the comment provides a clear direction for improvement, it does not specify which settings need to be shown or how to mimic the prior work. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. However, the comment does not specify which part of the paper discusses the algorithm or the settings, making it difficult for the authors to identify the exact section that needs improvement. While the suggestion is specific about the type of information needed, the lack of grounding makes it challenging for the authors to act upon the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. However, the comment lacks specific examples or detailed reasoning to support the claim that the current draft does not adequately address these aspects. Without concrete evidence or references, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could be enhanced by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. While the comment offers a clear direction for improvement, it lacks specific guidance on which settings need to be shown or how to effectively mimic the prior work. This makes the feedback 3, as it provides a general idea of what could be improved but does not offer detailed actionable steps. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of the specific examples presented in the paper, particularly concerning the biases of target statistics and the prediction shift of gradient values. While it identifies a gap in the paper\"s discussion, it does not provide explicit guidance on how the authors might address this issue or what additional analysis could be conducted to clarify the generalizability of these findings. The action is implicit and somewhat vague, as the authors are left to infer how to improve the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the paper\"s discussion on the generalizability of specific examples, particularly concerning the biases of target statistics and the prediction shift of gradient values. It explicitly mentions section 3.2 and Theorem 1, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be addressed, namely the lack of clarity on how general these situations are. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the paper\"s discussion regarding the generalizability of specific examples, particularly concerning the biases of target statistics and the prediction shift of gradient values. It questions whether the paper adequately explains how general these situations are. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the discussion lacks clarity. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the generalizability of the specific examples discussed in sections 3.2 and Theorem 1. It points out that while the paper acknowledges the potential for biases and prediction shifts, it does not adequately explain how general these situations are. This feedback is clear and actionable, as it directs the authors to address the lack of clarity in their discussion. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or generalizability of the examples. Overall, the comment is 4, as it highlights a significant issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors have made any additional novel effort in the Sec. 3.1 for 3D Gaussians generation, noting that it seems to follow the previous work, Luciddreamer. While the comment implies that the authors should clarify the novelty of their approach, it does not explicitly instruct them to provide evidence or details about any additional contributions. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the novelty of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. However, it does not specify which part of the paper Sec. 3.1 corresponds to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its request for clarification regarding novelty, but the lack of grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. While the comment implies that the authors should address the novelty of their approach, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of explicit evidence or justification makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 2, as it lacks sufficient support to fully understand the issue.", "helpfulness_rationale": "The review comment raises a question about the novelty of the Sec. 3.1 for 3D Gaussians generation, noting that it appears to follow the previous work, Luciddreamer. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the novelty of their approach, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even in simple cases. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves acknowledge. However, the comment does not provide explicit or implicit suggestions on how to address these issues or improve the paper. The authors are left without guidance on how to enhance the tractability of MMD DRO or refine the upper bound. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even in simple cases. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves acknowledge. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. The lack of specific references or sections makes the comment weakly grounded. While it provides some specificity by mentioning the issues with the tractability of MMD DRO and the limitations of the upper bound, it does not offer detailed guidance on how to address these concerns. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even in simple cases. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves acknowledge. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises several valid concerns about the tractability of MMD DRO and the limitations of the upper bound presented in Theorem 3.1. It points out that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also highlights that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even in simple cases. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves acknowledge. However, the comment does not provide specific suggestions or guidance on how to address these issues or improve the paper. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some insights but lacks depth and guidance for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the Appendix H section should be reorganized to improve its readability. However, it does not provide specific guidance on how to reorganize the section or what aspects of the organization are problematic. The comment lacks concrete details, leaving the authors uncertain about the exact steps to take. As a result, the action is implicit and vague, making it difficult for the authors to apply the feedback effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the Appendix H section should be reorganized to improve its readability. However, it does not specify which part of the paper Appendix H refers to, making it difficult for the authors to identify the exact section that needs reorganization. Additionally, the comment does not provide specific details on what aspects of the organization are problematic or how the reorganization should be implemented. This lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the Appendix H section should be reorganized to improve its readability. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this reorganization is necessary or how it would benefit the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the organization of Appendix H, suggesting that it is difficult to follow. However, it lacks specific details or suggestions on how the authors might reorganize the section to improve readability. Without actionable guidance or examples, the feedback is vague and does not provide the authors with a clear path to address the issue. As a result, the comment is 2, as it offers limited insight and lacks depth in addressing the concerns."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the paper\"s clarity and reproducibility. It suggests that while the paper provides an intuitive understanding, it lacks the necessary technical details for reproduction, such as specifics about the RNN implementation. However, the comment does not explicitly instruct the authors to include these details or provide guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional details and how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper and the issue of reproducibility, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the lack of technical details required for reproduction, such as specifics about the RNN implementation, and suggests that these details are missing from both the paper and the supplementary material. This provides clear guidance on what needs to be addressed to improve the paper\"s reproducibility. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is written to provide an intuitive understanding but lacks the necessary technical details for reproduction, such as specifics about the RNN implementation. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it is based on an observation but lacks substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reproducibility, noting that while it provides an intuitive understanding, it lacks the necessary technical details for reproduction. Specifically, it points out the absence of details about the RNN implementation, such as the number of units, and other technical aspects. This feedback is clear and actionable, as it directs the authors to include specific technical details to enhance the paper\"s reproducibility. However, the comment could be more helpful if it provided examples of where these details are missing or suggested specific types of information that should be included. Overall, the comment is 4, as it effectively highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars and more random trials to potentially eliminate random fluctuations in the results. While the comment provides explicit guidance on what should be added to the figure, it does not specify how to implement these changes or where to add them. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests improvements to Figure 1, specifically mentioning the need for error bars and more random trials to address potential random fluctuations. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed to enhance the figure, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with error bars and more random trials to address potential random fluctuations. However, it does not provide any specific reasoning, examples, or references to support why these changes would be beneficial or how they would impact the results. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improving Figure 1, such as adding error bars and conducting more random trials to address potential random fluctuations in the results. These suggestions are actionable and directly address a potential weakness in the presentation of the data. By offering concrete improvements, the comment empowers the authors to enhance the clarity and robustness of their findings. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or why these changes are expected to improve the results. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be further enhanced with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. It also points out that Figure 1 lacks clarity regarding the correspondence of different learning rates and steps to the points in the graph. This feedback provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment suggests providing a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. However, it does not explicitly mention which part of the related work section this should be included in, making it weakly grounded. The comment also points out a lack of clarity in Figure 1 regarding the correspondence of different learning rates and steps, which is specific but does not provide guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. However, it does not provide any reasoning or evidence to support why this suggestion is necessary or beneficial. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis for the suggestion. Therefore, the claim is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft, such as adding a brief introduction to energy models in the related work section and clarifying the correspondence of different learning rates and steps in Figure 1. These suggestions are actionable and directly address potential weaknesses in the paper, offering clear guidance for the authors to enhance their work. However, the comment could be more helpful if it included additional details or examples to further clarify the issues. Overall, the feedback is 4, as it provides a solid foundation for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is devoted to a general introduction of DNNs and lacks any mention of drift. It suggests that this paragraph is not central to the paper\"s focus on detecting drift types and magnitude, and that it provides little valuable information. This feedback is clear and specific, as it identifies a specific part of the paper that needs revision and provides a clear rationale for why it is not relevant to the paper\"s core focus. The authors can directly infer that they should either remove or reframe this paragraph to align with the paper\"s main contribution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the paragraph focuses on a general introduction of DNNs without mentioning drift, which is central to the paper\"s core focus. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. The comment suggests that this paragraph provides little valuable information to readers. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to independently assess the relevance of the paragraph to the paper\"s focus to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction section, noting that it focuses on a general introduction of DNNs without mentioning drift, which is central to the paper\"s core focus. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of the introduction to their work. By highlighting the lack of focus on drift, the comment provides a clear direction for improvement, suggesting that the authors should either remove or reframe the paragraph to align with the paper\"s main contribution. This feedback is 4 as it offers a specific and actionable suggestion, though it could be further enhanced by providing additional guidance on how to reframe the introduction. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should make the different curves in Figure 2 more distinguishable by using styles like dashed lines or adding color. This provides a clear and explicit action for the authors to take, as they know exactly how to improve the figure. The comment is specific and concrete, giving detailed guidance on how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure by suggesting the use of styles like dashed lines or adding color. This feedback is detailed and actionable, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 2 right is difficult to distinguish between different curves and recommends using styles like dashed lines or adding color. This is a subjective observation and suggestion for improvement, but it lacks specific reasoning or examples to support why these changes would be beneficial. Without additional context or evidence, the claim is 3, as it provides a suggestion but does not fully explain its relevance or impact. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between different curves. It provides a clear suggestion for improvement by recommending the use of styles like dashed lines or adding color to enhance the figure\"s clarity. This feedback is actionable and directly addresses a potential weakness in the presentation of the data, offering a concrete way for the authors to improve the figure. However, the comment could be more helpful if it included additional suggestions or considerations for other aspects of the figure or the overall presentation of the results. Despite this, the comment is 4 as it provides a clear and actionable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. It recommends toning down the introduction and suggesting that the task is more accurately described as a feedbackdriven QA in the form of a dialog. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to tone down the introduction or provide specific examples of what should be included. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the claims made in the introduction, suggesting that they are not aligned with the tasks and models described. It recommends toning down the introduction and describing the task as a feedbackdriven QA in the form of a dialog. However, the comment does not specify which part of the paper the introduction is located in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. The comment suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they do not align with the tasks and models described. It suggests that the authors should tone down the introduction and consider describing the task as a feedbackdriven questionanswering process in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific direction for revising their introduction to better reflect the actual content of the paper. However, the comment could be more helpful if it included additional suggestions or examples to guide the authors in making the necessary revisions. Overall, the comment is 4, as it provides a clear and actionable critique that would benefit the authors."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples of how the performance of the models in Table 4 is behind more recent models, citing GLaMM and UNINEXT. However, it does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of how the performance of the models in Table 4 is behind more recent models, citing specific models and their performance metrics. This level of detail helps the authors understand exactly what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of how these models perform compared to the current models. The claim is supported by the inclusion of references [ref1] and [ref2], which provide evidence for the performance of GLaMM and UNINEXT, respectively. This level of detail and support makes the claim 5, as it provides a clear basis for understanding the performance gap. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that they are behind more recent models. It provides concrete examples of how these models perform, referencing GLaMM and UNINEXT, which achieve higher performance metrics. This feedback is valuable as it highlights a clear area for improvement and provides specific examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this performance gap or what steps they could take to improve their models. Despite this, the comment is 4 as it directs the authors towards a specific area of concern and provides a basis for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts. The comment implies that the current phrasing, \"evidence,\" is too strong and suggests a more specific term like \"Fig.\" However, it does not provide explicit guidance on how to revise the claim or what specific changes are needed. The action is implicit and somewhat vague, as the authors need to infer that they should replace \"evidence\" with a more precise term and potentially reference a figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts, recommending a more specific term like \"Fig.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts. The comment implies that the current phrasing, \"evidence,\" is too strong and suggests a more specific term like \"Fig.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The comment lacks detailed reasoning or justification, which limits its verifiability. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the claim about the evidence supporting the idea that some information is learned before the model can use the concepts is too strong. It suggests that the authors should revise their claim to be more precise, such as by using a term like \"Fig.\" This feedback is clear and actionable, as it directs the authors to refine their language and make their claims more accurate and specific. However, it could be more helpful if it provided additional guidance on how to revise the claim or what specific changes to make. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, it does not provide explicit guidance on how the authors should address this point or what changes might be needed in their draft. The action is implicit, as the authors would need to infer that they should consider the rationale for using Triton over CUDA and potentially provide a justification for their choice. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Kernels are implemented with OpenAI\"s Triton, not CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains why the implementation choice is unnecessary due to engineering improvements. This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, the comment does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific implementation detail regarding the use of OpenAI\"s Triton for kernels, noting that it is unnecessary due to wellknown engineering improvements. While the comment highlights a potential area for clarification or justification in the paper, it does not provide detailed guidance on how the authors might address this issue or what changes could be made to their draft. The feedback is 3 as it points out a specific area that requires attention, but it lacks depth and actionable suggestions, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. It mentions specific sections of the paper (3.2 and 3.3) where this issue is discussed. However, the comment does not provide explicit guidance on how the authors might address this issue or improve their analysis. While the authors can infer that they need to strengthen their analysis or provide a more detailed discussion of the limitations of the current approach, the lack of concrete suggestions makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. The comment provides a specific example of where this issue is discussed in the paper (Sections 3.2 and 3.3). However, it lacks detailed reasoning or references to support the claim that the extension is indeed trivial or that the work bypasses the core problem of overparametrized neural networks. Without further elaboration or evidence, the claim is 3, as it provides a basis for the authors to consider but lacks sufficient depth to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the analysis of neural networks is considered less significant due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers the easy wide fullyconnected neural networks. This feedback is 3 as it highlights a potential weakness in the analysis and suggests that the authors might need to address this issue or provide a more detailed discussion of the limitations of their approach. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could improve their analysis or address the identified gap. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results presented in the paper, noting that while there are good performance results with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback suggests that the authors should include results with larger models to provide a more comprehensive evaluation of their approach. However, the comment does not specify which part of the paper should be updated or how the results should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add results for larger models and potentially update the discussion section to reflect this addition. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"imageNet classification\" and the models used, \"ResNet50/34/18,\" and suggests the inclusion of results for \"larger models like ResNet101/152.\" This provides clear guidance on which part of the paper needs attention. However, the comment is somewhat specific as it does not provide detailed guidance on how to include these results or what aspects of the results should be highlighted. The authors can infer that they need to add results for larger models, but the lack of specific instructions makes it somewhat specific. Therefore, this comment is classified as fully grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results with larger models like ResNet101/152, despite good performance with ResNet50/34/18. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to verify the claim or understand why it is important. The comment is therefore considered 1.", "helpfulness_rationale": "The review comment points out a gap in the results presented in the paper, specifically noting the absence of performance results with larger models like ResNet101/152, despite good performance with ResNet50/34/18. This feedback highlights an area where the authors could enhance their evaluation by including results with larger models. However, the comment lacks specific guidance on how to incorporate these results or what aspects of the results should be emphasized. While it identifies a potential improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework. It points out a discrepancy in the terminology used (\"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology used in these sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper (Stroh et al. 2017). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework, pointing out a discrepancy in terminology. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract and introduction use inconsistent terminology regarding the cost of the multifidelity framework, specifically mentioning \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. While the comment identifies a potential issue with clarity, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the inconsistency, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework. It points out a discrepancy in terminology, noting that the abstract uses \"relatively inexpensive\" while the introduction uses \"expensive to evaluate.\" This feedback highlights a need for the authors to clarify their terminology to avoid confusion. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples or rephrasing the terms to ensure consistency. While it points out a potential area for improvement, the feedback is 3 as it directs the authors\" attention to a specific issue that could impact the clarity of their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment also suggests comparing the paper to other approaches that have been proposed since the initial work and have significantly improved the results. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the captioning experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the comparison of results on the official COOC leader board on the blind test set, referencing specific examples and related work. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the captioning experiment with official test sets or development sets, but it suggests comparing them on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment provides specific references and examples to support its claim, making it 4. However, it could be more robust with additional details or examples to fully substantiate the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. Additionally, it suggests comparing the paper to other approaches that have been proposed since then and have significantly improved the results, providing a clear direction for improvement. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions or provided specific examples of how to compare the results. Overall, the feedback is 4 as it offers actionable insights for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the reliability of the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to verify the results, what steps to take to improve the reliability of the findings, or how to address the discrepancy between MSE and MAE. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE, raising concerns about their validity. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why the results are considered unreliable or how to address the discrepancy between MSE and MAE. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. This feedback is clear and actionable, as it highlights a potential problem with the experimental findings that the authors should investigate further. However, the comment could be more helpful if it provided suggestions on how to address the discrepancy between MSE and MAE or what steps the authors could take to ensure the reliability of their results. While it points out a critical issue, it lacks detailed guidance on how to resolve it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of novelty in the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their methodology or what specific aspects need to be improved. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what aspects of the methodology lack novelty or how the proposed metaalgorithm is a direct extension of existing methods. Without specific guidance or examples, the authors cannot effectively address the feedback. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that there is not much novelty in the methodology, suggesting that the proposed metaalgorithm is a direct extension of existing methods. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or comparisons to existing methods, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out the lack of novelty in the methodology, specifically noting that the proposed metaalgorithm is a direct extension of existing methods. While this feedback highlights an area for improvement, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach. The comment is 3 as it directs the authors to consider the novelty of their methodology, but it lacks actionable advice or detailed examples to guide them in addressing this issue. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. While the comment implies that the authors need to provide more context, it does not explicitly instruct them to clarify the meaning of \"wrong\" or how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions L248, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the meaning of \"wrong\" in the context of the paper. The comment provides a clear direction for the authors to improve their draft by clarifying the terminology. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" in the context of the paper, specifically at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the use of \"wrong\" is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis for this critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the use of the term \"wrong\" at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address the issue. By clarifying the meaning of \"wrong,\" the authors can enhance the clarity and precision of their paper, making it easier for readers to understand the nuances of their arguments. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive if it provided additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially concerning occupant comfort and energy efficiency. While the comment identifies a specific area that needs more attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to expand on this aspect, but the comment lacks concrete suggestions or detailed instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what the authors should cover, namely the types of activities and their importance in smart homes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. This feedback is 3 as it highlights a specific area that needs improvement, but it lacks detailed guidance on how the authors might address this gap. The comment provides a clear direction for the authors to expand their discussion, but it does not offer specific suggestions or examples of how to incorporate this information into the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue in Section 5.3, noting that a generator with a standard RGCN discriminator tends to collapse, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paper. The action is implicit, as the authors need to infer that they should provide a detailed explanation of the mechanism behind the proposed module\"s stability. The lack of concrete instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue in that section, noting the difference in stability between a generator with a standard RGCN discriminator and the proposed module. The comment requests a detailed explanation of the mechanism behind the proposed module\"s stability, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN discriminator tends to collapse after several iterations, while the proposed module does not. It suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for the claim but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue in Section 5.3, noting that a generator with a standard RGCN discriminator tends to collapse after several iterations, while the proposed module does not. It highlights that the reason behind this difference is crucial for demonstrating how the proposed method differs from previous ones. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific improvements could be made to the paper. While it points out a potential area for further exploration, it lacks actionable advice, making it 3. The authors would need to infer that they should provide a detailed explanation of the mechanism behind the proposed module\"s stability to address the feedback effectively."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting specific areas for improvement or providing guidance on how to address the originality concern. Without actionable feedback, the authors are left without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact areas that need attention. The comment is specific in its critique but lacks grounding, as it does not provide clear references or sections within the paper that need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their contributions. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it highlights an important aspect of the work but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete examples of what needs to be clarified or improved. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper discusses these comparisons, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks specific details or suggestions on how the authors might address this concern. Without additional guidance or examples, the authors may find it challenging to understand the nature of the problem and how to improve the clarity of their comparisons. Therefore, the comment is 2, as it provides a vague indication of an issue but does not offer actionable feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific area where the authors should provide more detailed experiments and explanations, particularly regarding the different queries used in spatiotemporal representation. It mentions the key difference between VideoChatGPT and other works, suggesting that the authors should include experiments with only spatial, temporal, or summary queries. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific results should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of experiments and explanation regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The comment also poses a question about what would happen if only specific queries were used, which provides a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the missing components in the ablation study, specifically regarding the different queries used in spatiotemporal representation. It suggests that the authors should include experiments and explanations for spatial, temporal, and summary queries, as these are key differences from VideoChatGPT and other works. However, the comment does not provide any specific reasoning, examples, or references to support why these components are important or how they should be addressed. The lack of detailed justification makes the claim 3, as the authors may need to infer the importance of these components to address the feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments section, particularly regarding the missing components of ablation studies. It highlights the importance of including experiments and explanations for different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This feedback is clear and actionable, as it directs the authors to address a key aspect of their work that is crucial for comparison with other methods like VideoChatGPT. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific results should be included. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claim about the lack of negative social impact, suggesting that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to incorporate these points into their draft. The action is implicit, as the authors need to infer that they should add a discussion on these aspects. However, the comment is 3 as it provides a concrete idea of what to include, but it lacks specific guidance on how to integrate these points into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the societal impact of the work, specifically questioning the authors\" claim that there are no negative social impacts. It suggests that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what the authors should consider, but the lack of grounding makes it difficult for the authors to pinpoint the exact area where the comment applies. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim that their work has no negative social impact, suggesting that this claim might be inaccurate. The comment provides a rationale for this suggestion by mentioning the potential social impact of increased automation and the risks associated with the dual use of their method. However, the comment lacks specific examples or references to substantiate these claims, making it 3. The authors would need to provide more detailed reasoning or evidence to address this concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim regarding the lack of negative social impact of their work. It questions the authors\" assertion and suggests that they should consider mentioning the social impact of increased automation or the risks associated with the dual use of their method. This feedback is 3 as it provides a direction for the authors to address a potential weakness in their work. However, the comment could be more helpful if it offered specific examples or guidance on how to discuss these aspects in the paper. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it points out a missing detail, it does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify or improve the explanation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the estimation process and the model\"s reliability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing: the estimation of the function for the optimal sequence length and the reliability of the model. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide any specific reasoning, examples, or references to support why this information is important or how it impacts the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it directs the authors to provide additional details that would enhance the transparency and rigor of their methodology. By addressing this issue, the authors can improve the clarity and reliability of their results, making the paper more robust and understandable. However, the comment could be more helpful if it suggested specific ways to present or justify the estimation process and reliability, such as providing additional context or examples. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the word \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to make the change or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should add the suggested phrase to improve the accuracy of the text. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006\" in the main text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out an inaccuracy in the use of the word \"thousands\" and suggests a concrete improvement by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the use of the word \"thousands\" in the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for the suggested change, which limits the verifiability of the comment. Therefore, it is rated as 2, as it provides some basis for understanding but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a specific issue in the text, noting that the use of the word \"thousands\" is not accurate in the context of the main text. It suggests a minor improvement by adding \"on the subword level\" to enhance clarity. While the comment points out a factual error, it does not provide a detailed explanation of why the word is inaccurate or how the suggested addition would improve the text. The feedback is 3 as it directs the authors to a specific area for correction, but it lacks depth and could be more actionable with additional guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It points out that certain hyperparameters, such as regularization, are not specified, which could hinder the reproducibility of the results. It also questions the yvalue at x=0 in the latent path figures, asking if it is normalized and seeking clarification. Additionally, the reviewer suggests further analysis using interpolations. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and require the authors to infer the necessary steps, making the comment 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to hyperparameters, such as the lack of specification for certain parameters like regularization, and questions the yvalue at x=0 in latent path figures, asking if it is normalized. It also suggests further analysis using interpolations. However, the comment does not explicitly mention specific sections or figures, making it weakly grounded. The specificity of the feedback is good, as it clearly identifies areas needing clarification and suggests additional analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the lack of specification for hyperparameters, such as regularization, and the yvalue at x=0 in latent path figures. It suggests further analysis using interpolations. However, the comment does not provide any specific reasoning, examples, or references to support these claims. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important points that could help improve the paper. It highlights the lack of specification for certain hyperparameters, such as regularization, which could hinder the reproducibility of the results. The reviewer also questions the yvalue at x=0 in the latent path figures, asking if it is normalized, which requires clarification from the authors. Additionally, the comment suggests further analysis using interpolations, which could provide valuable insights. While the comment identifies areas for improvement, it lacks detailed guidance or specific suggestions on how to address these issues. The feedback is 3 as it points out areas that need clarification and further exploration, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor, specifically in terms of epsilon. It does not provide explicit instructions or suggestions on how the authors should address this issue, such as whether they should explore theoretical bounds or conduct additional experiments. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the theoretical effect and error bounds, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support the question. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It highlights a potential area for clarification or further investigation, which could be valuable for the authors to address. However, the comment lacks actionable suggestions or guidance on how the authors might explore this issue or what experiments could be conducted to provide a more comprehensive understanding. While it identifies a potential area for improvement, it does not offer detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the two test settings in visual dialog and the results presented in Table 1, which only shows the result for the discriminative setting. The reviewer questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This comment implies that the authors should provide results for the generative setting to address the gap in the evaluation. However, it does not explicitly instruct the authors to include the generative setting results or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the generative setting results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what is missing in the evaluation and what additional results are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the discriminative setting in realworld applications and asks for results on the generative setting. While it does not contain a subjective claim, it suggests that the results presented in Table 1 are incomplete, as they only cover the discriminative setting. The comment implies that the authors should provide results for the generative setting to address this gap. However, it lacks specific examples or references to support the claim that the discriminative setting is not applicable to realworld applications. Therefore, the comment is 3, as it provides a logical reasoning but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that Table 1 only presents results for the discriminative setting in visual dialog, while there are two test settings. It questions the applicability of the discriminative setting to realworld applications and asks for the results on the generative setting. This feedback is clear and actionable, as it directs the authors to include results for the generative setting to address the gap in the evaluation. However, it could be more helpful if it provided additional guidance on how to present or interpret the results for the generative setting. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what additional evidence or reasoning should be included, nor does it provide concrete guidance on how to achieve this. The comment is vague and lacks explicit instructions, making it difficult for the authors to understand what action to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is vague and lacks specificity, as it does not detail what evidence or reasoning should be included. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to address it. Without additional context or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specificity and does not offer detailed guidance or suggestions on how to achieve this. It is vague and does not provide actionable feedback, making it 2. The authors are left without a clear understanding of what additional information or reasoning is needed to strengthen their claims. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This provides a clear and explicit action for the authors to take, as they need to either explicitly state the form of p or provide a reference to where it is discussed. The comment is specific and concrete, giving the authors a clear direction on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the form of p should be described near line 135, implying that the authors should provide more context or clarification regarding this aspect of their work. However, the comment does not specify which part of the paper line 135 refers to, making it weakly grounded. It is specific in suggesting that the form of p should be described, but without a clear reference to the section or table, the authors may find it challenging to locate the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This claim is 3 as it points out a specific area where the paper could be improved by providing more context or clarification. However, it lacks detailed reasoning or examples to fully support the suggestion, making it 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the form of p should be described near line 135. It acknowledges that the authors assume p is a Gaussian distribution but do not explicitly state it, which could lead to confusion. By suggesting that the form of p should be described, the comment offers a clear and actionable direction for the authors to enhance the clarity and completeness of their paper. This feedback is 4 as it provides a specific and actionable suggestion, though it could be more comprehensive if it included additional guidance on how to describe the form of p. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the lack of detailed explanation of the forwardprediction model and the poor schematic representation in Figure 2(b). It suggests that the figure should be redrawn and that the connection between the text, figure, and equations is unclear. While the comment provides explicit actions\u2014implying that the authors should improve the explanation, redraw the figure, and clarify the connection\u2014it lacks concrete guidance on how to achieve these improvements. The authors are left with a general idea of what needs to be done but without specific steps or examples, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the forwardprediction model, the schematic representation in Figure 2(b), and the difficulty in connecting the text, figure, and equations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, and Figure 2(b) does not accurately represent the schematic. It also notes that the connection between the text, figure, and equations is unclear. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered 2, as it provides some basis for concern but lacks sufficient depth to fully substantiate the feedback.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the explanation of the forwardprediction model and the schematic representation in Figure 2(b). It highlights the lack of clarity in connecting the text, figure, and equations, which could hinder the reader\"s understanding. While the comment points out these issues, it does not provide detailed suggestions or guidance on how to improve the explanation or the figure. This feedback is 3 as it directs the authors to areas that need attention, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a weakness in the baseline methods used in the paper, stating that they are weak and not representative of stateoftheart approaches. It also notes the absence of a discussion on limitations. The comment suggests that the authors should consider discussing the similarity and difference between their work and reinforcement learning (RL) and the extent to which the results are generalizable to RL settings. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to implement the suggestions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the weakness of baseline methods being weak and not representing stateoftheart approaches, and it notes the absence of a discussion on limitations. However, it does not specify which part of the paper discusses the baseline methods or where the authors should include a discussion on limitations. The comment is fully grounded in terms of identifying the area of concern, but it is not specific in detailing what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not representative of stateoftheart approaches, and it notes the absence of a discussion on limitations. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the baseline methods are weak and not representative of stateoftheart approaches. It also notes the absence of a discussion on limitations, which is a critical aspect of any research paper. The comment suggests that the authors should consider discussing the similarity and difference between their work and reinforcement learning (RL) and the extent to which the results are generalizable to RL settings. However, the comment lacks specific guidance on how to address these issues or what actions the authors should take to improve their draft. While it provides a clear direction for improvement, the feedback could be more helpful if it included detailed suggestions or examples of how to enhance the baseline methods or discuss the limitations. Therefore, the comment is 4, as it offers valuable insights but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment does not explicitly instruct the authors to run the suggested experiment or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance but lacks detailed instructions on how to implement the suggestions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific examples or references to support the claim that this approach would be effective or how it would impact the results. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. This question provides a potential avenue for further exploration and could help the authors refine their approach. Additionally, the comment offers a minor suggestion regarding Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks depth and specificity, as it does not provide detailed guidance or examples on how to implement these suggestions. While it offers some insight, the feedback is somewhat limited in its scope and actionable, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the necessity of longrange dependencies for powerful predictors in the context of semantic segmentation. It suggests that the paper should discuss whether locality with respect to the 2D image space is encoded in the graph structure and how this might affect prediction. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper opens that learning longrange dependencies is important for powerful predictors,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies what the authors should consider, namely the necessity of longrange dependencies and the potential impact of locality with respect to the 2D image space. This provides clear guidance on what needs to be discussed or addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of longrange dependencies for powerful predictors in the context of semantic segmentation, specifically questioning whether locality with respect to the 2D image space is encoded in the graph structure. While the comment provides a logical reasoning by suggesting that the truth might lie somewhere in between, it lacks specific examples or references to support the claim. The absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of longrange dependencies for powerful predictors in the context of semantic segmentation. It points out that while the paper claims learning longrange dependencies is important, the reviewer questions whether this is fully required and suggests that the truth might lie somewhere in between. The comment also implies that the absence of locality with respect to the 2D image space in the graph structure might affect prediction, depending on the image size. This feedback is 3 as it identifies a potential area for further discussion and exploration, but it lacks specific guidance on how the authors should address this issue or what additional experiments or analyses might be needed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises several concerns about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches or theoretical results. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks concrete guidance on how to address these issues, such as clarifying the meaning of $e_l$, providing additional context for the exponential dependence, or suggesting ways to improve the theoretical results. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific issues related to the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also mentions the potential weakness of the proposed approaches or theoretical results. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches or theoretical results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also points out a potential weakness in the proposed approaches or theoretical results, suggesting that the performance may be more quickly getting worse than standard random features. However, the comment lacks actionable guidance or suggestions for the authors to address these issues. Without specific advice on how to clarify the term $e_l$, provide additional context for the exponential dependence, or improve the theoretical results, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies areas for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the model collapsing less than other methods is a common occurrence and whether the authors have observed it in their experiments. While it prompts the authors to consider this aspect, it does not provide explicit instructions on what actions to take, such as conducting additional experiments or providing more detailed analysis. The comment is somewhat vague, as it leaves the authors to infer the need for further investigation and exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the commonality of this phenomenon and whether the authors have observed it in their experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the commonality of model collapse and the authors\" observation of it in their experiments. However, it does not provide any specific evidence, reasoning, or references to support the claim that this phenomenon is commonly encountered or observed. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the commonality of model collapse and whether the authors have observed it in their experiments. It specifically references line 159, where gradients become 0 and collapse, suggesting that this phenomenon might be a common occurrence. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what additional experiments they could conduct to explore this phenomenon further. While it identifies an area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it provides a starting point for the authors to consider but lacks depth and actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the performance of learningbased and heuristicbased solvers, noting that heuristicbased solvers, specifically the SOTA heuristicsolver (e.g., Concorde), usually perform better for singleobjective TSP. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This provides a clear and explicit action for the authors to take, which is to include the results for linear scalarization + Concorde in their analysis. The action is concrete, as it specifies exactly what needs to be done to improve the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"competitive baselines\" and \"heuristicbased solvers,\" allowing the authors to identify the specific parts of the paper being addressed. It also specifies the issue with the performance of the SOTA heuristicsolver (e.g., Concorde) for singleobjective TSP and suggests including the results for linear scalarization + Concorde for a better comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are much better than the heuristicbased solvers according to the experimental results. However, it highlights that for singleobjective TSP, the SOTA heuristicsolver (e.g., Concorde) usually performs better. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This claim is 3 as it provides a logical reasoning for why the inclusion of linear scalarization + Concorde is necessary for a comprehensive comparison. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers outperform heuristicbased solvers, but it highlights a potential gap in the comparison by suggesting the inclusion of results for linear scalarization with the SOTA heuristicsolver (e.g., Concorde). This feedback is actionable and provides a clear direction for the authors to improve their analysis by including additional comparisons. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their experimental evaluation. Therefore, the comment is 4, as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide glosses in Figure 2. This is a clear and explicit action that the authors can readily understand and implement. The comment is specific in its request, indicating exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which is a specific part of the paper. However, it does not explicitly mention the section or figure number, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide glosses in Figure 2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the \"No\" category.", "helpfulness_rationale": "The review comment suggests that the authors should provide glosses in Figure 2. This is a specific and actionable suggestion that directly addresses a potential area for improvement in the paper. By providing glosses, the authors can enhance the clarity and understanding of the content presented in Figure 2. This feedback is clear and constructive, offering a concrete step for the authors to take in improving their draft. Therefore, the comment is 4, as it provides a clear and actionable suggestion that is likely to be beneficial for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific advice or suggestions, the authors are left without a clear path to respond to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is vague and does not provide specific guidance on how to address the question or what changes might be necessary. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely a question, which does not offer any guidance or insight into why the authors might have made a particular choice. Therefore, it is classified as \"No\" because it lacks a claim that needs to be supported.", "helpfulness_rationale": "The review comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of pertensor and perchannel approaches. This question highlights a potential area for improvement in the paper, as it suggests that the authors might have overlooked a more detailed approach to quantization. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve their draft. Without actionable feedback or specific suggestions, the comment is 3 as it identifies a potential area for improvement but lacks depth and direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the definition of \"active vertices\" in line 135, which is a specific part of the paper. It implies that the authors need to clarify this term to ensure the reader understands the context. However, the comment does not provide explicit guidance on how to define \"active vertices\" or suggest alternative definitions. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear: the definition of \"active vertices.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definition of \"active vertices\" in line 135, which is a factual question about the paper\"s content. It does not contain a subjective claim, suggestion, or judgment that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the definition of \"active vertices\" in line 135. This is a clear and actionable piece of feedback that helps the authors clarify their terminology, ensuring that the reader understands the context. However, the comment could be more helpful if it provided additional context or suggested alternative definitions. Despite this, the feedback is 3 as it directs the authors to a specific area that needs clarification, allowing them to improve the clarity and precision of their writing. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. It also points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The comment suggests that the authors might be underestimating the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies a gap in the paper\"s discussion and suggests an area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out areas for improvement but lacks detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the lack of mention of the theory\"s inapplicability to the used model and the vagueness of \"structural assumptions.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section, which is a valid observation. It also highlights the vagueness of \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The comment suggests that the authors might be underestimating the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to provide more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. This oversight is a critical gap that needs to be addressed. Additionally, the comment points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The reviewer also suggests that the authors might be underestimating the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. This feedback is 4 as it provides clear guidance on areas for improvement, such as explicitly mentioning the limitations and elaborating on the societal impact. However, it could be more helpful if it included specific suggestions or examples to guide the authors in addressing these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide explicit guidance on which parts are vital or how to address the issue. The comment implies that the authors should clarify the discussion, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment also suggests that the discussion is necessary but does not provide specific guidance on what needs to be discussed or how to distinguish the paper from related work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the discussion is necessary. Therefore, the claim is considered 2, as it provides some context but lacks sufficient justification or examples to fully support the argument.", "helpfulness_rationale": "The review comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific guidance or examples to help the authors address this issue. While the comment identifies a potential area for improvement, it lacks depth and actionable suggestions, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It highlights that the decomposition and integration steps in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis need to be revised. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It highlights that the decomposition and integration steps introduced in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not specify which part of the paper discusses the HOI analysis or the Fourier analysis, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique of the analogy, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It claims that the decomposition and integration steps introduced in the paper do not have a close connection with Fourier analysis as claimed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The reasoning is vague and lacks detailed evidence, which limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment critiques the analogy between HOI analysis and Harmonic analysis, pointing out that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. This feedback highlights a potential inconsistency or lack of depth in the paper\"s analysis, which could help the authors refine their arguments and ensure the accuracy of their claims. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or strengthen their analysis. As it stands, the comment is 3, as it identifies a meaningful area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalization of the model\"s performance across different focusing distances, specifically those not present in the training data. It suggests that the authors should consider including images with other focusing distances to assess the model\"s generalization ability. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific distances to include or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and generalize the findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalization of the model\"s performance across different focusing distances, particularly those not included in the training data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalization of the model\"s performance across different focusing distances, specifically those not present in the training data. It does not contain a subjective claim or opinion but rather poses a question that requires the authors to consider additional experiments or analysis. The comment is factual and does not require external references or logical reasoning to be understood. Therefore, it aligns with the \"No\" category.", "helpfulness_rationale": "The review comment raises a valid concern about the generalization of the model\"s performance across different focusing distances, particularly those not included in the training data. It questions whether the model generalizes well beyond the distances present in the training set, which is a crucial aspect for evaluating the robustness of the model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing additional experiments or analysis methods. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, particularly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic.\" However, the comment does not provide explicit guidance on how to define content and style, nor does it offer concrete suggestions on how to address the ambiguity surrounding the meaning of \"style.\" The action is implicit and vague, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic.\" However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. While the suggestion is specific about the need for broader definitions, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the definitions of content and style in the context of a specific neural application, referencing Gabbay & Hosehn (2018). It suggests that style should be considered instancespecific and that content includes information transferable among groups. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed explanation or references makes the claim 3, as it lacks sufficient evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises important questions about the definitions of content and style in the context of the authors\" specific neural application, referencing Gabbay & Hosehn (2018). It highlights the need to consider instancespecific style and the transferability of content across groups. However, the comment does not provide specific guidance or suggestions on how to address these issues or clarify the meaning of \"style\" in the context of a nonsequential model. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a relevant issue but does not offer detailed guidance for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples and comparisons to support the claim that the analysis of vit quantification could be explained in depth. It highlights discrepancies in the variance difference between the proposed approach and the baseline, and mentions that the quantization of MHSA introduces a large loss of precision, a finding already established in other contexts. However, the comment does not explicitly instruct the authors to provide a detailed explanation of the vit quantification analysis or to address the discrepancies and the loss of precision. While the authors can infer that they need to expand on the analysis, the action is somewhat vague and lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as Line 45 and Figures 1(b) and 5(b), allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, namely the depth of the analysis of vit quantification and the discrepancies in variance differences and the loss of precision in MHSA quantization. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, providing specific examples and comparisons to support this claim. It highlights discrepancies in variance differences and the loss of precision in MHSA quantization, referencing findings in other contexts. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to infer the basis for the claim, which could be improved with more explicit evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed analysis of the paper\"s claims regarding vit quantification, offering specific examples and comparisons to support the argument that the analysis could be explained in depth. It highlights discrepancies in variance differences and the loss of precision in MHSA quantization, referencing findings in other contexts. This feedback is 4 as it provides clear insights into areas where the paper could be improved, offering actionable suggestions for the authors to enhance the depth and clarity of their analysis. However, it could be more helpful if it included specific recommendations on how to address these issues or provide additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It points out that the proposed Xtransformation is similar to STN, applied locally, and notes that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions the absence of empirical or conceptual comparisons to STN, which is crucial for the work. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the paper. The feedback is somewhat vague and lacks concrete suggestions, making it 3.", "grounding_specificity_rationale": "The comment addresses a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It highlights the similarity between the proposed Xtransformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions the absence of empirical or conceptual comparisons to STN, which is important. However, the comment does not specify which part of the paper discusses the technical novelty or the comparison to STN, making it weakly grounded. The specificity of the comment is moderate as it identifies the issue but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and that there are no empirical or conceptual comparisons to STN. The comment provides examples of existing works that have applied STN in local pixel neighborhoods, such as PointNet, which supports the claim. However, the comment could be more detailed by explicitly referencing specific sections or figures in the paper where these comparisons are missing. Despite this, the claim is 4 as it is supported by logical reasoning and examples, but it lacks some depth in terms of detailed references or specific comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN). It highlights the similarity between the proposed Xtransformation and existing STN applications, noting that other works have already explored applying STN in local pixel neighborhoods. The comment also points out the absence of empirical or conceptual comparisons to STN, which is crucial for establishing the novelty and contribution of the work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or what additional comparisons could be made to strengthen the paper. While it provides a clear direction for improvement, the feedback could be more helpful if it included concrete suggestions or examples of how to enhance the technical novelty. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the paper. The action is implicit, as the authors need to infer that they should clarify the source of the reward and provide more detailed explanations of the network model. While the comment is 3, it lacks concrete details on how to implement the suggested improvements, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not specify which part of the paper the authors should focus on, making it weakly grounded. The comment is specific in its request for clarification and suggestions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely Eq. 12, where the source of the reward at each trial is unclear. It also suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment lacks detailed guidance on how to address these issues or what specific changes should be made to the paper. While it points out areas for improvement, it does not provide actionable steps or detailed suggestions, making it 3. The feedback is 3 as it highlights areas that need clarification, but it could be more comprehensive with additional guidance on how to improve the clarity of the equations and the network model explanation."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to attach proofs to theorems and corollaries in the main paper to improve readability. However, the comment does not explicitly instruct the authors to correct the figure reference or to implement the suggestion about proof links. While the actions are implied, they are vague and lack concrete details on how to execute them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure reference, suggesting that \"Fig.7\" should be \"Fig.12.\" Additionally, the comment provides a clear suggestion to attach proofs to theorems and corollaries in the main paper, enhancing the paper\"s readability. However, the comment lacks specificity in terms of what aspects of the methodology or experiments need to be improved to address the concerns about motivation, methodology soundness, and experiment persuasion. While the authors can infer that these concerns relate to the content of the paper, the comment does not provide detailed guidance on how to address them. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point contains a claim about the correctness of a figure reference (\"Fig.7\" should be \"Fig.12\") and suggests improving the paper\"s readability by attaching proofs to theorems and corollaries. However, the comment lacks specific examples or detailed reasoning to support the claim about the figure reference. While the suggestion to improve readability is logical, the overall comment is 3 due to the lack of detailed justification for the figure reference claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on a potential error in the referencing of figures in the supplementary material, noting that \"Fig.7\" should be \"Fig.12\". It also suggests improving the paper\"s readability by attaching proofs to theorems and corollaries in the main paper. However, the comment lacks depth and does not address the concerns about motivation, methodology soundness, and experiment persuasion, which are mentioned as primary concerns. While it offers some actionable feedback, the lack of detailed guidance on how to address the concerns limits its helpfulness. Therefore, the comment is 3, as it provides some suggestions but could be more comprehensive and detailed to fully assist the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "No", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about specific sections of the paper, such as the missing determiner in the definition above Section 3, the selection and tagging of action verbs, and the concept of \"action frames.\" While the comment explicitly asks for clarification on these points, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit, as the authors need to infer that they should clarify these aspects in their draft. However, the lack of concrete guidance on how to implement these clarifications makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses specific sections of the paper, such as \"Above definition\" and \"Section 3,\" which allows the authors to accurately identify the parts being discussed. It also raises questions about the selection of action verbs and the concept of \"action frames,\" providing specific areas for clarification. This feedback is 5, as it clearly identifies the sections and issues that need attention. Therefore, the comment is rated as 5.", "verifiability_rationale": "The review point raises questions about specific sections of the paper, such as the missing determiner in the definition above Section 3 and the selection of action verbs. It also asks about the concept of \"action frames\" and how they are picked. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with the \"No\" category.", "helpfulness_rationale": "The review comment raises specific questions about the content of the paper, particularly regarding the missing determiner in a definition above Section 3, the selection of action verbs, and the concept of \"action frames.\" These questions are clear and direct, prompting the authors to clarify these aspects in their draft. However, the comment lacks suggestions or guidance on how to address these issues, such as providing examples or references. While it identifies areas for improvement, the feedback is somewhat limited in its actionable value, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is an explicit action that the authors can directly apply to improve the accuracy of the paper. The comment provides clear guidance on what needs to be corrected, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly identifies a minor grammatical error that needs correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is a factual correction and does not require any additional reasoning or references to be understood. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a minor grammatical error in the text, specifically pointing out that \"Empiically\" should be corrected to \"Empirically\". This is a clear and actionable suggestion that the authors can easily implement to improve the accuracy of their paper. While the comment is brief, it provides a specific and direct feedback that can help the authors enhance the quality of their writing. Therefore, the comment is 3, as it offers a clear and actionable improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue regarding the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. It suggests that the number of entities is fixed, which is not clear. However, the comment does not provide explicit guidance on how to address this issue or what steps the authors should take to generalize the model. The action is implicit and vague, as it does not specify how the authors might approach this problem or what changes are needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue and suggests that the number of entities is fixed, which is not clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. However, it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. It highlights that the number of entities is fixed, which is not clear, and suggests that this limitation could be addressed. However, the comment does not provide detailed guidance or suggestions on how to generalize the model or what specific changes might be necessary. While it points out a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the idea is not enough and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their idea or improve the complexity of their metric and method. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the novelty or complexity are lacking. The comment is vague and does not provide any guidance on how the authors might address these issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are relatively straightforward. However, the comment lacks specific evidence or examples to support these claims. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the novelty of the idea and suggests that both the new metric and method are relatively straightforward. While it points out these issues, it does not provide specific guidance or suggestions on how the authors might enhance the novelty or complexity of their work. The feedback is 3 as it highlights areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what changes could be made to the framing or how the contribution could be clarified. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper is being referred to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the specific issue and address it effectively. Additionally, the comment does not provide specific guidance on how to revise the framing or clarify the contribution. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the framing of the paper, suggesting that it oversells the method, making the contribution less clear. While the comment highlights a concern that could impact the perceived contribution of the work, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable advice or examples of how to revise the framing, the authors may find it challenging to improve their draft. Therefore, the comment is 2, as it points out a problem but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps, which would enhance understanding. It also notes that the use of many symbols and a notation table could be better. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific steps or examples. The action is implicit and somewhat vague, as the authors need to infer how to improve the presentation of the generative process and the use of symbols. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the use of many symbols and a notation table. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine where the comment applies. The comment is specific in its suggestions for improvement, but the lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with label 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and by using a notation table. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand the reasoning behind the claim. Without detailed justification or examples, the claim is 3, as it provides a general direction for improvement but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies areas for improvement in the model description, specifically suggesting that presenting the generative process in separate steps could enhance understanding. It also notes that the use of many symbols and a notation table could be better. While the comment provides some guidance on how the model description could be improved, it lacks specific examples or detailed suggestions on how to implement these changes. The feedback is 3 as it directs the authors to areas that need attention, but it could be more comprehensive with additional guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with identifying rationales, particularly for complex NLP tasks like machine translation, but it does not provide explicit or implicit actions for the authors to take. While it suggests that the paper is wellorganized and easy to follow, it does not offer guidance on how to address the issue of identifying rationales or how to improve the clarity of Figure 2. The feedback lacks concrete steps or suggestions for improvement, making it difficult for the authors to know what to do next. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of identifying rationales, particularly for complex NLP tasks like machine translation, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in suggesting that the paper is wellorganized and easy to follow, but it does not provide detailed guidance on how to improve the clarity of Figure 2. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that identifying rationales is not a simple problem, especially for complex NLP tasks like machine translation. It also suggests that the paper is wellorganized and easy to follow, but it does not provide specific evidence or references to support these claims. The comment lacks detailed reasoning or examples to substantiate the assertion about the complexity of identifying rationales. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically regarding the complexity of identifying rationales in complex NLP tasks like machine translation. It suggests that the paper is wellorganized and easy to follow, which is a positive observation. However, the comment also points out that Figure 2 is cluttered and the \"bold\" text is difficult to see, suggesting that the authors could improve the clarity of the figure. While the comment provides some feedback on the clarity of the figure, it lacks detailed suggestions or guidance on how to address the issue of identifying rationales. The feedback is 3 as it offers a specific observation about the figure\"s clarity but does not provide comprehensive advice for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the FlippedQA framework, which is described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take to address it. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment does not specify which part of the paper discusses the FlippedQA framework or the models it is applied to. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its suggestion to verify the framework\"s effectiveness and universality, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to justify why the framework should be verified in these specific models. Without such evidence, the claim remains 3, as the authors may need to infer the basis for the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by suggesting that the FlippedQA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in nonLLMbased models like HiTeA and InternVideo. This feedback is 3 as it points out a specific area that could enhance the paper\"s comprehensiveness and robustness. However, the comment lacks detailed guidance or suggestions on how to verify the framework\"s effectiveness or universality, which limits its impact on the authors. To be more helpful, the comment could provide specific examples or steps for the authors to take in their verification process. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and that it lacks significant theoretical novelty. The comment also expresses a willingness to improve the score if the authors address these concerns. However, it does not provide specific guidance on how to address these issues or what aspects of the method need to be improved to enhance its theoretical novelty. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of existing methods, such as ClopperPearson intervals and Gaussian elimination, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the concern regarding the lack of significant theoretical novelty, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how the method builds upon existing methods or why it lacks theoretical novelty. Without these elements, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a key weakness in the paper, noting that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and lacks significant theoretical novelty. This feedback is clear and actionable, as it highlights a specific area where the authors could improve their work. However, the comment could be more helpful if it provided suggestions on how to address the lack of theoretical novelty or how to differentiate the proposed method from existing approaches. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, allowing them to focus on enhancing the novelty and contribution of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should investigate and clarify the concatenation process. However, the comment lacks concrete details on how to implement this investigation or what specific aspects need clarification. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on how to execute it.", "grounding_specificity_rationale": "The comment raises a question about whether the text input is concatenated by four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on how to address the question or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about whether the text input is concatenated by four text elements of an object. While this question prompts the authors to consider a specific aspect of their work, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The comment lacks depth and actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it identifies a potential area for clarification but does not offer substantial guidance or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide specific guidance on how to rephrase or simplify the sentence. The authors are left with an implicit action to make the sentence clearer, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to make the sentence in lines 1217 clearer. This feedback is actionable and provides a clear direction for improvement, making it a 5 comment.", "verifiability_rationale": "The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the sentence is cumbersome or how to make it clearer. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that the sentence describing the number of questions is cumbersome and could be clearer. This feedback is actionable as it provides a clear suggestion for improvement, guiding the authors to rephrase the sentence for better readability. However, the comment could be more helpful if it offered additional suggestions or examples of how to make the sentence clearer. Overall, the comment is 3 as it provides a specific and actionable piece of feedback, but it could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that Decouple [Kang et al.] could potentially improve tail accuracy with hyperparameter adjustments. The comment encourages the authors to continue this line of work for future submission. However, the action is implicit, as the authors are not explicitly instructed to investigate the tradeoff for baselines or to adjust hyperparameters. The comment lacks concrete guidance on how to address these issues, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, and that the tradeoff between head and tail categories has not been fully investigated for the baselines. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, based on the results shown in \"3)\" and Table 5. It also suggests that the tradeoff between head and tail categories has not been fully investigated for the baselines, implying that Decouple [Kang et al.] could potentially improve tail accuracy with hyperparameter adjustments. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims, making it 3. The authors would need to provide more evidence or justification to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights the tradeoff between head and tail categories, which has not been fully investigated for the baselines. The comment suggests that by adjusting hyperparameters in Decouple [Kang et al.], the performance could be improved, indicating that the paper is not yet ready for submission. This feedback is clear and actionable, providing the authors with specific areas to address and improve their work. However, it could be more helpful if it included suggestions on how to conduct the hyperparameter adjustments or what specific experiments to perform. Overall, the comment is 4, as it effectively guides the authors toward addressing the identified weaknesses."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is limited, primarily relying on 4 OCR QA datasets. It acknowledges that this evaluation may be unreliable, as the authors themselves admit in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. However, the comment does not provide explicit guidance on how the authors should incorporate these additional scenarios or how to conduct the ablation studies. While the action is implied, it is vague and lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation, noting that it is limited to 4 OCR QA datasets and that the authors themselves acknowledge this limitation. The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. This provides clear guidance on what additional scenarios should be included. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, primarily relying on 4 OCR QA datasets, and that this evaluation may be unreliable, as acknowledged in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. However, the comment lacks specific examples or detailed reasoning to support the claim that the evaluation is unreliable or why the LLaVA benchmark would be more appropriate. Without concrete evidence or references, the claim is 3, as it provides a basis for improvement but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the paper, noting that it primarily relies on 4 OCR QA datasets. The authors themselves acknowledge this limitation in Figure 4(5), suggesting that the evaluation may be unreliable. The comment proposes that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. This feedback is 3 as it highlights a specific area for improvement and suggests additional scenarios that could enhance the robustness of the evaluation. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these additional scenarios or how to conduct the ablation studies. Overall, the comment offers valuable insights but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the notation and assumptions in the paper. It suggests that the authors should clarify the function pi and explain why the dimensions do not match in equation (2) due to the removal of the noop action. The comment implies that the authors should address these issues to improve the clarity and consistency of their paper. However, the action is implicit, as the authors need to infer that they should clarify the notation and provide a justification for the dimensional mismatch. The comment is 3 because it provides a clear direction for improvement, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the notation and assumptions in the paper, particularly concerning the function pi and the dimensions in equation (2). It provides a clear reference to line 75, allowing the authors to accurately identify the part of the paper being discussed. The comment is fully grounded as it explicitly mentions a specific section of the paper. It is also specific because it details the issues with the notation and assumptions, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the notation and assumptions in the paper, specifically regarding the function pi and the dimensions in equation (2). It suggests that the authors should clarify the function pi and explain why the dimensions do not match due to the removal of the noop action. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, particularly concerning the notation and assumptions. It points out a potential issue with the function pi and the dimensions in equation (2), suggesting that the authors should clarify the notation and provide a justification for the dimensional mismatch. This feedback is clear and actionable, as it directs the authors to specific aspects of their work that need attention. However, the comment could be more helpful if it provided additional guidance or examples on how to address these issues. Overall, the comment is 4, as it offers valuable insights that can guide the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly instruct the authors to address these issues or provide guidance on how to improve the realism of their evaluations. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not specify which part of the paper discusses the evaluation of weak supervision or the realism of the generated tweets. This makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its suggestions, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be better evaluated by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is 3 as it provides some justification but lacks depth and specific examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic nature of the author embeddings. However, the comment lacks detailed guidance on how to address these issues or what specific improvements could be made. While it highlights areas for improvement, it does not offer actionable steps or suggestions for enhancing the realism of the evaluation, leaving the authors with a clear understanding of the problem but without a clear path forward. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient detail to guide the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the keypoint detection results should be included in the experiments section. This is a clear and explicit action that the authors can take to improve their draft. By including these results, the authors can provide a more comprehensive evaluation of their work, allowing readers to better understand the significance of their findings. The comment is specific and concrete, as it directly instructs the authors on what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the keypoint detection results should be included in the experiments section. However, it does not specify which part of the paper this section is located in, making it difficult for the authors to identify the exact section to address. While the comment is specific about the content that needs to be included, the lack of grounding makes it challenging for the authors to understand where to make the necessary changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this inclusion is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the keypoint detection results should be included in the experiments section. This is a specific and actionable piece of feedback that provides the authors with a clear direction for improving their draft. By including these results, the authors can enhance the comprehensiveness of their experiments and provide a more thorough evaluation of their findings. This feedback is clear and constructive, making it 5 for the authors to improve their work. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as the one mentioned in the paper \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16)\". However, the comment does not provide explicit instructions on how to conduct this comparison or what specific aspects of the comparison should be addressed. The action is implicit, as the authors need to infer that they should perform the comparison, but it lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, referencing a specific paper. This provides full grounding as the authors can accurately identify the section or paper being mentioned. The comment is also specific, as it clearly specifies the comparison to be made with existing models that use answers as inputs. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models that use answers as inputs, such as the one mentioned in the paper \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16)\". This claim is 3 as it provides a specific reference to a relevant paper, allowing the authors to understand the basis for the comparison. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting a comparison with existing models that use answers as inputs. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their work by comparing their proposed model with relevant baselines. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what specific aspects of the comparison should be considered. Despite this, the feedback is 4 as it directs the authors towards a meaningful improvement in their research."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment implies that the authors should investigate the nature of these relations and consider whether they align with established linguistic standards. While the action is somewhat inferred, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the presence of a large number of dobj relations and asking whether this might be an artifact of colloquial language or a specific choice in the UD dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presence of a large number of dobj relations in Table A2, questioning whether this might be an artifact of colloquial language or a specific choice in the UD dataset. While the comment raises a valid concern, it does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to the table. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of subpar hyperparameters, similar to those used in other works, and questions the clarity of the results presented in the leftmost plots. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The comment implies that the authors should consider using better hyperparameters or providing more clarity on the results, but it lacks concrete steps or detailed advice on how to implement these suggestions. As a result, the comment is 3, as it identifies an area for improvement but does not offer specific guidance on how to achieve it. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels\" and \"Cross entropy,\" which are specific technical terms related to the paper\"s content. It also refers to \"iNaturalist19\" and \"beta value,\" which are specific elements of the paper. The comment is specific because it details the concern about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with a score of 5.", "verifiability_rationale": "The review point raises concerns about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it aligns with a score of 1, as it is 1.", "helpfulness_rationale": "The review comment raises concerns about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. It suggests that the authors should consider using better hyperparameters or providing more clarity on the results. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it does not provide actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This feedback is explicit, as it directly instructs the authors to include additional evaluations and specific elements in their draft. The action is also concrete, as it provides clear guidance on how to implement the suggestion by adding translations to Figure 6. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to add translations to Figure 6, which would help clarify the evaluation process for unseen words. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This claim is 3 as it implies the need for additional evaluation, but it lacks specific examples or references to support the suggestion. The authors would need to infer the need for more detailed evaluation and the rationale behind adding translations to Figure 6. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. The authors are encouraged to include more evaluation, particularly on classifying unseen words, and to add translations to Figure 6 to aid understanding for those who do not speak Chinese. This feedback is actionable and provides clear guidance on how to enhance the evaluation and presentation of the experiment. However, the comment could be more comprehensive by suggesting additional ways to improve the evaluation or addressing other aspects of the paper. Overall, the comment is 4, as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not provide any explicit or implicit suggestions on how to address these issues. The comment lacks actionable guidance, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses issues with the readability of text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment does not provide specific guidance on how to improve the readability of the text or how to correct the missing gradient symbol. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two claims: that the text in Table 1 is too small and hard to read, and that the gradient symbol is missing in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without justification or examples, the authors may find it challenging to understand why these issues are significant or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. While it points out these weaknesses, it does not provide any suggestions or guidance on how to address them. The feedback is 3 as it highlights areas that need improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the discussion of computational aspects, noting that the authors do not provide a detailed analysis of how their proposed methods can be practically useful for highdimensional data. It also points out that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for their experiments being conducted on smallscale datasets, which does not reflect the practical applicability of the methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer how to improve the discussion and experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and highlights the challenges associated with solving linear programs (LPs) in such settings. It also points out that the experiments are performed on smallscale datasets, which does not reflect the practical applicability of the methods. However, the comment does not specify which part of the paper discusses computational aspects or where the detailed discussion is lacking. This makes it difficult for the authors to pinpoint the exact areas that need improvement. The comment is specific in its critique of the computational aspects and the scale of the experiments, but it is weakly grounded as it does not provide explicit references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail, particularly regarding highdimensional data. It highlights that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for conducting experiments on smallscale datasets, which does not reflect the practical applicability of the methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the claim is not 5 without additional evidence or context. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a gap in the discussion of computational aspects, particularly regarding the applicability of the proposed methods to highdimensional data. It points out that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable, and that the experiments are conducted on smallscale datasets, which does not reflect the practical applicability of the methods. This feedback is 3 as it highlights specific areas where the authors could improve their discussion and experiments. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of how to make the methods practically useful for high dimensions. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the equations in the paper, suggesting that the signs should be changed. It also mentions a minor comment about a specific line. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The actions are implicit and somewhat vague, as the authors need to infer that they should correct the signs in the equations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (Line 502, 503, and 504), allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear feedback on the equations, detailing the necessary corrections to the signs. This level of detail helps the authors understand exactly what needs to be changed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a claim that the authors should correct the signs in specific equations. However, it does not provide any reasoning, examples, or references to support why these corrections are necessary or beneficial. Without additional context or justification, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific errors in the equations presented in the paper, providing clear and actionable feedback. It points out the incorrect signs in the equations, which are crucial for the accuracy and correctness of the mathematical formulations. By highlighting these errors, the comment helps the authors improve the precision and reliability of their work. However, the comment could be more helpful if it included suggestions on how to correct the errors or provided additional context on why these corrections are necessary. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests that comparing the current setup to a deeper ResNet with parameter sharing could be an interesting baseline, potentially equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide explicit guidance on how the authors should address this question or incorporate the suggested comparison into their draft. The action is implicit, as the authors need to infer that they should investigate the parameter sharing aspect and consider adding a comparison to a deeper ResNet. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by questioning whether the ResNet shares parameters and proposing a comparison to a deeper ResNet with parameter sharing. This suggestion is concrete and actionable, as it provides a specific direction for the authors to explore. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks and suggests a comparison to a deeper ResNet with parameter sharing. While the comment does not provide a direct claim or assertion, it implies a suggestion for further exploration or comparison. However, it lacks specific reasoning or references to support why this comparison would be interesting or relevant. The comment is 3 as it provides a suggestion but does not fully substantiate it with evidence or logical reasoning. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests that comparing the current setup to a deeper ResNet with parameter sharing could be an interesting baseline, potentially equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it identifies a potential area for further exploration and comparison, which could enhance the depth and rigor of the experiments. However, the comment lacks specific guidance on how the authors should conduct this comparison or what results would be expected, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bagofwords question model. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the model or the question design. The comment lacks concrete guidance on how to implement or revise the approach, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10, especially considering the bagofwords nature of the question model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bagofwords question model. While the comment raises a valid concern about the efficiency of encoding longer sequences, it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some context but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific design choice in the paper, namely the decision to trim questions after the first 10, and questions its effectiveness, especially given the use of a bagofwords question model. This is a valuable point as it highlights a potential inefficiency in the approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what alternative strategies could be considered. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically regarding the presence of the NO2 group. It suggests that additional postanalysis might be needed to extract shared motifs, implying that the analysis is not as straightforward as it could be. However, the comment does not provide explicit guidance on how to address this issue or what specific steps should be taken to improve the clarity of the explanation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation in Figure 1, questioning how the proposed method produces the explanation and suggesting that additional postanalysis might be necessary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically regarding the presence of the NO2 group. It suggests that additional postanalysis might be necessary to extract shared motifs, implying that the analysis is not as straightforward as it could be. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it offers a suggestion but lacks sufficient evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is unclear how the proposed method produces the explanation, particularly regarding the presence of the NO2 group. The reviewer suggests that additional postanalysis might be necessary to extract shared motifs, implying that the analysis is not as straightforward as it could be. This feedback is 3 as it highlights a potential area for improvement in the clarity and interpretability of the figure. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested alternative approaches to enhance the explanation. Overall, the comment offers a clear direction for improvement but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any specific guidance or action for the authors to take in response to this observation. The comment lacks explicit instructions on how the authors might address this point or incorporate it into their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (ln. 182184) of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear observation about the potential issue of nonconvexity in the context of SGD convergence, suggesting that this may not be a problem if the function Z has good properties. This feedback is detailed and provides a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonconvexity may not be an issue for the SGD to converge if the function Z has some good properties. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim regarding nonconvexity and SGD convergence. It suggests that the authors should consider the properties of the function Z, which could impact the convergence of SGD. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate it into their work. While it points out a potential area for improvement, it does not provide actionable steps or detailed insights, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks for clarification on the meaning of a specific term in Equation (2). While it does not explicitly instruct the authors to provide this clarification, it implies that they should explain the term to ensure the reader understands the equation. However, the action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the term. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the authors should focus on. It raises a question about the meaning of a term in Equation (2), but without any context or reference to a specific section, the authors cannot confidently determine where this issue lies. The comment is also not specific, as it does not provide any guidance or suggestions on how to address the question. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the meaning of a specific term in Equation (2). It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it seeks clarification on a technical detail within the paper. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the meaning of a specific term in Equation (2), which could be helpful for the authors to clarify. However, it does not provide any suggestions or guidance on how to address this issue or improve the clarity of the paper. The comment is vague and lacks actionable feedback, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies specific instances where the text color should be changed from red to green in the Supplementary Material (SuppMat). It also specifies the exact lines and sections where these changes need to be made, including L502, L507, and L509. The comment provides clear and explicit instructions on how the authors should update the document, making it 5. The feedback is detailed and specific, allowing the authors to understand exactly what needs to be done to improve the presentation of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L502, L507, and L509) in the paper where the text color should be changed from red to green. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear instructions on which lines need to be changed and what the correct colors should be. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about specific line numbers in the supplementary material where the text color should be changed. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on formatting inconsistencies in the supplementary material. It explicitly points out that certain lines should be in green instead of red, and it specifies the exact line numbers and sections where these changes need to be made. This detailed guidance allows the authors to easily correct the formatting issues, improving the clarity and presentation of their work. The comment is clear, concise, and directly addresses a specific aspect of the draft, making it highly valuable for the authors to improve their submission."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. While the comment prompts the authors to address these questions, it does not provide explicit instructions on how to incorporate the suggested comparisons or clarify the reasoning behind the exclusion of online learning approaches. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other instances where the authors discuss the limitations of online learning formulations. It also specifies the need for a proper comparison against online learning approaches and RL, highlighting the importance of considering retraining costs and incremental updates. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. While the questions are logical and relevant, they do not provide specific evidence or references to support the claims made. The comment lacks detailed reasoning or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. This feedback is valuable as it prompts the authors to address the limitations of their current evaluation and consider a more comprehensive comparison. However, the comment could be more helpful if it provided specific suggestions or guidance on how to incorporate these comparisons into the paper. Overall, the comment is 3, as it identifies a significant area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. The comment provides a clear action for the authors to take, which is to add these references and conduct a comparison. However, it does not specify how to implement this action, such as which sections of the paper should be compared or what specific aspects of the comparison should be highlighted. While the action is explicit, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, GFF[1] and EfficientFCN[2], which are relevant to the paper. It also specifies what needs to be addressed by encouraging a comprehensive comparison with these works. The comment is specific in detailing the need for a comparison and mentions the societal impact, providing clear guidance on what the authors should do. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. However, the comment lacks specific examples or detailed reasoning to support the claim that these references are indeed important and missing. Without additional context or justification, the authors may find it challenging to understand why these references are crucial. Therefore, the claim is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works, which is a valuable suggestion for enhancing the paper\"s context and relevance. However, the comment could be more helpful by providing more detailed guidance on how to conduct this comparison or by suggesting specific aspects of the comparison that would be beneficial. Despite this, the feedback is 4 as it directs the authors towards a crucial improvement that could strengthen their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen their claims. The feedback is implicit and lacks concrete details, making it difficult for the authors to understand how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper this claim is made or which tables or figures are being referenced. The lack of specific references makes it difficult for the authors to pinpoint the exact issue and address it effectively. Therefore, the comment is 1, as the authors cannot confidently determine which part of the paper it addresses, and it is also not specific because it does not provide detailed guidance on what needs to be addressed. This aligns with a score of 1 and Not Specific.", "verifiability_rationale": "The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. While the comment identifies a potential issue with the claim, it does not provide specific guidance or suggestions on how the authors might address this concern or strengthen their experimental results. The feedback is 3 as it highlights a critical point that needs attention, but it lacks actionable advice, making it difficult for the authors to improve their draft effectively. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the Cycle FC method, noting that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests that there could be many different designs for this method and recommends exploring experiments or analysis with different sampling intervals and sample sizes. While the comment identifies an area for improvement and provides a direction for further exploration, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the Cycle FC method, specifically mentioning that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests exploring experiments or analysis with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC method or where the analysis is conducted. This makes it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue of insufficient analysis, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the Cycle FC method is slightly insufficient, suggesting that there could be many different designs and that exploring experiments with different sampling intervals and sample sizes could enhance the analysis. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism or how to address it. The reasoning is vague and lacks detailed evidence, which limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the Cycle FC method, specifically noting that aligning features at different spatial locations to the same channel results in slightly insufficient analysis. It suggests that exploring experiments or analysis with different sampling intervals and sample sizes could enhance the understanding of the method. While the comment points out a specific area for improvement and provides a direction for further exploration, it lacks detailed guidance on how to conduct these experiments or what specific analyses would be beneficial. The feedback is 3 as it directs the authors to consider additional experiments, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the lack of standard deviations in the results, questioning the certainty of the best method\"s superiority. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or providing additional analysis to clarify the performance of other RF configurations. The action is implicit and vague, as the authors are left to infer that they need to include standard deviations to address the concern. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of standard deviations in the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, questioning the certainty of the best method\"s superiority due to the lack of standard deviations. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the results makes it uncertain whether the best method is truly the best or if other RF configurations have performances close to it. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of standard deviations in the results, which raises concerns about the certainty of the best method\"s superiority. While the comment highlights a critical gap in the analysis, it does not provide specific guidance or suggestions on how the authors might address this issue, such as including standard deviations or conducting additional analysis. The feedback is 3 as it points out a crucial area for improvement, but it lacks depth and actionable advice, making it only partially beneficial for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the choice of p < 0.4 in Algorithm 1, but it does not provide any guidance or suggestions on how the authors might have made this choice. The comment lacks explicit instructions or concrete advice on how to address the question or improve the algorithm. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper Algorithm 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it questions the choice of p < 0.4, but without the context of where Algorithm 1 is located, the authors cannot fully understand the scope of the question. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1, but it does not provide any justification or reasoning for why this specific value was chosen. Without additional context or explanation, the authors are left without guidance on how to address this question or improve the algorithm. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of p < 0.4 in Algorithm 1, which could be a point of confusion for the authors. However, the comment does not provide any guidance or suggestions on how the authors might have made this choice or how to address it. Without additional context or explanation, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide explanations or analysis for the figures presented in Section 5, specifically mentioning the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and direct, allowing the authors to understand exactly what needs to be addressed. The action is explicit and concrete, as it specifies the exact sections and elements that require clarification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5\" and the figures \"Figure 1, Figure 2, and Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of explanations or analysis for the figures, particularly the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors fail to provide explanations or analysis for the figures presented in Section 5, specifically mentioning the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of figures in Section 5, noting that the authors fail to provide explanations or analysis for Figures 1, 2, and 3. It highlights the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, as it directs the authors to specific areas where they need to improve their draft by adding explanations and analysis. However, the comment could be more helpful if it provided examples of how to explain or analyze the figures, such as suggesting specific types of analysis or questions to include. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation about the performance of RLCD and RLAIF as the model size increases, noting that the advantage of RLCD diminishes from 7B to 30B. It raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. While the comment identifies an area for further exploration and questions the scalability of RLCD, it does not provide explicit or implicit actions for the authors to take. The authors are left to infer that they should investigate the scaling behavior of RLCD and RLCDRescore with larger models. This lack of direct guidance makes the comment 3, as it provides a direction for further research but does not offer concrete steps on how to implement it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the performance of RLCD and RLAIF as the model size increases, specifically noting the shrinking advantage of RLCD from 7B to 30B. It raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. However, the comment does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section or table where this data is presented. While the authors can infer that it relates to the experimental results, the lack of explicit grounding makes the comment weakly grounded. The specificity of the comment is also limited as it does not provide detailed guidance on how to address the scalability issue or what experiments might be needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, based on the data presented in Table 2. The comment raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. However, the comment lacks specific examples or detailed reasoning to support the claim about the diminishing advantage. It does not provide references or logical arguments to substantiate the observation, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or detail to be 5.", "helpfulness_rationale": "The review comment highlights a specific observation regarding the performance of RLCD and RLAIF as the model size increases, noting that the advantage of RLCD diminishes from 7B to 30B. It raises a question about whether RLCD or RLCDRescore can scale to larger models that are better at differentiating responses near the decision boundary. This feedback is 3 as it identifies a potential area for further exploration and questions the scalability of RLCD. However, it lacks detailed guidance or suggestions on how the authors might investigate this issue or what experiments could be conducted to address it. The comment provides a direction for further research but does not offer concrete steps or insights that would significantly enhance the authors\" understanding or the quality of their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. While the comment highlights a potential limitation, it does not provide explicit guidance on how to address the scalability issue or suggest specific solutions. The action is implicit, as the authors need to infer that they should consider the scalability of their method and explore potential solutions. However, the lack of concrete details makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not specify which part of the paper discusses the proposed NC measure or the scalability issue, making it difficult for the authors to identify the exact section to address. While the comment is specific about the issue of scalability, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim about the scalability issue. The lack of evidence makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be significantly reduced without addressing this issue. While the comment highlights a potential limitation, it does not provide specific suggestions or guidance on how to address the scalability issue or improve the method\"s applicability to large datasets. The feedback is 3 as it identifies a significant area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the contribution of the CoNO model, specifically whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable and provides references to support the claim. While the comment implies that the authors should compare their model to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to UNets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed CoNO model and questions the source of its performance boost, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This comment is fully grounded as it explicitly mentions the CoNO model and the specific aspect of its performance that is being questioned. It is also specific because it provides clear guidance on what comparisons should be made, namely comparisons to UNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the source of the performance boost in the proposed CoNO model, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This provides a logical reasoning and specific examples to support the claim, making it 4. However, the comment could be more robust if it included a detailed explanation of why these comparisons are necessary or how they would be conducted. Overall, the claim is 4.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost in the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This feedback is 4 as it provides a clear direction for the authors to improve their draft by including comparisons to UNets. However, it could be more comprehensive if it offered additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4, as it identifies a significant area for improvement and provides a basis for further discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It points out that the comparison of computational complexity is expected in the experiment part. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the method. The action is implicit, as the authors are expected to infer that they need to compare the computational complexity of their method with the baselines. While the action is clear, the lack of explicit instructions makes it 3.", "grounding_specificity_rationale": "The comment addresses the computational complexity of the proposed PSA method, specifically mentioning that it requires more computation than baselines. It also notes that the comparison of computational complexity is expected in the experiment part. However, the comment does not specify which part of the paper discusses the algorithm or the experimental setup, making it weakly grounded. The comment is specific in identifying the issue with the computational complexity of the PSA method, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically noting that it involves calculating all previous layer outputs in the current layer. The comment suggests that a comparison of computational complexity is expected in the experiment part. However, the comment lacks specific details or references to support this claim, such as examples of how the computation is performed or comparisons with other methods. Without these details, the claim is 3, as it provides a general observation but lacks sufficient evidence to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It highlights that the comparison of computational complexity is expected in the experiment part, which is a relevant point for the authors to consider. However, the comment does not provide detailed guidance on how the authors might address this issue or what specific steps they could take to improve the method. While it points out a potential area for improvement, it lacks depth and actionable suggestions, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment provides several specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggesting that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment 5.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are clear and actionable, providing the authors with concrete steps to enhance their draft. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to rewrite a specific sentence in the paper, indicating that the original phrasing is unclear. This provides a clear and direct action for the authors to take, making the comment 5. The comment also specifies the location of the sentence, further aiding the authors in understanding where to make the change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the location of the sentence in the paper (P. 5, p. 3, l.), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a rewrite of a particular sentence to clarify its meaning, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests a rewrite of a specific sentence in the paper, which is a factual statement. There is X, suggestion, or judgment expressed in the comment. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The comment is 5 as it directly identifies a specific issue with the clarity of a sentence in the paper. By requesting a rewrite, it provides a clear and actionable suggestion for improvement, allowing the authors to enhance the readability and understanding of their work. The comment is specific and actionable, offering a clear path for the authors to address the identified weakness. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of the main contribution, suggesting that the performance gain is primarily due to PBSD. It also asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment implies that the authors should clarify the main contribution and provide additional motivations for PBSD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer what needs to be addressed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the clarity of the main contribution and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the content being questioned, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the main contribution and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, specifically questioning whether the performance gain is primarily due to PBSD. It also prompts the authors to clarify the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how to address the issue or enhance the motivation for PBSD. The feedback is 3 as it points out a potential area for clarification, but it does not provide actionable steps or specific advice to improve the paper. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it can be used to yield an (\u03f5, \u03b4)identity tester. It also asks for clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions or concrete guidance on how to address these questions or improve the draft. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to \"2 gives a tester for the spread parameter,\" which implies a specific part of the paper is being addressed. However, it does not explicitly mention which section or figure this refers to, making it weakly grounded. The comment is specific in questioning the implications of this tester and asking for clarification on how it handles certain pairs, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the implications of providing a tester for the spread parameter and whether it can yield an (\u03f5, \u03b4)identity tester. It also asks for clarification on how the tester handles specific pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential area for clarification, it does not provide any evidence or reasoning to support the claim that the reviewer has identified a significant issue or suggests a specific improvement. The lack of detailed explanation or justification makes the claim 3, as the authors would need to infer the basis for the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of providing a tester for the spread parameter and whether it can yield an (\u03f5, \u03b4)identity tester. It also asks for clarification on how the tester handles specific pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment identifies a potential area for clarification and questions the implications of the provided information, it lacks depth and does not offer specific guidance or suggestions for improvement. The feedback is 3 as it points out a need for further explanation, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This question implies that the authors should clarify the distinction between the two methods to avoid misleading readers. While the comment is explicit in its request for clarification, it lacks concrete guidance on how to address the issue or what specific aspects of the method need to be clarified. The authors are aware of the need to provide more detail but are not given explicit steps on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment questions the authors\" claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This question is clear and specific, as it directly addresses the method used in the paper. However, it does not provide explicit references to specific sections or parts of the paper, making it weakly grounded. The comment is specific in its request for clarification, as it asks for a comparison between the \"active learning pipeline\" and traditional active learning. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This is a subjective claim that requires clarification and justification. The comment does not provide any evidence or reasoning to support the claim, making it difficult for the authors to understand the basis of the question. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" is the same as traditional active learning, which could potentially mislead readers. This feedback is clear and identifies a specific area that needs clarification. However, it does not provide detailed guidance on how the authors should address this issue or what specific aspects of the method need to be clarified. While the comment is 3 as it highlights a potential issue, it lacks depth and actionable suggestions, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a selfsupervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how the authors should address this issue or incorporate a selfsupervised pretraining method. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s reliance on annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of supervised training. The authors may need to infer the relevant sections, making the comment weakly grounded. The comment is specific in detailing the issue with annotated labels and suggesting an alternative approach, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method necessitates annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it is based on a logical deduction but lacks sufficient substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, specifically that it requires annotated labels for learning semantic tokens, which restricts its applicability to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it highlights a potential area for improvement and offers an alternative approach. However, the comment could be more helpful if it provided specific guidance on how to implement or adapt the method for selfsupervised learning or suggested additional experiments to validate the proposed approach. Overall, the comment offers valuable insights but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the abstract and the inclusion of learning curves in the appendix. It explicitly states that the abstract should mention the expressivity of the model in terms of the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments, at least in an appendix. These suggestions are clear and concrete, providing the authors with specific actions to take. The comment is fully actionable as it directly instructs the authors on how to enhance the abstract and improve the presentation of experimental results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, providing a clear reference point for the authors to understand where the suggestion is being made. It also specifies the suggestion to include learning curves for all experiments, at least in an appendix, which is a concrete and actionable recommendation. The comment is specific in its suggestion, detailing what needs to be added to the abstract to enhance its clarity and comprehensiveness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract should include a more specific description of the model\"s expressivity, mentioning the change in linear regions in output space after a citation. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include learning curves for all experiments is also 3, as it points out a potential addition that could enhance the paper\"s comprehensiveness. However, the comment could be more robust if it provided more context or examples to support the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the abstract by adding more detail about the model\"s expressivity, referencing a change in linear regions in output space after a citation. It also suggests including learning curves for all experiments, at least in an appendix, which would enhance the comprehensiveness of the paper. These suggestions are clear and actionable, offering the authors concrete guidance on how to improve their draft. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the feedback is 4, as it directs the authors towards specific areas for improvement that could significantly enhance the quality of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the clarity of the paper\"s motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. While the comment implies that the authors should provide more context and examples to clarify the motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the motivation and provide examples of domain adaptation tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the paper\"s motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not specify which part of the paper discusses the motivation or the application of the proposed method, making it weakly grounded. It is specific in detailing what needs to be addressed, such as clarifying the motivation and providing examples of domain adaptation tasks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the paper\"s motivation and the absence of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it highlights a potential area for improvement but does not fully substantiate the concern.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by questioning the clarity of the motivation and the lack of a clear application for the proposed method. It highlights the absence of a clear demonstration of how the domain adaptation technique would be useful in practical scenarios, such as adapting a model trained on a synthetic dataset to a real dataset. The comment suggests that including examples of such applications would significantly enhance the paper\"s impact and relevance. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or tasks that could be used to demonstrate the method\"s utility. Overall, the comment is 4 as it directs the authors to address a critical aspect of their work, but it could be further improved with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare the tensor completion results for all models, including TW, TT, and TR, while ensuring that they have the same number of model parameters. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue of unclear comparisons. The comment is fully actionable because it specifies the exact steps required to improve the fairness of the comparison. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a comparison against other models in the experiments, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on how to address the issue, including the omission of model ranks and the requirement for a fair comparison with the same number of model parameters. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, this comment is rated as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the omission of model ranks makes it difficult to ensure a fair comparison. The comment suggests that the authors should compare tensor completion results for all models, including TW, TT, and TR, while having the same number of model parameters. This claim is 3 as it provides a logical reasoning for why the comparison is unclear and suggests a specific way to address the issue. However, it lacks detailed examples or references to support the claim fully, which could make it partially verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it identifies a significant issue with the experimental comparison, specifically the lack of clarity and the omission of model ranks. It provides clear guidance on how to address this issue by suggesting that the authors should compare tensor completion results for all models, including TW, TT, and TR, while ensuring that they have the same number of model parameters. This detailed feedback is actionable and constructive, as it helps the authors improve the fairness and comprehensiveness of their experiments. The comment is comprehensive and provides a clear path for the authors to enhance their draft, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it is shown to be better than \"FP\" in Table 1. This provides a clear and explicit action for the authors to take, which is to include \"ATA\" in the comparison. The comment is specific and concrete, as it directly instructs the authors on what needs to be done to strengthen the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific setting \"leave one out,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of the proposed method to \"ATA\" in the context of the results in Table 1. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as \"ATA\" is shown to be better than \"FP\" in Table 1. This claim is 3 as it provides a logical reasoning based on the results in Table 1 to justify the suggestion. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the proposed method should be compared to \"ATA\" in Table 2. This is based on the observation that \"ATA\" is better than \"FP\" according to the results in Table 1. The comment provides a clear and actionable suggestion for the authors to enhance the comparison and strengthen the evaluation of their method. By including \"ATA\" in the comparison, the authors can provide a more comprehensive and convincing analysis of their method\"s performance. This feedback is 4 as it offers a specific and constructive suggestion for improvement, though it could be further elaborated to provide additional context or rationale. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the normalization module between two versions of the paper, suggesting that the text might be misleading. It also points out the need for standardization in the pictograms used in the figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the reviewer notes minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the normalization module, suggesting that it appears different in two versions despite the text implying consistency. It also recommends standardizing pictograms in figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, it points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the need for standardization in the pictograms and identifies a specific issue with Figure 4. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the consistency of the normalization module between two versions of the paper, suggesting that the text might be misleading. It also recommends standardizing the pictograms used in the figures, particularly noting that Figure 4 is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. The comment provides specific examples and observations, such as the overlapping symbols, which offer some level of support. However, it lacks detailed reasoning or references to substantiate the claim fully. The feedback is 3 as it provides some evidence but could be strengthened with more detailed explanations or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the normalization module between two versions of the paper, which could lead to confusion for readers. It also suggests the need for standardization in the pictograms used in the figures, specifically pointing out that Figure 4 is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the comment notes minor issues with the text, such as a specific point on page 4 after equation 2. While the feedback highlights areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The comment is 3 as it points out areas that need attention, but it could be more comprehensive with actionable suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. The comment implies that the authors should clarify the algorithm\"s details and address the computational cost. However, it does not explicitly instruct the authors to provide these details or address the cost, making the action implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the claim, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the comment does not provide clear evidence or justification for the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the utility of subdivision splines and the computational cost of their proposed algorithm. It questions the lack of detail in the theoretical part of the paper, specifically mentioning that the authors did not provide information on how the algorithm removes subdivision splines. This feedback is 3 as it highlights a gap in the paper\"s explanation and encourages the authors to provide more detailed information. However, the comment could be more helpful if it offered suggestions on how to address this gap or clarify the computational cost. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including why the outputside layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies several areas that need clarification or improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about specific aspects of the paper, such as the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. However, it does not explicitly mention which sections or parts of the paper these issues relate to, making it difficult for the authors to pinpoint the exact areas needing attention. While the comment specifies the nature of the issues, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including why the outputside layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. Additionally, it questions the limitations and potential negative societal impact of the work. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The questions are openended and do not provide clear guidance on how the authors might address these issues. As a result, the comment is 4, as it identifies areas for improvement but lacks sufficient evidence to fully substantiate the claims. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, including the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies areas that need clarification or improvement, it lacks specific guidance on how the authors should address these issues. The feedback is 3 as it points out areas for improvement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that while the paper claims the same procedure is used as for baselines, most baselines do not use this dataset. The reviewer questions whether 300WLP is used in all experiments or just some, suggesting it could provide an unfair advantage to the proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the experimental methodology and address the concern about the dataset usage. The comment is concrete, as it specifies exactly what needs to be clarified and how it might impact the fairness of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the concern about the experimental methodology is raised, specifically mentioning the use of 300WLP in training the model. It also specifies the issue by questioning whether the same procedure is used as for baselines and whether the dataset is used in all experiments, which could provide an unfair advantage. This level of detail allows the authors to accurately identify the section of the paper being addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the experimental methodology, specifically regarding the use of the 300WLP dataset in training the model. It questions whether the same procedure is used as for baselines, noting that most baselines do not use this dataset. The reviewer suggests that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. This claim is 3 as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the clarity of the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that while the paper claims the same procedure is used as for baselines, most baselines do not use this dataset, raising concerns about potential unfair advantages for the proposed method. This feedback is clear and actionable, as it directs the authors to clarify the experimental setup and address the inconsistency in dataset usage. By highlighting this issue, the comment provides a specific and constructive suggestion for improvement, making it 5 for the authors to enhance the transparency and fairness of their experimental methodology. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. While the comment identifies a potential inconsistency in the formulation, it does not explicitly instruct the authors to revise the formulation or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider alternative aggregation methods or data types. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and refers to specific works, [Law et al., NeurIPS\"18] and [4], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support $v$, while the data might be aggregated by other procedures, such as simple summation or populationweighted average. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the formulation in Equation (1) assumes observations are obtained by averaging over the support $v$, but the data might be aggregated by other procedures, such as simple summation or populationweighted average. The reviewer provides examples of how disease incident data are often available in count or rate per the number of residents, suggesting that the current formulation might not accurately reflect the data aggregation process. This claim is 3 as it provides some reasoning and examples, but it lacks detailed references or specific guidance on how to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. This feedback highlights a potential gap in the paper\"s methodology and suggests that the authors should consider alternative aggregation methods or data types. While the comment provides a clear observation and suggests an area for improvement, it lacks specific guidance on how to address the issue or what changes might be necessary. Therefore, the comment is 3, as it offers a valuable insight but could be more comprehensive with detailed suggestions or examples. The authors would benefit from a more detailed explanation of how to revise the formulation to align with the data aggregation process described."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the lack of mathematical definition for architectural details, specifically mentioning multihead attention. It questions the clarity of the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values or if different sections are used. While the comment explicitly suggests that a formal definition would help readers understand the architecture, it does not provide specific guidance on how to implement this definition. The action is clear and explicit, but it lacks concrete details on how to define the mathematical aspects, making it 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the architectural details of the model, particularly the lack of mathematical definition for multihead attention. It also questions the clarity of a split arrow in Figure 2, asking for clarification on the use of query, key, and value vectors. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the mathematical definition of multihead attention and the clarification of the split arrow in Figure 2. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises specific questions about the architectural details of the model, particularly regarding the mathematical definition of multihead attention and the clarification of a split arrow in Figure 2. While the comment does not contain subjective opinions or claims, it provides detailed questions and suggestions for improvement, which can be considered as implicit feedback. However, the lack of explicit guidance or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is 3, as it provides some justification but lacks key elements for full understanding and action.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved, particularly in the lack of mathematical definitions for architectural details like multihead attention. It also raises questions about the clarity of a split arrow in Figure 2, specifically asking for clarification on whether the same vectors are used for keys and values or different sections of them. This feedback is actionable as it provides concrete suggestions for the authors to enhance the clarity and understanding of their model architecture. However, the comment could be more helpful if it offered additional guidance on how to provide these mathematical definitions or clarify the split arrow in the figure. Overall, the comment is 4, as it directs the authors to specific areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement this suggestion, such as which specific aspects of the policy to modify or which reinforcement learning algorithms to compare against. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in its suggestion to compare with a reinforcement learning algorithm baseline, but without grounding, the authors are left to infer which part of the paper this applies to. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without detailed reasoning or evidence, the claim is considered 2, as it provides a direction for improvement but lacks sufficient justification.", "helpfulness_rationale": "The review comment suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. This feedback provides a clear direction for improvement, indicating a potential area for enhancing the paper\"s contribution. However, the comment lacks specific details or suggestions on how to implement this change, such as which aspects of the policy to modify or which reinforcement learning algorithms to compare against. While it offers a valuable insight, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the comprehensiveness of the experiments, noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific aspects of the analysis need to be expanded. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the experiments, specifically noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issue of comprehensiveness and the question about performance improvement, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analyses of the method itself and the experimental outcomes are not comprehensive enough, and that the underperformance of the method compared to the baseline raises questions about the attribution of performance improvement. However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the comprehensiveness of the experiments, specifically noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. While the comment highlights a concern that could impact the paper\"s conclusions, it lacks specific guidance on how the authors might address these issues or what additional analyses could be conducted to strengthen the paper. The feedback is 3 as it points out an area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the literature review should include several papers that seem relevant, specifically mentioning [1] and [2]. It also notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the literature review should include several papers that seem relevant, specifically mentioning [1] and [2]. It also notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not specify which section of the paper the literature review is located, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the relevance of the mentioned papers and the comparison with QSGD. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issue. The absence of references or detailed explanations weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the literature review, noting that it may be overlooking several relevant papers. It provides specific examples, such as [1] and [2], which seem to satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks detailed guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. While it points out a potential gap in the literature review, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses difficulty in following the presentation of the paper but does not provide any specific guidance or suggestions on how the authors might improve the clarity or organization of their work. Without explicit instructions or concrete advice, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the presentation of the paper but does not specify which part of the paper is hard to follow. It lacks grounding as the authors cannot determine which section or aspect of the paper is causing the issue. Additionally, the comment does not provide specific details or suggestions for improvement, making it unspecific. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses difficulty in following the presentation of the paper, but it does not provide any specific claims, opinions, or suggestions for improvement. It lacks detailed reasoning, examples, or references to support the claim. As a result, the comment is classified as \"No\" because it does not contain a claim that requires verification.", "helpfulness_rationale": "The comment expresses difficulty in following the presentation of the paper, which is a valid concern for authors. However, it lacks specificity and actionable advice on how the authors might improve the clarity or organization of their work. Without detailed suggestions or guidance, the feedback is vague and does not provide the authors with a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the level of detail provided about the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the timedependent LGSSM parameters gamma. While the comment implies that the authors should elaborate on these aspects, it does not explicitly instruct them to add more details or clarify the computation requirements. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the computation requirements of the models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a more detailed presentation of the compared models, specifically DMM, DVBF, and KVAE. It also references Table 1, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the computation requirements of the three methods compared in Table 1. This provides the authors with a clear understanding of what additional information is needed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the level of detail provided regarding the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the timedependent LGSSM parameters gamma. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that the current presentation lacks detail. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the level of detail provided about the compared models, particularly DMM, DVBF, and KVAE. It highlights the need for more information on the computation requirements of these models, specifically mentioning the timedependent LGSSM parameters gamma. This feedback is 3 as it directs the authors to consider adding more detail to their presentation of the models and their computational aspects. However, the comment could be more helpful if it provided specific suggestions or examples of how to enhance the presentation of these models. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to perform these experiments or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct more experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments conducted on T5, PaLM, and GPT series LLMs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for more experiments on different famous LLMs like LLaMA and Falcon, providing clear guidance on what additional experiments should be conducted. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the comment implies the need for additional experiments, it does not provide specific reasoning, examples, or references to support why these additional experiments are necessary or beneficial. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their experimental setup and strengthen the validity of their results. By suggesting additional experiments, the comment offers a concrete way for the authors to address a potential gap in their current analysis. However, the comment could be more helpful if it provided more detailed guidance on how to select these LLMs or why they are important for benchmarking. Overall, the comment is 4, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This provides a clear and explicit action for the authors to take, as they know exactly what additional information to include in their table. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete improvement by comparing the real search cost in terms of GPU days, which provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This is a specific and actionable suggestion that provides a clear direction for improvement. However, the comment does not offer any reasoning or justification for why this comparison is important or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is 3, as it provides a specific action but lacks detailed reasoning or references to support its importance.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This feedback is actionable and directly addresses a potential area for enhancing the clarity and completeness of the paper. By offering a concrete suggestion, the comment empowers the authors to make a meaningful improvement to their draft, making it 4. However, it could be more helpful if it included additional context or reasoning for why this comparison is important. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct a typographical error in the phrase \"for \"inbetween\" uncertainty,\" specifically mentioning that the first quotation mark should be a forward mark rather than a backward mark. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be corrected and how to implement the suggestion. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty\" and provides a specific correction regarding the quotation mark. It clearly specifies what needs to be addressed, making it fully grounded. However, the comment does not provide any additional context or explanation about why this correction is necessary or how it impacts the overall understanding of the paper. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a factual correction regarding a typographical error in the phrase \"for \"inbetween\" uncertainty.\" It specifies that the first quotation mark should be a forward mark rather than a backward mark. While the comment is accurate, it does not provide any additional reasoning, examples, or references to support the claim. Therefore, it is considered 4, as it is wellsupported but lacks some depth in explanation or references. The comment is clear and specific, allowing the authors to understand the exact issue and how to address it.", "helpfulness_rationale": "The review comment identifies a specific typographical error in the phrase \"for \"inbetween\" uncertainty,\" noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and actionable suggestion that the authors can easily implement. By correcting this minor error, the authors can improve the clarity and readability of their paper. The comment is specific and provides a direct action for the authors to take, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the clarity and specificity of certain aspects of the paper. It asks the authors to clarify the meaning of \"Omega\" in line 178, to be more explicit about the OMD family of algorithms, and to specify the link function and theorem in reference to the regret guarantee. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how the authors should address these points. The authors are left to infer the necessary actions, which makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 178, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as clarifying the meaning of \"Omega,\" being more explicit about the OMD family of algorithms, and specifying the link function and theorem. This provides clear guidance on what aspects of the paper require attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity and specificity of certain aspects of the paper, such as the meaning of \"Omega\" in line 178, the OMD family of algorithms, the link function, and the specific theorem referenced. While the questions are logical and seek clarification, they do not provide specific examples or references to support the claims made. The comment lacks detailed reasoning or evidence to fully substantiate the concerns, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be clearer and more explicit. It questions the meaning of \"Omega\" in line 178, suggests that the paper should be more explicit about the OMD family of algorithms, and requests clarification on the link function and theorem referenced for the regret guarantee. These questions and suggestions provide actionable feedback that could help the authors improve the clarity and precision of their writing. However, the comment could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the feedback is 3, as it provides a clear direction for improvement but lacks depth in terms of specific suggestions or detailed explanations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before and are only aware of works reporting nodewise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so or provide specific guidance on how to find or include these references. The action is implicit and somewhat vague, as the authors need to infer that they should add references to support their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2\" and the context of \"CRF corresponding to using as a scoring loss the Hamming distance over entire parts of the sequence.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the use of the Hamming distance and suggests that the authors should point out some references to clarify this aspect. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before and are only aware of works reporting nodewise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect. However, the comment lacks specific references or detailed reasoning to support the claim that this approach is common or unusual. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF. It questions the novelty of this approach, noting that the authors have not encountered it before and are only aware of works reporting nodewise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect, which is a helpful suggestion for improving the paper. However, the comment could be more helpful if it provided specific references or examples of works that use this approach, or if it offered guidance on how to address the concern. Overall, the comment is 3 as it highlights an area for clarification and improvement, but it lacks depth and specificity to fully assist the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the name of the \"Evaluation\" element can be changed to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are wellknown and standard practice. This comment provides explicit guidance on how the authors should revise the paper, including specific actions such as changing the element name, removing sections, and updating captions. The actions are concrete and detailed, allowing the authors to understand exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are wellknown and standard practice. This comment is fully grounded as it explicitly mentions the \"Evaluation\" element, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it provides clear guidance on how to revise the paper, including changing the element name, removing sections, and updating captions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the name of the \"Evaluation\" element can be changed to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are wellknown and standard practice. This comment is 4 as it provides a clear rationale for the suggestion, explaining why the change would improve clarity and consistency. However, it lacks specific examples or references to support the claim that the metrics are wellknown and standard practice, which could enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the naming of the \"Evaluation\" element, suggesting that it could be changed to \"Metrics\" to avoid ambiguity. It also recommends removing corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are wellknown and standard practice. This feedback is clear and actionable, offering concrete suggestions for improving the clarity and consistency of the paper. By addressing these points, the authors can enhance the readability and understanding of their work. Therefore, the comment is 5, as it provides detailed guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement, noting that the improvement is evident but difficult to characterize as remarkable. It implies that the authors should consider using more precise language to describe the results. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specific examples of more objective terms or how to revise the text to achieve this. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, indicated by the reference to \"[218]\". This allows the authors to accurately identify the section being discussed. The comment is also specific because it provides clear guidance on how to improve the language used in the paper, suggesting the use of more objective terms instead of \"remarkable\" to describe the accuracy improvement. By pointing out the squished axes, the authors are given a specific reason for the suggestion, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement, noting that the improvement is evident but difficult to characterize as remarkable. This claim is 3 as it provides a specific suggestion for improvement but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the reasoning behind the suggestion, which could be improved with additional explanation or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the use of subjective terms in the paper, suggesting that \"remarkable\" should be replaced with more objective language to describe the accuracy improvement. It also points out that the axes in the paper are squished, making it difficult to characterize the improvement as remarkable. This feedback is actionable and provides clear guidance on how the authors can improve the clarity and objectivity of their results. By suggesting the use of more precise terms and highlighting the issue with the axes, the comment offers valuable insights that can help the authors enhance the quality and impact of their work. Therefore, the comment is 4, as it provides clear and actionable feedback that would significantly benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using longer video sequences to better capture motion, color, and object changes. It also acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the stateoftheart. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and provides examples, such as \"16 frames,\" which helps the authors identify the specific part of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of longer video sequences to capture motion, color, and object changes. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is interesting and extensive in its experiments, noting that the results are still not perfect but show improvement over the stateoftheart. However, the comment lacks specific evidence or references to support these claims. It does not provide detailed reasoning or examples to substantiate the assessment of the results being \"not perfect\" or \"improved over the stateoftheart.\" Without concrete evidence or references, the claim remains 3, as it is based on subjective interpretation and lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the use of short video sequences, suggesting that longer sequences could better capture motion, color, and object changes. It acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the stateoftheart. However, the comment lacks detailed guidance on how to implement the suggestion of using longer video sequences or what specific changes should be made to the draft. While it offers a direction for improvement, the feedback could be more helpful if it included concrete suggestions or examples of how to enhance the analysis or experiments. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the numerical evaluation: the use of synthetic data and the fairness of the comparison with [5]. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their evaluation or ensure a fair comparison. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation of the paper, specifically mentioning the use of synthetic data and the comparison with [5]. However, it does not specify which part of the paper discusses the numerical evaluation, making it weakly grounded. The comment is specific in identifying the issues with the evaluation, such as the use of synthetic data and the fairness of the comparison with [5]. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data, and the comparison with [5] is not fair due to the difference in problem complexity. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies two key issues with the numerical evaluation of the paper. First, it points out that the method is only evaluated on synthetic data, which may not accurately reflect realworld scenarios. Second, it notes that the comparison with [5] is not entirely fair because [5] is designed for a more complex problem, specifically lacking knowledge of camera pose parameters. These observations are clear and highlight potential limitations in the evaluation, but they do not provide specific guidance on how to address these issues or suggest improvements. While the feedback is 3 in identifying areas for improvement, it lacks actionable suggestions, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that the experiment might not be absolutely necessary but could strengthen the paper. While the comment implies that the authors should consider the relevance of the experiment, it does not provide explicit guidance on how to address this concern or what specific changes might be needed. The action is implicit and somewhat vague, as the authors are left to infer the need for further discussion or analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion regarding the experiment, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that the experiment might not be absolutely necessary but could strengthen the paper. However, the comment lacks specific evidence or reasoning to support the claim that the experiment is unnecessary or how it might strengthen the paper. The authors are left to infer the relevance of the experiment, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that the experiment might not be absolutely necessary but could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this concern or what changes could be made to strengthen the paper. The feedback is 3 as it points out a potential area for further exploration but does not provide detailed actionable advice. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks specific guidance on how to refine the performance or what aspects of the future work need improvement. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment is somewhat specific in that it suggests future refinement, but without detailed guidance on what aspects to focus on, it remains vague. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting room for further refinement in the future. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or detailed reasoning to substantiate the assertion that the enhancements are modest. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work could be improved. The comment lacks actionable advice, leaving the authors without a clear path to enhance their draft. As a result, the feedback is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235. It also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. These instructions are clear and direct, allowing the authors to know exactly what needs to be addressed. The comment is fully actionable as it provides specific guidance on where to add references and clarify terminology. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3.2, lines 230234 and 234235,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to provide references for two passages related to sequencetosequence machine translation (MT) models and decoding. Additionally, it points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment is rated as 5.", "verifiability_rationale": "The review point contains claims that require verification. It suggests providing references for specific passages in Section 3.2, lines 230234 and 234235, which are related to sequencetosequence machine translation (MT) models and decoding. Additionally, it points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. However, the comment lacks specific references or detailed reasoning to support these claims, making it 3. The authors would need to infer the need for references and clarification, which could be improved with more detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback by requesting references for two passages in Section 3.2, which are crucial for understanding the sequencetosequence machine translation model. It also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2, indicating a need for clarification. This feedback is actionable and constructive, as it directs the authors to specific areas where they need to improve the clarity and completeness of their paper. By addressing these points, the authors can enhance the understanding and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading. The comment also proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not explicitly instruct the authors to address this discrepancy or provide specific guidance on how to correct it. While the action is somewhat inferred, it lacks concrete details on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not specify which part of the paper contains the equation or figure, making it weakly grounded. It is specific in detailing the issue and suggesting improvements, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment lacks specific examples or detailed reasoning to support the claim that the output patches are masked versions, making it difficult for the authors to understand and address the issue. The suggestion for improvement is vague and does not provide clear guidance on how to implement it. Therefore, the comment is considered 2, as it provides some basis for questioning the figure but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. This feedback is 3 as it highlights a potential issue with the clarity of the figure and suggests a possible improvement. However, the comment could be more helpful if it provided more detailed guidance on how to address the discrepancy or clarify the figure. Overall, the comment offers some insight but lacks depth and specificity, making it a 3 out of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue regarding the discussion of training time reduction compared to parameter reduction. It notes that the discussion section does not address this point, suggesting that the authors should either revisit the discussion or remove the comment. However, the comment does not provide explicit guidance on how to revise the discussion or what specific aspects need to be addressed. The action is implicit, as the authors can infer that they need to revisit the discussion section to include the mentioned point. The action is somewhat vague, as it lacks detailed instructions on how to incorporate the information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that the discussion section does not revisit the point about training time reduction being less drastic than parameter reduction. This provides clear guidance on what part of the paper requires attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion section does not revisit the point about training time reduction being less drastic than parameter reduction. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify or address the issue effectively. The feedback is 3 as it points out a potential oversight but does not provide detailed evidence or guidance on how to correct it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the discussion section of the paper, noting that the discussion does not address the point about training time reduction being less drastic than parameter reduction. This feedback is clear and actionable, as it provides a specific area for the authors to revisit and potentially include in their discussion. By highlighting this oversight, the comment helps the authors improve the completeness and accuracy of their discussion. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to include the discussion. Overall, the comment is 4, as it offers clear guidance on an important aspect of the paper\"s presentation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the font size in Figure 6 is small, which could be a minor issue. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the font size or what specific changes are needed. Without actionable steps, the authors are left without a clear path to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the font size in Figure 6, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the font size in Figure 6 is small. However, it does not provide any justification or reasoning for why this is a problem or how it affects the paper. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with the font size in Figure 6, which could affect the readability of the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue. The comment is vague and does not provide actionable feedback, leaving the authors with limited insight into how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the clarity of the paper\"s goal in the introduction and suggests that the examples provided do not effectively convey the need for interprocess communication. It also offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. While the comment provides a clear action\u2014improving the clarity of the introduction and suggesting specific areas for focus\u2014it does not offer detailed guidance on how to achieve this. The suggestion is concrete but lacks specific steps or examples, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the introduction by suggesting that the examples chosen do not effectively convey the need for interprocess communication. The authors are given specific advice on focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This provides clear direction for improvement, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the paper\"s goal in the introduction and suggests that the examples provided do not effectively convey the need for interprocess communication. It offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The suggestion is clear and actionable, but the lack of specific evidence or references weakens the overall verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a lack of clarity in the paper\"s goal in the introduction and suggests specific areas for improvement. It provides a clear critique of the examples used, indicating that they do not effectively convey the need for interprocess communication. The suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild, is actionable and provides a concrete direction for the authors to enhance their work. However, the comment could be more helpful if it included additional guidance on how to effectively convey the paper\"s goal or more detailed examples of the suggested problems. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that the hyperlinks for footnote 3 and 4 are not working. This is a clear and explicit action that the authors can take to address the issue. The comment provides specific information about which parts of the paper need correction, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the hyperlink functionality, providing a clear direction for improvement. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a factual observation about the hyperlink functionality in the paper. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out a specific issue with the hyperlink functionality in the paper, noting that the hyperlinks for footnote 3 and 4 do not seem to work. This is a clear and actionable feedback that the authors can easily address by ensuring the hyperlinks are functional. The comment is specific and provides a direct action for the authors to take, making it 5 in improving the draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should revise the discussion, particularly in the modeling section, as it is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is explicit in its suggestions and provides concrete details on how the authors can improve the discussion. It instructs the authors to revise the section and clarify the role of Label Embeddings, which are external parameters, as opposed to the output of the encoder. This level of detail allows the authors to understand exactly what needs to be addressed and how to implement the changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is fully grounded as it explicitly mentions the modeling section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, such as the formalization of the architecture and the clarification of the Label Embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the discussion, especially in the modeling section, is not clear enough and needs revision. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is 4 as it offers clear reasoning and examples to support the claim that the discussion needs improvement. However, it could be more robust with additional references or detailed explanations to fully substantiate the feedback. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and completeness of the discussion, particularly in the modeling section. It suggests that the discussion is not clear enough and offers concrete examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is 4 as it identifies areas for improvement and provides actionable suggestions, but it could be more comprehensive if it included additional guidance on how to address these issues. Overall, the feedback is valuable and constructive, making it a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific questions (2.a and 2.b) that the authors need to address. Question 2.a asks for clarification on the relationship between temperature calibration and uncertainty calibration, particularly regarding the training regularization term H. Question 2.b critiques the motivation for calibrating networks given that they are already overconfident. These questions provide clear and explicit actions for the authors to take, making the comment 5. The feedback is detailed and specific, guiding the authors to clarify and address the confusion and critique. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 155160\" and \"lines 133136,\" allowing the authors to accurately identify the sections of the paper being addressed. It is also specific because it details the confusion regarding the relationship between temperature calibration and uncertainty calibration, and critiques the motivation for calibrating networks given their overconfidence. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific questions about the relationship between temperature calibration and uncertainty calibration, particularly concerning the training regularization term H. It also critiques the motivation for calibrating networks given their overconfidence. While the questions are clear and logical, the comment lacks detailed reasoning or references to support the claims made, such as the specific lines mentioned. The feedback is 3 as it provides a basis for the authors to address the confusion and critique, but it could be more robust with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it identifies specific areas of confusion and critique within the paper. It raises two key questions (2.a and 2.b) that the authors need to address. Question 2.a seeks clarification on the relationship between temperature calibration and uncertainty calibration, particularly regarding the training regularization term H. Question 2.b critiques the motivation for calibrating networks given that they are already overconfident. By addressing these points, the authors can gain a deeper understanding of the paper\"s claims and improve the clarity and coherence of their work. The feedback is detailed and actionable, providing clear guidance for the authors to enhance their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the linear program in Theorem 3 should be explained intuitively to help readers understand it better. It implies that the authors should provide an explanation of the objective and constraints in the linear program. However, the comment does not specify how to explain the objective and constraints or what kind of explanation would be most helpful. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the explanation of the objective and constraints in the linear program. This provides the authors with a clear understanding of the issue and how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 should be explained intuitively to aid reader understanding. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to improve the explanation. Without additional context or guidance, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the explanation of the linear program in Theorem 3. It suggests that the authors should provide an intuitive explanation of the objective and constraints in the linear program, which would significantly enhance the reader\"s understanding. However, the comment lacks specific guidance on how to explain the objective and constraints or what kind of explanation would be most effective. While it provides a clear direction for improvement, the feedback could be more helpful if it included examples or suggestions for enhancing the explanation. Therefore, the comment is 4, as it offers a clear and actionable suggestion but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is explicit and provides a clear action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is concrete as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of definition for the FLOT cost matrix in Algorithm 1. This provides the authors with a clear understanding of what needs to be addressed to improve the paper.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is clear and actionable, as it directly points out a missing element that needs to be addressed. By defining the FLOT cost matrix, the authors can improve the clarity and completeness of their algorithm description. However, the comment could be more helpful if it provided additional context or suggestions on how to define the cost matrix effectively. Overall, the comment is 3 as it highlights a crucial aspect that needs attention, but it lacks depth in terms of guidance or suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the convergence of a bound in Theorem 2, Eq. (30), as T approaches infinity. It notes that a similar bound in [Grunewalder et al, 2010], Eq. (27), does converge to 0. The reviewer explicitly asks the authors to prove that the second term in Eq. (30) also converges to 0. This is a clear and explicit action that the authors can readily follow, as it provides a specific task to address. The comment is detailed and concrete, guiding the authors on what needs to be proven. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27)\" from [Grunewalder et al, 2010], allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the bound in Theorem 2, Eq. (30), particularly regarding the convergence of the second term as T approaches infinity. The reviewer provides a detailed question and suggests that the authors prove this convergence, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of a bound in Theorem 2, Eq. (30), as T approaches infinity. It compares this to a similar bound in [Grunewalder et al, 2010], Eq. (27), which is known to converge to 0. The reviewer explicitly asks the authors to prove that the second term in Eq. (30) also converges to 0. This claim is 3 as it provides a logical reasoning based on the comparison with a known result, but it lacks specific examples or detailed references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the convergence of a bound in Theorem 2, Eq. (30), as T approaches infinity. It compares this to a similar bound in [Grunewalder et al, 2010], Eq. (27), which is known to converge to 0. The reviewer notes that while the first term in Eq. (30) converges to 0, it is not trivial to prove that the second term also converges to 0. This feedback is clear and actionable, as it provides a specific task for the authors to address, namely proving the convergence of the second term. The comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it suggested alternative approaches or provided more detailed guidance. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\" and i\"\". It suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment explicitly asks for clarification, it does not provide concrete guidance on how to address these issues or what specific changes should be made to the algorithm. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\" and i\". However, it does not specify which part of the paper Algorithm 2 is located in, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\" and i\". However, it does not provide any evidence or reasoning to support why these aspects are unclear or problematic. The comment lacks specific examples or references to clarify the issues, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\" and i\". It also suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment identifies a potential area for improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is 3 as it points out areas that need clarification, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically around 45. It suggests that the authors might be experiencing overfitting. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to investigate the cause of the accuracy drop and consider whether overfitting is a potential factor. While the action is implicit, it is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why accuracy starts to drop after a certain order and suggests that it might be due to overfitting. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically around 45, and suggests that it might be due to overfitting. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation and the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically around 45, and suggests that it might be due to overfitting. While the comment identifies a potential issue with the results presented in the figure, it does not provide any specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for further investigation, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to state how they handle comparisons between episodes with different lengths, providing a clear and concrete action to take. It also highlights a specific issue with the lack of a normalization factor in the distance calculation, which could bias the results towards longer trajectories. The comment is fully grounded as it directly references the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. The action is explicit and concrete, providing detailed guidance on how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with how comparisons between episodes with different lengths are handled, including the method used (padding) and the potential bias introduced by the lack of a normalization factor. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths, specifically mentioning that the authors pad shorter sequences by replicating their last state. It also highlights a potential issue with the lack of a normalization factor of 1/T, which could bias the results towards longer trajectories. The comment provides specific details about the method used and the potential bias, making it 4. However, it could be strengthened by including examples or references to support the claim about the bias. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on a critical aspect of the paper. It identifies a potential issue with how comparisons between episodes with different lengths are handled, noting that the authors pad shorter sequences by replicating their last state. The comment also points out a potential bias introduced by the lack of a normalization factor of 1/T, which could favor longer trajectories. This feedback is valuable as it directs the authors to clarify their methodology and address a potential weakness in their approach. The detailed suggestions and specific examples make the comment 5 and informative, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the absence of consideration for Vision Transformer in the experiment and the uncertainty of its effectiveness on larger datasets like ImageNet. It also questions whether the pruning strategy might differ in selfattention layers. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take. The suggestions are implicit and lack concrete details, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also inquires about the potential differences in pruning strategies in selfattention layers. However, the comment does not specify which part of the paper discusses the experimental setup or the results related to image classification, making it difficult for the authors to pinpoint the exact areas that need attention. The lack of specific guidance on what aspects of the paper should be revised or expanded limits the comment\"s effectiveness. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also asks about the potential differences in pruning strategies in selfattention layers. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the authors may find it challenging to address these concerns effectively. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental evaluation by pointing out the absence of consideration for Vision Transformer, a stateoftheart model in image classification. It also raises questions about the effectiveness of the proposed technique on larger datasets like ImageNet and the potential differences in pruning strategies in selfattention layers. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or what experiments could be conducted to provide a more comprehensive evaluation. The feedback is 3 as it points out critical areas for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the figures, including their readability, the clarity of the text, the explanation of inputs and outputs, and the selfcontained nature of the captions. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the figures, such as suggesting specific changes or providing examples of how to enhance readability. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the difficulty in parsing them, the small text size, the lack of clear explanation of inputs and outputs, and the unselfcontained nature of the captions. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Fig.1 to Fig.3 are very difficult to parse,\" \"The texts in the figures are too small,\" \"The inputs and outputs for each task are not clearly explained,\" and \"The captions are not selfcontained, and it is also very hard to link them to certain parts of the main text.\" These claims are supported by specific observations about the figures, such as the difficulty in parsing, the small text size, and the lack of clear explanations. However, the comment does not provide detailed reasoning or examples to substantiate these claims, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the figures, including their readability, the clarity of the text, the explanation of inputs and outputs, and the selfcontained nature of the captions. It points out that the figures are difficult to parse, the text is too small, and the captions are not selfcontained, making it hard to link them to certain parts of the main text. While the comment highlights these areas for improvement, it does not provide specific suggestions or actionable steps for the authors to take to address these issues. The feedback is 3 as it directs the authors to areas that need attention, but it lacks depth and guidance on how to improve the figures. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that the continuous diffusion model does not explicitly present a conditional framework but proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the conditional generation task should be addressed. The action is implicit and somewhat vague, as the authors need to infer how to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model, as evidenced by its performance in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that while the continuous diffusion model does not explicitly present a conditional framework, recent work [2] proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. The claim is supported by the performance data in Table 2 and the reference to recent work, providing a logical and verifiable basis for the suggestion. However, the comment could be more robust if it included specific examples or detailed reasoning about why this comparison is necessary. Overall, the claim is 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also provides context by mentioning that while the continuous diffusion model does not explicitly present a conditional framework, recent work proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. This feedback is clear and actionable, as it provides a specific suggestion for improvement and references relevant work. However, it could be more helpful if it included more detailed reasoning or examples of how this comparison would enhance the paper. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater depth and impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also expresses a concern that allowing \"t\" to be arbitrary does not add value. While the comment provides a specific suggestion for improvement, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity, indicating a specific part of the paper that needs attention. However, it does not explicitly mention which section or part of the paper this refers to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this change would improve clarity. The authors are left to infer the benefit of the suggestion, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. This feedback is actionable and directly addresses a potential area of confusion for the authors. However, the comment could be more helpful if it provided additional context or examples of how this change would enhance clarity. Overall, the feedback is 4 as it offers a clear and actionable suggestion, but it could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific suggestions for improvements, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific feedback on the values in Table 3, row 2, column 3, and the values in lines 995996. Each suggestion is explicit and concrete, allowing the authors to directly apply the feedback to improve their draft. The comment is fully actionable, as it provides clear guidance on what needs to be addressed and how to do so. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improvements, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific feedback on the values in Table 3, row 2, column 3, and the values in lines 995996. However, the comment does not explicitly mention which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the feedback is high as it provides detailed and actionable suggestions for each issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point provides specific suggestions for improving the draft, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific feedback on the values in Table 3, row 2, column 3, and the values in lines 995996. However, the comment lacks detailed reasoning or references to support these suggestions, making it 3. The authors can infer the need for these corrections but may require additional justification to fully understand the rationale behind each change. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the draft, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific feedback on the values in Table 3, row 2, column 3, and the values in lines 995996. These suggestions are detailed and actionable, allowing the authors to directly address the issues and improve the quality of their work. The comment is 4 as it offers clear guidance on specific areas for improvement, though it could be expanded to cover additional aspects of the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including confusion due to the use of undefined notation (M and N), suggesting that the acronym F.L.T.R be spelled out in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. The actions are explicit and concrete, as the authors are directed to spell out the acronym, address the readability issue in Figure 1, and crossreference notation with figures. This provides clear guidance on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment addresses issues with notation in the paper, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending crossreferencing notation with figures. However, the comment does not specify which part of the paper these issues are present, making it weakly grounded. The suggestions are specific and provide clear guidance on how to improve the clarity and readability of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation is confusing, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending crossreferencing notation with figures. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The suggestions are 3 as they provide a general direction for improvement, but without detailed reasoning or evidence, the claim is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the confusing notation used for variables M and N, which are not defined. It also suggests specific actions to enhance the clarity of the paper, such as spelling out the acronym F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. These suggestions are clear and actionable, providing the authors with concrete guidance on how to improve the presentation and readability of their work. However, the comment could be more helpful if it included additional details or examples to further clarify the issues. Overall, the feedback is 4, as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue, such as suggesting alternative notations or clarifying the usage of $p$. The action is implicit and vague, as the authors are left to infer that they need to make the notation clearer. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using $p$ to denote both the phase mixing probability and a dummy variable in Algorithm 1 could be confusing. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion might arise or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as proposing alternative notations or clarifying the usage of $p$. While the feedback highlights a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding of the approach. It also points out that the figure is too abstract and confusing, and that it does not align with the paper\"s main contribution, which is improvements on the WiC task. The comment implies that the authors should consider adding more text labels to the figure and potentially reworking it to depict the WiC task. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the highlevel description and the figure, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in these parts, such as adding a more detailed mathematical formulation and improving the clarity of the figure. The comment provides clear guidance on how to enhance the understanding of the approach and the figure, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the highlevel description helps understand the approach intuitively but suggests a more detailed mathematical formulation, potentially in the appendix, would be beneficial. It also criticizes the figure for being too abstract and confusing, noting that it does not align with the paper\"s main contribution, which is improvements on the WiC task. The comment provides specific suggestions for improvement, such as adding more text labels to the figure and potentially reworking it to depict the WiC task. However, it lacks detailed reasoning or references to support these claims, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on areas where the paper could be improved. It suggests that while the highlevel description helps in understanding the approach intuitively, a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding. Additionally, the comment points out that the figure is too abstract and confusing, and that it does not align with the paper\"s main contribution, which is improvements on the WiC task. The reviewer offers suggestions for improvement, such as adding more text labels to the figure and potentially reworking it to depict the WiC task. This feedback is clear and actionable, providing the authors with specific directions for enhancing their draft. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions. Overall, the comment is 4, as it offers valuable insights and actionable feedback that would guide the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and requests for additional information regarding the experiments conducted. It asks for the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment explicitly asks for these details, it does not provide explicit guidance on how to incorporate them into the draft or suggest specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address these requests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests additional information and comparisons regarding the performance of YOSO and linformer, particularly in terms of steps vs ppl, iterationwise convergence, and accuracy in downstream tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the experimental results and comparisons, specifically asking for the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment requests additional information and comparisons, it does not provide any specific reasoning, examples, or references to support these claims. The authors would need to infer the basis for these requests, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the authors could improve their experimental results and analysis. It requests additional information, such as the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment is clear and provides specific areas for improvement, it lacks detailed guidance on how to incorporate these requests into the draft or suggestions for addressing the issues. The feedback is 3 as it directs the authors to areas that need further clarification and analysis, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. However, it does not provide any explicit or implicit actions for the authors to take. The comment points out a potential issue but does not guide the authors on how to address it or what changes to make. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a clear discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. This provides the authors with a clear understanding of what needs to be corrected or clarified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract incorrectly states that the proposal distribution must upper bound the target everywhere, which is not true as the authors clarify in the text. This claim is supported by the fact that the authors themselves acknowledge this discrepancy in the text, providing a clear basis for the reviewer\"s observation. However, the comment could be more verifiable by explicitly referencing the specific section of the text where the clarification is provided, enhancing the clarity and support for the claim. Overall, the comment is 4, as it is supported by logical reasoning and the authors\" own clarification.", "helpfulness_rationale": "The review comment identifies a specific issue in the abstract, noting that the authors incorrectly state that the proposal distribution must upper bound the target everywhere, which is clarified in the text. This feedback is clear and actionable, as it directs the authors to correct the abstract to align with the content in the text. However, the comment could be more helpful if it provided additional guidance on how to revise the abstract or suggested specific changes to make. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. It suggests that the authors should clarify the use of the name or provide a different label. However, the comment does not specify how the authors should address this issue, such as by providing a detailed explanation of the differences or by suggesting an alternative label. The action is implicit and vague, as it does not provide concrete guidance on how to implement the suggested change. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the naming of \"PointNet\" in the context of the referenced paper, which is not present in the current paper. The comment provides a clear and detailed explanation of the confusion and suggests a specific reference for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. The comment provides a specific reference to \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi et al., which helps the authors understand the issue and potentially address it. However, the comment does not offer additional reasoning or examples to fully support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the naming of \"PointNet\" in Figure 1, noting that the name is used in another paper that is not referenced in the current work. The comment provides a clear reference to the paper with the same name, which is helpful for the authors to understand the confusion and potentially address it. However, the comment could be more helpful if it suggested specific actions the authors could take, such as clarifying the use of the name or providing an alternative label. Overall, the comment is 3 as it highlights a potential issue and provides a reference, but it lacks detailed guidance on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point. However, the comment does not provide explicit guidance on how to address this question or what specific aspects of the policy gradient need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the relationship between the policy gradient and the optimal problem. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or equation being discussed. Additionally, the comment is somewhat specific in its request for clarification but lacks detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Eq. 5. It suggests that the authors should clarify this point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the policy gradient might not solve the optimal problem. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the policy gradient in Equation 6 and whether it solves the optimal problem, specifically questioning if the converged solution aligns with Equation 5. It suggests that the authors should clarify this point, which is a valuable piece of feedback. However, the comment lacks specificity and does not provide detailed guidance on how to address the issue or what aspects of the policy gradient need clarification. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more helpful if it offered more detailed suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of the general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what changes might be necessary. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the distribution assumption, the absence of explicit grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the assumption of a general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not provide any specific reasoning, examples, or references to support this claim or question. The comment lacks depth and does not offer any guidance or justification for why this assumption might be made or what the implications could be. As a result, the claim is 1, making the comment unsuitable for providing actionable feedback to the authors.", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. This question is relevant as it challenges the authors to consider alternative assumptions that could impact the algorithm\"s performance or applicability. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what changes could be made to the algorithm. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide explicit guidance on how to implement this discussion or what specific aspects of the partitioning strategy should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors discuss the limitations of freezing the partitioning in the first iteration. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the assumption of coverage in the first iteration of partitioning. It suggests that this choice might be risky and recommends a discussion of its limitations. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. However, the comment could be more helpful if it offered additional guidance on how to discuss the limitations or what aspects of the partitioning strategy should be considered. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment implies that the authors should provide a justification for their decision, it does not explicitly instruct them to do so or offer specific guidance on how to explain the choice. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a rationale for their decision. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies the issue: the decision to use early stopping only by link prediction accuracy and questions why it was not averaged with type accuracy. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. However, the comment does not provide any specific reasoning, examples, or references to support why averaging with type accuracy would be a better approach. Without additional justification or evidence, the claim remains 3, as the authors are left to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific point of concern regarding the decision to use early stopping based solely on link prediction accuracy. It questions the rationale behind this choice, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it points out a potential weakness in the methodology, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors on how to set a reasonable classimbalanced task in the context of fewshot learning, given that the paper mentions \"sampling classimbalanced tasks.\" It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete details or examples to guide the authors. The comment implies that the authors need to clarify this aspect, but it lacks specific guidance on how to do so. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment questions the authors on how to set a reasonable classimbalanced task in the context of fewshot learning, given that the paper mentions \"sampling classimbalanced tasks.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how to set a reasonable classimbalanced task in the context of fewshot learning, given that the paper mentions \"sampling classimbalanced tasks.\" However, it does not provide any specific reasoning, examples, or references to support the claim that this is a significant issue or how it might affect the paper\"s conclusions. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" approach to setting classimbalanced tasks in the context of fewshot learning. It highlights a potential issue with the paper\"s description of \"sampling classimbalanced tasks,\" which could be misleading or unclear. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. While it identifies a potential area for improvement, it lacks actionable advice or detailed explanations, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was performed. This feedback is explicit, as it directly instructs the authors to include more information about the pruning process. However, the action is somewhat vague because it does not specify exactly what details need to be added or how the pruning process should be described. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the lack of detail in explaining how the ground truth of sensitivity is achieved, specifically mentioning the absence of information on how the pruning process was conducted. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was done. This feedback is clear and specific, as it identifies a missing element in the explanation. However, it does not provide any additional context or references to support the claim, which could make it slightly less verifiable. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area where the authors lack detail, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide sufficient information on how the actual pruning was conducted. This feedback is clear and actionable, as it directs the authors to include more details about the pruning process. However, the comment could be more helpful if it provided specific examples or guidance on how to describe the pruning process. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some parts of the text could be written more clearly, specifically mentioning the need for explicit explanations of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. While the comment provides specific examples of areas needing clarification, it does not offer explicit guidance on how to improve the writing or what specific changes should be made. The authors are left to infer the actions needed, which makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that some parts of the text could be written more clearly, specifically mentioning the need for explicit explanations of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. However, the comment does not provide specific guidance on how to improve the clarity of these sections or what specific changes should be made. The authors are left to infer the parts of the paper that need clarification, making the comment weakly grounded. Additionally, the comment is somewhat specific in identifying the areas that need clarification but lacks detailed guidance on how to achieve this clarity. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that some parts of the text could be written more clearly, specifically mentioning the need for explicit explanations of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies areas where the text could be written more clearly, specifically mentioning the need for explicit explanations of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. This feedback is 3 as it points out specific instances where clarity could be improved, providing the authors with a clear direction for enhancing the draft. However, the comment lacks depth and does not offer detailed suggestions or guidance on how to improve the clarity of these sections. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken by Cohen and Shashua, 2016. This comment provides a specific suggestion for improvement, indicating that the authors should consider a different term for the function. The action is explicit and concrete, as it clearly directs the authors to make a change to the terminology used in their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to consider renaming the function g as a binary operator, similar to the approach taken by Cohen and Shashua, 2016. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken by Cohen and Shashua, 2016. This comment provides a specific suggestion based on a reference to external work, which supports the claim. However, it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would benefit from a more comprehensive explanation of why this change would be beneficial and how it aligns with the paper\"s goals. Therefore, the comment is 4, as it provides some justification but could be more robust.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by suggesting that the authors might consider renaming the function g as a binary operator, similar to the approach taken by Cohen and Shashua, 2016. This suggestion is based on a reference to external work, which provides context and support for the idea. By offering a concrete change, the comment helps the authors enhance the clarity and consistency of their terminology. However, the comment could be more helpful if it included additional reasoning or examples to justify why this change would be beneficial. Overall, the comment is 4 as it provides actionable feedback, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors\" content and recommends shrinking the captions to provide more space for the methods or related work sections. This feedback is explicit and provides a clear action for the authors to take, which is to adjust the captions. The comment is specific in its suggestion, detailing what needs to be done to improve the layout and presentation of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, namely, to shrink the captions to leave more space for the methods or related work sections. This feedback is detailed and actionable, making the comment 5.", "verifiability_rationale": "The review point suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors\" content, recommending that the captions be shrunk to provide more space for the methods or related work sections. While the comment identifies a potential issue with the layout and presentation of the paper, it does not provide specific examples or references to support the claim that the captions overlap significantly. The suggestion is logical and actionable, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Figure 1 and Figure 2, noting that they have large overlaps with the authors\" content. It provides a clear suggestion to shrink the captions to leave more space for the methods or related work sections. This feedback is actionable and directly addresses a potential issue with the layout and presentation of the paper, offering a concrete step for the authors to take. However, the comment could be more helpful if it provided additional guidance on how to effectively shrink the captions or suggested alternative approaches to improve the layout. Despite this, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. It implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to include or exclude the dataset. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work and why it is not used as a potential benchmark for evaluation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment lacks specific examples or detailed reasoning to support the claim that Vidgen et al., 2021, is similar to the dataset or why it should be considered as a benchmark. Without these details, the claim is 3, as it provides a basis for discussion but lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate the dataset into their evaluation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3, as it offers a clear observation but requires further elaboration and guidance for the authors to fully benefit from it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. It also acknowledges the authors\" judgment regarding the lack of immediate societal impact. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative datasets or methods to address the issue. Without specific guidance on how to improve the draft, the authors are left without actionable feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is vague in terms of specificity, as it does not provide details on what needs to be addressed or how the issue can be resolved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how to address this concern or improve the draft. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insights on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment provides specific feedback on the clarity of a paragraph (L156166) and suggests that the authors should clarify the use of bandit algorithms and the explanation of the Gittins strategy. It also points out that the figure is hard to understand and that the explanation of dashed lines is vague. While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to clarify these sections or provide concrete guidance on what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper (L156166), allowing the authors to accurately identify the part being addressed. It also provides specific feedback on the clarity of the paragraph, the use of bandit algorithms, the explanation of the Gittins strategy, and the difficulty in understanding the figure. The comment is specific in detailing what needs to be clarified or improved, such as the explanation of bandit algorithms and the vagueness of the figure\"s explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph is barely understandable, despite the reviewer\"s expectation that they understand what is being said. It also critiques the use of bandit algorithms, specifically mentioning the Gittins strategy and the Markov chain nature of posterior evolution. The comment highlights the difficulty in understanding the figure, noting that the explanation of dashed lines is vague. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the basis for the critique, which limits the verifiability of the claim.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity of a paragraph (L156166), noting that it is barely understandable despite the reviewer\"s expectation of comprehension. It identifies issues with the explanation of bandit algorithms, particularly the Gittins strategy and the Markov chain nature of posterior evolution, suggesting that the authors should clarify these concepts. Additionally, the comment points out that the figure is hard to understand, specifically mentioning the vagueness of the explanation regarding dashed lines. While the comment highlights areas for improvement, it lacks detailed guidance on how to address these issues or provide concrete suggestions for clarification. The feedback is 3 as it directs the authors to specific areas that need improvement, but it could be more comprehensive with additional guidance on how to enhance the clarity of the paragraph and the figure."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the standard deviation of the noise in the simulation study is not as high as it could be, based on the observations compared to the true trajectories. It recommends studying the behavior of the model under higher noise. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specifying which aspects of the model should be studied or how to increase the noise level. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion to study the behavior of the model under higher noise, based on the observation that the current noise level is not as high as it could be. This guidance is detailed and actionable, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is not as high as it could be, based on the observations compared to the true trajectories. However, the comment lacks specific evidence or examples to support this claim. It does not provide a detailed explanation of why the current noise level is insufficient or how the model would behave under higher noise. Without this additional information, the claim remains 3, as the authors may need to infer the reasoning or seek further clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the simulation study, noting that the standard deviation of the noise is not as high as it could be based on the observations compared to the true trajectories. It suggests studying the behavior of the model under higher noise, which is a valuable and actionable piece of feedback. However, the comment could be more helpful by providing specific guidance on how to increase the noise level or what aspects of the model should be studied under higher noise. Despite this, the feedback is 4 as it directs the authors to an important area for improvement, allowing them to enhance the robustness of their simulation study. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with varying lengths. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what aspects of the paper need to be revised. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths, which could be a valuable point for discussion or further exploration. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this question or what aspects of their work could be improved. Without actionable insights or constructive feedback, the comment is 2, as it does not contribute significantly to the authors\" understanding or improvement of their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should evaluate the approximation error of the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue. The comment is fully actionable because it specifies the exact steps required to implement the suggested improvement. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3.3,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This level of detail makes the comment specific, as it clearly identifies what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a specific concern about the proposed training objective in Section 3.3, noting that it has ignored the KLdivergence term in equation (3). The comment suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in Section 3.3, where the proposed training objective has ignored the KLdivergence term in equation (3). It suggests that the authors evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the identified gap in their analysis. However, the comment could be more helpful if it included additional guidance on how to calculate the KLdivergence or suggested specific experiments to validate the approximation error. Despite this, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work [1]. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to strengthen the connection between Section 2 and the methodology section and expand the theoretical analysis to include more depth and novelty. The lack of specific actions or concrete suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2\" and \"the methodology section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the limited connection between these sections and the simplicity of the theoretical analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work [1]. While the comment provides a general assessment of the connection and the complexity of the theoretical analysis, it lacks specific examples or detailed reasoning to substantiate these claims. The absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for understanding but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the authors should strengthen this link. It also points out that the theoretical analysis is somewhat simplistic and closely related to a specific work [1], implying that the authors should expand or enhance the theoretical analysis to address this concern. While the comment provides some direction for improvement, it lacks specific guidance on how to strengthen the connection or expand the theoretical analysis. The feedback is 3 as it highlights areas for improvement but could be more detailed and actionable to fully assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. While the comment implies an action, it does not explicitly instruct the authors to provide a detailed discussion or analysis of these situations. The action is somewhat vague, as it leaves the authors to infer that they need to expand on the discussion of the losses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests further discussion or exploration of which situations the losses help, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the role of losses in particular situations, such as specular areas. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. This feedback is 3 as it points out a potential area for additional discussion that could enhance the paper\"s depth and clarity. However, the comment lacks specificity and does not provide detailed guidance on how to address this suggestion, leaving the authors with limited actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses doubt about the paper\"s strength for ICLR but does not provide any specific suggestions or actions for the authors to take to improve their draft. It lacks concrete guidance on what aspects of the paper need to be addressed or how the authors can enhance its quality. Without explicit instructions or detailed feedback, the authors are left without a clear path to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength for ICLR but does not specify which part of the paper is being questioned or what aspects need improvement. It lacks grounding as it does not point to a specific section, table, figure, or unique element of the paper. Additionally, it does not provide specific feedback or suggestions for improvement, making it not specific. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses doubt about the paper\"s strength for ICLR but does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed justification or examples to substantiate the authors\" concerns. Without such evidence, the claim remains unsubstantiated and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength for ICLR but does not provide any specific feedback or suggestions on how the authors might improve their work to meet the standards of the conference. It lacks actionable guidance, making it difficult for the authors to address the concerns effectively. Without concrete advice or suggestions, the comment is not helpful in guiding the authors to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues with the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. While the comment identifies these areas, it does not provide explicit guidance on how to address them or suggest concrete actions for the authors to take. The authors are left to infer that they need to clarify these aspects, but the lack of detailed instructions or examples makes the action vague and difficult to execute. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses issues with Algorithm 2 and line 225, providing specific examples of what needs clarification. It mentions the lack of explanation on how to determine n_t and the ambiguity of the term \"appropriate number.\" This allows the authors to accurately identify the parts of the paper being discussed, making the comment fully grounded. The specificity is also high as it clearly specifies the issues with the algorithm and the term in question, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific questions about the paper: how to determine n_t in Algorithm 2 and the meaning of \"appropriate number\" in line 225. While the questions are clear and point to specific areas needing clarification, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be clearer: the determination of n_t in Algorithm 2 and the meaning of \"appropriate number\" in line 225. By pointing out these ambiguities, the comment provides the authors with actionable feedback on areas that need clarification. However, the comment could be more helpful if it offered suggestions or examples to guide the authors in resolving these issues. Overall, the feedback is 3 as it highlights important areas for improvement, but it lacks depth and guidance, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the claim that \"in practice the mixing time is even better\" and argues that this claim is not sufficiently supported by the experiments. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or strengthen their evidence. The comment lacks explicit instructions on what actions the authors should take to improve their draft, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim \"in practice the mixing time is even better\" and questions its support by the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of sufficient support for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. Without additional evidence or context, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. This feedback is clear and actionable, as it highlights a gap in the evidence provided to practitioners. However, the comment could be more helpful if it suggested specific ways the authors could strengthen their evidence or provide additional experimental results. Despite this, the comment offers valuable guidance for improving the paper, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific suggestions for improving the clarity and detail of the paper. It suggests that the authors denote the vector representations of words in the equation, clarify whether the vectors are L2normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be done to enhance the paper. The comment is fully actionable, as it provides clear guidance on how to address the identified issues. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the clarity of the notation, the normalization of vectors, and the method used for computing nearest neighbor examples. The authors are guided on what specific aspects need attention, making the comment both 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the notation, normalization, and computation of nearest neighbor examples in the paper. It suggests that the authors denote the vector representations of words, clarify whether the vectors are L2normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). However, the comment does not provide any evidence or reasoning to support these suggestions, such as examples or references to similar practices in the field. Without additional context or justification, the claims are difficult for the authors to address effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the clarity and detail of the paper. It requests that the authors denote the vector representations of words in the equation, clarify whether the vectors are L2normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). These suggestions are actionable and detailed, offering clear guidance on how to enhance the paper. By addressing these points, the authors can improve the clarity and completeness of their work. Therefore, the comment is 5, as it provides detailed and actionable feedback that empowers the authors to make significant improvements to their draft. The comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It suggests that experiments should be run multiple times and that reporting statistics is essential. The comment provides a clear action for the authors to take: running multiple experiments and reporting statistics. This explicit instruction is concrete and detailed, allowing the authors to understand exactly what needs to be done to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It suggests that experiments should be run multiple times and that reporting statistics is essential. However, the comment does not specify which part of the paper discusses deep RL or where the issue is being addressed. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs improvement. While the comment is specific about the issue of reproducibility and the need for multiple experiments, the absence of explicit references to the paper\"s sections or content limits its effectiveness. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that experiments should be run multiple times to address the reproducibility issue with deep reinforcement learning (RL). It references a specific paper [a] that highlights the importance of reproducibility in deep RL. The comment provides a logical reasoning by linking the issue of reproducibility to the need for multiple experiments and reporting statistics. It also references a relevant external source, which supports the claim. However, the comment could be more detailed by providing specific examples or a more comprehensive explanation of why multiple runs are necessary. Overall, the claim is 4, as it is supported by logical reasoning and a reference, but it lacks some depth in explanation.", "helpfulness_rationale": "The review comment identifies a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It highlights the need for multiple experiments and reporting statistics, referencing a relevant paper [a] that emphasizes the importance of reproducibility in deep RL. This feedback is clear and actionable, providing the authors with a specific direction to improve the reproducibility of their experiments. However, the comment could be more helpful if it included suggestions on how to implement multiple runs or report statistics effectively. Despite this, the comment is 4 as it directs the authors towards a crucial aspect of their work that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the formatting of equations in the paper, noting that some end with a period while others end with a comma. It provides explicit instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. This feedback is clear and actionable, as it directly instructs the authors on what needs to be corrected. The comment is specific in its instructions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figure 2, Line 433, and Line 468, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue with the formatting of equations, noting that some end with a period while others end with a comma. This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about inconsistencies in the ending punctuation of equations in specific parts of the paper. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a minor issue with the formatting of equations in the paper, specifically noting inconsistencies in punctuation (some ending with a period, others with a comma). It provides clear instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. This feedback is actionable and specific, as it directly points out the areas that need correction and provides clear guidance on how to do so. While the comment is concise, it effectively directs the authors to make necessary revisions, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point questions whether the figures in Figure 1 are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback provides a clear and explicit action for the authors to take, namely to verify the nature of the figures and potentially conduct additional experiments. The comment is specific in its request for clarification and suggests a concrete way to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors should determine if the figures are generated by real experiments or artificially and, if artificially generated, conduct realworld experiments to support the phenomenon. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This comment is 3 as it provides a clear question and a suggestion for further investigation, but it lacks specific examples or references to support the claim. The authors would need to conduct additional research or experiments to fully address the suggestion, making the comment 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback is valuable as it prompts the authors to consider the validity and reliability of their experimental results. By addressing this question, the authors can strengthen the credibility of their findings and provide a more robust evaluation of their proposed method. The comment is clear, actionable, and constructive, making it 5 for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the authors were unclear about the number of parameters used in each approach, as mentioned in Section B.3. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what steps they should take to clarify the information. The comment lacks concrete guidance on how to improve the clarity of the section or what specific changes are needed. As a result, the authors are left without a clear understanding of what action to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of clarity regarding the number of parameters used in each approach. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the clarity of the numbers of parameters used in each approach in Section B.3. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out a specific issue in the paper, namely the lack of clarity regarding the number of parameters used in each approach discussed in Section B.3. This feedback is clear and actionable, as it directs the authors to a particular section where the information is unclear. However, the comment does not provide any suggestions or guidance on how the authors might improve the clarity of this section. While it identifies a problem, it lacks depth and does not offer constructive advice on how to address it. Therefore, the comment is 3, as it highlights an area for improvement but does not fully empower the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statistical significance of the evaluation results reported in Table 1, noting that the results are based on only three trials per case, which is not statistically significant. The comment suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the statistical significance of their results. The action is implicit and vague, as the authors are left to infer that they need to increase the number of trials or reconsider their claims. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statistical significance of the results, explaining why the reported deviations are not meaningful and why the claims made based on these results are not valid. The comment provides clear guidance on how the authors should address this issue, such as increasing the number of trials or reconsidering their claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials, which is not statistically significant. It argues that this lack of significance makes the reported deviations and claims, such as \"our performance is at least two standard deviation better than the next best baseline,\" unmeaningful. The comment provides a logical reasoning for why the results are not significant and suggests that the authors should reconsider their claims. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the statistical significance of the evaluation results reported in Table 1. It points out that the results are based on only three trials per case, which is not statistically significant, making the reported deviations and claims unmeaningful. The comment provides a clear rationale for why the results are not significant and suggests that the authors should reconsider their claims. However, it does not offer specific guidance on how the authors might address this issue or what steps they should take to improve the statistical significance of their results. While the feedback is valuable, it lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This comment provides an explicit action for the authors to take, which is to reconsider their usage of the word and ensure that it is appropriate and verifiable. The action is concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the usage of the word \"equivalent\" is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word, especially if the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This comment is 3 as it provides a suggestion for improvement but lacks specific examples or references to support the claim. While it implies that the authors should reconsider their usage, it does not provide detailed guidance or evidence to help them understand why the word might be problematic or how to verify the equivalence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their usage, especially if the equivalence is not verified. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. By recommending a more cautious approach, the comment helps the authors improve the accuracy and clarity of their writing. However, the comment could be more helpful if it provided additional guidance on how to verify the equivalence or suggested alternative terms. Overall, the comment is 4 as it highlights a specific issue and offers a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors need to provide a more detailed explanation of the architecture within the paper to make it selfcontained. However, the comment does not specify exactly what aspects of the architecture need clarification or how the authors should elaborate on it. While the action is implied, it is vague and lacks concrete guidance on what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clarity in the explanation of the architecture used for the experiments, which is a specific part of the paper. It also specifies that the authors refer to Jiang et al. (2019) for details, indicating that the paper is not selfcontained. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, as the authors refer to Jiang et al. (2019) for details. This claim is 3 because it points out a lack of clarity in the explanation, but it does not provide specific examples or references to support the claim. The authors would need to elaborate on the architecture to make the paper selfcontained. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained, and the authors rely on Jiang et al. (2019) for details. This makes the paper not selfcontained, as readers may need to refer to external sources to understand the methodology. The comment is clear and actionable, as it directs the authors to provide a more detailed explanation of the architecture within the paper. However, it could be more helpful if it suggested specific areas where the explanation could be expanded or provided with examples. Overall, the comment is 4 as it highlights a critical aspect of the paper that needs improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that maintaining consistency would be beneficial. While the comment identifies a specific issue, it does not provide explicit guidance on how to achieve consistency or what steps the authors should take to address this. The action is implicit, as the authors would need to infer that they should ensure consistent formatting of these terms. However, the lack of concrete instructions on how to implement this change makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent typesetting and suggests that maintaining consistency would be beneficial. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of BertScore and BLEURT throughout the paper, noting that they are inconsistently typeset as Bertscore or Bleurt. This observation is clear and actionable, as it points out a minor but noticeable inconsistency that could affect the readability and professionalism of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a specific style guide or providing examples of consistent formatting. While the feedback is 3, it lacks depth and could be more impactful with additional suggestions or guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to clarify the explanation or what specific aspects need to be improved. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. Additionally, the comment is vague and does not provide specific guidance on what needs to be addressed or improved. Therefore, it is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the explanation is vague or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the clarity of these explanations. Without additional details or constructive feedback, the authors are left without a clear path to address the identified issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their approach or what specific aspects need to be improved. Without actionable suggestions or concrete steps, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not specify which part of the paper this comment is addressing, making it weakly grounded. The comment is specific in identifying the issue of limited novelty and the comparison to ELECTRA, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. However, the comment lacks specific details or references to support this claim. It does not provide examples of how the proposed approach aligns with ELECTRA\"s strategies or what specific aspects of novelty are missing. Without this level of detail, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed approach to pretraining, noting that it closely resembles the strategies used in ELECTRA. While the comment highlights a specific concern, it does not provide detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the motivation for the Newton algorithm in section 4 is lacking, as it is essentially a 1dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\"s runtime and suggests that experiments could help motivate the need for the analysis/algorithm. While the comment implies that the authors should consider adding experiments to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments to demonstrate the impact of the Newton algorithm. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the Newton algorithm, suggesting that it is essentially a 1dimensional line search on a convex function and questioning the impact of this on the algorithm\"s runtime. The comment provides a clear and specific request for additional experiments to motivate the need for the analysis/algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for the Newton algorithm in section 4 is lacking, suggesting that it is essentially a 1dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\"s runtime and suggests that experiments could help motivate the need for the analysis/algorithm. However, the comment lacks specific examples or references to support the claim that the Newton algorithm is merely a linearly convergent 1dimensional line search. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation for the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\"s runtime and recommends that experiments be conducted to demonstrate the need for the analysis/algorithm. This feedback is 3 as it points out a specific area that could be strengthened by additional experiments. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or suggested specific experiments that could be performed. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary to make the results more idiomspecific. The action is implicit and vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed upweighing and KNN methods, referencing Figure 3 to support its claims. However, it does not specify which part of the paper Figure 3 is located in, making it difficult for the authors to pinpoint the exact section being discussed. While the comment is specific in its critique of the methods, the lack of grounding makes it challenging for the authors to understand the exact part of the paper that needs attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the impact of the proposed MT modeling methods on idiomatic vs. random data is similar, suggesting that the results may not be specific to idiomatic translations. The comment provides a logical reasoning based on the observation that the impact is similar across different language and score combinations, as shown in Figure 3. However, it lacks specific examples or references to support the claim further, making it 3. The authors could benefit from additional evidence or examples to strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. The comment provides a logical reasoning based on the observation that the impact is similar across different language and score combinations, as shown in Figure 3. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve the results to be more idiomspecific. While it identifies a potential weakness in the methodology, it lacks actionable advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits the comment\"s overall impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the consistency of the number of biases across different parts of the paper, specifically noting that the authors mention having C biases in section 3.4 but only find one hyperparameter for the feedforward models. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the discrepancy in the number of biases. The comment is specific in its request for clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a discrepancy in the number of biases mentioned in the text and the hyperparameter found in section 3.4, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the consistency of the number of biases mentioned in the text and the hyperparameter found in section 3.4. It suggests that the authors should clarify why they have C biases mentioned in the text but only one hyperparameter for the feedforward models described in section 3.4. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the number of biases is inconsistent. This lack of detailed explanation or evidence makes the claim 3, as the authors may need to infer the basis for the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the consistency of the number of biases mentioned in the text and the hyperparameter found in section 3.4. It points out that the authors mention having C biases but only find one hyperparameter for the feedforward models described in section 3.4, which creates confusion. This feedback is clear and actionable, as it directs the authors to clarify the discrepancy in the number of biases. By addressing this inconsistency, the authors can improve the clarity and coherence of their paper. The comment is 4 as it provides a specific area for improvement but could be more comprehensive if it suggested additional ways to enhance the clarity of the paper."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that subtracting dynamic factors from dynamic information in Equation 8 might lead to the loss of some dynamic information, which could hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the equation. The action is implicit and vague, as it leaves the authors to infer the necessary steps to mitigate the potential loss of information. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to Equation 8, indicating that the authors can accurately identify the part of the paper being discussed. It provides a clear and specific explanation of a potential problem with the equation, suggesting that subtracting dynamic factors might lead to the loss of dynamic information, which could affect the LSTM module\"s ability to capture complete dynamic changes. This level of detail and specificity allows the authors to understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting dynamic factors from dynamic information in Equation 8 might result in the loss of some dynamic information, which could hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically suggesting that subtracting dynamic factors might lead to the loss of dynamic information, which could affect the LSTM module\"s ability to capture complete dynamic changes. While the comment highlights a specific concern, it does not provide detailed guidance or suggestions on how to address this issue or what modifications might be necessary. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how to address these questions or what experiments to conduct to explore these effects. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it identifies areas that could be explored further, it does not provide specific guidance or suggestions on how to address these questions or what experiments to conduct. The feedback is 3 as it points out potential areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the evaluation of the proposed approach by noting the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it does not provide explicit guidance on how to conduct a direct comparison of test accuracy. The action is implicit, as the authors are expected to infer that they need to include a direct comparison of test accuracy to demonstrate the improvement of the proposed approach over the baseline. However, the lack of concrete instructions on how to perform this comparison makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of direct comparisons with the prior approach PRANC in both language and vision tasks, and the lack of a direct comparison of test accuracy. This provides the authors with a clear understanding of what needs to be addressed to strengthen the evaluation of the proposed approach. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in either the language or vision tasks used to evaluate the proposed approach. However, the comment does provide some evidence by mentioning comparisons of training loss in Section 3.4 and a comparison of the rank of possible solutions in Section 3.5. While these comparisons are mentioned, they do not directly address the lack of a direct comparison of test accuracy, which is the core of the claim. The lack of explicit examples or references to support the claim about the absence of direct test accuracy comparisons makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it highlights the critical issue of the lack of a direct comparison of test accuracy, which is essential for demonstrating the improvement of the proposed approach over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or suggested additional metrics to consider. Overall, the comment is 4, as it effectively guides the authors to address a key limitation in their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It asks for clarification on how these event types were selected and what coverage they provide on the 33 event types in the ACE data. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these concerns. The action is implicit, as the authors need to infer that they should provide more details on the selection process and coverage. However, the lack of concrete guidance on how to implement this action makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It specifically mentions Section 2 line 262, which indicates that 21 event types are selected from Freebase. However, the comment does not specify what the authors need to address regarding the selection process or the coverage on the 33 event types in the ACE data. This makes it difficult for the authors to pinpoint the exact part of the paper that needs clarification. The comment is weakly grounded as it does not provide explicit references to specific sections or parts of the paper, but it is specific in detailing what needs to be addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It specifically mentions Section 2 line 262, which indicates that 21 event types are selected from Freebase. However, the comment does not provide any justification or reasoning for why this selection is made or how it relates to the 33 event types in the ACE data. Without additional context or explanation, the claim that the authors need to address the generalizability of the method and the selection of event types remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It specifically mentions that 21 event types are selected from Freebase in Section 2, line 262, and asks for clarification on how these event types were selected and what coverage they provide on the 33 event types in the ACE data. This feedback highlights a potential gap in the paper\"s discussion and suggests that the authors need to provide more details to address these concerns. However, the comment lacks specific guidance on how the authors should address these issues or what additional information would be helpful. While it identifies an area for improvement, it does not offer detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the experimental evaluation of the paper, noting that the experiments conducted do not fully align with the claim of the importance of language modeling capability. It suggests that the authors should include experiments on tasks like language modeling, machine translation, or text summarization to better reflect the capabilities of language models. The comment provides a clear and explicit action for the authors to take, which is to include additional experiments that align with the paper\"s claims. This action is concrete, as it specifies exactly what experiments should be conducted. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments conducted in section 5.3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the experiments, noting that they do not align with the claim of the importance of language modeling capability. The comment suggests including tasks like language modeling, machine translation, or text summarization to strengthen the paper, providing specific guidance on how to improve the experimental evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments conducted do not fully align with the paper\"s claim about the importance of language modeling capability. It suggests that the authors should include experiments on tasks like language modeling, machine translation, or text summarization to better reflect this capability. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient. While the reasoning is logical, the absence of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental evaluation of the paper, noting that the experiments conducted do not fully align with the claim of the importance of language modeling capability. It suggests that the authors should include additional experiments on tasks such as language modeling, machine translation, or text summarization to better reflect the capabilities of language models. This feedback is clear and actionable, providing the authors with specific directions for improving their draft. By addressing this issue, the authors can strengthen the paper\"s claims and provide a more comprehensive evaluation of their work. Therefore, the comment is 5, as it offers constructive guidance for enhancing the paper\"s experimental rigor and relevance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern that the proposed method\"s improvement over existing RL methods is not impressive. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks concrete guidance on how the authors might enhance their method or present it more effectively to demonstrate its superiority. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment expresses concern about the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this concern relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the improvement are not impressive or how the authors might address this issue. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, the comment lacks specific details or evidence to support this claim. It does not provide any examples, references, or logical reasoning to substantiate the assertion that the improvement is not impressive. Without further context or justification, the authors are left without a clear understanding of why this claim is made or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the improvement of the proposed method over existing RL methods, suggesting that it is not impressive. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance their method. It does not provide actionable feedback or guidance on what aspects of the method could be improved to demonstrate its superiority. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the proposed method, PACE, addresses a gap by treating climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts. However, the comment does not provide explicit guidance on how the authors should revise their draft to clarify the distinction between their work and prior efforts. The action is implicit, as the authors need to infer that they should address the overlap with existing work. Additionally, the comment lacks concrete details on how to make the distinction clear, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim being made in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is misleading about the claim, noting that prior work, such as ClimateBench or ClimateSet, has already addressed similar concepts. This provides clear guidance on how the authors should revise their draft to clarify the distinction between their work and prior efforts. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim about addressing a gap by proposing PACE as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, has already done this. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how the prior work aligns with the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim made in the paper regarding the novelty of the proposed method, PACE, in addressing a gap in climate emulation. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts, which could make the claim misleading. However, the comment does not provide specific guidance on how the authors should revise their draft to clarify the distinction between their work and prior efforts. While it highlights a potential area for improvement, it lacks actionable advice or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It also recommends condensing the existing figures to make space for these visual results. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on which figures to move or how to condense them. The action is somewhat vague, as the authors need to infer which figures to move and how to condense them to effectively utilize the space. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, emphasizing the lack of visual results on crowd density estimation, which is a central experiment. It also recommends condensing the existing figures to make space for these visual results. However, the comment does not specify which figures are being referred to or how they should be condensed. This makes it difficult for the authors to accurately identify the parts of the paper that need attention. The comment is fully grounded in terms of identifying the area of concern, but it is not specific in detailing what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, emphasizing the lack of visual results on crowd density estimation, which is a central experiment. It recommends condensing the existing figures to make space for these visual results. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. The lack of detailed justification makes it difficult for the authors to understand the rationale behind the suggestion, leaving them with limited guidance on how to proceed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific feedback on the organization of the paper, suggesting that visual results from the supplementary material should be moved to the main paper to enhance the presentation of crowd density estimation, a central experiment. It also recommends condensing the existing figures to make space for these visual results. This feedback is actionable and constructive, as it directly addresses a specific area of the paper that could improve its clarity and impact. By providing clear guidance on where to move visual results and how to condense figures, the comment empowers the authors to make meaningful improvements to their draft. Therefore, the comment is rated as 4, as it offers detailed and actionable suggestions that could significantly enhance the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include an analysis or results on other datasets, such as ImageNet derivatives, to verify the effectiveness of the framework. It implies that the authors should consider presenting these results in the main paper. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects of the framework should be evaluated on these datasets. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include an analysis or results on other datasets, such as ImageNet derivatives, to verify the effectiveness of the framework. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its suggestion to include results on ImageNet1k or ImageNet100, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include an analysis or results on other datasets, such as ImageNet derivatives, to verify the effectiveness of the framework. While the comment implies the importance of this additional analysis, it lacks specific details or references to support the claim. The authors are left to infer the need for this analysis, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while improvements are shown on CIFAR derivatives, the analysis lacks results on other datasets, such as ImageNet derivatives. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive evaluation of the framework\"s effectiveness. However, the comment could be more helpful if it suggested specific ways to analyze or present the results on these additional datasets, such as proposing particular metrics or methods for evaluation. Without these details, the authors may find it challenging to fully address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the initial mention of BigFive and MBTI as models in the Abstract and Introduction sections and their subsequent use as datasets in the Experiments section. It suggests that the authors should either extend their explanation for using these as models or state them as datasets throughout the paper. While the comment identifies a specific issue and provides a clear direction for addressing it, it does not offer detailed guidance on how to extend the explanation or what specific aspects of the models should be discussed. The action is explicit but somewhat vague, as it leaves the authors with a general idea of what needs to be done but lacks concrete steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Abstract and Introduction sections where BigFive and MBTI are initially presented as models, and the Experiments section where they are used as datasets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue: the discrepancy between the initial mention of BigFive and MBTI as models and their use as datasets in the experiments. It suggests that the authors should either extend their explanation or state them as datasets throughout the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are initially presented as models in the Abstract and Introduction sections but are used as datasets in the Experiments section. This observation is based on a direct comparison of the content in these sections. The comment suggests that the authors should either extend their explanation or state them as datasets throughout the paper. While the claim is based on factual observation, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the authors to address the issue but does not offer comprehensive support or detailed justification.", "helpfulness_rationale": "The review comment identifies a discrepancy between the initial presentation of BigFive and MBTI as models in the Abstract and Introduction sections and their use as datasets in the Experiments section. It suggests that the authors should either provide an extended explanation for this approach or consistently treat them as datasets throughout the paper. This feedback is clear and actionable, as it provides a specific direction for the authors to address the inconsistency in their usage of these terms. However, the comment could be more helpful if it offered additional guidance on how to extend the explanation or what specific aspects of the models should be discussed. Overall, the comment is 4, as it effectively highlights an issue and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. While the comment provides a clear action\u2014either to include rejection rates or to consider misclassifications as rejections\u2014it does not specify how to implement this action. The authors are left with a general direction but lack concrete guidance on how to incorporate rejection rates into their results or how to justify viewing misclassifications as rejections. Therefore, the comment is 3, as it provides an explicit action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. However, it does not specify which part of the paper this issue pertains to, such as the results section or a specific table. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to verify the claim independently. The comment suggests that misclassifications could be viewed as rejections, but it lacks detailed reasoning or evidence to substantiate this claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that misclassifications could be viewed as rejections, which is a valuable insight for the authors to consider. However, the comment lacks detailed guidance on how to incorporate rejection rates into the results or how to justify viewing misclassifications as rejections. While it provides a clear direction for improvement, the feedback could be more helpful if it included specific steps or examples for the authors to follow. Therefore, the comment is 3, as it offers a clear area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While the comment explicitly requests information about the thresholds and hyperparameters, it does not provide specific guidance on how to obtain or present this information. The authors are left to infer that they need to provide these details, but the action is not concrete. Therefore, the comment is 3, as it provides an implicit action but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. However, it does not specify which part of the paper these thresholds and hyperparameters are discussed in, making it difficult for the authors to identify the exact section or table that needs attention. The comment is specific in its request for information but lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. This is a request for additional information and clarification, which is a common request in peer reviews. It does not contain a subjective opinion or claim that requires verification. Therefore, the comment is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment requests clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While the comment identifies an area for improvement, it lacks specificity and actionable guidance on how to address the issue. The authors are left to infer that they need to provide these details, but the comment does not offer concrete steps or examples to improve the draft. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While this is a specific suggestion, it does not provide explicit guidance on how to achieve this optimization. The authors are left to infer that they need to adjust the figure\"s layout or design to reduce whitespace usage. However, the comment lacks concrete details on how to implement this optimization, such as specific design elements or techniques that could be used. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests optimizing Figure 1 to use less whitespace. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in its suggestion to optimize the figure, but without knowing the exact location, the authors may struggle to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this optimization is necessary or how it would impact the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While this feedback is specific and actionable, it lacks broader context or suggestions for improvement. The authors are left to infer that optimizing whitespace could enhance the figure\"s visual appeal and readability, but without additional guidance or examples, the feedback is somewhat limited in its scope. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of replacing the first column of Qo with vo, which affects the reachability of the first state. It suggests that this change might impact the validity of Assumption 1, which concerns the finite length of an option. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of this change on their assumptions and potentially revise their approach. The lack of concrete instructions makes the action somewhat vague, aligning with a score of 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the implications of replacing the first column of Qo with vo and its impact on the reachability of the first state and Assumption 1. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the implications of a specific change in the paper, namely the replacement of the first column of Qo with vo, and its impact on the reachability of the first state and Assumption 1. While the comment highlights a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, pointing out a potential problem with the replacement of the first column of Qo with vo, which affects the reachability of the first state and potentially impacts Assumption 1. While the comment highlights a potential area of concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or what changes could be made to the paper. The feedback is 3 as it directs the authors to a specific part of the paper that requires attention, but it lacks depth and actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not explicitly instruct the authors on how to implement this suggestion or what specific aspects to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this suggestion is relevant or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a suggestion for the authors to consider if they did not see improvements in FLOPs or inference time, suggesting they should look for improvements in accuracy or specific properties. While the comment offers a potential direction for exploration, it lacks specific guidance on which aspects to focus on or how to approach this analysis. The suggestion is 3 as it prompts the authors to consider alternative metrics or properties, but it does not provide detailed instructions or examples, which could limit its effectiveness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should have tested this assumption, the comment does not provide explicit guidance on how to conduct the test or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer that they need to test the assumption. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not specify which part of the paper this assumption is made or where it is discussed. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the testing of the assumption, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to assume that the assumption has not been tested, but they cannot verify this claim independently. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the assumption made regarding the use of d_e as replacements for entity embeddings. It questions whether this assumption has been tested, which is a crucial aspect of ensuring the validity of the research. However, the comment does not provide any specific guidance or suggestions on how the authors might test this assumption or what aspects they should focus on. While it identifies an important gap in the evaluation, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the choice of IoT datasets, specifically FlatCam Face [26] and Headpose detection [11], is unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might have been more appropriate. While the comment identifies a potential issue with the dataset selection, it does not provide explicit guidance on how the authors should address this concern or what specific datasets they should consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative datasets and potentially reevaluate their benchmarking results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the choice of IoT datasets, namely that they are unpopular and outdated, and suggests better options for benchmarking. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, specifically FlatCam Face [26] and Headpose detection [11], is unpopular and outdated, making the benchmarking results difficult to sense and evaluate. The comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. However, the comment lacks specific examples or references to support the claim that these datasets are indeed unpopular or outdated. Without detailed justification or evidence, the claim remains 3, as the authors may need to conduct further research to fully understand the basis of the criticism. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, noting that the selected datasets, FlatCam Face [26] and Headpose detection [11], are unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. This feedback is 3 as it highlights a potential weakness in the dataset selection and provides suggestions for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to select or justify the use of these datasets or suggested specific alternative datasets. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions that the paper formatting does not follow the NeurIPS style, specifically noting issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and provides specific actions for the authors to take, such as revising the formatting and restructuring the paper. The comment is explicit and concrete, allowing the authors to understand exactly what needs to be addressed and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions issues with the paper formatting, specifically noting that it does not follow the NeurIPS style, with the abstract font being too large and the bottom page margins altered. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is fully grounded as it clearly identifies the specific parts of the paper being addressed, and it is specific because it details the issues with the formatting and suggests concrete actions for improvement. Therefore, this comment is rated as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the paper formatting does not follow the NeurIPS style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the issues or understand how to address them. The feedback is 3 as it provides a general direction but lacks detailed evidence or guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not adhere to the NeurIPS style. It highlights particular problems, such as the abstract font being too large and the bottom page margins being altered. The comment suggests that by addressing these formatting issues, the authors could gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, it could be more helpful if it included additional suggestions or guidance on how to address the formatting issues. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a clear and explicit action that the authors can easily understand and implement. The comment provides a specific and concrete instruction on how to improve the figure, making it 5.", "grounding_specificity_rationale": "The comment suggests that the annotations in Figure 4 can be further enlarged for better visibility. However, it does not specify which part of the paper Figure 4 is located in, nor does it provide any context or explanation for why this is necessary. The authors may infer that it refers to a specific section or figure, but the lack of explicit mention makes it difficult to pinpoint the exact area. The comment is specific in its suggestion but weakly grounded as it does not provide clear guidance on which part of the paper needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a factual observation about the presentation of the figure, but it does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is descriptive and does not provide any reasoning or evidence to support the claim. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a specific and actionable piece of feedback that the authors can easily implement. By making the annotations more visible, the authors can improve the readability and understanding of the figure, which is crucial for the clarity of the paper. However, the comment could be more helpful if it provided additional context or suggestions for improving the figure\"s presentation beyond just enlarging the annotations. Overall, the comment is 3 as it offers a clear direction for improvement, but it could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment raises a concern about the scope of the claim but does not offer guidance on how to address it or what changes might be necessary. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific as it clearly specifies what is being questioned, namely the scope of the claim regarding the existence of multiple entities in relation classification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any specific evidence, examples, or references to support this critique. Without additional context or justification, the claim remains unsubstantiated, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, it does not provide any suggestions or guidance on how to address this issue or improve the draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse\". This is a specific and actionable suggestion that the authors can easily implement by revising the label. The comment provides clear guidance on what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that one of the labels on the color bar should be \"worse,\" providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse.\" This is a specific observation that requires the authors to verify the accuracy of the label. However, the comment does not provide any additional context, reasoning, or references to support why this correction is necessary or beneficial. Without further explanation or evidence, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment points out a specific issue with Figure 4, suggesting that one of the labels on the color bar should be \"worse.\" This is a clear and actionable feedback that the authors can easily address by revising the label. The comment is specific and provides a direct suggestion for improvement, making it 5 for the authors to enhance the clarity and accuracy of their work. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific issue in the text, pointing out that the phrase \"training/validation/test\" should be \"training/validation/test sets\". This is an explicit action that the authors can take to correct the text. The comment is clear and provides a concrete instruction on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the correction needed, which is to add \"sets\" to the phrase \"training/validation/test\". This provides the authors with a clear understanding of what needs to be changed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, stating that the phrase \"training/validation/test\" should be \"training/validation/test sets\". This is a straightforward observation that does not require any additional reasoning or evidence to be verified. The comment is clear and accurate, making it 5. Therefore, it aligns with a score of 5.", "helpfulness_rationale": "The review comment identifies a specific error in the text, pointing out that the phrase \"training/validation/test\" should be corrected to \"training/validation/test sets\". This is a clear and actionable suggestion that directly addresses a factual inaccuracy in the paper. By providing this correction, the authors can improve the accuracy and clarity of their work. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets around the term or defining the bracketed term separately. These suggestions are explicit and provide concrete guidance on how the authors might address the issue. The comment is clear and actionable, allowing the authors to directly implement the proposed changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides concrete suggestions for improving the clarity of the definition by adding extra brackets or defining the bracketed term separately. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets or defining the bracketed term separately. While the comment provides a suggestion for improvement, it does not offer any specific reasoning or examples to support why the current definition might be confusing. The lack of detailed explanation or evidence makes it difficult for the authors to fully understand the basis of the claim. Therefore, the comment is considered 2, as it provides some suggestion but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the definition of the quantile, suggesting that adding extra brackets or defining the bracketed term separately could improve understanding. This feedback is specific and actionable, providing the authors with clear guidance on how to enhance the clarity of their paper. By addressing this suggestion, the authors can make their work more accessible and easier to comprehend for readers. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a \"very high performing model\" or a similar phrase. This provides a clear and explicit action for the authors to take, as they can directly address the suggestion by considering alternative models or updating their references. The action is also concrete, as it specifies the exact change needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the model by Dozat and Manning (2016) with a \"very high performing model\" or a similar phrase, providing clear guidance on what needs to be done. This level of detail helps the authors understand exactly how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing the model by Dozat and Manning (2016) with a \"very high performing model\" or a similar phrase. While the suggestion is based on the reviewer\"s opinion that the model is no longer stateoftheart, it lacks specific evidence or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a specific issue with the model used in the paper, suggesting that the model by Dozat and Manning (2016) is no longer stateoftheart. It provides a clear and actionable suggestion to replace it with a \"very high performing model\" or a similar phrase. This feedback is helpful as it directs the authors to consider alternative models or update their references, potentially improving the accuracy and relevance of their work. However, the comment could be more helpful if it provided additional context or guidance on which models might be suitable replacements. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used in the approach design. While it suggests that exploring additional properties might be beneficial, it does not provide explicit guidance on how to identify or utilize these properties. The comment is somewhat vague, as it lacks specific examples or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a direction but not a detailed path for implementation.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide context or references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. This feedback is 3 as it prompts the authors to consider expanding their approach and potentially enhancing its effectiveness. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to identify or utilize these additional properties. Without concrete examples or actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness in the method, noting that it is mostly constructed on top of previous methods without significant network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes to make. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies weaknesses in the method, specifically noting that it is mostly constructed on top of previous methods without significant network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issues with the method, but it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the method, noting that it is mostly constructed on top of previous methods without significant network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not provide detailed reasoning or suggestions for improvement, leaving the authors with limited guidance on how to address the identified issue. While it points out a potential area for simplification, the lack of actionable advice makes the comment 3, as it highlights a specific area for improvement but does not fully support the authors in making changes. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 tsne plots. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested analysis into their draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the redundancy of RQ1 and suggests an interesting point for analysis regarding the relationship between explicit and implicit hate speech detection. However, it does not specify which part of the paper discusses RQ1 or where the suggested analysis should be included. The comment is weakly grounded as it does not provide explicit references or sections, but it is specific in detailing what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also suggests an interesting point for analysis regarding the relationship between explicit and implicit hate speech detection. However, the comment lacks specific examples or references to support the claim that the RQ1 is redundant or adds no extra information. The suggestion for analysis is vague and does not provide detailed guidance on how to implement it. Therefore, the claim is 1 due to the lack of supporting evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a potential issue with the redundancy of RQ1 in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis regarding the relationship between explicit and implicit hate speech detection, specifically mentioning the impact of the percentage of explicit hate information on implicit hate speech detection performance and vice versa. However, the comment lacks detailed guidance on how the authors should address this issue or incorporate the suggested analysis into their draft. While it provides a direction for improvement, the feedback is somewhat limited in its depth and actionable nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the authors\" work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it prompts the authors to elaborate on these differences, it does not provide explicit guidance on how to address this question or what specific aspects need to be clarified. The action is implicit, as the authors need to infer that they should compare their work with the mentioned papers and explain the differences. However, the comment lacks concrete details on how to implement this comparison or what specific aspects to focus on, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"other works focusing on the semantic face editing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it prompts the authors to elaborate on the differences between their work and these papers, particularly regarding continuous control over attributes. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the differences between the authors\" work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it does not contain a direct claim, it prompts the authors to elaborate on these differences, which could be considered a suggestion for improvement. However, the comment lacks specific examples or detailed reasoning to support the need for this elaboration, making it 3. The authors would need to infer the importance of this comparison to understand the value of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the differences between the authors\" work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. This is a relevant point that could help the authors better position their work within the existing literature. However, the comment lacks specific guidance on how to elaborate on these differences or what aspects of the comparison are most important. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable advice, making it 3. The authors would need to infer the need for a more detailed comparison to fully benefit from this feedback. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a minor issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address the issue, such as suggesting where the additional content might be or how to update the caption. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a specific issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix that is missing or that the caption is out of date. However, the comment does not provide explicit guidance on which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section or figure being referred to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a specific issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text and suggesting that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment identifies a potential issue, it lacks detailed reasoning or references to support the claim that the label is missing or that the caption is out of date. The authors would need to infer the missing information or additional content, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the label \"OAA\" is not referenced in the body text and suggesting that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment highlights a potential oversight, it does not provide detailed guidance on how to address the issue or what specific content might be missing. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the introduction by stating that the proposed solution is a \"fix\" of [12], rather than a new PIC approach. It provides a specific example of where this clarification should be made, in lines 2930. This direct instruction and explicit guidance on how to implement the change make the comment 5. The authors know exactly what needs to be added to the introduction to address the feedback. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section where the clarification should be made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors must clarify the proposed solution as a \"fix\" of [12] rather than a new PIC approach, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors must clarify the introduction by stating that the proposed solution is a \"fix\" of [12] rather than a new PIC approach. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would benefit from additional context or references to support the assertion that the proposed solution aligns with the work of [12]. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides a clear and specific suggestion for improvement. It instructs the authors to clarify the introduction by explicitly stating that the proposed solution is a \"fix\" of [12] rather than a new PIC approach. This guidance is actionable and directly addresses a potential ambiguity in the paper, helping the authors to improve the clarity and accuracy of their presentation. By providing a specific example of where this clarification should be made, the comment offers a clear path for the authors to enhance their draft. Therefore, this comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference [2]. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions or detailed guidance on how to conduct the analysis or present the findings. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of the GS module on the effective receptive field. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the GS module and its impact on the effective receptive field, referencing a specific paper [2]. It does not explicitly mention a specific part of the paper where this issue is discussed, making it weakly grounded. However, the comment is specific in its focus on the effective receptive field and its relevance to the GS module. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference [2]. While the comment implies that the authors should investigate this aspect, it lacks specific details or examples to support the claim. The suggestion to compute the effective receptive field from [2] is a starting point, but the comment does not provide a comprehensive explanation or justification for why this is important or how it would be implemented. Therefore, the claim is 3, as it provides a basis for further exploration but lacks detailed support.", "helpfulness_rationale": "The review comment raises a question about the impact of the GS module on the effective receptive field, suggesting that it can be computed from a reference [2]. This feedback is 3 as it points out a potential area for further analysis and exploration. However, it lacks depth and does not provide specific guidance on how to conduct the analysis or what results to expect. The comment could be more helpful if it offered detailed suggestions or examples of how to approach the analysis, making it 4 rather than fully helpful. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While it prompts the authors to provide a justification for this combination, it does not explicitly instruct them to do so or offer guidance on how to address this question. The action is implicit, as the authors need to infer that they should provide a rationale for the combination. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the clarification is needed. While the comment is specific in its inquiry about the rationale and regularization, the absence of explicit grounding information makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This is a question that seeks clarification and does not present a subjective opinion or claim that requires verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This question prompts the authors to provide a justification for their approach, which could help them clarify their methodology and improve the clarity of their work. However, the comment lacks specific guidance or suggestions on how to address this question or what aspects of the combination might need further explanation. While it identifies an area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential area for clarification but does not offer comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, questioning the underperformance of linear/exponentialdecay sampling compared to uniform sampling and suggesting an alternative approach based on the authors\" argument about the predictor\"s accuracy on the good subregion. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the results are confusing or that the suggested alternative approach is valid. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable advice or detailed reasoning, making it 3. The authors would need to infer the necessary steps to address the concern, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. While the comment explicitly suggests that a brief explanation of \"multiaspect\" would be helpful, it does not provide guidance on how to implement this suggestion, such as what kind of explanation would be beneficial or how to integrate it into the paper. Similarly, the question about the subscripts in Figure 1 is specific but lacks guidance on how to address it. Therefore, the comment is 3, as it identifies areas for improvement but does not provide concrete steps for the authors to take. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 14, 47\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed: a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. This level of detail provides clear guidance on what the authors should do to improve their draft. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of two parts: a request for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. The first part is a suggestion for improvement, which is a claim that requires some level of justification. However, the comment does not provide specific examples or references to support why a brief explanation would be helpful. The second part is a question, which does not require verification. Overall, the comment is 3, as it provides a suggestion that could be substantiated with additional context or examples, but it lacks the depth of a 5 claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. While the comment identifies areas for improvement, it lacks depth and actionable guidance. The suggestion to provide a brief explanation of \"multiaspect\" is clear, but it does not offer specific advice on what kind of explanation would be beneficial or how to integrate it into the paper. Similarly, the question about the subscripts in Figure 1 is specific but does not provide guidance on how to address it. Overall, the comment is 3 as it highlights areas for improvement but does not provide comprehensive or detailed suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a missing citation for the public skipgram data set mentioned in line 425. While it points out the omission, it does not provide any explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include the citation, but the comment lacks detail on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the section of the paper where the issue lies. It is also specific because it clearly identifies the missing citation for the public skipgram data set, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, namely the missing citation for the public skipgram data set mentioned in line 425. This is a clear and actionable piece of feedback that directly points out a deficiency in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as where to find the missing citation or how to incorporate it into the paper. While it highlights a critical oversight, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the discussion regarding the hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback provides a clear and explicit action for the authors to take, which is to include a detailed discussion on how to set the hyperparameter in practice and to analyze its sensitivity. The comment is concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the discussion on arbitrary hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in detailing what is missing, such as guidance on setting the hyperparameter and sensitivity analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the hyperparameter \u03b3 is missing, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This claim is 3 as it highlights a gap in the paper but does not provide specific examples or references to support the claim. The authors would need to infer the missing information, which limits the verifiability of the comment. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the hyperparameter \u03b3, specifically regarding how to set it in practice for a given graph and the lack of sensitivity analysis. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the importance of this hyperparameter and its impact on the results, the comment guides the authors to include a detailed discussion that would enhance the clarity and reproducibility of their work. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should redefine Figure 3 to show scalar quantities instead of vectors. This is a clear and explicit action that provides specific guidance on how the authors should modify their draft. The comment is concrete, as it specifies exactly what needs to be changed and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the expected quantities should be scalars but are currently shown as vectors. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should redefine Figure 3 to show scalar quantities instead of vectors. This is a specific and actionable suggestion that directly addresses a potential issue with the presentation of the figure. However, the comment does not provide any reasoning or justification for why the quantities should be scalars or why they are currently shown as vectors. Without additional context or explanation, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is 3, as it is specific but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the expected quantities are scalars but are currently shown as vectors. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the accuracy and clarity of their figure. By redefining the figure to accurately represent the scalar quantities, the authors can enhance the precision and correctness of their presentation. This level of detail and specificity makes the comment 5, as it guides the authors in making a necessary correction to their work. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the resolution of the 3D voxel and its impact on computational cost. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the study of global features and specifically mentions methods like PiFu that avoid voxellike features due to computational and memory costs. It questions the resolution of the 3D voxel and whether it introduces unnecessary overhead. The comment suggests studying the importance of global features in Section 4.2 by comparing different resolutions of voxel features, noting that a 1x1x1 resolution is equivalent to using a single global feature. This provides a clear and specific direction for the authors to address the issue, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxellike features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that different resolutions of voxel features could provide valuable insights. The authors would need to infer the basis for this suggestion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxellike features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. This feedback is clear and actionable, providing a specific direction for the authors to improve their study by exploring the impact of different voxel resolutions on computational efficiency and the importance of global features. However, the comment could be more helpful if it included additional suggestions or guidance on how to conduct this comparison effectively. Overall, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It recommends exploring development set trends with respect to hyperparameters. However, the comment does not provide explicit guidance on how the authors should analyze the table or what specific actions they should take to identify these trends. The suggestion is somewhat vague and lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the table, namely the difficulty in discerning trends and suggests exploring development set trends with respect to hyperparameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a suggestion for improvement, specifically regarding the analysis of Table 3. It does not contain a subjective claim or opinion, but rather a request for clarification or further analysis. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly the behavior of PM+CL compared to PM or CL alone. It suggests exploring development set trends with respect to hyperparameters, which provides a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to analyze the table or what specific metrics to consider. Overall, the feedback is 3 as it highlights an area for improvement and suggests a potential avenue for further exploration, but it lacks depth and detail to fully empower the authors to address the issue comprehensively. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a difficulty in understanding Figure 5 due to overlapping lines, suggesting that the authors could report additional metrics such as FLOPs or model size to make the figure more concrete. While the comment provides a clear action\u2014improving the clarity of Figure 5 by adding more metrics\u2014it does not specify how to implement this action, such as which metrics to include or how to present them. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue with the figure, namely the difficulty in understanding due to overlapping lines, and suggests a concrete improvement by reporting additional metrics like FLOPs or model size. This provides clear guidance on what needs to be addressed to enhance the clarity and comprehensiveness of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to overlapping lines, and suggests that reporting additional metrics like FLOPs or model size would make the figure more concrete. While the comment identifies a specific issue with the figure\"s clarity, it lacks detailed reasoning or examples to fully support the claim. The suggestion to include additional metrics is logical but could be more robust with specific examples or references to similar practices in the field. Therefore, the comment is 3, as it provides a basis for improvement but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could enhance the figure\"s clarity by reporting additional metrics such as FLOPs or model size. This feedback is actionable and provides a clear direction for improvement, as it guides the authors on what additional information to include to make the figure more informative and easier to interpret. However, the comment could be more helpful if it offered specific examples of how to report these metrics or suggested alternative ways to present the data. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a primary concern that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It suggests simplifying the description and explaining the architecture and computations better. Additionally, it recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. While the comment provides explicit suggestions for improvement, such as simplifying descriptions and reducing content, it lacks concrete guidance on how to achieve these changes. The authors are left with a general idea of what needs to be done but without specific steps or examples, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on how to improve the paper, such as simplifying the description and explaining the architecture and computations better. The suggestion to reduce the content of lines 3964 further emphasizes the need for conciseness. This level of detail and specificity makes the comment 5 and grounded, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It suggests simplifying the description and explaining the architecture and computations better, and recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. While the comment provides a general suggestion for improvement, it lacks specific examples or references to support the claim that the paper is too dense. The authors may need to infer the need for simplification and reduction based on the feedback, which could make the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s readability, noting that it is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The reviewer provides specific suggestions for improvement, such as simplifying the description and explaining the architecture and computations better. Additionally, the comment recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. These suggestions are actionable and provide clear guidance for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or detailed explanations of how to simplify the content. Overall, the feedback is 4 as it offers valuable insights and actionable advice, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate the performance of EIGNN with respect to oversmoothing on realworld datasets, particularly in comparison to variants like GCNII. However, it does not provide explicit instructions or detailed guidance on how to conduct this evaluation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests evaluating the performance of EIGNN with respect to oversmoothing on realworld datasets, specifically comparing it to variants like GCNII. However, it does not specify which part of the paper this evaluation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare against certain variants, but the lack of grounding makes it difficult for the authors to pinpoint the exact area of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the performance of EIGNN with respect to oversmoothing on realworld datasets, particularly in comparison to variants like GCNII. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is important or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests evaluating the performance of EIGNN with respect to oversmoothing on realworld datasets, particularly in comparison to variants like GCNII. This feedback provides a specific direction for the authors to consider in their evaluation, which could enhance the robustness and comprehensiveness of their analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct this evaluation or what specific aspects to focus on. While it points out an area for improvement, it does not fully address the authors\" needs for a comprehensive evaluation. Therefore, the comment is 3, as it offers a clear direction but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a separate part or subsection dedicated to introducing the inference strategy. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit, as the authors can infer that they need to add a section or subsection explaining the inference strategy, but the comment lacks concrete details on how to implement this addition. Therefore, the comment is 3, as it provides a clear indication of what is missing but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of a separate part or subsection to introduce the inference strategy, particularly how multiple prompts are used in the test stage. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper that lacks clarity, namely the introduction of the inference strategy. It points out that the paper does not provide a separate part or subsection explaining how multiple prompts are used in the test stage. This feedback is clear and actionable, as it directs the authors to a specific section that needs improvement. However, the comment could be more helpful if it provided suggestions on how to introduce the inference strategy or examples of how to implement it. Overall, the comment is 3 as it highlights a clear area for improvement, but it lacks depth and guidance on how to address the issue effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that Figure 4 is confusing and that the columns are not explained in the text or caption. While the comment highlights a specific issue with the figure, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the meaning of the columns in the figure, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with Figure 4, which is the lack of explanation for the columns. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because it is not clear what the columns mean, as this is not explained in the text or caption. This claim is 3 as it points out a specific issue with the figure\"s clarity, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for clarification, making the comment 3.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 4, noting that it is confusing and lacks explanation for the columns. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the figure, such as adding a legend or a more detailed caption. Despite this, the comment offers a clear starting point for the authors to address the issue, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. The comment questions the complexity of the procedure to find upper bounds on gaps and its implications for solving a ranking problem. However, the comment does not provide explicit guidance on how to improve the discussion of the results or how to clarify the realworld applications. The suggestions are somewhat vague and lack concrete details, making the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. However, the comment does not specify which part of the paper these discussions or applications are related to, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises two main concerns: the need for a more detailed discussion of the experiment results and the lack of clarity regarding the realworld applications of the new problem setting. The first part suggests that the authors should provide a more comprehensive analysis of the results, particularly in the context of the Streetview experiment, and question the conclusion that MaxGapTop2UCB is better than other methods. This claim is 3 as it provides a specific example of what needs to be addressed but lacks detailed reasoning or references to support the suggestion. The second part of the comment questions the clarity of the realworld applications, specifically mentioning sorting and ranking, and raises concerns about the computational complexity of the procedure to find upper bounds on gaps. This part is also 3 as it points out a potential issue but does not provide extensive justification or examples. Overall, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the discussion of experiment results and the clarity of realworld applications. It suggests that the authors should provide a more detailed analysis of the Streetview experiment results, questioning the conclusion that MaxGapTop2UCB is better than other methods. Additionally, it points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. The comment also raises concerns about the computational complexity of the procedure to find upper bounds on gaps, which could impact the practicality of solving a ranking problem. While the comment provides some direction for improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is 3 as it highlights areas for the authors to enhance their paper, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or improve their results, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. The lack of specific referencing makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, it is 1 because it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. While the comment identifies a potential issue with the experimental setup or results, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps or detailed explanations to help the authors enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern regarding the verification of the hypothesis through the designed experiment. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. The comment suggests that it would be better to compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to conduct an additional experiment to strengthen the motivation of the work. The action is concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the comparison between models trained on the original dataset and the mixture of the original and adversarial examples to better verify the hypothesis. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not well verified by the designed experiment, specifically noting a discrepancy in how models are trained in conventional methods versus the base model. The comment suggests an additional experiment to compare models trained on the original dataset versus the mixture of the original and adversarial examples. This claim is 3 as it provides a logical reasoning for why the experiment might not be sufficient, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the hypothesis is not well verified by the designed experiment. It highlights a specific issue with the training methodology, noting that the base model is trained only on the adversarial set, while conventional methods are trained on the original training set in addition to the generated adversarial examples. The comment suggests a crucial experiment to compare the model trained on the original dataset with that trained on the mixture of the original and adversarial examples. This feedback is clear, actionable, and provides a specific direction for the authors to improve their draft by enhancing the motivation and experimental design. Therefore, the comment is 5, as it offers constructive guidance for the authors to address a critical aspect of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention that the results for model (3) in Table 1 were computed by themselves, as they are not reported in the original paper. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be added to their draft to address this issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results for model (3) (Chung et al. 2016) for CsEn were not reported in the original paper and suggests that the authors should mention this if they computed the results themselves. This provides a clear and detailed instruction for improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) in Table 1 were not reported in the original paper and suggests that the authors should mention this if they computed the results themselves. This claim is 3 as it provides a specific observation about the content of the paper and suggests a potential issue. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the results for model (3) in Table 1 were not reported in the original paper and suggests that the authors should mention this if they computed the results themselves. This feedback is clear and actionable, providing the authors with a direct instruction to address a potential inconsistency or omission in their work. By highlighting this detail, the comment helps the authors improve the accuracy and transparency of their presentation. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. While the comment implies an action, it does not explicitly instruct the authors to include a detailed plan or specify how to address the limitations. The action is somewhat vague, as it lacks concrete guidance on what constitutes a detailed plan or how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which part of the paper discusses the limitations, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion to provide a detailed plan, but it lacks grounding as it does not mention the specific part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment lacks specific details or examples of how this detailed plan might be structured or what actions could be taken. Without additional information or guidance, the authors may find it challenging to understand how to implement this suggestion effectively. Therefore, the comment is considered 2, as it provides some indication of what needs to be addressed but lacks sufficient detail or examples to be 5.", "helpfulness_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is 3 as it identifies a specific area for improvement\u2014addressing the limitations\u2014but lacks depth and specificity. The authors are given a direction to enhance their work, but the comment does not provide detailed guidance or examples of how to develop this plan. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It points out a potential inconsistency in the use of notation in Equation 3, specifically noting the use of p m in the numerator and p c in the denominator. The authors are asked to clarify the reason for this inconsistency. Additionally, the comment suggests that the variance could be considered for further improvement in Algorithm 2, where only the mean \u03bc f is used for the fusion prototype. The reviewer also suggests using \u03bc g instead of \u03bc f to maintain consistency with Equation 3. While the comment provides specific areas for clarification and potential improvement, it does not explicitly instruct the authors on how to address these issues. The suggestions are somewhat concrete, but the lack of explicit guidance on how to implement them makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses issues in Equation 3 and Algorithm 2, specifically regarding the use of notation and the consideration of variance. However, it does not explicitly mention which part of the paper these issues are located in, such as specific sections or equations. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of notation in Equation 3 and suggests considering the variance in Algorithm 2. However, it does not provide any specific reasoning or justification for why the notation is confusing or why variance should be considered. The comment lacks detailed explanations or references to support the claims, making it difficult for the authors to understand the basis of the feedback. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, such as clarifying the notation used in Equation 3 and suggesting the inclusion of variance in Algorithm 2. It also points out a potential inconsistency in the use of notation and suggests a more consistent notation. While the comment provides some actionable feedback, it lacks depth and could be more helpful if it offered more detailed guidance or suggestions for improvement. The feedback is 3 as it directs the authors to specific areas that need attention, but it could be more comprehensive to fully assist them in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in certain settings. While the comment implies that the authors should provide a more comprehensive discussion of computational complexity, it does not explicitly instruct them to do so or offer specific guidance on how to address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of computational complexity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment does not specify which part of the paper discusses the computational cost or where the authors should provide a more comprehensive discussion. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the computational cost, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion of computational cost, specifically questioning why the additional cost did not lead to significant delays and whether the proposed approach might become prohibitive in certain settings. While the comment highlights an area that could be improved, it does not provide specific suggestions or guidance on how to address these concerns. The feedback is 3 as it points out a potential weakness in the paper\"s discussion, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of indepth analysis of the experimental results. It provides a specific example, asking for clarification on why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is explicit and concrete, as it directly points out the need for a more detailed analysis and provides a clear direction for the authors to address this issue. The authors can infer that they should include a more thorough discussion of the experimental results, explaining the observed differences in model performance across different datasets. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for indepth analysis of the experimental results, specifically questioning the reasons behind the limited improvements on the offense detection dataset and the significant improvements on the coarse stereotype set. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it provides a clear example of what needs to be addressed, prompting the authors to delve deeper into the analysis of their experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of indepth analysis of the experimental results. It specifically questions the reasons behind the limited improvements of models on the offense detection dataset and the significant improvements on the coarse stereotype set. This feedback is valuable as it directs the authors to enhance the depth and clarity of their experimental analysis, which is crucial for a comprehensive understanding of their findings. However, the comment could be more helpful if it provided suggestions or guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 3 as it highlights an important area for improvement, but it lacks detailed actionable advice, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more baselines for graph contrastive learning and test them on common datasets. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is concrete, as it specifies which baselines to include and what datasets to test on, providing a clear path for improvement. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and suggests adding more baselines for graph contrastive learning. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies which baselines are missing and suggests testing them on common datasets, providing detailed guidance on what needs to be done. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the compared baseline in the graph classification task is not sufficient, specifically mentioning MVGRL[4] and gptgnn[5] as missing baselines. While the comment identifies a potential gap in the comparison, it does not provide specific reasoning or evidence to support why these baselines are missing or why their inclusion would be beneficial. The suggestion to add more baselines and test them on common datasets is clear, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the baselines used in the graph classification task, noting that MVGRL[4] and gptgnn[5] are missing. It provides a clear suggestion to include these baselines and test them on common datasets, which is a valuable piece of feedback for improving the comprehensiveness of the experimental evaluation. However, the comment could be more helpful by offering additional guidance on how to select appropriate baselines or datasets, or by suggesting specific metrics for comparison. Despite this, the feedback is 4 as it directs the authors to a concrete area for improvement, making it a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve the clarity of the table legends. The action is concrete, as it specifies the exact changes required, such as expanding the legends and clarifying the meaning of the numbers. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified in the legends, namely whether the numbers represent % errors or % correct, and specifies the context of MNIST and CIFAR. This level of detail helps the authors understand exactly what revisions are needed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This is a clear and specific claim that provides guidance on how to improve the clarity and accuracy of the table legends. The suggestion is logical and directly addresses the need for better labeling, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it provides specific feedback on the clarity and accuracy of the legends in Tables 1, 2, and 3. It suggests that the legends should be longer and clarify whether the numbers represent % errors or % correct, which is particularly relevant for the MNIST and CIFAR datasets. This feedback is actionable and constructive, as it guides the authors on how to improve the presentation and understanding of their results. By addressing a specific issue with the table legends, the comment offers a clear path for enhancing the clarity and interpretability of the paper, making it a valuable piece of feedback. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the theoretical foundation of the analysis, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, it does not provide explicit instructions or suggestions on how the authors might address these issues. The comment implies that the authors should consider providing these details, but it lacks concrete guidance on how to do so. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical work on sampling and particlebased optimization methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis is weak due to the lack of discussion on the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the theoretical foundation of the analysis, specifically regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. It highlights that these aspects are not discussed, which could impact the robustness and credibility of the analysis. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the analysis. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it offers a clear direction for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific questions and suggestions for improvement regarding the description of the graph G in Section 3.3. It asks how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be added or clarified in their draft. The comment is fully actionable, as it provides clear guidance on how to improve the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the size and elements of G, and adding the dimensions of G, X, and W to enhance understanding of the DGCN model. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for improvement regarding the description of the graph G in Section 3.3. It asks how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. While the comment provides specific suggestions for improvement, it does not offer any logical reasoning, common knowledge, or external references to support these claims. The feedback is primarily in the form of requests for clarification and additional information, which can help the authors improve their draft but lacks the depth of a 5 comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the draft, particularly in Section 3.3. It questions how the graph G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W. These suggestions are clear and direct, guiding the authors on what needs to be clarified or expanded in their paper. By addressing these points, the authors can improve the clarity and comprehensibility of their work, making the comment 5. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or improve the clarity of their terminology. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear definition of hyperspectral imaging, which helps the authors understand the confusion and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that calling \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any additional evidence or reasoning to support this claim. The comment lacks specific examples or references that would help the authors understand why the term is confusing or how it could be clarified. As a result, the claim is 1, making the comment unsuitable for improving the paper.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"hyperspectral.\" It suggests that this term might be confusing and provides a definition of hyperspectral imaging. However, the comment does not offer any actionable advice or suggestions on how the authors might address this confusion or improve the clarity of their terminology. While it points out a potential area for improvement, it lacks depth and does not provide guidance on how to implement the suggested changes. Therefore, the comment is 2, as it identifies a problem but does not offer substantial assistance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the concept of energy, which is introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment implies that the authors should consider providing additional context or hints about how to interpret energy, particularly in the context of morpheme splitting, and should clarify the concept of peak in the figure. However, the comment does not explicitly instruct the authors to add or modify content, making it 3. The action is clear but could be more explicit by directly instructing the authors to include these explanations and descriptions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Section 3.1 and Section 5.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as refreshing the concept of energy and providing hints for interpretation, as well as clarifying the concept of peak in Figure 5. This level of detail provides clear guidance on what changes are needed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment implies that the authors should consider providing additional context or hints about how to interpret energy, particularly in the context of morpheme splitting, and should clarify the concept of peak in the figure. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to infer the need for clarification and additional context, which could be improved with more explicit guidance.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the clarity and completeness of the paper. It highlights that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. Additionally, it points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. By suggesting these changes, the comment offers actionable feedback that could help the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to implement these suggestions or examples of how to interpret the energy concept. Overall, the feedback is 4, as it identifies key areas for improvement and encourages the authors to address them."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. It mentions specific examples, such as the combination of Linformer and window attention in Big Bird, to illustrate the need for such details. However, the comment does not explicitly instruct the authors to include these explanations or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of each component to the final performance improvements, with an example provided. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, with an example given. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis for the suggestion. The reasoning is vague and does not provide a clear justification for why such explanations are necessary. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed explanations of how each component contributes to the final performance improvements. It offers an example, such as the combination of Linformer and window attention in Big Bird, to illustrate the need for such detailed explanations. This feedback is 3 as it points out a specific area where the authors can enhance their draft, but it lacks depth and could be more actionable with additional guidance on how to provide these explanations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete advice on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the role of visual information in the paper, noting that it is not explicitly discussed or verified. It mentions an ablation study in Table 10, where the performance of the model with and without the perception module is similar, and the implementation details of the \"w/o perception\" module are unknown. The comment also questions the significance of the experimental results given the sample size, suggesting that the improvements might not be significant. However, the comment does not specify which part of the paper discusses the role of visual information or the ablation study, making it weakly grounded. It is specific in detailing the issues with the ablation study and the experimental results, but without explicit references to sections or tables, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. The comment provides specific examples, such as the similar performance of the model with and without the perception module, and questions the statistical significance of the improvements given the sample size. However, it lacks detailed reasoning or references to support these claims, making it 3. The authors would need to infer the basis for these claims, which could be improved with more detailed explanations or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, such as clarifying the role of visual information, providing explicit verification in the ablation study, and questioning the statistical significance of the experimental results. However, the comment lacks specific suggestions or actionable guidance on how the authors might address these issues. While it points out important weaknesses, it does not provide detailed feedback or constructive advice, making it 3. The authors would need to infer the necessary steps to improve their draft, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. It also points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. The comment is fully actionable because it specifies exactly what needs to be done, including identifying and citing previous works on Lasso screening. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue: the lack of citation and comparison of previous works on Lasso screening, providing a clear direction for improvement. The comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not provide any evidence or reasoning to support this claim. It suggests that previous works on Lasso screening are not cited or compared, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 29923006. However, the comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. However, it points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. By highlighting this gap, the comment offers constructive guidance for improving the paper\"s completeness and accuracy. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive if it included suggestions for how to address the issue or additional relevant works."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific claim made in the paper on line 238, which is that the Central Limit Theorem (CLT) implies that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer points out that this statement is incorrect, as the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment provides a clear and explicit action for the authors to take, which is to correct this inaccurate claim. It also specifies exactly what needs to be addressed, making the action concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly details the incorrect assertion made about the Central Limit Theorem (CLT) and provides a detailed explanation of why the claim is incorrect, including the limitations of the CLT in nonasymptotic regimes and its applicability to finite linear combinations of arbitrary random variables. This level of detail helps the authors understand exactly what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement on line 238, \"According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables,\" is incorrect. The reviewer provides a detailed explanation of why this claim is incorrect, citing the limitations of the CLT in nonasymptotic regimes and its applicability to finite linear combinations of arbitrary random variables. This detailed reasoning and explanation support the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific and incorrect claim made in the paper regarding the Central Limit Theorem (CLT). It provides a clear and detailed explanation of why the authors\" statement is inaccurate, highlighting the limitations of the CLT in nonasymptotic regimes and its applicability to finite linear combinations of arbitrary random variables. This feedback is actionable and constructive, as it guides the authors to correct the inaccurate claim, thereby improving the accuracy and reliability of their work. The comment is comprehensive and provides a clear path for improvement, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly instructs the authors to analyze the time complexity of the proposed policies mentioned in that section. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement, as it instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is clear and specific, instructing the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This provides a clear and actionable direction for the authors to improve their draft by addressing a specific aspect of their work. The feedback is concise and directly helpful, making it a valuable piece of guidance. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide explicit guidance on how the authors should address this overclaiming or what specific aspects need to be revised. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the overclaiming of the BC loss and provides a clear explanation of why the different aspects are considered the same concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential overclaiming of the proposed BC loss in the theoretical analysis section, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. This feedback is 3 as it points out a potential issue with the paper\"s claims, but it lacks specific guidance on how the authors might address this concern or what changes could be made to clarify the distinction. The comment provides a clear direction for improvement but does not offer detailed suggestions or actionable steps, which limits its overall impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or make changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It also critiques the use of arenabased evaluation systems like Chatbot Arena for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the evaluation methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arenabased evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3, as it provides a general critique but lacks detailed evidence or reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arenabased evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. While the comment identifies a potential issue with the evaluation methodology, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it highlights areas for improvement but lacks depth and actionable advice, leaving the authors with limited insight into how to proceed. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the statistical significance of the improvements of the proposed model over the RL without feedback model, based on the data presented in row 3 and row 4 of Table 6. It suggests that the authors should verify if the improvements are statistically significant. However, the comment does not provide explicit guidance on how to perform this verification or what specific statistical tests should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a statistical significance test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the improvements of the proposed model over the RL without feedback model, particularly noting that the BLEU1 score is worse. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the statistical significance of the improvements of the proposed model over the RL without feedback model, based on the data presented in row 3 and row 4 of Table 6. While the comment identifies a potential issue with the BLEU1 score, it does not provide any specific reasoning, examples, or references to support the claim that the improvements are not statistically significant. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the statistical significance of the improvements of the proposed model over the RL without feedback model, as indicated in Table 6. It questions whether the observed improvements, particularly in BLEU1, are statistically significant. This feedback is valuable as it highlights a potential area for further analysis and strengthens the authors\" claims. However, the comment could be more helpful if it provided guidance on how to conduct the statistical significance test or suggested specific statistical methods to use. Without these details, the authors may struggle to address the concern effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like RefNeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to compare the methods. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines in their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the choice of baseline methods, specifically mentioning RefNeRF and MipNerf for comparison, particularly in the appearance decomposition part and for larger outdoor scenes. However, it does not specify which part of the paper discusses these methods or where the comparison should be made. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its suggestions but weakly grounded as it lacks explicit references to the paper sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like RefNeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. However, the comment does not provide specific reasoning or evidence to support why these methods are particularly relevant or beneficial for the study. While the suggestions are logical, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the choice of baseline methods, particularly in the context of appearance decomposition and larger outdoor scenes. It recommends comparing the current methods to existing ones, such as RefNeRF and MipNerf, which could offer valuable insights and enhance the robustness of the evaluation. However, the comment lacks detailed guidance on how to implement these suggestions or what specific aspects of the comparison should be emphasized. While it offers a clear direction for improvement, the feedback could be more helpful if it included additional details or examples. Therefore, the comment is 4, as it provides actionable suggestions but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential confusion in the manuscript regarding the use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the usage of P in the manuscript, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment identifies a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. This provides clear guidance on what needs to be addressed, making the comment specific. However, the comment does not explicitly mention the section or part of the paper where this inconsistency is observed, which makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. This observation is clear and directly points out a potential confusion in the manuscript. However, the comment does not provide any additional context, examples, or references to support the claim. While the issue is verifiable, the lack of detailed explanation or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the manuscript, noting that the variable P is sometimes used as a probability and sometimes as a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it highlights a potential inconsistency in the manuscript that could affect the clarity and accuracy of the presentation. However, the comment could be more helpful if it provided suggestions on how the authors might address this confusion, such as clarifying the usage of P in the text or providing examples of how to use it consistently. Overall, the comment is 4 as it points out a significant issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion that individual standardization of feature dimensions could avoid this issue. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the suitability of their feature spaces and potentially standardize them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the suitability of feature spaces for 1NN and suggesting that standardizing feature dimensions could improve performance. This provides clear guidance on how to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and suggests that standardizing feature dimensions could improve performance. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that feature spaces not close to a spherical Gaussian may perform poorly. This makes the claim 3, as the authors would need to infer the basis for the claim or seek additional evidence to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the suitability of feature spaces for 1NN and provides a suggestion that standardizing feature dimensions could improve performance. While it identifies a potential issue with the feature space, it does not offer detailed guidance or specific advice on how to address this concern. The comment is 3 as it highlights an area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper: the description of state changes and environment giving a reward in section 3.1, line 143, and the clarity of the action description in line 154. It explicitly points out that the statement is not true of standard MDP formulations, suggesting that the authors may be implying a reward after each action, which is misleading. The comment also notes that it is unclear whether each action is a single feature or the power set, and suggests that the description could be made clearer. While the comment identifies specific issues and areas for improvement, it does not provide explicit guidance on how to address these issues. The actions are somewhat vague, as the authors are left to infer how to revise the description to align with standard MDP formulations and clarify the action representation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the content of these sections, pointing out that the statement about state changes and environment giving a reward is not true of standard MDP formulations and that the description of actions as single features or the power set is unclear. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in section 3.1, line 143, \"Then the state changes and environment gives a reward,\" is not true of standard MDP formulations. It also notes that the description of actions as single features or the power set is unclear. The comment provides a logical reasoning by pointing out the discrepancy between the statement and standard MDP formulations, which is a clear and verifiable claim. However, it could be more robust by providing specific examples or references to support the claim about standard MDP formulations. Overall, the comment is 4, as it is wellsupported but lacks some depth in explanation or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific feedback on two key areas of the paper. It points out that the statement in section 3.1, line 143, \"Then the state changes and environment gives a reward,\" is not true of standard MDP formulations, suggesting that the authors may be implying a reward after each action, which is misleading. This feedback is valuable as it highlights a potential misunderstanding or misrepresentation in the paper. Additionally, the comment notes that it is unclear whether each action is a single feature or the power set, and suggests that the description could be made clearer. This feedback is actionable and constructive, as it provides specific areas for improvement that the authors can address to enhance the clarity and accuracy of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text (L_task) and the notation used in Figure 1 (L_class). This suggests that the authors should ensure consistency in their notation throughout the paper. However, the comment does not provide explicit guidance on how to address this inconsistency or what specific changes need to be made to the text or figures. The action is implicit, as the authors can infer that they need to correct the inconsistency, but the lack of detailed instructions makes the action vague and challenging to execute. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a discrepancy in the notation used for the task loss, noting that it is called L_task in the text but L_class in Figure 1. This provides a specific reference to the inconsistency, allowing the authors to identify the exact part of the paper where the issue lies. The comment is fully grounded as it explicitly mentions the sections or figures where the discrepancy is noted. It is also specific because it clearly identifies the inconsistency in notation, which is a concrete issue that needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the notation used for the task loss, noting that it is called L_task in the text but L_class in Figure 1. This observation is factual and requires no further verification or reasoning to understand. The comment is a normal statement, as it describes a factual inconsistency without making any claims or suggestions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and highlights a potential source of confusion for the readers. However, the comment does not provide any suggestions or guidance on how the authors might address this inconsistency or improve the clarity of their presentation. While it points out a minor issue, it lacks actionable advice, making it 3. The authors would need to infer that they should ensure consistency in their notation, but the comment does not offer detailed steps or examples to facilitate this process. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It implies that the current evaluation, which only includes answer generation and summarization, is limited because these tasks are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment provides a clear action for the authors to take, which is to include machine translation in their evaluation. However, it does not specify how to implement this suggestion, such as which datasets or metrics to use. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the evaluation of the proposed method should include machine translation, which is considered a more convincing approach due to its lower uncertainties per word. However, the comment does not specify which part of the paper discusses the evaluation methodology or where the evaluation is currently performed. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs to be addressed. While the comment is specific in suggesting the inclusion of machine translation, the absence of explicit references or context makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of the proposed method is limited to answer generation and summarization, which are considered close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that including machine translation would provide a more convincing evaluation due to lower uncertainties per word. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed justification or evidence makes the claim 3, as it provides a logical argument but lacks the necessary depth to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization, which are considered close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that including machine translation would provide a more convincing evaluation due to lower uncertainties per word. This feedback is 3 as it highlights a specific area for improvement and suggests a potential enhancement to the evaluation methodology. However, it could be more helpful if it provided additional guidance on how to implement the machine translation evaluation or suggested specific datasets or metrics to use. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring what happens when \u03bb is even smaller. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. While the comment identifies specific areas that need clarification or correction, it does not provide explicit instructions on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring what happens when \u03bb is even smaller. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring what happens when \u03bb is even smaller. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. However, the comment lacks specific reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it identifies areas that need clarification or correction, but it does not provide detailed explanations or evidence to support the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring what happens when \u03bb is even smaller. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. While the comment identifies specific areas that need clarification or correction, it lacks detailed guidance on how the authors should address these issues. The feedback is 3 as it provides some insights into potential areas of concern, but it does not offer comprehensive suggestions or actionable steps for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific sentence in the paper that is confusing and requires clarification. It suggests that the authors should reread the sentence and the subsequent sentences to understand it better. However, the comment does not provide explicit guidance on how to clarify the sentence or what specific changes should be made. The action is implicit and vague, as it does not specify what needs to be done to make the sentence clearer. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, indicated by the line numbers [9395]. This allows the authors to accurately identify the section being discussed. The comment is also specific because it clearly identifies a confusing sentence and suggests that the authors should reread it and the subsequent sentences to understand it better. This provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a specific sentence in the paper is confusing and requires clarification. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors cannot determine why the sentence is confusing or how it could be clarified. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment identifies a specific sentence in the paper that is confusing and requires clarification. It suggests that the authors should reread the sentence and the subsequent sentences to understand it better. However, the comment lacks actionable guidance on how to clarify the sentence or what specific changes should be made. While it points out an area for improvement, it does not provide detailed suggestions or examples, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific instances where the authors need to address certain claims or statements in their paper. It explicitly mentions that the claims on lines 7879, 129130, 156158, and 217218 require citations or evidence. However, the comment does not provide any guidance on how the authors should go about finding or providing these citations or evidence. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment provides specific line numbers (7879, 129130, 156158, and 217218) where the authors need to address certain claims or statements. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. Additionally, the comment specifies what needs to be addressed in each of these sections, such as the need for citations or evidence. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific claims in the paper that require citations or evidence. It provides line numbers (7879, 129130, 156158, and 217218) where these claims are made, allowing the authors to accurately pinpoint the sections that need attention. However, the comment does not provide any examples, detailed reasoning, or references to support these claims, making it 3. The authors are informed about the need for citations or evidence but are not given specific guidance on how to obtain or present them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas in the paper where additional evidence or citations are needed, providing clear guidance for the authors to improve their draft. By pointing out the need for citations on lines 7879, 129130, 156158, and 217218, the comment directs the authors to specific sections where they should address these claims. This feedback is 4 as it offers actionable suggestions and highlights areas that require further support, but it could be more comprehensive if it provided more detailed guidance or examples of how to obtain the necessary evidence or citations. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is clear and explicit, providing a direct action for the authors to take: they should ensure consistency in the figures. However, the comment does not specify how the figures should be aligned or what changes need to be made to achieve consistency. While the action is clear, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the inconsistency between the two figures, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This provides a clear and detailed explanation of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is not consistent with Figure 2, specifically noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it provides a clear observation about the inconsistency between the two figures. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is clear and actionable, providing the authors with a direct point of comparison and highlighting a potential issue with the consistency of their figures. However, the comment could be more helpful if it suggested specific ways to address this inconsistency or provided guidance on how to ensure the figures are aligned. Overall, the feedback is 3 as it points out a clear issue that needs attention, but it lacks depth and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions how the inequality after line 433 follows from Lemma 7, suggesting that it might be a combination of previous inequalities. The comment implies that the authors should clarify the connection between Lemma 7 and the inequality, but it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should elaborate on the derivation of the inequality from Lemma 7. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the derivation of the inequality after line 433 from Lemma 7. The comment provides a clear and detailed request for clarification, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the derivation of an inequality from Lemma 7, specifically asking for clarification on how the inequality after line 433 follows from the lemma. While the comment does not contain a subjective claim or opinion, it does suggest that the authors should provide more context or explanation to facilitate understanding. However, it lacks specific examples or references to support the claim, making it 3. The comment is 4 as it points out a potential area for clarification but does not provide sufficient evidence or guidance for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific point of confusion regarding the derivation of an inequality from Lemma 7, which is crucial for understanding a particular aspect of the paper. By asking for clarification on how the inequality after line 433 follows from Lemma 7, the comment highlights a potential area where the authors may need to provide more detailed explanations or context. This feedback is actionable and constructive, as it directs the authors to improve the clarity and coherence of their presentation. However, the comment could be more helpful if it provided some guidance on how to address the issue or suggested specific ways to clarify the derivation. Overall, the comment is 4, as it effectively points out an area for improvement but could be more comprehensive in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the results of the bottomup method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. While the comment provides explicit guidance on what data to include and how to evaluate performance, it lacks specific instructions on how to implement these suggestions, such as which columns or metrics to focus on. The action is somewhat vague, as it does not provide detailed steps or examples for inclusion and evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the bottomup method [9]\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what data to include in the table and how to evaluate the performance of the authors\" method on the MS COCO dataset, particularly in easy (nonoccluded) settings. This level of detail helps the authors understand exactly what needs to be addressed and how to do it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the results of the bottomup method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. While the comment provides a clear suggestion for improvement, it lacks specific examples or detailed reasoning to support why this inclusion would be beneficial. The authors are left to infer the value of this suggestion, which makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by including the results of the bottomup method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. This feedback is actionable and constructive, as it guides the authors on what additional data to include and how to assess the performance of their method. However, the comment could be more helpful if it provided more detailed guidance on how to evaluate the performance or what specific metrics to focus on. Overall, the comment is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their approach. The authors are left without guidance on how to revise their draft to align with the complexity of annotation guidelines, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by pointing out that the paper only considers label names, descriptions, and fewshot examples, while annotation guidelines in the Information Extraction (IE) domain are complex and curated by linguists. The comment provides specific examples, such as the TACRED slot filling guidelines, to illustrate the complexity of annotation guidelines. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper may be overstating its use of \"annotation guideline\" by only considering label names, descriptions, and fewshot examples. It provides specific examples from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. The comment is 4 as it offers a clear rationale and examples to support the claim, but it could be strengthened by including more detailed references or a broader range of examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential overstatement in the paper\"s claim regarding the use of \"annotation guideline.\" It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. This critique highlights a gap in the paper\"s approach, suggesting that the proposed prompts might not fully capture the depth of true guideline understanding. However, the comment could be more helpful if it offered suggestions on how the authors could address this issue or improve their approach to align with the complexity of annotation guidelines. Overall, the feedback is valuable and provides a clear direction for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. It recommends comparing the method to token pruning and token combination baselines. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct these additional comparisons. The authors are left to infer that they need to add these comparisons to their experimental setup. This lack of explicit guidance makes the action somewhat vague and leaves the authors with limited direction on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment comparison is weak, specifically mentioning that the authors only compare their method to the BERTbaseline. It recommends comparing the method to token pruning and token combination baselines. However, the comment does not specify which part of the paper this comparison is intended for, such as a specific section or table. This makes it difficult for the authors to accurately identify the section being addressed, resulting in weak grounding. The comment is specific in its suggestion to include additional baselines, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak, as the authors only compare their method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is considered 2, as it provides a general suggestion but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should include comparisons to token pruning and token combination baselines to provide a more comprehensive evaluation of their method. This feedback is clear and actionable, as it directs the authors to enhance their experimental setup by adding additional baselines. However, the comment could be more helpful if it provided more detailed guidance on how to implement these comparisons or why these specific baselines are important. Overall, the comment is 4, as it offers a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to add this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these methods in their experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it should be in the experimental section. The comment is specific in its suggestion to include these methods, but it lacks grounding as it does not pinpoint the exact section or part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not provide specific reasoning or examples to support why such a comparison is important or how it would enhance the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some indication of the need for comparison but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section by suggesting that it should include a comparison to coordinateaware methods like TFN or SchNet. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s experimental evaluation. By comparing the proposed method to these coordinateaware methods, the authors can better demonstrate the effectiveness and relevance of their approach. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or why such a comparison is necessary. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential weakness in the paper by stating that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might identify or demonstrate these weaknesses, leaving them without a clear path forward. As a result, the comment is 1 because it does not offer any specific steps or suggestions for improvement. Therefore, this comment aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the authors did not show the possible weaknesses of the proposed model. It lacks any reference to a specific section, table, or figure, making it difficult for the authors to identify the exact issue. Additionally, the comment is not specific because it does not provide any details on what aspects of the model\"s weaknesses are not addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the model\"s weaknesses are missing, making the claim difficult to verify. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the authors did not demonstrate the possible weaknesses of the proposed model. This is a valuable piece of feedback as it highlights an area where the authors could strengthen their work by providing a more comprehensive analysis of their model\"s limitations. However, the comment lacks specific suggestions or guidance on how the authors might address these weaknesses, such as suggesting additional experiments or analyses that could be included. While it provides a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. While the comment implies that the authors should include more related work, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on which additional works to include or how to compare their method with BGLN. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. However, the comment does not specify which part of the paper the introduction of related work is located, making it weakly grounded. It is specific in suggesting the need for more work on GLN and the comparison with BGLN, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the introduction of related work, noting that it is insufficient and recommending the inclusion of more work on GLN to reflect the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft. However, it could be more helpful if it included suggestions on which specific works to include or how to effectively compare the proposed method with BGLN. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider adding more parameters to their model or providing a rationale for their current choice. The comment is 3 because it identifies a potential issue but lacks concrete details on how to implement the suggested changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. The comment is specific in its suggestion regarding the need for additional parameters, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind using only one dropout rate for Moon\"s approach, suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to explain why the authors chose to use only one dropout rate or why additional parameters would be beneficial. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment raises a specific question about the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. This feedback is 3 as it identifies a potential area for improvement in the paper, prompting the authors to consider whether their choice of dropout parameters aligns with the capabilities of different dropout methods. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors might address this issue or what specific changes they should make to their draft. While it points out a potential area for improvement, it does not offer a comprehensive or actionable response, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. While it points out a potential issue with the method\"s clarity, it does not provide explicit or implicit actions for the authors to take. The comment suggests that the authors should include information from 2hop neighbors and clarify why the method is effective. However, it does not specify how to incorporate this information or what aspects of the method need clarification. The action is somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of not including information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the issue of 2hop neighbors, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"overall, no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or context, the claim remains 3, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the method, specifically noting that it does not include information from 2hop neighbors and questions the effectiveness of the method. While it points out a gap in the information provided, it does not offer specific suggestions or guidance on how to address this issue or improve the method\"s clarity. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus used and the impact of changing the cycle duration on the model\"s time scale of adaptation. While the comment provides some context and questions, it does not explicitly instruct the authors to provide additional information or clarify their methodology. The action is implicit, as the authors need to infer that they should elaborate on the training process and the implications of changing the cycle duration. However, the comment lacks concrete guidance on how to address these points, making it 3.", "grounding_specificity_rationale": "The comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus used and the impact of changing the cycle duration on the model\"s time scale of adaptation. However, the comment does not specify which part of the paper Figure 7 is located in, making it weakly grounded. It is specific in detailing what needs to be clarified regarding the training process and the impact of changing the cycle duration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point requests clarification on how the model in Figure 7 was trained and whether changing the cycle duration would affect the model\"s time scale of adaptation. While the comment provides some context and questions, it lacks specific details or references to support the claims made. The authors are left to infer the reasoning behind the questions, which makes the claim 3. However, the comment could be more helpful if it provided examples or references to support the claims about the model\"s behavior.", "helpfulness_rationale": "The review comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus used and the impact of changing the cycle duration on the model\"s time scale of adaptation. It also references a study (Smirnakis et al. Nature 1997) to provide context. While the comment identifies an area that needs clarification, it does not offer specific suggestions or guidance on how to address the issue. The feedback is 3 as it prompts the authors to provide more detailed information, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. While the comment identifies a potential issue with the comparability of the results, it does not explicitly instruct the authors to address this concern or provide guidance on how to ensure fair comparisons. The action is implicit and somewhat vague, as the authors need to infer that they should consider the data usage in their comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons, questioning the use of different amounts of data in the comparisons. The authors are informed about the specific comparisons that use less data, such as H>N and H>B compared to H>N+B, and H>N>H and H>N>H compared to H>N+B>H. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B compared to H>N+B, and H>N>H and H>N>H compared to H>N+B>H. However, the comment does not offer any justification or reasoning for why this is a concern or how it might affect the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the comparability of results in Table 2, specifically questioning the use of different amounts of data in the comparisons. It provides specific examples, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is clear and actionable, as it directs the authors to consider the impact of data usage on the comparability of their results. However, the comment could be more helpful if it suggested specific ways to address this issue, such as standardizing the data usage or providing a rationale for the observed differences. Overall, the comment is 4 as it identifies a significant concern and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting that it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several issues, it does not provide explicit guidance on how to address them or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific guidance on how to address these issues further reduces the comment\"s effectiveness. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed justification or references makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm\"s application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several areas for improvement, it lacks specific guidance on how the authors might address these issues or what actions they should take. The feedback is 3 as it highlights areas that need attention, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment does not explicitly instruct the authors to remove or reorganize the section, nor does it provide specific guidance on how to better integrate the description of the proposed methodology with the model choice or how to use the time spent on ResNet architecture more effectively. The action is implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in suggesting that the description of the proposed methodology should be integrated with the model choice and that the time spent on ResNet architecture could be better used for motivation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general critique but lacks detailed justification or references. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of Section 2.1, specifically questioning the relevance of Batch Normalization in the context of the proposed Conditional Batch Normalization (CBN). It suggests that the description of the methodology appears independent of the model choice and that the time spent on describing the ResNet architecture could be better utilized to provide motivation and intuition for the CBN approach. While the comment highlights a potential area for improvement in the paper\"s structure and clarity, it does not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it points out a potential area for clarification and improvement, but it lacks detailed actionable advice, making it only marginally helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It highlights a potential inconsistency in the reasoning, suggesting that multiplying by a nicelyconditioned matrix might not result in a dense matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for clarification or correction. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue raised in the paper at line 122, where the authors assume a dense projection matrix multiplication leads to a sparse matrix. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly explains the inconsistency in the reasoning regarding the sparsity of the resulting matrix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It points out a potential inconsistency in the reasoning, suggesting that multiplying by a nicelyconditioned matrix might not result in a dense matrix. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper regarding the assumption made in equation (1) about the sparsity of the resulting matrix after multiplication by a dense projection matrix. It questions the reasoning behind this assumption, noting that multiplying by a nicelyconditioned matrix might not result in a dense matrix. This feedback is 3 as it highlights a potential inconsistency in the paper\"s logic, prompting the authors to reconsider their assumptions. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or clarify their reasoning. Overall, the comment offers a clear point of concern but lacks depth in terms of actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors need to provide a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This action is clear and concrete, as it specifies exactly what the authors should do to address the issue. The comment is fully actionable, as it provides a direct and detailed instruction on how to improve the paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question addressed in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of direct evidence for the motivation and suggests a way to support it by plotting a figure showing the decline in accuracy over time in different settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence of the motivation is not direct and suggests that the authors need to plot a figure to support their claim. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim. The comment is 3 as it offers a reasonable suggestion but could be strengthened with additional details or references to substantiate the claim. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the evidence supporting the motivation is not direct. It suggests that the authors should plot a figure demonstrating the decline in accuracy of a predictor over time in different settings to provide a more compelling argument. This feedback is clear and actionable, as it provides a concrete suggestion for improvement. However, the comment could be more helpful if it included additional guidance on how to design the figure or what specific data points should be included. Despite this, the comment is 4 as it directs the authors towards a clear and actionable improvement, enhancing the paper\"s clarity and impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It asks the authors to explain how excessive risk is defined in line 103 and how it is calculated in practice, particularly concerning expectation. The comment also questions why excessive risk is a good representation for fairness, given that the optimal solution \u03b8* is not the optimal solution for the loss function with respect to data of group a, potentially leading to negative values. The reviewer points out that all excessive risk values in Figure 3 and Figure 7 are positive and asks if these values are comparable across different groups. These questions and requests for clarification provide explicit guidance on what the authors should address, making the comment 5. The authors know exactly what aspects of the paper need further explanation or clarification, which helps them improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, including the definition of excessive risk, its calculation, and its comparability across different groups. This level of detail provides clear guidance on what aspects of the paper require clarification or explanation, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It asks the authors to explain how excessive risk is defined in line 103 and how it is calculated in practice, particularly concerning expectation. The reviewer also questions why excessive risk is a good representation for fairness, given that the optimal solution \u03b8* is not the optimal solution for the loss function with respect to data of group a, potentially leading to negative values. The comment points out that all excessive risk values in Figure 3 and Figure 7 are positive and asks if these values are comparable across different groups. While the comment raises valid questions that could be addressed with further explanation or examples, it lacks specific references or detailed reasoning to fully substantiate the claims. Therefore, the comment is 3, as it provides a basis for discussion but requires additional evidence or clarification to be fully convincing.", "helpfulness_rationale": "The review comment provides detailed feedback on the definition and calculation of excessive risk, raising several important questions that could help the authors improve their draft. It asks for clarification on how excessive risk is defined in line 103, how it is calculated in practice, and why it is a good representation for fairness. The reviewer also points out a potential issue with the values in Figure 3 and Figure 7, noting that they are all positive despite the possibility of negative values. This feedback is 4 as it identifies specific areas where the authors need to clarify their methodology and reasoning, but it could be more comprehensive if it included suggestions for addressing the issue with the positive values or additional examples to support the claims. Overall, the comment provides valuable insights that can guide the authors in refining their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific instances where the authors\" draft could be improved. It highlights a potential issue with the phrasing at line 200, suggesting that the term \"for every arm a\" might imply a single optimistic parameter, which is not necessarily the case. Additionally, it questions the choice of T_0 = m Sqrt(T) and suggests an alternative formulation that could improve the condition. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors need to infer how to revise their draft based on the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L200 and L303) in the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific feedback on the phrasing at line 200, questioning the implication of \"for every arm a\" and suggesting an alternative formulation. Additionally, it offers a specific suggestion regarding the choice of T_0 = m Sqrt(T) and proposes an alternative condition that could improve the paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts, both of which are factual statements. The first part questions the phrasing at line 200, suggesting that it might imply a single optimistic parameter, which is not necessarily the case. The second part questions the choice of T_0 = m Sqrt(T) and suggests an alternative formulation that could improve the condition. While the claims are based on logical reasoning and common knowledge, they lack specific examples or references to support the claims fully. Therefore, the comment is 3, as it provides some justification but could be strengthened with more detailed reasoning or references. The label aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on two distinct points in the paper, offering detailed suggestions for improvement. It questions the phrasing at line 200, suggesting that it might imply a single optimistic parameter, which is not necessarily the case. This feedback is actionable as it prompts the authors to reconsider the wording and ensure clarity. Additionally, the comment questions the choice of T_0 = m Sqrt(T) and suggests an alternative formulation that could improve the condition, providing a clear direction for the authors to enhance their work. While the feedback is specific and actionable, it could be more comprehensive if it included additional suggestions or examples. Overall, the comment is 4, as it offers valuable insights and guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue regarding the definition of variables L and E in the paper. It points out that these variables are not defined in the immediate vicinity, which could hinder the reader\"s understanding. Additionally, the comment notes inconsistencies in the italicization of L and E, which could affect the clarity and consistency of the paper. While the comment identifies a clear issue and suggests a specific area for improvement, it does not provide explicit guidance on how to define L and E or how to ensure consistent italicization. The action is somewhat vague, as the authors need to infer that they should define the variables and maintain consistent formatting. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the variables L and E are not defined in the immediate vicinity and that there are inconsistencies in their italicization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point highlights a specific issue regarding the definition of variables L and E in the paper, noting that they are not defined in the immediate vicinity and that there are inconsistencies in their italicization. While the comment identifies a factual observation about the paper\"s formatting and clarity, it does not provide any logical reasoning, common knowledge, or external references to support the claim. The authors are left to infer the need for clarification or correction, which limits the verifiability of the comment. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the variables L and E are not defined in the immediate vicinity and that there are inconsistencies in their italicization. This feedback is clear and actionable, as it points out a lack of clarity and consistency in the presentation of the variables. By highlighting these issues, the comment provides the authors with a direct path to improve the readability and consistency of their paper. However, the comment could be more helpful if it suggested specific ways to define the variables or ensure consistent formatting. Overall, the comment is 4 as it identifies a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which aspects of the experimental section are weak or what additional experiments would be beneficial. The comment lacks concrete guidance on how to improve the experimental section, leaving the authors with a general idea but no specific direction to follow. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which part of the paper the experimental section is located in, nor does it provide any details on what aspects of the experiments are weak or what additional experiments could be beneficial. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any guidance on how to improve the experimental section or what kind of additional experiments would be helpful. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer the nature of the weakness and the need for more experiments, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental section, noting that it is \"a little weak\" and that \"more experiments are required.\" While this feedback highlights an area for improvement, it lacks specificity and actionable guidance. The authors are left with a general idea of what needs to be addressed but without detailed suggestions on how to enhance the experimental section or what additional experiments might be beneficial. This lack of specificity and depth makes the comment 3, as it provides a starting point for improvement but does not fully empower the authors to address the issue effectively. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the use of \"Despite of\" and \"to a even deeper,\" and to correct the grammatical error on line 265. These instructions are clear and direct, allowing the authors to understand exactly what changes are needed. However, the comment does not provide additional guidance on how to achieve these changes or what specific aspects of the writing should be improved. Therefore, the comment is 4, as it provides explicit instructions but lacks detailed guidance on implementation. This aligns with a score of 4.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the use of \"Despite of\" and \"to a even deeper,\" and to correct the grammatical error on line 265. This provides clear guidance on which parts of the paper need revision, making the comment fully grounded. Additionally, it specifies what needs to be addressed in these parts, enhancing the specificity of the feedback. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of four claims, each suggesting specific changes to improve the writing style and clarity of certain sentences in the paper. The claims are specific and provide clear instructions on how the authors should revise the sentences. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. While the suggestions are logical and actionable, the absence of additional justification or evidence makes the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the use of \"Despite of\" and \"to a even deeper,\" and to correct the grammatical error on line 265. These suggestions are clear and actionable, offering the authors a clear path to improve the clarity and grammatical correctness of their text. However, the comment could be more helpful if it provided additional guidance on how to achieve these changes or what specific aspects of the writing should be improved. Overall, the feedback is 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not provide explicit guidance on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not provide any specific evidence, reasoning, or references to support the claim that the method might perform better in pure combinational logic or that it would be easier to model without staterelated registers. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. While it identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might address this question or what experiments could be conducted to substantiate the claim. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it suggests that the authors should provide this information, it does not explicitly instruct them to include it in the draft or specify how to calculate or present the results. The action is implicit, as the authors need to infer that they should add this information to the experiment section. However, the lack of detailed guidance on how to implement this suggestion makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment section where the authors have designed a baseline combining LDA and LSTM. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it requests the performance of this baseline in terms of the topic switch percent metric, providing a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. However, it does not provide any evidence, reasoning, or references to support why this metric is important or how it should be evaluated. The comment lacks specific details or justification, making it difficult for the authors to understand the basis for the request. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what data might be relevant. The comment lacks actionable advice, such as suggesting alternative metrics or providing examples of how to calculate the topic switch percent. As a result, the feedback is 3, as it highlights a potential area for improvement but does not offer detailed guidance for the authors to enhance their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4, specifically mentioning the BLEU score for WMT17WIKT. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be done to improve their draft, which aligns with the definition of a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be included in the table, namely bold numbers for the baselines of previous work, particularly for WMT17WIKT, where the best BLEU result is in the baselines. This level of detail helps the authors understand exactly what changes are required. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that requests the inclusion of bold numbers for baselines in Table 4, specifically mentioning the BLEU score for WMT17WIKT. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is specific and actionable, providing clear guidance on what needs to be included in Table 4. It requests the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT, where the best BLEU score is in the baselines. This feedback is valuable as it directly addresses a specific aspect of the paper and offers a clear direction for improvement. However, the comment could be more helpful if it suggested alternative ways to present this information or provided additional context. Overall, the comment is 4, as it provides actionable feedback but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for examples of \"unreliable neighbors,\" which implies that the authors should provide specific instances to clarify the concept. However, it does not explicitly instruct the authors to include these examples in their draft or suggest where they should be added. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and understand the context of \"unreliable neighbors.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests examples of \"unreliable neighbors,\" which directly points out what needs clarification or further explanation in that section. This provides clear guidance on what the authors should address to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks for examples of \"unreliable neighbors,\" which is a request for clarification and does not contain a subjective claim or suggestion that requires verification. It is a factual request for information, making it a \"No\" category.", "helpfulness_rationale": "The comment requests examples of \"unreliable neighbors,\" which is a specific and actionable suggestion for the authors to clarify a concept in their paper. By asking for examples, the reviewer provides a clear direction for improving the draft, making it 3. However, the comment could be more helpful if it offered additional guidance on how to define or illustrate these neighbors effectively. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study, as it is crucial for understanding these synergies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to include the TD3GA algorithm and its comparison. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, specifically noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study. However, the comment does not specify which part of the paper discusses the synergies or the comparison to TD3GA, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main paper does not mention the TD3GA algorithm, which is crucial for understanding the synergies between DQD and PPO. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the assertion. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficient backing of the claim about the synergies between DQD and PPO. It points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the study, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to incorporate the TD3GA algorithm or how to structure the comparison. Despite this, the feedback is 4 as it directs the authors to a critical area for revision and improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance. It prompts the authors to explain why this occurs, suggesting that they should provide a detailed explanation of the results. However, the comment does not explicitly instruct the authors to include this explanation in their draft or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Sections 6.1 and 6.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance and asks for an explanation. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance. While it prompts the authors to explain this phenomenon, it does not provide any specific evidence, reasoning, or references to support the claim. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the observation and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a surprising result in the paper, specifically the outperformance of the treesliced Wasserstein distance over the original optimal transport distance, and prompts the authors to explain why this occurs. This feedback is valuable as it highlights a potential area for further clarification or discussion in the paper. However, the comment lacks specific guidance on how the authors might approach explaining this result or what additional analysis might be needed. While it points out an important aspect that requires attention, it does not provide detailed suggestions or actionable steps for improvement. Therefore, the comment is 3, as it identifies a meaningful issue but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be stronger if it reported the numbers observed in a label noise experiment on ImageNet with 1000 classes, particularly focusing on nontail classes. This provides a clear and explicit action for the authors to take, as they can directly incorporate these additional results into their draft. The comment is specific in its suggestion and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on nontail classes. This provides a clear and specific direction for the authors to enhance their analysis. However, the comment does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The suggestion is specific in its request for additional data, which would help stresstest the conjecture. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, particularly focusing on nontail classes. This claim is 3 as it provides a specific suggestion for additional data that could strengthen the paper. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The comment suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on nontail classes. This feedback is 3 as it provides a clear direction for the authors to enhance their analysis and potentially strengthen their conjecture. However, the comment lacks depth and does not offer specific guidance on how to conduct or interpret these additional experiments, which limits its overall impact. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the evaluation section, including the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of incontext examples. It also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the evaluation section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of incontext examples. Additionally, it highlights the limitation of relying solely on one dataset, which may limit the generalizability of the results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of mention of the number of different sets of incontent examples used and the lack of exploration of the effects of varying the number of incontext examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. These claims are supported by logical reasoning and specific examples, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims about the limitations of the evaluation.", "helpfulness_rationale": "The review comment identifies several areas where the evaluation section of the paper could be improved. It highlights the lack of transparency regarding the experiment setup, specifically noting the absence of information about the number of different sets of incontent examples used. Additionally, it points out the lack of exploration of the effects of varying the number of incontext examples, which is a crucial aspect for understanding the robustness of the results. The comment also notes that the evaluation relies solely on one dataset, which may limit the generalizability of the findings. These observations provide clear feedback on areas that need attention to enhance the comprehensiveness and robustness of the evaluation. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as suggesting additional datasets or methods for exploring the impact of varying incontext examples. Overall, the comment is 3 as it identifies important areas for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is explicit and provides a clear action for the authors to take, namely to add these experiments to better showcase the unique advantages or potential shortcomings of the proposed method. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides a clear direction for the authors to improve the paper by including these additional experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests a specific area for improvement, but it does not provide detailed reasoning or examples to support why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the need for such comparisons to fully understand the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where additional comparative experiments are needed to better showcase the advantages or potential shortcomings of the proposed method. By suggesting the inclusion of experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, the comment provides a clear and actionable direction for the authors to improve their draft. This feedback is 4 as it offers a specific and constructive suggestion that could significantly enhance the paper\"s comprehensiveness and impact. However, it could be more helpful if it included more detailed reasoning or examples of how these experiments would be conducted or what specific outcomes they would demonstrate. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. It provides a specific example of how the tables could be reorganized, suggesting that the 8 SFII columns and then the 8 SPDI columns should be grouped separately. This feedback is explicit and concrete, as it clearly indicates the action the authors should take to improve the readability of the tables. The suggestion is specific and provides a clear direction for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, with one table per measure. The example provided, such as separating the 8 SFII columns and then the 8 SPDI columns, further clarifies the intended improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. While the suggestion is logical and could improve readability, it lacks specific examples or references to support why this change would be beneficial. The comment does not provide detailed reasoning or evidence to justify the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and actionable piece of feedback that directly addresses a potential issue with the presentation of the data. By suggesting a reorganization of the tables, the comment offers a concrete way for the authors to enhance the clarity and accessibility of their results. This feedback is 4 as it provides a clear direction for improvement, though it could be further expanded to include additional suggestions or considerations. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "No", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a clear and explicit action that the authors can take to improve their draft. The comment provides a specific request for clarification, which helps the authors understand what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between \"valid\" and \"orig\". This provides the authors with a clear understanding of what revisions are necessary. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a request for clarification and does not contain a subjective opinion or claim that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is helpful as it provides a specific request for clarification regarding the terms \"valid\" and \"orig\" in Figure 5. By asking the authors to specify the difference between these terms, the comment directs them to a specific area where clarification is needed. This feedback is actionable and constructive, as it helps the authors improve the clarity and precision of their presentation. However, the comment could be more helpful if it provided additional guidance on how to clarify the terms or suggested alternative ways to present the information. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, it does not provide explicit guidance on which methods to compare or how to adapt them for language tasks. The action is implicit, as the authors need to infer that they should consider comparing to specific methods and adapt them for language tasks. While the comment is 3, it lacks concrete details on how to implement the suggested comparison, making it 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to methods mentioned in the computer vision setting, which implies a specific part of the paper where these methods are discussed. However, it does not explicitly mention which section or part of the paper this comparison should be made. The comment is specific in its suggestion to compare to certain methods, but it lacks full grounding as the authors cannot confidently determine which part of the paper it addresses. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that comparing to methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand why this comparison would be beneficial. The comment lacks detailed reasoning or evidence, which limits its verifiability. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment suggests that including a comparison to methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. While the comment provides a rationale for why this comparison might be beneficial, it lacks specific examples or detailed guidance on which methods to compare or how to adapt them for language tasks. This feedback is 3 as it offers a direction for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the discussion around equation (10) is terse and not clearly explained. While it suggests that the authors should improve the clarity of this discussion, it does not provide specific guidance on how to achieve this. The action is implicit, as the authors need to infer that they should enhance the explanation of the discussion around equation (10). However, the comment lacks concrete details on what aspects of the discussion need to be clarified or expanded. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out that the discussion around this equation is terse and not wellexplained, providing a clear indication of what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is actionable as it provides a clear area for improvement, suggesting that the authors should enhance the clarity and depth of their discussion. However, the comment lacks specific guidance on how to improve the explanation or what aspects of the discussion need clarification. While it offers a valuable suggestion, it could be more helpful if it provided more detailed guidance or examples of how to improve the explanation. Therefore, the comment is 4, as it directs the authors to an area of improvement but does not fully address the need for actionable feedback."}
