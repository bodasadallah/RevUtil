{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It also implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset quality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It also implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment does not specify which part of the paper discusses the dataset or where the authors should focus their analysis. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of dataset quality, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. The reviewer provides an example of the \"pristine\" set of tweets potentially containing misinformation, which implies that the dataset quality needs more analysis. However, the comment lacks specific examples or references to support the claim about the dataset's potential noise and misinformation. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a basis for concern but lacks thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. The reviewer provides an example of the 'pristine' set of tweets potentially containing misinformation, which highlights a concern about the dataset's reliability. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending additional analysis or methods to ensure dataset quality. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should conduct further analysis to address the concerns raised, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap, such as suggesting additional analysis or experiments. Without concrete guidance on how to improve the paper, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific area of the paper that needs attention: the lack of exploration of the theoretical properties of the proposed algorithm, particularly its convergence. However, it does not specify which part of the paper discusses the algorithm or where the theoretical analysis is lacking. This makes it difficult for the authors to pinpoint the exact section or aspect that requires improvement. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where to address the problem. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of exploration of the theoretical properties of the proposed algorithm, specifically its convergence. This is a crucial aspect that needs to be addressed to strengthen the paper's theoretical foundation. However, the comment does not provide any suggestions or guidance on how the authors might approach this issue, such as suggesting additional analysis or experiments. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a critical weakness but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' choice of operators, specifically the and operator or element-wise max, and suggests that they might have considered the or operator or element-wise min instead. It implies that the authors should consider the union and intersection concepts from the or operator and element-wise min, respectively, and provide a reason for their choice. However, the comment does not explicitly instruct the authors to consider these alternatives or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the suggested operators and provide a rationale. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions sections 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors' choice of operators, suggesting that they might have considered the or operator or element-wise min instead, and provides a rationale for why the chosen operators might be better. This level of detail helps the authors understand what needs to be addressed and why. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' choice of operators, specifically the and operator or element-wise max, and suggests that they might have considered the or operator or element-wise min instead. It implies that the chosen operators might be better options due to their correspondence with the union and intersection concepts from the or operator and element-wise min. However, the comment does not provide any specific reasoning, examples, or references to support why the chosen operators are better or why the alternatives were not considered. This lack of detailed justification makes the claim somewhat verifiable, as the authors are left to infer the reasoning behind the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the choice of operators in the paper, specifically questioning why the authors did not consider the and operator or element-wise max. It suggests that the or operator or element-wise min might have been more appropriate and provides a rationale for this consideration. This feedback is clear and actionable, as it directs the authors to reconsider their operator choices and provide a justification for their selection. However, the comment could be more helpful if it offered specific examples or guidance on how to approach the reconsideration. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the description of HIERENC, suggesting that the current explanation is unclear and that the method of averaging representations from all possible entity instantiations might introduce noise. However, the comment does not provide explicit guidance on how the authors should revise the description or address the issue of noise. While it identifies a problem, it lacks concrete steps or suggestions for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of HIERENC, providing a specific explanation of how the input (h_i) is processed. It highlights a potential issue with the method of averaging representations from all possible entity instantiations, suggesting that this approach might introduce noise. The comment is fully grounded as it explicitly mentions the part of the paper being discussed, and it is specific because it clearly specifies the issue with the description of HIERENC. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that averaging representations from all possible entity instantiations might introduce noise. While the reviewer provides a specific example to illustrate the potential issue, the comment lacks detailed reasoning or references to support the claim that this approach is inherently problematic. The authors may need to infer the reasoning behind the claim, which could be challenging. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the method of averaging representations from all possible entity instantiations might introduce noise. This feedback is clear and actionable, as it provides a specific example of a potential problem in the description. However, it could be more helpful if it suggested alternative approaches or provided guidance on how to address the issue. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this selection affects the underestimation of performances. While it prompts the authors to consider the reason for this selection, it does not provide explicit guidance on how to address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should explain the rationale and discuss the potential impact on performance estimation. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area they need to address. While the comment is specific in its inquiry about the impact on performance estimation, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not provide any specific reasoning, examples, or references to support the claim that this selection might lead to an underestimation of performances. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the rationale behind selecting only 10 answers from all correct answers and whether this selection might affect the underestimation of performances. This is a valid concern that could impact the accuracy and reliability of the results presented in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the methodology. While it identifies an important area for consideration, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or insights for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors may have selected sentences from raw data sources, but it also claims that these sources already contain syntactic information. The comment implies that the data selected is a subset of Li et al. (2019a)\u2019s dataset and suggests that this should be clarified by mentioning Li et al. (2019a) earlier in the paper. While the comment provides a clear action\u2014namely, to revise the description to make it clearer and more precise\u2014it does not specify exactly how this revision should be done. The action is explicit but somewhat vague, as it leaves the authors to infer the specific changes needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (226-238 and 242-244), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the discrepancy in the description of the data selection process and the suggestion to revise the description to mention Li et al. (2019a) earlier. This provides clear guidance on how the authors should address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors may have selected sentences from raw data sources, but it also states that these sources already contain syntactic information. The comment suggests that the data selected is a subset of Li et al. (2019a)\u2019s dataset and recommends revising the description to make it clearer and more precise. However, the comment does not provide specific examples or references to support the claim that the data is a subset of Li et al. (2019a)\u2019s dataset. Without this additional information, the claim remains somewhat verifiable, as the authors may need to infer the basis for the revision. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the description of the data selection process, specifically regarding the use of raw data versus the presence of syntactic information. It suggests that the data selected might be a subset of Li et al. (2019a)\u2019s dataset, which could be clarified by mentioning this earlier in the paper. This feedback is clear and actionable, as it provides a specific area for revision and suggests a way to improve the clarity of the description. However, the comment could be more helpful if it included examples or detailed reasoning to support the claim, making it easier for the authors to understand and address the issue. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the average duration and consider whether it includes user waiting time. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in questioning the purpose and content of the average duration, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. This comment is somewhat verifiable as it identifies a gap in the explanation but lacks specific examples or references to support the claim. The authors would need to infer the need for a clearer explanation and consider whether the average duration includes user waiting time, but the comment does not provide detailed guidance or evidence to fully substantiate the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the presentation of data in Table 1, specifically questioning the purpose of the average duration reported and noting the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the average duration and consider the inclusion of user waiting time. However, the comment could be more helpful if it suggested specific ways to improve the explanation or provided examples of how to present the data more effectively. Overall, the comment is mostly helpful, as it offers clear guidance for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. While it does not explicitly instruct the authors to provide this information, it implies that they should clarify this aspect to improve the transparency and understanding of the results. The action is implicit, as the authors need to infer that they should address the lack of clarity in the table. However, the comment lacks concrete guidance on how to clarify the splits, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: \"what splits are used for obtaining the ATIS numbers.\" This provides a clear and precise indication of the issue that needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the splits used in Table 4, specifically for obtaining the ATIS numbers. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is factual and descriptive, aligning with the classification of \"No Claim.\" Therefore, the comment is labeled as \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on the splits used for obtaining the ATIS numbers in Table 4. While it identifies a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is vague and lacks actionable advice, making it barely helpful. The authors are left without a clear understanding of what information is needed to improve the clarity of the table. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should correct the wording used to describe their performance, noting a potential cognitive bias among NLP researchers. However, it does not provide explicit guidance on how to correct the wording or what specific changes should be made. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (l.791) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a potential issue with the wording used to describe the authors' performance, suggesting that it might be misleading due to a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should correct the wording used to describe their performance, noting a potential cognitive bias among NLP researchers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording used to describe the authors' performance, specifically noting a cognitive bias among NLP researchers that might lead to misinterpretation of \"on par\" and \"better\" results. While the comment highlights a concern that could affect the clarity and accuracy of the presentation, it does not provide specific guidance on how to correct the wording or suggest alternative phrasing. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOS-Q and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOS-V. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these interpretations or what changes might be necessary. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the results in Table 3 are discussed, making it difficult for the authors to identify the relevant section. Additionally, the comment is not specific because it does not provide detailed guidance on how to interpret the results or what actions should be taken. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOS-Q and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOS-V. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOS-Q and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOS-V. However, it does not provide any suggestions or guidance on how the authors might address these interpretations or what changes could be made to improve the clarity or robustness of the results. Without actionable feedback or specific suggestions, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any explicit or implicit suggestions on how to address this issue, such as recommending a consistent formatting approach or providing guidance on why the inconsistency is problematic. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistency in the presentation of data, noting that some items have spaces between accuracy and standard deviation while others do not, which affects the visual appeal and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any specific reasoning, examples, or references to support why this inconsistency is problematic or how it impacts the overall quality of the paper. Without additional context or justification, the authors may find it challenging to understand the significance of the comment and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of data in Table 2 and Table 3, noting inconsistencies in the presentation of accuracy and standard deviation values. While the comment points out a potential issue with the visual appeal and readability of the tables, it does not provide any suggestions or guidance on how to address this problem. The feedback is somewhat helpful as it highlights a minor issue that could impact the presentation of the data, but it lacks actionable advice or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': \"The review point identifies a specific issue with the formatting of references, noting that the antecedent 'both tasks' is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. The comment is explicit in pointing out the missing antecedent and provides concrete guidance on how to address the issue by checking the references for specific formatting details. This allows the authors to directly apply the feedback and improve the formatting of their references. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the section of the paper where the issue is located, specifically 'both tasks'. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be done, such as checking the references for format, capitalization, and bibliographic details. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point identifies a specific issue with the formatting of references, noting that the antecedent 'both tasks' is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. While the comment provides a clear instruction for improvement, it lacks specific examples or references to support the claim that the references are missing or need correction. This makes the claim somewhat verifiable, as the authors can infer the need for correction but may require additional guidance to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the formatting of references, noting that the antecedent 'both tasks' is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the formatting of their references. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it provided additional guidance on how to check the references or examples of correct formatting. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been explored in various NLP and image-text models. It acknowledges that the related work section summarizes these efforts and notes that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide explicit guidance or suggestions on how the authors can address this issue or enhance the novelty of their work. The authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, such as a particular section, table, or figure. It also lacks specificity in detailing what aspects of the paper are lacking novelty or how the authors can address this issue. The comment provides a general overview of the related work but does not offer specific guidance or suggestions for improvement. Therefore, it is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, specifically noting that adversarial attacks on text have been explored in various NLP and image-text models. It mentions that the related work section summarizes these efforts and that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide specific examples or detailed reasoning to support the claim of lack of novelty. It lacks detailed evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, specifically pointing out that adversarial attacks on text have been explored in various NLP and image-text models. It acknowledges that the related work section summarizes these efforts and notes that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide specific suggestions or guidance on how the authors can address this issue or enhance the novelty of their work. While it highlights a concern, it lacks actionable advice, making it somewhat helpful as it provides a starting point for improvement but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the explanations for lexical features and sentence-level features in Section 3.2 are somewhat intertwined and confusing. It provides a clear action for improvement: organizing the section with separate paragraphs for each type of feature. This action is concrete and specific, as it clearly indicates how the authors should restructure the section to enhance clarity. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the organization of the section by suggesting separate paragraphs for lexical and sentence-level features. This level of detail helps the authors understand exactly what needs to be done to enhance the clarity of the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations for features in Section 3.2 are somewhat intertwined and confusing, implying that the section could be more coherently organized. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without detailed reasoning or examples, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of explanations in Section 3.2, noting that the features are somewhat intertwined and confusing. It provides a clear suggestion for improvement by recommending a more coherent organization of the section with separate paragraphs for lexical and sentence-level features. This feedback is actionable and constructive, as it directly addresses a potential weakness in the paper and offers a concrete solution for the authors to consider. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the clarity of the explanations. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the amount of space dedicated to the assumptions section and experimental results, suggesting that it might be excessive. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors need to infer that they should consider reducing the space dedicated to these sections or reorganizing the paper to make it more concise. The comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"assumptions\" section and the \"experimental results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly states the concern that the information is not so useful and that dedicating a whole section plus experimental results is excessive. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a subjective opinion about the usefulness of the information presented in the assumptions section and the experimental results. It suggests that the amount of space dedicated to these sections is excessive. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the excessive space dedicated to the assumptions section and experimental results. While it acknowledges the value of fleshing out the assumptions, it suggests that the amount of space allocated is excessive, which could be a concern for the authors. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing alternative ways to present the information or suggesting a more concise approach. Without actionable advice or detailed feedback, the comment is somewhat helpful, as it highlights a potential area for improvement but does not provide a comprehensive solution. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include an ablation study to demonstrate the importance of the post-processing steps used to filter out \"false-positive\" neurons. While the comment implies that an ablation study is needed, it does not explicitly instruct the authors to conduct one or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that an ablation study is necessary to validate the significance of the post-processing steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of integrated gradients and post-processing steps, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the lack of demonstration of the importance of these post-processing steps and suggests the need for an ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not show how important the post-processing steps are, suggesting that an ablation study may be needed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general suggestion but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should include an ablation study to demonstrate the importance of the post-processing steps used to filter out \"false-positive\" neurons. This feedback is actionable and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it included suggestions on how to conduct the ablation study or what specific metrics to use. Despite this, the comment offers valuable guidance, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide explicit guidance or suggestions on how to address this issue or improve the method. The action is implicit, as the authors would need to infer that they should clarify the method or provide more details on how to handle non-pronoun head words. The comment is vague and lacks concrete details on how to implement the suggested action. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is specific in its critique of the method but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a specific question about how an antecedent can be identified when the prediction is a pronoun, particularly questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun, which is a valid concern for the paper's methodology. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the method. While it identifies a potential area for clarification, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors would need to infer that they should clarify the method or provide more details on how to handle non-pronoun head words, but the comment does not offer concrete steps to improve the draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and points out that the paper does not adequately describe this comparison, instead emphasizing soft vs. hard word sense disambiguation. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, it does not provide explicit instructions on how to implement these suggestions, such as which specific baselines to include or how to compare the models. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the comment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the comparison between the proposed models and models that consider different senses but not sememes, suggesting that the MST baseline might be an example. However, it does not specify which part of the paper this comparison is intended to address, making it weakly grounded. The comment is specific in that it identifies a gap in the comparison and suggests the inclusion of more baselines based on related work, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the comparison between the proposed models and models that consider different senses but not sememes, suggesting that the MST baseline might be an example. It also points out that the paper does not adequately describe this comparison, instead emphasizing soft vs. hard word sense disambiguation. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, it lacks specific examples or references to support the claim that the MST baseline is an example of a model considering different senses but not sememes. The reasoning is somewhat vague, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the comparison between the proposed models and models that consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and points out that the paper does not adequately describe this comparison, instead emphasizing soft vs. hard word sense disambiguation. The comment implies that the inclusion of more baselines based on related work would strengthen the paper. However, the feedback lacks specific guidance on which baselines to include or how to compare them, making it somewhat helpful. The authors would benefit from a clearer understanding of the need for additional baselines, but the comment could be more actionable with detailed suggestions. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" However, it does not explicitly instruct the authors to include this example or provide guidance on how to do so. The action is implicit, as the authors would need to infer that they should add an example to the abstract to address the inconsistency. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests improving the abstract by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" This guidance is clear and actionable, making the comment fully grounded and specific. Therefore, the label is 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract could be improved by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential improvement to the abstract by suggesting that it could be made more effective by providing an example of the inconsistency between \"evaluating with gold answers\" and \"human evaluation.\" This feedback is actionable and provides a clear direction for the authors to enhance the abstract. However, the comment could be more helpful if it included specific examples or guidance on how to illustrate this inconsistency. Despite the lack of detailed examples, the comment offers a valuable suggestion that could significantly improve the abstract's clarity and impact. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific suggestions or actions that the authors can take to clarify or improve their methodology. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the issue is addressed. Additionally, the comment lacks specificity, as it does not provide details on how the selection process is unclear or what needs to be clarified. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any claim or suggestion that requires verification. The comment is purely descriptive and does not offer any reasoning, evidence, or references to support the question. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific guidance or suggestions on how the authors might address this lack of clarity. Without actionable advice or examples, the comment is vague and lacks depth, making it barely helpful. The authors are left without a clear path forward to improve their methodology, which limits the overall impact of the feedback.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some discussions are needed on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of results. However, the comment does not provide explicit guidance on what kind of discussions are needed or how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the convergence process and its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of results. However, the comment does not specify which part of the paper these discussions should be included in, making it weakly grounded. The comment is specific in its suggestion to include discussions on convergence and stable points, but without explicit references to sections or figures, it is difficult for the authors to pinpoint the exact areas where these discussions should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of results. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that these discussions are necessary. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of the need for additional discussion but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that additional discussions on the convergence of the proposed joint learning process, particularly in the context of probabilistic metric space and stable points, would enhance the clarity and understanding of the paper. It highlights a concern that readers may find it challenging to understand how stable points are obtained, which could hinder the repetition of results. However, the comment does not provide specific guidance on what kind of discussions are needed or how to address this issue. While it points out a potential weakness, it lacks detailed suggestions or examples, making it somewhat helpful. The authors would need to infer the need for additional discussions but would not have a clear roadmap for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific instructions for the authors to address certain aspects of their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. It also questions why the term \"latent in verbs\" is not mentioned. These instructions are explicit and provide clear guidance on what needs to be done, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment does not explicitly mention sections, tables, or figures, making it weakly grounded. The instructions are specific in terms of what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with the category of \"Weakly Grounded and Specific.\"', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. These instructions are clear and provide actionable guidance, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully support the suggestions. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides specific and actionable feedback on areas that need improvement in the draft. It instructs the authors to discuss the results for the task of inferring knowledge on objects and to include results for model (B), which are important aspects of the paper. Additionally, it suggests using consistent terminology for the model in Tables 1 and 2, enhancing clarity and readability. The comment also questions why the term 'latent in verbs' is not mentioned, prompting the authors to consider this aspect. By providing clear guidance on what needs to be addressed, the comment is mostly helpful, as it offers constructive feedback that can significantly improve the draft. However, it could be more helpful if it included additional suggestions or examples to further enhance the authors' understanding of the areas for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggesting an alternative phrasing. The comment is explicit in pointing out the error and providing a clear alternative, allowing the authors to directly address the issue. However, it does not provide detailed guidance on how to implement the suggested change or what specific aspects of the sentence need to be revised. While the action is explicit, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a factual error in the description of the GRU model and suggests an alternative phrasing that aligns with the information presented in Figure 2. This provides clear guidance on what needs to be corrected or clarified in the paper.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in line 212 is not strictly correct and suggests an alternative phrasing. While the comment provides a specific example and suggests a correction, it lacks detailed reasoning or references to support the claim. The authors would need to independently verify the correctness of the sentence and the suggested alternative phrasing. Therefore, the claim is somewhat verifiable, as it provides a basis for correction but requires further justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with a sentence in the paper, noting that it is not strictly correct and suggests an alternative phrasing. This feedback is clear and actionable, providing the authors with a specific point of improvement. However, the comment could be more helpful if it offered additional guidance on how to revise the sentence or suggested alternative phrasing that aligns with the information in Figure 2. While it identifies a minor issue, it lacks depth and could be expanded to provide more comprehensive feedback. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add baselines. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its suggestion to include additional baselines, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanations or references to existing literature that could substantiate the assertion about the straightforward nature of the extension or the need for additional baselines. Without such support, the claim remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could benefit from additional baselines, specifically character embeddings. This feedback is somewhat helpful as it points out a specific aspect that could enhance the paper's comprehensiveness and robustness. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why character embeddings are particularly relevant. The authors are left with a general idea but no concrete steps to take, which limits the comment's overall helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the baseline models used in the paper. First, it points out that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. This suggests that the authors should include this comparison to provide a more comprehensive evaluation of their models. Second, the comment notes that the authors do not compare their models to other domain adaptation methods, such as those mentioned in Section 8. This implies that the authors should include these comparisons to strengthen their analysis. The review point also suggests that the authors should clarify the statement on line 277, which is vague and lacks specificity. While the comment identifies two areas for improvement and suggests a need for clarification, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is somewhat vague, as the authors need to infer how to compare their models to the mentioned works and clarify the statement on line 277. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the baseline models used in the paper and refers to specific sections, such as Section 8, which suggests that the authors should compare their models to other domain adaptation methods. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it identifies two key issues: the lack of comparison to Campos et al. (2020) and the absence of comparisons with other domain adaptation methods. Additionally, it suggests clarifying a statement on line 277, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak and suggests comparing the models to Campos et al. (2020) and other domain adaptation methods. However, the comment lacks specific evidence or detailed reasoning to support these claims. It does not provide examples of how the models might be weak or why the suggested comparisons are necessary. Without additional justification or references, the claim remains somewhat verifiable, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two key weaknesses in the paper: the lack of comparison to specific baseline models, particularly Campos et al. (2020), and the absence of comparisons with other domain adaptation methods. It also suggests clarifying a statement on line 277, which is vague and lacks specificity. While the comment provides a clear direction for improvement by highlighting areas where the authors should enhance their analysis, it could be more helpful if it offered specific suggestions or examples of how to conduct these comparisons. The feedback is mostly helpful as it directs the authors to areas that need attention, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 4: Mostly Helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the y-axis label in Figure 5 might use \"Exact Match ratio\" directly. This is a specific and actionable suggestion, as it provides a clear and direct instruction for the authors to consider changing the label. The authors can easily identify where the label is located and apply this change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that the y-axis label in Figure 5 may use \"Exact Match ratio\" directly. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the y-axis label in Figure 5 may use \"Exact Match ratio\" directly. This is a specific and factual observation, as it points out a potential issue with the labeling of the figure. However, it does not provide any reasoning or justification for why this is a problem or how it might affect the interpretation of the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides some basis for consideration but lacks detailed support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the labeling of the y-axis in Figure 5, suggesting that it may use \"Exact Match ratio\" directly. This is a specific and actionable feedback that could help the authors improve the clarity and accuracy of their figure. By addressing this issue, the authors can ensure that their figure is easily understood and interpreted by readers. However, the comment could be more helpful if it provided additional context or suggestions for how to improve the figure beyond just changing the label. Overall, the comment is somewhat helpful as it identifies a specific area for improvement, but it could be more comprehensive and actionable.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the lack of description regarding the societal biases of the knowledge bases used in the paper. It questions whether the knowledge bases are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. The action is implicit and vague, as it does not specify how the authors should conduct the analysis or what data they should use to demonstrate the presence or absence of societal biases. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, it does not specify which part of the paper discusses the knowledge bases or where the issue is addressed. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it pertains to. It is also specific in that it highlights a potential issue with the knowledge bases, but without explicit references to sections or figures, the authors may struggle to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and whether the issue is affected by these restrictions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure the knowledge bases are free from societal biases. While it identifies a potential area for improvement, it does not provide actionable advice or detailed examples, making it somewhat helpful. The comment is incomplete and could be more helpful with additional guidance on how to address the identified issue.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is easier to demonstrate that something does not work in sequence-to-sequence multi-task learning (MTL) with attention, but the value lies in understanding why it fails and how to modify the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to change the attention mechanism. The action is implicit and vague, as it lacks concrete steps or examples for the authors to follow. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that it is easier to demonstrate that something does not work in sequence-to-sequence multi-task learning (MTL) with attention, but the value lies in understanding why it fails and how to modify the attention mechanism to make it work. However, the comment does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the absence of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is easier to demonstrate that something does not work in sequence-to-sequence multi-task learning (MTL) with attention, but the value lies in understanding why it fails and how to modify the attention mechanism to make it work. However, the comment does not provide specific examples, reasoning, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a valuable insight by suggesting that demonstrating why a sequence-to-sequence multi-task learning (MTL) with attention mechanism does not work is easier than finding the reasons for its failure and proposing a solution. This feedback highlights the importance of understanding the limitations of the current approach and how to address them. However, the comment lacks specific guidance on how to identify the reasons for failure or how to modify the attention mechanism to make it work. While it offers a direction for improvement, it does not provide detailed steps or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it offers some insight but could be more comprehensive and actionable.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the lack of strong baselines in Table 3 and specifically mentions the baselines in [1]. It requests the authors to justify their choice of baselines. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific baselines they should include. The action is implicit, as the authors need to infer that they should add more baselines and justify their selection. The comment is somewhat actionable because it identifies a specific area for improvement but lacks concrete details on how to implement it. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to justify the reason for the absence of strong baselines, such as those mentioned in [1]. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of strong baselines in Table 3 and suggests that the authors should justify their choice of baselines by including those mentioned in [1]. However, the comment does not provide any specific reasoning or examples to support why these baselines are important or how they would improve the paper. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting the absence of strong baselines and suggesting that the authors justify their choice of baselines by including those mentioned in [1]. This feedback is clear and actionable, as it directs the authors to address a potential gap in their experimental setup or baseline comparisons. However, the comment could be more helpful if it provided additional guidance on how to select or justify the baselines, or if it suggested specific types of baselines that might be relevant. Overall, the comment is mostly helpful as it highlights a critical area for improvement and encourages the authors to provide a more comprehensive comparison.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the paper's reliance on supplemental space, suggesting that the paper is not truly independent due to references to supplemental figures and model comparisons. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should consider making the paper more self-contained, but it lacks concrete guidance on how to achieve this. As a result, the authors are left without a clear understanding of what steps to take to improve the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental space\" and \"supplemental figures,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper is not truly independent due to references to supplemental figures and model comparisons, particularly noting the issue with S3.1 reference to Sup. Fig. 6 and the model comparison and span vs. sentence investigation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper relies on supplemental space, making it not truly independent, and provides specific references to the supplemental figures (S3.1 and Sup. Fig. 6) and model comparisons. However, the comment lacks detailed reasoning or examples to fully substantiate the claim. While it identifies a potential issue, it does not provide a comprehensive explanation or evidence to support the assertion that the paper is not truly independent due to its reliance on supplemental space. Therefore, the claim is somewhat verifiable, as it is partially supported but lacks sufficient detail to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper's reliance on supplemental space, noting that the paper is not truly independent due to references to supplemental figures and model comparisons. This feedback is clear and actionable, as it highlights a potential problem with the paper's self-containment. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as integrating key information from the supplemental material into the main text or providing a more detailed explanation of the supplemental content. Without specific guidance, the authors may find it challenging to improve their draft based solely on this feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al. It also questions whether the KNs in Figure 3 are in the source language or in English, given that mentions have been translated to English. The comment implies that this clarification is necessary for the authors to improve their draft. However, the action is implicit, as the authors need to infer that they should add this information and clarify the figure. The comment is somewhat actionable because it provides a clear direction for improvement, but it lacks explicit guidance on how to implement these suggestions. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as adding information about word embeddings and clarifying the KNs in Figure 3. This provides clear guidance on what changes are required, making the comment fully grounded and specific. Therefore, the comment aligns with category 5: Fully Grounded and Specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should consider adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al., and that the KNs in Figure 3 should be clarified regarding their language. However, the comment does not provide any specific reasoning or evidence to support these claims. It lacks detailed explanations or references that would help the authors understand why these additions are necessary or beneficial. As a result, the claim is unverifiable, as it lacks sufficient justification or supporting details. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improvement, such as adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al., and clarifying the KNs in Figure 3. It also mentions that the authors will correct the figure in their response, which is a positive indication of their commitment to addressing the feedback. However, the comment could be more helpful if it provided additional guidance on how to implement these suggestions or if it included examples of how the changes might look. Overall, the feedback is somewhat helpful as it offers actionable suggestions but lacks depth and detail, leaving the authors with a clear direction for improvement but not a comprehensive roadmap. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies the main weaknesses of the paper as the experiments, specifically noting that they are only conducted in an extremely low-resource regime and for a sentence classification task, which are not representative of real-world applications. It also suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these weaknesses or improve their experiments. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main weaknesses of the paper, specifically focusing on the experiments. It mentions that the experiments are only conducted in an extremely low-resource regime and for a sentence classification task, which are not representative of real-world applications. It also suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. However, the comment does not specify which part of the paper discusses the experiments or the tasks, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issues with the experiments and suggests potential improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point identifies the main weaknesses of the paper as the experiments, specifically noting that they are only conducted in an extremely low-resource regime and for a sentence classification task, which are not representative of real-world applications. It also suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the issues effectively. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies the main weaknesses of the paper, specifically focusing on the experiments. It points out that the experiments are limited to an extremely low-resource regime and a sentence classification task, which may not be representative of real-world applications. The comment also suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. However, the feedback lacks specific guidance on how the authors could address these weaknesses or improve their experiments. While it provides a clear direction for improvement, the comment could be more helpful if it offered detailed suggestions or examples of how to enhance the experimental setup or tasks. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not provide comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or what changes could be made to their draft. The comment implies that the authors should consider the overlap between concept map extraction and generic summarization, but it lacks concrete steps or actionable advice. Therefore, the comment is not actionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It also discusses the challenges of distinguishing concept maps with increasing node numbers. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of the necessity of a separate task, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It also discusses the challenges of distinguishing concept maps with increasing node numbers. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that concept map extraction is redundant or unnecessary. Without these elements, the claim lacks sufficient justification and is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for questioning the necessity of the task but lacks detailed support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the necessity of treating concept map extraction as a separate task, suggesting that it might be redundant given the capabilities of generic summarization systems. It also discusses the challenges of distinguishing concept maps with increasing node numbers, implying that general summaries might be more readable. However, the comment does not provide specific suggestions or actionable advice on how the authors might address this concern or what changes could be made to their draft. While it identifies a potential area for improvement, it lacks depth and guidance, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more details about the traits of the experts involved in the annotation process and justify why expert annotation is necessary, beyond its commercial value. It also asks for clarification on whether the experts are linguistic or domain experts, and whether the annotation process differs from what non-experts would do. This feedback is explicit and provides clear guidance on what needs to be addressed, making it highly actionable. The authors know exactly what information is required to improve their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions about the traits of the experts, the justification for expert annotation, and the differences between expert and non-expert annotation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the expertise of the annotators and the justification for expert annotation, which are relevant to the paper's methodology. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the feedback. The comment is somewhat verifiable as it offers a logical basis for questioning the methodology but lacks detailed evidence or references to substantiate the claims. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific questions and suggestions for the authors to consider regarding the expertise of the annotators and the justification for expert annotation. It highlights the need for a clearer explanation of why expert annotation is necessary, beyond its commercial value, and asks for clarification on the nature of the experts involved and the differences between expert and non-expert annotation. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing these points. However, the comment could be more helpful if it offered additional guidance on how to address these issues or provided examples of how to justify the use of expert annotation. Overall, the comment is mostly helpful, as it identifies key areas for improvement and encourages the authors to provide more detailed explanations. Therefore, it is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with lines 102-106, stating that the term \"such distribution\" is misleading because it does not align with the discussion in the preceding text. However, the comment does not provide any explicit guidance on how the authors should revise or clarify this section. The action is implicit, as the authors need to infer that they should address the misleading use of the term \"such distribution\" to ensure consistency and accuracy in their discussion. While the action is clear, the lack of concrete instructions on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 102-106, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a misleading use of the term \"such distribution\" in the context of the discussion, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading because the term \"such distribution\" does not align with the preceding discussion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with lines 102-106, noting that the term \"such distribution\" is misleading and does not align with the preceding discussion. This feedback is clear and actionable, as it directs the authors to revisit and clarify this section to ensure consistency and accuracy in their writing. However, the comment could be more helpful if it provided additional guidance on how to revise the text or suggested specific examples of how the term could be used more appropriately. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would benefit from including examples of the system applied to actual texts, as opposed to other components or models. While the comment implies that this would be helpful, it does not explicitly instruct the authors to add such examples or specify how to do so. The action is implicit and somewhat vague, as the authors are left to infer that adding examples would improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of the system on actual texts, which implies that the authors should consider adding such examples to the paper. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. Additionally, the comment is specific in that it suggests adding examples to improve the paper, but the lack of grounding makes it difficult for the authors to understand where to apply the suggestion. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from including examples of the system on actual texts, which implies that the current draft lacks such examples. However, the comment does not provide any specific reasoning or evidence to support why this would be beneficial or how it would improve the paper. Without additional context or justification, the claim is difficult for the authors to fully understand or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from including examples of the system applied to actual texts, which could enhance the understanding and impact of the work. However, the comment lacks specificity, as it does not specify which parts of the paper would benefit from such examples or how these examples should be presented. While it provides a general direction for improvement, the feedback is somewhat vague and could be more helpful if it offered more detailed guidance or suggestions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims need more analysis or provide any guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to delve deeper into the analysis of certain claims. Without explicit instructions or concrete examples, the authors are unable to understand what specific aspects require more detailed analysis. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims or sections of the paper are being referred to, nor does it provide any guidance on how to conduct this analysis. The lack of specific information makes it difficult for the authors to identify the exact parts of the paper that need improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some claims in the paper would benefit from more in-depth analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the comment, making it difficult to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not provide any guidance on which claims need more analysis or how to conduct this analysis. The comment is vague and does not offer actionable feedback, leaving the authors with limited insight into how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues regarding the presentation of the model. It asks for clarification on the pooling method used for embedding features, referencing line 397, and questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC. The comment also suggests that the left-hand side of the equation might be a conditional probability. While the comment identifies two areas for clarification, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the pooling method and the definition of E_i, as well as the nature of the left-hand side of Equation (7). Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (397 and 472) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed: the pooling method used for embedding features and the clarity of Equation (7), including the definition of E_i and the nature of the left-hand side of the equation. This level of detail provides clear guidance on how the authors should improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific questions about the presentation of the model, focusing on the pooling method used for embedding features and the clarity of Equation (7). The first question asks for clarification on the pooling method referenced in line 397, which is a factual request for information. The second question questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC, and suggests that the left-hand side of the equation might be a conditional probability. While the comment provides some context and asks for clarification, it lacks detailed reasoning or references to support the claims. Therefore, the comment is somewhat verifiable, as it provides some basis for understanding but could be more robust with additional justification or examples. The label aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It provides detailed questions and suggestions for clarification, such as asking for the definition of E_i and whether the left-hand side of Equation (7) represents a conditional probability. This feedback is actionable and constructive, as it guides the authors to address specific issues that could enhance the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be expanded for greater depth and impact.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper raises two hypotheses about multilinguality and country/language-specific bias, but it does not mention these hypotheses again in the draft. The reviewer suggests that the paper should study these hypotheses more thoroughly, but the comment does not provide explicit guidance on how to do so. While the action is implied, it is vague and lacks concrete details on how the authors should address the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper by referencing specific lines (078-086) where hypotheses are raised. This provides full grounding as the authors can accurately identify the section being discussed. The comment also specifies that the hypotheses are valuable but not studied, and suggests that the paper should delve deeper into these topics. This level of detail makes the comment specific and actionable, as it provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper raises two hypotheses about multilinguality and country/language-specific bias but does not actually study these hypotheses or mention them again. The reviewer suggests that the paper should delve deeper into these topics. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The reasoning is somewhat vague, and the claim is not fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue in the paper by pointing out that the hypotheses raised in lines 078-086 are not actually studied or discussed again in the draft. This observation is valuable as it highlights a gap in the paper's exploration of the underlying ideas. However, the comment could be more helpful by providing specific suggestions or guidance on how the authors might address these hypotheses more thoroughly. While it identifies a significant area for improvement, the lack of actionable advice limits its overall impact. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether feature engineering could improve the performance of the work, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the feature engineering process should be explored. The action is implicit and somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether feature engineering could improve performance, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results of this work. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. It is specific in suggesting that the authors consider using the same feature set as Uto et al. (2020), but without clear guidance on how to implement this suggestion or what specific aspects of the feature engineering process should be explored. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether feature engineering could improve performance, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results of this work. However, the comment lacks specific details or evidence to support the claim that the current feature set is suboptimal or why it might not be effective. Without additional context or reasoning, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether feature engineering could improve the performance of the work, referencing Uto et al. (2020) as an example. It suggests that using the same feature set from Uto et al. (2020) might improve the results of this work. However, the comment does not provide specific guidance or suggestions on how to implement this idea or what aspects of the feature engineering process should be explored. While it offers a potential direction for improvement, it lacks actionable advice, making it somewhat helpful. The authors are left to infer how to apply the suggestion, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper. It asks whether the CS is used for evaluation purposes and also for augmenting the training material. The comment implies that the authors should clarify how the CS is used and what data split is employed. However, it does not provide explicit instructions or detailed guidance on how to address these questions or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and the specific areas to address. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not specify which part of the paper discusses the CS or where these questions should be addressed. This makes it difficult for the authors to pinpoint the exact sections that need clarification. While the comment is specific about the content of the questions, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not provide any evidence, reasoning, or references to support these questions or claims. The questions are based on the authors' understanding, but without further clarification or justification, they remain speculative. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. While the comment identifies an area that needs clarification, it does not provide specific guidance or suggestions on how to address these questions or improve the draft. The feedback is somewhat helpful as it points out a potential area of confusion, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. While the comment identifies specific issues with the claim, it does not provide explicit guidance on how the authors should address these concerns or what changes to make to their draft. The action is implicit, as the authors need to infer that they should reconsider the representation of substructures and the use of the term \"knowledge'. However, the comment lacks concrete details on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. However, the comment does not specify which part of the paper discusses the model's generalization or the use of \"knowledge,\" making it difficult for the authors to pinpoint the exact areas that need revision. While the comment is specific about the issues with the representation and the use of the term \"knowledge,\" it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides a general critique but lacks detailed reasoning or evidence to fully substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" in the context of the paper, suggesting it might be misleading as it relates to syntax or semantics rather than world or external knowledge. While the comment identifies a potential issue with the representation of substructures and the use of the term \"knowledge,\" it does not provide specific guidance or suggestions on how the authors might address these concerns. The feedback is somewhat helpful as it highlights areas for improvement but lacks detailed actionable advice, leaving the authors with a general sense of what needs to be considered without clear direction on how to proceed. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the performance of nouns compared to clustering approaches, noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific analyses or improvements to address the performance discrepancy or the contradiction. The authors are left without clear guidance on how to address these issues, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the performance of nouns and clustering approaches, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the higher oracle GAP for PPDBClus compared to most clustering approaches and the contradiction with the claim of generalizability to all parts of speech. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment lacks specific examples or references to support the claim that the clustering approach is generalizable to all parts of speech. Without additional evidence or context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. This feedback is somewhat helpful as it identifies a potential issue with the clustering approach's generalizability and highlights an area that needs further investigation. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the performance discrepancy or the contradiction. Without actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion in section 5.2 is abstract and lacks clarity regarding why the new model is better than MH. It suggests providing examples of spurious structures to help the authors understand the insights. However, the comment does not explicitly instruct the authors to provide these examples or clarify the abstract discussion. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to section 5.2 of the paper, providing specific guidance on how to improve the discussion by offering examples of spurious structures. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies what needs to be addressed, namely the abstract nature of the discussion and the need for examples of spurious structures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstract nature of the discussion in section 5.2 and suggests providing examples of spurious structures to clarify the insights. However, it does not offer any specific reasoning, references, or examples to support why the discussion is abstract or how the suggested examples would clarify the insights. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the paper, namely the abstract nature of the discussion in section 5.2, which makes it difficult for the authors to understand why the new model is better than MH. The comment suggests providing examples of spurious structures to clarify the insights, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to include these examples in the discussion. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement and offers a clear direction for addressing it. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F-1. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a baseline smaller PCFG with specific parameterizations, which could help in comparing parsing F-1. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it lacks specific references or context, and it is also not specific about what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F-1. However, it lacks detailed reasoning or examples to support why this comparison is necessary or how it would be beneficial. The comment does not provide specific references or logical reasoning to justify the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F-1. While it provides a potential improvement to the methodology, it lacks detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be highlighted. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not offer comprehensive feedback or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a clear and explicit action that provides specific guidance on what needs to be included in the paper. The authors know exactly what information is missing and how to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"241,\" which allows the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: stating the maximum number of tasks done by any annotator. This provides the authors with a clear understanding of the issue and how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should state the maximum number of tasks done by any annotator. This is a factual suggestion that requires no further verification or reasoning. The comment is clear and specific, providing a clear instruction for the authors to include in their paper. Therefore, it is classified as \"3: Somewhat Verifiable\" as it is clear but lacks some depth in terms of why this information is important or how it impacts the paper.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by asking the authors to include the maximum number of tasks done by any annotator. This is a clear and actionable piece of feedback that directly addresses a potential omission in the paper. By providing this information, the authors can enhance the transparency and completeness of their work, making it more informative and useful for readers. The comment is specific and actionable, making it highly helpful for the authors to improve their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions how the experiments relate to the underlying research question and the specific hypothesis tested. However, the comment does not provide any explicit or implicit suggestions on how the authors might improve the clarity or organization of the paper to address this issue. Without specific guidance on what aspects need clarification or how to present the results more effectively, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions how the experiments relate to the underlying research question and the specific hypothesis tested. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the clarity of the results, it is not grounded because it does not provide explicit references to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the clarity of the empirical results and analyses presented in the paper, questioning how they relate to the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, noting that while it contains many empirical results and analyses, it lacks clarity in explaining how these results relate to the underlying research question and the specific hypothesis being tested. The comment highlights a gap in the paper's ability to present a coherent and comprehensive picture of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or organization of the paper to address this issue. Without actionable advice or examples of how to present the results more effectively, the authors may find it challenging to improve their draft based on this feedback alone. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity in its suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a clear and explicit action that the authors can readily follow. The comment provides a specific and concrete instruction on what needs to be done to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. However, it does not specify which part of the paper Table 1 is located in, nor does it provide any guidance on how to implement this suggestion. The authors would need to infer that the comment is related to the results section, but the lack of explicit mention or detailed guidance makes the comment weakly grounded. Additionally, the comment is specific in its suggestion to include a baseline, but the absence of grounding makes it difficult for the authors to understand the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a suggestion for improvement, but it lacks specific reasoning or examples to support why this addition would be beneficial. Without detailed justification or references, the claim is somewhat verifiable, as it provides a direction for improvement but does not fully substantiate the need for the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a specific and actionable suggestion that could enhance the clarity and comprehensiveness of the results section. By providing a concrete example of what additional information would be beneficial, the comment offers valuable guidance for the authors to improve their draft. However, it could be more helpful if it included a brief explanation of why this baseline is important or how it would impact the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors towards a specific improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of numerical results in the paper, specifically questioning how the proposed method can be applied to popular algorithms and how its performance compares to existing DP algorithms. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include numerical results and conduct comparisons with existing algorithms. However, the action is implicit and somewhat vague, as it does not specify which algorithms to use or how to perform the comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of numerical results and questions the application of the proposed method to popular algorithms, specifically comparing its performance with existing DP algorithms. However, it does not specify which algorithms are being referred to or provide any details about the numerical results. The authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a section or figure. The comment is specific in its request for numerical results and comparisons, but the lack of grounding makes it difficult for the authors to understand the exact area that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the lack of numerical results and the need to apply the proposed method to popular algorithms for comparison with existing DP algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered verifiable. Therefore, it is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and the absence of comparisons with existing DP algorithms. This feedback is valuable as it highlights a critical area where the authors can strengthen their work by providing empirical evidence and demonstrating the practical applicability of their method. However, the comment could be more helpful if it suggested specific algorithms or methods for comparison or provided guidance on how to conduct these comparisons. Overall, the comment is somewhat helpful as it directs the authors to an important aspect of their work that needs further development, but it lacks detailed suggestions for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). While the comment implies that the authors should conduct these additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental comparisons are not enough and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, it does not specify which part of the paper these comparisons are made or which sections of the paper need to be revised. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the need for additional experiments, it does not provide specific guidance on how to conduct these experiments or what results to expect. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental comparisons are not enough and suggests testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, the comment lacks specific reasoning or examples to support this claim. It does not provide a clear rationale for why these additional comparisons are necessary or how they would enhance the paper's contribution. Without detailed justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the experimental comparisons by suggesting that the proposed method, InvP, could be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback is somewhat helpful as it provides a specific direction for improving the experimental setup and potentially enhancing the paper's contribution. However, the comment lacks depth and does not offer detailed guidance on how to conduct these additional experiments or what results to expect. While it points out an area for improvement, it does not fully address the authors' needs for a comprehensive evaluation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection in the paper is not drawn formally enough to be considered more than motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. The comment provides explicit guidance on what needs to be done, namely, to formalize the connection or clarify the language. This level of detail makes the action clear and actionable for the authors, allowing them to understand exactly how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the probabilistic connection in the paper is not drawn formally enough, implying that it is considered motivational rather than substantiated. However, the comment does not specify which part of the paper discusses the probabilistic connection, making it weakly grounded. It is specific in pointing out the issue with the formal drawing of the connection, but without explicit references to sections or figures, the authors may need to infer the exact part being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection is not drawn formally enough, making it appear motivational rather than substantiated. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the probabilistic connection in the paper, noting that it is not drawn formally enough to be considered more than motivational. The comment suggests that the authors either formalize this connection or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included additional suggestions or examples of how to formalize the connection. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is explicit and provides a clear action for the authors to take, which is to include empirical evidence to substantiate the claim. The comment is specific in its suggestion and offers a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not specify which part of the paper discusses the third contribution or the Column Subset Selection problem, making it weakly grounded. It is specific in suggesting the need for empirical evidence, but without clear references, the authors may find it challenging to identify the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it difficult to understand and address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include specific evidence to substantiate their claims. By providing empirical evidence, the authors can strengthen the credibility and impact of their work. However, the comment could be more helpful if it offered guidance on how to conduct or present the empirical evidence effectively. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their training scheme. The action is implicit and vague, leaving the authors without a clear path to follow. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. However, it does not specify which part of the paper discusses the robust training scheme or the datasets used. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue with the scalability of the training scheme, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in high-dimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. This feedback highlights a potential limitation of the proposed method and provides a specific area for the authors to consider. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or improve the scalability of their training scheme. While it identifies a significant concern, the feedback could be more helpful if it offered actionable advice or potential solutions. Therefore, the comment is somewhat helpful, as it provides a clear point of concern but lacks depth and actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. While it prompts the authors to consider these aspects, it does not provide explicit guidance on how to address these questions or what specific actions the authors should take to improve their draft. The comment is somewhat vague, as it leaves the authors to infer the need for more detailed analysis or discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. It is also not specific because it does not detail what needs to be addressed or how the authors should approach the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support why a 4-year period might be insufficient or what kind of style shifts are relevant. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of a 4-year period for studying style shifts and questions the types of style shifts that might occur within this timeframe. It prompts the authors to consider whether the chosen period is adequate for capturing the nuances of style shifts. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional data or analysis could be included to strengthen their study. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit instructions for correcting the placement of a callout in Table 5 to Table 3 and for improving the clarity of the callout in Figure 6. These actions are concrete and specific, allowing the authors to directly apply the corrections. The comment is clear and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 5\" and \"table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout in Figure 6, indicating that the authors need to ensure the callout is directing properly. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations about the placement of callouts in the paper. It specifies that the callout to Table 5 should be in Table 3 and that the callout for Figure 6 is not directing properly. While the comment is accurate, it does not provide any reasoning or justification for why these corrections are necessary or how they impact the paper. However, the lack of additional context or explanation makes it somewhat verifiable, as the authors can infer the need for these corrections based on the provided information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the placement of callouts in the paper, noting that the callout for Table 5 should be in Table 3 and that the callout for Figure 6 is not directing properly. This feedback is clear and actionable, as it directly points out the need for correction. By addressing these specific issues, the comment helps the authors improve the clarity and accuracy of their paper. However, the comment could be more helpful if it suggested alternative placements or provided guidance on how to ensure proper directing of callouts. Overall, the comment is mostly helpful, as it offers clear and actionable feedback that the authors can easily address.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the experiments in the paper, specifically noting that the paper only reports self-comparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to address the lack of explanation for the self-comparisons or to include comparisons with SketchRNN. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments section of the paper, specifically mentioning the issue of only reporting self-comparisons and the lack of explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. However, the comment does not specify which part of the experiments section this issue is discussed, making it weakly grounded. The comment is specific in identifying the problem with the experiments and suggesting an improvement, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only reports self-comparisons and lacks explanation for this choice, which adds to the poor motivation problem. It suggests that comparisons with SketchRNN could be performed. However, the comment does not provide specific examples or references to support the claim about the lack of explanation or the suggestion to include comparisons with SketchRNN. This makes the claim somewhat verifiable, as it lacks detailed reasoning or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the experiments section of the paper, specifically noting that the paper only reports self-comparisons and lacks explanation for this choice. This observation highlights a potential weakness in the motivation and depth of the experimental analysis. The comment also suggests that comparisons with SketchRNN could be performed, which could enhance the comprehensiveness of the experiments. While the comment points out a specific issue and provides a suggestion for improvement, it does not offer detailed guidance on how to address the lack of explanation or how to incorporate comparisons with SketchRNN. The feedback is somewhat helpful as it directs the authors to a potential area for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more analysis and comments are needed regarding the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It disagrees with the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The comment provides specific observations about the performance of DeiT models on different datasets, noting that DeiT-B does not outperform DeiT-T and DeiT-S in APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment does not explicitly instruct the authors on how to conduct this additional analysis or what specific aspects to focus on. While the authors can infer that they need to provide more analysis, the lack of explicit guidance on the methodology or specific areas to explore makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed observations about the performance trends of DeiT models compared to CNNs, highlighting discrepancies in their performance across different datasets. The authors are informed about what specific aspects need further analysis, making the comment both fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' viewpoint regarding the performance trends of increasing model capacity for ViT (DeiT) is incorrect. It provides specific observations about the performance of DeiT models on different datasets, noting that DeiT-B does not outperform DeiT-T and DeiT-S in APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to independently verify the claims by examining the data presented in Figure 3 and comparing the performance of different models. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the performance trends of increasing model capacity for ViT (DeiT) in Figure 3, offering specific observations and comparisons with CNNs. It challenges the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, noting that DeiT models do not consistently outperform CNNs across all datasets. This feedback is valuable as it highlights a potential area for further analysis and suggests that the authors should consider the nuances in performance trends. However, the comment could be more helpful if it provided guidance on how to conduct this additional analysis or what specific aspects of the performance trends should be explored. Overall, the comment is mostly helpful, as it identifies a significant aspect of the paper that requires further attention and provides a basis for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not provide explicit guidance on what needs to be addressed in those areas or how the authors should improve the clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the confusing parts mentioned in point 3. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not specify which part of the paper these areas of confusion are located in, making it difficult for the authors to pinpoint the exact issues. The comment is weakly grounded because it does not provide clear guidance on which sections need revision. It is also specific in that it mentions the potential confusion in \"point 3,\" but without further elaboration, the authors may struggle to understand the exact nature of the confusion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion, specifically referring to \"point 3.\" However, it does not provide any specific examples or detailed reasoning to support the claim that these areas are indeed confusing. Without concrete examples or references, the authors may find it challenging to understand the nature of the confusion and how to address it. Therefore, the comment is barely verifiable, as it lacks sufficient evidence to support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not provide any detailed feedback or suggestions on how to address these areas of confusion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what needs to be improved. As a result, the feedback is barely helpful, as it does not offer any meaningful insights or suggestions for improvement. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it contradicts itself by stating that this is false and providing references. While the comment suggests that the authors should acknowledge the existence of such tools, it does not explicitly instruct them to add or discuss these tools in their paper. The action is implicit, as the authors can infer that they need to address the lack of tools, but the lack of concrete guidance on how to do so makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it claims that there is no corresponding set of tools for this setting, which is a clear and actionable suggestion for the authors to consider. The comment provides a specific point of reference and guidance, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it contradicts itself by stating that this is false and providing references. While the comment acknowledges the existence of such tools by referencing them, it does not provide specific examples or detailed reasoning to support the claim. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors can infer the need to address the issue but may require additional information to fully understand the implications. Therefore, this comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the absence of corresponding tools for the reinforcement learning setting. It acknowledges that the claim is false and provides references to support this assertion. While the comment does not offer specific suggestions for improvement, it highlights a gap in the paper that the authors should address. By pointing out this issue, the comment provides a clear direction for the authors to enhance their work. However, the feedback could be more helpful if it included suggestions on how to incorporate or discuss these tools. Overall, the comment is somewhat helpful as it identifies a specific area for improvement, but it lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency to understand. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the results need clarification. The comment implies that the authors should consider making the results more accessible to a broader audience, but it lacks concrete suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results being based on \"standard\" techniques, which allows the authors to identify the specific part of the paper being addressed. It also specifies what the issue is: the results are not obvious a priori and require a degree of technical competency to understand. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results, while based on \"standard\" techniques, are not obvious a priori and require a fair degree of technical competency to understand. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results, noting that they are based on \"standard\" techniques but are not immediately obvious or accessible to a broader audience. This suggests that the results may require a certain level of technical competency to understand, which could limit their impact or comprehensibility. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or make the results more accessible. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that don\\'t. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion in their draft. The comment is specific in its recommendation, detailing what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates the frozen model and those that don\\'t, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that do not. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this distinction is important or how it would improve the paper. Without additional context or justification, the claim is somewhat verifiable, as it is based on a logical suggestion but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors make a distinction between hard prompt work updates the frozen model and those that do not. This feedback is actionable and directly addresses a potential area for clarification or enhancement in the paper. However, the comment could be more helpful if it provided additional context or examples to support the suggestion, or if it explored the implications of this distinction in more detail. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the conclusion that the direct model is clearly the better of the two, given the significant difference in the amount of data used for training the text disambiguation model and the end-to-end system. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might address the issue or what steps they should consider to strengthen their conclusions. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly the better of the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the data difference and its impact on the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the conclusion regarding the performance of the direct model compared to the end-to-end system, given the difference in the amount of data used for training. However, it does not provide any specific evidence, reasoning, or references to support the claim that the conclusion is questionable. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the conclusion regarding the performance of the direct model compared to the end-to-end system. It highlights the significant difference in the amount of data used for training the two models, which questions the claim that the direct model is clearly the better of the two. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their conclusions. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to address the concern, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, specifically regarding the recovery of updated parameters from projected gradients. While the comment identifies these areas, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide a clearer motivation for GaRare and a more detailed explanation of the algorithmic process. This lack of explicit action makes the comment somewhat actionable, as it provides a general direction but lacks specific details on how to implement the changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. However, it does not specify which part of the paper discusses GaRare or the algorithmic process, making it weakly grounded. The comment is specific in detailing the issues that need to be addressed, such as the motivation for GaRare and the need for a more detailed algorithmic presentation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clear motivation for GaRare and does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes the claim somewhat verifiable, as the authors would need to provide additional information to address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is somewhat helpful as it points out areas that require attention, but it lacks depth and actionable advice, leaving the authors with a general idea of what needs to be improved rather than detailed steps to follow. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. While the comment provides a clear action\u2014conducting an ablation study\u2014it does not specify how to implement this action or what data to use for the study. The suggestion is somewhat vague, as it lacks detailed guidance on the methodology or expected results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment does not specify which part of the paper discusses the visDial dataset or the proposed model, making it difficult for the authors to identify the exact section or figure being referenced. While the comment is specific about the experiment of interest, the lack of grounding makes it challenging for the authors to understand the context and relevance of the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory, referencing ATT(+H) in Figure 4 left. However, the comment lacks detailed reasoning or examples to support the claim that this ablation study would provide additional validation. It does not provide specific references or logical reasoning to justify why this experiment is necessary or how it would enhance the paper. As a result, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It highlights a particular experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. This feedback is actionable and constructive, as it directs the authors to a specific area for further investigation and provides a clear goal for their work. However, the comment could be more helpful if it included more detailed guidance on how to conduct the ablation study or what specific metrics to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any explicit or implicit suggestions on how the authors should address this gap or incorporate these works into their draft. Without specific guidance on what needs to be done, the authors are left without a clear action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields\" and \"Continuous Conditional Neural Fields,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a missing link to similar work that has a similar structure to the CRF and ability to perform exact inference, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this claim is important or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the related work section by pointing out the absence of references to similar works on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and ability to perform exact inference, which is relevant to the paper's topic. However, the comment does not provide any suggestions or guidance on how the authors might address this gap or incorporate these works into their draft. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides a clear indication of a missing element but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should try to explain why the Wavelet Packet Analysis (WPA) works, particularly with np.ones input, and what the model predicts in this case. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is crucial for future research directions. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it lacks concrete guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should try to explain why WPA works, particularly with np.ones input, and what the model predicts in this case. It also questions whether any input could serve as a \"white paper\" and notes that Figure 2 suggests Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is crucial for future research directions. However, the comment does not specify which part of the paper this analysis should be conducted on, making it weakly grounded. It is specific in suggesting the need for a deeper explanation of WPA's functionality, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the functionality of WPA, specifically with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well as WPA. The comment implies that the authors should provide more insights into how WPA works, which is important for future research directions. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors should explore this aspect. It does not provide a clear rationale for why this is a significant issue or how it impacts the paper's conclusions. As a result, the claim is somewhat verifiable, as it is based on logical reasoning but lacks sufficient evidence or references to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by questioning the functionality of WPA, particularly with np.ones input, and suggests that Figure 2 indicates Gaussian noise input does not work as well as WPA. It highlights that the authors spend considerable time demonstrating WPA's improvement in test performance but fail to provide insights into how WPA works, which is crucial for future research directions. This feedback is valuable as it prompts the authors to delve deeper into the mechanisms of WPA and its implications. However, the comment could be more helpful if it provided specific suggestions or guidance on how to explore this aspect, such as suggesting additional experiments or analyses that could shed light on WPA's functionality. Overall, the comment is somewhat helpful, as it points out an important area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" While it suggests that the authors should provide more clarification, it does not explicitly instruct them to do so or offer specific guidance on how to clarify the similarity. The action is implicit, as the authors need to infer that they should clarify the relationship between their method and the cited work. However, the comment lacks concrete details on what aspects of the method need clarification, making it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the similarity between the method part and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in questioning the similarity, but without clear references to the method part or the related work, the authors may find it challenging to pinpoint the exact areas that need clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This is a subjective claim, as it expresses an opinion about the similarity between the method and the cited work. However, the comment lacks specific evidence or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without further explanation or examples, the claim is not verifiable. Therefore, this comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the similarity between the method part of the paper and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This raises a valid point that the authors should address to ensure the novelty and distinctiveness of their work. However, the comment lacks specific guidance or suggestions on how the authors might clarify or differentiate their method from the cited work. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for addressing the concern. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. Second, it suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific comparisons or exploring the potential of the technique. The feedback lacks concrete guidance on how to address the concerns or implement the suggestions, leaving the authors without clear directions for improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of a proposal generator pretrained on MSCOCO, questioning the fairness of comparisons with other methods. It also suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not specify which part of the paper discusses the comparison with other methods or the potential for promoting existing methods. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the concerns raised, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns: the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, and the potential of the proposed technique to promote existing class incremental semantic segmentation methods. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the claims are difficult to verify, making the comment borderline verifiable. The authors would need to provide more context or evidence to fully understand and address the concerns raised in the comment.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. Second, it suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. While the comment identifies a potential issue with the comparison, it does not provide specific guidance or suggestions on how to address this concern or explore the potential of the technique. The feedback lacks depth and actionable advice, making it somewhat helpful as it highlights areas for improvement but does not fully support the authors in enhancing their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by pointing out that while two important parameters/thresholds are mentioned in the end of Section 2, the experimental section (Section 3) does not discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is explicit and provides a clear action for the authors to take, which is to address this gap by including a discussion of parameter settings and their impact on performance in the experimental section. The comment is specific and concrete, as it directly instructs the authors on what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the end of Section 2 and the experimental section (Sec. 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of discussion on how the two important parameters/thresholds are set and how sensitive the performance is with respect to these parameters. This provides a clear direction for the authors to improve their draft. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a gap in the paper by pointing out that while two important parameters/thresholds are mentioned in the end of Section 2, the experimental section (Section 3) does not discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is clear and provides a logical reasoning for why the experimental section lacks this information, making the claim somewhat verifiable. However, it could be more robust with additional examples or references to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out that while two important parameters/thresholds are mentioned in the end of Section 2, the experimental section (Section 3) does not discuss how these parameters are set or how sensitive the performance is with respect to them. This feedback is clear and actionable, as it provides a direct suggestion for the authors to address this gap by including a discussion of parameter settings and their impact on performance in the experimental section. By doing so, the authors can improve the completeness and clarity of their paper, making it more informative and useful for readers. Therefore, the comment is highly helpful, as it offers a clear and constructive direction for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 is written in a very concise manner, which might be due to space limitations. It implies that the section could have been written more slowly to improve readability. However, the comment does not provide explicit guidance on how to achieve this, such as suggesting specific ways to expand the section or what content could be added to enhance readability. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the section for better clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section is written in a very concise manner and suggests that it could have been written more slowly for easier readability. This provides clear guidance on what needs to be improved in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is written in a very concise manner, which might be due to space limitations. It suggests that the section could have been written more slowly for easier readability. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing style of Section 4, noting that it is written in a very concise manner, which could hinder readability. While the comment suggests that the section could have been written more slowly for easier comprehension, it lacks detailed guidance or suggestions on how to achieve this. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps or specific advice on how to enhance the readability of the section. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the approach. The comment lacks concrete guidance on what specific aspects of the model or task need to be revised or enhanced. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors cannot confidently determine which aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details or suggestions on how to address this potential weakness, making it under-specific. Therefore, this comment is weakly grounded and under-specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might impact the data efficiency and training difficulty of the models. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how to address this concern or improve the approach. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete guidance on what needs to be done, making the comment highly actionable. The authors know exactly how to address the issue by adding a table and providing an explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to address the distribution of video lengths across the dataset, which is a specific part of the paper. It also specifies what needs to be addressed, including the inclusion of a table showing the distribution and an explanation of how balanced representation was ensured. This provides clear guidance for the authors to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide relevant explanations regarding the distribution of video lengths within the benchmark, which is crucial for assessing reasoning ability and robustness. The comment suggests that the authors should include a table showing this distribution and explain how they ensured a balanced representation across the 11 categories. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. While it provides a general direction for improvement, it does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it identifies a potential issue but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding the distribution of video lengths across the benchmark. It highlights the importance of this distribution for assessing reasoning ability and robustness, suggesting that the authors should include a table showing the distribution and explain how they ensured a balanced representation across the 11 categories. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the clarity and completeness of their work. However, the comment could be more helpful if it included specific examples or suggestions for how to ensure balanced representation. Overall, the comment is mostly helpful as it offers valuable guidance for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the implementation of the bilinear layer, asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the comment provides specific questions that the authors should address, it does not offer explicit guidance on how to clarify these points or what specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address the questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs clarification, such as the differences between the bilinear layer and other approaches, the dimensionality of embeddings, and the swapping of the bilinear layer with Hadamard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still applied. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the implementation of the bilinear layer, specifically asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the questions are logical and require the authors to provide detailed explanations, the comment lacks specific examples or references to support the claims. The authors would need to infer the basis for these questions, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several questions about the implementation of the bilinear layer, specifically asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the comment identifies areas where the authors could provide more detail, it lacks specific guidance on how to address these questions or what additional information would be beneficial. The feedback is somewhat helpful as it points out areas for clarification but does not offer detailed suggestions or actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should take a cautious approach regarding the contribution until the promised dataset is made publicly available. However, it does not provide any specific guidance or actions on how the authors should proceed with this cautious approach. The comment lacks explicit instructions or concrete steps that the authors can take to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the promised dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of public availability of the dataset and the need for a cautious approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the promised dataset has not yet been made publicly available, suggesting a cautious approach should be taken. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the availability of a promised dataset, which is essential for the contribution of the paper. By noting that the dataset is not yet publicly available, the reviewer suggests a cautious approach, which is a valuable piece of feedback for the authors. However, the comment lacks specific guidance on how the authors should proceed with this cautious approach or what steps they should take to address the issue. While it highlights an important concern, the feedback could be more helpful if it provided actionable suggestions or guidance on how to manage the situation until the dataset is available. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It suggests that the paper should discuss the differences between the proposed method and these existing modules. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the method need to be clarified. The action is implicit, as the authors would need to infer that they should discuss the similarities and differences with the mentioned works. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the similarity issue and suggesting that the paper should discuss the differences between the proposed method and these existing modules. However, it lacks detailed guidance on how to address this issue or what specific aspects of the method need to be clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. The comment provides specific references to previous works [1, 2, 3] and ResNeSt [4], suggesting that the paper should discuss these similarities. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which could be improved with more explicit justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It provides specific references to previous works, which could help the authors understand the context and differentiate their approach. However, the comment could be more helpful if it offered suggestions on how to address the similarity or how to highlight the unique aspects of the proposed method. While it points out a critical area for improvement, it lacks detailed guidance on how to enhance the paper's contribution. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider directly illustrating the results of the latter loss term. While the comment is somewhat specific in identifying the issue with the use of cosine similarity, it lacks concrete suggestions on how to improve the presentation or results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, suggesting an alternative approach. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, the comment does not provide any specific reasoning, examples, or references to support why cosine similarity is being used or why it might be inappropriate in this context. Without additional justification or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the use of cosine similarity to illustrate the results of the latter loss term of Eqn 13. It questions the rationale behind this approach, noting that the preactivation values of two networks are the same membrane potentials, which might lead to a high cosine similarity. The comment suggests an alternative approach, which could be valuable for the authors to consider. However, the comment lacks detailed guidance on how the authors might address this issue or what specific changes they should make to their draft. While it identifies a potential area for improvement, it does not provide a comprehensive or actionable response, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It suggests that these methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of robustness in video action recognition and highlights the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It suggests that these TTA methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with test-time adaptation (TTA) methods, such as [A-B], which are relevant to the topic of robustness in video action recognition. The comment suggests that these TTA methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not provide specific examples or detailed reasoning to support the claim that such a comparison is necessary or beneficial. While the reasoning is somewhat logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting the absence of a comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It highlights that these TTA methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and suggests that the paper should compare data processing with model parameter adjustment. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the comparison should be addressed. While it points out an important area for improvement, the lack of detailed suggestions or examples makes it somewhat helpful. The authors would need to infer the necessary steps to address this feedback, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. This direct feedback allows the authors to identify the specific issue and correct the expression in their draft. The action is explicit and concrete, as it clearly specifies which part of the paper needs revision and what the correct expression should be. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the first expression for J(\u03b8) is incorrect and provides the correct expression, making the comment fully grounded and specific. This level of detail enables the authors to understand exactly what needs to be corrected and how to do it. Therefore, the comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. However, it does not offer any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the expression is incorrect or how to correct it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in Section 3.2.1, pointing out that the first expression for J(\u03b8) is incorrect and providing the correct expression. This feedback is clear and actionable, allowing the authors to directly address the issue and improve the accuracy of their paper. By correcting the expression, the authors can enhance the precision and reliability of their results. The comment is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific examples of capitalization issues in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also mentions specific publications, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020, along with a reference to p. 13, supplement, Fig. This explicit instruction to capitalize specific words in the references provides clear guidance on what needs to be addressed, making the comment highly actionable. The authors know exactly which parts of the references require correction and how to implement the suggested changes. Therefore, this comment is rated as 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections and references, such as \"p.8\" and \"p. 13, supplement, Fig.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed examples of capitalization issues in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. Additionally, it lists specific publications and their venues, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020. This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment is rated as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific examples of capitalization issues in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also mentions specific publications and their venues, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020. These examples provide clear evidence of the issues that need to be addressed, making the claim fully verifiable. The comment is logical and precise, offering specific references and examples to support the claim. Therefore, it is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the capitalization issues in the references. By pointing out specific examples such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers, the comment guides the authors to correct these inconsistencies. Additionally, it lists specific publications and their venues, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020, providing clear examples of where capitalization needs to be addressed. This detailed feedback is comprehensive and actionable, allowing the authors to effectively improve their draft. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the completeness of the paper, specifically regarding the inclusion of parameter values and the rationale behind their selection. It explicitly asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, as the authors are left to infer how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the completeness of the paper, specifically regarding the inclusion of parameter values and the rationale behind their selection. It asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. While the questions are specific about the parameters, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the completeness of the paper, specifically regarding the inclusion of parameter values and the rationale behind their selection. It asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not provide any specific reasoning, examples, or references to support the claim that these parameters are missing or that the selection process needs clarification. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises specific questions about the completeness of the paper, particularly regarding the inclusion of parameter values and the rationale behind their selection. It asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not provide any guidance or suggestions on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it lacks actionable advice, making it barely helpful. The authors are left to infer what steps they should take, which limits the comment's usefulness.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the authors' claim of achieving state-of-the-art results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to substantiate their claim. The feedback is somewhat vague and lacks concrete details, leaving the authors uncertain about how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"state-of-the-art results\" and \"challenging scene text recognition tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the authors' claim, suggesting that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' claim of achieving state-of-the-art results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the assertion that the performance is primarily due to the first step. Without this additional information, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks. It suggests that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or substantiate their claim. While it raises a valid concern, the feedback lacks actionable advice, making it somewhat helpful. The authors would need to conduct additional experiments or provide more detailed analysis to address the concern effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for this observation. While the comment prompts the authors to address this issue, it does not explicitly instruct them on how to do so, such as suggesting specific actions or analyses to conduct. The action is implicit, as the authors need to infer that they should provide an explanation or analysis to address the performance difference. However, the comment lacks concrete guidance on what specific aspects to focus on or how to approach the explanation, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for an explanation of why applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4 deteriorates performance for the GuessWhat?! model compared to applying it to layers 4 and 3 only. This provides a clear and specific request for clarification, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for this observation. While the comment prompts the authors to address this issue, it does not provide any specific evidence, reasoning, or references to support the claim that applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. The lack of supporting evidence or logical reasoning makes the claim somewhat verifiable, as the authors would need to conduct further analysis or experimentation to understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It points out that applying CBN to layer 2 in addition to layers 3 and 4 results in a performance deterioration compared to applying it to layers 4 and 3 only. This observation is intriguing and prompts the authors to provide an explanation for this phenomenon. However, the comment lacks detailed guidance or suggestions on how the authors might approach this analysis or what specific aspects to investigate. While it identifies a potential area for improvement, it does not offer concrete steps or insights that would significantly enhance the authors' understanding or the quality of their work. Therefore, the comment is somewhat helpful, as it highlights a specific issue but does not provide comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the lack of comparison to a highly relevant method that utilizes both inter-task and intra-task ensembles. It explicitly mentions that the authors did not include a method comparison or performance comparison with this relevant method. This provides a clear and explicit action for the authors to take, which is to include a comparison with the mentioned method. The comment is specific in its suggestion, detailing what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, providing specific details about the method and its components (inter-task ensemble and intra-task ensemble). It also specifies the need for a comparison or performance comparison, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not include a comparison with a highly relevant method that utilizes both inter-task and intra-task ensembles. However, the comment lacks specific details or references to support this claim. It does not provide examples of how the comparison could be made or why it is necessary. Without this additional information, the claim remains somewhat verifiable, as it lacks the depth and specificity needed to fully substantiate the authors' assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method that utilizes both inter-task and intra-task ensembles. It provides specific details about the method, including its components, which helps the authors understand the importance of including this comparison. By highlighting the absence of such a comparison, the comment offers a clear and actionable suggestion for improvement, guiding the authors to enhance the comprehensiveness and depth of their work. This feedback is mostly helpful as it directs the authors towards a specific area for improvement, but it could be more comprehensive if it suggested additional areas for consideration or provided more detailed guidance on how to conduct the comparison. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific details or suggestions on what changes might be necessary to clarify the concept. Without actionable steps or concrete advice, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the issue of confusion regarding the implicit call to the Witness oracle. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the call is confusing or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the implicit call to the Witness oracle, which could be confusing for readers. However, the comment lacks specific details or suggestions on how the authors might address this confusion. Without actionable guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not provide sufficient detail or direction for the authors to act upon.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes are needed in the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the proposed method not handling headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the proposed method or headpose handling, making it weakly grounded. It is specific in questioning the authors' claim and suggesting an alternative approach, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the authors' claim regarding the proposed method's inability to handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to provide more evidence or explanation to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the proposed method's inability to handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. This feedback highlights a potential limitation of the proposed method and prompts the authors to consider how to address this issue. However, the comment could be more helpful if it provided specific suggestions or guidance on how to condition headpose parameters in NeRF, similar to the approach in the cited work. Without detailed insights or actionable steps, the authors may find it challenging to fully address the feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and single-pixel and simple patterns by Gu et al. (2019) [1]. However, the comment does not explicitly instruct the authors to address this similarity or provide specific guidance on how to improve their draft based on this observation. While the authors might infer that they should discuss or differentiate their spurious features from existing backdoor triggers, the lack of explicit action or detailed guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples of how these triggers have been used in previous work. This allows the authors to understand the specific issue and how it relates to their own work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both are artificial patterns appearing a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and single-pixel and simple patterns by Gu et al. (2019) [1]. This claim is supported by logical reasoning and references to specific examples, making it mostly verifiable. The authors can understand the basis of the claim and how it relates to their work, allowing them to address it effectively. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and single-pixel and simple patterns by Gu et al. (2019) [1]. This observation is insightful and highlights a potential area for further discussion or differentiation in the paper. However, the comment does not offer specific guidance on how the authors might address this similarity or incorporate it into their work. While it provides a valuable observation, it lacks actionable suggestions, making it somewhat helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a structural optimization component that has been emphasized multiple times, but it points out that the optimization algorithm is directly derived from previous works. This feedback suggests that the authors should clarify the novelty and contribution of their optimization approach. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects need to be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the novelty of their optimization algorithm. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component of the paper, which is a specific part of the work. However, it does not explicitly mention which section or part of the paper this optimization is discussed in, making it weakly grounded. The comment is specific in identifying that the optimization algorithm is directly from previous works, which reduces the contribution. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the optimization algorithm is directly from previous works, which reduces the contribution. However, the comment does not provide specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it difficult to verify the claim and understand the basis for the criticism. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the structural optimization component of the paper, noting that it is directly derived from previous works. This observation raises concerns about the novelty and contribution of the optimization approach. While the comment highlights a specific area that needs clarification, it does not provide detailed guidance on how to address this issue or suggest specific improvements. The feedback is somewhat helpful as it points out a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that the pipeline method does not yield better average results compared to baseline models. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors can infer that they need to improve the introduction of baseline models and potentially re-evaluate the experimental results. The lack of concrete suggestions or detailed guidance makes the action somewhat vague and challenging to implement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results of a pipeline method, specifically mentioning that it does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models are not well introduced in the experiments. However, the comment does not specify which part of the paper discusses the experimental results or the introduction of baseline models, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of baseline model introduction, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline method does not provide better average results for both XVNLI and MaRVL, and that the baseline models are not well introduced in the experiments. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental results, noting that the pipeline method does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. While the comment highlights a potential weakness in the experimental setup, it lacks detailed guidance on how the authors might address this issue or what specific changes could be made to improve the results. The feedback is somewhat helpful as it directs the authors' attention to a critical aspect of their experimental evaluation, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of reproducing a well-known result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative methodologies or providing more detailed analysis. The comment lacks concrete guidance on how the authors might address this concern or improve their draft. As a result, the comment is unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used in reproducing a well-known result in the literature, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the methodology, questioning the necessity of reproducing a known result using this approach. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of reproducing a well-known result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. However, the comment does not provide specific examples or references to support the claim that the observation is unclear or needs to be made again. Without detailed reasoning or evidence, the claim is difficult to verify, making it unverifiable. Therefore, the comment aligns with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the necessity of reproducing a well-known result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. This critique provides a clear and actionable feedback, prompting the authors to consider alternative methodologies or more detailed analysis to strengthen their work. By highlighting the redundancy of the approach, the comment encourages the authors to enhance the novelty and impact of their findings. However, it could be more helpful if it suggested specific alternative methodologies or provided guidance on how to address the issue. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue regarding the related work section, specifically mentioning the importance of discussing modular networks for Visual Question Answering (VQA). It points out that the introduction currently suggests that no one uses modular architectures for VQA, which is not accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of modular networks they should discuss. The action is implicit, as the authors need to infer that they should include a discussion of modular networks for VQA in the related work section. While the action is somewhat vague, it is clear that the authors need to address this issue to improve the accuracy and completeness of their introduction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to mention related work on modular networks for VQA, such as [A], to correct the inaccurate depiction in the introduction. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction inaccurately suggests that no one uses modular architectures for Visual Question Answering (VQA). However, it does not provide specific examples or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. Without additional evidence or context, the claim remains unsubstantiated, and the authors may struggle to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue in the introduction, specifically pointing out that it inaccurately suggests that no one uses modular architectures for Visual Question Answering (VQA). This is a significant oversight that needs to be addressed to ensure the accuracy and completeness of the paper. However, the comment lacks specific guidance on how the authors should incorporate this information or what aspects of modular networks they should discuss in the related work section. While it highlights an important area for improvement, the feedback could be more helpful if it provided suggestions on how to address the issue or what specific related work should be included. Therefore, the comment is somewhat helpful, as it points out a crucial issue but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the authors' discussion by noting that they primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods like TSC and greedy subspace clustering by Park. While the comment identifies a specific area where the authors could improve their discussion, it does not provide explicit guidance on how to address this gap or what specific aspects of the contrast should be included. The action is implicit, as the authors need to infer that they should expand their discussion to include these methods. However, the lack of concrete suggestions or detailed guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on SSC and the lack of contrast with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the absence of a comparison with these other methods, which are computationally efficient and have similar guarantees. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not contrast their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it is based on an observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the authors' discussion by pointing out that they primarily focus on SSC without adequately contrasting their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is somewhat helpful as it highlights an area where the authors could enhance their discussion and provide a more comprehensive comparison of their method with existing approaches. However, the comment could be more helpful if it provided specific suggestions or guidance on how to include these methods in the comparison. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the distinction between weak and semi-supervised training of the proposed method. It provides specific examples, such as renaming a column in Table 1 to \u201cFully supervised\u201d and suggests a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These instructions are clear and concrete, providing the authors with explicit actions to take. The comment is fully actionable as it offers precise guidance on how to improve the clarity and organization of the paper. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to clarify the distinction between weak and semi-supervised training, suggesting renaming a column and proposing a more detailed categorization of training data. This level of detail and specificity makes the comment highly actionable and informative for the authors. Therefore, this comment is rated as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the clarity of the paper, such as renaming a column in Table 1 and proposing a more detailed categorization of training data. These suggestions are logical and actionable, as they offer clear guidance on how to enhance the presentation of the data. However, the comment lacks references or detailed reasoning to fully substantiate the claims. While the suggestions are well-supported, the absence of additional evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the clarity of the distinction between weak and semi-supervised training in the proposed method. It suggests renaming a column in Table 1 to \u201cFully supervised\u201d and proposes a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These suggestions are clear and constructive, offering the authors a clear path to improve the organization and understanding of their work. The comment is mostly helpful as it addresses a specific area of confusion and provides concrete guidance for improvement, though it could be further enhanced by additional details or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the small contributions of the proposed method over previous methods, such as NCNet [6] and Sparse NCNet [21]. It also notes that the work is mostly engineering-focused and suggests that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the differentiation or to enhance the novelty of the contributions. As a result, the authors are left without clear directions on how to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"small contributions over previous methods\" and specifically names \"NCNet [6] and Sparse NCNet [21]\" as examples. It also notes that the work is \"mostly engineering\" and that it is \"challenging to differentiate it from its predecessors\" due to \"similar performance in practice.\" This provides full grounding as the authors can accurately identify the parts of the paper being addressed, including the specific contributions and methods mentioned. The comment is also specific, as it details the nature of the contributions and the challenges in differentiating the proposed method from its predecessors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contributions of the proposed method are small compared to previous methods, such as NCNet [6] and Sparse NCNet [21]. It also suggests that the work is mostly engineering-focused and that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. However, the comment lacks specific examples or detailed reasoning to support these claims. Without further elaboration or evidence, the authors may find it difficult to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the small contributions of the proposed method over previous methods, such as NCNet [6] and Sparse NCNet [21]. It also notes that the work is mostly engineering-focused and suggests that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. While the comment identifies a potential weakness in the novelty of the contributions, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the differentiation of their method. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, making it only marginally helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"semantic\" segmentation is not low-level because the categories are specified for each pixel. It implies that the statements about semantic segmentation being a low-level cue should be removed from the paper. However, the comment does not provide explicit instructions on how to remove these statements or what specific parts of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer that they should remove the statements and potentially re-evaluate the categorization of semantic segmentation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the term \"semantic\" segmentation is not low-level because the categories are specified for each pixel, implying that the statements about semantic segmentation being a low-level cue should be removed from the paper. However, the comment does not specify which part of the paper discusses semantic segmentation or low-level cues, making it difficult for the authors to identify the exact section that needs revision. While the comment is specific about the content that should be removed, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"semantic\" segmentation is not low-level because the categories are specified for each pixel, suggesting that statements about semantic segmentation being a low-level cue should be removed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a basis for action but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the terminology used in the paper, suggesting that \"semantic\" segmentation is not low-level due to the pixel-specific categories. This feedback is clear and actionable, as it directs the authors to reconsider the categorization of semantic segmentation and potentially remove statements that imply it is a low-level cue. However, the comment could be more helpful if it provided additional context or examples to support the claim, allowing the authors to better understand the implications of this observation. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or RL is not used. While the comment identifies a specific issue with the experimental results and the presentation of the data, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to clarify the discrepancy and include the missing cases in the tables. This lack of explicit action makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the ablation experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the discrepancy in performance and the missing cases in the tables. This provides clear guidance on how the authors should revise their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or RL is not used. This observation is based on the experimental results presented in the paper. However, the comment does not provide specific examples or references to support the claim that the performance dropped lower or that the cases are missing. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or reinforcement learning (RL) is not used. This feedback is clear and actionable, as it highlights a potential discrepancy in the experimental results and suggests that the authors should include these missing cases in their tables for a more comprehensive presentation. By addressing this issue, the authors can improve the clarity and completeness of their experimental results, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It highlights that the results are only presented on the CIFAR-10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment does not provide explicit guidance on how the authors should expand their experiments or what specific datasets or model types they should consider. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely that they are limited to the CIFAR-10 dataset and do not consider other datasets from federated learning benchmarks. The comment provides specific examples of relevant datasets and suggests considering additional works for details on different datasets and model types. This level of detail helps the authors understand what needs to be addressed to improve the comprehensiveness of the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments section is a main weakness of the paper, as the results are presented only on the CIFAR-10 dataset and do not consider other datasets from federated learning benchmarks. The comment suggests considering datasets from the LEAF benchmark and recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to infer the need for a more comprehensive evaluation based on the provided information, which could be improved with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section. It points out that the results are only presented on the CIFAR-10 dataset and suggests considering other datasets from federated learning benchmarks, such as those available on the LEAF benchmark. The comment also recommends exploring relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is mostly helpful as it provides clear guidance on how the authors can enhance the comprehensiveness of their experimental evaluation, which is crucial for addressing the identified weakness. However, the comment could be more helpful if it included specific suggestions or examples of how to expand the experiments. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should use another dataset for the ablation study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the claim made in the paper regarding the improvement of proposed modules in accuracy and completeness, referencing a table. However, it does not specify which part of the paper the claim is made or which table is being referred to, making it weakly grounded. The comment is specific in questioning the validity of the claim and suggesting an alternative dataset for the ablation study, but without explicit references to the table or section, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using a different dataset, it does not provide specific reasoning or examples to support why this alternative dataset would be beneficial. The suggestion is somewhat vague and lacks detailed justification, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for consideration but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment questions the claim that the proposed modules improve in both accuracy and completeness, based on a table, and suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. This feedback is somewhat helpful as it identifies a potential area for further investigation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or examples to support why the alternative dataset would be beneficial, making it incomplete. The authors would benefit from a more comprehensive explanation of the rationale behind the suggestion, which could enhance the feedback's usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their methodology. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not specify which part of the paper discusses the methodology or the results, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and the difficulty in interpreting the results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It suggests that previous work has considered multiple vulnerabilities simultaneously, which raises questions about the generalizability of the findings. The comment also notes that the results are difficult to interpret, implying a lack of clarity in the study's conclusions. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to address these concerns effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It suggests that previous work has considered multiple vulnerabilities simultaneously, which raises questions about the generalizability of the findings. The comment also notes that the results are difficult to interpret, implying a lack of clarity in the study's conclusions. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their methodology. While it identifies a potential issue, it lacks actionable advice, making it somewhat helpful. The authors would need to seek further clarification or guidance to fully address the feedback.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the explanation of how a small degree of bias arises from a clear community structure, noting that Theorem 1 and 2 prove the relationship but do not provide intuitive understanding. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so or suggest specific ways to improve the explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the relationship between community structure, degree bias, and the theorems. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the explanation of how a small degree of bias arises from a clear community structure, referencing Theorem 1 and 2. However, it does not specify which part of the paper this explanation is intended for, making it weakly grounded. The comment is specific in its critique of the lack of intuitive understanding of the relationship between community structure, degree bias, and the theorems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of how a small degree of bias arises from a clear community structure is insufficient, noting that Theorem 1 and 2 prove the relationship but do not provide intuitive understanding. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it identifies a gap in the explanation but does not provide sufficient evidence or guidance for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more detailed explanations. It points out that while Theorem 1 and 2 prove the relationship between community structure and degree bias, the explanation of how a small degree of bias arises from a clear community structure is not intuitive enough. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation. However, it could be more helpful if it suggested specific ways to improve the explanation or provided examples to illustrate the concept. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It implies that the authors need to clarify how these clean manifolds are constructed, particularly when the exemplar manifolds are derived from stochasticity. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 182-183, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for non-stochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It questions how these manifolds are constructed when the exemplar manifolds are derived from stochasticity. However, the comment does not provide any evidence, reasoning, or references to support the claim that the construction of clean manifolds for non-stochastic networks is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a specific question about the construction of clean exemplar manifolds for non-stochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. It points out a potential inconsistency in the description of how these manifolds are constructed, as the paper mentions both adversarial perturbations and stochasticity in the construction of exemplar manifolds. This feedback is somewhat helpful as it identifies a potential area of confusion and encourages the authors to clarify their methodology. However, it could be more helpful if it provided guidance on how to construct these manifolds or suggested additional experiments to address the issue. Overall, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the clarity of the notation used in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the clarity of notation in the paper, particularly the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the variables S and Xt, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the problem. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment highlights a specific area that could be improved, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for clarification, but it lacks depth and actionable advice, leaving the authors with limited direction on how to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3. It points out that the paper states the choice is empirical but does not provide sufficient motivation for this specific form. While the comment suggests that the authors should clarify the motivation, it does not offer concrete guidance on how to do so. The action is implicit, as the authors need to infer that they should provide more detailed reasoning or justification for the choice of $\\theta$. However, the lack of specific guidance on what kind of motivation to include makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3, but it does not specify which part of the paper this choice is discussed in. The authors can infer that it relates to the section or theorem where this choice is made, but the comment lacks explicit grounding. However, it is specific in detailing the issue with the motivation, as it points out the lack of clarity and the need for more detailed reasoning. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and clear. It suggests that the paper states the choice is empirical but lacks detailed motivation for this specific form. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the motivation for the choice of $\\theta = \\frac{\\pi}{2}(1-h)$ from Theorem 3. It points out that the paper states the choice is empirical but lacks detailed motivation for this specific form. This feedback is clear and actionable, as it directs the authors to provide more detailed reasoning or justification for their choice. However, the comment could be more helpful if it suggested specific ways to enhance the motivation, such as providing examples or comparisons with other choices. Overall, the comment is mostly helpful as it highlights a clear area for improvement and encourages the authors to elaborate on their reasoning.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also points out that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it does not explicitly instruct the authors to provide these details or suggest specific ways to improve the explanations. The action is implicit and somewhat vague, as the authors are left to infer that they should add these details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for more details in the writing, particularly regarding the definition of the resistance distance and more explanations for Algorithm 1. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper deals with many graph notions, which can be challenging to understand, but the writing is generally good. However, it suggests that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies an area for improvement, it lacks specific examples or references to support the claim about the difficulty of understanding the paper. The suggestion to provide more details is clear, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, noting that while the writing is generally good, more details could be provided, particularly regarding the definition of the resistance distance and explanations for Algorithm 1. This feedback is clear and actionable, as it directs the authors to specific areas where additional information would enhance the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it provided suggestions on how to improve these explanations or examples of where more detail is needed. Overall, the comment is mostly helpful, as it offers valuable guidance for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the originality of their work or what specific aspects they could explore to differentiate their contribution from existing literature. Without actionable suggestions or guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or discussion sections. This lack of grounding makes it difficult for the authors to understand where the issue lies and how to address it. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the originality of the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the originality of the paper, specifically noting that the main idea of variable splitting and the algorithm are not new. However, it does not provide any suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or specific suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment implies that the authors should consider including such results, it does not explicitly instruct them to do so or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should include quantitative results on testing images. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the shape model invariance study, specifically questioning the sufficiency of evaluation on training images. However, it does not specify which part of the paper this study is located in, making it weakly grounded. The comment is specific in its request for quantitative results on testing images, which would enhance the evaluation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment does not contain a subjective claim or opinion, it poses a logical question that could be addressed with additional information or justification. However, without further context or explanation, the claim is considered borderline verifiable, as it lacks detailed reasoning or references to support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the evaluation of the shape model invariance study, particularly concerning the need for quantitative results on testing images. This feedback is clear and actionable, as it prompts the authors to consider whether their evaluation is comprehensive enough. By highlighting a potential gap in the evaluation, the comment provides a constructive suggestion for improvement, encouraging the authors to include testing image results to strengthen their study. However, the comment could be more helpful if it offered additional guidance on how to conduct or present these tests. Overall, the feedback is mostly helpful, as it identifies a meaningful area for improvement and encourages the authors to enhance their evaluation process.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment implies that this related work should be discussed and compared against to provide a better understanding of the state-of-the-art. However, it does not explicitly instruct the authors to include this discussion or comparison in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this omission. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the missed related work and the need to discuss and compare against it to provide a better understanding of the state-of-the-art. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment suggests that this related work should be discussed and compared against to provide a better understanding of the state-of-the-art. However, the comment lacks specific examples or detailed reasoning to support the claim that this work is indeed relevant and should be discussed. Without additional context or evidence, the authors may find it challenging to understand why this specific paper is important and how it relates to their work. Therefore, the claim is considered borderline verifiable, as it provides some basis for the suggestion but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the related work section by pointing out a relevant paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. This is a valuable piece of feedback as it suggests that the authors should consider discussing and comparing their work against this related study to provide a more comprehensive understanding of the state-of-the-art. However, the comment could be more helpful if it provided specific guidance on how to discuss or compare the two works, such as highlighting the differences in approach or findings. Overall, the comment is somewhat helpful as it directs the authors to an important area for consideration, but it lacks detailed suggestions for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two main concerns regarding the scalability of the optimal transport distance computation and the exact computation of optimal transport. It points out that while the authors mention the computation time on a 36-core machine, it is unclear how the method scales on normal machines with fewer cores. Additionally, the comment questions how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. The comment does not provide explicit instructions on how to address these issues or suggest specific actions, such as conducting experiments or providing detailed explanations. While the feedback identifies areas for improvement, it lacks concrete guidance on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scalability of the optimal transport distance computation, specifically questioning whether it scales on normal machines with a couple of cores. It also raises a question about how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport. However, the comment does not specify which part of the paper discusses the optimal transport distance computation or the Sinkhorn method, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the relevant sections of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions about the scalability of the optimal transport distance computation and the exact computation of optimal transport. The first question about scalability is addressed by the authors, who mention the computation time on a 36-core machine. However, the comment does not provide additional evidence or reasoning to support the claim that the method is not scalable on normal machines with fewer cores. The second question about the exact computation of optimal transport is also not fully addressed, as the authors do not provide a detailed explanation of how the Sinkhorn method is used to obtain the exact optimal transport. While the comment identifies areas for improvement, it lacks sufficient evidence or reasoning to fully substantiate the claims, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by questioning the scalability of the optimal transport distance computation and the exact computation of optimal transport. It highlights a potential issue with the method's scalability on normal machines with fewer cores, which is an important consideration for practical applications. Additionally, the comment raises a question about how the Sinkhorn method, which produces a doubly stochastic matrix, is used to compute the exact optimal transport, suggesting a need for clarification or further explanation. While the feedback identifies specific areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The comment is somewhat helpful as it points out important aspects that need attention, but it could be more helpful with additional actionable feedback or suggestions for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study, which could be confusing for practitioners. It also points out the lack of analysis on the parameters \\sigma, \\eta, and \\tau, suggesting that such analysis would be beneficial. However, the comment does not provide explicit guidance on how to conduct the ablation study or how to analyze the impact of these parameters. The actions are implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies the absence of an ablation study and points out the lack of analysis on specific parameters like \\sigma, \\eta, and \\tau in the RBF kernel. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is weakly grounded because the authors cannot confidently determine which part of the paper is being addressed. It is also specific in that it highlights the need for an ablation study and the importance of analyzing the parameters, but without explicit references, the authors may struggle to pinpoint the exact areas to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some ablation study is missing, which could cause confusion and extra experimentation for practitioners. It also notes that the parameters \\sigma, \\eta, and \\tau in the RBF kernel are crucial but lack analysis. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the draft, specifically the absence of an ablation study, which could be confusing for practitioners. It also points out the lack of analysis on the parameters \\sigma, \\eta, and \\tau in the RBF kernel, suggesting that such analysis would be beneficial. However, the comment does not provide specific guidance on how to conduct the ablation study or how to analyze the impact of these parameters. While it highlights important areas for improvement, the lack of detailed suggestions or examples makes it somewhat helpful, as it gives the authors a general idea of what to address but lacks actionable guidance. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper was difficult to follow, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the paper. The comment lacks guidance on how the authors might address these issues, such as suggesting specific sections to clarify or providing examples of how to improve the writing. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of grounding makes it challenging for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending clearer explanations or additional details. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any specific evidence, examples, or references to support this claim. Without any supporting evidence, the claim remains subjective and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the paper's readability, specifically mentioning the difficulty in following the experimental procedures and evaluations. This feedback is valuable as it points out a critical area that needs improvement, allowing the authors to enhance the clarity and comprehensibility of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending clearer explanations, additional details, or specific sections that need clarification. While the feedback identifies a clear weakness, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that INRs operate on a per-data-instance basis, arguing that this is not an advantage and that such a model would be almost useless. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors might infer that they need to reconsider the framing of their argument or provide a more nuanced explanation of the benefits of INRs. The comment lacks concrete details on how to implement this feedback, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the claim that INRs operate on a per-data-instance basis and argues that this is not an advantage, suggesting that such a model would be almost useless. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"Finally, INRs operate on a per-data-instance basis, meaning that one time-series instance is required to train an INR\" is true but argues that it is not an advantage. The reviewer provides a logical reasoning by suggesting that a model capable of handling only a single time-series instance is almost useless. However, the comment lacks specific examples or references to support the claim that this limitation is indeed a significant drawback. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific claim in the paper, stating that INRs operate on a per-data-instance basis, and argues that this is not an advantage. The reviewer provides a logical reasoning by suggesting that such a model would be almost useless. While the comment highlights a potential weakness in the paper's argument, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it points out a critical aspect that needs attention, but it lacks actionable advice or detailed examples to help the authors make meaningful improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It provides an example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m, and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is explicit and provides concrete guidance on what needs to be addressed in the paper. The authors know exactly what aspects to consider and how to implement the suggested clarification, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific section of the paper (line 132), allowing the authors to accurately identify the part being addressed. It also provides specific guidance on what needs to be clarified, such as the aspects of the specific model that are specific to this example model and the clarification regarding the bounds of certain parameters. This level of detail ensures that the authors understand exactly what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the clarity and precision of the paper, particularly regarding the aspects of the specific model being discussed. It suggests that the authors should clarify the bounds of certain parameters, such as acceleration and scaling parameters, and that they should explicitly mention that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m. This feedback is logical and provides clear guidance on how to enhance the paper, making it fully verifiable. The comment is detailed and actionable, allowing the authors to understand exactly what changes are needed to improve the paper.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the paper, particularly regarding the clarity and precision of the aspects of the specific model being discussed. It suggests that the authors should clarify the bounds of certain parameters, such as acceleration and scaling parameters, and explicitly mention that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m. This feedback is clear and detailed, offering concrete guidance on how to improve the paper. By addressing these points, the authors can enhance the clarity and accuracy of their work, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the experiments are limited to RoBERTa-base and raises concerns about the generalizability of the results to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. It also recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT-2. The comment provides clear guidance on what needs to be addressed and how to do it, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"most of the experiments\" and \"Section 4.1.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of limited experiments, the need to generalize results to other models, and suggests including more analysis for GPT-2. This provides detailed guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the limited scope of the experiments, specifically noting that most experiments are conducted using only the RoBERTa-base model. It suggests that the results may not be generalizable to other models, such as those with learnable APEs, different model sizes, objective functions, or architectures. The comment implies that the authors should investigate the generalizability of their findings and include more analysis, particularly for GPT-2. However, the comment lacks specific examples or references to support the claim about the generalizability of the results. While it provides a clear direction for improvement, the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the scope of the experiments, noting that most experiments are conducted using only the RoBERTa-base model. It raises concerns about the generalizability of the results to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. The comment suggests that the authors should investigate whether the results can be generalized to these other models, which is a valuable and actionable piece of feedback. By recommending the inclusion of more analysis, particularly for GPT-2, the comment provides a clear direction for improving the draft. This feedback is mostly helpful as it offers specific suggestions for enhancing the paper, but it could be further strengthened by providing more detailed guidance or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not provide explicit guidance on how to conduct this exploration or what specific steps the authors should take. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not specify which part of the paper discusses the parameters or the experiments, making it weakly grounded. It is specific in suggesting that the authors should consider applying the principles to other areas, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment lacks specific examples or references to support the claim that the parameters are only applicable to image data and ViT. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. This feedback is somewhat helpful as it points out a potential limitation in the scope of the study and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what additional experiments might be necessary. Overall, the comment offers a valuable insight but lacks detailed actionable suggestions, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This provides a clear and explicit action for the authors to take, as they know exactly what additional experiments to conduct to strengthen their paper. The comment is concrete, as it specifies the exact area of evaluation and the method to use (WILDS). Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This provides a clear and explicit reference to a specific area of the paper where additional evaluation is needed. The authors can easily identify the part of the paper that requires further evaluation, making the comment fully grounded. Additionally, the comment specifies what needs to be addressed, namely the evaluation of TTA methods on more conditions of natural distribution shift. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests evaluating TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9]. This claim is somewhat verifiable as it provides a specific example of a condition to consider, which could strengthen the paper. However, it lacks detailed reasoning or references to support why this additional evaluation would be beneficial. The authors would need to infer the importance of this suggestion, which could be improved with more explicit justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of TTA methods, specifically noting that using non-standard benchmarks can break popular TTA methods. It suggests that the authors should consider evaluating their TTA methods on more conditions of natural distribution shift, such as WILDS [9], to strengthen the paper. This feedback is clear and actionable, providing a specific direction for the authors to improve their work. However, it could be more helpful if it included additional suggestions or considerations for the evaluation process. Overall, the comment is mostly helpful as it offers a clear and actionable improvement for the authors to consider.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with large-scale datasets. While the comment identifies a potential issue with the learning rate condition, it does not provide explicit guidance on how the authors might address this concern or what specific changes could be made to the draft. The action is implicit, as the authors would need to infer that they should consider alternative learning rate scaling strategies or provide a more realistic justification for the current condition. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the scalability of the required condition on the learning rate, which is a critical aspect of the paper. It highlights a concern that the learning rate scales with the number of samples, a point that is not realistic in practice. The comment is fully grounded as it explicitly mentions the learning rate condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the learning rate condition and its implications for scalability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with large-scale datasets. The comment provides a logical reasoning for why the condition might be unrealistic, but it lacks specific examples or references to support the claim. Without additional evidence or references, the claim is somewhat verifiable, as it offers a plausible argument but does not provide a comprehensive basis for the authors to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the required condition on the learning rate, noting that it scales with the number of samples, which is not realistic in practice. The reviewer points out that the step size does not typically grow with the sample size, potentially leading to unreasonably large learning rates when dealing with large-scale datasets. This feedback is valuable as it highlights a potential limitation or unrealistic assumption in the paper, prompting the authors to reconsider their approach or provide a more realistic justification for the learning rate condition. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue or improve the scalability of their method. Overall, the comment is somewhat helpful, as it provides a clear point of concern but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the significance of the paper, suggesting that the utility of tensor networks in representing PMFs of discrete variables is not clear in the context of machine learning algorithms or analysis. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to clarify the significance or improve the paper's relevance to machine learning. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the significance of the paper, specifically questioning how the use of tensor networks in representing PMFs of discrete variables is relevant to machine learning algorithms or analysis. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the significance of the paper is poor because the utility of tensor networks in representing PMFs of discrete variables is not clear in the context of machine learning algorithms or analysis. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a general critique but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the significance of using tensor networks to represent PMFs of discrete variables in the context of machine learning algorithms or analysis. It suggests that the paper does not clearly explain how these results are useful to machine learning, which could impact the perceived significance of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their work. While it points out a potential area for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of unlabeled data, noting that the data is perfectly balanced and may not be practical in real-world applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This comment provides a clear and explicit action for the authors to take, which is to consider using a more realistic setting for their experiments. The suggestion is concrete and offers a specific example of how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"preprocessed Amazon review dataset (Blitzer version)\" and the \"2000 unlabeled data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear rationale for the issue, suggesting that the authors should consider using a more convincing setting as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This provides a specific example of how the authors could address the issue, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of unlabeled data from the preprocessed Amazon review dataset is impractical in real-world applications because it is perfectly balanced. The reviewer suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This claim is somewhat verifiable as it provides a logical reasoning for the issue and references a specific example of a more convincing setting. However, it lacks detailed explanation or examples to fully support the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of unlabeled data, specifically noting that the data from the preprocessed Amazon review dataset is perfectly balanced, which may not be practical in real-world applications. The reviewer suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018. This feedback is mostly helpful as it provides a clear and actionable suggestion for the authors to consider, offering a specific example of how to address the issue. However, it could be more helpful if it included additional guidance or suggestions for alternative approaches. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify the sampling process. The action is implicit, as the authors would need to infer that they should seek clarification or provide more details on the sampling method. The comment is vague and lacks concrete suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it identifies a potential issue with the clarity of the sampling process and suggests that it might be similar to sampling from the leverage score, as discussed in [3]. This provides a clear direction for the authors to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the sampling process is unclear or that it is similar to sampling from the leverage score. Without additional context or evidence, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this problem is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the sampling process. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should seek clarification or provide more details on the sampling method to address the issue raised. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that the extent to which the observations generalize to few-shot learners beyond Prototypical Networks is not evaluated. This observation suggests that the paper's contributions may be limited in terms of understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability of their observations. The action is implicit and vague, as it leaves the authors without a clear understanding of how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the observations to few-shot learners beyond Prototypical Networks, which is a specific aspect of the paper. However, it does not explicitly mention a particular section, table, or figure, making it weakly grounded. The comment is specific in identifying the issue with the generalizability of the observations, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the extent to which the observations generalize to few-shot learners beyond Prototypical Networks is not evaluated, which may limit the scope of the submission\u2019s contributions. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by pointing out that the extent to which the observations generalize to few-shot learners beyond Prototypical Networks is not evaluated. This observation is important as it may limit the scope of the paper's contributions in understanding the properties of episodic training. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or expand their analysis to include few-shot learners. While it highlights a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a meaningful weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 directly removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. The lack of concrete steps or detailed explanations leaves the authors uncertain about how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 directly removes the modal subset of all instances, which may not be appropriate. However, the comment does not specify which part of the paper this issue is discussed or how it relates to the overall content. The authors are left to infer that this concern might be relevant to the introduction or methodology sections, but without explicit references, they cannot confidently determine which part to address. The comment is specific in its critique but lacks grounding, making it difficult for the authors to focus their responses. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 directly removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that this issue is significant or how it affects the overall contribution of the paper. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the contribution of different modalities and instances, suggesting that some instances with good performance in one modality might belong to a strong modality, while others might not. It also points out that Equation 3 directly removes the modal subset of all instances, which may not be appropriate. However, the comment does not provide specific guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. While it identifies a potential problem, it lacks depth and actionable advice, making it somewhat helpful. The authors may gain some insight into the issue but would need to seek further clarification or guidance to fully address the feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the abstract effectively explains the proposed idea but does not provide details on how the idea was evaluated or what the outcome was. It also mentions minor language issues. While the comment identifies a gap in the abstract's content, it does not explicitly instruct the authors to include details about the evaluation process or the outcome. The suggestion to address minor language issues is vague and lacks specific guidance. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not provide clear instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding how the proposed idea was evaluated and what the outcome was, as well as mentioning minor language issues. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract effectively explains the proposed idea but lacks details on how it was evaluated and what the outcome was. It also mentions minor language issues. However, the comment does not provide any specific examples or references to support the claim about the lack of detail in the evaluation process or the outcome. The mention of minor language issues is vague and lacks context. Therefore, the claim is unverifiable due to the absence of supporting evidence or justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the abstract, noting that while it effectively explains the proposed idea, it lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include additional information that would enhance the comprehensiveness of the abstract. However, the comment could be more helpful if it provided specific examples or suggestions for how to include this information. Overall, the comment is mostly helpful as it highlights a clear area for improvement and provides a basis for the authors to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. While the comment highlights a potential issue with the experimental section, it does not provide explicit or implicit guidance on how the authors should address this concern. The authors are left without a clear understanding of what specific changes or additions are needed to make the experiments more useful. The feedback is vague and lacks concrete suggestions, making it difficult for the authors to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. However, it does not specify which part of the paper these examples are discussed or how they relate to the overall narrative. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its critique of the experimental section, highlighting the absence of relevant experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. The reviewer provides two examples of POMDP problems with non-convex value functions, but does not offer any additional evidence or reasoning to support the claim that these examples are insufficient or unconvincing. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises concerns about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. The reviewer provides two examples of POMDP problems with non-convex value functions, but does not offer any additional evidence or reasoning to support the claim that these examples are insufficient or unconvincing. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the concern. While the feedback highlights a potential issue with the experimental section, it does not provide actionable guidance or suggestions for improvement, leaving the authors without a clear path forward. Therefore, the comment is barely helpful, as it identifies a weakness but does not offer substantial assistance in addressing it.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a confusion regarding the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for the target domain \\\\tau is unlabeled, which is inconsistent with the original MFDA paper (Yue et al., 2021a). The comment suggests that the authors should clarify the use of unlabeled data in source domains during training, as it is unclear whether this is consistent with the original paper. While the comment identifies a specific issue and suggests a clarification, it does not provide explicit instructions on how to address the confusion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potentially make revisions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the confusion regarding the description of the MFDA setting, particularly the notation for the target domain \\\\tau and the use of unlabeled data in source domains during training. The comment provides a detailed explanation of the issue, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the consistency of the description of the MFDA setting with the original paper (Yue et al., 2021a). It highlights a specific discrepancy regarding the notation for the target domain \\\\tau and the use of unlabeled data in source domains during training. The comment suggests that the authors should clarify these aspects to align with the original paper. However, the comment lacks detailed reasoning or specific examples to fully support the claim, making it somewhat verifiable. The authors would need to infer the need for clarification and potentially make revisions to the draft to address the inconsistency. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the description of the MFDA setting within the Method Section, particularly concerning the notation for the target domain \\\\tau and the use of unlabeled data in source domains during training. It highlights a discrepancy with the original MFDA paper (Yue et al., 2021a), which could confuse readers. The comment suggests that the authors should clarify these aspects to ensure consistency and accuracy in their description. While the feedback is clear and points out a potential area of confusion, it could be more helpful if it provided specific guidance on how to clarify the description or what aspects of the original paper should be referenced. Overall, the comment is mostly helpful as it directs the authors to a specific area that needs attention, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that epoch-wise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of the algorithms to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that epoch-wise analysis, especially for finite sum settings, could provide insights into the behavior of optimization algorithms. It provides specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. This guidance is clear and specific, as it outlines potential areas for further analysis and comparison between deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be applied to, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that epoch-wise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. This claim is somewhat verifiable as it provides a logical reasoning for why such analysis could be beneficial, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that epoch-wise analysis, especially in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms' progress after each full pass of the data. This could help with comparative analysis between deterministic and stochastic methods. However, the comment lacks detailed guidance on how the authors should conduct this analysis or what specific aspects of the algorithms to focus on. While it provides a direction for improvement, it does not offer concrete steps or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors' claim about the immense workload but disagrees with the assessment of the paper's contribution as incremental. It suggests that the paper is essentially a combination of GraphRAG and GraphCare [1] and points out that many key baselines were not cited. The comment also notes that essential RAG algorithms, such as MedRetriever [2], and commonly used GraphRAG algorithms like KGRAG [3], should have been introduced. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific sections to revise or how to incorporate the missing information. While the action is implied, it is vague and lacks concrete details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about the immense workload and the incremental contribution of the article, referencing specific works [1], [2], and [3]. It also provides specific suggestions for improvement, such as introducing essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This level of detail allows the authors to understand exactly what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' contribution is incremental and suggests that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out that many key baselines were not cited and suggests the inclusion of essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3]. However, the comment lacks specific examples or detailed reasoning to fully support these claims. While the suggestions are logical, the absence of detailed evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the authors' work, identifying the incremental nature of their contribution and suggesting that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out the lack of key baselines and suggests the inclusion of essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3]. While the comment offers specific suggestions for improvement, it could be more helpful if it provided more detailed guidance on how to address these issues or incorporated these suggestions into the draft. Overall, the feedback is mostly helpful as it directs the authors towards enhancing the depth and comprehensiveness of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the issue. It questions the annotators' consideration of local regulations and their impact on zero-shot cross-country classification. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the distinction between the two types of speech. While the authors are left to infer the need for clarification, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Paper Summary,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. The comment is specific in detailing what needs to be addressed, including the need for clearer definitions and the impact of local regulations on annotations and classification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the distinction between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. It also questions the role of local regulations in the annotations and their impact on zero-shot cross-country classification. However, the comment lacks specific examples or references to support the claim that the distinction is difficult to differentiate or that local regulations play a significant role. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the differentiation between derogatory and exclusionary extreme speech, which is a crucial aspect of the paper. It provides an example from the sample data file to illustrate the confusion, questioning the annotators' consideration of local regulations and their impact on zero-shot cross-country classification. This feedback is clear and actionable, as it highlights a potential area for improvement in the paper's clarity and rigor. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific changes to the methodology. Overall, the comment is mostly helpful, as it offers valuable insights that can guide the authors in refining their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement is due to the network design or the nature of ImageNet. This provides clear guidance on what needs to be done and how to address the concern, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to show a graph of T vs the number of images and Expectation(T) over the ImageNet test set, allowing the authors to accurately identify the parts of the paper that need revision. It is also specific because it provides clear guidance on what needs to be addressed, including the purpose of the graph and the question about the source of performance improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment lacks specific examples or references to support the claim that these visualizations are necessary or how they would address the concern about performance improvement. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by requesting the inclusion of a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a critical question about whether the performance improvement is due to the network design or the nature of ImageNet, which is an important consideration for understanding the results. By addressing these points, the comment offers actionable feedback that could help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it provided more detailed guidance on how to create the graph or how to address the question about the source of performance improvement. Overall, the comment is mostly helpful as it identifies key areas for improvement and encourages the authors to consider additional analyses.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should make the paper mathematically correct, but it acknowledges that this might make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment provides some guidance, it does not explicitly instruct the authors on how to make the paper mathematically correct or how to introduce the notation L_l. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.\" which indicates a figure in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue with the notation L_l, suggesting that it should be introduced beforehand. This provides clear guidance on what needs to be addressed in the figure or the surrounding text. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the mathematical correctness of the paper and the notation used, specifically questioning why the notation L_l is used instead of just L. While the comment suggests that the authors should consider making the paper mathematically correct, it does not provide specific examples or references to support this claim. The reasoning is somewhat vague, as it lacks detailed explanations or evidence to substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mathematical correctness of the paper and raises a question about the notation L_l. It suggests that the authors should consider making the paper mathematically correct, but it also acknowledges that this might make other equations messy. Additionally, it points out that the notation L_l should be introduced beforehand, implying that it is not clear why this specific notation is used. While the comment highlights potential areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it points out specific areas that need attention, but it could be more comprehensive with actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical limitation in the study of sequential ensembling, specifically the lack of consideration for noise accumulation in homomorphic encryption. It points out that this omission prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit, as the authors need to infer that they should study the effect of noise accumulation in the context of homomorphic encryption to address the identified limitation. While the action is somewhat vague, it is clear that the authors need to consider this aspect to improve their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to sequential ensembling and noise accumulation in the context of homomorphic encryption. It highlights a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that for sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. This limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study of sequential ensembling, particularly the lack of consideration for noise accumulation in the context of homomorphic encryption. This limitation is significant because it prevents the use of even single deep neural networks on homomorphically encrypted data, which is a critical aspect of the research. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it points out a crucial limitation but does not offer constructive feedback for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, noting that the baseline and time-aware models show similar performance. It suggests that the proposed method might make more sense under different time-step scenarios. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by questioning the effectiveness of the proposed methods when the training and evaluation time-steps are the same, suggesting that the method might make more sense under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, based on the observation that Figure 5 shows similar performance between the baseline and time-aware models. While the comment identifies a potential issue, it does not provide specific examples, detailed reasoning, or references to support the claim that the effectiveness of the proposed methods is questionable under these conditions. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, as evidenced by the similar performance shown in Figure 5. The comment suggests that the proposed method might make more sense under different time-step scenarios, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it provided specific examples or guidance on how the authors might explore these scenarios or address the issue. Overall, the comment is somewhat helpful as it identifies a potential limitation and offers a direction for further exploration, but it lacks detailed actionable advice.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to obtaining fully disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the mechanisms and guarantees of disentanglement. However, the comment does not specify exactly how this should be done, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to obtaining fully disentangled latent vectors. However, the comment does not specify which part of the paper discusses disentanglement or how it is realized. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of disentanglement, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to obtaining fully disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is somewhat verifiable as it points out a specific area where the paper could be clearer, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the need for more explanation based on the existing information, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the 'Broader Impacts and Limitations' section mentions a limitation related to obtaining fully disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation regarding disentanglement. However, the comment could be more helpful if it provided specific examples or suggestions for how to address this issue. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used a standard regularization trick. However, the comment does not provide any explicit or implicit guidance on how to implement this suggestion or what specific aspects of the comparison need to be addressed. The authors are left without a clear understanding of how to apply this feedback, making it difficult to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, it does not specify which part of the paper this comparison is intended for or which section discusses the previous result. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the type of regularization trick, the absence of explicit references or context makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, as the authors are left to infer the reasoning behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison of the proposed method's complexity to a previous result in a strongly-convex concave case, suggesting the use of a standard regularization trick. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or what specific aspects of the comparison need to be addressed. While it points out a potential improvement, it does not offer actionable steps or examples to help the authors enhance their work. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not fully support the authors in making necessary changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison to assess the impact of mean teacher regularization. The comment is specific in its suggestion and provides a concrete action for the authors to implement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit reference to a specific part of the paper, allowing the authors to accurately identify the section where the comparison should be included. The comment is specific in its suggestion, detailing what needs to be added to the graph to provide a meaningful comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3 to assess the impact of mean teacher regularization. This claim is somewhat verifiable as it provides a specific suggestion for comparison, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the necessity of this comparison and its relevance to the paper's findings. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of a learning curve for a model without mean teacher or pi regularization in Figure 3. This addition would allow the authors to compare the performance of their model with and without these regularization techniques, providing valuable insights into the impact of mean teacher regularization. The comment is clear, actionable, and directly addresses a potential area for enhancing the paper's analysis and results. However, it could be more helpful if it included additional guidance on how to interpret or present the new learning curve effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \\u03c6 and the shared model \\u03b8_S. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the objective equation. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the proposed objective equation, which is mentioned in line 128. It highlights that the optimization over both parameters of the transformation \\u03c6 and the shared model \\u03b8_S is not clearly discussed in comparison to prior work, such as AlignFlow. However, the comment does not specify which part of the paper this issue is located in, making it weakly grounded. It is specific in detailing the issue with the objective equation and the lack of discussion regarding the number of parameters compared to prior work. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed objective equation requires optimization over both the parameters of the transformation \\u03c6 and the shared model \\u03b8_S, and it notes that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it lacks sufficient justification to fully understand the issue.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective equation, noting that it requires optimization over both the parameters of the transformation \\u03c6 and the shared model \\u03b8_S. It highlights that the effect on the number of parameters compared to prior work, such as AlignFlow, has not been discussed clearly. This feedback is somewhat helpful as it points out a potential area for improvement in the paper, specifically regarding the clarity and depth of the discussion on the objective equation. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or improve the discussion. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the handling of different types of inputs and the disordered citation. For the first part, it suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, and present their solutions. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be addressed and how to do it. However, the comment does not specify which part of the paper this discussion should be included in, leaving some ambiguity. For the second part, the comment suggests that the citation is disordered, but it does not provide specific guidance on how to correct it. While the action is somewhat explicit for the first part, the second part lacks detail, making the comment somewhat actionable overall.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the handling of different types of inputs, such as bio-medical signals or speech, suggesting that the authors should discuss this and present their solutions. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss how they handle these different types of inputs and present their solutions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns: the handling of different types of inputs and the disordered citation. While the comment suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, it does not provide specific examples or references to support this claim. The suggestion to present solutions is clear, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. The comment also mentions that the citation is disordered, but it does not elaborate on why it is disordered or how it should be corrected, which limits the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the handling of different types of inputs and the disordered citation. It suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, and present their solutions. This provides a clear direction for the authors to enhance their paper. However, the comment lacks specific guidance on which sections of the paper should include this discussion or how to correct the disordered citation. While it offers valuable feedback, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between equations 4 and 3, specifically asking if the improvement of the designed solutions in Table 5 is significant on some datasets. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not offer explicit guidance on how the authors should address this issue or what specific actions they should take to improve the significance of their results. The action is implicit and vague, as it does not provide concrete steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between equations 4 and 3, specifically asking if the improvement of the designed solutions in Table 5 is significant on some datasets. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in detailing the issue of marginal improvement on certain datasets, but without explicit references to sections or tables, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between equations 4 and 3 and provides an example of marginal improvement in the results presented in Table 5. It questions whether the improvement of the designed solutions is significant on some datasets, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment lacks detailed reasoning or references to support the claim that the improvement is not significant. It does not provide a clear explanation of why this specific improvement is considered marginal or how it impacts the overall significance of the results. As a result, the claim is somewhat verifiable, as it is based on a specific observation but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the relationship between equations 4 and 3, specifically asking whether the improvement of the designed solutions in Table 5 is significant on some datasets. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This feedback highlights a potential issue with the significance of the results, which could be valuable for the authors to address. However, the comment lacks detailed guidance on how the authors might improve the significance of their results or what specific actions they should take. While it identifies a potential area for improvement, it does not offer concrete suggestions or detailed reasoning, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific missing state-of-the-art references in the face recognition experiment, providing examples such as \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\", http://vis-www.cs.umass.edu/lfw/results.html#baidu.\" The comment also suggests that the VRF achieves a higher accuracy (98.65%) on the LFW dataset compared to the results in Table 3 of the paper. While the comment identifies specific references that are missing and provides a comparison of results, it does not explicitly instruct the authors to include these references or incorporate the comparison into their draft. The action is implicit and somewhat vague, as the authors would need to infer that they should add the missing references and discuss the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and provides specific examples of missing state-of-the-art references, such as \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\", http://vis-www.cs.umass.edu/lfw/results.html#baidu.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what is missing and provides a comparison of results, guiding the authors on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\", http://vis-www.cs.umass.edu/lfw/results.html#baidu.\" It also suggests that the VRF achieves a higher accuracy (98.65%) on the LFW dataset compared to the results in Table 3 of the paper. The claim is supported by providing a specific example of a missing reference and a comparison of results, which allows the authors to understand the basis of the critique. However, the comment could be more robust by including a broader range of state-of-the-art references or providing a more detailed analysis of the comparison. Overall, the comment is mostly verifiable, as it provides sufficient evidence to support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the face recognition experiment by pointing out the absence of certain state-of-the-art references, such as \"Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\", http://vis-www.cs.umass.edu/lfw/results.html#baidu.\" It also highlights that the VRF achieves a higher accuracy (98.65%) on the LFW dataset compared to the results presented in Table 3 of the paper. This feedback is clear and actionable, as it directs the authors to include the missing references and discuss the comparison, which could enhance the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or address the accuracy comparison. Overall, the comment is mostly helpful, as it offers valuable insights for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not 'Wh-types'/transformable. However, it does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary. The comment lacks concrete guidance on how to improve the generalization of the model or what specific modifications could be made to the template mapping. As a result, the authors are left without a clear understanding of how to apply the feedback to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the question answering process, specifically mentioning the template mapping and its potential impact on generalization to questions that are not 'Wh-types'/transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential problem with the template mapping, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process might cause poor generalization to questions that are not 'Wh-types'/transformable due to the template mapping. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it difficult to understand or address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not 'Wh-types'/transformable. This feedback is somewhat helpful as it highlights a specific area that could be improved, but it lacks detailed guidance or suggestions on how to address this issue. The authors are left with a general idea of the problem but without concrete steps to resolve it, which limits the overall helpfulness of the comment. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or incorporate the idea into their work. The comment lacks guidance on how to proceed or what changes might be necessary. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VolumeDeform [1]\" and provides context by stating that utilizing a volumetric representation in the deformation field is not a novel idea. It specifies that this is relevant to the real-time dynamic reconstruction task. However, the comment does not provide specific guidance on what needs to be addressed or how the authors might incorporate this information into their work. Therefore, it is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform [1] as an example. This claim is somewhat verifiable as it provides a specific reference to support the assertion that the idea is not novel. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the approach, specifically regarding the use of volumetric representations in the deformation field. It references VolumeDeform [1] to support the claim that this idea is not novel. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or incorporate the idea into their work. While it highlights a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. The authors would need to infer how to address the issue based on the comment, which limits its helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the ICL-HAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit, as the authors need to infer that they should expand the discussion on the trade-off between consistency and accuracy. The comment is somewhat actionable because it identifies a specific area that needs attention but lacks concrete details on how to implement the suggestion. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ICL-HAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the trade-off between consistency and accuracy scores. This provides clear guidance on how the authors should respond, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ICL-HAR, while improving consistency and verifiability, has negatively impacted accuracy scores, dropping from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the comment lacks specific examples or references to support the claim about the accuracy drop. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ICL-HAR, noting that while it improves consistency and verifiability, it negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This observation is important for the authors to address, as it highlights a trade-off that needs to be discussed or acknowledged in more detail. However, the comment lacks specific guidance on how to address this issue or what aspects of the discussion should be included. While it provides a clear point of improvement, the feedback could be more helpful if it offered suggestions on how to enhance the discussion or present the findings more effectively. Therefore, the comment is somewhat helpful, as it identifies a meaningful issue but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the rock-paper-scissors example is inspired by previous work and requests that the authors cite the source appropriately. While the comment implies that the authors should cite the source, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should cite the source. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests that the authors cite the source appropriately, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by an example from previous work and requests that the authors cite the source appropriately. While the comment suggests a necessary action, it does not provide any specific reasoning or evidence to support why this claim is accurate or how the example is inspired by previous work. The request for citation is clear, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the rock-paper-scissors example, noting that it is inspired by examples from previous work. It requests that the authors cite the source appropriately. This feedback is clear and actionable, as it directs the authors to address a potential oversight in their citation practices. However, the comment could be more helpful if it provided specific examples of previous work that inspired the rock-paper-scissors example or suggested where the authors might find these sources. Despite this, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited nature of the innovations in network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the innovations or the performance of the oracle expert. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions the \"innovations of network architecture design and constraint embedding\" and the \"performance is limited by the performance of the oracle expert,\" but without specific references to sections, tables, or figures, the authors cannot pinpoint the exact areas that need improvement. The comment is also not specific because it does not provide detailed feedback or suggestions on how to address the identified limitations. Therefore, this comment is not grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the innovations of network architecture design and constraint embedding are \"rather limited\" and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of this critique and how it applies to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty and effectiveness of the proposed innovations, specifically regarding network architecture design and constraint embedding. It suggests that the performance is constrained by the performance of the oracle expert, which could be a significant issue. However, the comment lacks specific guidance or suggestions on how the authors might address this limitation or improve their work. Without actionable advice or detailed feedback, the authors may find it challenging to understand how to enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide comprehensive guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that comparing the model's performance only on pre-trained synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. While the comment implies that the authors should provide this additional information, it does not explicitly instruct them to do so or specify how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to include results from fine-tuning on real-world datasets with different losses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of comparing model performance only on pre-trained synthetic data, which is an important aspect of the paper. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is specific in that it suggests an alternative approach to demonstrating the importance of the proposed projection errors by including results from fine-tuning on real-world datasets with different losses. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparing the model's performance only on pre-trained synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. While the comment provides a rationale for why the comparison is unfair, it lacks specific examples or references to support the claim. The suggestion to include results from fine-tuning on real-world datasets with different losses is logical but could be more detailed. Therefore, the claim is somewhat verifiable, as it is supported by reasoning but lacks sufficient detail or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the model's performance, suggesting that it is unfair to only compare results on pre-trained synthetic data. It recommends demonstrating the importance of the proposed three projection errors by providing performance metrics on real-world datasets with different losses. This feedback is somewhat helpful as it highlights a specific area for improvement and suggests a way to strengthen the evaluation of the model. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this additional analysis or included examples of how to present the results effectively. Overall, the comment offers valuable insights but could be more comprehensive in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should consider averaging over subword representations, a common practice in certain cases, and provides a specific reference to support this suggestion. This action is clear and concrete, as it directly instructs the authors on how to improve their draft by incorporating a common practice and referencing relevant literature. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L.490), allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, referencing a common practice and providing a specific example with a citation. This feedback is detailed and actionable, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is common to average over subword representations in certain cases, providing a specific reference to support this claim. This allows the authors to understand the basis of the suggestion and potentially incorporate it into their work. However, the comment could be more robust if it included additional examples or a broader discussion of the implications of this practice. Overall, the claim is mostly verifiable, as it is supported by a reference but could benefit from more detailed justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out a common practice in certain cases, namely averaging over subword representations, and referencing a relevant paper. This feedback is actionable and offers a clear direction for the authors to enhance their draft. However, it could be more helpful if it included additional context or examples to further guide the authors in implementing the suggestion. Overall, the comment is mostly helpful, as it provides a valuable insight and actionable feedback that can significantly improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not provide explicit guidance on how to implement these suggestions or actions, such as specific steps or examples of how to conduct the calibration curves or discuss the differences. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model AUC's ability to assess discriminant ability and suggests that it may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not specify which part of the paper discusses the model AUC or where the calibration curves or discussions on differences would be most relevant. This makes it weakly grounded, as the authors cannot confidently determine which sections or parts of the paper need revision. The comment is specific in detailing the issues and suggestions, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It suggests conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it recommends discussing the differences between the traditional method and the proposed method. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the feedback effectively. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model AUC's ability to demonstrate consistency with actual risk, suggesting that calibration curves could be used to show agreement. It also encourages the authors to prove the feasibility of the generated scoring system and to discuss the differences between the traditional method and the proposed method. While the comment provides some guidance on areas for improvement, it lacks specific details or actionable steps for the authors to take. The feedback is somewhat helpful as it highlights important aspects that need attention but could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues related to the paper's content. First, it notes that the range of ID and OOD does not change much after sparsification, as seen in Figure 4. Second, it points out that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on what changes to make. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not change much after sparsification, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the range of ID and OOD does not change much after sparsification, as seen in Figure 4, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment lacks specific examples or references to support the claim that these conditions are crucial for DICE. Without detailed reasoning or evidence, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues in the paper: the lack of change in the range of ID and OOD after sparsification, as shown in Figure 4, and the insufficient discussion of Lemma 2's requirements, particularly the need for approximately identical means for DICE. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. While the feedback highlights areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The comment is somewhat helpful as it points out specific weaknesses but does not offer comprehensive advice or detailed steps for improvement, leaving the authors with a clear direction but limited actionable guidance. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs. While the question prompts the authors to consider the space issue, it does not provide explicit guidance on how to address the integration concern or how to break the sections into paragraphs. The action is implicit and somewhat vague, as the authors need to infer the specific changes required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs. While the question prompts the authors to consider the space issue, it does not specify which part of the paper the bolded sections are located in, making it weakly grounded. However, the comment is specific in suggesting that the sections should be broken into paragraphs to improve readability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs due to space concerns. While the question prompts the authors to consider the space issue, it does not provide specific reasoning or examples to support the claim that breaking the sections into paragraphs would address the space issue. The comment lacks detailed justification or references, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the integration of environments and suggests that the bolded sections on page 6 should be broken into paragraphs to improve readability due to space concerns. While the comment identifies a potential issue with the formatting of the paper, it does not provide specific guidance or suggestions on how to address the space issue or integrate environments effectively. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the strength and fairness of the experiments, including the use of position kernels for all baselines, the lack of comparison with baselines using default settings, and the absence of baselines related to BO with discrete and categorial variables. It also points out the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors need to infer how to strengthen the experiments, include additional baselines, and discuss limitations and societal impacts. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the strength and fairness of the experiments, specifically questioning why all baselines use position kernels and why default settings are not used. It also notes the absence of baselines related to BO with discrete and categorial variables and suggests a comparison with these baselines. However, the comment does not specify which part of the paper these issues are related to, such as the experimental setup or results section. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues with the baselines, it is not grounded because it does not provide clear references to the sections or parts of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the strength and fairness of the experiments, including the use of position kernels for all baselines, the lack of comparison with baselines using default settings, and the absence of baselines related to BO with discrete and categorial variables. The comment also suggests that the paper does not mention much about the limitations or societal impacts of the proposed approach. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides some reasoning but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several concerns about the strength and fairness of the experiments, specifically questioning the use of position kernels for all baselines and the lack of comparison with baselines using default settings. It also points out the absence of baselines related to BO with discrete and categorial variables and suggests a comparison with these baselines. Additionally, the comment notes that the paper does not mention much about the limitations or societal impacts of the proposed approach. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues or what actions the authors should take to strengthen their work. The feedback is somewhat helpful as it provides a general direction for improvement but could be more detailed and actionable to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take or suggest how to address this observation. The comment lacks guidance on what changes might be necessary or how to improve the results. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is related to, such as a particular section, table, or figure. Without this context, the authors cannot confidently determine where the issue lies or how to address it. The comment is not grounded, as it lacks specific references to the paper, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any specific evidence, reasoning, or references to support this observation. Without additional context or explanation, the authors are left to interpret the claim, making it difficult to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. While this observation is interesting, the comment does not provide any actionable feedback or suggestions on how to address this issue or improve the results. It lacks depth and does not offer guidance on what changes might be necessary or how to enhance the paper's findings. As a result, the comment is not particularly helpful in guiding the authors to improve their draft, making it a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the observed results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not provide explicit instructions on how the authors should address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to clarify the results and improve the presentation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the question about the sparsity patterns and the suggestion to clarify whether the results are specific to the sparsity detection problem or generalizable to GNNs in general. Additionally, it points out that the presentation of bits in Section 4.3 could be improved. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment lacks specific examples or references to support the claim that the sparsity patterns do almost equally well and that no insight is provided. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the sparsity patterns observed in the paper, suggesting that they do almost equally well and that no insight is provided to explain this phenomenon. It also points out that the presentation of bits in Section 4.3 could be improved. While the comment identifies an area that needs clarification and suggests a potential improvement in presentation, it lacks specific guidance on how the authors should address these issues or what changes would be beneficial. The feedback is somewhat helpful as it highlights areas for improvement but does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the temperature \u03c4 is missing from the derivation and suggests that it should be shown rigorously or mentioned in the paper. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown rigorously or mentioned in the paper. This claim is somewhat verifiable as it points out a specific issue in the derivation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the missing temperature and its importance, which could be improved with additional explanation or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, namely the omission of the temperature \u03c4 in the derivation from Eqn. 3 to Eqn. 4. It suggests that the temperature should be shown rigorously or mentioned in the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve the rigor and completeness of their work. By addressing this issue, the authors can enhance the clarity and accuracy of their derivation, making the paper more robust and understandable. Therefore, the comment is highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a citation on differential privacy should be added to line 156 to benefit the reader. This is an explicit action, as it clearly instructs the authors to include a specific citation. The action is also concrete, as it provides a clear and specific instruction on what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, which is a clear and actionable recommendation. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a citation on differential privacy to line 156. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this addition would be beneficial. The authors are left to infer the value of the suggestion, which makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is specific and actionable, as it suggests adding a citation on differential privacy to line 156. This addition would enhance the clarity and comprehensiveness of the paper by providing readers with additional context and background information. However, the comment could be more helpful if it provided more context or explanation about why this citation is necessary or how it would benefit the reader. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, allowing them to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two distinct points. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is somewhat explicit but could be more detailed, as it does not provide specific guidance on how to address this concern or what additional assumptions might be considered. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a concrete action that the authors can take to correct the error. However, the first part of the comment is somewhat vague and lacks detailed guidance, making the overall comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first para of Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, questioning the claim about \"significant additional assumptions\" and suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set. Additionally, it points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains two claims: one questioning the claim that the methodology requires \"significant additional assumptions\" and another pointing out an error in the sign of an inequality. The first claim is somewhat verifiable as it provides a specific example of an assumption that is considered natural in machine learning settings, which partially supports the reviewer\\'s concern. However, it lacks detailed reasoning or references to substantiate the claim fully. The second claim is fully verifiable as it points out a specific error in the sign of an inequality, providing a clear and logical basis for the critique. Overall, the comment is mostly verifiable, as it provides some support for one claim but lacks detailed justification for the other.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on two distinct issues. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is somewhat helpful as it challenges the authors to reconsider the significance of their assumptions. However, it could be more actionable if it provided guidance on how to address this concern or what additional assumptions might be considered. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a clear and actionable suggestion that the authors can easily address. Overall, the comment is mostly helpful as it provides specific feedback on one actionable issue but could be more comprehensive in addressing the other concern.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values. It also recommends including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. However, the comment does not specify how the authors should conduct this comparison or what specific aspects of the transformation should be discussed. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to compare Shapely values with other methods, such as CaCE or raw gradients, to support their argument. It also recommends including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. However, the comment does not specify which part of the paper this comparison or discussion should be included in, making it weakly grounded. The comment is specific in its suggestions, but the lack of grounding makes it difficult for the authors to identify the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. It also recommends including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the argument. The feedback is somewhat verifiable as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a need for the authors to provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values. It also suggests including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the comparison or what aspects of the transformation should be discussed. This feedback is somewhat helpful as it highlights important areas for the authors to address but could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, leaving the authors to infer that it should be done in the context of the related work or discussion section. This lack of specific guidance makes the comment weakly grounded. Additionally, the comment is specific in suggesting a comparison to prior efforts, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the related work section could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is somewhat helpful as it identifies a potential area for improvement, specifically in enhancing the discussion of related work. However, the comment lacks specific guidance on how to implement this suggestion, such as providing examples of prior work or outlining the comparison criteria. Without these details, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current number is fixed at 200. However, the comment does not provide explicit guidance on how to conduct this examination or what specific scenarios to consider. While the suggestion is clear, it lacks concrete details on how to implement the analysis, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining the performance with different numbers of scenarios, implying that the current number of scenarios (200) might be fixed. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or table. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting an analysis of performance with varying numbers of scenarios, but without clear guidance on how to do this. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of the paper is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion that the performance is closely related to the number of scenarios. As a result, the claim is not verifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the performance of the paper might be closely related to the number of scenarios used for training. It recommends examining the performance with different numbers of scenarios, noting that the current number is fixed at 200. This feedback is somewhat helpful as it identifies a potential area for further investigation that could provide additional insights into the robustness and generalizability of the results. However, the comment lacks specific guidance on how to conduct this examination or what specific scenarios to consider, which limits its impact on the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model's ability to predict it. It also suggests considering the impact of disturbances in the training data on the model's performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what actions they should take to improve their draft. The feedback is vague and lacks concrete details, making it difficult for the authors to understand how to respond or incorporate the suggestions. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between generating a quality label and the model's ability to predict it, suggesting that disturbances in the training data might affect the model's performance. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the impact of disturbances, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model's ability to predict it, specifically questioning whether disturbances in the training data might affect the model's performance. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or logical reasoning to substantiate the concern, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the relationship between generating a quality label and the model's ability to predict it. It suggests considering the impact of disturbances in the training data on the model's performance, which is a valuable point for the authors to consider. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue or what actions they should take to improve their draft. While it identifies an important area for consideration, the feedback is somewhat limited in its scope and depth, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point describes the experiments conducted by the authors to validate the efficacy of CATER in different settings, such as an architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might improve their draft or address any specific issues related to the experiments. As a result, the authors are left without any actionable feedback, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the experiments conducted, providing clear guidance on what aspects of the work are being validated. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point describes the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. However, it does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, providing no basis for the authors to critique or improve their work. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment describes the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. While this provides some context for the experiments, it does not offer any suggestions for improvement or highlight potential weaknesses in the methodology or results. The comment lacks actionable feedback, making it unhelpful for the authors to enhance their draft. Therefore, it aligns with a score of 1, as it does not provide any meaningful guidance or suggestions for improvement.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors\\' claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors would need to infer that they need to clarify or revise their claims to better reflect the strategic nature of their setting. The comment is vague and lacks concrete details on how to implement the suggested improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. However, the comment does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique of the strategic nature of the setting, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the authors\\' claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. This critique is based on a logical assessment of the paper\\'s content and the authors\\' claims. However, the comment lacks specific examples or references to support the claim that the opponent does not behave strategically. Without detailed evidence or examples, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the authors to consider but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. This feedback is somewhat helpful as it highlights a specific area that needs clarification or revision. However, the comment lacks depth and does not provide detailed guidance on how the authors might address this issue or what specific changes they should make to their draft. The feedback is somewhat helpful because it points out a potential weakness, but it could be more actionable with additional suggestions or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Appendix A.2 does not illustrate the state space representation of the environment clearly. While it points out a specific area that needs improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the representation in the appendix, but without specific suggestions or examples, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies a need for improvement but lacks concrete guidance on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Appendix A.2,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies that the appendix does not illustrate the state space representation of the environment clearly, offering a clear and specific critique. This allows the authors to understand exactly what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation illustrated in Appendix A.2. This feedback is clear and actionable, as it directs the authors to improve the clarity of their appendix. However, the comment lacks broader context or suggestions on how to enhance the clarity, such as providing more detailed explanations or examples. While it points out a specific area for improvement, it does not offer a comprehensive guide for the authors to address the issue effectively. Therefore, the comment is somewhat helpful, as it provides a clear direction but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might adapt their approach or what changes could be made to make it applicable to larger problems. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors' approach is only applicable to small or medium-scale problems, implying that it may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, the comment does not specify which part of the paper this issue is discussed or addressed, leaving the authors uncertain about the exact section or aspect that needs attention. Additionally, the comment lacks specificity in detailing what changes or adaptations could be made to make the approach applicable to larger problems. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the authors\\' approach, noting that it is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. This feedback highlights a potential constraint on the applicability of the authors\\' work, which could be valuable for the authors to consider in future iterations of their research. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or adapt their approach for larger problems. Without actionable advice or examples, the comment is somewhat helpful, as it points out a critical area for improvement but does not provide a comprehensive roadmap for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the restrictive nature of the bounded noise assumption in stochastic optimization literature and mentions several efforts to extend these noise conditions, citing specific works. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative assumptions or exploring the cited works. The comment lacks concrete guidance on how the authors might address the issue or incorporate the suggested references. As a result, the authors are left without clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounded noise assumption in stochastic optimization literature, referencing specific works that extend these noise conditions. However, it does not specify which part of the paper discusses this assumption or how it relates to the authors' work. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment mentions specific works, it does not provide detailed guidance on how these works could be integrated or discussed in the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and suggests that there have been efforts to extend these noise conditions, citing specific works. However, the comment does not provide detailed reasoning or examples to support this claim. It lacks specific evidence or references that would allow the authors to understand the extent of the restriction or the significance of the suggested extensions. As a result, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the bounded noise assumption, which is a common assumption in stochastic optimization literature. It suggests that this assumption might be restrictive and points to several efforts to extend these noise conditions, citing specific works. However, the comment does not provide detailed guidance on how the authors might address this limitation or incorporate the suggested references into their work. While it highlights an important aspect of the literature, the feedback lacks actionable steps or suggestions for improvement, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the motivation need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not specify which part of the paper discusses this motivation, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is specific in identifying the issue but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the overall motivation of using characteristic function regularization is not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the motivation is unclear or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the motivation behind using characteristic function regularization. However, it lacks specific details or suggestions on how the authors might address this issue or what aspects of the motivation need clarification. Without actionable guidance or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It claims that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the paper or what specific aspects need to be addressed to enhance the contribution. As a result, the comment is unactionable, as the authors are left without a clear path forward to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the combination of existing techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a detailed description of the techniques used and suggests that the combination of these techniques is not surprising, implying that the contribution might be incremental. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or evidence to substantiate the assertion that the combination of these techniques is not surprising or that the contribution is incremental. As a result, the claim is unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by suggesting that the combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, might not be surprising. This observation implies that the contribution of the paper could be considered incremental. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address this concern or enhance the novelty of their work. While it raises a valid point about the incremental nature of the contribution, it lacks depth and guidance, making it somewhat helpful. The authors would need to infer what steps to take to improve their draft, which limits the comment's helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the aggregation operation after \"Integration\" needs further clarification. It also provides a concrete action by instructing the authors to provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This direct and specific guidance allows the authors to understand exactly what needs to be addressed and how to implement the suggested changes. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiscale modeling\" and \"Integration,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified, namely the aggregation operation after \"Integration\" and the need for more details in the main paper. The comment also suggests acknowledging the structure of other architectures if they are referred to, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification. While it provides a general direction for improvement, it lacks specific details or examples to guide the authors on how to clarify the operation. Without additional context or suggestions, the authors may find it challenging to understand what specific aspects require clarification. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks the depth needed for full clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for further clarification on the aggregation operation after \"Integration.\" It provides a clear and actionable suggestion by instructing the authors to provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is specific and directly addresses a potential weakness in the paper, offering a clear path for improvement. However, the comment could be more helpful if it provided additional guidance on how to clarify the aggregation operation or suggested specific examples of where the clarification is needed. Overall, the comment is mostly helpful as it effectively guides the authors toward enhancing the clarity of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies several writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific guidance or suggestions on how the authors should address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to resolve the identified issues. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies several writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections or parts of the paper are affected by these issues, making it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity in detailing what needs to be addressed to resolve these issues. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide any specific examples or references to support these claims. Without detailed examples or references, the authors may find it challenging to understand the nature and extent of the issues. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies significant writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it lacks specific details or suggestions on how the authors might address these issues. While it highlights areas for improvement, the comment does not provide actionable guidance or examples of how to correct the identified problems. This limits the authors' ability to effectively improve their draft, making the comment somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit instructions for the authors to address specific issues in their figures and tables. It instructs them to run experiments for untrained networks and add these results to the figures and Table 1. Additionally, it requests clarification on whether the figures show results for networks trained on random data or unaltered data, and whether the non-random data is normalized. The comment also suggests showing examples of random data in the appendix. These instructions are clear and provide concrete guidance on what needs to be done, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3) mentioned above,\" which implies a specific part of the paper being addressed. It also specifies what needs to be addressed, such as running experiments for untrained networks and adding results to figures and Table 1. The comment further requests clarification on whether the figures show results for networks trained on random data or unaltered data, and whether the non-random data is normalized, suggesting the inclusion of examples in the appendix. This level of detail provides clear guidance for the authors to improve their draft, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request to run experiments for untrained networks and add the results to figures and Table 1, and a request for clarification on the data used in the figures. The first part is a clear instruction, but it lacks specific examples or references to support the claim that these results are important. The second part is also a request for clarification, which does not require verification. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on areas that need improvement in the paper. It requests the authors to run experiments for untrained networks and add the results to figures and Table 1, which is a clear and direct suggestion for enhancing the completeness of the results. Additionally, the comment requests clarification on the data used in the figures, specifically whether the networks are trained on random data or unaltered data, and whether the non-random data is normalized. This feedback is detailed and constructive, guiding the authors to address specific issues and improve the clarity and completeness of their work. Therefore, the comment is mostly helpful, as it offers clear and actionable suggestions that would significantly enhance the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. It does not provide an explicit action or suggestion for the authors to take, such as clarifying the definition of \"100 steps\" or providing additional context. The comment is vague and lacks concrete guidance on how the authors should address this issue. Therefore, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a factual question seeking clarification, and it does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically questioning whether it refers to 100 sampled strategies. This is a clear and direct inquiry that could help the authors clarify a potential ambiguity in their methodology or experimental setup. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as suggesting alternative interpretations or providing additional context. While it identifies a potential area of confusion, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, suggesting that the authors should consider this in their work. However, the comment does not provide explicit guidance on how the authors should explore energy models or how they should address the similarity to the prior VAE paper. The action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, suggesting that the authors should consider this in their work. However, the comment does not specify which part of the paper discusses the related work or the exploration of energy models, making it weakly grounded. The comment is specific in suggesting that the authors should explore energy models and address the similarity to the prior VAE paper, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that energy models for image generation are less explored compared to GANs and VAEs, suggesting that exploring them further is a promising direction. It also notes that the motivation and goals of the model are similar to a prior VAE paper, implying that the authors should consider this in their work. However, the comment lacks specific examples or references to support the claim about the relative unexploredness of energy models, making it somewhat verifiable. The suggestion to address the similarity to the prior VAE paper is clear, but the lack of detailed reasoning or evidence weakens the overall verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, which could help the authors contextualize their work. However, the comment lacks specific guidance on how the authors should explore energy models or how they should address the similarity to the prior VAE paper. While it provides a direction for future work, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity in its recommendations.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the improvement over previous methods is small, around 0.2%-1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The authors are advised to repeat the experiments and conduct statistical significance analysis. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The suggestion is implicit and somewhat vague, as it lacks specific instructions on how to report the mean and standard deviation or how to conduct the statistical significance analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the results, such as the lack of reporting of mean and standard deviation and the difficulty in assessing statistical significance. The suggestion to repeat experiments and conduct statistical significance analysis is clear and provides a concrete action for the authors to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement over previous methods is small, about 0.2%-1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The comment suggests repeating experiments and conducting statistical significance analysis. However, the claim lacks specific examples or references to support the assertion about the small improvement or the absence of mean and standard deviation reporting. While the suggestion to improve the paper is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper, noting that the improvement over previous methods is marginal, with a range of 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 lack the reporting of mean and standard deviation, making it difficult to assess the statistical significance of the findings. The comment suggests repeating the experiments and conducting statistical significance analysis, which are actionable steps for the authors to take. However, the comment could be more helpful if it provided specific guidance on how to conduct the statistical analysis or what statistical tests to use. Despite this, the feedback is mostly helpful as it directs the authors towards improving the rigor and clarity of their results.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the method should be evaluated on a different benchmark, such as Atari, to assess its generalizability to other domains. It provides a clear and concrete action for the authors to take, which is to run experiments on this new benchmark. This guidance is specific and detailed, allowing the authors to understand exactly how to apply the suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on a single domain and suggests running experiments on a different benchmark, such as Atari, which is a common practice in the literature. This provides clear guidance on which part of the paper needs improvement. The comment is also specific, as it specifies the need to evaluate the method on a different benchmark to assess its generalizability and performance with discrete action spaces and high-dimensional observations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is evaluated only on the Meta World domain, making it difficult to judge its generalizability to other domains. The suggestion to run experiments on a different benchmark, such as Atari, is logical and provides a clear rationale for why this additional evaluation would be beneficial. The comment is mostly verifiable as it offers a logical and well-reasoned suggestion, but it could be strengthened by providing more specific examples or references to similar studies. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the method. It highlights the limitation of evaluating the method on a single domain, specifically the Meta World robotic manipulation domain, and suggests running experiments on a different benchmark, such as Atari, to assess the method's generalizability. This recommendation is well-supported and provides a concrete direction for the authors to enhance the robustness and applicability of their work. By addressing the issue of generalizability, the comment offers valuable guidance that could significantly improve the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the model's behavior should be examined. The comment is somewhat vague, as it lacks concrete details on how to implement the suggested analysis. Therefore, the comment is somewhat actionable, as it identifies a potential improvement but does not provide detailed instructions on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in or what aspects of the model's behavior should be examined. The comment lacks grounding as it does not provide clear guidance on which section or part of the paper needs attention. It is also specific in suggesting the inclusion of an analysis, but without detailed guidance on how to conduct it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include an analysis of what the model does, which could be interesting. However, the comment lacks specific details or examples to support this suggestion, making it difficult for the authors to understand how to implement or expand upon it. Without clear guidance or references, the claim remains somewhat verifiable, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors include an analysis of what the model does, which could be interesting. However, the comment lacks specific guidance on how to conduct this analysis or what aspects of the model's behavior should be examined. While it points out a potential enhancement, it does not provide detailed suggestions or examples, making it somewhat helpful. The feedback is incomplete and could be more actionable with additional details, but it does offer a direction for improvement. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the task setup description, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. While the comment identifies a specific issue with the clarity of the task setup, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify these aspects in their draft, but the action is not concrete or detailed. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but lacks explicit instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the task setup description, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper discusses the task setup, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the input notes in the EHR and the distance of the outcomes from the last note date. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the task setup is not described clearly, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or references, the authors are left to assume the claim is valid, which makes it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the task setup description in the paper. It points out that the authors need to clarify which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and completeness of their paper. However, the comment could be more helpful if it suggested specific ways to improve the clarity or provided examples of how to present this information effectively. Overall, the comment is mostly helpful, as it directs the authors to a critical area for revision, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the convergence rate of the proposed algorithm DMLCBO compared to previous works that utilize the double momentum technique. It suggests that the authors should discuss the reasons for this difference and the theoretical technique differences between DMLCBO and the mentioned works. While the comment provides a clear direction for the authors to address the issue, it does not specify how to analyze the convergence rate or the theoretical differences. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the suggested discussion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and its basis in the double momentum technique, referencing specific previous works, SUSTAIN[1] and MRBO[2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of the convergence rate discrepancy and encourages the authors to discuss the reasons and theoretical differences between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO, based on the double momentum technique, does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO, which achieve $\\mathcal{\\widetilde O}(\\epsilon^{-3})$. The comment suggests that the authors should discuss the reasons for this discrepancy and the theoretical differences between DMLCBO and the mentioned works. However, the claim lacks specific examples or detailed reasoning to fully support the assertion. While the authors might infer the need for such a discussion, the comment does not provide sufficient evidence or guidance to make it fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed algorithm DMLCBO, noting that it does not achieve the same convergence rate as previous works that utilize the double momentum technique. It encourages the authors to discuss the reasons for this discrepancy and the theoretical differences between DMLCBO and the mentioned works. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the theoretical limitations of their algorithm. However, the comment could be more helpful if it offered additional guidance on how to analyze the convergence rate or suggest specific areas for theoretical exploration. Overall, the comment is mostly helpful, as it effectively highlights a critical aspect of the algorithm that needs further discussion and analysis.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the approach section is missing in the main paper, which is a clear indication of an action the authors should take. It also suggests that the supplementary material should be used as additional information rather than an extension of the paper. This feedback provides a direct and concrete action for the authors to improve their draft by ensuring all necessary sections are included and properly integrated. The comment is fully actionable as it clearly specifies what needs to be addressed and how to do it. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part being addressed. It also specifies that the supplementary material should be used as additional information rather than an extension of the paper, providing clear guidance on what needs to be addressed. This level of detail ensures that the authors understand exactly what part of the paper requires revision and how to do it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach section is missing in the main paper, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The comment lacks detailed reasoning or evidence, which could be improved by providing specific examples or references. Therefore, the claim is considered borderline verifiable, as it is somewhat supported but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the draft, specifically noting the absence of an \"approach section\" in the main paper. It also suggests that the supplementary material should be treated as additional information rather than an extension of the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it included suggestions for how to integrate the supplementary material or how to ensure the main paper is comprehensive. Despite this, the comment is mostly helpful as it highlights a critical oversight and offers a clear path for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should revise the statement or what specific changes are needed to make it more robust. While the authors can infer that they should strengthen the statement, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not specify which part of the introduction contains this statement, making it difficult for the authors to pinpoint the exact area that needs revision. While the authors can infer that the critique applies to the introduction, the lack of explicit grounding makes the comment weakly grounded. The comment is specific in its critique of the statement's weakness, but without clear grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, suggesting that it is widely accepted that backpropagation is biologically implausible. This claim is somewhat verifiable as it provides a logical reasoning that the statement is weak and lacks depth. However, it does not offer specific examples or references to support the claim, which could enhance its persuasiveness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the introduction, noting that the statement regarding the biological plausibility of backpropagation is too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it provides a direct critique of the statement and suggests that it should be strengthened to better reflect the established understanding in the field. By highlighting this discrepancy, the comment offers a clear direction for improvement, allowing the authors to enhance the accuracy and depth of their introduction. Therefore, the comment is mostly helpful, as it provides a clear and constructive suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide explicit guidance on how the authors might address these issues or what specific actions they should take to improve the modulator. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to understand how to apply it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not specify which part of the paper discusses the modulator or where the issue of scalability is addressed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific in its critique of the modulator's design, the absence of explicit references or grounding weakens the overall impact. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the heuristic design of the modulator, suggesting that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the heuristic design of the modulator, specifically questioning its scalability and the need for tedious hyperparameter tuning for diverse training data. This feedback highlights a concern that could impact the practical applicability and robustness of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the modulator's design. While it points out a potential weakness, it does not provide actionable steps or detailed insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it raises a valid concern but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might be impractical for less informed functions like f_R/f_P. However, it does not provide explicit guidance on how the authors should address this issue or what changes could be made to the experiments to reduce the reliance on domain knowledge. The action is implicit and vague, as it does not specify how the authors can incorporate less domain knowledge or what experiments could be modified. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"f_R and f_P\" and \"experiments performed here,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the issue of incorporating domain knowledge into the structure of the experiments, suggesting that less informed functions might require impractical amounts of data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might be impractical for less informed functions like f_R/f_P. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experiments performed in the paper, specifically noting that they incorporate a significant amount of domain knowledge. This observation is insightful and could guide the authors in refining their experimental design to make it more generalizable or applicable to less informed functions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what changes could be made to the experiments. While it highlights a valuable point, the feedback could be more helpful if it provided actionable advice or examples of how to reduce the reliance on domain knowledge. Therefore, the comment is somewhat helpful, as it offers a clear observation but lacks detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of imitation learning, suggesting that obtaining labeled data through optimal problem-solving is necessary. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to conduct experiments or analyze the impact of labeled data size. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the necessity of obtaining labeled data for imitation learning, suggesting that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its critique, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the necessity of obtaining labeled data for imitation learning and suggests that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of imitation learning, specifically the need for labeled data obtained through optimal problem-solving. It highlights the absence of experiments exploring the difficulties in obtaining this data and how performance might vary with the size of the labeled data. This feedback is somewhat helpful as it points out a gap in the experimental evaluation and suggests areas for further investigation. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what kind of analysis would be beneficial. Overall, the comment offers a clear direction for improvement but lacks detailed suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment identifies a potential issue with the paper, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The suggestion is implicit, as it implies that the authors should explore the connection between generalization bounds and the constructions of ReLU networks. However, the lack of concrete steps or detailed guidance makes the comment somewhat actionable. Therefore, it aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its questioning of the connection between memorization and generalization, the absence of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. The comment suggests that the paper does not clearly address this connection, implying that the authors should explore the relationship between generalization bounds and the constructions of ReLU networks. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to fully address the concern raised in the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. This is a significant concern that could impact the paper's conclusions. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. It does not provide specific steps or insights that could help the authors improve their draft, leaving them with a vague understanding of the problem. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's exploration of the proposed method's implications for other NLP tasks is limited, which somewhat limits the generalizability of the results. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore the method's implications for other NLP tasks. The action is implicit and vague, as it does not specify how the authors can enhance the exploration of the method's implications. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"contrastive learning in code search tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation highlights a potential gap in the generalizability of the results, which could limit the impact of the paper. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or expand the scope of their exploration. While it identifies an important area for improvement, the lack of actionable advice makes the comment somewhat helpful, as it provides a clear direction for the authors to consider but does not fully empower them to enhance their work. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It suggests that the term might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It does not specify whether the authors should consider alternative terminology or provide a clearer explanation of the term's usage in their context. Without concrete suggestions or actions, the authors are left without a clear path to resolve the potential misinterpretation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the use of the term \"certificate\" in the paper, particularly at line 267. It highlights a potential misinterpretation due to the strong meaning of \"certificate\" in complexity theory. However, the comment does not provide specific guidance on how the authors should address this issue or suggest alternative terminology. The authors can infer that the comment pertains to the specific section or part of the paper where line 267 is located, but the lack of explicit mention makes it weakly grounded. The comment is specific in identifying the issue with the terminology but lacks guidance on how to resolve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without detailed reasoning or evidence, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the use of the term 'certificate' in the paper, specifically at line 267, noting that its strong meaning in complexity theory might lead to misinterpretation. While the comment highlights a valid concern, it does not provide any suggestions or guidance on how the authors might address this issue. Without actionable advice or alternative terminology, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential problem but lacks depth and constructive suggestions.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. While the comment provides a clear action\u2014mentioning and comparing with untrained neural networks\u2014it does not specify how to implement this comparison or where in the paper this discussion should be included. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OOD experiments\" and \"imaging in the recent few years,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests mentioning and comparing the current method with untrained neural networks used for solving inverse problems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. This claim is somewhat verifiable as it provides a specific example of a relevant area for comparison, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would benefit from additional context or references to fully understand the implications of this comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper, namely the discussion of out-of-distribution (OOD) experiments. It suggests that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. This feedback provides a clear direction for the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it included specific guidance on how to integrate this comparison into the paper or suggested additional relevant literature. Overall, the comment offers valuable insights and actionable feedback, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method's performance should be evaluated on real data where barycenters can be used, which would be interesting to demonstrate. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to incorporate real data into their experiments. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments being limited to toy data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, suggesting that the method's performance should be evaluated on real data where barycenters can be used. This provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited to toy data and suggests evaluating the method's performance on real data where barycenters can be used. This is a subjective observation and suggestion for improvement, but it lacks specific examples or references to support the claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method's performance should be evaluated on real data where barycenters can be used, which would be interesting to demonstrate. This feedback is somewhat helpful as it points out a specific area for improvement and encourages the authors to consider expanding their experiments to real-world scenarios. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or suggested specific real-world datasets to use. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should conduct additional experiments to include these network structures. However, the comment does not explicitly instruct the authors to perform these experiments or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments with these network structures. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to specific works, which helps the authors understand the context and relevance of the suggested experiments. However, the comment does not specify which part of the paper these additional experiments should be conducted in or how they should be integrated. This makes the comment weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting the need for additional experiments and providing references, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to specific works that include these network structures, which supports the claim that additional experiments would enhance the paper. However, the comment lacks detailed reasoning or examples of how these additional experiments would specifically strengthen the paper. While the references provide some context, the authors may need to infer the connection between the suggested experiments and the paper's content. Therefore, the claim is somewhat verifiable, as it is supported by references but lacks detailed reasoning or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should conduct additional experiments to include these network structures. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects of the paper would benefit from these additional experiments. While it offers a direction for improvement, the feedback is somewhat vague and could be more helpful if it included detailed suggestions or examples of how to integrate these experiments into the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. While it highlights a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need to be explained. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the mechanism and its impact on label distribution. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or aspect that needs clarification. The comment is specific in its critique of the mechanism's effectiveness but lacks grounding as it does not provide explicit references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left to infer the basis of the critique, making it difficult to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed sample selection mechanism, specifically questioning its effectiveness in preserving label distribution. This feedback highlights a critical aspect of the methodology that needs clarification or further explanation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed insights into how the authors could improve their approach. As a result, the comment is somewhat helpful, as it raises an important concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the evaluation of the results, noting that while the analysis is detailed and comprehensive, it only considers two relatively old and small models. This feedback provides a clear and explicit action for the authors to take, which is to expand the evaluation to include more recent and larger models. The comment is specific in its suggestion, offering a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results/analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the evaluation is limited to two relatively old and small models, which the authors can address by expanding their evaluation to include more recent and larger models. This provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results/analysis, despite being detailed and comprehensive, are limited to only two relatively old and small models. This claim is somewhat verifiable as it provides a specific observation about the scope of the evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors could benefit from additional context or examples to better understand the limitations of the evaluation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the evaluation of the results, noting that despite being detailed and comprehensive, the analysis is limited to only two relatively old and small models. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors should expand their evaluation to include more recent and larger models. By addressing this suggestion, the authors can enhance the comprehensiveness and relevance of their analysis, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, making the motivation of Algorithm 1 unclear. However, it does not provide explicit guidance on how the authors should reformulate the subproblem or how this reformulation would clarify the motivation of Algorithm 1. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the prox-linear subproblem in Eq.(1) and suggests that it can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This provides a clear and specific reference to the part of the paper being discussed, allowing the authors to accurately identify the section being addressed. The comment is fully grounded as it explicitly mentions the equation and algorithm, and it is specific because it details the suggestion for reformulation and its implications for the motivation of Algorithm 1. Therefore, this comment is classified as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This claim is somewhat verifiable as it provides a specific suggestion for reformulation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to understand the implications of this reformulation to fully grasp the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, making the motivation unclear. While the comment points out a specific area that could be improved, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it highlights a potential weakness in the paper's motivation, but it lacks actionable advice on how to resolve it. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting how to incorporate this perspective into their work or discussing the implications of this view. The comment lacks concrete guidance on how the authors might address this point or integrate it into their draft. Therefore, the comment is not actionable, as it does not provide any direction for the authors to improve their work.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a claim about the relationship between KD and LS, but without referencing specific sections, tables, or figures, the authors cannot determine where this discussion is relevant. The comment is also not specific because it does not detail what needs to be addressed or how the authors should approach the relationship between KD and LS. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a belief that KD can be viewed as a special form of LS under specific conditions. However, it lacks detailed reasoning or examples to support this claim. Without specific references or logical reasoning, the authors may find it challenging to understand and address the point effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment expresses a belief that KD can be viewed as a special form of LS under specific conditions, particularly when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment does not provide any actionable feedback or suggestions on how the authors might incorporate this perspective into their work or discuss the implications of this view. It lacks depth and does not offer any guidance on how the authors could address this point or improve their draft. As a result, the comment is not helpful to the authors, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. While the comment provides a clear direction for improvement, it does not specify which specific methods should be included or how the results should be presented. The action is explicit but somewhat vague, as it lacks detailed guidance on the implementation of the suggested changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the year 2021 and the concept of \"Competing dynamic-pruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to include more recent works and results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. However, the comment lacks specific references or examples to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the authors should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to better verify the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it included suggestions on which specific methods or datasets to include or how to present the additional results effectively. Despite this, the comment offers valuable guidance that can significantly improve the paper, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to provide an explanation for the degradation in performance of the FBN results when additional information is included. While it prompts the authors to address this issue, it does not explicitly instruct them on how to do so. The action is implicit, as the authors need to infer that they should provide an explanation for the observed performance degradation. However, the comment lacks specific guidance on what aspects of the additional information might be causing the degradation or how to analyze it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to provide an explanation for the degradation in performance when additional information is included, which is a clear and actionable request. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the degradation in FBN results when additional information is included. It does not contain a subjective claim or suggestion but rather poses a question that requires the authors to provide an explanation or analysis. Since the comment is a question rather than a statement that requires verification, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the FBN results, noting that the performance degrades when additional information is included. This observation is clear and highlights a potential area for further investigation or clarification. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their results. While it points out a problem, it lacks actionable advice or insights that could help the authors enhance their work. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not offer substantial guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific sections of the paper that are hard to read and points out a lack of clarity in the explanation of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. However, the comment does not offer any explicit or implicit suggestions on how to improve the clarity of these sections. The authors are left without guidance on how to address these issues, making the comment unactionable. Therefore, the comment aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises specific questions about the clarity of certain sections in the paper, particularly regarding the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. While the questions highlight areas where the authors may need to improve their explanations, they do not provide any additional context, reasoning, or references to support the claims made. The lack of detailed explanation or justification makes it difficult for the authors to fully understand the issues being raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies specific sections of the paper that are difficult to read, particularly the first two sections. It highlights a lack of clarity in the explanation of previous approaches, specifically mentioning issues with the conversion of a stacked LSTM to a sequential LSTM and the meaning of certain variables in a figure. The comment provides detailed examples of where the authors fail to explain these concepts, such as the unclear explanation of why the stacked LSTM is 'trivial' to convert and the confusion surrounding the variables h_{t-1}^{1..5} and h_{t-1} in Figure 2(b). However, the comment does not offer any suggestions or guidance on how the authors might improve the clarity of these sections. While it points out areas needing improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the captions should be more descriptive and that the authors should explain the \"scramble network\" better. While the comment provides explicit guidance on what needs to be improved, it lacks specific details on how to make the captions more descriptive or how to explain the \"scramble network\" better. The authors are left with a general idea of what to do but without concrete steps to follow. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests making the captions more descriptive and explains the \"scramble network\" better. However, it does not specify which parts of the paper these captions or explanations are located in, making it weakly grounded. The comment is specific in its suggestions regarding the need for more descriptive captions and a clearer explanation of the \"scramble network,\" but without explicit references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the captions should be more descriptive and that the authors should explain the \"scramble network\" better. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the need to make figure captions more descriptive and to explain the \"scramble network\" better. This feedback is actionable, as it directs the authors to improve the clarity and comprehensibility of their figures and the explanation of a key concept. However, the comment could be more helpful if it offered additional guidance on how to make the captions more descriptive or how to explain the \"scramble network\" effectively. Despite this, the feedback is mostly helpful as it identifies areas for improvement and provides a clear direction for the authors to follow, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that while the choice might be interesting, it is not well-motivated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the task are interesting. The action is implicit and vague, as it leaves the authors to infer that they need to provide a clearer motivation for their choice. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the motivation, but without explicit references to sections or figures, the authors cannot confidently determine where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. While the reviewer suggests that this choice is not well-motivated, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this particular choice is problematic or how it could be improved. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that while the choice might be interesting, it is not well-motivated. This feedback highlights a potential gap in the paper's justification for the experimental setup. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the motivation for their choice. While it identifies a concern, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve the motivation, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper argues that the proposed method finds flat minima but lacks an analysis of flatness. It highlights that minimizing the averaged loss across noise-injected models does not guarantee flatness and suggests that an analysis of the losses of the noise-injected models after training is required to support the claim. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the losses of the noise-injected models. The comment is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the analysis of flatness is missing, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the analysis, stating that minimizing the averaged loss across noise-injected models does not ensure the flatness of the minima and that an analysis of the losses of the noise-injected models after training is required. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper argues that the proposed method finds flat minima but lacks an analysis of flatness. It highlights that minimizing the averaged loss across noise-injected models does not ensure the flatness of the minima and suggests that an analysis of the losses of the noise-injected models after training is required. This claim is somewhat verifiable as it provides a logical reasoning for why the analysis is missing and suggests a specific area for improvement. However, it lacks detailed examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that while the paper claims the proposed method finds flat minima, it lacks an analysis of flatness. The reviewer provides a clear explanation of why the current analysis is insufficient, specifically noting that minimizing the averaged loss across noise-injected models does not guarantee flatness. The comment suggests that an analysis of the losses of the noise-injected models after training is necessary to support the claim. This feedback is highly actionable and constructive, as it provides a specific and actionable suggestion for the authors to improve their draft by including the required analysis. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the readability of the text within a figure and its labels, suggesting that the text should be of the same size as the manuscript text. This feedback is explicit, as it directly instructs the authors to address the issue by adjusting the size of the text. It is also concrete, as it provides a clear and specific action to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the readability of the text within a figure and its labels, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the text should be roughly the same size as the manuscript text. This provides clear guidance on how to improve the figure and labels. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the readability of the text within a figure and its labels. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the text within a figure and its labels, noting that the text is too small to read without zooming. It suggests that the text should be roughly the same size as the manuscript text. This feedback is clear and actionable, providing the authors with a direct and specific direction to improve the presentation of their work. By addressing this issue, the authors can enhance the clarity and accessibility of their figures, which is crucial for effective communication. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the motivation behind the paper is not clear and suggests that the introduction should be revised to make the paper easier to follow. While the comment identifies a potential issue with the clarity of the motivation, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should revise the introduction to improve clarity. However, the comment lacks concrete details on what aspects of the motivation are unclear, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction or the paper is unclear, leaving the authors to infer that it pertains to the introduction. This lack of specific grounding makes it difficult for the authors to pinpoint the exact area that needs revision. Additionally, the comment does not provide specific details on what aspects of the motivation are unclear, further limiting its specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific details or examples to support this claim. It does not provide any evidence or reasoning to justify why the motivation is unclear or how the introduction could be revised to improve clarity. Without such support, the claim remains unsubstantiated, making the comment unverifiable. Therefore, the comment aligns with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the motivation in the paper, suggesting that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it lacks specific guidance on how to revise the introduction or what aspects of the motivation need clarification. This feedback is somewhat helpful as it points out a crucial weakness, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of multiple local prompts, suggesting that while it is intuitive, the features and their positions vary across different categories. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider the variability in features and positions, but it lacks concrete instructions on how to implement this consideration. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of using multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the variability in features and positions, but the lack of grounding makes it challenging for the authors to understand where to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that while it is intuitive that including multiple local prompts helps, the features and their positions are not the same for different categories. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the consistency of feature representation across categories. While it points out a valid concern, the feedback could be more helpful if it provided actionable advice or examples of how to implement the suggested improvements. Therefore, the comment is somewhat helpful, as it identifies a meaningful issue but does not fully guide the authors in addressing it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might validate the alignment or what specific steps they should follow to ensure it is sufficiently validated. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or aspect of the paper is being referred to, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to validate the alignment or what steps should be taken to address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments remains insufficiently validated. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, noting that it remains insufficiently validated. This feedback is clear and actionable, as it highlights a potential weakness in the methodology or experimental setup that could impact the reliability of the results. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as proposing specific validation methods or additional experiments. Overall, the comment is somewhat helpful as it points out a critical area for improvement, but it lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It also recommends improving the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment provides explicit suggestions for improvement, such as replacing natural language with notation and adding diagrams, it does not specify how to implement these changes or what specific aspects of the presentation need improvement. The action is somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. However, the comment does not specify which part of section 4 is particularly challenging or where the complexity lies, making it difficult for the authors to pinpoint the exact areas that need improvement. While the suggestion to improve presentation is clear, the lack of specific guidance on which parts to focus on makes the comment weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. However, the comment lacks specific examples or detailed reasoning to support the claim that the model is complicated or that these changes would effectively improve the presentation. Without concrete evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis for the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the model and suggests ways to improve its presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This feedback is actionable and provides specific suggestions for enhancing the clarity and effectiveness of the model's presentation. By offering concrete improvements, the comment empowers the authors to address the identified weakness and potentially enhance the overall quality of their work. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how the changes might look. Overall, the comment is mostly helpful, as it offers clear and actionable feedback that guides the authors in improving their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that the experiments are conducted on a limited number of molecules and only include in-distribution testing. The reviewer suggests that the value of the method might be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors might address this issue or what steps they should take to improve the method. The action is implicit and vague, as it does not specify how the authors can overcome the limitation or what changes they should make to the method. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of limited experiments on a small number of molecules and the lack of in-distribution testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the limitation of the experiments and suggests that the value of the method might be limited if it requires training for each molecule individually. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only conducts experiments on a limited number of molecules and only provides in-distribution testing. This is a factual observation about the scope of the experiments. However, the comment does not provide any reasoning, examples, or references to support why this limitation is significant or how it might impact the value of the method. Without additional context or justification, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that the experiments are conducted on a limited number of molecules and only include in-distribution testing. This observation is clear and highlights a potential constraint on the method's value. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the scope of their experiments. While it points out an important issue, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the symbols used in the paper are complex and time-consuming to understand. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might simplify the symbols or make them more accessible to readers. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the symbols used in the paper are complex and time-consuming to understand. However, it does not specify which part of the paper contains these symbols or how they are used. This lack of grounding makes it difficult for the authors to pinpoint the exact issue and address it effectively. Additionally, the comment is specific in its critique of the complexity of the symbols, but without grounding, it does not provide clear guidance on how to improve the clarity of the symbols. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the symbols used in the paper are \"a little bit complicated and takes a lot of time to understand.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the symbols used in the paper, noting that they take a lot of time to understand. While this feedback highlights a specific area for improvement, it lacks actionable guidance or suggestions on how the authors might simplify or clarify these symbols. Without concrete advice or examples, the authors may find it challenging to address this issue effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide sufficient detail to guide the authors in making changes. The score of 3 aligns with this assessment.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a specific part of the paper (Figure 3) and highlights an area of confusion, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to clarify the source of the test data and the presence of a ground truth. However, the action is implicit and somewhat vague, as it does not offer concrete steps on how to resolve the confusion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line in Figure 3, questioning the source of the test data and the presence of a ground truth. This provides the authors with a clear understanding of what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. This is a factual question that requires clarification but does not contain any subjective opinions or claims that need verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, namely the lack of clarity regarding the source of the test data and the presence of a ground truth. This feedback is clear and actionable, as it directs the authors to clarify these aspects in their paper. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific ways to improve the clarity of the figure. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement, allowing the authors to enhance the clarity and completeness of their work. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, is used in most experiments, except for Experiment 1b, where the relationships involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. While the comment poses a question that could lead to further exploration, it does not provide explicit guidance on how to address this question or what actions the authors should take to investigate it. The action is implicit and vague, as the authors are left to infer how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions that the comparison model cannot capture periodic relationships and that most experiments, except for Experiment 1b, involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the role of periodicity in the results, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations to substantiate the question, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It highlights a specific aspect of the comparison model and questions whether adding periodicity to the spectral kernel could improve its performance. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this question or explore the impact of periodicity on their results. While it identifies an area for further investigation, it does not offer actionable advice or insights that would help the authors improve their draft. Therefore, the comment is barely helpful, as it provides a starting point for discussion but lacks the necessary depth and guidance to be fully beneficial.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the paper's writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance or suggestions on how the authors might improve the writing, presentation, or formatting. The feedback is vague and lacks actionable steps for the authors to address the issues. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concern about the paper\\'s writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing or presentation need improvement further limits the comment\\'s effectiveness. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not very well-written, possibly hurriedly written, and difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism or how to address it. Without detailed examples or references, the claim is unverifiable, as it does not provide a clear path for improvement. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing quality, suggesting that it is rushed and difficult to read. It also points out problems with presentation and formatting, particularly in figures and tables. However, the comment lacks specific suggestions or guidance on how the authors might improve the writing, presentation, or formatting. While it highlights areas for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. The feedback is valuable but could be more impactful with additional guidance on specific areas for enhancement. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. While it implies that the introduction needs to be expanded, it does not specify what aspects of the introduction are lacking in detail or how the authors should make it more detailed. The action is implicit and vague, as the authors are left to infer that they need to add more detail to the introduction. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction is lacking in detail or what specific aspects need to be expanded upon. The authors cannot confidently determine which section of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting that the introduction could be more detailed, but it lacks concrete guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer that the introduction lacks detail, but they are not provided with a clear path to address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to enhance the introduction. The comment is somewhat helpful as it highlights a need for more detail, but it does not provide actionable advice or examples of how the authors might address this issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work has shown sample-wise multiple descent in linear regression. However, it does not provide explicit guidance on how the authors should address this point or what specific aspects of their result need to be highlighted to differentiate it from prior work. The comment implies that the authors should clarify the novelty of their result, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the novelty of the result in relation to prior work. However, the comment does not provide specific examples or detailed guidance on how to highlight the novelty, making it somewhat specific. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper's main contribution is the result that optimal regularization can remove double descent even in certain anisotropic settings, given that prior work has shown sample-wise multiple descent in linear regression. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential gap in the paper's contribution by pointing out that prior work has already shown sample-wise multiple descent in linear regression. It suggests that the paper's main contribution might be the result that optimal regularization can remove double descent even in certain anisotropic settings. However, the comment does not provide specific guidance on how the authors should address this point or clarify the novelty of their result in relation to prior work. While it highlights an area for improvement, it lacks detailed suggestions or actionable advice, making it somewhat helpful. The authors would need to infer how to address the comment, which limits its overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed methods, suggesting that they are independent and lack an inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment identifies a potential area for improvement but does not offer guidance on how to make the methods more connected or how to strengthen the connection between them. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the proposed methods, suggesting that they are independent and lack an inner connection in terms of intuition and algorithm. However, it does not specify which part of the paper discusses these methods or where the independence is claimed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of independence or how to strengthen the connection between the methods. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed methods, contrastive training objective and contrastive search, are two independent methods with little inner connection in terms of intuition and algorithm. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed methods, specifically noting that they are described as two independent methods with little inner connection in terms of intuition and algorithm. This observation highlights a potential area for improvement in the paper, suggesting that the authors should explore ways to strengthen the connection between these methods. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing a framework or methodology to integrate the methods. Without actionable advice or examples, the comment provides a general observation but does not offer substantial assistance to the authors in improving their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide detailed guidance for action.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the goal of the paper, suggesting that the authors should clarify whether the work aims to establish a foundation model or provide a proof of concept. It also points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the method's benefit over these existing approaches. The comment implies that the authors should provide a clearer justification and demonstrate future applications of their method. However, it does not explicitly instruct the authors to address these points in their draft, leaving the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically mentioning the existence of DAS earthquake detectors, such as PhaseNet-Das, and the lack of comparison or justification against these existing methods. It also suggests that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. However, the comment does not specify which part of the paper discusses the goal or the comparison with existing methods, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the goal and providing a justification for the method's benefit. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the method's benefit over these existing approaches. The comment suggests that if the paper's claim is to establish a foundation model, it should be clearer and demonstrate future applications. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more evidence or justification to fully address the concern raised in the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s goal and the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It highlights the absence of a clear justification for the method\\'s benefit over these existing approaches, which is a crucial aspect for the paper\\'s contribution. The comment also suggests that if the paper aims to establish a foundation model, it should be clarified and demonstrate future applications. This feedback is mostly helpful as it provides a clear direction for the authors to address the identified weaknesses and improve the paper\\'s impact. However, it could be more comprehensive if it included specific suggestions or examples of how to demonstrate the method\\'s benefit or future applications.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCT-pair) and what the ablation studies of MCT without the adaptive metrics entail. While the questions prompt the authors to provide explanations and clarify certain aspects of their results, they do not offer explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to align the results and conduct ablation studies, but the actions are not clearly defined or detailed. Therefore, the comment is somewhat actionable, as it provides implicit guidance but lacks concrete steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions regarding the results presented in Table 6 and Table 1, specifically questioning why the results are not aligned and what the ablation studies of MCT without adaptive metrics entail. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in nature, as they directly address the alignment of results and the need for ablation studies. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the alignment of results in Table 6 with Table 1 and the relevance of ablation studies for MCT without adaptive metrics. However, it does not provide any specific reasoning, examples, or references to support why these questions are important or how they should be addressed. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis for these questions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two specific questions about the results presented in Table 6 and Table 1, particularly concerning the alignment of results and the relevance of ablation studies for MCT without adaptive metrics. While the questions highlight potential areas of concern or confusion, they do not provide any guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it identifies areas that require clarification or further explanation, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses have been conducted in prior works, noting that the results are not particularly surprising. It provides specific examples, such as the study of CIFAR-10 models on distribution shifts in RobustBench and the evaluation of adversarially trained models in [A, B]. However, the comment does not offer explicit or implicit suggestions for how the authors might address these points or improve their work. The authors are left without guidance on how to respond to these observations or incorporate additional context into their paper. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific prior works and examples, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should consider by noting that similar analyses have been conducted on smaller scales and that the results are not particularly surprising. This provides clear guidance on how the authors might address these points in their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, such as RobustBench, which studied the robustness of CIFAR-10 models on distribution shifts. It provides specific examples, including CIFAR-10.1, CINIC-10, and CIFAR-10-C, and references the work of Croce et al. (2021). Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. The claim is supported by logical reasoning and specific references, making it fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a detailed analysis of similar studies conducted in prior works, specifically mentioning RobustBench and other relevant studies. It highlights that the results of these analyses are not particularly surprising, which suggests that the authors should consider expanding their work to include a more comprehensive discussion of these findings. The comment also references specific examples, such as the study of CIFAR-10 models on distribution shifts and the evaluation of adversarially trained models, providing the authors with concrete evidence to support their claims. However, the comment could be more helpful if it offered suggestions on how the authors might address these points or incorporate additional context into their paper. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth in actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the 10 sub-tasks in the paper are simplistic for the bAbi task and that the final model could solve all of them. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes are needed to make the sub-tasks more challenging or relevant. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the 10 sub-tasks are simplistic for the bAbi task and that the final model could solve all of them. However, it does not specify which part of the paper these sub-tasks are discussed in, making it difficult for the authors to identify the exact section or context. Additionally, the comment lacks specificity in terms of what aspects of the sub-tasks need to be addressed or how they should be made more challenging. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the 10 sub-tasks are simplistic for the bAbi task and that the final model could solve all of them. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of the 10 sub-tasks used in the paper, suggesting that they might be too simplistic for the bAbi task. The comment implies that the final model could solve all the sub-tasks, which raises concerns about the novelty and depth of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the sub-tasks more challenging. While it points out a potential area for improvement, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is possible. While the comment implies that the authors should consider this limitation, it does not provide explicit guidance on how to address it or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration or discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this restriction is discussed in, making it difficult for the authors to pinpoint the exact section or context. The comment is specific in its inquiry about the limitation but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the question as a potential area for further exploration or discussion, but the claim itself is not substantiated. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation of the approach or that an extension to longer subsequences is straightforward. This question prompts the authors to consider the implications of this restriction and whether it could be addressed or expanded upon. While the comment does not provide specific guidance or suggestions for improvement, it does highlight a potential area for further exploration or discussion, which could be valuable for the authors to consider. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might mitigate this computational overhead or what steps they should consider to balance model size and accuracy. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential computational overhead introduced by the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor). However, it does not specify which part of the paper this issue is discussed or how it affects the overall methodology or results. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to mitigate this computational overhead or what steps should be taken to balance model size and accuracy. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) may introduce significant computational overhead. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. This observation is important as it highlights a potential limitation in the pursuit of determining the optimal trade-off between model size and accuracy. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the computational overhead. Without actionable advice or detailed recommendations, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also points out the absence of related work, which seems relevant to the paper's novelty. However, the comment does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the term and discuss related work, but without specific instructions on how to do so, the action is implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also points out the absence of related work, which seems relevant to the paper's novelty. However, the comment does not specify which part of the paper discusses \"sequence of episodes\" or where the related work is discussed. This makes it difficult for the authors to pinpoint the exact sections that need clarification or additional context. While the comment is specific about the content it questions, it lacks grounding because it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also points out the absence of related work, which seems relevant to the paper's novelty. However, the comment lacks specific examples or references to support the claim about the missing related work. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion regarding the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also highlights the absence of related work, which seems relevant to the paper's novelty. However, the comment lacks detailed guidance on how the authors should clarify the term or address the missing related work. While it points out areas for improvement, it does not provide specific suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies potential weaknesses but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks concrete guidance on how to revise the study or clarify its nature. As a result, the authors are left without a clear understanding of what action to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect being discussed. The comment is vague and lacks specificity, as it does not provide any details on what needs to be addressed or how the study should be revised. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the study is not an ablation study. As a result, the claim is not well-supported, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. This feedback is somewhat helpful as it identifies a potential issue with the study's categorization, which could help the authors clarify the nature of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. Without actionable advice or examples, the authors may struggle to understand how to revise their study or clarify its classification. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the paper. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the paper need to be addressed to incorporate this idea. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 126\" and the section \"Further Questions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the paper. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it aligns with the paper's content. The claim is vague and lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the paper. However, it lacks specific guidance on how to implement this suggestion or what aspects of the paper need to be addressed to incorporate this idea. The comment is vague and does not provide actionable feedback, leaving the authors uncertain about how to proceed. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. This feedback suggests that the authors should consider expanding the evaluation to include more datasets to provide a more comprehensive assessment of the metric. However, the comment does not specify which additional datasets should be included or how this expansion would be implemented. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct further testing. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the issue with the metric's testing, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the new proposed metric is only tested on a single dataset. This is a factual observation, as the paper does not provide evidence of testing on multiple datasets. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer that the metric's limited testing is a potential issue, but the comment does not provide detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the new proposed metric, noting that it is only tested on a single dataset. This feedback is valuable as it highlights a potential area for improvement, suggesting that the authors should consider expanding their evaluation to include more datasets. However, the comment lacks specific guidance on which additional datasets to include or how this expansion would be implemented. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This provides a clear and explicit action for the authors to take, as they can now understand exactly what additional evaluations are needed to strengthen the comparison. The comment is specific in its suggestion, detailing which methods should be included in the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not specify which part of the paper this evaluation is intended for, making it weakly grounded. It is specific in suggesting the inclusion of additional evaluations, but without clear references to sections or figures, the authors may find it challenging to identify the exact part of the paper that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the evaluation. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their evaluation by including additional comparisons. By evaluating the base DA methods with and without these architectural competitors, the authors can provide a more comprehensive and robust assessment of the proposed TransferNorm architecture. This feedback is mostly helpful as it offers a clear and constructive suggestion for improvement, though it could be further detailed to provide more specific guidance on how to conduct these additional evaluations. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It provides examples of where these definitions are missing, which helps the authors understand the specific areas that need clarification. However, the comment does not offer explicit guidance on how the authors should define these terms or notation. While the authors can infer that they need to address these issues, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific instances in the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation, which provides clear guidance on what needs to be addressed. The inclusion of references to specific papers further enhances the specificity of the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some abbreviations are not defined, specifically mentioning \"NE\" on L73 and the superscript notation in Eq 6, which is only defined later in the paper. The comment provides examples of where these definitions are missing, such as L166, and includes references to specific papers that use similar notation. This provides some level of support for the claim, as it highlights specific instances where definitions are lacking and offers context through references. However, the comment could be more robust by explicitly explaining why these undefined abbreviations hinder understanding or by providing more detailed examples of how the lack of definition impacts the paper. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It provides examples of where these definitions are missing, which helps the authors understand the areas that need clarification. However, the comment does not offer detailed guidance on how the authors should define these terms or notation, nor does it suggest specific ways to improve the clarity of the paper. While the feedback is somewhat helpful in pointing out areas for improvement, it lacks depth and actionable suggestions, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve their evaluation or select more appropriate baselines. As a result, the authors are left without a clear understanding of what steps to follow to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not detail what aspects of the evaluation are weak or why the baselines are not suitable for fair classification. Without this information, the authors cannot effectively address the feedback. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific details or examples to support this claim. It does not provide any references or evidence to substantiate the assertion that the baselines are unsuitable for fair classification. Without such evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation section of the paper, specifically noting that the baselines used are not designed for fair classification. This feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and specificity. The authors are left without clear guidance on how to address this issue or what steps they could take to ensure fair classification. While the comment points out a potential problem, it does not provide actionable suggestions or detailed examples of how to improve the evaluation process. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It also implies that the authors might be overstating the generality of their work, which could muddle the exposition. However, the comment does not provide explicit guidance on how to clarify the setting or address the issue of overstating generality. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to spell out the setting more clearly and the concern about overstating generality. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2, suggesting that the authors might be overstating the generality of their work. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their work. This feedback is clear and actionable, as it provides a specific area for improvement and highlights a potential issue with the exposition. However, the comment could be more helpful if it offered suggestions on how to clarify the setting or address the concern about overstating generality. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method works on these newer architectures or what its advantages are compared to them. While the comment implies that the authors should consider using more recent baselines, it does not provide explicit guidance on how to implement this change or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should compare their method with more advanced 3D CNNs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these 3D CNNs or what its advantages are compared to them. However, the comment does not specify which part of the paper discusses the choice of baselines or the experimental setup, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of using older baselines and suggesting the use of more advanced ones, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these newer architectures or what its advantages are compared to them. While the comment raises a valid concern about the choice of baselines, it lacks specific examples or references to support the claim that the proposed method might not be effective on more advanced 3D CNNs. The authors would need to provide more detailed reasoning or evidence to fully address this concern, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these newer architectures or what its advantages are compared to them. This feedback highlights a potential gap in the experimental design and encourages the authors to consider more recent and advanced baselines to strengthen their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what specific comparisons would be most informative. Overall, the comment is somewhat helpful as it identifies an area for improvement but lacks detailed suggestions for action.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the implementation details of the attention module's integration with the ResNet-20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed (e.g., after each block or stage). While the comment explicitly asks for clarification, it does not provide any guidance on how the authors should address these questions or what specific changes might be needed. The action is implicit and vague, as the authors are left to infer that they need to clarify these details in their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the implementation details of the attention module's integration with the ResNet-20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not specify which part of the paper these details are discussed or where the authors should provide this clarification. This makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific about the content it addresses, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the implementation details of the attention module's integration with the ResNet-20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not provide any evidence or reasoning to support why these details are important or how they impact the paper. It lacks specific examples or references, making it difficult for the authors to understand the basis of the concern. As a result, the claim is not verifiable, and the comment does not provide actionable guidance for improvement. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises specific questions about the implementation details of the attention module's integration with the ResNet-20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed, such as after each block or stage. This feedback is somewhat helpful as it identifies a lack of clarity in the methodology section, which could hinder the understanding and reproducibility of the research. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address these questions or improve the clarity of their methodology. Overall, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions: first, it questions the performance of the proposed method at low bitrate compared to baselines, and second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first part of the comment is explicit, as it directly asks for clarification on the precise bitrate range used for BD-rate comparison. However, the second part, while suggesting a related work, does not provide explicit guidance on how to incorporate or discuss this work. The action is somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific questions about the performance of the proposed method at different bitrates and suggests a related work for discussion. However, it does not explicitly mention which part of the paper these questions or suggestions relate to, making it weakly grounded. The questions are specific, as they ask for clarification on the bitrate range and suggest a relevant related work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: first, it questions the performance of the proposed method at low bitrate compared to baselines, and second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first part of the comment is a question that requires clarification, but it does not provide a claim or suggestion that needs verification. The second part of the comment is a suggestion for discussion, which is somewhat verifiable as it points to a relevant area for comparison. However, the comment lacks specific examples or references to support the suggestion, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on the performance of the proposed method at different bitrates, noting that it is stronger at high bitrate but close to baselines at low bitrate. This observation is valuable for the authors to understand the limitations of their method. Additionally, the comment suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, which could provide further context and insights. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate or discuss this related work. Overall, the feedback is somewhat helpful as it identifies an area for improvement and suggests a relevant comparison, but it lacks depth and actionable suggestions for the authors to fully address the feedback.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point recommends that the authors distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This recommendation provides a clear and explicit action for the authors to take, as they need to clarify the distinction between these two concepts in their paper. The action is concrete, as it specifies exactly what needs to be done to improve the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made or where the concepts are discussed. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment provides a general suggestion, it lacks specificity in terms of what needs to be addressed or how the distinction should be made. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This feedback is clear and actionable, as it provides a specific area for improvement by highlighting a potential gap in the paper's explanation or discussion. By addressing this distinction, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to make this distinction or suggested specific examples where this clarification would be beneficial. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide explicit or implicit actions for the authors to take. The comment implies that the authors should conduct more analysis, but it does not specify how to do so or what kind of analysis would be beneficial. Without concrete guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"improvements on three tasks over the previous works and self-implemented baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the issue of marginal improvements and the need for further analysis beyond the main experiments. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the improvements on three tasks over previous works and self-implemented baselines are marginal. It also suggests that further analysis beyond the main experiments is not sufficient. While the comment highlights a concern, it lacks specific guidance or suggestions on how the authors might address this issue or what additional analysis could be conducted to strengthen the paper. Without actionable advice or detailed feedback, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the proof of Theorem 8 or provide a clearer explanation of how the linear convergence rates are derived. The action is implicit and somewhat vague, as it does not specify the exact steps the authors should take to improve the clarity of the proof. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 8,\" which is located at the end of the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the proof of Theorem 8, which is the lack of clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the label is 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that all linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This claim is somewhat verifiable as it points out a specific issue with the paper, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to independently verify the claim by examining the appendix and the proof of Theorem 8 to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This feedback is somewhat helpful as it highlights a potential area for improvement, specifically the clarity of the proof of Theorem 8. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue, such as suggesting alternative approaches or providing additional explanations. While it points out a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, suggesting that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This implies that the authors should revise their statement to accurately reflect the capabilities of the Walkman algorithm. Second, the comment points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which makes it difficult for the authors to understand what is being referred to. While the feedback is explicit and provides clear guidance on what needs to be addressed, it lacks detailed instructions on how to implement these changes. Therefore, the comment is mostly actionable, as it provides a clear direction but could be more specific in terms of actionable steps.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, namely the Related Work section (Page 2, second paragraph) and Section 3, first paragraph. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed feedback on the accuracy of a statement regarding the Walkman algorithm and the clarity of a reference, offering concrete suggestions for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains two claims. The first claim critiques the accuracy of a statement regarding the related work, specifically mentioning the Walkman algorithm and its solvers. The comment provides a detailed explanation of the two versions of the algorithm, suggesting that the original statement is inaccurate. This provides a clear justification for the claim. The second claim points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which makes it difficult for the authors to understand what is being referred to. While the comment identifies a specific issue, it lacks detailed examples or references to clarify the reference, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on two key areas of the paper. First, it critiques the accuracy of a statement regarding the related work, particularly the Walkman algorithm, which is solved by ADMM with two versions, not just SGD. This feedback is valuable as it highlights a potential misrepresentation in the paper and encourages the authors to revise their claims for accuracy. Second, the comment points out a lack of clarity in a reference within Section 3, first paragraph, where the term \"it\" is used without a clear reference, making it difficult for the authors to understand what is being referred to. While the feedback is clear and identifies areas for improvement, it could be more helpful if it provided specific suggestions or examples for how to address these issues. Overall, the comment is mostly helpful as it offers actionable feedback that can guide the authors in refining their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the theoretical results of the paper, specifically that the utility guarantees are only provided for Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific area for improvement and provides a clear direction for the authors to address it, it does not explicitly instruct them on how to compare the rates or what specific literature to consult. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the limitation of the theoretical result, which is the requirement for Gaussian features and noise, and suggests a comparison to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only for Gaussian features and noise, which is a strong requirement compared to previous algorithms that do not need this assumption. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. However, the comment lacks specific examples or references to support the claim about the comparison to existing rates. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the theoretical results of the paper, noting that the utility guarantees are only provided for Gaussian features and noise. This is a significant constraint, especially considering that previous algorithms do not require this assumption. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which is a valuable piece of feedback for improving the paper. However, the comment could be more helpful if it provided specific examples or references to existing literature for comparison. Despite this, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would have been beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on the simulated data. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects should be compared. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this comparison. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the comparison, the lack of grounding makes it difficult for the authors to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is somewhat helpful as it identifies a potential area for comparison that could enhance the paper's contribution. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. Without additional details, the authors may find it challenging to fully understand and implement the suggested improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. It provides specific examples of these works, such as [1, 2, 3], which implies that the authors should include these in their experimental comparisons to better demonstrate the effectiveness of their method. The comment is explicit in suggesting the addition of more baselines and provides concrete examples, making it clear how the authors should apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions, such as [1, 2, 3]. This provides a clear indication of what additional comparisons are needed. However, the comment does not specify which part of the paper discusses the experimental section or where these comparisons should be added. This makes it weakly grounded, as the authors may need to infer the specific section to address the feedback. The comment is specific in suggesting the need for more comparisons, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. The comment provides specific examples of these works, such as [1, 2, 3], which suggests that the authors should include these in their experimental comparisons. However, the comment lacks detailed reasoning or references to support the claim fully. While the examples are provided, the reasoning behind why these additional comparisons are necessary could be more explicit. Therefore, the claim is somewhat verifiable, as it is supported by some evidence but lacks depth and clarity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, noting that the authors only compared their proposed method with two baselines. It suggests that there are other works focusing on similar questions and provides examples of these works, such as [1, 2, 3]. This feedback is clear and actionable, as it directs the authors to include more relevant baselines in their experimental comparisons to better demonstrate the effectiveness of their proposed method. By adding these additional comparisons, the authors can strengthen their experimental results and provide a more comprehensive evaluation of their method. Therefore, the comment is highly helpful, as it offers specific guidance on how to improve the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is explicit and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results being reported on the dev set instead of the test set and suggests a concrete improvement by presenting average results on the test set with error bars. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should present average results on the test set with clearly defined error bars under different random seeds. This claim is somewhat verifiable as it suggests a specific improvement to the presentation of results, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would need to infer the need for such improvements based on the feedback, which could be more effective with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Tables 1 and 2, noting that the best results are reported on the dev set despite hyperparameter search and model selection also being performed on the dev set. This is a critical point, as it questions the robustness and generalizability of the findings. The comment strongly suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds to provide a more convincing and reliable evaluation. This feedback is actionable and constructive, as it provides a clear direction for improving the paper's presentation and ensuring the validity of the results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide more values for \\\\alpha, specifically mentioning 1e-2 and 1e-3. This direct instruction provides clear guidance on how the authors should improve their draft by expanding the ablation study. The action is explicit and concrete, as it clearly specifies the additional values needed for \\\\alpha. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study on \\\\alpha, recommending the inclusion of additional values such as 1e-2 and 1e-3. This provides detailed guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study on \\\\alpha is insufficient, as it only includes values of 1e-4, 1e-1, and 5e-1, with a large gap between 1e-4 and 1e-1. The comment suggests that the authors should provide more values, specifically mentioning 1e-2 and 1e-3. However, the comment does not provide any reasoning or justification for why these additional values are necessary or how they would impact the results. Without specific examples or references, the claim is somewhat verifiable, as it lacks detailed support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation study on \\\\alpha, noting that it only includes a limited set of values (1e-4, 1e-1, and 5e-1) with a large gap between the first two. The comment suggests that the authors should provide more values, such as 1e-2 and 1e-3, to enhance the comprehensiveness of the study. This feedback is clear and actionable, as it directly points out the need for additional values and provides specific examples of what the authors should include. By addressing this suggestion, the authors can improve the robustness and thoroughness of their ablation study, which is crucial for validating the effectiveness of their approach. Therefore, the comment is highly helpful, as it provides clear guidance on how to enhance the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. While the comment explicitly asks for these details, it does not provide any guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors without clear instructions on how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any additional context, reasoning, or references to support the need for these details. The questions are clear and specific, but the lack of supporting evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topic-word parameters were obtained for the 'real' dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any guidance or suggestions on how the authors might address these questions or improve their draft. While the questions are clear and specific, the lack of actionable feedback limits the comment's helpfulness. Therefore, the comment is rated as barely helpful, as it identifies areas for improvement but does not provide sufficient guidance for the authors to act upon.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is somewhat barebones, as it only compares against 3 basic alternatives and ignores other NAS approaches like super-nets or one-shot methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what additional comparisons or analyses should be included. The action is implicit, as the authors would need to infer that they should expand their analysis to include more comprehensive comparisons. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BRP-NAS\" and specifies the issue with the analysis, which is the limited comparison against only 3 basic alternatives and the omission of other NAS approaches like super-nets or one-shot methods. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly identifies the need for a more comprehensive comparison, including the omission of other NAS approaches. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is \"somewhat barebones\" because it only compares against 3 basic alternatives and ignores other NAS approaches like super-nets or one-shot methods. While the comment provides a specific example of what is missing, it lacks detailed reasoning or references to support the claim. The authors would need to infer that the analysis is indeed limited based on the provided information, but the lack of explicit justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the analysis of BRP-NAS, noting that it only compares against 3 basic alternatives and omits other NAS approaches like super-nets or one-shot methods. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis by including a more comprehensive comparison. By suggesting the inclusion of additional comparisons, the comment helps the authors improve the depth and comprehensiveness of their analysis, making it mostly helpful. However, it could be more helpful if it provided specific examples of the other NAS approaches that should be included. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a preference for the paper's focus on few-shot learning over the inclusion of the zero-shot version and its connection to density estimation. It argues that this is more of an aesthetic argument than a technical one. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the paper. There is no guidance on what specific aspects of the paper need to be revised or how the authors can make the paper more focused on the main point. As a result, the comment lacks actionable feedback, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, such as a particular section, table, or figure. It is also not specific because it does not detail what is distracting or how it relates to the main point of the paper. The comment is vague and does not provide any guidance on how the authors might address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the distractiveness of the zero-shot version and its connection to density estimation in the context of the paper's main focus on few-shot learning. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that this is a distracting element. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper's focus, specifically the inclusion of the zero-shot version and its connection to density estimation, which the reviewer finds distracting. While the comment highlights a concern about the paper's main point, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the paper's focus. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide explicit guidance on what specific aspects of the methodology should be included or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more details on the filtering process, but the lack of concrete instructions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"details around the filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is lacking, namely \"more information on the translation and filtering methodology,\" which is crucial for assessing the dataset quality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset, suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the dataset quality is lacking. Without additional context or evidence, the authors may find it challenging to understand the specific issues or how to address them. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper by providing more details about the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific area requiring additional detail. However, the comment could be more helpful if it suggested specific aspects of the methodology that need clarification or examples of how the filtering process was implemented. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions or concrete guidance on how to implement these suggestions. The authors are left to infer that they need to add more diverse attacks and analyze the impact of thresholds, but without specific steps or examples, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions relate to, such as specific sections or tables. This lack of grounding makes it difficult for the authors to pinpoint where to make these improvements. While the comment is specific about the nature of the enrichment needed, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without detailed guidance or evidence, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment results by suggesting that they could be enriched with attacks of varying strengths and by exploring the influence of different thresholds on detection performance. This feedback is somewhat helpful as it points out specific aspects that could enhance the depth and comprehensiveness of the experimental analysis. However, the comment lacks detailed guidance or suggestions on how to implement these enhancements, which limits its impact on the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this is different from Figure 4 due to the co-adaptation between the discriminator and the generator, which might lead to a local optimum. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to train the discriminator. The action is implicit and somewhat vague, as the authors are left to infer the exact implementation details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the need to train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias. This level of detail provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that training a discriminator on generations from the learned model is needed to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this is different from Figure 4 due to the co-adaptation between the discriminator and the generator, which might lead to a local optimum. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why this approach is necessary or how it would confirm the claim. Without additional context or evidence, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific need for the authors to train a discriminator on generations from their learned model to confirm the claim of reducing exposure bias. It provides a clear rationale for why this is necessary, drawing a comparison to Figure 1 and highlighting the difference from Figure 4 due to the co-adaptation between the discriminator and the generator. This feedback is actionable and constructive, as it guides the authors on a specific step they should take to strengthen their evaluation. However, it could be more helpful if it included additional suggestions or considerations for the training process. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for more comprehensive guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the impact of using different image sizes and variations of ResNets on the performance difference. While it suggests that the authors should provide more information on this aspect, it does not explicitly instruct the authors on how to address this issue or what specific data or analysis to include. The action is implicit, as the authors need to infer that they should provide more details on the performance differences. However, the comment lacks concrete guidance on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L170), allowing the authors to accurately identify the part being addressed. It also specifies what the authors should know, namely the impact of using different image sizes and variations of ResNets on the performance difference. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the impact of using different image sizes and variations of ResNets on the performance difference. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a valid question about the impact of using different image sizes and variations of ResNets on the performance difference. It prompts the authors to consider the significance of these choices and how they might affect the results. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what specific analysis they should conduct to provide a comprehensive answer. While it identifies an important area for clarification, it does not offer detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While the comment implies that the authors should provide a detailed description of the algorithm, it does not specify how this detailed description should be presented or what aspects of the algorithm need to be emphasized. The action is explicit but lacks concrete guidance on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not specify which part of the paper this refers to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion to provide a detailed description of the algorithm, the absence of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While this feedback is relevant and provides a clear direction for improvement, it lacks specific guidance on how the authors might enhance the description of the algorithm. The comment is somewhat helpful as it identifies a potential area for improvement but does not offer detailed suggestions or examples of how to achieve this. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up, and it would be interesting to see a runtime comparison at test time. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the comparison should be included. The action is implicit, as the authors would need to infer that they should conduct a runtime comparison. While the suggestion is concrete, the lack of explicit guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up and recommends a runtime comparison at test time. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include a runtime comparison, but without a clear reference to the relevant section, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up and recommends a runtime comparison at test time. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without additional context or justification, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speed-up and recommends a runtime comparison at test time. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific experiment or analysis that could enhance the paper's impact. However, the comment lacks depth and does not provide detailed guidance on how to conduct the runtime comparison or what specific aspects of the comparison should be included. While it offers a direction for improvement, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. While the comment raises a valid concern about the method's generalizability, it does not provide explicit guidance on how the authors might address this issue or what steps they should take to test the method on natural images. The action is implicit, as the authors would need to infer that they should explore the method's performance on CIFAR10 or similar datasets. However, the lack of concrete suggestions or detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. However, it does not specify which part of the paper discusses the method's application or testing on these datasets, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its question about the method's applicability, the lack of grounding makes it challenging for the authors to understand which part of the paper needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. This is a valid concern, as the method's performance on natural images is crucial for its real-world applicability. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the method is limited to digit or text images. Without additional context or evidence, the claim is somewhat verifiable, as it raises a pertinent question but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit or text images like MNIST and SVHN. This is a pertinent question that highlights a potential limitation of the method's generalizability. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or explore the method's performance on natural images. While it identifies an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it points out a potential weakness but does not offer concrete improvements.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the organization and formatting of the prompts, it does not provide explicit guidance on how to improve the organization or formatting. The authors are left to infer that they need to reorganize the prompts and adjust the formatting to prevent sentences from being squeezed together. This lack of explicit action makes the comment somewhat actionable, as it provides a clear direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the organization of the prompts and the formatting of the sentences, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prompts are not well-organized and that all sentences are squeezed together, which is a subjective observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without detailed examples or references, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the authors' concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and formatting of the prompts in Table 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides the authors with a specific area to improve the presentation of their work. However, the comment could be more helpful if it offered suggestions on how to reorganize the prompts or adjust the formatting to prevent the squeezing of sentences. Despite this, the comment is mostly helpful as it directs the authors to a clear area for improvement, allowing them to enhance the clarity and readability of their paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the clarity of the figures, specifically mentioning that figure 2 is confusing due to the relationship between its sub-figures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should clarify the relationships between the sub-figures and label the missing modules. This lack of explicit action makes the comment somewhat actionable, as it provides a clear direction but lacks detailed instructions on how to implement the changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the clarity of the figures, such as the confusion in the relationship between sub-figures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures are not clear, specifically mentioning confusion in figure 2 due to the relationship between sub-figures and the lack of labels for modules like CMAF, L_BT, and VoLTA. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors are left to question the validity of the feedback, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly noting confusion in figure 2 due to the relationship between sub-figures and the lack of labels for certain modules. This feedback is clear and actionable, providing the authors with specific areas to improve the presentation of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or labeling of the figures, such as proposing specific design changes or referencing best practices for figure presentation. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It also recommends adding a line or two to indicate that there is no solution for this, which would improve the readability and provide a clearer overall picture for the reader. The comment is explicit in suggesting what should be done and provides concrete details on how to implement the action, such as exploring existing work or adding a note about the difficulty of the problem. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFNs\" and \"linear decomposition,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests exploring existing work to compute the contribution of FFNs, even if a linear decomposition is not possible, and recommends adding a note about the difficulty of the problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It recommends adding a note about the difficulty of this problem to improve readability. However, the comment lacks specific references or examples to support the claim that such work exists or does not exist. Without detailed evidence or references, the claim is somewhat verifiable, as it provides a suggestion but lacks the necessary depth to fully substantiate the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the omission of FFNs due to the inability to obtain a linear decomposition, suggesting that there might be existing work that offers a way to compute their contribution. It also recommends adding a note about the difficulty of this problem to improve the readability and provide a clearer overall picture for the reader. This feedback is actionable and provides a specific suggestion for improvement, which could help the authors enhance their draft. However, the comment could be more helpful if it included examples of existing work or a more detailed explanation of the challenges involved. Overall, the comment is mostly helpful, as it offers clear guidance on how to address a specific aspect of the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after fine-tuning. It also points out that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. The authors are directed to consider and address these concerns, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after fine-tuning. It highlights that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. However, the comment does not specify which part of the paper discusses these design choices or how they are controlled, making it fully grounded but somewhat specific. Therefore, this comment aligns with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises concerns about the use of perplexity as a measure of semantic information retention after fine-tuning, questioning its relevance to domain drift. It suggests that perplexity might not capture aspects of domain drift separate from catastrophic forgetting. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology, specifically questioning the use of perplexity as a measure of semantic information retention after fine-tuning. It highlights that perplexity might not capture aspects of domain drift separate from catastrophic forgetting, which is a crucial consideration in the study. The comment also asks how such factors are controlled, providing a clear direction for the authors to address this concern. By pointing out this potential issue and suggesting a specific area for improvement, the comment offers valuable guidance to the authors, making it mostly helpful. However, it could be more helpful if it provided additional context or examples to fully address the concern.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks how the number of images impacts the model performance, and second, it suggests explaining the BYOL model in the abstract. While the questions are explicit and direct, they do not provide concrete guidance on how to address these issues. The authors are left to infer that they need to conduct further analysis or provide more context on the impact of image numbers and the BYOL model. The lack of specific instructions or suggestions for improvement makes the comment somewhat actionable. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. However, it does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in that it asks for clarification and suggests an improvement, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: how the number of images impacts model performance and whether more training images make performance worse or better. It also suggests explaining the BYOL model in the abstract. While the questions are logical and relevant to the paper, the comment lacks specific examples or references to support the claims. The authors are left to infer the basis for these questions, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important questions regarding the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. These questions are relevant and could help the authors improve the clarity and completeness of their paper. However, the comment lacks specific guidance on how to address these issues or provide additional context. While it identifies areas for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the rationale behind the method's effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" However, the comment does not explicitly instruct the authors to include these explanations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the reasoning behind the method's effectiveness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component. However, it does not specify which part of the paper discusses this component or the method's effectiveness. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a need for stronger arguments or intuitions regarding why the L_pixel losses are \"bound to help,\" but without explicit grounding, the authors may struggle to locate the relevant section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component, suggesting that the authors should provide stronger arguments or intuitions for why these losses are \"bound to help.\" However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the method works effectively. Without additional context or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the rationale behind the method's effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these specific losses are \"bound to help\" in enhancing the method's effectiveness. This feedback is somewhat helpful as it highlights an area where the authors could improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the arguments or intuitions. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. It mentions specific areas, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The comment is clear and specific, offering concrete guidance on what needs to be included in the Related Work section. This allows the authors to directly address the feedback and improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the section by discussing specific methods and their limitations, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail helps the authors understand exactly what needs to be added or improved in the Related Work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. It suggests including specific methods such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The claim is well-supported by specific examples and references, making it fully verifiable. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the Related Work section. It identifies a significant area for improvement by noting the lack of detail and suggesting specific methods and their limitations that should be included. The references provided, such as [1, 2, 3, 4, 5, 6, 7], offer concrete examples of existing approaches that the authors could incorporate to enhance the comprehensiveness of the Related Work section. This detailed guidance empowers the authors to significantly improve the depth and relevance of their paper, making the comment highly valuable. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific changes could be made to the dataset. While it identifies a potential problem, the lack of actionable advice makes it difficult for the authors to respond effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While it provides some specificity by mentioning the concern about the dataset size, the lack of explicit grounding makes it challenging for the authors to understand the exact context of the comment. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. The comment provides a logical reasoning by comparing the dataset size to the typical training data of LLMs, making the claim somewhat verifiable. However, it lacks specific examples or references to support the claim fully, which could make it partially verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. This feedback highlights a potential limitation in the dataset's ability to represent diverse user characteristics and content topics, which could impact the model's performance and generalizability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative dataset sizes or methods for data augmentation. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models understanding of fine-grained errors like technique error. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the evaluation. The comment lacks concrete guidance on what alternative metrics or methods could be considered, making it difficult for the authors to take action to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models understanding of fine-grained errors like technique error. However, it does not specify which part of the paper this concern relates to, such as a particular section or table. This lack of grounding makes it difficult for the authors to identify the exact area where the issue needs to be addressed. While the comment is specific in its critique of the metric, the absence of grounding information limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models understanding of fine-grained errors like technique error. However, the comment lacks specific examples or references to support the claim that binary classification is inadequate for this purpose. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique error. This feedback is somewhat helpful as it identifies a potential weakness in the evaluation methodology. However, the comment could be more helpful if it provided suggestions or guidance on alternative metrics or methods that could better capture the nuances of the models' understanding. Without specific recommendations or examples, the authors may struggle to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the method to accommodate these feature types. The comment lacks concrete guidance on how to extend the method or what specific steps should be taken. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not specify which part of the paper discusses the use of binary features or how the method is applied. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the applicability of the method to real and categorical features, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples to explain why the method might not be applicable to these feature types. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the applicability of the method to real and categorical features, as the work primarily focuses on binary features. This is a pertinent issue, as real-world data often includes a mix of feature types. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or extend their method to accommodate these feature types. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or insights for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors should improve them. The comment lacks explicit actions or concrete suggestions, making it difficult for the authors to know what to address. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to address these issues. The authors cannot confidently determine which sections or points require revision, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the writing are unclear or how the authors should improve them. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address these issues. Without detailed guidance or examples, the authors may find it challenging to understand the areas that require improvement and how to make the necessary revisions. Therefore, the comment is barely helpful, as it identifies a general area for improvement but does not offer specific advice or direction.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use other metrics to evaluate the Results, such as BERTScore. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve their draft. The comment is specific in its recommendation, indicating which alternative metrics could be used. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not specify which part of the paper the results are presented in, making it difficult for the authors to identify the exact section that needs revision. While the suggestion is specific in terms of the metrics, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not provide any reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the evaluation process. The comment lacks sufficient justification to be considered verifiable. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using other metrics, such as BERTScore, to evaluate the results. This is a specific and actionable suggestion that could enhance the robustness and comprehensiveness of the evaluation process. By providing a concrete alternative to the current evaluation method, the comment offers valuable guidance for the authors to improve their draft. However, the comment could be more helpful if it provided additional context or rationale for why these alternative metrics are beneficial. Overall, the feedback is mostly helpful as it directs the authors towards a specific improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It also highlights the difficulty in understanding under what conditions SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. While the comment provides a clear action\u2014comparing the metric with others\u2014it does not offer specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"a large amount of work on LLM evaluation [2]\" and suggests comparing the SynTextBench metric with other metrics proposed in the literature. This allows the authors to accurately identify the part of the paper being addressed. Additionally, the comment is specific because it requests a comparison of SynTextBench with other metrics and highlights the difficulty in understanding when to use SynTextBench over other metrics like MMLU or Big Bench for language generation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not adequately compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It suggests that the authors should compare SynTextBench with metrics like MMLU and Big Bench to understand when to use it. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to conduct additional research to fully understand the basis of this claim and how it relates to the paper\u2019s content. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by suggesting that the authors compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It highlights the difficulty in understanding when to use SynTextBench over other metrics, such as MMLU or Big Bench for language generation. This feedback is actionable as it directs the authors to a specific area for comparison and provides a clear rationale for why such a comparison is important. However, the comment could be more helpful if it included specific examples or guidance on how to conduct this comparison effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the algorithm for constructing coresets is not novel, as existing frameworks for classical k-means and (k,z) clusterings have been extended to the kernelized setting. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how the authors might enhance the novelty of their work or what specific aspects of their algorithm could be improved to differentiate it from existing frameworks. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the algorithm for constructing coresets, noting that it is not novel and that existing frameworks have been extended to the kernelized setting. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of novelty, the absence of grounding information makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel, as existing frameworks have been extended to the kernelized setting. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on a general observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the algorithm for constructing coresets, noting that existing frameworks have been extended to the kernelized setting. While this observation is accurate, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. It lacks actionable advice, such as recommending alternative approaches or providing examples of how to differentiate their algorithm from existing frameworks. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the writing and annotations in the paper are difficult to follow. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of their writing or annotations. The comment lacks explicit instructions or concrete advice on what needs to be done to address the issue. As a result, the authors are left without a clear understanding of how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment is not specific, as it does not detail what aspects of the writing or annotations are hard to follow. Without specific examples or guidance, the authors cannot effectively address the issue. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing and annotations are \"poor\" and \"hard to follow.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the writing and annotations in the paper, specifically noting that they are \"poor\" and \"hard to follow.\" However, the comment lacks specificity and actionable suggestions. It does not provide any details on what aspects of the writing or annotations are problematic, nor does it offer any guidance on how the authors might improve them. Without concrete examples or recommendations, the authors are left without a clear understanding of how to address the issue, making the comment barely helpful. Therefore, the comment is rated as 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the results presented in Table 2. The first question asks why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method. The second question inquires about the discrepancy in F1 scores between the overall setting and individual types in the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the results presented in the table, particularly regarding the number of SOTA performances and the discrepancy in F1 scores. This provides clear guidance on what aspects of the results require further explanation or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the results presented in Table 2, specifically regarding the number of SOTA performances achieved by the proposed method and the discrepancy in F1 scores between the overall setting and individual types. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas in the results section that require further clarification. It questions the number of evaluation metrics achieving SOTA performances for the proposed method and asks for an explanation of why the method achieves the best overall F1 score but not the best F1 score in all single types. This feedback is clear and actionable, as it directs the authors to specific parts of their paper that need further explanation or analysis. By addressing these questions, the authors can improve the clarity and completeness of their results section, enhancing the overall quality of their work. Therefore, the comment is mostly helpful, as it provides clear guidance on areas for improvement but could be more comprehensive if it suggested specific ways to address the issues.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of including all reports. While the comment is somewhat specific in questioning the rationale, it lacks concrete suggestions on how to implement this change or what specific aspects of the reports might be easier to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area of concern. While the comment is specific in its questioning of the rationale, the absence of explicit grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports might be easier. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper. However, the comment lacks depth and specificity, as it does not provide detailed reasoning or suggestions for how the authors might address this concern. Without additional guidance or examples, the authors may struggle to fully understand the implications of the comment and how to incorporate it into their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this incremental nature or how they could improve upon it. Without specific suggestions or guidance, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not specify which part of the paper this comment is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what needs to be addressed. Additionally, the comment is vague and does not provide specific suggestions or guidance on how to improve the solution. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. While it identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this incremental nature or enhance their solution. The comment is vague and does not provide actionable feedback that would empower the authors to make meaningful improvements to their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the discussion of scalability bounds, specifically mentioning the absence of a thorough exploration of the upper limits of FedDES's scalability, as well as the lack of discussion on memory requirements or computational complexity. While the comment identifies a specific area that needs improvement, it does not provide explicit guidance on how the authors should address these issues or what specific aspects of the discussion should be expanded upon. The action is implicit, as the authors would need to infer that they should include a more detailed discussion of these aspects. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the limited discussion of scalability bounds, memory requirements, and computational complexity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it identifies the lack of discussion on these aspects, which could help the authors improve the paper by addressing these gaps. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the upper limits of FedDES's scalability, specifically mentioning the absence of a discussion on memory requirements or computational complexity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of a thorough discussion of scalability bounds, memory requirements, and computational complexity. This feedback is valuable as it highlights an area where the authors could enhance the depth and comprehensiveness of their analysis. By addressing these aspects, the authors can provide a more robust and complete understanding of the limitations and potential of FedDES. However, the comment could be more helpful if it offered specific suggestions or guidance on how to discuss these aspects, such as suggesting additional experiments or analyses that could be included. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. It notes that the current instances have a maximum of 7 variables, which raises concerns about the ability of LLMs to model problems with large instance sizes. However, the comment does not provide explicit guidance on how the authors should generate these additional instances or what specific steps they should take to address this concern. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion to increase the number of variables, the absence of grounding information makes it challenging for the authors to address the concern effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. However, the comment does not provide any specific reasoning, examples, or references to support why this is a concern or how it impacts the paper. Without additional context or evidence, the claim remains unverifiable, as the authors cannot confidently understand the basis of the concern or how to address it. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the number of variables in the instances used in the paper, suggesting that the authors may want to generate instances with more constraints and variables. This is a valid point, as the current instances have a maximum of 7 variables, which may limit the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional experiments could be conducted to explore this concern. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable and constructive nature, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests improvements to the results presentation, specifically mentioning that the y-axis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which figures to revise or how to add the scatter plot. While the action is somewhat inferred, it lacks concrete details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the results presentation, specifically mentioning that the y-axis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not specify which parts of the paper these figures are located in, making it weakly grounded. The suggestion to highlight best results in tables is also vague and lacks specific guidance on how to do so. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests improvements to the results presentation, specifically mentioning that the y-axis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The suggestion to highlight best results in tables is also vague and lacks detailed guidance. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or depth to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies areas for improvement in the results presentation, specifically mentioning the ambiguity of the y-axis labels in Figures 2 and 3 and the absence of runtime representation. It suggests a scatter plot with runtime and performance axes as a way to enhance the reader's understanding and interpretation of the results. Additionally, it proposes highlighting the best results in tables, which could improve clarity. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific steps or examples. While it provides some actionable feedback, it could be more helpful with additional details or suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the interpretation of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment prompts the authors to clarify their understanding, it does not provide explicit instructions or suggestions on how to address this clarification. The action is implicit, as the authors need to infer that they should clarify the statement. However, the comment lacks concrete guidance on what specific aspects to focus on or how to provide the clarification. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It does not explicitly mention a specific part of the paper, such as a section, table, or figure, making it weakly grounded. However, the comment is specific in its request for clarification regarding the impact of the base node on the ordering, key nodes for attention, and model performance. This specificity allows the authors to understand the exact issue being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It does not contain a subjective claim or suggestion but rather asks for clarification on the implications of this statement. The comment is factual and does not require verification, as it is a request for understanding rather than a critique or assertion. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, key nodes for attention, and model performance. This question prompts the authors to clarify their understanding of the statement, which could help them better understand the implications of the method described in the paper. However, the comment does not provide any suggestions or guidance on how to address this clarification or what specific aspects to focus on. While it identifies an area that needs clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow's direction, it does not provide explicit guidance on how to address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the arrow's direction and its impact on n^(i). However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. Additionally, it does not specify what needs to be addressed or why the current direction of the arrow is problematic. Therefore, the comment is not grounded and not specific, aligning with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It does not contain a claim that requires verification or justification. The comment is a question seeking clarification, which is a normal statement. Therefore, it should be labeled as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It challenges the authors to consider the rationale behind the arrow's direction, which could be crucial for understanding the model or method being presented. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve the clarity or accuracy of the figure. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of abbreviations in Table 5, noting that they are not defined. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to define the abbreviations, but the comment lacks concrete instructions on which abbreviations need to be defined and how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the abbreviations in Table 5 are not defined, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \u201cAR\u201d in Table 5 stands for domain adaptation tasks and algorithms. While the comment identifies a potential issue with clarity and consistency in the use of abbreviations, it does not provide specific examples or references to support the claim. The authors are left to infer that the lack of definition for abbreviations could hinder understanding, but without additional context or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations in Table 5, noting that they are not defined. This is a clear and actionable piece of feedback that could help the authors improve the clarity and readability of their paper. By defining the abbreviations, the authors can ensure that their work is easily understood by readers. However, the comment could be more helpful if it provided guidance on which abbreviations need to be defined or how to define them effectively. Overall, the comment is somewhat helpful as it highlights a specific area for improvement, but it lacks depth and detail to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what aspects of the analysis might need to be reconsidered. The comment is vague and lacks concrete actions for the authors to take, making it difficult for them to understand how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the specific part of the paper being addressed. The comment is vague and lacks specificity, as it does not provide detailed guidance on what aspects of the analysis might need reconsideration. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. While it prompts the authors to consider alternative approaches, it does not provide specific guidance or suggestions on what those considerations might be or how they could be addressed. The comment is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its critique of the setting, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique, leaving them uncertain about how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the \"Unsupervised Online Adaptation\" setting, specifically questioning whether the inclusion of labels in the training set aligns with the definition of unsupervised learning. This critique is clear and provides a specific point of concern that the authors should consider. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what changes could be made to the setting. While it highlights a potential weakness, it does not provide detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training, unlike most compared baselines. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the fairness of their comparison. The comment implies that the authors should consider the impact of different sample weights on the performance comparison, but it lacks concrete steps or actionable advice on how to do so. Therefore, the comment is not actionable, as it does not provide the authors with a clear path to follow to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the fairness of the performance comparison in Table 1, specifically pointing out that VINS uses different sample weights during training, unlike most compared baselines. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the comparison, but the lack of grounding makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair because VINS uses different sample weights during training, unlike most compared baselines. This claim is somewhat verifiable as it highlights a specific difference in the experimental setup that could potentially affect the fairness of the comparison. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors could benefit from additional explanation or evidence to strengthen the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training, unlike most compared baselines. This observation is important as it highlights a potential bias in the experimental setup that could affect the validity of the comparison. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparison. While it points out a critical aspect of the evaluation, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time complexity of the method might be too high if the reply buffer is too large, referencing a specific paper. While it identifies a potential issue, it does not provide explicit guidance on how to address this problem or what specific aspects of the method need to be improved. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of the reply buffer size on the method\\'s efficiency. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the time complexity issue related to a large reply buffer, referencing a specific paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear issue and suggests a potential solution by referencing a relevant paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper. While the claim is based on a logical argument about the relationship between buffer size and computational complexity, it lacks detailed reasoning or specific examples to fully substantiate the claim. The reference to the paper provides some context, but the reasoning could be more explicit and detailed. Therefore, the comment is mostly verifiable, as it provides a basis for understanding the issue but could benefit from more detailed justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the method when the reply buffer is too large, referencing a specific paper. This feedback is clear and actionable, as it highlights a potential area for improvement in the method\\'s efficiency. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific techniques to optimize the method. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions or details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The comment is somewhat vague and lacks concrete details, making it difficult for the authors to understand exactly what actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and perspectives, but without clear references to the paper, the authors may struggle to identify the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment lacks specific references or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without detailed reasoning or examples, the claim is considered borderline verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it provides a direction for the authors to consider additional baselines and perspectives, which could enhance the comprehensiveness of their work. However, the comment lacks specific guidance on which baselines to include or how to implement these suggestions, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a brief conclusion and a summary of the paper's contributions should be included. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to their draft. The comment is specific in its request, detailing the exact elements that should be included, making it highly actionable. Therefore, this comment aligns with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a brief conclusion and a summary of the paper's contributions should be included. However, it does not specify which part of the paper this refers to, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its request for inclusion, but the lack of grounding makes it challenging for the authors to understand where to make the changes. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a brief conclusion and a summary of the paper's contributions should be included. This is a straightforward and logical request, as it aligns with standard academic writing practices. However, the comment lacks specific examples or references to support why these elements are necessary or how they would enhance the paper. While the suggestion is clear, it does not provide detailed reasoning or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that a brief conclusion and a summary of the paper's contributions should be included. This is a clear and actionable piece of feedback that directly addresses a common element missing in many academic papers. By providing specific suggestions for improvement, the comment empowers the authors to enhance the completeness and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to craft these elements effectively or provided examples of what constitutes a good conclusion and summary. Despite this, the feedback is mostly helpful as it directs the authors towards important areas for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, suggesting that the data distribution in Figure 1 might be inseparable from the network model. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify or improve the experiment. The comment implies that the authors should consider the nonlinear expression ability of neural networks and how it relates to the data distribution, but it lacks concrete steps or suggestions for implementation. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being discussed. While the comment is specific in its critique of the experiment, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. The comment does not provide any evidence, reasoning, or references to support the claim that the data distribution is inseparable from the network model. Without additional context or justification, the authors are left to interpret the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the synthetic experiment in a non-separable case, specifically questioning the inseparability of the data distribution illustrated in Figure 1 from the network model. It raises a valid concern about the nonlinear expression ability of neural networks and how it relates to the data distribution. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as barely helpful, as it points out a problem but does not offer constructive feedback for resolution.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment does not specify which method should be used for comparison or how this comparison should be presented in the paper. The action is implicit, as the authors need to infer that they should include this comparison, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the authors should include this comparison in their paper. However, it does not specify which method should be used for comparison or how this comparison should be presented. The comment lacks specific guidance on which part of the paper should address this comparison, making it weakly grounded. It is also specific in suggesting the need for a comparison with a method defending against multiple attacks, but the lack of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without additional context or references, the claim is not fully verifiable, as it does not provide a clear rationale or evidence for why this comparison would be beneficial. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific guidance on which method to use for comparison or how to present this comparison in the paper. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful. The feedback is clear but could be more comprehensive if it provided more actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results are presented in a convoluted manner and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. It also notes that the reason for this presentation is unclear. While the comment identifies a potential issue with the clarity of the results, it does not provide explicit guidance on how the authors should address this issue or present their results differently. The action is implicit, as the authors would need to infer that they should clarify the presentation of their results and include the safety violations. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results being presented in a convoluted way and specifically points out that the results disregard the safety violations of the agent in the first 1000 episodes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the disregard of safety violations in the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are presented in a convoluted way and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. The comment also states that the reason for this presentation is unclear. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are convoluted or that the reason for disregarding safety violations is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the results, noting that they are convoluted and disregard the safety violations of the agent in the first 1000 episodes. It also points out that the reason for this presentation is unclear. This feedback is somewhat helpful as it highlights a potential area for improvement in the clarity and completeness of the results section. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or present their results more effectively. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed. The comment is specific and concrete, giving the authors a precise task to complete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, indicated by the line number (l111). This allows the authors to accurately identify the section where the bounds for \\\\tau_i^l need to be defined. The comment is also specific because it clearly specifies what needs to be addressed, which is the definition of the bounds for \\\\tau_i^l. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests the authors to define the bounds for \\\\tau_i^l, which is important for understanding the time-warp function. While the request is clear and specific, it does not provide any additional context, reasoning, or references to support why this definition is necessary or how it impacts the overall understanding of the time-warp function. The comment lacks depth and does not offer any guidance or justification for the request, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is specific and actionable, as it requests the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This feedback is clear and provides a direct instruction for the authors to improve their draft by clarifying a key aspect of their methodology. However, the comment could be more helpful if it offered additional context or guidance on how to define these bounds effectively. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, allowing them to enhance the clarity and comprehensiveness of their work. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific instances of writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment highlights these errors, it does not provide explicit guidance on how the authors should correct them or what specific changes need to be made. The action is implicit, as the authors can infer that they need to revise the text to remove the redundant \"informative\" and add a title to the \"performance\" section. However, the lack of detailed instructions on how to implement these corrections makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This provides full grounding as the authors can accurately pinpoint the sections where these errors occur. The comment is also specific because it clearly specifies the nature of the errors and what needs to be addressed, such as correcting the redundant \"informative\" and adding a title to the \"performance\" section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment highlights these errors, it does not provide any reasoning or justification for why these are problematic or how they impact the paper's clarity or coherence. The authors are left to infer that these errors need to be corrected, but without additional context or explanation, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment points out these issues, it does not provide any suggestions or guidance on how the authors might address these errors. The feedback is somewhat helpful as it highlights areas that need improvement, but it lacks actionable advice or detailed suggestions on how to correct the errors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques a statement on line 134 regarding the applicability of a theorem to standard sigmoid functions, noting that it depends on the maximum slope. It suggests that the theorem, specifically Theorem 4.1, would be more useful if the authors elaborated on why this holds, particularly in the context of RNNs converging to the nearest fixed point compared to URNNs. While the comment implies that the authors should provide more detail, it does not explicitly instruct them to do so or specify how to elaborate. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the explanation in the main text. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors elaborate on why the statement holds, particularly in the context of RNNs converging to the nearest fixed point compared to URNNs. This provides clear guidance on what part of the paper requires further explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques a statement on line 134 regarding the applicability of a theorem to standard sigmoid functions, noting that it depends on the maximum slope. It suggests that the theorem, specifically Theorem 4.1, would be more useful if the authors elaborated on why this holds, particularly in the context of RNNs converging to the nearest fixed point compared to URNNs. The comment provides a logical reasoning by explaining the relevance of the convergence behavior of RNNs and URNNs, which helps the authors understand the basis of the critique. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion regarding the applicability of a theorem to standard sigmoid functions, particularly in the context of RNNs and URNNs. It suggests that the authors should elaborate on why the statement holds, specifically mentioning the convergence behavior of RNNs to the nearest fixed point compared to URNNs. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to enhance the explanation in the main text. By addressing this point, the authors can improve the clarity and depth of their paper, making the comment mostly helpful. However, it could be more helpful if it provided more detailed suggestions or examples to further guide the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the efficiency of their method or what changes could be made to enhance its practical applicability. As a result, the authors are left without a clear understanding of what steps to undertake to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or context. The comment is specific in its critique of the efficiency of pairwise matching, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to be used in practical application systems. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of pairwise matching, noting that it is very low and may limit its practical application. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable advice or examples of how to enhance the efficiency, the authors may find it challenging to incorporate this feedback into their draft. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. While the comment identifies a potential issue with the figure's allocation, it does not explicitly instruct the authors on how to improve the space allocation or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, indicating that the authors need to consider how to improve the space allocation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the allocation is indeed \"too naive\" or why the authors should consider editing the space more wisely. Without concrete examples or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and that the authors could have edited the space of the main paper more wisely. While the comment points out a potential issue, it lacks specific guidance or suggestions on how to address this concern. The feedback is somewhat helpful as it highlights an area for improvement, but it does not provide detailed actionable advice or examples to help the authors enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the plan-based method, noting that it requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. The comment suggests that the proposed method may be difficult to generalize to a new dataset without ground truth summary. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their method. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitations of the plan-based method, specifically noting that it requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as suggested by Table 2. The comment further indicates that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the comment does not specify which part of the paper discusses the plan-based method or Table 2, making it weakly grounded. The comment is specific in detailing the issues with the plan-based method, but without explicit references, it is difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also suggests that the learned plan methods are not comparable to methods with predefined plans, as indicated by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims. While the reasoning is somewhat logical, the absence of concrete evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the plan-based method, noting that it requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. This observation raises concerns about the generalizability of the proposed method to new datasets without ground truth summaries. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve their method. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first sentence of the abstract should be re-written. This is a clear and explicit action that the authors can take to improve their draft. The comment provides a specific instruction on what needs to be done, making it highly actionable. Therefore, this comment is rated as 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the first sentence of the abstract needs to be re-written. However, it does not specify which part of the abstract this refers to, making it difficult for the authors to pinpoint the exact section that requires revision. Additionally, the comment lacks specificity in terms of what aspects of the first sentence need to be re-written or how it should be revised. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the first sentence of the abstract needs to be re-written. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this change is necessary or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the first sentence of the abstract needs to be re-written. While this provides a clear direction for improvement, it lacks specificity and does not offer any guidance on what aspects of the sentence should be revised or how it should be re-written. The comment is vague and does not provide actionable feedback, making it barely helpful. Therefore, the comment is rated as 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should report results for multiple train/test splits or folds to provide a more accurate illustration of the method's performance. It acknowledges that this might be time-consuming due to the size of the datasets but encourages the authors to carry out this exercise. The comment is explicit in its suggestion and provides a clear action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should report results for multiple train/test splits or folds, which is a specific and actionable suggestion. However, it does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its recommendation, as it clearly specifies the need for multiple splits to provide a more accurate illustration of the method\\u2019s performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results should be reported for multiple train/test splits or folds, which is a standard practice in many papers on Gaussian Processes. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors are encouraged to consider this suggestion, but the lack of detailed reasoning or evidence weakens the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental methodology, suggesting that the results are reported for a single held-out test set, which may not provide a comprehensive evaluation of the method's performance. The comment recommends using multiple train/test splits or folds, a standard practice in many papers on Gaussian Processes, to offer a more accurate illustration of the method's performance. While the comment does not provide specific guidance on how to implement this suggestion, it offers a clear direction for improvement. The feedback is mostly helpful as it highlights a common practice and encourages the authors to enhance the robustness of their results, though it could be more detailed with specific examples or references. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to simplify the method, but without grounding, the authors are left to make an educated guess about where to apply this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method described in the paper is more involved than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on an observation without clear justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While the comment identifies a potential area for simplification, it lacks specific guidance or suggestions on how to achieve this simplification. The authors are left to infer what changes might be needed, which limits the actionable nature of the feedback. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not provide detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. While the comment acknowledges the potential benefit of the approach, it does not provide explicit guidance on how to implement this method or what specific aspects of transferability it aims to improve. The action is implicit, as the authors would need to infer that they should consider adding such a method to enhance transferability. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. Without explicit mention of a section or methodology, the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in its critique of the approach but lacks grounding as it does not provide a clear reference point. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that this approach is not a significant contribution. As a result, the claim is considered unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a critique of a potential method for improving transferability, suggesting that adding a method on top of other methods is a good idea but not a significant contribution. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this method or what aspects of transferability it might address. The feedback is somewhat helpful as it highlights a potential issue with the approach but does not offer actionable advice or detailed insights to help the authors improve their work. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the hGRU architecture appears to be ad-hoc and lacks motivation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what changes could be made to the architecture or how the motivation could be improved. As a result, the authors are left without a clear understanding of how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the hGRU architecture is \"ad-hoc and not very well motivated,\" but it does not specify which part of the paper this observation pertains to. Without knowing the exact section or context, the authors cannot determine where to address this feedback. Additionally, the comment lacks specificity in explaining what aspects of the architecture are ad-hoc or poorly motivated. This makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the hGRU architecture is \"ad-hoc and not very well motivated.\" However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hGRU architecture, suggesting that it is ad-hoc and lacks motivation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the motivation behind the architecture. Without actionable feedback or detailed suggestions, the authors may find it challenging to understand how to respond to this critique. Therefore, the comment is barely helpful, as it highlights a concern but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these points. The authors would need to infer that they should correct the potential error in the algorithm, discuss the asymptotic performance, and provide additional experimental results. The action is somewhat explicit but could be more concrete. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to Algorithm 1, Line 8, suggesting a potential error in using s_t instead of s_n. It also raises questions about the asymptotic performance of the proposed method and requests additional results with more environment steps. However, the comment does not explicitly mention which part of the paper Algorithm 1 is located in, making it weakly grounded. The comment is specific in detailing the issue with the algorithm and the request for additional results, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies areas for clarification and improvement, it lacks specific reasoning or references to support the claims. The authors would need to infer the basis for the questions, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about a potential error in Algorithm 1, Line 8, suggesting that s_n should be used instead of s_t. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies an area for improvement and provides a clear question, it lacks detailed guidance on how to address these points or what specific changes might be necessary. The feedback is somewhat helpful as it points out a potential issue and suggests further exploration, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It also recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not provide explicit guidance on how to address these challenges or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not specify which part of the paper discusses the analysis of Adam under the (L0,L1)-smoothness condition, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the issue of challenges and differences, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that standard analysis might be directly applicable. Without further elaboration or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the analysis of Adam under the (L0,L1)-smoothness condition. It questions whether the challenges are significant enough to warrant detailed explanation and suggests that standard analysis might be directly applicable. This feedback is somewhat helpful as it highlights a potential gap in the paper's analysis and encourages the authors to clarify the challenges and differences with Zhang et al.'s work. However, the comment could be more helpful if it provided specific examples or guidance on how to address these challenges. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests toning down the statement about the neural network memorizing \"critical points\" and provides feedback on the method section being wordy and containing grammatical errors. While the comment offers specific suggestions for improvement, it does not explicitly instruct the authors on how to tone down the statement or compress the method section. The feedback on grammatical errors is vague and lacks concrete guidance on how to address them. Therefore, the comment is somewhat actionable, as it provides some direction but lacks detailed instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific part of the paper by referencing \"34\" and \"TopoNet [24]\", indicating that the authors can accurately identify the section being discussed. It also provides feedback on the method section being wordy and suggests compressing it, which is specific to the method section. Additionally, the comment points out the presence of grammatical errors, particularly with plurals and articles, and provides an example of such errors. This level of detail allows the authors to understand exactly what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains a claim that the authors should tone down the statement about the neural network memorizing \"critical points,\" suggesting that this is not accurate in the context of TopoNet [24]. However, the comment does not provide specific reasoning or examples to support this claim, making it difficult for the authors to understand why the statement should be toned down. The feedback on the method section being wordy and containing grammatical errors is somewhat verifiable, as it suggests areas for improvement but lacks detailed guidance. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides specific feedback on a particular statement in the paper, suggesting that it should be toned down. It also offers feedback on the method section, noting that it is wordy and could be compressed, and points out the presence of grammatical errors. While the comment is somewhat detailed, it could be more comprehensive by providing specific examples of grammatical errors or suggesting ways to compress the method section. Overall, the feedback is helpful as it offers actionable suggestions for improvement, but it could be more detailed to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that most person re-ID methods build on pedestrian detectors and mentions the existence of end-to-end methods. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this point or incorporate it into their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general overview of person re-ID methods, categorizing them as building on pedestrian detectors or being end-to-end. However, it does not specify which part of the paper this observation relates to, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. Additionally, the comment lacks specificity in detailing what aspects of these methods are being discussed or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that most person re-ID methods build on pedestrian detectors and mentions the existence of end-to-end methods. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a brief overview of person re-ID methods, categorizing them as building on pedestrian detectors or being end-to-end. While this observation is relevant to the field, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this point in their work. It does not provide actionable feedback or insights that could help the authors improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding a first sentence to introduce Section 3.2. This is an explicit action that the authors can directly implement by adding a sentence at the beginning of the section. The comment is specific and provides clear guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the label \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it suggests adding a first sentence to introduce Section 3.2. This is a clear and direct feedback that provides the authors with a concrete step to improve their draft. By adding this sentence, the authors can enhance the clarity and coherence of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment implies that the authors should clarify the term \"perfect,\" it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the term. However, the comment lacks concrete details on what specific clarification is needed, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment raises a valid point about the implications of a perfect rationale selector, it does not provide specific examples or references to support the claim. The reasoning is somewhat clear but lacks depth and detail, making it borderline verifiable. Therefore, the comment aligns with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion regarding the term \"perfect\" in the context of the initial rationale selector. It questions the meaning of \"perfect\" and suggests that if it were perfect, no additional work would be needed. This feedback is clear and actionable, as it prompts the authors to clarify the term and understand its implications. However, the comment could be more helpful if it provided additional context or examples to illustrate the concept of a perfect rationale selector. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for clarification and improvement. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the definition of uncertainty could be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution, and that upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion to improve the clarity of their paper. The comment is specific and concrete, offering detailed guidance on how to enhance the explanation of uncertainty. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides detailed feedback on how the definition could be clarified, suggesting that the authors should update the explanation to include the representation of epistemic model uncertainty in the prior distribution and the updating of beliefs in the posterior distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of uncertainty could be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This claim is somewhat verifiable as it provides a logical reasoning for why the current definition might be unclear, suggesting a more detailed explanation. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of the paper by clarifying the definition of uncertainty. It suggests that the authors should update their explanation to specify that the epistemic model uncertainty is represented in the prior distribution and that it is updated in the form of a posterior distribution upon observing data. This feedback is clear and constructive, offering a concrete way for the authors to enhance the understanding of their work. However, the comment could be more helpful if it included additional suggestions or examples to further guide the authors in improving the clarity of their explanation. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for greater depth and impact.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zero-shot intent classifier. While it does not explicitly instruct the authors to address these questions, it implies that they should provide more clarity on these aspects. The action is implicit, as the authors need to infer that they should clarify these points in their draft. However, the questions are specific and direct, giving the authors a clear idea of what needs to be addressed. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks explicit instructions on how to implement the changes. This aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zero-shot intent classifier. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific and direct, as they ask for clarification on the methodology and accuracy of the system. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zero-shot intent classifier. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, lacking any assertion or guidance that would need justification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the experimental setup, particularly concerning the use of domain ontologies and the details of the zero-shot intent classifier. It asks for clarification on whether the authors experimented with domain ontologies to avoid placeholder generation and for details on the number of questions created and the accuracy of the system. While the questions are clear and direct, they do not provide actionable feedback or suggestions for improvement. The authors are left with a request for clarification rather than guidance on how to enhance their work. Therefore, the comment is barely helpful, as it identifies areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of citations to recent works on self-play and population-play in the context of exploration and coordination in MARL. It suggests that these missing citations would help set the paper in a broader context. However, the comment does not provide explicit guidance on which specific papers should be cited or how these citations should be integrated into the draft. The action is implicit, as the authors need to infer that they should include these citations, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for citations to recent works on self-play and population-play in the context of exploration and coordination in MARL. This allows the authors to accurately identify the part of the paper where these citations should be added. The comment is also specific because it provides clear guidance on what kind of citations are needed, such as recent papers on self-play and population-play. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks citations to recent works on self-play and population-play in the context of exploration and coordination in MARL. It provides specific examples of such papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. These references support the claim by providing context and examples of relevant work. The comment is mostly verifiable as it offers clear and specific examples of missing citations, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of citations to recent works on self-play and population-play in the context of exploration and coordination in MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which helps the authors understand the importance of these citations for setting the paper in context. However, the comment could be more helpful by suggesting specific ways to integrate these citations or by providing guidance on how to discuss the related work. Overall, the feedback is somewhat helpful as it highlights an important area for improvement but lacks detailed actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their method with other self-supervised learning methods that are not based on contrastive learning. This provides a clear and explicit action for the authors to take, as they can directly compare their method with relevant baselines. The comment is specific in its suggestion, guiding the authors on what kind of comparisons would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the authors' method with other self-supervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this comparison should be made or where these methods are discussed. The authors cannot confidently determine which section or part of the paper this suggestion relates to, making it weakly grounded. Additionally, while the suggestion is specific in terms of the type of comparison, it lacks detail on how to implement or execute this comparison. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the authors\\' method with other self-supervised learning methods that are not based on contrastive learning. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this comparison is necessary or how it would benefit their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the authors\\' method with other self-supervised learning methods that are not based on contrastive learning. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their work by including additional comparisons. By comparing their method with other relevant approaches, the authors can better position their work within the existing literature and demonstrate its unique contributions. This feedback is mostly helpful as it offers a concrete suggestion for improvement, but it could be more comprehensive if it included specific examples or guidance on how to conduct the comparison effectively. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by models. It does not provide explicit instructions or suggestions on how the authors should address this question or clarify the distinction. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to respond. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the abstention process and its relation to decision thresholds, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its request for clarification regarding the difference between the abstention process and decision thresholds. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the abstention process and its relation to decision thresholds, but it does not contain a claim or suggestion that requires verification. It is a request for clarification and does not provide any evidence or reasoning to support a claim. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the abstention process and its relation to decision thresholds, specifically asking how the abstention process differs from a decision threshold used by models. This question is clear and identifies a potential area for clarification in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a specific area that needs attention, the comment lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the claim of COCO-LM being parameter-efficient, noting that the conclusion would apply to related works. The comment implicitly suggests that the authors should provide a more nuanced comparison and address the impact of BPE vocabulary changes on performance. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address them. The action is somewhat vague, as the authors need to infer the specific areas for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCO-LM being parameter-efficient, implying that the conclusion would apply to related works. However, the comment does not specify which part of the paper this comparison is made or which sections discuss the performance of these models. This makes it difficult for the authors to pinpoint the exact areas that need revision. The comment is specific in its critique of the comparison but lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCO-LM being parameter-efficient, noting that the conclusion would apply to related works. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references or logical arguments to support the assertion that the comparison is overrated or that the conclusion applies to other works. As a result, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCO-LM being parameter-efficient, implying that the conclusion would apply to related works. This feedback provides a clear point for the authors to reconsider their claims and potentially adjust their conclusions. However, the comment lacks specific suggestions or detailed guidance on how to address the issue or improve the comparison. While it identifies an area for improvement, it does not offer actionable steps or detailed reasoning, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analysis presented in lines 128 to 149, noting that it is not convincing enough. It highlights a specific observation from a histogram in Figure 3, where the GS-P-50 model is claimed to have smaller class selectivity scores, suggesting that it shares more features with the ResNet-50 model, which learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how to improve the analysis or address the concerns raised. While it identifies a potential issue with the analysis, it lacks actionable steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the analysis presented in lines 128 to 149, specifically mentioning a histogram in Figure 3. It highlights a discrepancy in the class selectivity scores between the GS-P-50 and ResNet-50 models, suggesting that GS-P-50 shares more features with ResNet-50, which learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not specify which part of the paper this analysis is located in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the content being criticized, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the analysis presented in lines 128 to 149, specifically mentioning a histogram in Figure 3. It highlights a discrepancy in the class selectivity scores between the GS-P-50 and ResNet-50 models, suggesting that GS-P-50 shares more features with ResNet-50, which learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide specific examples or detailed reasoning to support the claim that this observation indicates GS-P-50 learns better representations. While the reference to external works is provided, the lack of detailed explanation or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the analysis presented in lines 128 to 149, specifically mentioning a histogram in Figure 3. It highlights a discrepancy in the class selectivity scores between the GS-P-50 and ResNet-50 models, suggesting that GS-P-50 shares more features with ResNet-50, which learns more class-specific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the analysis. It lacks actionable feedback, making it difficult for the authors to understand how to enhance their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue is raised, specifically the conclusions that are not convincing. It provides specific examples, such as the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality,\" and suggests exploring the impact of different combination methods, particularly in rehearsal-free continual learning. The mention of specific works, such as [R1], [R2], and [R3], further clarifies the issue and provides context. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issues raised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to provide more evidence or examples to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern in the paper, noting that some conclusions are not convincing. It provides a detailed critique of the claim that 'continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.' The authors are encouraged to explore the impact of different combination methods, particularly in rehearsal-free continual learning, where feature-replay methods have shown promise. The review also suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. This feedback is somewhat helpful as it highlights a potential area for improvement and provides some direction for the authors to consider. However, it could be more helpful if it offered more specific guidance or suggestions on how to address the issue. Therefore, the comment is rated as 3: Somely Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of meaningful baselines in the authors' comparisons, suggesting that they should include more sophisticated baselines such as a chain-of-thought prompting approach. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific baselines to consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more meaningful baselines. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue of lacking meaningful baselines and suggests a specific alternative baseline, the chain-of-thought prompting approach. This provides the authors with clear guidance on what needs to be addressed and how to improve their comparisons. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors limit their comparisons to simple naive baselines, suggesting that they should include more meaningful baselines such as a chain-of-thought prompting approach. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The lack of detailed reasoning or evidence weakens the verifiability of the claim, as the authors may not be able to effectively address the issue without further clarification. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of meaningful baselines used for comparison. It suggests that the authors should include more sophisticated baselines, such as a chain-of-thought prompting approach, to provide a more comprehensive evaluation of their model. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their comparisons. However, the comment could be more helpful if it provided specific examples of how to implement these baselines or suggested additional baselines that could be considered. Overall, the comment is mostly helpful, as it effectively guides the authors to improve their draft by addressing a critical gap in their evaluation.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment prompts the authors to clarify their methodology, it does not provide explicit instructions or suggestions on how to address the question or improve the draft. The action is implicit, as the authors need to infer that they should clarify their methodology and discuss the generalization of their approach. However, the comment lacks concrete guidance on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set, and it also asks about the generalization of this approach to scenarios where labels are not available. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its inquiry about the model's training and generalization, the lack of grounding makes it challenging for the authors to respond effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the training methodology of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential area for clarification, it does not provide any specific evidence, reasoning, or references to support the claim that this is a significant issue or a gap in the paper. The authors are left to interpret the relevance of this question, making it difficult to fully understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the training methodology of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and address the comment effectively. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific guidance or actions for the authors to take to address this concern. The comment lacks explicit instructions on how the authors should consider or address the hardware and software dependencies in their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which part of the paper these observations and decisions are discussed in, nor does it provide any specific examples or guidance on how to address this issue. The lack of grounding makes it difficult for the authors to understand which sections need revision, and the comment lacks specificity in detailing what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some observations and design decisions might be hardware and software dependent, which is a valid concern. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without additional context or examples, the authors may struggle to understand the implications of this observation and how to incorporate it into their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable advice or detailed guidance. The score aligns with a rating of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It does not provide explicit instructions or suggestions on how the authors should address these concerns, such as suggesting alternative methods for validation or providing more detailed analysis. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not specify which part of the paper \"Tab.\" refers to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its questioning but lacks grounding as it does not provide clear references or guidance on how to address the issues. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any evidence, reasoning, or references to support these claims. The questions are open-ended and do not offer specific guidance or justification for the authors to address them. As a result, the comment is unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It specifically references 'Tab.' but does not provide detailed feedback or suggestions on how the authors might address these concerns. While the comment identifies a potential issue with the results, it lacks actionable guidance or depth, making it somewhat helpful. The authors are left with a general idea of what to consider but without specific steps to take. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of experimental details in the main body and the minimal explanations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8, noting that they are not explained. However, the comment does not provide explicit guidance on what specific details are missing or how the authors should address these issues. While the authors can infer that they need to include more experimental details in the main body and provide explanations for the PCA experiments, the lack of concrete suggestions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the PCA experiments in Figures 3, 7, and 8, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the missing experimental details and the lack of explanations in the Appendix, particularly for the PCA experiments. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This claim is somewhat verifiable as it provides some evidence but lacks detailed reasoning or references to support the assertion that the PCA experiments are not explained. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is valuable as it highlights areas where the authors could improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided suggestions on what specific details are missing or how the authors might address the lack of explanations in the Appendix. Despite this, the comment offers actionable feedback that encourages the authors to enhance the presentation of their experimental results, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of new evaluation metrics and the need for an in-depth exploration of the reasons behind the experimental results. However, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues, such as suggesting the development of new metrics or the inclusion of a detailed analysis of the experimental results. The comment lacks concrete details on how to implement these suggestions, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of new evaluation metrics and the need for an in-depth exploration of experimental results, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the paper is being discussed, making the comment weakly grounded. However, it is specific in detailing the issues that need to be addressed, such as the absence of new metrics and the need for deeper analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks new evaluation metrics and that only existing metrics are linearly combined. It also suggests that the experimental analysis section needs an in-depth exploration of the reasons behind the results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two key areas for improvement in the paper: the lack of new evaluation metrics and the need for a more in-depth exploration of the reasons behind the experimental results. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is somewhat helpful as it points out areas that require attention, but it lacks actionable advice or detailed examples, which could have been more beneficial for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit action that the authors should take to avoid confusion and ensure clarity in their notation. The comment provides a direct and concrete instruction, making it highly actionable. The authors know exactly what needs to be addressed and how to implement the suggested change. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit reference to specific parts of the paper, such as L166 and L176, which allows the authors to accurately pinpoint the issue. The comment is fully grounded as it provides specific references to the sections where the notation is used. It is also specific because it clearly specifies the problem with the notation, making it easy for the authors to understand and address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a factual observation that requires no further verification or reasoning to understand. The comment is clear and specific, making it verifiable. Therefore, it is classified as a \"3: Somewhat Verifiable\" comment, as it is clear but lacks some depth in terms of suggesting potential consequences or implications of the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion for the readers. By pointing out this inconsistency, the comment provides the authors with a concrete suggestion to improve the clarity and consistency of their notation. This feedback is valuable as it helps the authors enhance the readability and understanding of their work. Therefore, the comment is mostly helpful, as it offers a clear and actionable piece of advice that can significantly improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical impact of the weak recovery problem studied, suggesting that it may be primarily of theoretical interest and that the AMP algorithm's usefulness for non-Gaussian problems is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the practical relevance of their work. The action is implicit, as the authors would need to infer that they should consider the practical implications of their study and explore the AMP algorithm's performance in non-Gaussian settings. The lack of concrete steps or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practical impact of the weak recovery problem studied, suggesting that it is primarily of theoretical interest and that the AMP algorithm's usefulness for non-Gaussian problems is unclear. However, the comment does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it weakly grounded. It is specific in identifying the issue with the practical impact of the study, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak recovery problem studied is primarily of theoretical interest and that the AMP algorithm's usefulness for non-Gaussian problems is unclear, limiting practical impact. However, the comment lacks specific evidence or references to support these claims. Without detailed reasoning or examples, the authors may find it difficult to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practical impact of the weak recovery problem studied, suggesting that it is primarily of theoretical interest and that the AMP algorithm may not be useful for non-Gaussian problems. This feedback highlights a gap in the paper's discussion of the algorithm's real-world applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the practical relevance of their work. While it points out an important consideration, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should explore the AMP algorithm's performance in non-Gaussian settings or discuss the practical implications of their findings more thoroughly. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of connections to human cognition in the context of the paper's focus on a reductionist problem. It suggests that the authors should clarify their claims and provide more context or citations to support their arguments. However, the comment does not explicitly instruct the authors on how to address this issue or what specific changes to make. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their claims and provide more context or citations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the relevance of connections to human cognition in the context of the paper, suggesting that the authors should clarify their claims and provide more context or citations. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its critique of the authors' claims and suggestions for improvement, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relevance of connections to human cognition in the context of the paper, suggesting that the authors should clarify their claims and provide more context or citations. However, the comment lacks specific examples or references to support the claim that the authors' claims are unclear or require more context. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the relevance of connections to human cognition in the context of the paper, suggesting that the authors should clarify their claims and provide more context or citations. This feedback is somewhat helpful as it identifies a potential area for improvement by prompting the authors to clarify their arguments and provide additional support for their claims. However, the comment lacks specific guidance on how to address the issue or what kind of evidence would be most beneficial, making it somewhat helpful rather than fully helpful. The authors would need to infer the need for clarification and additional context, which could be improved with more detailed suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a specific issue with the writing style, it does not provide explicit guidance on how to revise the conclusion or suggest specific changes to make the word choice less flamboyant. The action is implicit, as the authors would need to infer that they should revise the conclusion to be more concise and less exaggerated. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue of exaggerated wording and suggests that the word choice is a bit flamboyant in multiple places, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a subjective opinion about the writing style, it does not provide specific examples or references to support the claim. This lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing style in the conclusion, noting that the wording is overly exaggerated and that the word choice is a bit flamboyant in multiple places. This feedback is clear and actionable, as it provides the authors with a specific area to improve the tone and conciseness of their conclusion. However, the comment could be more helpful if it offered suggestions on how to revise the language or provide examples of more concise phrasing. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and explicit action for the authors to take, as they know exactly what experiments to conduct and what metrics to compare. The comment is specific in its suggestion, guiding the authors on how to improve their draft by adding these experiments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this comparison should be made or which section of the paper discusses the proposed method. This makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is somewhat verifiable as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the comparison with other methods. The authors would need to conduct additional research or experiments to fully understand the implications of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by conducting additional experiments. However, the comment could be more helpful if it included more detailed guidance on how to conduct these experiments or why these metrics are important. Overall, the comment is mostly helpful, as it offers valuable insights for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines. It suggests that the authors should include such comparisons to prove the effectiveness of the proposed approach. However, the comment does not provide any guidance on how to implement this suggestion, such as which baselines to use or how to conduct the comparison. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. The comment is specific in its critique but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparison to simple feature acquisition baselines, which is a subjective opinion. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines. This is a crucial point because it questions the effectiveness of the proposed approach without proper benchmarking. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as which baselines to include or how to conduct the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement, but it lacks explicit guidance on how to address them. The comment suggests exploring other bit operations, provides feedback on Figure 5a, asks for clarification on how the paper handles DVS input, and suggests analyzing energy consumption as in reference [15]. However, it does not provide concrete steps or detailed guidance on how to implement these suggestions. The actions are implicit and vague, making it difficult for the authors to know exactly what to do. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises several questions and suggestions for improvement, but it does not specify which part of the paper these concerns relate to. The references to \"11,\" \"Fig. 5 a,\" and \"DVS input\" are vague and do not allow the authors to pinpoint the exact sections or figures being discussed. While the comment provides some guidance on what to consider, it lacks specificity in addressing the issues. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and analyzing energy consumption. However, it lacks specific reasoning or references to support these claims. The feedback is somewhat vague and does not provide detailed guidance or evidence to help the authors address these issues. Therefore, the comment is rated as 3: Somewhat Verifiable, as it offers some suggestions but lacks sufficient justification or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several points for improvement, including suggestions to explore other bit operations, provide more explanations for Figure 5a, and analyze energy consumption, referencing a specific paper [15]. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to address these suggestions or what specific analyses or comparisons should be made. The feedback is somewhat helpful as it identifies areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes that clarifications are needed on how the embeddings are combined and fed into the CSCM. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the combination and feeding of embeddings. However, the action is somewhat vague as it does not specify the exact steps or methods that need clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific question about how historical observations are combined with inputs known over all time, particularly focusing on the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes the need for clarifications on how the embeddings are combined and fed into the CSCM. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what needs clarification regarding the combination and feeding of embeddings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes the need for clarifications on how the embeddings are combined and fed into the CSCM. This feedback is somewhat verifiable as it points out a specific area where clarification is needed, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for clarification based on the feedback, which could be improved with more explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely how historical observations are combined with inputs known over all time, particularly concerning the differences in sequence lengths (L vs L+M). It points out that while the text mentions separate embedding and addition with positional encoding, it lacks clarity on how the embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to clarify a specific aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples to guide the authors in addressing this issue. Overall, the comment is mostly helpful, as it effectively highlights an area for improvement and encourages the authors to provide more detailed explanations. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the approach, suggesting that the introduction of multi-granularity and multi-scale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. However, the comment does not provide explicit guidance on how the authors might address these issues or improve their contribution. The action is implicit and vague, as it does not specify what changes the authors should make to enhance the novelty of their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of multi-granularity and multi-scale techniques in the article, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the novelty of the approach in the context of MLMs and critiques the use of algorithms from object detection. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the novelty of the approach, suggesting that the introduction of multi-granularity and multi-scale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. However, the comment lacks specific examples or detailed reasoning to support its claims, making it difficult for the authors to understand and address the issues effectively. The feedback is somewhat verifiable as it provides a general critique but lacks the depth needed for actionable improvement.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the approach, suggesting that the introduction of multi-granularity and multi-scale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. This feedback provides a clear critique of the novelty of the approach and highlights areas where the authors might need to improve their contribution. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors could enhance the novelty of their work. Overall, the comment is somewhat helpful as it identifies a key issue but lacks detailed actionable feedback.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue, such as suggesting a method for analyzing hyper-parameter sensitivity or specifying their values. The action is implicit and vague, as the authors are left to infer how to improve the paper. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hyper-parameters $m_1$, $m_2$, and $\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion and specification of the sensitivity of these hyper-parameters. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified in the paper. This is a factual observation that requires no further verification or evidence. The comment is clear and specific, providing a direct observation about the absence of discussion and specification of these hyper-parameters. Therefore, it is classified as \"3: Somewhat Verifiable\" as it is clear but lacks some depth in terms of suggesting how the authors might address this issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified. This is a clear and actionable feedback that highlights a gap in the paper. By pointing out the lack of discussion and specification of these hyper-parameters, the comment provides the authors with a clear direction for improvement. However, it could be more helpful if it suggested specific methods or approaches for analyzing the sensitivity of these hyper-parameters or specifying their values. Despite this, the comment is mostly helpful as it directs the authors to an important area that needs attention, enabling them to enhance the completeness and clarity of their work. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the similarity-aware positive sample selection and its potential impact on GNN-based encoder over-smoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not provide explicit guidance on how to conduct these additional experiments or what specific aspects of the model should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer the need for more experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the similarity-aware positive sample selection and its potential impact on GNN-based encoder over-smoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarity-aware positive sample selection or where the experiments on graph classification are detailed. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the concerns regarding over-smoothing and generalization, it is not grounded because it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the similarity-aware positive sample selection and its potential impact on GNN-based encoder over-smoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples or detailed reasoning to substantiate these claims, making it difficult for the authors to understand the basis of the concern. The feedback is somewhat verifiable as it provides a general direction for improvement but lacks detailed evidence or references to support the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the similarity-aware positive sample selection and its potential impact on GNN-based encoder over-smoothing, specifically questioning whether it might lead to over-smoothing or lower generalization performance. It suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific guidance on how to conduct these additional experiments or what aspects of the model should be evaluated. While it identifies a potential area for improvement, the feedback is somewhat helpful as it points out a critical issue that needs further exploration. The authors are left to infer the need for more comprehensive experimentation, which limits the comment's direct usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to discuss the power of different architectures. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for more discussion but lacks grounding as it does not clearly indicate where this discussion should occur. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not contain any claims or opinions that require verification. The comment is purely descriptive and does not provide any evidence or reasoning to support it. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or what aspects of the architectures should be discussed. The comment is somewhat helpful as it points out a relevant area for further exploration, but it does not provide detailed feedback or actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the methods should be evaluated across different splits of train-val-test to obtain robust results, rather than relying on different initialisation seeds. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve the robustness of their results. The comment is specific in its recommendation, detailing exactly what needs to be done to enhance the evaluation process. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the methods should be evaluated across different splits of train-val-test to obtain robust results, rather than relying on different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the methods should be evaluated across different splits of train-val-test to obtain robust results, rather than relying on different initialisation seeds. This claim is somewhat verifiable as it provides a logical reasoning for why evaluating across different splits would lead to more robust results. However, it lacks specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the robustness of the results by recommending that the methods be evaluated across different splits of train-val-test, rather than relying solely on different initialisation seeds. This feedback is actionable and directly addresses a potential weakness in the evaluation process. By offering a clear and constructive suggestion, the comment empowers the authors to enhance the reliability and validity of their findings. However, it could be more helpful if it included additional guidance on how to implement this suggestion or why this approach is beneficial. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be further refined to be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the first two bullet points about contributions in the introduction could be combined. This is a clear and explicit action that the authors can easily understand and implement. The comment provides specific guidance on how to improve the draft by merging the contributions, which is concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the first two bullet points about contributions in the introduction could be combined. However, it does not specify which part of the introduction these bullet points are located in, making it difficult for the authors to identify the exact section to address. While the comment is specific about the action to be taken, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the first two bullet points about contributions in the introduction could be combined. This is a suggestion for improvement, but it does not provide any specific reasoning, examples, or references to support why this combination would be beneficial. The comment lacks depth and does not offer any justification for the suggestion, making it difficult for the authors to understand the rationale behind it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the first two bullet points about contributions in the introduction could be combined. This is a specific and actionable suggestion that could potentially improve the clarity and conciseness of the introduction. By merging the contributions, the authors could streamline the introduction and make it more focused. However, the comment lacks additional guidance or suggestions on how to combine the contributions effectively, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but does not offer comprehensive advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its critique but weakly grounded as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the types of situations or social norms discussed in the main paper are not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the types of situations or social norms discussed in the main paper. However, it lacks actionable guidance or suggestions on how the authors might address this lack of clarity. Without specific advice on how to improve the clarity or provide more detailed explanations, the authors may find it challenging to effectively respond to the comment. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the extent to which the paper improves upon existing solutions, particularly in the context of segmentation problems. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm's ability to find closed contours and its robustness against weak boundaries. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the paper need to be improved. The action is implicit and vague, as it does not specify which parts of the paper should be revised or how the authors should incorporate the suggested references. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper targets a problem that somewhat differs from general segmentation problems, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of demonstrating the algorithm's ability to find closed contours and its robustness against weak boundaries, particularly for bottom-up methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm's ability to find closed contours and its robustness against weak boundaries. However, the comment lacks specific examples or references to support the claim that the paper needs to address these issues. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the extent to which the paper improves over existing solutions, particularly in the context of segmentation problems. It suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm's ability to find closed contours and its robustness against weak boundaries, especially for bottom-up methods. This feedback is somewhat helpful as it identifies an important area for improvement and provides a direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or examples of how to incorporate these trends into the paper. Overall, the comment provides a clear and actionable direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific baselines or domains to include, or how to motivate the design choices. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not specify which baselines or domains should be included, nor does it provide guidance on how to motivate the design choices. The authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a specific section or figure. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the suggestions. The feedback is somewhat verifiable as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides feedback on the need for more baselines and domains to be tested, as well as the lack of strong motivation for certain design choices. It suggests that the authors should include baselines with other design choices and test on more domains to strengthen their empirical results. However, the comment lacks specific guidance on which baselines or domains to include, making it somewhat helpful. The feedback is clear and actionable, but it could be more comprehensive if it provided detailed suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests the authors to define the dashed lines in figures 2A-B and 4B. This is a clear and explicit action that the authors can readily take to improve their draft. By defining these lines, the authors can enhance the clarity and understanding of the figures, making them more informative and easier to interpret. The comment provides a direct instruction on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment requests the authors to define the dashed lines in figures 2A-B and 4B. While the comment is specific in terms of the elements it addresses (dashed lines in specific figures), it does not provide any guidance on how to define these lines or what they represent. The authors can infer that they need to clarify the meaning of these lines, but the comment lacks explicit instructions or examples. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point requests the authors to define the dashed lines in figures 2A-B and 4B. This is a factual request for clarification, as it does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is a normal statement, as it does not provide any additional information or reasoning to support the request. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests the authors to define the dashed lines in figures 2A-B and 4B. This is a clear and actionable suggestion that directly addresses a potential area of confusion or lack of clarity in the figures. By defining these lines, the authors can enhance the readability and understanding of their figures, making them more informative and easier to interpret. This feedback is specific and provides a direct path for improvement, making it mostly helpful. However, it could be more helpful if it suggested specific ways to define the lines or provided examples of how to do so. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the comparability of their results. The comment lacks concrete guidance on what specific steps the authors should take to make their results more comparable or to enhance the significance of their proposed methods. As a result, the authors are left without a clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concern about the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, it does not specify which part of the paper this issue is related to, such as the results section, the discussion, or the methodology. Without clear grounding, the authors cannot confidently identify where the issue lies, making the comment weakly grounded. Additionally, the comment is specific in its critique of the results but lacks detailed suggestions on how to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, the comment lacks specific details or evidence to support this claim. It does not provide any examples, references, or logical reasoning to substantiate the assertion that the results are not comparable. Without such support, the authors are left without a clear understanding of why the results are not comparable or how to address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable guidance or examples, the authors are left without a clear path to enhance the significance of their work. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited novelty of the paper, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. It mentions that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty or provide deeper insights into the unique challenges of overcorrelation in recommender systems. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DeCorr\" and \"graph collaborative filtering,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the lack of unique insights into overcorrelation in recommender systems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, as it primarily applies existing literature, specifically DeCorr, to a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's novelty, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. The authors are informed that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment highlights that the paper lacks deeper insights into the unique challenges of overcorrelation in recommender systems. This feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional suggestions or guidance on how to enhance the novelty and provide unique insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with Figure 2: the ambiguity of some symbols and the curiosity about information redundancy and interference in the multi-sphere icosahedral discretization process. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should clarify the symbols and explain the redundancy and interference processes. This lack of explicit guidance makes the comment somewhat actionable, as the authors can deduce the necessary steps but do not have concrete instructions on how to implement them. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of ambiguity in Figure 2, specifically mentioning that some symbols are not explained clearly. However, it does not specify which part of the figure is ambiguous or provide details on what needs to be clarified. The comment also raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process, but it does not specify which part of the paper this relates to. Therefore, the comment is not grounded, as the authors cannot confidently determine which part of the paper it addresses, and it is not specific because it lacks detailed guidance on what needs to be clarified or addressed. This aligns with a score of 1: Not Grounded and Not Specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises two issues regarding Figure 2: the ambiguity of some symbols and the curiosity about information redundancy and interference in the multi-sphere icosahedral discretization process. While the comment identifies these issues, it does not provide any specific examples, references, or detailed reasoning to support the claim that these ambiguities or curiosities are significant or require attention. The lack of justification makes it difficult for the authors to understand the basis of the concern and how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with Figure 2, specifically noting that some symbols are not explained clearly. It also raises a question about the presence of information redundancy and interference in the multi-sphere icosahedral discretization process, which could be a point of clarification for the authors. However, the comment lacks detailed guidance or suggestions on how to address these issues or what specific improvements could be made to the figure. While it points out areas for attention, it does not provide actionable advice or examples of how to enhance the clarity or accuracy of the figure. Therefore, the comment is somewhat helpful, as it offers some insight but lacks depth and specificity in its feedback.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a limitation in the results of the paper, specifically regarding the assumption that the spectrum of a kernel is sub-gaussian. It notes that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that the results could be restrictive due to this limitation. However, the comment does not provide explicit guidance on how the authors might address this issue or what changes could be made to the paper to mitigate this limitation. The action is implicit and vague, as it does not specify how the authors should incorporate or discuss the inclusion of Matern kernels. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitation of the results by pointing out that the assumption of sub-gaussian spectra for kernels is valid for Gaussian kernels but restricts the results due to the exclusion of other popular kernels like Matern kernels, which have polynomial decay spectra. The comment is fully grounded as it explicitly mentions the issue in the context of the paper, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it clearly specifies the limitation and suggests that the results could be more comprehensive by including Matern kernels. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is sub-gaussian. It argues that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that the results could be limited by this assumption. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion. While the reasoning is logical, the absence of concrete evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper's results, specifically regarding the assumption that the spectrum of a kernel is sub-gaussian. It points out that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. This observation suggests that the results of the paper could be more comprehensive if these kernels were included. However, the comment does not provide specific guidance on how the authors might address this limitation or what changes could be made to the paper to incorporate these kernels. While it highlights an important area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it is a key factor in performance gain, especially compared to other modules. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the pretraining method need to be discussed. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague and leaves the authors uncertain about how to implement the action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining in the main paper and suggests that it is more important than other modules. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4, but lacks detailed discussion in the main paper. The comment suggests that the unsupervised pretraining is more important than other modules, as evidenced by the ablation study in Table 5. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion that unsupervised pretraining is more important. The comment provides a logical argument but could benefit from more detailed evidence or references to support the claim. Therefore, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a key issue in the paper, noting that the unsupervised pretraining method is a significant factor in performance gain, as indicated by data in Table 4. However, it points out that there is a lack of detailed discussion on this topic in the main paper. The comment suggests that the authors should focus more on the pretraining method, especially considering its importance compared to other modules discussed in the ablation study in Table 5. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by expanding on the discussion of unsupervised pretraining. However, it could be more helpful if it included suggestions on how to elaborate on the discussion or what specific aspects of the pretraining method should be addressed. Overall, the comment is mostly helpful, as it effectively guides the authors toward a crucial area for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker's gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors can implement the suggested changes or what steps they should take to ensure accurate results. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\\'s gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, particularly in cases where vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table discussing the selection of ELMs. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of gender detection and accuracy, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\\'s gender, which could be a drawback. The comment implies that the accuracy should be calculated after using a gender detection model in the pipeline, particularly in cases where vocal traits match speaker identity. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue raised. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker's gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, particularly in cases where vocal traits match speaker identity. This feedback highlights a potential limitation in the methodology and suggests that the authors should consider the implications of gender detection on their results. However, the comment lacks specific guidance on how the authors might address this issue or what changes they should make to their draft. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide any specific guidance or suggestions on how to simplify the writing or what aspects of the writing are particularly challenging. The authors are left with a general idea of what needs to be improved but lack concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without this information, the authors cannot accurately identify the areas that need improvement. The comment is not grounded as it lacks specific references to the paper, and it is not specific because it does not detail what aspects of the writing are difficult to follow. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific areas where the writing is unclear or difficult to follow. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the writing, stating that it is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific details or suggestions on how to improve the writing, such as providing examples of unclear sections or recommending specific strategies for simplification. While it highlights a critical area for improvement, the lack of actionable guidance limits its helpfulness to the authors. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical depth or substance of their work. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. The authors cannot confidently determine which section is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity in detailing what aspects of the paper are lacking in technical substance or how the addition of a new loss impacts the overall contribution. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that it is incremental and lacks technical substance, primarily adding a new loss to [31]. While this feedback highlights an area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable advice, such as recommending additional experiments, deeper analysis, or a more detailed explanation of the technical contributions. Without concrete suggestions, the authors may find it difficult to understand how to enhance the depth and impact of their work. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not offer comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on how to determine which $P^*$ to fix. While the comment provides some direction for improvement, it lacks explicit instructions on how to incorporate this intuition or guidance into the paper. The authors are left to infer the specific actions needed, making the comment somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for more intuition regarding the proof of Theorem 1, specifically concerning the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently identify the exact part of the paper being addressed. The comment is specific in its suggestions for improvement, such as providing intuition and practical guidance, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the intuition behind the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also asks for practical guidance on determining which $P^*$ to fix. While the questions are logical and relevant to the paper's content, they do not provide specific examples or references to support the claims. The comment lacks detailed reasoning or evidence, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific suggestions for improving the paper, such as offering more intuition about the proof of Theorem 1, particularly regarding the invertible function $f^*$ and its dependence on the fixed $P^*$. It also raises questions about the practical determination of $P^*$, which could guide the authors in enhancing the clarity and practical relevance of their work. However, the comment could be more helpful if it provided additional guidance or examples on how to incorporate this intuition and practical considerations into the paper. Overall, the feedback is somewhat helpful, as it identifies areas for improvement but lacks depth and detail.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the equations. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the use of different variables in equations (7) and (10), specifically asking why they are not analogous. However, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The authors are left without a clear understanding of what part of the paper needs revision or how to improve the consistency of the equations. As a result, the comment is not grounded, as the authors cannot confidently identify the specific part of the paper being addressed, and it is not specific because it does not offer any actionable advice. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. However, it does not provide any claim, suggestion, or judgment that requires verification. The comment is purely analytical and does not offer any evidence or reasoning to support its observation. Therefore, it is classified as \"No\" because it lacks a claim that needs verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. While it identifies a potential inconsistency or area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to the equations. The comment lacks depth and actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the applicability of the model to real-world diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in real-world scenarios. However, the comment does not specify which part of the paper should be revised or how the empirical evidence should be presented. The action is implicit and vague, as it leaves the authors to infer the necessary steps to address the concern. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment does not specify which part of the paper discusses the model's applicability or where the empirical evidence should be provided. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs revision. While the comment is specific in its suggestion to provide empirical evidence, the absence of explicit references or sections makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment lacks specific details or examples to substantiate this concern, making it difficult for the authors to understand the basis of the issue. Without additional context or references, the claim remains somewhat verifiable, as it lacks the necessary evidence or reasoning to fully support the authors in addressing the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the applicability of the model to real-world diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in real-world scenarios. This feedback is valuable as it highlights a crucial aspect of the paper that needs further substantiation. However, the comment could be more helpful if it provided specific guidance on how to conduct or present the empirical evidence. Despite this, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the method has been tested on more than two datasets. It suggests that the authors should try more datasets to get a better understanding of the method's performance. However, the comment does not provide explicit guidance on which datasets to use or how to analyze the results. The action is implicit, as the authors need to infer that they should expand their testing to more datasets. The comment is vague because it lacks specific details on which additional datasets to consider or how this expansion would impact the results. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether the method has been tested on more than two datasets, suggesting that the authors should try more datasets to get a better understanding of the method\\'s performance. However, the comment does not specify which datasets were used in the initial testing or provide any guidance on how to select additional datasets. This makes it difficult for the authors to identify the specific part of the paper being addressed, as they cannot determine which section or aspect of the method relates to the testing on datasets. Additionally, the comment lacks specificity in terms of what kind of additional datasets or analyses would be beneficial. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try more datasets to get a better understanding of the method\\'s performance. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the limited scope of testing for the proposed method, noting that it has only been evaluated on two datasets. This feedback is somewhat helpful as it highlights a potential area for improvement, suggesting that the authors should consider expanding their testing to more datasets to gain a better understanding of the method\\'s performance and generalizability. However, the comment lacks specific guidance on which additional datasets to use or how this expansion would impact the results. While it points out a limitation, it does not provide detailed suggestions or actionable steps for the authors to take, which limits its overall helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues regarding the clarity of the description in Section 4.2 and the equation presented. It points out that the description does not align with the equation, particularly noting the absence of a term for r^q, which is the question representation. The reviewer also questions the meaning of \\sigma in the equation, suggesting it might be a sigmoid activation. The comment implies that these issues need clarification to improve the understanding of how the question is used to learn an attention on the image feature. While the action is implicit, the reviewer provides specific areas for clarification, making the comment mostly actionable. The authors can infer that they need to clarify the description and the equation, but the lack of explicit guidance on how to do so makes it somewhat actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the description and the equation, particularly the absence of a term for r^q and the unclear meaning of \\sigma. This provides detailed guidance on what needs to be clarified, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises specific questions about the clarity of the description in Section 4.2 and the equation presented. It points out that the description does not align with the equation, particularly noting the absence of a term for r^q, which is the question representation. The reviewer also questions the meaning of \\sigma in the equation, suggesting it might be a sigmoid activation. The comment implies that these issues need clarification to improve the understanding of how the question is used to learn an attention on the image feature. However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to infer the need for clarification but would not have a clear path to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific feedback on areas where the paper could be improved. It highlights a lack of clarity in Section 4.2, particularly regarding how the question is used to learn an attention on image features. The comment points out a mismatch between the description and the equation, specifically noting the absence of a term for r^q, which is the question representation. Additionally, it questions the meaning of \\sigma in the equation, suggesting it might be a sigmoid activation, and raises concerns about potential numerical instability due to multiplying two sigmoid activations. This feedback is detailed and actionable, providing the authors with clear guidance on how to improve the clarity and accuracy of their work. The comment effectively addresses specific issues and offers constructive suggestions, making it highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks explicit actions or concrete details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section being discussed. It also lacks specificity, as it does not detail what aspects of the contribution are not novel or how the authors might address this issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the contribution is not novel. As a result, the claim is unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are most affected. This feedback is explicit and provides a clear action for the authors to take, which is to generate and include such a plot. The comment is concrete as it specifies exactly what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. The comment is specific in its suggestion to include a plot and analyze weight changes, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. This claim is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors would need to infer the need for such a plot to address the issue of layer-specific weight changes after unlearning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors include a plot showing how different weights of the model change after unlearning. This feedback is actionable and directly addresses a potential area for clarification or further analysis in the paper. By suggesting a visual representation of weight changes across layers, the comment helps the authors enhance the interpretability and depth of their results. However, the comment could be more helpful if it provided additional guidance on how to generate or interpret the plot effectively. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the paper is limited, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty of the paper or what specific aspects need to be improved. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. It provides a detailed explanation of the novelty of the paper, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. This provides clear grounding as the authors can accurately identify the section being addressed. Additionally, the comment specifies what needs to be addressed, highlighting the limited novelty and suggesting that the authors should enhance the novelty of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a specific claim about the novelty of the paper, it lacks detailed reasoning or references to support the assertion that the ENCODE part is already proposed in [10]. Without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10]. It also highlights that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a clear observation about the novelty, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the paper's contribution. Without specific advice on improving the novelty or suggesting alternative approaches, the feedback is somewhat helpful as it directs the authors to consider the limitations of their work. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should address the missing information about the input domain. However, the comment lacks concrete details on what specific information needs to be added or how to clarify the issue. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. However, it does not specify which part of the paper this issue relates to, making it difficult for the authors to pinpoint the exact section or figure where this information should be addressed. The comment is specific in its suggestion to clarify the input domain, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. This feedback highlights a potential gap in the clarity of the paper, as it leaves the authors uncertain about the scope and nature of the inputs being discussed. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as clarifying the input domain or expanding the discussion. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it identifies a potential area for clarification but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with the work mentioned in [A]. However, it does not provide any explicit or implicit suggestions on how the authors should address this comparison or what specific aspects of the comparison should be considered. The comment lacks concrete guidance on how to conduct the comparison or what data or analysis would be necessary. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with a work mentioned in [A]. However, it does not specify which part of the paper this comparison should be made or which sections of the work [A] are relevant. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on what aspects of the comparison should be considered, leaving the authors with no clear direction on how to address the question. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with a work mentioned in [A]. However, it does not provide any specific evidence, reasoning, or references to support the claim that such a comparison is necessary or beneficial. Without additional context or justification, the authors are left to interpret the significance of the question, making it difficult to understand the basis of the comment. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with a work mentioned in [A]. However, it does not provide any suggestions or guidance on how the authors might address this comparison or what aspects of the comparison are important. The comment lacks actionable advice, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies issues with the presentation of the paper, specifically noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. While the comment explicitly states the issue with the presentation and provides a suggestion for improvement, it does not offer concrete guidance on how to create or integrate the illustrative figure into the paper. The action is implicit and somewhat vague, as the authors would need to infer how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue as the presentation being too equation-driven and the notation being convoluted, and suggests that an illustrative figure would have been helpful. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would have been helpful. However, the comment lacks specific examples or references to support the claim about the convoluted nature of the notation or the effectiveness of an illustrative figure. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the paper, noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to create or integrate the illustrative figure effectively. Overall, the comment is mostly helpful as it highlights a significant area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. While the comment highlights a specific issue, it does not provide explicit guidance on how the authors should address this conflict or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to resolve the conflict. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the definition of minimal conditional dependence and the equations, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. The comment provides a clear logical reasoning by pointing out the inconsistency between the definition and the equation. However, it lacks specific examples or references to support the claim, which could make it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, namely a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It highlights a discrepancy between the theoretical expectation and the equation presented, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This feedback is clear and actionable, as it points out a specific area where the authors need to address a potential inconsistency. However, the comment could be more helpful if it provided guidance on how to resolve the conflict or what changes might be necessary. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to improve the subscripts or what specific enhancements could be made. Without concrete suggestions or instructions, the authors are left without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the visual presentation of the data, particularly the subscripts, which could be enhanced for better readability and aesthetic appeal. This provides the authors with a clear understanding of what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to improve the presentation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left with a general idea of what needs to be addressed but without specific steps or examples, which limits the comment's helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but could be more comprehensive with actionable feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. While the comment highlights a point of confusion for the reviewer, it does not provide explicit guidance or suggestions on how to address this confusion or clarify the issue. The authors are left to infer that the comment is intended to prompt them to explain the difference more clearly. The action is implicit and somewhat vague, as it does not specify how to clarify the issue or what aspects of the explanation need improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the explanation of Batch Normalization and Online Normalization in terms of gradient bias. It highlights a point of confusion for the reviewer, who has read other reviews and the author response but remains uncertain about the distinction between the two methods. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in identifying the confusion and suggesting that the authors clarify the difference between the two methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. The reviewer expresses confusion about this distinction and suggests that the authors clarify it. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the distinction is unclear or that the authors need to clarify it. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the reviewer's confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the distinction between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. The reviewer expresses confusion about this distinction and suggests that the authors clarify it. However, the comment lacks detailed guidance or suggestions on how to address this confusion or provide a clearer explanation. It does not offer specific advice on how to improve the clarity or accuracy of the explanation, leaving the authors with limited actionable feedback. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to enhance their draft.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. It also mentions that this formatting issue effectively violates the 9-page paper limit, which is a significant concern. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the formatting. The authors are left without guidance on how to resolve the whitespace problem or enhance the visual presentation of the paper. Therefore, the comment is unactionable as it lacks any direction for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" indicating a specific part of the paper being addressed. It also specifies the issue by detailing the formatting problems with equations and captions, which are common elements in academic papers. The comment is specific in its critique of the formatting, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions too close to the figures. This is presented as a violation of the 9-page paper limit, which is a factual observation. However, the comment lacks specific examples or references to support the claim that this formatting issue is a significant problem or how it impacts the paper's readability or adherence to standards. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. This observation is presented as a potential violation of the 9-page paper limit, which is a significant concern. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the formatting. Without actionable feedback or recommendations, the authors are left without a clear path to resolve the problem. Therefore, the comment is barely helpful, as it highlights a weakness but does not offer any constructive advice for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide explicit guidance on what specific aspects need to be expanded or improved. The comment implies that the authors should elaborate on the technical details and formulations to better showcase the novelty of their work, but it lacks concrete suggestions on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be addressed, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"technical details and formulations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the lack of detail and the potential novelty of the scheme or procedure. This provides clear guidance on how the authors can improve their draft, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the technical details and formulations are limited, suggesting that the novelty lies in the scheme or procedure. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the depth of their technical details. While it highlights an area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the concept of \"local interactions\" in the paper. It asks whether \"local\" refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue or clarify the concept in their draft. The action is implicit, as the authors would need to infer that they need to clarify the definition of \"local interactions\" to avoid confusion. However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references to the paper's sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. This is a subjective question that seeks clarification rather than making a claim that requires verification. The comment does not provide any evidence or reasoning to support a claim, making it a factual statement. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. This question highlights a potential area of confusion for the readers and suggests that the authors should clarify this concept to improve the paper's clarity. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as providing examples or definitions. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper's claim of better results in the Molecule generation experiment (Table 3) and the observation that adding the proposed constrained method yields lower validity and diversity. However, it does not provide explicit or implicit actions for the authors to take. The comment suggests that the authors should re-evaluate their results and consider the impact of the constrained method on validity and diversity. While the authors can infer that they need to address this issue, the comment lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Molecule generation experiment (Table.3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue: the paper claims better results, but the addition of the proposed constrained method yields lower validity and diversity. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper's claim of better results in the Molecule generation experiment (Table 3) is contradicted by the observation that adding the proposed constrained method yields lower validity and diversity. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper's claim of better results in the Molecule generation experiment and the observation that adding the proposed constrained method yields lower validity and diversity. This feedback highlights a potential issue with the paper's claims and suggests that the authors need to re-evaluate their results and consider the impact of the constrained method on validity and diversity. While the comment points out a specific area of concern, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it directs the authors to a critical area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of how archetype positions are updated after initialisation in Algorithm 2. It does not provide explicit instructions or suggestions on how the authors should address this issue, leaving the authors to infer that they need to clarify this aspect in their draft. The action is implicit and vague, as it does not specify what needs to be done to improve the clarity of the algorithm. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the algorithm, namely the lack of clarity regarding how archetype positions are updated after initialisation. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of how archetype positions are updated after initialisation in Algorithm 2. It does not contain a subjective claim or suggestion but rather points out a lack of clarity in the description. The comment is factual and descriptive, as it highlights a specific aspect of the algorithm that needs clarification. Therefore, it is classified as \"No\" because it does not contain a claim that requires verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Algorithm 2, noting that the update mechanism for archetype positions after initialisation is not clear. It raises a question about this aspect, which could help the authors clarify their methodology. However, the comment lacks actionable suggestions or detailed guidance on how to address the issue, making it somewhat helpful. The authors would need to infer that they should provide more details on the update mechanism to improve the clarity of the algorithm. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where additional information is missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are explicit and provide clear guidance on what information needs to be included to improve the paper. The authors can directly apply these actions to enhance the completeness and clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for additional information in the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what specific parts of the paper need improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and suggestions regarding the completeness of the empirical study, including the need for recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are logical and provide clear guidance on what information is missing, making the claim somewhat verifiable. However, the comment could be more robust if it included specific examples or references to support the need for these details. Overall, the comment is mostly verifiable, as it provides a clear basis for improvement but lacks some depth in terms of evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several important areas where additional information is missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, the condition of the resting-state recording (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These suggestions are clear and actionable, providing the authors with specific guidance on what information needs to be included to enhance the completeness and clarity of their draft. The feedback is mostly helpful as it offers detailed and constructive suggestions that would significantly improve the paper, though it could be further expanded to include additional recommendations or examples. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant risk of methods exploiting relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, mentioning that AU6 can occur in both expressions of pain and happiness, and that this co-occurrence differs in datasets like SEMAINE and UNBC pain dataset. The comment suggests that cross-dataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The comment is explicit in identifying the issue and provides a clear action for the authors to take, which is to conduct cross-dataset experiments. This makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"action units\" and \"datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by highlighting the differences in co-occurrences of action units across datasets, such as SEMAINE and UNBC pain dataset. The comment suggests a specific way to test the generalization of the work by performing cross-dataset experiments, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that methods exploiting relationships between action units can lead to different co-occurrences across datasets, as illustrated by the example of AU6 occurring in both pain and happiness expressions. It suggests that cross-dataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The claim is supported by a specific example and a logical suggestion for improvement, making it mostly verifiable. However, it could be strengthened by providing more detailed reasoning or references to support the claim about the differences in co-occurrences across datasets.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the variability of these relationships across different datasets. It provides a clear example, such as the co-occurrence of AU6 in expressions of pain and happiness, and notes that this difference is evident in Figure 1. The comment suggests that cross-dataset experiments would be a good way to test the generalization of such work, which is a valuable and actionable suggestion for the authors. By pointing out this issue and offering a specific direction for improvement, the comment is mostly helpful, as it provides clear guidance on how the authors can enhance their work. However, it could be more comprehensive if it included additional suggestions or elaborated on the implications of this variability.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional detail would be beneficial, it does not explicitly instruct the authors to provide this description or specify how it should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the description of the Starcraft environment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this description should be included in or how it should be integrated. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also specific in terms of suggesting the inclusion of more description, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional description would be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While this feedback provides a specific area for improvement, it lacks depth and actionable guidance. The authors are left to infer that additional detail would enhance the paper, but the comment does not offer specific suggestions or examples of how to improve the description. Therefore, the comment is somewhat helpful, as it identifies a potential area for enhancement but does not provide comprehensive guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the statement about over-parametrization leading to overfitting and worse performance, suggesting that over-parametrization can be beneficial in practice. It also mentions theoretical work supporting the benefits of over-parametrization. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address the critique or incorporate the suggested benefits into their work. As a result, the authors are left without clear directions on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (line 47-48), allowing the authors to accurately identify the part being addressed. It also provides specific feedback by questioning the statement about over-parametrization and suggesting that it might be beneficial in practice, referencing theoretical work. This feedback is clear and specific, guiding the authors on how to address the critique and incorporate additional insights. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the statement about over-parametrization leading to overfitting and worse performance, suggesting that over-parametrization can be beneficial in practice. It references theoretical work supporting this benefit, providing a basis for the critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from a more detailed explanation or additional evidence to fully understand the critique and address it effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques a statement about over-parametrization, suggesting that it is not always detrimental and can be beneficial in practice. It references theoretical work that supports the benefits of over-parametrization, providing a counterpoint to the initial statement. However, the comment lacks specific guidance on how the authors might address this critique or incorporate the benefits of over-parametrization into their work. While it offers a valuable perspective, the feedback could be more helpful if it included actionable suggestions or examples of how to improve the draft based on the critique. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to improve the efficiency of the training process or how to compare the processing efficiency with existing work. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment highlights a potential issue with the methodology, it lacks specificity in detailing what needs to be addressed or how to improve the efficiency. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time-consuming nature of the training process due to the pixel-level shape model and the independent training on all font images and characters. It also mentions the complexity of the parsing model as a high-order factor graph with four types of factors. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the efficiency of their training process. While it points out a potential area for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors combine two existing techniques without innovation and questions the use of an old and simple domain adaptation method. It implies that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not provide explicit guidance on which specific methods to use or how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the need for improvement and the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the combination of two existing techniques and the use of an old and simple domain adaptation method. It provides specific guidance on why the authors should consider using more recent and effective domain adaptation methods to improve performance. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors combine two existing techniques without innovation and questions the use of an old and simple domain adaptation method. It suggests that more recent and effective methods could be used to improve performance. However, the comment lacks specific examples or references to support the claim about the novelty of the combination or the effectiveness of the proposed methods. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment borderline verifiable. Therefore, the label is 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the authors' approach by suggesting that the combination of two existing techniques lacks innovation. It questions the use of an old and simple domain adaptation method, implying that more recent and effective methods could be used to improve performance. This feedback is somewhat helpful as it points out a potential area for improvement and encourages the authors to consider more advanced techniques. However, the comment could be more helpful if it provided specific examples of recent domain adaptation methods or suggested alternative approaches. Overall, the comment offers a clear direction for enhancing the work, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This is a clear and explicit action that the authors can readily follow. The comment provides specific guidance on what needs to be included in the discussion, making it highly actionable. Therefore, this comment is rated as 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to know exactly where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This is a suggestion for improvement, but it lacks specific details or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the transparency and reproducibility of the research. By addressing this suggestion, the authors can strengthen their paper and provide valuable context for their work. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive if it included additional suggestions or examples.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the clarity of the motivation or how to differentiate their work from incremental contributions. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not specify which part of the paper is difficult to follow or where the motivation is discussed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide detailed feedback on what aspects of the motivation are unclear or how the paper might be perceived as incremental. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is difficult to follow and suggests it might be an incremental engineering paper. However, it does not provide any specific evidence, examples, or references to support these claims. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the difficulty in following the motivation and the perception of it being an incremental engineering paper. While these points highlight areas for improvement, the comment lacks specific guidance or suggestions on how the authors might address these issues. It does not provide actionable advice or examples of how to enhance the clarity of the motivation or differentiate the work from incremental contributions. As a result, the feedback is somewhat helpful, as it points out areas for improvement but does not offer detailed guidance for the authors to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study on the weighting method of the cross-entropy loss would be beneficial. It also mentions an example where the authors' method underperforms due to repetitive background sounds, which the reviewer expects the weighting method to address. While the comment provides a clear action\u2014asking for an ablation study\u2014it does not specify how the authors should conduct this study or what aspects of the weighting method should be explored. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an ablation study on the weighting method of the cross-entropy loss, referencing an example where the authors' method underperforms due to repetitive background sounds. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting an ablation study, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an ablation study on the weighting method of the cross-entropy loss, referencing an example where the authors' method underperforms due to repetitive background sounds. However, the comment lacks specific details or examples to substantiate the claim that the weighting method could have helped remedy this issue. Without further explanation or evidence, the claim remains somewhat verifiable, as it is based on an inference rather than a direct observation or logical reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an ablation study on the weighting method of the cross-entropy loss, noting that the authors' method underperforms due to repetitive background sounds. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific example to consider. However, the comment lacks detailed guidance on how to conduct the ablation study or what aspects of the weighting method should be explored. While it points out a relevant issue, it does not offer comprehensive suggestions for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical weakness in the paper, stating that it lacks novelty and is incremental in nature. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit suggestions on how the authors might address these issues or improve the paper. The authors are left without guidance on how to enhance the novelty or significance of their work, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper discusses the dataset or the approach, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique of the novelty and approach, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, criticizing the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentioning another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. This feedback provides a clear and actionable critique that highlights the need for the authors to address the novelty and significance of their work. However, the comment could be more helpful if it offered suggestions on how the authors might enhance the novelty or significance of their approach. Despite this, the comment is mostly helpful as it directs the authors to areas that require improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are only conducted on one game environment and that more experiments are necessary. While the comment implies that additional experiments should be performed, it does not specify which additional environments or types of experiments would be beneficial. The authors are left with a general direction for improvement but lack concrete guidance on how to execute it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific details on how to implement the suggested action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are only conducted on one game environment and that more experiments are necessary. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors cannot confidently determine which section needs revision, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what additional experiments should be conducted or why the current single environment is insufficient. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to assume the validity of the claim, making it difficult to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the experiments are only conducted on one game environment. This feedback is clear and actionable, as it highlights a specific area where the authors could enhance their work by conducting additional experiments. However, the comment lacks depth and does not provide suggestions on which additional environments or types of experiments would be beneficial. While it points out a necessary improvement, it does not offer a comprehensive guide for the authors to address this issue. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not provide specific guidance on how to demonstrate the importance of these assumptions or what kind of examples would be effective. The action is implicit, as the authors need to infer that they should provide detailed explanations and examples to support their claim. The comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for detailed explanations and examples, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide a detailed explanation of why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. This feedback is actionable and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it included specific examples or guidance on how to demonstrate the importance of these assumptions. Overall, the comment is mostly helpful as it directs the authors towards a crucial aspect of their work that needs further elaboration.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet-18, and mentions the accuracy is around 70%. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to improve the implementation. While the authors might infer that they need to optimize their implementation, the lack of explicit instructions or detailed suggestions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ImageNet\" and provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet-18, as well as the accuracy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the performance issues with the implementation, including the time taken and the accuracy, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' implementation of ImageNet is slow and has low accuracy, providing specific details such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and an accuracy of around 70%. This claim is supported by specific numerical data, making it mostly verifiable. However, the comment could be strengthened by providing more context or comparison to other implementations, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete data, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and mentions the accuracy is around 70%. This feedback is clear and actionable, as it highlights a significant performance issue that the authors need to address. However, the comment could be more helpful if it suggested specific steps or strategies for improving the implementation's speed and accuracy. Despite this, the comment provides valuable insights that can guide the authors in enhancing their work, making it mostly helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and M-PHATE in Figure 3. Additionally, the comment questions the purpose of examining the learning curves, asks about the accuracy of the models, and whether worse-performing models always lead to structural collapse. While the comment provides several specific actions, it lacks a clear and explicit instruction on how to implement these suggestions. The authors are left to infer the exact steps needed to address each point, making the feedback somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and M-PHATE in Figure 3. Additionally, it questions the purpose of examining the learning curves, asks about the accuracy of the models, and whether worse-performing models always lead to structural collapse. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. It is specific in detailing what needs to be addressed, such as adding explanations and clarifying the correspondence between learning curves and M-PHATE. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point contains several claims that require justification. For instance, it questions the purpose of examining learning curves and asks about the accuracy of the models, suggesting that worse-performing models might lead to structural collapse. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The request for a detailed explanation of the correspondence between learning curves and M-PHATE is logical but lacks sufficient evidence. Overall, the comment is somewhat verifiable, as it provides some reasoning but lacks depth and specific examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides several suggestions for improving the draft, such as adding more sentences to explain the experimental setting for continual learning and clarifying the correspondence between learning curves and M-PHATE in Figure 3. It also questions the purpose of examining the learning curves and asks about the accuracy of the models, which could help the authors understand the significance of their results. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to address these points or why they are important. While the feedback is somewhat helpful, it could be more comprehensive and actionable to fully assist the authors in improving their draft. Therefore, the comment is rated as 4: Mostly Helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, it does not provide explicit or implicit actions for the authors to take, such as conducting experiments or providing feedback on the use of labeled data. The comment lacks concrete guidance on how the authors might address this question or incorporate the suggestion into their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. While it is specific in its suggestion about the use of labeled data, the lack of grounding makes it challenging for the authors to understand the context and relevance of the comment. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, the comment does not provide any specific reasoning, examples, or references to support the claim that labeled data could be beneficial. Without detailed justification or evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. It provides a specific example of how labeled data might be beneficial, referencing two relevant papers on graph contrastive learning. However, the comment lacks actionable guidance or suggestions for the authors to explore this idea further. It does not offer concrete steps or insights on how the authors could incorporate labeled data into their consistency training process or how this might impact their results. While the comment identifies an interesting area for exploration, it does not provide sufficient direction or depth to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental part needs to be reorganized and further improved. It highlights that the current experimental content in the main text does not effectively showcase the superiority of the method. The comment implies that the authors should reorganize the experimental section to better highlight the method's advantages. However, it does not provide specific guidance on how to reorganize the content or what aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental part needs to be reorganized and further improved, indicating that the authors should reorganize the experimental section to better highlight the method\\'s superiority. However, the comment does not specify which part of the paper the experimental section is located in, making it weakly grounded. It also lacks specificity in detailing what aspects of the experimental content need to be improved to showcase the method\\'s superiority. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the experimental part needs to be reorganized and further improved, indicating that the current content in the main text does not effectively highlight the superiority of the method. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without additional information or guidance, the claim remains somewhat verifiable, as it is based on an observation without clear justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for reorganization and improvement in the experimental part of the paper. It points out that the current content in the main text does not effectively highlight the superiority of the method, suggesting that the experimental section should be restructured to better showcase this aspect. However, the comment lacks specific guidance on how to reorganize the content or what particular improvements should be made. While it provides a clear direction for improvement, the absence of detailed suggestions or examples limits its helpfulness. Therefore, the comment is somewhat helpful, as it offers a general idea but could be more comprehensive with actionable feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors\\' claim that their proposed classification network is universally as good as the standard softmax network, particularly in terms of classification accuracy. It suggests that building a new model for better out-of-distribution detection might come at the cost of reduced classification accuracy. The comment implies that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. While the comment suggests specific actions, such as reporting accuracy and providing theoretical justifications, it does not provide detailed guidance on how to implement these actions or what specific aspects of the model should be analyzed. The actions are somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors proposing a new classification network, allowing the authors to identify the specific part of the paper being addressed. It also specifies what the authors should report, namely the classification accuracy of the proposed classifier on ImageNet data, as well as the need for theoretical justifications. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the classification accuracy of the proposed network compared to the standard softmax network, particularly in the context of out-of-distribution detection. It suggests that the authors should report the classification accuracy on ImageNet data and provide theoretical justifications. However, the comment lacks specific examples or references to support the claim that the proposed network is universally as good as the standard softmax network. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors would need to provide additional information to substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the classification accuracy of the proposed network compared to the standard softmax network, particularly in the context of out-of-distribution detection. It questions whether the new model might sacrifice classification accuracy while improving out-of-distribution detection. The comment suggests that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on what experiments or analyses the authors should conduct. However, it could be more helpful if it included suggestions for alternative metrics or comparisons with other models. Overall, the comment is mostly helpful, as it offers valuable insights and actionable feedback that can guide the authors in enhancing their draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or what specific actions they should take to improve their draft. The action is implicit and vague, leaving the authors without clear direction on how to respond. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practical implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide any specific examples, reasoning, or references to support the claim that such an exhaustive list is difficult to implement or test. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. This feedback highlights a potential gap in the paper's discussion or methodology, suggesting that the authors need to address the feasibility and practicality of their approach. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the draft. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It suggests that the proposed method, which was pre-trained before fine-tuning, might have an advantage over methods that were not pre-trained in the same way. The comment implies that the authors should clarify the initialization conditions of the compared methods to ensure a fair comparison. However, it does not provide explicit guidance on how to address this issue, such as suggesting specific steps to ensure fair initialization or providing additional details on the experimental setup. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potentially address it in their response. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental comparison with other methods, specifically questioning the fairness of the comparison due to the pre-training of the proposed method before the fine-tuning stage. It highlights that the compared methods might not have been initialized with the same or similar pre-trained models, which could lead to an unfair comparison. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it clearly specifies the issue with the experimental setup and provides a detailed explanation of why the comparison might be unfair. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison with other methods is unfair due to the proposed method being pre-trained before fine-tuning, while the compared methods might not have been initialized with the same or similar pre-trained models. The comment provides a logical reasoning by suggesting that this difference in initialization could explain the inferior performance of the proposed method without SSL, as shown in Table 1. However, the claim lacks specific examples or detailed references to support the assertion that the compared methods were not initialized with similar pre-trained models. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. The comment highlights that the proposed method, which was pre-trained before fine-tuning, might have an advantage over methods that were not pre-trained in the same way. This observation is important for ensuring a fair comparison and understanding the true performance of the proposed method. However, the comment could be more helpful if it provided specific guidance on how to address this issue, such as suggesting additional experiments or clarifying the initialization conditions of the compared methods. Overall, the comment is somewhat helpful as it points out a potential weakness in the experimental setup, but it lacks detailed suggestions for improvement, making it partially beneficial for the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that the meta-data used in the zero-shot learning results on the CUB dataset (Table 3, page 7) are \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing Table 1 of \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" The comment also acknowledges the authors' response and concludes that the paper is acceptable for NIPS. This feedback is explicit and provides a clear action for the authors to take, which is to update their results with better meta-data embeddings. The comment is detailed and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"zero-shot learning on CUB dataset\" and \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improvement by recommending the use of better meta-data embeddings options, referencing a specific paper. This guidance is clear and actionable, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta-data used in the zero-shot learning results on the CUB dataset (Table 3, page 7) are \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing Table 1 of \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" This claim is mostly verifiable as it provides a reference to support the suggestion of using better meta-data embeddings. However, it could be more robust with additional examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the results of zero-shot learning on the CUB dataset, noting that the meta-data used is \"attribute,\" which is good for fair comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing a specific paper. This feedback is actionable and constructive, as it guides the authors to consider enhancing their method with more advanced meta-data embeddings. The comment is clear and provides a clear direction for improvement, making it highly helpful. However, it could be more comprehensive if it included additional suggestions or considerations for the authors to address. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a plot comparing the flexibility of SGC with LoRA, using sparsity on the x-axis and performance on the y-axis. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is explicit and detailed, guiding the authors on how to implement the suggested improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SGC\" and \"LoRA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a concrete action: including a plot with sparsity on the x-axis and performance on the y-axis to compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed, making the comment highly specific and grounded. Therefore, this comment is rated as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that PEFT methods typically target compute-constrained scenarios, where fine-grained control may require extra tuning, thus reducing practicality. The comment suggests including a plot comparing SGC with LoRA, using sparsity on the x-axis and performance on the y-axis. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about PEFT methods. The suggestion to include a plot is clear and actionable, making the comment mostly verifiable. Therefore, the comment is rated as 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the applicability of SGC, suggesting that PEFT methods, such as LoRA, are more practical in compute-constrained scenarios due to their ability to target specific parts of the model without extensive tuning. The comment provides a clear and actionable suggestion to include a plot comparing SGC with LoRA, using sparsity on the x-axis and performance on the y-axis. This visualization would help illustrate the practical benefits of SGC\u2019s fine-grained control at different sparsity levels. By offering a specific and constructive suggestion, the comment is highly helpful in guiding the authors to improve their draft. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the proposed method is its computational time, and it recommends publishing the code. However, the comment does not provide explicit guidance on how to address the question or what specific actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to respond or what changes to make. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its inquiry about the training time difference, the lack of grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the proposed method is its computational time and recommends publishing the code. However, the comment lacks specific reasoning or evidence to support the claim that the training time difference is reasonable or that the code should be published. Without detailed justification or examples, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the proposed method is its computational time and recommends publishing the code. However, the comment lacks specific guidance or detailed reasoning to support the claim, making it difficult for the authors to understand the basis for the question or how to address it. The feedback is somewhat helpful as it identifies an area for clarification but does not provide actionable steps or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. It does not provide explicit instructions on how to address these points, such as suggesting specific sections or types of descriptions to include. The comment is somewhat vague, as it implies that the authors should consider these aspects but does not offer concrete guidance on how to do so. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. While it is specific in terms of the content it suggests, the lack of grounding makes it difficult for the authors to act upon. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the paper regarding the concept of Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It asks for clarification on why entropy is not a good measure of the spreading of teacher predictions, specifically referencing line 115 and line 113. However, the comment does not provide any evidence, reasoning, or references to support these claims. The authors are left to interpret the questions and potentially seek clarification from the authors or external sources, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also raises a question about why entropy is not a good measure of the spreading of teacher predictions, referencing specific lines in the paper. While the comment highlights a potential gap in the paper's explanation and provides a clear direction for improvement, it lacks detailed guidance on how to address these issues or what specific aspects of the paper need clarification. The feedback is somewhat helpful as it points out areas that require further explanation, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the human baseline's performance and the claim made in the abstract. It points out that the human baseline is based on a 1-hour recording, which is less than the 15-hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the draft. The action is implicit, as the authors need to infer that they should clarify the discrepancy in the human baseline's performance and the abstract's claim. The action is somewhat vague, as it does not specify how to address the issue or what changes to make. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the human baseline by pointing out that it is based on a 1-hour recording, which is less than the 15-hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also mentions the abstract, where the authors claim that the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources.\" This suggests that the abstract's claim might be misleading due to the discrepancy in the recording duration. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the human baseline and the misleading claim in the abstract, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the human baseline is based on a 1-hour recording, which is less than the 15-hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also points out that the abstract claims the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources,\" which is misleading given the 1-hour vs. 15-hour discrepancy. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the basis of the claim and seek additional evidence to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the human baseline's performance, noting that it is based on a 1-hour recording compared to the 15-hour recording used for the model baseline. This makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also highlights a misleading claim in the abstract, where the authors mention that the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources.\" This discrepancy suggests that the abstract's claim might be inaccurate due to the difference in recording duration. While the comment points out a specific issue, it does not provide detailed guidance on how the authors should address this discrepancy or clarify the misleading claim in the abstract. The feedback is somewhat helpful as it identifies a critical issue that needs attention, but it lacks depth and actionable suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the strong assumptions made for the termination states of instructions, particularly in the general case where manual labeling of large datasets is expensive. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment identifies a potential problem but lacks guidance on how the authors might address it, such as suggesting alternative assumptions or methods for handling the cost of labeling. Without specific actions or suggestions, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, noting that it is strong and expensive to label data manually in the general case. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure being referenced. The comment is specific in its critique of the assumption but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is strong and expensive to label data manually in the general case. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer's assertion remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumptions made for the termination states of instructions, specifically noting that it is expensive to label data manually in the general case. This feedback highlights a limitation in the current approach and suggests that the authors should consider alternative assumptions or methods to address the cost of labeling. However, the comment lacks specific guidance or suggestions on how to implement these changes, making it somewhat helpful. The authors are informed about a potential weakness but are not provided with actionable steps to improve their work. Therefore, the comment aligns with a score of 3, as it offers some insight but requires further elaboration to be fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It suggests that the paper should be more explicit about the contribution, noting that the approach involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer expresses confusion about the paper's point until this clarification is provided. While the comment identifies a specific issue and suggests a way to address it, it does not provide explicit guidance on how to make the contribution clearer or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the nature of the contribution with respect to ECE_sweep, specifically mentioning that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. This provides a clear reference to a specific part of the paper, allowing the authors to identify the issue. The comment is specific in detailing what needs to be addressed, as it highlights a lack of clarity regarding the contribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not clearly describe the nature of the contribution with respect to ECE_sweep, specifically mentioning that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that this is not fundamentally different and would prefer the paper to be upfront about the contribution. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the basis of the claim, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It highlights that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer expresses confusion about the paper's point until this clarification is provided, indicating that the paper could be more explicit about its contribution. While the comment points out a specific area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it directs the authors to clarify their contribution, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is explicit and provides a clear action for the authors to take: they should consider incorporating these methods as baselines in their experiments. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a gap in the related work by noting that while other methods for training NMT models beyond MLE are discussed, none of them are used as baselines. This provides a clear and specific direction for the authors to improve their draft by including these methods as baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section discusses other methods for training NMT models beyond MLE but does not include any of these methods as baselines. This claim is somewhat verifiable as it highlights a gap in the related work section, but it lacks specific examples or references to support the claim. The authors would need to infer that the omission of these methods as baselines is a significant oversight. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the related work section by noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is clear and actionable, as it provides a specific suggestion for improvement: the authors should consider incorporating these methods as baselines in their experiments. By doing so, the authors can provide a more comprehensive comparison and better contextualize their work. This feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive if it suggested specific methods or baselines to include. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential ambiguity in the terminology used in the paper, specifically regarding the term \"efficient proxy.\" It questions whether the authors are referring to a specific proxy or a family of efficient proxies. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should clarify this point or suggest specific changes to the text. The action is implicit, as the authors need to infer that they should clarify the terminology, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the terminology used in the paper, particularly the term \"efficient proxy.\" It questions whether the authors are referring to a specific proxy or a family of efficient proxies, noting that the use of \"is\" suggests a particular proxy, while the lack of a specific proxy named \"Efficient Proxy\" implies a broader reference. However, the comment does not specify which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in detailing the ambiguity in the terminology, but without explicit references to sections or figures, it is difficult for the authors to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the terminology used in the paper, specifically regarding the term \"efficient proxy.\" It points out that the use of \"is\" suggests a particular proxy, while the lack of a specific proxy named \"Efficient Proxy\" implies a broader reference. This raises a valid concern about the ambiguity in the terminology, which could lead to confusion for readers. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to clarify the terminology to avoid misinterpretation, but the comment lacks detailed guidance on how to do so. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential ambiguity in the terminology used in the paper, specifically regarding the term 'efficient proxy.' It questions whether the authors are referring to a specific proxy or a family of efficient proxies, noting that the use of 'is' suggests a particular proxy, while the lack of a specific proxy named 'Efficient Proxy' implies a broader reference. This feedback highlights a need for clarification in the terminology, which could improve the precision and understanding of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, making it somewhat helpful. The authors would benefit from clarifying the terminology to avoid confusion, but the feedback lacks depth and actionable advice, thus aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any explicit or implicit suggestions for improvement or action. The authors are left without guidance on how to address this combination of methods or why it might be problematic. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not specify which part of the paper this combination is discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the methods used, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any critical feedback or reasoning that would help the authors understand why this combination might be problematic or how it could be improved. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any critical feedback, suggestions, or reasoning that would help the authors understand why this combination might be problematic or how it could be improved. The comment lacks actionable insights and does not offer any guidance on addressing the described methods. As a result, it is not helpful to the authors in improving their draft. Therefore, it should be rated as 1: Not Helpful at All.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The suggestion to explore the resilience of the metric to the choice of random projection is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable, as it does not provide clear instructions or specific steps for the authors to follow. The comment is also somewhat vague, as it does not specify how to analyze the variability or what kind of analysis would be helpful. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its suggestion to explore the resilience of the metric to the choice of random projection, but without explicit references to the appendix or specific sections, the authors may find it challenging to pinpoint the exact area to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix. However, the comment lacks specific examples or references to support the claim that pathological projection matrices could skew the scores. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix, which could be a valuable insight for improving the robustness of their findings. However, the comment lacks specific guidance on how to address this issue or what steps the authors should take to explore the resilience of their metric to different random projection matrices. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide actionable advice, making it somewhat helpful. The comment could be more helpful if it offered suggestions on how to analyze the variability or what kind of analysis would be beneficial. Therefore, the comment aligns with a score of 3, as it provides some insight but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides several specific questions and suggestions for the authors to address. It asks for an example of synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests explicitly writing down the model used in the appendix. These actions are clear and direct, allowing the authors to understand exactly what needs to be done to improve their draft. The comment is fully actionable as it provides concrete guidance on how to address the issues raised. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear questions and suggestions for the authors to clarify and improve their work, such as asking for an example of synthetic data and explaining the meaning of \"support data\" and \"predicted training count data.\" This level of detail ensures that the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and suggestions for the authors to clarify and improve their paper. It does not contain any subjective opinions or claims that require verification. The questions are logical and straightforward, guiding the authors to provide additional context and details. Therefore, this comment is classified as \"No\" because it does not contain any claims that need to be verified.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific questions and suggestions for the authors to address, such as asking for an example of synthetic data, clarifying the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggesting explicitly writing down the model used in the appendix. These requests are clear and actionable, offering the authors concrete guidance on how to improve their draft. By addressing these points, the authors can enhance the clarity and completeness of their work. Therefore, the comment is mostly helpful, as it provides valuable feedback that can significantly improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the performance should be evaluated. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods, implying that the evaluation is currently only used for the ablation study. However, the comment does not specify which part of the paper discusses the evaluation of FGT or the ablation study, making it weakly grounded. It is specific in suggesting that the evaluation should be expanded, but without clear guidance on how to do so. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of FGT is only used to assess the method performance in the ablation study, suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of the proposed method, noting that the current evaluation of FGT is limited to the ablation study and suggests that it should be used to assess the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a specific direction for improvement. However, it could be more helpful if it included suggestions on how to conduct this additional evaluation or what specific aspects of performance should be considered. Overall, the comment is mostly helpful as it highlights a clear area for improvement and provides a basis for further action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model is overly simple, which could be a feature or a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit actions or concrete steps that the authors can take to improve their model. As a result, the authors are left without a clear understanding of what changes are needed or how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the model is overly simple, which could be a feature or a bug. However, it does not specify which part of the paper this issue is related to, such as the methodology, experimental setup, or results. Without this context, the authors cannot determine where the issue lies and how to address it. The comment is not grounded as it does not provide specific references or sections of the paper. It is also not specific because it does not detail what aspects of the model's simplicity are problematic. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the model is \"overly simple,\" but it does not provide any specific reasoning or evidence to support this assertion. Without detailed justification or examples, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model's simplicity, suggesting that it might be overly simplistic. However, it does not provide any specific details or suggestions on how this simplicity could be addressed or improved. The comment lacks actionable guidance, leaving the authors without a clear understanding of what changes might be necessary to enhance the model. As a result, the feedback is not particularly helpful, as it does not offer constructive advice or insights that could guide the authors in improving their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work's narrow focus on a specific task and language might limit its broader impact. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might broaden the scope or impact of their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It provides a general observation about the narrow focus of the work, but without referencing specific sections or elements, the authors cannot confidently identify the area that needs attention. The comment is also not specific, as it does not detail what aspects of the work could be broadened or how the impact might be limited. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work's narrow focus on a specific task and language might limit its broader impact. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the work, specifically that its narrow focus on a specific task and language might limit its broader impact. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or broaden the scope of their work. Without actionable feedback or suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the paper, specifically questioning how it contributes novelly to the understanding of the winner-take-all property given that similar findings have been reported in previous works. However, it does not provide explicit or implicit actions for the authors to take to address these concerns. The comment lacks guidance on how to demonstrate the novelty of the paper or how to expand on the findings to differentiate them from previous work. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the originality of the paper by questioning the novelty of the findings in light of previous works that have explored the winner-take-all property. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in that it highlights the concern about the novelty of the findings, but without clear guidance on how to address this issue, the comment is somewhat actionable. Therefore, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's findings are not novel, as similar results have been reported in previous works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is not fully verifiable, as it relies on the authors' interpretation of the existing literature. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novelly to the understanding of the winner-take-all property given that similar findings have been reported in previous works. While the comment identifies a potential issue with the paper's novelty, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. The feedback is somewhat helpful as it highlights an important aspect of the paper that needs attention, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of run-times in the experiments to aid readers in applying the method. While the comment provides explicit actions\u2014mentioning the computational cost and including run-time examples\u2014it does not specify how to integrate these elements into the main paper or experiments. The actions are clear and concrete, but the lack of detailed guidance on implementation makes the comment somewhat actionable. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method and include a rough example of run-times in the experiments. However, it does not specify which part of the paper this should be included in, making it weakly grounded. The comment is specific in its suggestion to include the computational cost and run-time examples, which would help the authors improve the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method and include a rough example of run-times in the experiments. This claim is somewhat verifiable as it provides a logical suggestion for improving the paper's clarity and motivation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by mentioning the negligible computational cost of CHR and suggesting the inclusion of run-time examples in the experiments. This feedback is actionable and offers concrete guidance on how the authors can enhance the motivation and clarity of their work. By addressing these points, the authors can better motivate their method and provide readers with a clearer understanding of its practical implications. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. The comment is explicit in its request for clarification and provides a concrete action for the authors to take, which is to elaborate on the process and its interpretation. This guidance is clear and specific, allowing the authors to understand exactly what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the interpretation of the EEG topography plots and suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This provides a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the ambiguity in interpreting Figure 3, which presents EEG topography plots for both input and output during the EEG token quantization process. The comment suggests that the authors should elucidate this procedure in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. However, the comment does not provide specific examples or references to support the claim that the spatial arrangement of EEG sensors played a role in the process. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting the ambiguity in interpreting the EEG topography plots during the EEG token quantization process. It suggests that the authors should elucidate this procedure in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and interpretability of their results. By addressing this suggestion, the authors can enhance the understanding of their methodology and its implications, making the paper more accessible and impactful. Therefore, the comment is highly helpful, as it offers constructive guidance for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this suggestion or what changes they should consider making to their draft. Without specific instructions or suggestions, the authors are left without a clear path forward, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where these distances are discussed. This lack of grounding makes it difficult for the authors to understand where the comment applies and what changes might be necessary. Additionally, the comment does not provide specific guidance on how the authors might address this issue or what changes could be made to their draft. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how it might impact their work. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential redundancy in the paper by suggesting that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While the comment identifies a potential area for simplification, it does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their draft. Without actionable advice or detailed reasoning, the comment is somewhat helpful as it highlights a potential area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment does not provide explicit guidance on how the authors should revise their approach to address the problem more directly. The action is implicit and vague, as it does not specify what changes need to be made to align with the reviewer\\'s critique. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the approach but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. This critique suggests that the approach does not directly address the problem. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without clear justification or examples, the claim is considered borderline verifiable, as it provides some basis but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case, and suggests that this approach does not directly address the problem. While the comment identifies a potential issue with the methodology, it lacks specific guidance on how the authors might address this concern or improve their approach. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, as it offers some insight but could be more comprehensive and helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by Nguyen-Tang et al. (AAAI\u201921). It implies that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide explicit guidance on how the authors should incorporate this information into their draft or suggest specific sections to address. The action is implicit and somewhat vague, as the authors need to infer that they should discuss moment matching and its relevance to DRL. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, lines 22-30, where the discussion of distributional RL occurs. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue: the paper lacks relevant literature on using moment matching for DRL, suggesting that this should be discussed. The authors are informed about the specific area where the literature gap exists, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by Nguyen-Tang et al. (AAAI\u201921). The comment suggests that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to seek additional information to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where additional literature could be discussed, particularly regarding the use of moment matching in distributional reinforcement learning. It provides a specific example of relevant work, referencing Nguyen-Tang et al. (AAAI\u201921), which could enhance the paper's comprehensiveness. However, the comment could be more helpful if it offered additional guidance on how to integrate this information or suggested specific sections where the discussion should be expanded. Overall, the feedback is somewhat helpful as it points out a potential area for improvement but lacks detailed instructions for the authors to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. The comment is explicit in its suggestion and provides concrete details on how the authors can address the issue by including these comparisons. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. However, the comment lacks detailed reasoning or references to support why these comparisons are necessary or how they would enhance the paper. The suggestion is somewhat verifiable as it provides a clear direction but lacks depth in justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a concrete example of a baseline to consider, which is testing on a smaller subset of RepoEval. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating additional baselines. However, the comment could be more helpful if it provided more detailed guidance on how to implement these comparisons or why they are essential. Overall, the comment is mostly helpful as it provides a valuable suggestion for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria used for this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detail and consider additional tasks or datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in that it highlights a potential issue with the scope of the evaluation, but without clear references, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not provide any specific reasoning, examples, or references to support why this choice might limit generalizability or what alternative approaches could be considered. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It questions the criteria behind this selection and suggests that the authors should provide more insight into why this specific subset was chosen. This feedback is somewhat helpful as it highlights a potential limitation in the scope of the evaluation and encourages the authors to consider the broader applicability of their findings. However, the comment could be more helpful if it provided specific examples or criteria for the selection of the subset, or suggested alternative tasks or datasets that might yield different insights. Overall, the comment offers a starting point for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. While it points out that the authors may be assuming tumour growth, it does not provide explicit guidance on how to address this ambiguity. The comment suggests that the authors should clarify the specific aspects being modelled, but it does not offer concrete steps or examples on how to do so. As a result, the authors are left with a vague understanding of what needs to be addressed, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of clarity regarding what is being modelled in the context of modelling curves, particularly in the second paragraph of the introduction. This provides the authors with a clear understanding of the specific area that needs improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential issue with the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It suggests that the authors may be assuming tumour growth, but it does not provide any specific examples or references to support this claim. Without additional context or evidence, the claim remains somewhat verifiable, as the authors are left to infer the intended meaning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modelling curves but lacks clarity on what is being modelled. This feedback is clear and actionable, as it directs the authors to improve the clarity of their writing in the introduction. However, the comment could be more helpful if it provided suggestions on how to clarify the modelling process or examples of what could be modelled. Overall, the comment is somewhat helpful as it highlights an area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues. First, it questions the rationale behind using shift=0 compared to shift~ N ( 0 , \u03c3 2 ) in the shifted-MNIST experiment, suggesting that both cases incorporate a domain shift. This implies that the authors need to clarify why one approach is preferred over the other. Second, the comment suggests that it would be beneficial to show the performance of the model and baselines on test samples from the observational (in) distribution. This provides a clear action for the authors to take, which is to include additional results that would help clarify the model's performance under different conditions. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses two distinct issues related to the shifted-MNIST experiment. First, it questions the rationale behind using shift=0 compared to shift~ N ( 0 , \u03c3 2 ), suggesting that both cases incorporate a domain shift. This part of the comment is not grounded as it does not specify which part of the paper it is referring to. Second, it suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, which is also not grounded as it does not specify which part of the paper this relates to. However, the comment is specific in detailing what needs to be addressed, such as clarifying the rationale for the shift parameter and providing additional performance results. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: first, it questions the rationale behind using shift=0 compared to shift~ N ( 0 , \u03c3 2 ) in the shifted-MNIST experiment, suggesting that both cases incorporate a domain shift. This implies a need for clarification, but the comment does not provide specific reasoning or evidence to support why one approach might be preferred over the other. Second, it suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, which is a logical request for additional results. However, the comment lacks detailed reasoning or references to support why this additional data would be beneficial. Overall, the comment is somewhat verifiable, as it provides some justification but lacks depth and specific examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important points that could enhance the clarity and robustness of the paper. First, it questions the rationale behind using shift=0 compared to shift~ N ( 0 , \u03c3 2 ) in the shifted-MNIST experiment, suggesting that both cases incorporate a domain shift. This implies that the authors need to clarify why one approach is preferred over the other, which is a valuable piece of feedback for improving the understanding of the experimental setup. Second, the comment suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, which would provide additional insights into the model's performance under different conditions. This feedback is clear and actionable, offering specific guidance on how the authors can improve their draft. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the suggestions. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the experimental description, which makes it difficult for readers to judge the results. It suggests that the authors should provide more clarity to allow readers to better understand the experimental setup. However, the comment does not explicitly instruct the authors on what specific aspects of the description need to be improved or how to enhance clarity. While the authors can infer that they should add more detail, the action is not concrete and lacks specific guidance on what to include. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of detail in the experimental description, which is crucial for readers to judge the results. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of experimental details is lacking in clarity, making it difficult for readers to judge the results. However, the comment does not provide specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the lack of detail in the experimental description, which hinders the reader's ability to judge the results. It provides a clear and actionable suggestion to improve the clarity of the experimental details, making it somewhat helpful. However, the comment could be more helpful if it offered specific examples or guidance on how to enhance the clarity of the description. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should provide more explanation to clarify certain aspects, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically mentions the CBR contribution and requests a discussion on the implications of minimizing different terms in Equation 3. However, the comment does not provide explicit guidance on how to improve the explanation or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the exact areas that require more detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide more explanation, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically mentions the CBR contribution and requests a discussion on the implications of minimizing different terms in Equation 3. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the need for more explanation and discussion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should provide more explanation to clarify certain aspects, particularly regarding the main contributions and the discussion of different optimization strategies. It requests a discussion on the implications of minimizing different terms in Equation 3. However, the comment lacks specific examples or references to support the claim that the paper is unclear or lacks explanation. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a need for more explanation in the paper, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically requests a discussion on the implications of minimizing different terms in Equation 3, providing a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to enhance the explanation or suggested specific areas where more detail is needed. Overall, the feedback is somewhat helpful as it directs the authors to areas requiring improvement, but it lacks depth and specificity to fully guide them in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This provides a clear and explicit action for the authors to take, as they can directly incorporate this definition into their draft. The comment is specific in its suggestion, detailing exactly what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. However, it does not specify which part of the paper this definition should be included in, such as a specific section or paragraph. This lack of grounding makes it difficult for the authors to identify the exact location where the definition should be added. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This is a clear and logical suggestion that provides a specific action for the authors to take. However, the comment does not provide any additional context, examples, or references to support the claim that including this definition would enhance the paper. While the suggestion is logical and actionable, the lack of supporting evidence makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their draft by adding a crucial element that supports the logical flow and clarity of the paper. By including this definition, the authors can enhance the comprehensibility and rigor of their work, making it easier for readers to understand the theoretical foundations and proofs presented. This feedback is mostly helpful as it offers a direct and constructive suggestion for improvement, though it could be further expanded to include additional details or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the algorithm should be examined. The action is implicit, as the authors need to infer that they should analyze the quality of the local minima, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part being addressed. It also specifies what needs to be addressed, namely, the analysis of the quality of local minima found by Algorithm 1, including the approximation ratio under certain assumptions. This provides clear guidance on what aspects of the paper require improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggested improvement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that while the paper analyzes the convergence of Algorithm 1 to permutations as local minima, it lacks an analysis of the quality of these local minima. The comment suggests that the authors should consider analyzing the approximation ratio of these local minima under certain assumptions, which is a valuable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects of the algorithm should be examined. Overall, the comment is mostly helpful as it highlights a clear area for improvement and offers a constructive suggestion, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of self-containment in the paper, noting that it is not understandable given the NIPS format. It suggests that the supplementary material is necessary to understand large parts of the main paper and to allow for reproducibility. The comment also requests the authors to release the source code of their experiments to enable the reproduction of their results. While the comment identifies specific issues and requests, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve the paper. The actions are implicit and somewhat vague, as the authors are left to infer how to make the paper self-contained and reproducible. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper's self-containment and its understandability given the NIPS format. It suggests that the supplementary material is necessary to understand large parts of the main paper and to allow for reproducibility. Additionally, the comment requests the authors to release the source code of their experiments to enable the reproduction of their results. However, the comment does not specify which sections or parts of the paper are particularly difficult to understand, nor does it provide specific examples of what needs to be clarified. The authors can infer that the issue lies in the main paper's understandability, but the lack of explicit references makes the comment weakly grounded. The comment is specific in detailing the need for supplementary material and source code release, but the lack of grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and understandable given the NIPS format, suggesting that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. It also requests the authors to release the source code of their experiments to allow for the reproduction of their results. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not self-contained or understandable. Without additional context or evidence, the authors may find it challenging to fully understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's self-containment and understandability, particularly given the NIPS format. It highlights the necessity of supplementary material to comprehend large parts of the main paper and emphasizes the importance of reproducibility, requesting the authors to release the source code of their experiments. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, the comment could be more helpful if it offered additional guidance on how to make the paper more self-contained or suggestions for improving reproducibility beyond just releasing the source code. Overall, the comment is mostly helpful as it directs the authors to important aspects of their work that need attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, specifically referencing a sentence in the paper. It does not provide explicit instructions or suggestions on how to address this question or improve the paper. The comment is vague and lacks concrete guidance, leaving the authors uncertain about what action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any evidence, reasoning, or references to support the claim or question raised. The comment lacks context and does not offer any guidance or justification for the inquiry, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any suggestions or insights on how to address this question or improve the paper. The comment lacks actionable feedback, leaving the authors without guidance on how to enhance their work. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of the added complexity of using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice is not ablated and asks whether one IN would suffice. While the comment implies that the authors should consider the importance of the added complexity, it does not provide explicit guidance on how to address this concern or what actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of using a single IN. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the model, mentioning the use of multiple INs at different speeds in the dynamics predictor. It questions the necessity of this design choice and asks whether one IN would suffice. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the design choice and its request for clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not provide any evidence, reasoning, or references to support the claim that this design choice is important or how it impacts the model. Without additional context or justification, the authors are left to question the validity of the claim, making it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. It asks whether one IN would suffice, prompting the authors to consider the importance of the added complexity. While the comment identifies a potential area for improvement by questioning the design choice, it lacks specific guidance or suggestions on how to address this concern or what experiments might be needed to validate the claim. The feedback is somewhat helpful as it highlights a potential issue, but it does not provide detailed actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the experimental results, noting that the opponent's performance is not as good as expected because it does not aim to maximize the multi-agent payoff. However, it does not provide explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this issue or what changes could be made to the experiments. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the opponent not aiming to maximize the multi-agent payoff, explaining why the results are not surprising. This provides clear guidance on what needs to be addressed in the experiments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments do not come as a complete surprise because the opponent does not aim to maximize the multi-agent payoff, as evidenced by the experiments where the opponent maximizes classical SE and AE. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why this observation is significant or how it impacts the overall findings of the paper. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on an observation but lacks thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific observation about the experimental results, noting that the opponent's performance is not as good as expected because it does not aim to maximize the multi-agent payoff. This observation is based on the fact that the opponent maximizes classical SE and AE instead of the multi-agent payoff. While the comment highlights an interesting aspect of the experiments, it does not provide actionable feedback or suggestions on how the authors might address this issue or improve their draft. The lack of guidance leaves the authors without a clear understanding of how to respond or enhance their work. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not offer substantial guidance or constructive advice.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. It implies that the authors should clarify why they chose REINFORCE, potentially referencing the attention model paper they are building upon. However, the comment does not explicitly instruct the authors to include this rationale in their draft or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a rationale for their choice of algorithm. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. However, it does not specify which part of the paper this rationale should be included in, making it weakly grounded. The comment is specific in that it requests clarification on the reasoning behind the algorithm choice, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. While the comment implies that the authors should clarify their reasoning, it lacks specific examples or detailed explanations of why REINFORCE was chosen over PPO. Without additional context or justification, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to improve their draft by explaining the rationale behind their choice of the REINFORCE algorithm for training. It specifically requests clarification on why this algorithm was chosen over alternatives like PPO, which is relevant to the attention model paper the authors are building upon. This feedback is valuable as it prompts the authors to provide a detailed justification for their methodological choices, enhancing the transparency and rigor of their work. However, the comment could be more helpful if it included specific examples or guidance on how to articulate this rationale effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth and detail.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the statement but lacks grounding as it does not provide clear guidance on how to address the confusion or clarify the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. While the comment identifies a potential issue with the statement, it lacks specific guidance or suggestions on how the authors might address this confusion or clarify the issue. The feedback is somewhat helpful as it points out a potential area of concern, but it does not provide actionable steps or detailed explanations to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper lacks insight into this aspect, which is important for task domain adaptation. However, the comment does not provide explicit guidance on how to address these questions or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should explore or clarify these points. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. The comment is weakly grounded as it lacks specific references to sections or figures. It is also specific in that it identifies a gap in the paper regarding the discussion of morphologic segmentation across domains. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper lacks insight into this aspect, which is important for task domain adaptation. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the paper lacks insight into this aspect. The lack of evidence or justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It highlights a potential gap in the paper, noting that the authors assumed morphologic segmentation would be invariant without providing insight into this aspect. This feedback is valuable as it points out a specific area where the paper could be strengthened by offering more detailed discussion or analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these questions or explore the topic further. Overall, the comment is somewhat helpful as it identifies a crucial aspect that needs more attention, but it lacks depth and actionable advice, making it only partially beneficial.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to their draft. The comment is specific in its request for additional experiments, which helps the authors understand exactly what needs to be done to strengthen their claims. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides the authors with a clear understanding of what additional experiments are required to support their claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This claim is somewhat verifiable as it provides a clear direction for the authors to take, but it lacks specific examples or references to support the need for such experiments. While the suggestion is logical, the absence of detailed reasoning or examples makes it somewhat challenging for the authors to fully understand and implement the recommendation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include experimental results of excluding the mixup technique from their proposed method. This is a clear and actionable suggestion that would help demonstrate the pure contribution of the proposed method. By providing a specific direction for additional experiments, the comment offers valuable guidance to the authors, enhancing the depth and impact of their work. Therefore, the comment is mostly helpful, as it provides a clear and constructive feedback that can significantly improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are explicit and provide clear guidance on what the authors should clarify in their draft. The feedback is concrete, as it directly instructs the authors to address these specific aspects of their method. Therefore, the comment is highly actionable, as it provides explicit and detailed instructions for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. This provides clear guidance on what aspects of the paper need clarification. However, the comment does not explicitly mention a specific section or part of the paper where this clarification is needed, making it weakly grounded. The questions are specific and detailed, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are factual and require the authors to clarify their methodology. However, the comment does not provide any additional context, reasoning, or references to support the questions, making it difficult for the authors to understand the basis of the inquiry. As a result, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the questions posed.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are clear and actionable, providing the authors with specific areas to clarify in their draft. By addressing these questions, the authors can improve the clarity and completeness of their methodology description. However, the comment could be more helpful if it suggested specific ways to clarify these aspects or provided examples of how to present the information effectively. Overall, the feedback is mostly helpful as it identifies key areas for improvement and guides the authors toward enhancing their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this gap. The comment suggests that the authors should include a discussion of these works, but it lacks detailed instructions or examples on how to do so. As a result, the authors are left with a general idea of what needs to be added but without specific steps to follow. Therefore, this comment is somewhat actionable, as it provides a clear direction but lacks concrete guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link to a specific paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about the Set Transformer and other related works that use summary tokens. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support this claim. Without additional context or references, the authors may find it challenging to understand why this omission is significant or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. This is a valuable piece of feedback as it highlights an area where the authors could enhance the comprehensiveness and depth of their work. However, the comment lacks specific guidance on how the authors might address this gap, such as suggesting particular aspects of the Set Transformer to discuss or how to integrate these works into the paper. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it offers a clear area for enhancement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide explicit guidance on what needs to be addressed or how to improve the analysis. The authors are left to infer that they should either provide a more detailed analysis or address the question raised. This lack of explicit action or guidance makes the comment somewhat actionable, as it points out a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its focus on the theoretical support, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide any specific evidence, examples, or references to support the claim that this theoretical support is essential. Without additional context or justification, the authors are left to infer the importance of this aspect, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. This feedback highlights a potential gap in the paper's theoretical foundation, which is crucial for understanding the merits of Fourier features. However, the comment does not provide specific guidance on how to address this issue or what additional analysis might be necessary. While it identifies an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it points out a critical aspect that needs attention but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to their draft. The comment lacks concrete guidance on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for details, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely factual and descriptive, lacking any opinions or assertions that could be challenged or supported. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the methodology, noting that the authors do not provide details on how the network is trained to fit the residual instead of directly learning the input-output mapping. This feedback is valuable as it highlights a potential gap in the clarity and completeness of the methodology section. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies an area for improvement, it does not provide concrete steps or examples for the authors to follow, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not explicitly instruct the authors to provide more details about the experiment setup or how the data augmentation methods and learning rate were chosen. While the authors can infer that they need to clarify these aspects, the action is implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not specify which part of Section 3.3 is being referred to, making it weakly grounded. The comment is specific in asking for details about the experiment setup, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not contain a subjective claim or suggestion that requires verification. It is a factual request for clarification, making it a \"No\" claim.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their draft. It does not provide specific advice on what aspects of the experiment setup need clarification or how the authors can enhance their presentation. As a result, the comment is not particularly helpful in guiding the authors to improve their work, making it a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether an error in the initial calibration steps of the algorithm might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to investigate or correct the error. The comment lacks concrete guidance on how to proceed, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" which provides full grounding as the authors can accurately identify the section being addressed. It also specifies the concern about an error in the initial calibration steps that might explain the speed disparities observed between the RSPs and FDs, making the comment specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about potential errors in the initial calibration steps of the algorithm, which could explain the observed speed disparities between RSPs and FDs. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about potential errors in the initial calibration steps of the algorithm, which could explain the observed speed disparities between RSPs and FDs. This feedback is somewhat helpful as it identifies a potential issue that the authors should investigate. However, it lacks actionable guidance on how to address the error or what steps the authors should take to verify or correct it. The comment is incomplete and does not provide a clear path for improvement, making it somewhat helpful but not fully supportive of the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, arguing that this is not a significant issue compared to other techniques like backprop. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve their draft. It lacks actionable steps or concrete advice, leaving the authors without a clear understanding of what to do to address the issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not provide details on what needs to be addressed or how the issue might be resolved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, arguing that this is not a significant issue compared to other techniques like backprop. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the argument or how to address it. Without detailed reasoning or examples, the claim is unverifiable, as it relies on subjective interpretation and lacks sufficient justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, suggesting that this is not a significant issue compared to other techniques like backprop. However, the comment does not provide any specific feedback or suggestions on how the authors might address this concern or improve their draft. It lacks actionable guidance, making it difficult for the authors to understand how to respond to the criticism or what steps they should take to enhance their work. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide explicit instructions or suggestions on how the authors should address this concern, such as conducting a statistical significance test or providing justification for the closeness of the numbers. The action is implicit and vague, as the authors are left to infer that they need to address the issue of statistical significance. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. However, it does not specify which part of the paper contains these numbers or where the comparison is made. This makes it difficult for the authors to identify the exact section or figure that needs attention. While the comment is specific about the issue of statistical significance, it lacks grounding as it does not provide clear references or guidance on where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not contain a claim that requires verification or justification. The comment is factual and descriptive, as it simply questions the closeness of the numbers without providing any evidence or reasoning. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment raises a valid concern about the statistical significance of the numbers when comparing the proposed method with baselines. It questions whether the closeness of the numbers is due to chance or if there is a significant difference. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as conducting a statistical significance test or providing a rationale for the closeness of the numbers. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically focusing on common inference tasks. It asks which tasks can be computed exactly or approximately with an NP-SPEC-HMM. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"learning HMMs with non-parametric emission distributions\" and \"NP-SPEC-HMM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the impact of these emission distributions on inference tasks, such as filtering, smoothing, and marginal observation likelihood, and asks which tasks can be computed exactly or approximately. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in HMMs, specifically asking which tasks can be computed exactly or approximately with an NP-SPEC-HMM. While the question is clear and directly relates to the paper's focus, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks depth and does not offer any guidance or justification for the question, making it difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of non-parametric emission distributions on inference tasks in HMMs, specifically focusing on common inference tasks such as filtering, smoothing, and marginal observation likelihood. It asks which of these tasks can be computed exactly or approximately with an NP-SPEC-HMM. This feedback is somewhat helpful as it identifies a potential area for clarification and exploration in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment could be more helpful if it offered actionable advice or examples of how the authors could enhance their discussion of inference tasks. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a deficiency in the analysis of experimental results, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to conduct a deeper analysis or provide guidance on how to address this issue. The action is implicit, as the authors can infer that they need to expand their analysis to include reasons for the poor performance. However, the lack of concrete guidance on what specific analysis to conduct makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT-3.5-turbo, providing a clear indication of what needs to be addressed. This level of detail helps the authors understand exactly where the issue lies and what kind of analysis is missing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a gap in the analysis but lacks specific examples or references to support the claim. The authors could strengthen the comment by providing more detailed reasoning or examples to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the analysis of experimental results, specifically pointing out that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to expand their analysis and provide a deeper understanding of the results. By highlighting this gap, the comment encourages the authors to enhance the depth and comprehensiveness of their experimental analysis, which is crucial for a thorough evaluation of their work. Therefore, the comment is mostly helpful, as it provides a clear direction for improvement but could be further enhanced with specific suggestions or examples.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. While the comment implies an action to be taken\u2014comparing batch and greedy methods in more datasets\u2014it does not provide explicit guidance on how to implement this action or what specific steps should be taken. The action is somewhat vague, as it lacks concrete details on how to conduct the additional comparisons or what data or analysis would be required. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. It is specific in questioning the choice of datasets and the comparison methods, but without clear references to sections or figures, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any justification or reasoning for this choice, nor does it offer any examples or references to support the claim. Without additional context or explanation, the authors may find it difficult to understand the basis for this decision and how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. While the comment identifies a potential area for further exploration or clarification, it does not provide any actionable feedback or suggestions on how the authors might address this issue. The comment lacks depth and does not offer any guidance on how to improve the draft or address the concern. As a result, it is barely helpful, as it only points out a potential area for improvement without providing any concrete advice or direction for the authors to follow.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the motivation in the introduction regarding low-rank factorization, suggesting that it is unnecessary given the main result focuses on polytopes. It also implies that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation in the introduction regarding low-rank factorization, suggesting it is unnecessary given the focus on polytopes. However, it does not specify which part of the introduction this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the relevance of low-rank factorization to the main result about polytopes and suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a question about the relevance of the motivation in the introduction regarding low-rank factorization, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment lacks specific examples or references to support the claim that the motivation is unnecessary or that the implications for low-rank matrix factorization are not adequately addressed. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation in the introduction, specifically questioning the relevance of low-rank factorization given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. This feedback is somewhat helpful as it points out a potential gap in the motivation and encourages the authors to consider the broader implications of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to address this issue, making it actionable for the authors. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to explicitly specify the labels for each dataset in section 4.1, including their source. It questions whether the labels are derived from the dataset itself or from additional information, particularly for cas-peal-r1 and mugshot. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so or offer guidance on how to present the labels. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the labels and their sources. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions section 4.1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is needed: the labels for each dataset in section 4.1, including their source (from the dataset itself or from additional information). This provides a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning the source of these labels. It implies that the labels are either derived from the dataset itself or from additional information, particularly for cas-peal-r1 and mugshot. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the labels are easily obtainable for generated datasets but not for cas-peal-r1 and mugshot. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of confusion regarding the labels used in section 4.1 of the paper. It questions the source of these labels, particularly for cas-peal-r1 and mugshot, which are not clearly explained. This feedback is valuable as it highlights a potential gap in the clarity of the paper, allowing the authors to improve the transparency and understanding of their dataset labels. However, the comment could be more helpful if it provided additional guidance or suggestions on how to clarify these labels or address the confusion. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental with respect to [31], as it adapts the existing architecture for the multi-person case and produces identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the draft or what specific changes are needed to make it more substantial. Without actionable feedback, the authors are left without a clear path to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"with respect to [31]\", allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the paper is incremental and adapts the existing architecture for the multi-person case, producing identity/tag heatmaps with joint heatmaps. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is \"rather incremental\" with respect to [31], as it adapts the existing architecture for the multi-person case and produces identity/tag heatmaps with joint heatmaps. However, the comment lacks specific evidence or examples to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered borderline verifiable, as it provides a subjective assessment but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper's novelty, suggesting that it is incremental with respect to [31]. The authors adapt an existing architecture for a multi-person case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper's contribution. While it highlights a concern, it lacks actionable advice, making it somewhat helpful. The authors would benefit from additional feedback that offers concrete suggestions for improvement, such as exploring alternative approaches or expanding the analysis to address the incremental nature of the work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the clarity of the explanation. The authors are left to infer that they need to clarify the calculation of \u03bb and provide a clearer explanation of the ELLA's performance in COMBO environments. This lack of explicit and concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper (Page 9, lines 310-313 and Page 8, lines 281-285), allowing the authors to accurately identify the parts being addressed. It also specifies what the authors need to understand, namely the process of calculating \u03bb and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. Additionally, the comment references specific papers [1], [2], and [3], which provides context and suggests further reading. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment lacks specific details or references to support these claims, making it difficult for the authors to understand the basis of the concern. The absence of detailed reasoning or examples makes the claim somewhat verifiable, as the authors may need to infer the basis of the concern themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and questions the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment, referencing specific papers to provide context. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the clarity of the explanation. While it identifies areas for improvement, it does not provide actionable steps or specific advice, making it somewhat helpful. The authors would need to infer the need for clarification and additional context, which limits the comment's overall impact.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point mentions that an alternating direction method is used to solve a min-min problem but does not specify which method is being referred to. While it acknowledges the brief mention, it does not provide any guidance or suggestions on how the authors should clarify or improve the description of the method used. The action is implicit, as the authors need to infer that they should identify and specify the method used. However, the lack of explicit guidance or concrete suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what needs to be addressed regarding the mention of the alternating direction method. The comment lacks both grounding and specificity, making it difficult for the authors to understand which part of the paper is being discussed and what needs to be improved. Therefore, this comment is rated as 1: Not Grounded and Not Specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement, as it describes the use of an alternating direction method to solve a min-min problem. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is brief and does not provide specific feedback or suggestions on how the authors can improve their draft. It mentions that an alternating direction method is used to solve a min-min problem but does not specify which method is being used or why this is important. Without additional context or guidance, the authors are left without actionable information on how to enhance their work. Therefore, the comment is barely helpful, as it lacks depth and specificity to provide meaningful feedback. The score is 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of lower bound double q-learning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies specific areas of concern, it does not provide explicit guidance on how the authors should address these issues or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of lower bound double q-learning, specifically mentioning the MsPacman environment in Figure 2 and noting a slight performance decrease compared to Clipped DDQN. It also highlights convergence to the same solutions in other environments and suggests that the algorithm overestimates the true maximum value. However, the comment does not specify which part of the paper discusses these issues or environments, making it weakly grounded. The comment is specific in detailing the concerns about the algorithm's performance and potential overestimation, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of lower bound double q-learning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the effectiveness of lower bound double q-learning, specifically questioning its performance in the MsPacman environment of Figure 2, where it shows a slight performance decrease compared to Clipped DDQN. It also notes that the algorithm converges to the same solutions in other environments, such as WizardOfWor, Zaxxon RoadRunner, and BattleZone, and suggests that it overestimates the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance on how the authors might address these issues or what changes could be made to improve the algorithm's performance. The feedback is somewhat helpful as it points out potential weaknesses, but it could be more actionable with additional suggestions or recommendations. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear understanding of how to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without this context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the novelty of the paper. Therefore, the comment is not grounded and lacks specificity, making it unactionable.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this claim is made or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, suggesting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance the novelty of their work. It does not provide actionable feedback or guidance on what aspects of the paper could be improved to differentiate it from existing methods. As a result, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that it is not helpful at all.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches vanilla methods from below. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit, as the authors need to infer that they should clarify the performance discrepancy and provide an explanation. While the action is somewhat vague, it is clear that the authors need to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig.3-4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA becoming worse than vanilla DNN when lambda is small, and it provides a specific observation about the expected behavior. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It suggests that the authors should clarify why the performance is worse and why it approaches vanilla methods from below. However, the comment lacks specific reasoning or examples to support the claim that the performance should approach from above. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a question but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the performance of DNN+MMA compared to vanilla DNN when lambda is small, referencing figures 3 and 4. It points out that the performance is worse and suggests that the authors should clarify why this occurs and why the performance approaches vanilla methods from below. This feedback is somewhat helpful as it identifies a potential area of confusion or inconsistency in the results. However, it could be more helpful if it provided additional context or suggested specific ways to address the issue, such as explaining the expected behavior or providing a rationale for the observed performance. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper by noting that it does not compare the results with some earlier research work from 2020. While the authors mention that they compared their results to earlier systems with worse performances, such as Taghipour and Ng (2016), the comment does not provide explicit guidance on how to address this issue or what specific comparisons would be beneficial. The action is implicit, as the authors need to infer that they should include comparisons with other relevant works from 2020. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison of results with earlier research work from 2020, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the absence of comparison with state-of-the-art systems from 2020 and suggests comparing with earlier systems like Taghipour and Ng (2016). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not compare the results with some earlier research work from 2020. While the authors have compared their results to earlier systems with worse performances, such as Taghipour and Ng (2016), the comment lacks specific examples or detailed reasoning to support the claim that the comparison with 2020 works is missing. This makes the claim somewhat verifiable, as it provides a basis for the authors to understand the issue but does not offer comprehensive evidence or detailed examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting the absence of comparisons with earlier research work from 2020. While the authors have addressed this by comparing their results to earlier systems with worse performances, the comment could be more helpful by providing specific examples of earlier works from 2020 that should have been included for comparison. Additionally, the comment could offer guidance on how to effectively compare the results with these works, such as highlighting specific aspects or metrics that would be relevant for such comparisons. Without these details, the feedback is somewhat helpful, as it points out an area for improvement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signed-rank test, due to the comparison being made between two samples generated from the same input. While the comment implies that a paired test would be more appropriate, it does not explicitly instruct the authors to perform this test or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for a paired test and understand how to apply it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signed-rank test, due to the comparison being made between two samples generated from the same input. However, the comment does not specify which part of the paper discusses the significance testing or where the comparison between the two samples is made. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the suggestion to use a paired test, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signed-rank test, due to the comparison being made between two samples generated from the same input. However, the comment lacks specific justification or examples to support why a paired test would be more appropriate in this context. It does not provide references or logical reasoning to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the choice of significance testing method, suggesting that a paired test might be more appropriate given the comparison between two samples generated from the same input. It recommends using the Wilcoxon signed-rank test as an alternative. While the comment points out a specific area for improvement, it lacks detailed guidance on how to implement the suggested test or why it would be more suitable. The feedback is somewhat helpful as it directs the authors to consider a different statistical approach, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to expand the experiments or what additional baselines should be included. The authors are left with a general idea of what needs to be done but lack concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not specify which parts of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the nature of the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments should be more comprehensive and general, specifically noting that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of these suggestions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experiments section, noting that they should be more comprehensive and general. It highlights the limitations of the current model size and the restrictive nature of the baselines used for both the language modeling task and the image classification task. While the comment points out these issues, it does not provide specific suggestions or guidance on how to address them, such as proposing additional baselines or expanding the scope of the experiments. This feedback is somewhat helpful as it directs the authors to consider enhancing their experimental design, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should elaborate on the conditions under which Hoeffding\\'s bound holds, particularly in the context of stochastic algorithms. It implies that the current explanation is insufficient and that the authors should provide more detail to clarify this point. The action is explicit, as it directly instructs the authors to elaborate on the conditions for Hoeffding\\'s inequality to hold. However, the comment lacks specific guidance on how to elaborate, such as suggesting additional details or examples. Therefore, the action is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely lines 124-125. This allows the authors to accurately identify the section being discussed. The comment is also specific because it provides a clear request for elaboration on the conditions under which Hoeffding\\'s bound holds, particularly in the context of stochastic algorithms. This guidance is detailed and specific, allowing the authors to understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should elaborate on the conditions under which Hoeffding\\'s bound holds, particularly in the context of stochastic algorithms. The comment provides a logical reasoning by explaining that the bound holds under specific conditions, such as independent samples, and that stochastic algorithms further guarantee its validity. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from additional details or examples to fully understand and address the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area in the paper where the authors could provide more elaboration, particularly regarding the conditions under which Hoeffding's bound holds. It suggests that the authors should elaborate on the role of stochastic algorithms in guaranteeing the validity of the inequality. This feedback is clear and actionable, as it provides a specific direction for improvement. However, it could be more helpful if it included examples or suggested additional details to enhance the explanation. Overall, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. While it implies that this addition would be beneficial, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the table would benefit from such an addition. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to incorporate the suggested approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not specify which part of Table-1 would benefit from this addition or what specific issues the authors are addressing. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. Additionally, it does not specify what needs to be added or how it would enhance the table. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not provide any justification or reasoning for why this addition would be beneficial or how it would improve the paper. Without specific examples or references, the claim lacks support and is therefore unverifiable. The comment is classified as \"1: Unverifiable\" as it does not offer a clear or substantiated suggestion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting a specific technique that could enhance the paper. However, the comment lacks depth and does not provide detailed reasoning or guidance on how to implement this suggestion. The authors would need to infer the exact steps to incorporate the suggested approach, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using few-shot examples for Chain-of-Thought (CoT). However, it does not provide explicit guidance on how the authors should conduct or present this ablation study. The action is implicit, as the authors need to infer that they should include an ablation study to justify their prompt choice. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using few-shot examples for Chain-of-Thought (CoT). However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental section. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is also specific in that it suggests an improvement by recommending the inclusion of an ablation study. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using few-shot examples for Chain-of-Thought (CoT). However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the paper lacks such an ablation study. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of an ablation study explaining the choice of prompt, particularly the potential benefits of using few-shot examples for Chain-of-Thought (CoT). This feedback is somewhat helpful as it highlights a gap in the paper's analysis and suggests a potential improvement. However, the comment could be more helpful if it provided more detailed guidance on how the authors might conduct or present this ablation study. Without specific suggestions or examples, the authors may struggle to address the feedback effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, it does not provide explicit guidance on how the authors should revise the text to address this concern. The comment implies that the authors need to clarify their use of the term, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not provide detailed guidance on how to implement the suggested change.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" recommending that the authors use it carefully to distinguish it from temporal relationships. This provides the authors with clear guidance on how to revise the text. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it identifies a potential issue but does not provide enough evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment on page 1 points out a potential issue with the use of the term \"causal mechanisms,\" suggesting that it should be used carefully to distinguish it from temporal relationships. This feedback is clear and identifies a specific area for improvement in the paper. However, it lacks detailed guidance on how the authors might address this issue or what specific changes should be made to the text. While it provides a clear direction for improvement, the comment could be more helpful if it offered additional suggestions or examples of how to revise the text to clarify the distinction between causal mechanisms and temporal relationships. Therefore, the comment is somewhat helpful, as it identifies a meaningful issue but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment implies that the authors should consider whether the performance drop is significant enough to support their claim of a strong demonstration. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to strengthen their argument. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"You write: 'Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance'\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the claim that \"better than random\" is a strong demonstration of capability, providing a clear direction for the authors to consider and potentially address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations to substantiate the assertion that the performance drop is significant enough to be considered a strong demonstration of capability. As a result, the claim is unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. This feedback is somewhat helpful as it identifies a potential issue with the claim's strength and encourages the authors to reconsider their argument. However, the comment lacks detailed guidance or suggestions on how the authors might address this concern or strengthen their demonstration of capability. It does not provide specific examples or actionable steps for the authors to take, which limits its impact on improving the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide explicit guidance on how to incorporate this discussion into the draft or what specific aspects of the results should be addressed. The action is implicit, as the authors need to infer that they should add a discussion section related to this topic. While the suggestion is concrete in terms of the content to be included, the lack of explicit guidance on how to implement it makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. It is specific in that it clearly identifies the area where the discussion should be added, but the lack of grounding makes it difficult for the authors to pinpoint the exact section. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by incorporating a discussion on this topic. However, the comment could be more helpful if it offered additional guidance on how to structure or integrate this discussion into the paper. Despite this, the feedback is mostly helpful as it directs the authors towards a meaningful improvement that could strengthen the paper. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper's results is unclear. It also provides a rationale for why PCA might be intuitive and offers a reference to support the claim that certain assumptions are met. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the paper. The action is implicit, as the authors need to infer that they should clarify the novelty and significance of their results and ensure that the assumptions of PCA are well-justified. While the comment is somewhat actionable, it lacks concrete steps for the authors to take, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce the interaction count and questions its significance, suggesting that it may be incremental. It also provides a reference to support the claim that certain assumptions are met. However, the comment does not specify which part of the paper discusses the use of PCA or the interaction count, making it weakly grounded. The comment is specific in that it identifies a potential issue with the novelty and significance of the paper's results, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper's results is unclear. It provides a reference to support the claim that certain assumptions are met, which helps in understanding the context. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the incremental nature of the novelty. While the reference provides some support, the overall claim is somewhat verifiable, as it could benefit from more detailed explanation or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the novelty of using PCA to reduce the interaction count and questions the significance of the paper's results. It provides a reference to support the claim that certain assumptions are met, which could help the authors understand the context better. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the paper's clarity. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. The authors would need to infer that they should clarify the novelty and significance of their results and ensure that the assumptions of PCA are well-justified, which could be a bit challenging without further guidance. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asking for a comparison with relation extraction/generation models in few-shot settings. While the comment identifies a potential issue with the choice of models, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer that they need to compare their models with relation extraction/generation models. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asking for a comparison with relation extraction/generation models in few-shot settings. However, the comment does not specify which part of the paper discusses the choice of models or where the authors might find information about this topic. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its request for comparison, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asking for a comparison with relation extraction/generation models in few-shot settings. The comment provides specific examples of state-of-the-art models, such as those found in the provided links, which serve as evidence to support the claim. However, the reasoning could be more detailed, and the request for comparison lacks specific guidance on how to conduct this comparison. Overall, the claim is somewhat verifiable, as it is supported by evidence but could benefit from more detailed reasoning and examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of few-shot RC models used in the paper, suggesting that they are not state-of-the-art. It also raises a question about how the performance of these models compares to relation extraction/generation models in few-shot settings. While the comment points out a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their models. The feedback is somewhat helpful as it highlights a potential weakness but lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the results in section 4 are limited to shallow fully-connected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might extend their results to deeper networks or how they could improve the scope of their findings. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results in section 4 apply only to shallow fully-connected ReLU networks, providing a clear and specific issue to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results in section 4 apply only to shallow fully-connected ReLU networks. This is a specific observation that could be verified by examining the content of section 4. However, the comment does not provide any additional context, examples, or references to support this claim, making it somewhat verifiable. The authors would need to independently verify the claim by reviewing section 4 to fully understand its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a specific limitation in the results presented in section 4, noting that they apply only to shallow fully-connected ReLU networks. This is a clear and actionable piece of feedback that highlights a potential gap in the scope of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their findings to include deeper networks. While it identifies an important area for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides a clear observation but lacks actionable guidance for the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. While the comment implies that these actions would enhance the paper, it does not explicitly instruct the authors to do so. The actions are somewhat vague, as the authors are not given specific guidance on how to integrate the background knowledge or where to place the related literature descriptions. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks concrete details on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. However, it does not specify which part of the paper this improvement should be applied to, making it weakly grounded. The comment is specific in its suggestion to enhance the organization by adding background knowledge and moving related literature descriptions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to implement these suggestions effectively. Without clear guidance or references, the claim remains somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. This feedback is somewhat helpful as it identifies a potential area for enhancement in the paper's structure and content. However, the comment lacks specific guidance on how to achieve these improvements, such as suggesting particular sections or examples where additional background information or related literature descriptions would be beneficial. While it provides a general direction, the authors may need to infer the exact actions to take, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on whether the authors should include these models in their comparison or provide a rationale for their exclusion. As a result, the authors are left without a clear understanding of what action to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some other representative panoptic segmentation models,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the missing models, PanopticFPN and Mask2Former, which the authors should consider comparing against. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanations or references to justify why these models are not included or why their absence is a significant omission. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the comparison of panoptic segmentation models, noting the absence of models like PanopticFPN and Mask2Former. This feedback is valuable as it highlights an area where the authors could enhance their work by including a broader range of models in their comparison. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what additional models they should consider. While it points out a relevant area for improvement, it does not offer actionable steps or suggestions for enhancing the comparison, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the lack of results presented in the discussion of using sequential MCB vs a single MCT layers for the decision head. It suggests that the authors should provide more context or explanation about what was observed. However, the comment does not explicitly instruct the authors to include results or provide additional details, leaving the action somewhat vague. The authors can infer that they need to address this gap, but the lack of explicit guidance makes the action somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more context or explanation about what was observed in this discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of results presented in the discussion of using sequential MCB vs a single MCT layers for the decision head. It suggests that the authors should provide more context or explanation about what was observed. However, the comment does not provide any specific reasoning, examples, or references to support why this observation is important or how it impacts the overall findings. Without additional context or justification, the claim remains somewhat verifiable, as the authors are left to infer the significance of the missing results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that lacks results, namely the discussion of using sequential MCB vs a single MCT layers for the decision head. It questions the absence of results and requests more context or explanation about what was observed. This feedback is somewhat helpful as it highlights a gap in the paper and encourages the authors to provide additional details or results to support their claims. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as suggesting additional experiments or analyses that could be conducted. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several minor language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). It also suggests that the authors should proofread the paper and fix all language problems. While the comment identifies specific instances of language issues, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit, as the authors need to infer that they should correct the language in the mentioned instances. However, the lack of detailed guidance on how to correct these issues makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific instances of language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the exact language issues that need to be corrected. However, it does not provide any suggestions or guidance on how to address these issues, which limits its overall impact. Therefore, this comment is fully grounded and specific, but it lacks actionable guidance, making it somewhat helpful.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of minor comments on language usage, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). These comments are factual observations about the language used in the paper. However, they do not contain any subjective opinions, suggestions, or judgments that require verification. Therefore, the comment is classified as \"No Claim\" as it does not provide any claims or assertions that need to be substantiated.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several minor language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). It also suggests that the authors should proofread the paper and fix all language problems. While the comment points out specific instances of language issues, it does not provide detailed guidance on how to correct these problems or what specific changes should be made. The feedback is somewhat helpful as it highlights areas for improvement, but it lacks depth and actionable suggestions, making it only marginally helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. While it implies that the authors should consider this aspect, it does not provide explicit guidance on how to control the number of distribution sets or what specific actions should be taken. The comment is somewhat vague, as it leaves the authors to infer the need for further exploration and experimentation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in questioning the choice of distribution sets, the lack of grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. This feedback is somewhat helpful as it points out a potential area for further investigation and experimentation. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might approach this exploration. The comment could be more helpful if it offered actionable advice or examples of how to control the number of distribution sets or what implications this might have. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluative framework is somewhat limited in scope, as it only considers three Question-Answering tasks and two language models. The authors are left with reservations about the method's broader applicability, particularly regarding its potential to generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance on how the authors might address these limitations or expand the framework. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve the framework. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework's limited scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. This provides some grounding as the authors can infer the part of the paper being addressed, although it is not explicitly mentioned. The comment is specific in detailing the limitations of the framework, suggesting that it may not be applicable to other reasoning or generation tasks or more advanced models like vicunna or alpaca. This specificity is clear, as it specifies the areas where the framework's applicability is questioned. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is somewhat limited in scope, as it only considers three Question-Answering tasks and two language models. This limitation raises concerns about the method's broader applicability. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claim. Therefore, the comment is barely verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This observation raises concerns about the method's broader applicability and its potential to generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. While the comment highlights an important area for consideration, it does not provide specific suggestions or guidance on how the authors might address these limitations or expand the framework. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with a clear understanding of the issue but no clear path forward. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. It provides a clear and explicit action for the authors to take, indicating that they should consider updating their experiments to align with current NLP trends. The comment is specific in its suggestion, detailing which models should be used and why. This provides the authors with a concrete and actionable direction for improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. It provides a clear and specific recommendation for the authors to consider updating their experiments to align with current NLP trends. However, the comment does not explicitly mention which part of the paper the authors should focus on, such as a specific section or table. This makes it weakly grounded, as the authors may need to infer the relevant part of the paper. The comment is specific in its suggestion, as it clearly specifies the type of models that should be used. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. This claim is somewhat verifiable as it provides a clear rationale for why transformer-based models are more appropriate, aligning with current NLP trends. However, it lacks specific examples or references to support the claim, which could enhance its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the perplexity experiments, noting that they are conducted on obsolete language models that are rarely used in current NLP research. The comment suggests that the authors should consider using transformer-based language models, which are more relevant and widely adopted in the field. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup. By aligning their experiments with current trends, the authors can enhance the relevance and impact of their work. The comment is mostly helpful as it offers a clear and constructive suggestion for improvement, though it could be further expanded to include additional details or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. While the comment provides a clear direction for improvement, it lacks specific guidance on which aspects of the experiments need to be expanded or what specific types of additional experiments would be beneficial. The authors are aware of the need for more experiments but are not given detailed instructions on how to conduct them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment does not specify which part of the paper the experiments are related to, making it weakly grounded. It is specific in suggesting the need for more experiments, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas that require improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are not sufficient and suggests that more empirical or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment lacks specific details or examples to support the claim that the current experiments are insufficient. It does not provide a clear rationale for why more experiments are necessary or how they would address the identified gaps. Without additional context or justification, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that the experiments are not sufficient to fully validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that additional empirical or toy experiments, particularly for the simplified self-attention model considered in the theoretical analysis, are necessary. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft. However, the comment could be more helpful if it included suggestions for the types of additional experiments or specific areas where the current experiments are lacking. Overall, the comment is mostly helpful as it highlights a critical gap in the experimental validation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the estimation process. The comment lacks concrete guidance on what needs to be done to clarify or improve the estimation of mu. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its critique of the estimation process but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific reasoning, examples, or references to support why this estimation is unclear or problematic. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the estimation process. While it highlights a concern that needs attention, it lacks actionable advice or detailed insights that would help the authors enhance their work. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not offer substantial guidance for the authors to follow.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific way to present the sensitivity of the performance to initialization by varying the distance of the initialization matrix M^0 from the ground-truth matrix M^*. It provides a clear and concrete action for the authors to take, which is to include this analysis in their draft. The comment is explicit and provides detailed guidance on how to implement the suggested action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the ground-truth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing the proposed analysis, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the ground-truth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not offer any specific examples or references to support the claim that this analysis would be beneficial or how it aligns with existing literature. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a direction for improvement but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the presentation of the paper by analyzing the sensitivity of performance to initialization. It proposes a method to vary the distance of the initialization matrix M^0 from the ground-truth matrix M^* and reports the performance accordingly. This feedback is actionable and offers a clear direction for the authors to enhance their draft by including this analysis. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or discussed the expected outcomes in more detail. Overall, the comment is mostly helpful as it directs the authors towards a specific improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This comment provides a specific and explicit action for the authors to consider, as they can verify whether the operation is indeed necessary. The suggestion is clear and concrete, allowing the authors to understand exactly what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the definition of the Frobenius norm, suggesting that the absolute value operation is not needed since tensor entries are real numbers. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This claim is logical and verifiable as it is based on the understanding that the Frobenius norm is typically defined for real-valued tensors, where the absolute value is not necessary. The comment provides a clear reasoning for the suggestion, making it mostly verifiable. However, it could be strengthened by explicitly stating that the Frobenius norm is defined for real-valued tensors, which would enhance the clarity and robustness of the justification. Therefore, the comment is rated as mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a minor issue in the definition of the Frobenius norm, specifically pointing out that the absolute value operation might be unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement. By highlighting this detail, the comment helps the authors refine their definition and ensure its accuracy. However, the comment could be more helpful if it provided additional context or examples to support the claim. Overall, the feedback is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth and impact.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide high-probability bounds instead of only bounds in expectation. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides explicit guidance on what should be included, it does not specify how to implement these changes or where in the draft these additions should be made. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for high-probability bounds and robustness measures in the experiments. It specifies what needs to be addressed, making it clear for the authors to understand the areas that require improvement. However, the comment does not provide specific examples or detailed guidance on how to achieve these improvements, such as suggesting specific ensemble methods or statistical measures. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a claim about the need for high-probability bounds and robustness measures in the experiments. It suggests that ensemble methods could be used to achieve this, referencing the experiments section. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general direction, it does not offer detailed evidence or references to support the suggestion comprehensively. Therefore, the claim is somewhat verifiable, as it is partially supported but lacks depth and specificity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide high-probability bounds instead of only bounds in expectation. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is actionable and provides clear guidance on what the authors should do to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples of how to implement these suggestions or detailed reasoning behind the recommendations. Overall, the comment is mostly helpful as it offers valuable insights and actionable feedback, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results are less impressive and recommends evaluating them from more aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. However, it does not provide explicit guidance on how to conduct this additional evaluation or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the areas where the results should be evaluated, such as actual latency on the target device, memory consumption during inference, and actual network size. This provides clear guidance for the authors to focus on specific aspects of their results. The comment is also specific in its suggestions, as it recommends evaluating the results from these additional perspectives. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results are less impressive and recommends evaluating them from additional aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the results section, suggesting that the findings are less impressive and recommend evaluating them from additional aspects, such as actual latency on the target device, memory consumption during inference, and actual network size. This feedback is somewhat helpful as it provides a direction for improvement, but it lacks depth and specificity. The authors are left to infer the exact steps needed to conduct this additional evaluation, which limits the comment's impact. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the model to explicitly enforce diversity. The authors are left without guidance on how to proceed, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title of the paper, which includes the word \"diversity.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the concern: the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model, leading to a disappointment. This provides a clear direction for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the model does not enforce diversity explicitly. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant concern regarding the paper's motivation of \"diversity,\" noting that the word is present in the title but the model does not explicitly enforce it. The reviewer expresses disappointment with this discrepancy, suggesting that the authors were initially excited about incorporating diversity into their model but were disappointed to learn that it was not done so explicitly. This feedback is somewhat helpful as it identifies a key area for improvement, prompting the authors to reconsider how they present and implement diversity in their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue. Overall, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on what these missing experiments should include or how they should be conducted. The authors are left without a clear understanding of what additional experiments to add or how to address the issue of missing experiments. Therefore, the comment is unactionable as it lacks explicit and detailed instructions for the authors to follow.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are intended to address or how they relate to the overall content. The authors cannot confidently determine which sections or parts of the paper need additional experiments. While the comment is specific about the types of experiments missing, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any justification or reasoning for why these experiments are missing or how their absence impacts the paper. Without additional context or explanation, the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some experiments are missing, particularly those related to contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to consider adding these experiments to enhance the comprehensiveness and depth of their work. By highlighting specific areas where additional experiments are needed, the comment provides a clear path for improvement, allowing the authors to address the identified gap in their research. Therefore, the comment is mostly helpful, as it offers a clear direction for enhancing the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the existing bound with the independence number might be better for some graphs. It also notes that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment does not provide explicit guidance on how the authors should address this gap or what specific changes might be necessary. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning the discrepancy between \\\\sqrt(\\\\beta) and \\\\beta^{1/3}. It also notes that the existing bound with the independence number might be better for some graphs and that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment does not specify which part of the paper discusses these bounds or results, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear references or sections for the authors to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the existing bound with the independence number might be better for some graphs. It also notes that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific examples or detailed reasoning to support the claim that the existing bound might be better in certain cases. Without concrete evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning that the existing bound with the independence number might be better for some graphs. It also notes that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific guidance or suggestions on how the authors might address this gap or improve their results. While it points out an area for potential enhancement, it does not provide actionable advice or detailed insights into how the authors could achieve this. Therefore, the comment is somewhat helpful, as it highlights a potential improvement but does not offer comprehensive guidance for the authors to implement it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that while FIDs are still used, there are flaws associated with them and the Inception network. It recommends using DinoV2 Frechet Distances for comparisons, in addition to FID. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the draft need to be addressed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FIDs\" and \"Inception network,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear recommendation to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This guidance is detailed and actionable, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are flaws associated with FIDs and the Inception network, suggesting the use of DinoV2 Frechet Distances for comparisons. However, the comment lacks specific examples or references to support the claim about the flaws of FIDs and the Inception network. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of FIDs and the Inception network, suggesting that there are flaws associated with them. It recommends using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is clear and actionable, as it provides a specific suggestion for improvement. However, the comment could be more helpful if it included more detailed reasoning or examples of the flaws associated with FIDs and the Inception network, or if it suggested alternative metrics or methods for comparison. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the paper, suggesting that it might be incremental and similar to a previously published work. It asks the authors to clarify the differences between their paper and the cited work, specifically questioning whether the novelty lies in applying a similar methodology to a new task. While the comment prompts the authors to address the issue of novelty, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should compare their work with the cited paper and clarify the differences. However, the comment lacks concrete details on how to implement this comparison or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the novelty of the paper by comparing it to a specific prior work, https://aclanthology.org/2021.findings-acl.57.pdf. It asks the authors to clarify the differences between their paper and the cited work, particularly whether the novelty lies in applying a similar methodology to a new task. However, the comment does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this discussion. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it clearly identifies the issue of novelty and asks for clarification, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the paper by comparing it to a specific prior work, https://aclanthology.org/2021.findings-acl.57.pdf. It asks the authors to clarify the differences between their paper and the cited work, particularly whether the novelty lies in applying a similar methodology to a new task. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the paper is incremental or similar to the cited work. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the novelty of the paper, questioning whether it builds upon existing work or presents a truly novel contribution. It prompts the authors to compare their work with a specific prior publication, https://aclanthology.org/2021.findings-acl.57.pdf, and asks whether the novelty lies in applying a similar methodology to a new task. This feedback is somewhat helpful as it highlights a potential area for improvement and encourages the authors to clarify the unique aspects of their work. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to address the issue of novelty or what specific comparisons should be made. To be more helpful, the comment could include suggestions for additional analysis or comparisons that would strengthen the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or resolve this discrepancy, leaving them without a clear path forward. As a result, the comment is unactionable, as it does not offer any actionable feedback or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"the reported ablation studies in Table 2,\" which provides a clear reference point for the authors to understand the context of the issue. It specifically mentions the performance of the complete loss function compared to those with some terms missing on the CUB and SOP datasets, questioning why this does not make sense. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies the issue with the ablation studies and the unexpected results, providing a clear direction for the authors to address the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation is unexpected or problematic. Without additional context or justification, the claim remains unverifiable, as the authors are left without a clear understanding of why this result is significant or how it might impact their conclusions. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation studies presented in Table 2, noting that the complete loss function performed worse than those with some terms missing. This observation raises a question that the authors may need to address to understand the unexpected results. However, the comment does not provide any suggestions or guidance on how the authors might investigate or resolve this issue. While it highlights a potential area of concern, it lacks actionable advice or insights that could help the authors improve their draft. Therefore, the comment is barely helpful, as it points out a problem but does not offer a comprehensive or constructive response to guide the authors in addressing it.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include an experiment where the image is occluded, similar to previous suggestions. It provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model's long-range inference capacity. The comment implies that these experiments should be included in the final version of the paper, unless the authors can provide a reason for exclusion. However, the action is implicit, as the authors need to infer that they should run these experiments. Additionally, the comment lacks specific guidance on how to implement these experiments or what specific aspects to focus on, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an experiment where the image is occluded, similar to previous suggestions, and provides two reasons for this: (a) to simulate irregularity in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model\\'s long-range inference capacity. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. It is specific in detailing what the authors should do\u2014include an experiment with occluded images and explain its benefits. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the model\\'s long-range inference capacity. While the suggestion is logical and aligns with the goals of the paper, it lacks specific examples or references to support the claim. The comment provides a rationale for why this experiment would be beneficial, but it does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but could be strengthened with more detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for an additional experiment that could enhance the paper by simulating irregularity in neural/behavioral data and allowing the inspection of the model\\'s long-range inference capacity. The suggestion is clear and actionable, as it outlines the type of experiment that would be beneficial and provides reasoning for why it would be valuable. However, the comment could be more helpful if it included details on how to implement the experiment or what specific aspects of the model's inference capacity should be examined. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. It recommends using a second y-axis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit, as the authors can infer that they need to revise the figure to address the issue. However, the comment lacks concrete details on how to implement this suggestion, such as specific examples of how to use a second y-axis or another visualization. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, which is not physically accurate. The suggestion to use a second y-axis or another visualization is a concrete and actionable step for the authors to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward and implies negative rates, which is not physically accurate. The reviewer suggests using a second y-axis or another visualization for better clarity. However, the comment lacks specific examples or references to support the claim about the figure's accuracy. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary depth to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not physically accurate. The reviewer suggests using a second y-axis or another visualization to improve the clarity and accuracy of the figure. This feedback is clear and actionable, providing the authors with a specific direction to improve the presentation of their data. However, the comment could be more helpful if it included examples of how to implement the suggested changes or if it offered additional guidance on choosing the most appropriate visualization. Overall, the comment is mostly helpful as it highlights a clear area for improvement and provides a concrete suggestion, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on an observation without detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential area for improvement by suggesting that the authors consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. This feedback is somewhat helpful as it identifies a specific aspect that could enhance the paper's comprehensiveness and robustness. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to implement this idea, leaving the authors with limited actionable insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and that the abstract should be more high-level, omitting technical details. While the comment implies that the authors should revise the abstract to make it clearer, it does not provide explicit guidance on how to achieve this. The action is implicit, as the authors need to infer that they should clarify the statement. However, the comment lacks concrete details on how to make the abstract clearer, such as suggesting specific ways to rephrase the sentence or what aspects of the statement need clarification. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, namely that the statement is unclear and contains technical details that are not necessary for a high-level abstract. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and contains technical details that are not necessary for a high-level abstract. However, the comment does not provide any evidence or reasoning to support why the statement is unclear or why the technical details are unnecessary. Without specific examples or references, the authors may find it difficult to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that the statement is unclear and contains technical details that are not necessary for a high-level abstract. This feedback is clear and actionable, as it provides the authors with a specific area to improve the clarity and conciseness of their abstract. However, the comment could be more helpful if it suggested specific ways to rephrase the statement or what aspects of the statement need clarification. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, allowing them to enhance the overall quality of their paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The comment lacks concrete actions or detailed feedback on what aspects of the algorithm could be made more complex. As a result, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper Algorithm 2 is located in or provide any details on what aspects of the algorithm could be improved. This makes it difficult for the authors to understand exactly where the comment applies and what specific changes are needed. The comment is not grounded, as it does not provide clear references to specific sections or parts of the paper. It is also not specific, as it lacks detailed guidance on how to improve the complexity of the algorithm. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that there is room to improve the complexity of Algorithm 2, but it does not provide specific guidance or suggestions on how to achieve this improvement. While it identifies a potential area for enhancement, the comment lacks actionable advice or detailed feedback that would help the authors understand what aspects of the algorithm could be made more complex. This limits the comment's usefulness in guiding the authors to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it does not explicitly instruct the authors on which modalities to include or how to present the results. The suggestion is somewhat vague, as it lacks specific guidance on which tasks or modalities to focus on. Therefore, the comment is somewhat actionable, as it gives a general idea of what needs to be done but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. However, it does not specify which modalities or tasks should be included, nor does it provide guidance on how to present the results or address the concerns about expected test loss. The comment is not grounded as it does not clearly identify the specific part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be done. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. However, the comment lacks specific examples or references to support the claim that expected test loss is not meaningful for language-related tasks. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. The authors would need to provide more context or examples to fully understand the basis of the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it lacks specific guidance on which modalities or tasks to include, making it somewhat helpful. The suggestion to consider out-of-distribution (OOD) performance is relevant, but the comment could be more actionable by providing examples or guidance on how to address this concern. Overall, the feedback is somewhat helpful as it offers a general direction for improvement but lacks detailed instructions, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/few training steps. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what actions the authors should take to strengthen their motivation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/f few training steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work should be further justified, specifically regarding how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/few training steps. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/few training steps. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to provide a more robust justification for their approach. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the comment is somewhat helpful as it points out a crucial weakness that needs attention, but it lacks depth and actionable advice, making it a 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their work need improvement. While it identifies a potential area for enhancement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat actionable, as it highlights a concern but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the straightforward and naive use of Gaussian Process (GP) in the paper, referencing the GP community's investigation into dynamical modeling since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not specify which part of the paper discusses the use of GP or how the authors might address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, while it points out a potential area for improvement, it does not provide specific guidance on how to make the use of GP more sophisticated or aligned with the GP community's practices. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed evidence or guidance, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the straightforward and naive use of Gaussian Process (GP) in the paper, suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of Gaussian Process Dynamical Models in NIPs 2005. While the comment highlights a concern about the depth of the use of GP, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable advice or detailed examples, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim made in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs and suggests that the baseline models might not be properly regularized. The comment implies that the authors should investigate the regularization techniques used in their models, specifically questioning whether dropout is applied to the hidden states as well. However, the comment does not explicitly instruct the authors to conduct this investigation or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the regularization techniques and potentially adjust their models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim made in that section, suggesting that the baseline models might not be properly regularized and that the authors should investigate whether dropout is applied to the hidden states. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the regularization techniques used in the baseline models, specifically questioning whether dropout is applied to the hidden states. The reviewer provides a counter-argument based on their experience with high-dimensional LSTMs, suggesting that the baseline models might not be properly regularized. However, the comment lacks specific examples or references to support the claim that the baseline models are not properly regularized. While the reviewer provides a logical argument, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the supplemental section D.4, questioning the claim that smaller architectures are necessary for language models (LMs) compared to GAN models to avoid overfitting. It provides a counter-argument based on the reviewer's experience with high-dimensional LSTMs, suggesting that the baseline models might not be properly regularized. The comment also raises a specific question about whether dropout is applied to the hidden states, which could be a valuable point for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to investigate the regularization techniques or suggested specific experiments to address the issue. Overall, the comment is somewhat helpful as it highlights a potential area for improvement and encourages the authors to explore further, but it lacks depth and actionable suggestions to fully enhance the draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some ablations mentioned in previous sections are difficult to find in the subsequent content, suggesting that the writing in that part needs improvement. However, it does not provide explicit guidance on what specific aspects of the writing need improvement or how the authors should address this issue. The action is implicit and vague, as it leaves the authors to infer that they need to improve the writing in the mentioned part. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that some ablations mentioned in previous sections are hard to locate in the following contents, implying that the writing in that part needs improvement. However, it does not specify which sections or parts of the paper contain these ablations, making it difficult for the authors to pinpoint the exact areas that require attention. Additionally, the comment lacks specificity in detailing what aspects of the writing need improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that some ablations mentioned in previous sections are hard to locate in the following contents, suggesting that the writing in that part needs improvement. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some ablations mentioned in previous sections are difficult to locate in the subsequent content, suggesting that the writing in that part needs improvement. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the writing need improvement or how the authors can address this issue. While it identifies a potential area for improvement, it does not offer actionable feedback or suggestions for specific changes, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The actions are implicit and vague, leaving the authors without clear direction on how to improve their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"given2)-5)\" and \"differential privacy application,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should \"think through it more clearly\" and \"move the experimental results from the appendix to the main paper,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the differential privacy application is \"half-baked\" and recommends moving experimental results from the appendix to the main paper. However, it does not provide specific reasoning or examples to support why the application is considered half-baked or why the results should be moved. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"half-baked\" and recommends the authors think through it more clearly. It also suggests moving the experimental results from the appendix to the main paper, which could enhance the paper's impact. However, the comment lacks specific guidance on how to address the \"half-baked\" nature of the application or what specific aspects need clarification. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers some insight but could be more comprehensive and detailed to fully assist the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in its critique of the contribution of multilingual chain-of-thought being incremental compared to villa chain-of-thought, but without grounding, the authors cannot determine where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the incremental nature of the contribution of multilingual chain-of-thought compared to the villa chain-of-thought. While it identifies a potential weakness in the paper's contribution, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The comment lacks actionable advice, making it somewhat helpful as it highlights an area for improvement but does not offer a comprehensive or detailed response. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation. It suggests that using robotic manipulation in general could be more appropriate. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the methodology. The action is implicit, as the authors need to infer that they should clarify the methodology's specificity to bimanual manipulation. The comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its critique, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. This feedback highlights a potential ambiguity in the methodology description, which could hinder the reader's understanding. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the methodology. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it identifies a potential area for clarification but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. This is an explicit action that the authors can readily follow, as it clearly indicates what additional information is needed to improve the draft. The comment is specific in its request, detailing the exact metric (METEOR) that should be included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide METEOR results, which are also reported in recent works. However, it does not specify which part of the paper this information should be included in or how it relates to the content of the paper. The comment lacks grounding as it does not provide clear guidance on where the METEOR results should be added or discussed. It is also specific in its request for METEOR results, but without context, it is difficult for the authors to understand the exact need. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would benefit the paper. It lacks detailed justification or references to specific sections or studies that would help the authors understand the importance of including these results. As a result, the claim is unverifiable, as it lacks sufficient support or explanation. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide METEOR results, which are also reported in recent works. This feedback is specific and actionable, as it directs the authors to include additional quantitative results that align with current standards in the field. By providing these results, the authors can enhance the comprehensiveness and comparability of their work. However, the comment could be more helpful if it offered guidance on how to present or interpret these results effectively. Overall, the feedback is mostly helpful, as it provides a clear direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the comparability of G-effect values across different unlearning objectives and approaches, given that the study examines each objective in isolation. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the comparability of G-effect values, but it does not offer specific guidance on how to do so. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the concern regarding the comparability of G-effect values across different unlearning objectives and approaches, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of G-effect values across different unlearning objectives and approaches, noting that the study examines each objective in isolation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the comparability of G-effect values across different unlearning objectives and approaches, as the study examines each objective in isolation. This is a valid point that could impact the interpretation and comparability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the comparability of their findings. While it highlights an important consideration, the feedback could be more helpful if it provided actionable advice or suggestions for further analysis. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1-shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. However, the comment does not offer explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete details, making it challenging for the authors to understand how to respond or improve their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the consistency of the UNIFORM procedure's advantage over other methods, specifically noting that the results are not always clear, especially in the 1-shot setting. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or table. While the authors can infer that it relates to the experimental results or discussion of the UNIFORM procedure, the lack of explicit mention makes it weakly grounded. The comment is specific in identifying the need for a theory to explain the effectiveness in the 1-shot setting, but the absence of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the consistency of the UNIFORM procedure's advantage over other methods, particularly in the 1-shot setting. It notes that the tables show the UNIFORM method does not always offer a clear advantage. However, the comment lacks specific examples or references to support the claim that the results are not always clear. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the consistency of the UNIFORM procedure's advantage over other methods, particularly in the 1-shot setting. It points out that the results are not always clear, which could indicate a need for further clarification or a theory to explain the effectiveness in this setting. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or improve their draft. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it offers some insight but requires more comprehensive guidance for the authors to fully benefit from it.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this concept and suggests adding it to strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it does not specify which parts of the paper need to be revised or how to integrate the suggested theory. The action is explicit but somewhat vague in terms of implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, referencing specific sections of the paper (pages 7 or 8). It also asks if there is any existing linguistic theory that could explain this concept and suggests adding it to strengthen the paper. However, the comment does not specify which part of the paper discusses dialogue or information value, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the concept being discussed, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reason why information value is a stronger predictor for dialogue, referencing specific sections of the paper (pages 7 or 8). It suggests that the authors consider if there is any existing linguistic theory that could explain this concept and proposes adding it to strengthen the paper. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that information value is a stronger predictor. Without these elements, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by questioning the reason why information value is a stronger predictor for dialogue, referencing specific sections of the paper (pages 7 or 8). It suggests considering existing linguistic theories that could explain this concept and proposes adding such theories to strengthen the paper. This feedback is somewhat helpful as it points out a specific area for further exploration and potential enhancement of the paper. However, it could be more helpful if it provided more detailed guidance or examples on how to integrate these theories into the discussion. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the paper that could be improved by providing more detailed commentary on the use of AutoML approaches, particularly in extracting hints for future network architecture design. It suggests that the authors should elaborate on the takeaways from the found architecture. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of AutoML approaches, specifically focusing on extracting hints for future network architecture design. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide more detailed commentary on these aspects, but it lacks explicit references to specific sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not spend much time commenting on the use of AutoML approaches, particularly in extracting hints for future network architecture design. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on an observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the authors did not adequately comment on the use of AutoML approaches, particularly in extracting hints for future network architecture design. This feedback is somewhat helpful as it highlights a potential gap in the paper's discussion and suggests that the authors should provide more detailed commentary on this aspect. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as recommending additional sections or analyses that could be included. Overall, the comment provides a clear direction for improvement but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This suggests that the authors may need to ensure that all terms are defined before they are used in the paper. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting where the definition should be placed or how to clarify its usage. The action is implicit and somewhat vague, as the authors need to infer that they should define T_a(t) before using it in Section 3.1. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly points out that the term T_a(t) is used in Section 3.1 but only defined in Section 4, highlighting a potential issue with clarity and consistency. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation about the structure of the paper, and it does not require any additional evidence or reasoning to be considered verifiable. The comment is clear and specific, providing a clear indication of a potential issue with the paper\\'s organization. Therefore, the comment is classified as fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the term T_a(t) is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper\\'s structure and definitions. While the comment points out a specific area that needs attention, it does not provide detailed guidance on how to address the issue or suggest improvements. The feedback is somewhat helpful as it directs the authors to a particular area that requires clarification, but it lacks depth and actionable suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and that the inclusion of empirical results would be beneficial. However, it does not specify which sections of the introduction need to be revised or how the authors should make the text more concise. While the comment provides a general direction for improvement, it lacks specific guidance on what needs to be done to achieve conciseness or how empirical results should be integrated. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, especially the introduction, could be more concise and that including empirical results would be beneficial. However, it does not specify which sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is vague in its suggestion to include empirical results, as it does not provide any guidance on how to incorporate them or what kind of empirical results would be most relevant. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and that including empirical results would be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support why these suggestions are necessary or how they would improve the paper. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, especially the introduction, could be more concise and that including empirical results would be beneficial. While the comment identifies areas for improvement, it lacks specific guidance on how to achieve these changes. The feedback is somewhat helpful as it points out potential areas for enhancement, but it does not provide detailed instructions or examples for the authors to follow. Therefore, the comment is rated as 3: Somewhat Helpful, as it offers some direction but could be more comprehensive and actionable.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the confusion regarding the empirical analysis in Figure 3 and the large spacing in Equations (9) and (10). For the first concern, the authors are asked to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a clear and explicit action that the authors can take to address the issue. However, the comment does not specify how to provide this clarification, leaving the authors to infer the necessary steps. For the second concern, the authors are asked to explain why the adjustments are effective in enhancing the model's performance, which is also an explicit action but lacks concrete guidance. Overall, the comment is mostly actionable, as it provides clear directions but could be more detailed in terms of implementation. Therefore, it aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the empirical analysis in Figure 3, which is a specific part of the paper. It also mentions Equations (9) and (10), providing specific references to the parts of the paper that need clarification. This allows the authors to accurately identify the sections being discussed, making the comment fully grounded. The comment is also specific as it requests additional clarification on the adjustments made to the amplitudes of the input series and forecasting target, and why these adjustments are effective in enhancing model performance. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two questions: one about the confusion regarding the empirical analysis in Figure 3 and another about the large spacing in Equations (9) and (10). The first question prompts the authors to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a request for clarification and does not contain a subjective claim or assertion that requires verification. The second part of the comment questions the large spacing in Equations (9) and (10), which is a factual observation. However, the comment lacks specific examples or references to support the claim about the spacing, making it somewhat verifiable. Overall, the comment is somewhat verifiable as it provides some context but lacks detailed justification or evidence to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on two key areas: the empirical analysis in Figure 3 and the formatting of Equations (9) and (10). It requests additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a valuable suggestion that could help the authors improve the clarity and understanding of their empirical analysis. Additionally, the comment questions the large spacing in Equations (9) and (10), which is a factual observation that could be addressed by the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is mostly helpful as it identifies areas for improvement and provides a clear direction for the authors to follow, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison with the recent related work CoCoOp [1] in their experiments. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to add or discuss this comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate this comparison into their experimental analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the recent related work CoCoOp [1] and suggests that it should be compared in the experiments. This provides the authors with clear guidance on which part of the paper needs attention. The comment is also specific because it clearly specifies the need to compare with CoCoOp, indicating that this comparison is necessary for the experiments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent related work CoCoOp [1] should be compared in the experiments. While the comment suggests that this comparison is necessary, it does not provide specific reasoning or examples to support why this comparison is important or how it would enhance the paper. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a basis for improvement but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should include a comparison with the recent related work CoCoOp [1] in their experiments. This is a valuable piece of feedback as it highlights a gap in the current evaluation and suggests a relevant comparison that could enhance the paper's comprehensiveness. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or why it is necessary. Overall, the feedback is somewhat helpful as it directs the authors towards an important aspect of their work that needs further attention.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not provide explicit guidance on how to improve the figure or what specific aspects need to be addressed. The action is implicit and vague, as the authors are left to infer the necessary changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests improvements to Figure 1, specifically mentioning the need to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what aspects of the figure need improvement, but without explicit references to the figure itself, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide specific examples, references, or detailed reasoning to support why these improvements are necessary or how they would enhance the figure. Without additional context or evidence, the authors may find it challenging to understand the basis for the suggestion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving Figure 1, which could enhance the clarity and effectiveness of the paper. By suggesting that the figure should better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring, the comment offers actionable feedback that could help the authors improve the presentation of their work. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how the figure could be improved. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL model's performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide explicit guidance on how to address this limitation or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their experiments to more complex games. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ReBeL's performance on more complex problem\" and \"bigger depth,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a limitation in the experimental setup, noting that the experiments were only conducted on two typical games, and suggests that the model's performance on more complex problems, especially those with larger depth, could be explored. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL model's performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the experiments were limited to two typical games. This lack of evidence makes it difficult for the authors to understand the basis of the claim and how it might impact their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It highlights the potential for the ReBeL model's performance to be explored on more complex problems, especially those with larger depth, which could lead to significant inputs for the value and policy functions. While the comment points out a specific area for improvement, it does not provide detailed guidance on how to address this limitation or what specific experiments should be conducted. The feedback is somewhat helpful as it directs the authors to consider expanding their experiments, but it lacks depth and specificity, making it challenging for them to fully understand and implement the suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This comment provides a clear and explicit action for the authors to take: they should remove or define the abbreviations in the section header. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that abbreviations like \"MoCo\" should not appear in the section header, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This claim is somewhat verifiable as it provides a logical reasoning for why the inclusion of such abbreviations could be problematic. However, it lacks specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of abbreviations in the section header, noting that readers might not understand them. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By recommending that abbreviations like \"MoCo\" should not appear in the section header, the comment helps the authors enhance the clarity and accessibility of their paper. However, the comment could be more helpful if it provided additional guidance on how to define or remove abbreviations effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the analysis need to be clarified. The comment lacks explicit instructions or concrete details on how to improve the clarity of the technical contribution or the novelty of the analysis. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact issue. The comment lacks specificity in identifying what aspects of the analysis are standard and how they impact the clarity of the technical contribution. Without specific examples or references, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how it applies to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the technical contribution of the paper, suggesting that it is unclear and that most of the analysis is standard. However, the comment lacks specific details or actionable suggestions on how the authors might address this issue. It does not provide guidance on what aspects of the analysis need clarification or how the authors can enhance the novelty of their contribution. Without concrete feedback or suggestions, the authors may find it challenging to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide explicit guidance on what specific evidence or arguments are needed to establish this contribution as significant. The comment implies that the authors should provide more detailed evidence or arguments, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a need for more evidence but does not offer specific guidance on how to achieve this.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs to be addressed. The comment is specific in its critique of the contribution, but it lacks grounding as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer's assertion remains unsubstantiated, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. While it highlights this point, it does not provide specific feedback or suggestions on how the authors might address this issue or strengthen their contribution. The comment lacks actionable guidance, making it somewhat helpful as it points out a potential area for improvement but does not offer detailed advice or constructive feedback. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also notes that many previous works focus on this topic, implying that adding topic entities might be incremental. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to enhance the novelty of their work. The action is implicit and vague, as it does not specify which aspects of the paper need improvement or how the authors can demonstrate the significance of their contributions. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited, implying that the authors should consider adding topic entities, which might be incremental. However, the comment does not specify which part of the paper discusses the improvements on different datasets or the novelty of the paper. It lacks grounding as the authors cannot confidently determine which sections or aspects of the paper are being addressed. Additionally, the comment is somewhat specific in that it points out the triviality of the improvements and the incremental nature of adding topic entities, but it does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that adding topic entities might be incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper, suggesting that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also implies that adding topic entities might be incremental, which could be seen as a critique of the paper's contribution. However, the comment lacks specific details or suggestions on how the authors might address these issues or enhance the novelty of their work. Without actionable guidance or examples, the feedback is somewhat helpful, as it provides a general direction for improvement but does not offer a comprehensive roadmap for the authors to follow. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap or what aspects of the discussion could be expanded. The comment identifies a specific area that needs attention but does not offer guidance on how to improve the draft. As a result, the authors are left without a clear direction for action, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific gap in the paper by pointing out the lack of discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue is related to, such as a particular section or paragraph. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where to address the gap. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. This is a critical aspect that needs to be addressed for a comprehensive understanding of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as potential areas for further research or discussion. While it highlights an important issue, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it identifies a crucial area for improvement but does not provide detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measures for evaluating the generated VCEs, noting that the evaluation is primarily based on visual inspection. While it identifies a gap in the methodology, it does not provide explicit guidance on how to address this issue or suggest specific quantitative measures. The action is implicit, as the authors would need to infer that they should consider adding quantitative metrics to their evaluation process. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"generally lacking a quantitative measure to evaluate the generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking quantitative measures and suggests that the evaluation is primarily based on visual inspection. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, with evaluation primarily relying on visual inspection. This claim is somewhat verifiable as it highlights a potential gap in the methodology but does not provide specific examples or references to support the claim. The authors would need to infer that the lack of quantitative measures could be a limitation, but the comment lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of quantitative measures for evaluating the generated VCEs. It notes that the evaluation is primarily based on visual inspection, which may not provide a comprehensive or objective assessment. This feedback is valuable as it highlights a potential gap in the methodology and suggests that the authors should consider incorporating quantitative measures to enhance the rigor and depth of their evaluation. However, the comment could be more helpful if it provided specific examples of quantitative measures that could be used or suggested alternative evaluation methods. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors claim their method performs better than baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors can address this issue or improve their results. It lacks concrete actions or detailed feedback on what specific aspects of the method or experiments need to be revised or enhanced to achieve more significant performance gains. As a result, the authors are left without clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"only marginal improvements over baselines\" and \"error bar range,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of marginal improvements and the high error range, suggesting that the performance differences between some methods are not significant. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' method only shows marginal improvements over baselines, mostly within the error bar range. It suggests that the performance differences between some methods are not significant. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a key issue with the authors' claims regarding the performance of their method compared to baselines. It points out that the improvements are marginal and within the error bar range, suggesting that the performance differences are not significant. This feedback is valuable as it highlights a potential overstatement in the authors' claims and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue, such as suggesting additional experiments or analyses to demonstrate more substantial performance gains. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, noting that only some are convincing and that the action recognition performance is below the state-of-the-art on the UCF dataset. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the video generation or action recognition performance. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, such as a particular section, table, or figure. It also lacks specificity, as it does not detail what aspects of the generated videos or action recognition performance need improvement. The comment is vague and does not provide clear guidance on how the authors might address the issues mentioned. Therefore, it is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point mentions that the generated videos have significant artifacts and that only some are convincing. It also notes that the action recognition performance is below the state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the nature of the artifacts or the specific performance issues. Without detailed evidence or examples, the claim is considered borderline verifiable, as it provides some basis for concern but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the generated videos, noting that they have artifacts and that the action recognition performance is below the state-of-the-art on the UCF dataset. This feedback highlights areas where the authors could improve their work, specifically in terms of video quality and performance. However, the comment lacks specific suggestions or guidance on how to address these issues, such as potential improvements in video generation techniques or action recognition methods. While it points out important weaknesses, the absence of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It also asks for clarification on how to select representative images. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the action is not concrete or detailed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method and how to select representative images. However, it does not provide any specific reasoning, examples, or references to support why this is an issue or how it could be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. This feedback highlights a potential gap in the paper's methodology or experimental design, suggesting that the authors need to clarify how their new evaluation set differs from existing methods and how they ensure the selection of representative images. However, the comment lacks specific guidance or suggestions on how to address these issues, leaving the authors with a general idea of what needs improvement but without concrete steps to take. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide detailed actionable feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These suggestions are clear and direct, allowing the authors to understand exactly what needs to be added to their draft. The comment is fully actionable as it provides concrete guidance on how to improve the paper. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. While it provides some specificity by mentioning the need for a background section and a brief overview of the DPO algorithm, it does not detail how these additions would improve the paper. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment provides a logical reasoning for the need for these additions, it lacks specific examples or references to support the claim fully. The authors would need to infer the importance of these additions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by recommending the inclusion of a background section on the basic RL framework, including elements of the MDP, trajectories, and policy. This would help readers understand the context of the work. Additionally, the comment suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These suggestions are clear and actionable, offering valuable guidance for the authors to enhance the clarity and comprehensibility of their paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests a potential limitation of the proposed method when users continuously add new languages due to limited model capacity. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment identifies a potential problem but lacks guidance on how to mitigate it or what steps the authors should consider. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the proposed method's limitation when users continuously add new languages due to limited model capacity. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the proposed method's limitation when users continuously add new languages due to limited model capacity. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method when users continuously add new languages due to limited model capacity. This is a valid concern that could impact the scalability and applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation. While it highlights an important issue, it does not provide actionable advice or insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer comprehensive guidance for resolution.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). While it raises a valid point about the need to clarify the connection between the term and the cited work, it does not provide explicit guidance on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should clarify the relevance of the term in the context of the cited work. However, the lack of concrete instructions on how to do so makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider by questioning the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). While it does not contain a subjective claim or suggestion, it prompts the authors to consider the connection between the term and the cited work. However, without further elaboration or context, the comment lacks sufficient justification or evidence to be considered fully verifiable. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). This question prompts the authors to consider the connection between the term and the cited work, which could help them clarify their terminology and ensure consistency in their use of terms. However, the comment lacks depth and does not provide specific guidance on how the authors might address this question or incorporate it into their draft. While it identifies an area for improvement, it does not offer actionable feedback that would significantly enhance the authors' understanding or the quality of their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. While this feedback identifies a potential area for improvement, it does not provide explicit guidance on how the authors should expand their experiments or what additional datasets they could consider. The action is implicit, as the authors can infer that they need to include more diverse datasets to enhance the robustness and generalizability of their findings. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments being limited to MNIST and a single real-world dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation in the experiments, indicating that the authors should consider expanding their experiments to include more diverse datasets. This provides clear guidance on what needs to be addressed to improve the robustness and generalizability of the findings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. This feedback is somewhat verifiable as it points out a potential gap in the experimental scope, but it lacks specific examples or references to support the claim. The authors might infer that expanding the experiments to include more diverse datasets would enhance the robustness and generalizability of their findings, but the comment does not provide detailed guidance or evidence to support this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. This feedback is valuable as it highlights a potential area for improvement, suggesting that the authors should consider expanding their experiments to include more diverse datasets. However, the comment lacks specific guidance on which additional datasets to consider or how to approach this expansion. While it provides a clear direction for improvement, the lack of detailed suggestions or examples makes it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the action is implicit, as the authors need to infer that they should provide more details to address the question. The action is vague because it does not specify exactly what additional details are needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. It suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the authors cannot confidently determine which part of the paper this comment refers to, as it is not explicitly mentioned. The comment is specific in its critique of the S2D structure, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. This reasoning is clear and logical, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue in the S2D structure, questioning why the number of parameters does not change when the kernel height and width remain the same. It provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The reviewer acknowledges that efficiency could be improved due to the quadratic nature of FLOPs on activation side length but emphasizes the need for more details regarding parameters. This feedback is clear and actionable, as it directs the authors to provide additional information or clarification on the parameter changes in the S2D structure. However, it could be more helpful if it suggested specific areas where more details are needed or provided examples of how to address the issue. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the similarity between the proposed method and the approach in [10], suggesting that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider whether [10] could benefit from these side information. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it does not specify how the authors should explore or implement the suggestions. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between the proposed method and the approach in [10], suggesting that [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is intended to address, making it weakly grounded. The comment is specific in its suggestion to consider the potential of [10] for additional features, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the similarity between the proposed method and the approach in [10], suggesting that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the suggestion. Without clear justification or references, the claim is barely verifiable, as it relies on the authors' interpretation and understanding of the existing work. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the similarity between the proposed method and the approach in [10], suggesting that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to differentiate their method from [10]. While it identifies a potential area for improvement, it does not provide actionable advice or detailed reasoning, making it somewhat helpful. The authors would need to infer the need for further exploration and comparison, which limits the comment's effectiveness. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the analysis. The comment lacks concrete guidance on what changes could be made to the results or how the authors might enhance their interpretation. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the Atari game results are discussed in, nor does it provide any context or explanation for why the results are limited to a single game and baseline. The authors cannot confidently determine which section or part of the paper is being addressed, making it difficult to understand the issue being raised. Additionally, the comment is not specific because it does not detail what aspects of the results are difficult to interpret or what suggestions could be made to improve the analysis. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the Atari game results are limited to a single game and a single baseline, making them difficult to interpret. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. While the comment highlights a potential issue with the scope of the results, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the analysis. The feedback is somewhat helpful as it points out a weakness in the results section, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This absence could lead to the model using more factors as the number of tasks increases, resulting in increased computation. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest any specific actions to improve the model. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to understand how to implement the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the proposed method, noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This allows the authors to accurately identify the part of the paper being discussed, making the comment fully grounded. The comment is also specific, as it clearly explains the issue and its potential consequences, providing guidance on how the model might be incentivized to use more factors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method lacks a sparsity constraint, which could lead to an increase in the number of factors and computation as the number of tasks increases. However, the comment does not provide specific evidence or references to support this claim, such as examples of how the lack of sparsity might manifest or why it is a significant issue. Without detailed reasoning or supporting evidence, the claim remains somewhat verifiable, as it lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This lack of constraint could lead to an increase in the number of factors and computation as the number of tasks increases, potentially impacting the model's efficiency. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the model. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the presentation of the simulation study is not effective in supporting the authors. It specifically notes that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to the bandit feedback and not the use of information about the form of the cost function. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their presentation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comment on why the GPC (benchmark) performs better than BPC (the authors' method) and suggests that this difference is due to bandit feedback and not the use of information about the cost function form. This provides a clear direction for the authors to improve their presentation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation of the simulation study is not effective in supporting the authors, specifically noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to bandit feedback and not the use of information about the cost function form. However, the comment lacks specific examples or detailed reasoning to substantiate this claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which limits its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) performs better than BPC (their method). It suggests that the difference is due to bandit feedback and not the use of information about the cost function form. This feedback is clear and actionable, as it provides a specific area for improvement and a clear rationale for why the authors should address this issue. However, the comment could be more helpful if it offered suggestions on how to reiterate this point or provide additional context. Overall, the comment is mostly helpful, as it guides the authors to improve their presentation but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim, leaving the action somewhat vague. The authors are left to infer that they need to provide more evidence or explanation to support the claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work very well in very deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. However, the comment does not explicitly mention which part of the paper this claim is being addressed, making it weakly grounded. The comment is specific in suggesting that the authors should provide more evidence or explanation to support the claim. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work very well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat verifiable. The authors would need to infer the basis for the claim and seek additional evidence to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work very well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. However, the comment does not offer detailed guidance on how to quantify or clarify the claim, leaving the authors with limited actionable feedback. While it points out a potential area for improvement, it lacks depth and specificity, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It also asks for clarification on how the perplexity was calculated. While the comment identifies a potential issue with the reported perplexity values and requests clarification on the calculation method, it does not provide explicit guidance on how to address the issue or improve the draft. The action is implicit, as the authors need to infer that they should investigate the discrepancy and provide a detailed explanation of the perplexity calculation. However, the lack of concrete steps or suggestions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexity values, noting that they are over 30 and contradict better BLEU scores. The comment requests clarification on how the perplexity was calculated, providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It requests clarification on how the perplexity was calculated. While the comment identifies a potential issue with the reported perplexity values, it lacks specific examples or references to support the claim that the perplexity is over 30 and contradicts better BLEU scores. The request for clarification is logical but does not provide detailed reasoning or evidence to substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported perplexity values in Figure 1, noting that they are over 30 and contradict better BLEU scores. It also requests clarification on how the perplexity was calculated. This feedback is somewhat helpful as it points out a discrepancy that needs to be addressed, but it lacks detailed guidance on how to resolve the issue or improve the draft. The authors are left with a general direction but without specific steps or suggestions, which limits the comment's impact. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. While the comment implies that these additions are necessary, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their evaluation to include these aspects. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is intended for, nor does it provide any guidance on how to conduct these experiments or what specific aspects of the model should be evaluated. The lack of grounding makes it difficult for the authors to understand which sections or parts of the paper need revision. Additionally, the comment is specific in terms of suggesting the need for additional experiments, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any specific reasoning, examples, or references to support why these additions are necessary or beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. This feedback is somewhat helpful as it identifies a specific area for improvement in the evaluation section. However, it lacks depth and does not provide detailed guidance on how to conduct these additional experiments or what specific aspects of the evaluation should be expanded. The comment is clear in its suggestion but could be more comprehensive if it offered more detailed advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper where the authors define rooted patterns but do not elaborate on their importance or how the roots are chosen. It suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. While the comment implies that the authors should provide more context and explanation, it does not explicitly instruct them to add a discussion or clarify the choice of roots. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the importance and selection of rooted patterns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the definition of rooted patterns and suggests that the authors should elaborate on their importance and how they choose the roots. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to elaborate on the importance and selection of rooted patterns, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors define rooted patterns but do not elaborate on their importance or how they choose the roots. It suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. This claim is somewhat verifiable as it provides a logical reasoning for why the authors should elaborate on the importance and selection of rooted patterns, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper where the authors define rooted patterns but do not elaborate on their importance or how the roots are chosen. It suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if non-rooted patterns are sufficient. This feedback is somewhat helpful as it points out a specific area where the authors could improve the clarity and depth of their explanation. However, it could be more helpful if it provided more detailed guidance on how to elaborate on the importance and selection of rooted patterns, or suggested specific examples to include in the discussion. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, it does not provide explicit guidance on what specific aspects of the paper need further explanation or elaboration. The suggestion to give more explanations is clear and actionable, as it directs the authors to expand on this point. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but lacks detailed guidance on how to implement it.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (95-97 and 308-310) where the issue of consistency between training and inference is discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should provide more explanations on this topic, indicating what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where the consistency between training and inference is discussed, noting that it can be easily satisfied due to the smoothness of neural models. The comment suggests that the authors should provide more detailed explanations on this topic. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work that could enhance its clarity and depth. However, the comment could be more helpful if it provided specific examples or guidance on how to elaborate on the consistency issue. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment does not explicitly instruct the authors to conduct this exploration or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should test the model with larger parameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment does not specify which part of the paper discusses the model's performance or parameters, making it weakly grounded. It is specific in questioning the claim and suggesting an additional experiment, but without clear references to the sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the claim or understand the reasoning behind it. The feedback is somewhat verifiable as it provides a direction for further investigation but lacks detailed justification or evidence. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the authors' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific guidance or suggestions on how to conduct this exploration or what experiments to perform to substantiate the claim. While it points out a potential area for further investigation, it does not provide actionable steps or detailed feedback that would help the authors address the issue effectively. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for finetuning the extra two hyperparameters, k and \u03b7, and suggests that this process depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide explicit guidance on how the authors should implement this finetuning process or what specific steps they should take. It lacks concrete details on how to determine the optimal values for these hyperparameters or how to integrate them into the model. As a result, the authors are left without a clear understanding of how to address this issue, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for finetuning two hyperparameters, k and \u03b7, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being discussed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to finetune these hyperparameters or what impact they might have on the model. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the extra two hyperparameters, k and \u03b7, require finetuning, which depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered verifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning. It highlights that this process depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the proper finetuning of these hyperparameters. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful. The authors are left with a clear problem but no concrete steps to resolve it, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the regularization methods used for the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to reproduce the features of previous models. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the regularization methods used in the LN model and the GLM, specifically noting a discrepancy in the regularization techniques. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not specify which part of the paper discusses the regularization methods or the GLM, making it weakly grounded. The comment is specific in detailing the issue with the regularization methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a specific concern about the regularization methods used in the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. The comment provides a detailed explanation of the discrepancy in regularization techniques, referencing the work of Pillow et al. This allows the authors to understand the issue and potentially address it by aligning their approach with previous studies. The claim is mostly verifiable as it is supported by logical reasoning and references to previous work, but it could be strengthened with more specific examples or detailed reasoning. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the regularization methods used in the LN model and the GLM, noting a discrepancy with the methods described in previous work. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, it could be more helpful if it included suggestions on how to reproduce the features of previous models or examples of how to implement the suggested approach. Overall, the comment is mostly helpful, as it offers valuable guidance but could be expanded for more comprehensive assistance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be improved by including some failure cases and related discussion. While the comment implies that this addition would enhance the paper, it does not explicitly instruct the authors to include specific examples or details about these failure cases. The action is implicit, as the authors need to infer that they should add this information, but it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would be improved by including some failure cases and related discussion. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors cannot confidently determine where to address this feedback, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include failure cases and related discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would be improved by including some failure cases and related discussion. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this suggestion is beneficial or how to incorporate it into their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would be improved by including some failure cases and related discussion. While this feedback is relevant and could enhance the paper's comprehensiveness, it lacks specific guidance on how to incorporate these failure cases or what aspects of the discussion would be beneficial. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide detailed suggestions or examples, leaving the authors with limited actionable insights. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform an ablation study to address the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its suggestion to conduct an ablation study, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests that an ablation study would be helpful. However, the comment does not provide any specific reasoning, examples, or references to support why the base layer GNN encoding is unclear or why an ablation study is necessary. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically questioning the necessity of the base layer GNN encoding. It suggests that an ablation study would be helpful to address this concern. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific results would be expected. This makes the feedback somewhat helpful, as it points out a potential weakness but does not fully address the authors' needs for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the variable \\\\(\\\\epsilon\\\\) should be introduced when discussing equation (11) instead of equation (10). This provides a clear and explicit action for the authors to take, as they can directly address the issue by introducing \\\\(\\\\epsilon\\\\) in the context of equation (11). The comment is specific and concrete, giving the authors a precise idea of what needs to be done to improve the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the variable \\\\(\\\\epsilon\\\\) is not used in equation (10) but is used in equation (11), suggesting that introducing \\\\(\\\\epsilon\\\\) when discussing equation (11) would improve clarity. This provides a clear and actionable direction for the authors to take, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that introducing \\\\(\\\\epsilon\\\\) when discussing equation (11) would improve clarity. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the variable \\\\(\\\\epsilon\\\\) is not used in equation (10) but is used in equation (11). The comment suggests that introducing \\\\(\\\\epsilon\\\\) when discussing equation (11) would improve the clarity of the paper. This feedback is clear and actionable, providing the authors with a specific direction to enhance the presentation of their work. By addressing this suggestion, the authors can improve the readability and understanding of their paper, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not adequately discuss the computational complexity of counting homomorphomorphisms. It notes that the authors make brief statements in the paper, such as \"Better still, homomorphism counts of small graph patterns can be efficiently computed even on large datasets,\" but suggests that it would be beneficial to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. The comment implies that the authors should provide a more detailed discussion of the computational complexity, which is a clear and explicit action. However, it does not specify exactly how to elaborate on the upper bounds or empirical runtimes, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue of computational complexity is discussed, specifically referencing \"better still, homomorphism counts of small graph patterns can be efficiently computed even on large datasets\" in the context of line 145. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on the computational complexity of counting homomorphisms and suggests adding upper bounds and elaborating on empirical runtimes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, noting that the paper makes brief statements but suggests that it would be beneficial to explicitly add the upper bounds of counting and elaborate on empirical runtimes. The comment provides a logical reasoning by highlighting the lack of detailed discussion and suggesting specific areas for improvement. However, it does not offer specific examples or references to support the claim, which could make it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the authors could improve their paper by discussing the computational complexity of counting homomorphisms. It points out that the paper makes brief statements but suggests that explicitly adding the upper bounds of counting and elaborating on empirical runtimes would enhance the paper's clarity and depth. This feedback is clear and actionable, providing the authors with specific directions for improvement. However, the comment could be more helpful if it offered additional guidance on how to calculate or estimate these upper bounds or suggested specific empirical runtime comparisons. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on a potential error in the text, noting that the first \"f\" should be \"g\" and that there is an extra \".\" in the middle of a sentence. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment explicitly points out the error and raises a question, it does not provide explicit guidance on how to correct the error or address the question. The action is implicit, as the authors would need to infer that they should correct the error and consider the impact of early learner cutting. However, the feedback is somewhat vague, as it lacks detailed instructions on how to implement the correction or address the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (108 and 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, such as correcting a typographical error and questioning the convergence of networks in a baseline MCL with deep learning. This level of detail provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the concern, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies specific issues in the text, such as a typographical error and a question about the convergence of networks in a baseline MCL with deep learning. It provides actionable feedback by pointing out the error in line 108 and the potential impact of early learner cutting on ensemble performance. However, the comment could be more helpful if it offered guidance on how to address the question or suggested alternative approaches to ensure convergence. While the feedback is somewhat detailed, it lacks depth and could be expanded to provide more comprehensive advice, making it mostly helpful rather than fully helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a study of inference time for their pose estimation method, comparing it to previous top-down and bottom-up methods. While the comment implies that this study should be conducted, it does not provide explicit guidance on how to perform the study or what specific aspects of inference time to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis of inference time and compare it to other methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a study of inference time for their pose estimation method, comparing it to previous top-down and bottom-up methods. However, it does not specify which part of the paper this should be addressed in, making it weakly grounded. The comment is specific in its suggestion to include a study of inference time and compare it to other methods, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a study of inference time for their pose estimation method, comparing it to previous top-down and bottom-up methods. However, the comment lacks specific details or references to support the claim, making it difficult for the authors to understand the basis for this suggestion or how to address it. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on a logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a study on inference time for the proposed pose estimation method. It suggests that the authors should compare the inference speed of their method to previous top-down and bottom-up pose estimation methods, which is a valuable and actionable piece of feedback. By highlighting this omission, the comment encourages the authors to conduct a comparative analysis that could enhance the practical applicability and relevance of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct the study or what aspects of inference time to focus on. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not provide explicit instructions or suggestions on how to address these issues, such as suggesting alternative indexing or revisiting the calculation. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the indexing of the input x and the calculation of the sum of squares of the second layer weights, specifying exactly what needs to be clarified or corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not contain any subjective opinions or claims that require verification. The questions are factual and descriptive, aligning with the classification of \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific issues in the proof of Theorem A.3, particularly questioning the indexing of the input x and the calculation of the sum of squares of the second layer weights. It points out that the input is a vector, not a matrix, and questions the correctness of the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d , instead of d. While the comment highlights potential errors in the proof, it does not provide detailed guidance or suggestions on how to correct these issues. The feedback is somewhat helpful as it directs the authors to specific areas that need attention, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in the description of results, particularly in sections 4.3 and 4.4. It questions the accuracy of the results, noting that only 77% of the results list contains the ground truth logical forms. The reviewer also asks about the percentage of correct entities and relationships plugged in when no ground truth is available. While the comment identifies a potential issue with the accuracy of the results and raises questions about the reliability of the findings, it does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific sections of the paper, 4.3 and 4.4, making it fully grounded. It also specifies the issue with the use of terms like \"somewhat\" and \"good generative ability\" and questions the accuracy of the results, particularly the 77% of results containing ground truth logical forms. The reviewer asks about the percentage of correct entities and relationships plugged in when no ground truth is available, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of the results presented in sections 4.3 and 4.4, specifically questioning the use of terms like \"somewhat\" and \"good generative ability.\" It highlights that only 77% of the results list contains the ground truth logical forms and asks about the percentage of correct entities and relationships plugged in when no ground truth is available. While the comment identifies a potential issue with the accuracy of the results, it lacks specific examples or references to support the claim that the results are not accurate or that the use of these terms is problematic. The reasoning provided is somewhat vague, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the accuracy of the results presented in sections 4.3 and 4.4, specifically questioning the use of terms like 'somewhat' and 'good generative ability.' It highlights that only 77% of the results list contains the ground truth logical forms, which raises questions about the reliability of the findings. The comment also asks about the percentage of correct entities and relationships plugged in when no ground truth is available, prompting the authors to consider the accuracy of their results. While the comment identifies a potential issue with the accuracy of the results, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out a critical area for improvement but lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not provide explicit instructions or suggestions on how to address these limitations or what specific aspects of the claim need to be discussed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and internal covariate shift, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, suggesting that Batch Normalization standardizes variance and centers activation, which should be discussed explicitly. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides a general direction but lacks depth and specificity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also points out that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the limitations of the claim. However, the comment could be more helpful if it offered additional guidance on how to discuss these limitations or suggested specific aspects of the claim that need clarification. Overall, the comment is mostly helpful as it provides a clear and actionable feedback, but it could be further enhanced to be fully comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the dependence of FedPCL's performance on the selection of pre-trained models, noting that this limits its applicability to a broader range of areas. It also mentions that the model accuracy is sensitive to the choice of pre-trained models, as shown in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific actions they should take to improve the framework. While the authors are informed of the issue, they are not given concrete steps to follow, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by stating that the performance of FedPCL heavily relies on the selection of different pre-trained models, limiting its applications. The comment further details the issue by mentioning that the model accuracy is sensitive to the pre-trained models and that the authors have adequately addressed the limitations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedPCL heavily relies on the selection of different pre-trained models, limiting its applications to a broader range of areas. It also notes that the model accuracy is sensitive to the choice of pre-trained models, as shown in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the sensitivity of model accuracy to pre-trained models. While the authors are informed of the issue, the comment does not provide a clear explanation or evidence to support the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the performance of FedPCL, which is heavily dependent on the selection of pre-trained models. This limits its applicability to a broader range of areas. The comment also notes that the model accuracy is sensitive to the choice of pre-trained models, as evidenced by the results in Table 4. While the comment acknowledges that the authors have adequately addressed these limitations, it does not provide specific suggestions or guidance on how to improve the framework or address the identified issues. The feedback is somewhat helpful as it highlights a key area for improvement but lacks depth and actionable advice, leaving the authors with a general understanding of the problem without clear steps to resolve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. This provides a clear and explicit action for the authors to take, as they know exactly what additional information to include in their figures. The comment is specific in its request, detailing what needs to be added to enhance the qualitative analysis. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including tentative attention maps in the qualitative figures, which implies that the authors should consider adding this information to enhance their analysis. However, the comment does not specify which part of the paper the authors should focus on or which figures are relevant. This lack of specific grounding makes it difficult for the authors to identify the exact sections or parts of the paper that need attention. While the comment is specific in its suggestion, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including \"tentative attention maps\" in the qualitative figures, which implies that the authors should consider adding this information to enhance their analysis. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including \"tentative attention maps\" in the qualitative figures, which could enhance the analysis and provide additional insights into the model's behavior. However, the comment lacks specificity, as it does not specify which figures or sections of the paper should include these maps. Additionally, it does not provide any guidance on how to generate or interpret these maps, which limits its helpfulness. While the suggestion is relevant, the lack of detailed feedback makes it somewhat helpful, as it provides a direction for improvement but lacks depth and actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which aspects of the contribution need more detail or how the authors should go about adding this description. The action is implicit and vague, as it does not provide concrete guidance on what specific elements of the contribution require additional explanation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this contribution is discussed in, nor does it provide any guidance on what aspects of the contribution need more detail. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any details on what kind of description is needed or how it should be added. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is necessary or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it lacks specificity and does not provide any guidance on what aspects of the contribution need more detail or how the authors should go about adding this description. The comment is vague and does not offer actionable feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the organization of the paper by suggesting that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. It also suggests that tricks like normalization or feature scaling could be referenced in a separate section. However, the comment does not explicitly instruct the authors on how to implement these suggestions, such as where to add these sections or how to integrate the tricks. While the suggestions are clear, the lack of explicit guidance on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the organization of the paper, such as separating the description of the main contributions and the generative/inference models, and referencing tricks like normalization or feature scaling in a separate section. However, it does not explicitly mention which sections or parts of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of minor comments and suggestions regarding the organization and structure of the paper. It suggests that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. However, the comment lacks specific examples, detailed reasoning, or references to support these suggestions, making it difficult for the authors to understand and implement the changes. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment provides specific suggestions for improving the organization and structure of the paper. It suggests that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. This would help improve the clarity and flow of the paper. Additionally, the comment recommends referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper's clarity and completeness. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific section titles or formatting instructions. While the feedback is somewhat helpful, it could be more comprehensive with additional details on implementation. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about Figure 5 or its labels, but it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this issue, making the comment unactionable. Therefore, this comment aligns with the lowest score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about Figure 5 or its labels, but it does not specify which part of the paper this issue pertains to, nor does it provide any guidance on how to address it. The authors cannot confidently determine which section or element of the paper is being referred to, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what needs to be clarified or corrected. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about Figure 5 or its labels, but it does not provide any specific reasoning, examples, or references to support the claim. The authors are left to interpret the issue, making the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about Figure 5 or its labels, but it does not provide any specific guidance or suggestions on how to address this issue. The authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include supervised baselines in their experiments, particularly for datasets of a certain scale. It provides a rationale for why this is important, explaining that full annotation is often available for datasets of this size and that it would be informative to compare self-supervised methods to fully supervised pre-trained networks. However, the comment does not explicitly instruct the authors on how to implement this suggestion, such as which specific baselines to include or how to compare the results. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of missing supervised baselines in the experiments, which is a specific aspect of the paper. It provides a rationale for why this is important, suggesting that it would be informative to compare self-supervised methods to fully supervised pre-trained networks, especially for datasets of a certain scale. However, the comment does not explicitly mention which part of the paper discusses the experiments or the datasets used, making it weakly grounded. The specificity of the comment is good as it clearly specifies the need for supervised baselines and the rationale behind it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks supervised baselines, which is a reasonable suggestion given the scale of the datasets used. The comment provides a rationale for why this is important, explaining that full annotation is often available for datasets of this scale and that it would be informative to compare self-supervised methods to fully supervised pre-trained networks. However, the claim lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. While the reasoning is logical, the lack of detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why these baselines are important, suggesting that they would be informative for comparing self-supervised methods to fully supervised pre-trained networks, especially for datasets of a certain scale. This feedback is valuable as it highlights a crucial aspect that could enhance the comprehensiveness and impact of the paper. However, the comment could be more helpful if it provided specific examples of where these baselines could be included or how they would be implemented. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the paper: the minimal performance differences between methods and the use of outdated and saturated benchmarks. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should consider re-evaluating their results or selecting more appropriate benchmarks, but it does not offer specific guidance on how to do so. Without concrete steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance differences between methods and the use of outdated benchmarks, but it does not specify which part of the paper these issues are discussed in. The authors cannot confidently determine which sections or figures are being referred to, making the comment weakly grounded. However, the comment is specific in detailing the issues with minimal performance differences and outdated benchmarks, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point, which may be due to random variation. It also suggests that the benchmarks used are outdated and likely saturated, citing a specific reference. The claim about minimal performance differences is somewhat verifiable as it is supported by the observation of small differences in results. However, the claim about outdated benchmarks lacks specific examples or detailed reasoning, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. This observation suggests that the results may be due to random variation, which is a critical point for the authors to address. Additionally, the comment points out that the benchmarks used are outdated and likely saturated, indicating a need for more comprehensive or up-to-date evaluations. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address these concerns, such as suggesting alternative benchmarks or methods for analysis. The feedback is somewhat helpful as it points out areas for improvement, but it lacks actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for the authors to consider. It questions the effectiveness of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. Additionally, it asks why BEAR is missing from the baselines. While the comment provides some guidance, it lacks explicit instructions on how to address these points or what specific actions the authors should take. The suggestions are somewhat vague and do not offer detailed guidance on how to conduct the additional evaluations or why BEAR is missing from the baselines. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment does not specify which part of the paper discusses the method's application or evaluation on Hopper, making it weakly grounded. While it provides some specificity by questioning the method's effectiveness and suggesting additional evaluations, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The questions are open-ended and do not provide clear guidance or evidence, leaving the authors uncertain about how to address the concerns. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several important questions and suggestions for the authors to consider. It questions the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. This provides a clear direction for further experimentation and analysis, which could help the authors better understand the method's limitations and potential applications. Additionally, the comment points out the absence of BEAR in the baselines, which is a relevant concern for the authors to address. However, the comment could be more helpful if it provided specific guidance on how to conduct these evaluations or why BEAR is missing from the baselines. Overall, the feedback is somewhat helpful as it identifies areas for improvement and suggests further analysis, but it lacks detailed guidance to fully enhance the authors' understanding and approach.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. While the comment implies that this justification is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors need to infer that they should add a theoretical or conceptual explanation for the effectiveness of these techniques. However, the comment lacks concrete guidance on how to provide this justification, such as suggesting specific types of theocratical reasoning or examples. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. However, it does not specify which part of the paper this justification should be included in, making it weakly grounded. The comment is specific in its request for a justification, but without clear guidance on where to include it, the authors may struggle to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or examples, the claim remains vague and challenging to verify. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors provide a theocratical justification for why co-training and weight averaging improve results. This feedback is somewhat helpful as it highlights a specific aspect of the paper that could enhance its clarity and depth. However, the comment lacks detailed guidance on how to provide this justification, such as suggesting specific types of theocratical reasoning or examples. Without more detailed instructions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. It provides a specific reason for this suggestion, indicating that the histogram should include the multiplicities of labels. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors would need to infer that they should revise the definition of \"X\" and consider the implications for the histogram representation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and detailed explanation of why the term \"X\" should be a multiset instead of a set, emphasizing the need to include multiplicities of labels for accurate histogram representation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a specific reasoning, explaining that including the multiplicities of labels is necessary for the histogram to honestly represent such graphs. This reasoning is logical and well-supported, making the claim fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, suggesting that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a clear rationale for this suggestion, explaining that including the multiplicities of labels is necessary for the histogram to honestly represent such graphs. This feedback is actionable and provides a specific direction for improvement, helping the authors refine their work. However, the comment could be more helpful if it included additional guidance on how to implement this change or examples of how it would affect the results. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or incorporate Bayesian considerations into their derivation. The authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment does not provide specific guidance on how to address the issue or incorporate Bayesian considerations. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides an example of Bayesian-PAC based bounds, suggesting that the authors should consider incorporating Bayesian considerations. However, the comment lacks detailed reasoning or specific references to support the claim that classical bounds are unrealistic without Bayesian considerations. The authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which may not yield realistic results without incorporating Bayesian considerations. While the comment highlights a specific area for improvement, it does not provide detailed guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their derivation. The feedback is somewhat helpful as it points out a potential weakness, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide explicit guidance on what specific aspects of the method need to be elaborated upon or how the authors should present these details. The action is implicit and vague, as it does not specify which parts of the paper require additional details or how the authors should address these points. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its request for more details, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or reasoning to support why these details are important or how they would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that more details about the proposed method should be presented. It highlights the need for a clearer explanation of how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment lacks specificity in terms of which parts of the paper require additional details or how the authors should present these details. While it provides a general direction for improvement, it does not offer concrete suggestions or examples, making it somewhat helpful. The feedback is valuable but could be more impactful with additional guidance or specific examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method in detecting hallucinations in open-ended responses, providing a specific example to illustrate the issue. It suggests that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific improvements could be made to the method. The action is implicit and somewhat vague, as it leaves the authors to infer the need for further investigation or modification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, noting its potential struggle to detect hallucinations in open-ended responses. It provides a concrete example, such as the prompt \"introduce a sports celebrity to me,\" to illustrate the challenge. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The specificity of the comment is high as it clearly identifies the problem and provides an example, guiding the authors on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, providing an example of a prompt that could lead to this issue. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or examples, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method in detecting hallucinations in open-ended responses, using a specific example to illustrate the issue. It highlights that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. While the comment points out a specific area of concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the method. The feedback is somewhat helpful as it identifies a potential weakness, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical findings\" and suggests verifying the conclusion about \"label noise and model size on MNIST and CNN.\" This provides clear guidance on which parts of the paper need attention. However, the comment lacks specificity in detailing what aspects of the findings need verification or how the authors should approach this verification. It does not provide specific examples or detailed instructions on what needs to be verified, making it weakly specific. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models. It suggests verifying the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific examples or detailed reasoning to support the claim that the findings are unclear or need verification. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by questioning the clarity of how theoretical findings relate to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific guidance on how to conduct this verification or what aspects of the findings need to be clarified. While it points out an area for improvement, the suggestion is somewhat vague and does not provide detailed instructions or examples, making it somewhat helpful. The authors would need to infer the necessary steps to address the feedback, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved and recommends drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequent-error cluster\" and asks for justification regarding the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides explicit suggestions for improvement, such as drawing a table and justifying assumptions, it lacks concrete guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be done but without detailed steps or examples, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weaknesses/feedback\" and suggests improvements related to the writing quality and organization. It also specifies the need to draw a table comparing different CoT prompting methods across different dimensions, questioning the assumption about error clusters and the selection criteria in section 4.2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the writing quality and organization, suggesting that the paper could be improved. It provides specific feedback on the need to draw a table comparing different CoT prompting methods across different dimensions, questioning the assumption that \"questions of all the wrong demonstrations fall into the same frequent-error cluster,\" and asking for justification regarding the selection criteria in section 4.2. However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis for these suggestions, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies areas for improvement in the paper, specifically suggesting that the writing could be enhanced by drawing a table to compare different CoT prompting methods across various dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequent-error cluster\" and requests justification for the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides clear suggestions for improvement, it lacks detailed guidance on how to implement these suggestions, such as providing examples of how to draw the table or elaborate on the reasoning behind the selection criteria. This makes the feedback somewhat helpful, as it offers a direction for improvement but could be more comprehensive with additional details. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explicitly mention the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to ensure the applicability of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs section. However, the comment does not provide specific guidance on how the authors should address this point or what changes need to be made to the draft. The action is implicit and vague, leaving the authors uncertain about how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the issue arises, specifically in the context of Kalman Filtering and Smoothing and CVI. It provides specific guidance on the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to ensure the applicability of these techniques. This allows the authors to accurately identify the section that needs attention. The comment is also specific, as it clearly specifies what needs to be addressed in the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should explicitly mention the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to ensure the applicability of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs section. However, the comment lacks specific examples or detailed reasoning to support why this assumption is crucial for the applicability of these techniques. Without additional context or references, the claim is somewhat verifiable, as it provides a logical basis but lacks sufficient detail to fully substantiate the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the assumption of a Gaussian distribution for p(y | H_f(t_n)) is necessary for the applicability of Kalman Filtering and Smoothing and CVI. It also mentions that this assumption is already made in the ELBOs section. While the comment highlights an important aspect of the methodology, it does not provide detailed guidance on how the authors might address this issue or suggest alternative approaches. The feedback is somewhat helpful as it points out a potential area for clarification, but it lacks depth and actionable suggestions, making it only partially beneficial for the authors. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay, suggesting that the authors should expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are not reported. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should extend their plots or provide additional analysis to address the issue. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the application of weight decay, noting that the plots do not extend to large weight decay strengths where cosine similarities are not reported. However, it does not explicitly mention which part of the paper this issue is discussed in, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the section being addressed. The comment is specific in detailing the issue with the plots and the expected behavior of cosine similarities, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plots do not extend to large weight decay strengths where cosine similarities are not reported, which is a logical observation based on the described behavior of cosine similarities. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the basis for this claim, which could be improved by providing more detailed reasoning or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of weight decay, noting that the plots do not extend to large weight decay strengths where cosine similarities are not reported. This observation is logical and suggests that the authors should consider extending their plots or providing additional analysis to address this issue. However, the comment lacks specific guidance on how to extend the plots or what additional analysis might be necessary. While it provides a clear direction for improvement, the lack of detailed suggestions or examples makes it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This omission is serious, as it could lead to misinterpretations and incorrect conclusions. The comment suggests that this issue must be addressed for publication and implies that it would be straightforward to fix. However, the comment does not provide specific guidance on how to revise the sections to include this information, leaving the authors with a general idea of what needs to be done but lacking concrete steps. The action is explicit but somewhat vague, as it does not detail the exact changes required. Therefore, the comment is mostly actionable, aligning with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sections of the paper where the issue is raised: the title, abstract, introduction, and discussion. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue: the results are not explained for unsupervised random forests, which is a critical omission that could lead to misinterpretations. The authors are informed about the specific sections that need clarification and the nature of the problem. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The comment suggests that this issue must be addressed for publication and implies that it would be straightforward to fix. However, the comment lacks specific examples or detailed reasoning to support the claim that the omission is indeed serious or how it could lead to misinterpretations. While the authors might infer the importance of this omission, the lack of explicit evidence or detailed explanation makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Weakly Grounded and Specific, as it specifies the issue but does not provide detailed reasoning or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, noting that the title, abstract, introduction, and discussion fail to specify that the results are for unsupervised random forests. This omission is significant because it could lead to misinterpretations and incorrect conclusions, as casual readers might remember the wrong conclusions. The comment suggests that this issue must be addressed for publication, implying that it would be straightforward to fix. However, the comment lacks detailed guidance on how to revise the sections to include this information, leaving the authors with a general idea of what needs to be done but lacking specific steps. While the feedback is somewhat helpful, it could be more comprehensive if it provided more detailed suggestions or examples of how to address the issue. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to show that minimizing HSICcond-i could perform better than minimizing HSIC_HOOD, potentially using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, suggesting the inclusion of visualization results or schematic diagrams to aid understanding. The comment provides explicit actions for the authors to take, such as conducting additional experiments and providing comparative results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting the inclusion of illustrative experimental results. It also points out the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, recommending the inclusion of visualization results or schematic diagrams. However, the comment does not specify which part of the paper these experiments or results should be included in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issues with the lack of qualitative experiments and the need for comparative evaluations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to show that minimizing HSICcond-i could perform better than minimizing HSIC_HOOD, potentially using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, suggesting the inclusion of visualization results or schematic diagrams to aid understanding. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as including illustrative experimental results, using a toy dataset to demonstrate the separability of inlier and outlier features, and conducting comparative experiments with other metrics for the proposed test metric. The comment also suggests the inclusion of visualization results or schematic diagrams to aid understanding, which could enhance the clarity and comprehensiveness of the paper. By offering concrete and actionable feedback, the comment is mostly helpful, as it guides the authors on how to strengthen their work. However, it could be more helpful if it provided more detailed guidance or examples of how to conduct these experiments and visualizations.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the proposed method requires significantly more computation than other methods, given that the authors describe an online version of the algorithm due to the impracticality of training multiple iterations/epochs with large models and datasets. While the comment implies that the authors should compare the computational complexity of their method with others, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the authors describe an online version of the algorithm, allowing the authors to accurately identify the section being addressed. It is also specific because it requests a comparison of the computational complexity of the proposed method with other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, which is a relevant concern for the authors to address. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the proposed method requires significantly more computation. Without additional context or justification, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the computational complexity of the proposed method compared to other methods, which is a crucial aspect for evaluating the efficiency and practicality of the approach. By questioning whether the proposed method requires significantly more computation, the reviewer highlights a potential area for improvement or further analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as providing a detailed comparison of computational complexity or suggesting alternative approaches. While the feedback identifies an important concern, it could be more helpful if it included actionable steps or examples to guide the authors in addressing the issue. Therefore, the comment is somewhat helpful, as it points out a relevant area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a systematic study of the impact of the cost of incentivization on performance would be helpful. It provides specific examples, such as examining the reward incentives for different values of \\alpha and the collective return. The comment implies that the authors should conduct this analysis to address the concern about the emergence of roles between \"winners\" and \"cooperators.\" However, the comment does not explicitly instruct the authors to perform this analysis or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a systematic study of the impact of the cost of incentivization on performance, providing specific examples such as examining reward incentives for various values of \\alpha and the collective return. This feedback is fully grounded as it explicitly mentions the part of the paper that could benefit from additional analysis, allowing the authors to accurately identify the section being addressed. The comment is also specific, as it clearly specifies what needs to be addressed, including the potential impact of varying the cost of incentivization and the emergence of roles between \"winners\" and \"cooperators.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a systematic study of the impact of the cost of incentivization on performance would be helpful, providing specific examples such as examining reward incentives for various values of \\alpha and the collective return. The comment implies that this analysis could address the concern about the emergence of roles between \"winners\" and \"cooperators.\" However, the claim lacks specific examples or references to support the suggestion, making it somewhat verifiable. The authors would need to infer the basis for the claim, which could be improved with more detailed reasoning or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a helpful suggestion for improving the paper by proposing a systematic study of the impact of the cost of incentivization on performance. It offers specific examples, such as examining the reward incentives for various values of \\alpha and the collective return, which could address the concern about the emergence of roles between \"winners\" and \"cooperators.\" This feedback is clear and actionable, as it guides the authors on what additional analysis could enhance the paper's contribution. However, the comment could be more helpful if it included more detailed guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for greater depth and actionable guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of significance testing to support the claims made about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT-4, and suggests that the authors should conduct significance testing to substantiate their claims. However, the comment does not provide explicit guidance on how to perform the significance testing or what specific statistical methods should be used. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (line 486) and provides examples of claims made in the draft. It specifies what needs to be addressed by suggesting the inclusion of significance testing to support the claims about the differences between various methods. This provides clear guidance on how the authors can improve their draft, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should conduct significance testing to support their claims about the differences between various methods, such as ChatGPT and GPT-4. It provides specific examples and numerical data to illustrate the differences in scores. However, the comment lacks detailed reasoning or references to justify why significance testing is necessary or how it should be conducted. While the claim is somewhat verifiable due to the inclusion of examples, the absence of a clear explanation or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue in the paper by pointing out the lack of significance testing to support claims about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT-4, and highlights the minimal differences in scores, making it difficult to determine if the claims are significant without proper testing. The comment suggests that the authors should conduct significance testing, including checking the distribution and accounting for multiple comparisons, to substantiate their claims. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a clear path for addressing the issue. Therefore, the comment is highly helpful, as it offers detailed guidance on how to enhance the rigor and validity of the paper's claims.\", 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the approach description in Section 3 is difficult to follow and recommends using the additional page of the camera-ready version to extend this description rather than adding more experiments. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the clarity of the approach description. The comment is explicit and concrete, giving the authors a precise understanding of how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"approach description (\u00a7 3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the approach description by suggesting that the additional page of the camera-ready version should be used instead of adding more experiments. This provides a clear direction for the authors to enhance their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description in Section 3 is difficult to follow and suggests using the additional page of the camera-ready version to extend it. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the approach description is difficult to follow or how the suggested solution would address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the approach description in Section 3, noting that it is difficult to follow. It suggests that the additional page of the camera-ready version should be used to extend the approach description rather than adding more experiments. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to enhance the clarity of the description or suggested specific ways to restructure the content. Overall, the comment is mostly helpful as it directs the authors towards a concrete improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the experiments section: the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to include more detailed discussions and comparisons to strengthen the paper. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments part of the paper, specifically mentioning the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. It also highlights the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifold-based learning. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or table. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in detailing the issues with the experiments section, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments part lacks interpretive insights into why the proposed gyro-structures outperform existing methods and that the paper does not compare its methods with other state-of-the-art approaches that do not rely on gyro-structures. This claim is somewhat verifiable as it highlights specific areas where the paper could be improved, but it lacks detailed reasoning or references to support the assertion. The authors would need to provide more evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper's experiments section by pointing out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. It also highlights the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach truly outperforms simpler or more commonly used techniques in manifold-based learning. This feedback is valuable as it directs the authors to enhance the depth and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to include these comparisons or interpret the results. Overall, the comment is somewhat helpful, as it directs the authors to areas for improvement but lacks detailed guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. This comment is explicit in its request for additional evidence and analysis, providing a clear action for the authors to take. It specifies what kind of evidence or analysis is needed, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment is specific in its request for more evidence and analysis, but without grounding, it is difficult for the authors to know where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to enhance the depth and clarity of their analysis. However, the comment could be more helpful if it provided specific examples or guidance on what kind of evidence or analysis would be beneficial. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 5 is difficult to comprehend and suggests that the authors should provide more details about the two baselines presented in the figure. It also notes that the study is limited to English-centric datasets and suggests that the authors could extend CATER to other languages in the future. While the comment explicitly mentions the need for more details about the baselines and suggests a potential future direction, it does not provide specific guidance on how to enhance the comprehensibility of Figure 5 or how to extend CATER to other languages. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the comprehensibility of Figure 5 and the need for more details about the two baselines. Additionally, the comment suggests extending CATER to other languages, which is a specific and actionable suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 is difficult to comprehend and suggests providing more details about the two baselines presented in the figure. It also notes that the study is limited to English-centric datasets and suggests extending CATER to other languages. While the comment identifies a potential issue with the comprehensibility of Figure 5 and suggests a future direction for the study, it lacks specific examples or detailed reasoning to fully substantiate these claims. The suggestion to extend CATER to other languages is somewhat vague, as it does not provide concrete guidance on how to achieve this. Therefore, the claim is somewhat verifiable, as it provides some basis for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and lacks details about the two baselines presented. It also points out that the study is limited to English-centric datasets, which is a valid observation. The comment suggests extending CATER to other languages, which could be a valuable direction for future work. However, the feedback could be more helpful if it provided specific suggestions or guidance on how to improve the comprehensibility of Figure 5 or how to extend CATER to other languages. Overall, the comment is somewhat helpful as it highlights areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for improvement in the literature review, specifically mentioning that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. While the comment suggests that the paper should provide a more explicit and comparative analysis of related work, it does not provide specific guidance on what aspects of the literature review need to be improved or how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to expand the literature review to include a clearer comparison with existing work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for improvement in the literature review, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be addressed, namely, the clarity of the main contribution and the distinction from existing work, particularly in relation to GFlowNet for sequence generation. This provides clear guidance on how the authors should enhance their literature review. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review is unclear and needs improvement, specifically regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact areas that need improvement. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to guide the authors effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper, specifically the lack of clarity in the literature review. It highlights that the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation, are not adequately addressed. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples or guidance on how to improve the literature review. Despite this, the feedback is mostly helpful as it directs the authors towards a critical area for improvement, allowing them to enhance the clarity and depth of their work. Therefore, the comment is rated as 4: Mostly Helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.2 can be eliminated, implying that readers are likely to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not provide explicit guidance on how to eliminate the section or what specific content should be removed. The action is implicit and vague, as it leaves the authors to infer the exact steps needed to implement the suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that section 3.2 can be eliminated, implying that readers are likely familiar with the Gumbel-Softmax/Concrete distribution. However, it does not specify which part of the paper section 3.2 corresponds to, making it weakly grounded. The comment is specific in suggesting that the section can be removed, but without explicit references to the content of section 3.2, the authors may find it challenging to understand which part needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that section 3.2 can be eliminated because readers are likely familiar with the Gumbel-Softmax/Concrete distribution. However, the comment lacks specific reasoning or examples to support this claim. It does not provide detailed justification or references to similar sections or studies that might explain why this section is redundant. Without this additional context, the authors may find it difficult to understand the basis of the suggestion and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that section 3.2 can be eliminated because readers are likely familiar with the Gumbel-Softmax/Concrete distribution. This feedback is somewhat helpful as it points out a potential area for simplification in the paper. However, it lacks specific guidance on which parts of section 3.2 could be removed or what content might be redundant. The comment does not provide actionable advice or detailed suggestions, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that improvements are due to distillation rather than regularization effects. It suggests that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies to verify the claim. However, the comment does not provide explicit guidance on how the authors should conduct these ablation studies or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that improvements are due to distillation rather than regularization effects, suggesting that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not specify which part of the paper discusses the fine-tuning process or the GLUE dataset, making it weakly grounded. It is specific in detailing the issue with the fine-tuning process and the need for ablation studies, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements in the paper could be due to regularization effects rather than distillation, as the fine-tuning was performed for 10 epochs without early stopping. The reviewer suggests that the high variance in fine-tuning on GLUE without validation early stopping necessitates proper ablation studies to verify the claim. However, the comment lacks specific examples or references to support the claim about the potential impact of regularization effects. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that improvements are due to distillation rather than regularization effects. It points out that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies to verify the claim. This feedback is somewhat helpful as it highlights a specific area that requires further investigation and provides a suggestion for improvement. However, it could be more helpful if it included more detailed guidance on how to conduct the ablation studies or what specific aspects to focus on. Overall, the comment provides a clear direction for the authors to address a potential weakness in their analysis, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding performance evaluations on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. It also recommends including experiments on morphologically rich and low-resource languages. However, the comment does not provide explicit instructions or detailed guidance on how to implement these suggestions, such as which specific metrics to use or how to conduct the experiments. The actions are implicit and somewhat vague, as the authors need to infer how to apply the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding performance evaluations on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. It also recommends including experiments on morphologically rich and low-resource languages. However, the comment does not specify which parts of the paper these additions should be made, nor does it provide detailed guidance on how to conduct these experiments. The lack of specific references or sections makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests adding performance evaluations on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. It also recommends including experiments on morphologically rich and low-resource languages. However, the comment lacks specific details or references to support these suggestions, making it difficult for the authors to understand the rationale behind the recommendations. Without clear reasoning or examples, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient evidence to fully substantiate the suggestions.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the experiments section by adding performance evaluations on word similarity and sentence translation tasks, similar to those in the MUSE paper. This addition would enhance the credibility and robustness of the framework. Additionally, the comment suggests including experiments on morphologically rich and low-resource languages, which would broaden the scope and applicability of the research. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific metrics or experimental designs. While it offers valuable insights, the feedback could be more helpful if it included more detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how node importance is used in a 1-shot scenario and notes that the experimental part does not include a 1-shot setting, despite related works like RALE having it. While the comment identifies a potential gap in the paper's discussion and experimental setup, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the use of node importance in a 1-shot setting and include an experiment for this setting. This lack of explicit action makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how node importance is used in a 1-shot scenario, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this question pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant section. The comment is specific in that it identifies a gap in the experimental part, noting the absence of a 1-shot setting despite its inclusion in related works like RALE. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of node importance in a 1-shot scenario and the absence of a 1-shot setting in the experiments, despite its inclusion in related works like RALE. While the comment identifies a potential gap in the paper's discussion and experimental setup, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors are left to infer the basis for these observations, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the use of node importance in a 1-shot scenario and points out that the experimental part does not include a 1-shot setting, despite related works like RALE having it. This feedback highlights a potential gap in the paper's discussion and experimental setup, suggesting that the authors should clarify how node importance is used in a 1-shot setting and include an experiment for this setting. However, the comment lacks specific guidance on how to address this issue or what changes might be necessary. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more details about the formula in the text, specifically mentioning $\\ell_{BCE}$. While the comment implies that additional details are needed, it does not specify what kind of details should be included or how they should be presented. The action is explicit but somewhat vague, as it lacks concrete guidance on what additional information is required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing more details about the formula in the text, specifically mentioning $\\ell_{BCE}$. However, it does not specify which part of the paper this formula is discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for more details but lacks grounding as it does not pinpoint the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more details about the formula in the text, specifically mentioning $\\ell_{BCE}$. However, it does not offer any specific reasoning, examples, or references to support why this is necessary or beneficial. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more details about the formula in the text, specifically mentioning $\\ell_{BCE}$. While the comment identifies a potential area for improvement, it lacks specificity and does not offer detailed guidance on what additional information would be beneficial. The suggestion is somewhat vague and could be more helpful if it provided examples or specific types of details that should be included. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these issues. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on what aspects of the discussion should be included or how to address the problems. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of LLM limitations and solutions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to address the issue of LLM limitations, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. Without additional context or references, the claim remains somewhat verifiable, as it is based on a general observation without detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these issues. This feedback is somewhat helpful as it highlights a specific area where the authors could enhance their work by providing a more comprehensive discussion. However, the comment lacks depth and does not offer specific guidance on what aspects of the discussion should be included or how to address the problems. To be more helpful, the comment could provide examples or suggestions for addressing the issue, making it more actionable for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for self-supervised learning on 360 video data with spatial audio, the paper does not provide sufficient insights into why this specific type of data is important for self-supervised learning. The comment implies that the authors should elaborate on the significance of this data type in the context of self-supervised learning. However, it does not explicitly instruct the authors to add more details or examples to support this claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights into the importance of the data type. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of insights into why self-supervised learning is needed for 360 video data with spatial audio. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for more insights but lacks detail on what those insights should include or how they should be presented. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not provide sufficient insights into why self-supervised learning is needed for 360 video data with spatial audio. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the paper does not offer sufficient insights. As a result, the claim is not well-supported, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that while the experimental results suggest the value of the proposed approach for self-supervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for self-supervised learning. This feedback highlights a need for the authors to elaborate on the significance and relevance of this data type in the context of their study. However, the comment does not provide specific suggestions or guidance on how to address this gap, leaving the authors with a clear understanding of the issue but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a meaningful area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides two specific actions for the authors to take: first, to explain the link between IP and the terms/equations more explicitly and prominently, and second, to include labels for subfigures in Figures 3 and 4 instead of just stating it in the captions. These actions are explicit and concrete, as they clearly instruct the authors on what needs to be done. The comment is fully actionable, as it provides precise guidance on how to improve the draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Figures 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: explaining the link between IP and the terms/equations more explicitly and prominently, and including labels for subfigures in Figures 3 and 4. This level of detail helps the authors understand exactly what changes are required. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: first, it suggests that the link between IP and the terms/equations could be explained more explicitly and prominently, and second, it recommends including labels for subfigures in Figures 3 and 4. While the first part is somewhat verifiable as it implies the need for clearer explanation, the second part is fully verifiable as it provides specific guidance on how to improve the presentation of figures. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the link between IP and terms/equations. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two key areas that need improvement in the paper. It suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a valuable piece of advice for enhancing the clarity and understanding of the paper. Additionally, the comment recommends including labels for subfigures in Figures 3 and 4, which would improve the visual presentation and make the figures more accessible. These suggestions are clear and actionable, providing the authors with concrete steps to take to enhance their draft. Therefore, the comment is highly helpful, as it offers specific guidance on improving the clarity and presentation of the paper.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This provides a clear and explicit action for the authors to take, as they need to average their results over multiple runs to ensure the statistical significance of their findings. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the statistical validity of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion, the absence of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and common practice in scientific research to ensure the reliability and validity of results. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for averaging results based on common knowledge in the field. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that directly addresses a potential weakness in the paper, namely the lack of statistical rigor in the results. By averaging results over multiple runs, the authors can strengthen the reliability and validity of their findings, making the paper more robust and credible. This feedback is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the analysis of the SimCLR approach, specifically mentioning the absence of analysis on the projection head, which is considered important based on recent studies like SimCLR-v2. However, the comment does not provide explicit guidance on how the authors should address this gap or what specific aspects of the projection head analysis should be included. While the authors can infer that they need to expand their analysis to include the projection head, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the absence of analysis on a seemingly important aspect of the SimCLR approach, namely the projection head, which is a key element that should be included for a comprehensive analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only the SimCLR case is covered and that there is no analysis on a seemingly important part of that approach, specifically the projection head. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to the paper's content. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the analysis of the SimCLR approach, noting that only the SimCLR case is covered and that there is no analysis on a seemingly important aspect, such as the projection head. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this gap, such as suggesting additional experiments or analyses that could be included. Without specific recommendations, the authors may find it challenging to fully understand how to improve their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the trade-offs between annotation effort and training performance. While the comment implies that the authors should highlight these observations, it does not provide explicit instructions on how to do so. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section, implying that the authors should highlight them. However, it does not specify which part of the experimental section contains these observations or conclusions, making it weakly grounded. The comment is specific in recommending highlighting these observations to improve understanding of trade-offs, but the lack of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the trade-offs between annotation effort and training performance. However, the comment does not provide any specific examples, reasoning, or references to support why highlighting these observations would be beneficial. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how it should be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations would enhance the reader's understanding of the trade-offs between annotation effort and training performance. While the comment provides a clear direction for improvement, it lacks specific guidance on how to highlight the observations or what aspects to emphasize. This makes the feedback somewhat helpful, as it offers a general idea but could be more detailed to fully assist the authors in enhancing their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide ablation experiments to validate the model performance further, as several modifications mentioned in Section 3.4 were used. This comment is explicit in its suggestion to conduct ablation experiments, which directly informs the authors of the necessary action. The action is also concrete, as it specifies the type of experiments to be conducted. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide ablation experiments to validate the model performance further, as several modifications mentioned in Section 3.4 were used. However, the comment does not specify which part of the paper the ablation experiments should be conducted on, making it weakly grounded. It is specific in suggesting the need for ablation experiments to validate model performance, but the lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide ablation experiments to validate the model performance further, as several modifications mentioned in Section 3.4 were used. However, the comment lacks specific details or references to support why these ablation experiments are necessary or how they would validate the model performance. Without additional context or justification, the claim remains somewhat verifiable, as it provides a suggestion but lacks the necessary evidence or reasoning to fully substantiate the need for ablation experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should provide ablation experiments to validate the model performance further, as several modifications mentioned in Section 3.4 were used. This feedback is clear and actionable, as it directly points out a specific area where the authors can improve their draft by conducting additional experiments. By providing ablation experiments, the authors can better understand the impact of the modifications and validate their effectiveness. This feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive if it suggested specific types of ablation experiments or how to interpret the results. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance comparison of the KDE method when the decision space is beyond binary, referencing Remark 1 and the work of Zhang et al. [44]. It suggests that the authors might consider showing this comparison. However, the comment does not provide explicit instructions or detailed guidance on how to implement this suggestion, such as which datasets to use or how to present the comparison. The action is implicit and somewhat vague, leaving the authors with a general idea but lacking concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment references \"Remark 1\" and \"Zhang et. al. [44]\", which provides some grounding by indicating specific parts of the paper that are relevant. However, it does not explicitly mention which section or part of the paper contains Remark 1 or the work by Zhang et al. [44]. This makes it somewhat difficult for the authors to pinpoint the exact location of the referenced content. Additionally, the comment is specific in questioning the possibility of a performance comparison, but it does not provide detailed guidance on how to conduct this comparison or what datasets to use. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance comparison of the KDE method when the decision space is beyond binary, referencing Remark 1 and the work of Zhang et al. [44]. While the comment suggests that the authors might consider showing this comparison, it does not provide any specific reasoning or evidence to support why this comparison is important or how it would impact the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the performance comparison of the KDE method when the decision space is beyond binary, referencing Remark 1 and the work of Zhang et al. [44]. It suggests that the authors might consider showing this comparison, which could provide valuable insights into the method's performance in more complex scenarios. However, the comment lacks specific guidance on how to conduct this comparison or what datasets to use, leaving the authors with a general idea but no concrete steps to follow. While the feedback is somewhat helpful in identifying an area for further exploration, it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While the first question prompts the authors to explore the relationship between model capacity and FID, it does not provide explicit guidance on how to address this. The second part acknowledges the presence of unexpected artifacts but does not offer specific suggestions or actions for the authors to take. The comment lacks explicit and concrete actions or suggestions for the authors to address these issues, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific about the issues, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" These questions are open-ended and do not contain any subjective opinions, judgments, or suggestions. They are factual inquiries that require the authors to provide their own analysis or findings. Therefore, the comment is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions about the impact of the SR model's capacity on the FID and the unexpected artifacts introduced by the pipelining method. While these questions highlight potential areas for further investigation and clarification, they do not provide specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it identifies areas that require attention, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether the proposition is merely an illustration of the partitioning principle of K-means and notes the absence of a \"proof.\" However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting what content should be added to Appendix A or how to clarify the purpose of Proposition B.1. The feedback is vague and lacks concrete steps for improvement, making it difficult for the authors to know what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the content of Appendix A, noting that it is left blank, and questions the purpose of Proposition B.1 in Appendix B, suggesting it may be merely an illustration of the partitioning principle of K-means. It also points out the absence of a \"proof.\" However, the comment does not specify which part of the paper Appendix A or Appendix B corresponds to, making it difficult for the authors to identify the exact sections being referred to. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether the proposition is merely an illustration of the partitioning principle of K-means and notes the absence of a \"proof.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two key issues with the paper: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether the proposition is merely an illustration of the partitioning principle of K-means and notes the absence of a 'proof.' However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as what content could be added to Appendix A or how to clarify the purpose of Proposition B.1. While the feedback highlights important areas for improvement, it lacks actionable advice, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3, indicating that it provides some insights but requires more detailed guidance to be fully helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. While it suggests that these experiments are needed, it does not provide explicit guidance on how to conduct them or what specific aspects of the paper should be compared or analyzed. The action is implicit and somewhat vague, as the authors need to infer that they should perform these experiments to address the lack of additional experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments are missing from or where they should be conducted. This makes it difficult for the authors to identify the exact areas that need improvement. The comment is fully grounded in terms of identifying the need for additional experiments but is not specific in detailing what is missing. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand why these experiments are necessary or how they would enhance the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is valuable as it highlights specific areas where the paper could be strengthened to provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it suggested specific ways to conduct these experiments or provided examples of how they could be implemented. Overall, the comment is somewhat helpful as it directs the authors to important areas for improvement, but it lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107-110 to reassure readers that it is not a real concern. The comment implies that the authors should provide more details or evidence to address this concern, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the vulnerability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of approximations introduced in the paper, specifically mentioning \"several approximations (i -iii)\" and the vulnerability due to the assumption of attacks being in the feasible set only in lines 107-110. However, it does not specify which part of the paper these approximations are discussed or how they are presented. The authors can infer that the comment pertains to the sections where these approximations are introduced, but the lack of explicit mention makes it weakly grounded. The comment is specific in identifying the need to expand on the vulnerability, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that requires attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors introduce several approximations, which leaves loose ends. It suggests that the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107-110 needs to be expanded to reassure readers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or logical reasoning to substantiate the assertion that the approximations leave loose ends or that the vulnerability is a real concern. Without additional evidence or explanation, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by pointing out that the authors introduce several approximations, which could leave readers with questions about the robustness of the results. It suggests that the authors should expand on the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107-110 to reassure readers that it is not a real concern. This feedback is somewhat helpful as it highlights a specific area that needs clarification or expansion, but it lacks depth and does not provide detailed guidance on how to address the issue. The authors would benefit from additional context or examples to fully understand and address the concern. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any specific suggestions or actions for the authors to take to address this concern. The comment lacks explicit guidance on how the authors might improve the contribution or the model, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the limited contribution and incremental nature of the proposed model, but it does not specify which part of the paper this opinion pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is weakly grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. While it identifies a potential weakness in the paper, it does not provide specific suggestions or actionable feedback on how the authors might address this issue. The comment lacks depth and does not offer guidance on improving the contribution or the model. As a result, it is barely helpful, as it does not provide the authors with a clear path forward for enhancing their work.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores. However, it points out that more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment implies that the authors should provide more details about the evaluation procedures to address this concern. While the action is clear and explicit, it lacks concrete guidance on how to conduct this additional analysis or what specific aspects of the evaluation procedures need to be detailed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but it highlights the need for more careful analysis, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the evaluation procedures or the \"old\" benchmarks, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the need for more detailed analysis, it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but suggests that more careful analysis is needed, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment also recommends providing more details about the evaluation procedures. However, the claim lacks specific examples or references to support the need for more careful analysis, making it somewhat verifiable. The authors would need to infer the reasoning behind the claim, which could be improved with additional details or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the impressive performance of the proposed model on several benchmarks, setting new SoTA scores. However, it suggests that a more careful analysis is needed, particularly for 'old' benchmarks where the data might have been indirectly seen by the model through 'data curation' processes. The comment also recommends providing more details about the evaluation procedures. This feedback is somewhat helpful as it identifies an area for improvement and suggests a specific aspect that requires further attention. However, it could be more helpful if it provided more detailed guidance on how to conduct this additional analysis or what specific aspects of the evaluation procedures need to be detailed. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the experimental setup, noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. While the comment identifies a potential issue with the experimental design, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the evaluation methods. The action is implicit, as the authors need to infer that they should consider the differences between the two sets of benchmarks and potentially adjust their experimental design accordingly. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental part of the paper, specifically mentioning Figure 4 and Figure 5, which contain different evaluation methods for OPE methods. However, it does not specify which sections of the paper these figures are located in, making it weakly grounded. The comment is specific in that it highlights a discrepancy in the experimental setup, suggesting that the differences between the two sets of benchmarks are significant. This provides clear guidance on what needs to be addressed, but the lack of explicit section references makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the differences between two sets of evaluation methods used in the experimental part of the paper, specifically mentioning Figure 4 and Figure 5. While the comment highlights a potential issue with the experimental design, it does not provide any specific evidence, reasoning, or references to support the claim that the differences between the two sets of benchmarks are significant. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue in the experimental part of the paper, specifically noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. This observation raises a question about the consistency and comparability of the results presented in Figure 4 and Figure 5. While the comment points out a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this discrepancy. The feedback is somewhat helpful as it highlights a potential issue that needs attention, but it lacks depth and actionable advice, leaving the authors with limited insight into how to improve their experimental design or analysis. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the fairness of the comparison between the proposed method and the state-of-the-art (SOTA). It points out that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental results and highlights a concern regarding the fairness of the comparison between the proposed method and the state-of-the-art (SOTA). It points out that without prior information, the proposed method does not show an advantage compared to the SOTA, similar to the benchmarks. However, the advantage is only evident when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. While the comment is specific about the issue of fairness and the need to consider the extra complexity of the proposed method, it does not explicitly mention which part of the paper this issue is discussed in. This makes it weakly grounded but specific, as the authors can infer the relevant section but lack full grounding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors may need to infer the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the fairness of the comparison between the proposed method and the state-of-the-art (SOTA). It highlights that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer points out that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. This feedback is valuable as it challenges the authors to consider the fairness of their comparison and the practical implications of their method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these concerns, such as by including prior information or simplifying the model. Overall, the comment is somewhat helpful, as it raises important questions about the evaluation process and the practicality of the proposed method.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments lack collaborative games and recommends exploring the behavior of evaluated methods in both collaborative and competitive settings. While the comment implies that the authors should consider adding collaborative games to their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add collaborative games to their experiments. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments lack collaborative games and recommends exploring the behavior of evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper discusses the experiments or where the suggestion should be addressed. The authors cannot confidently determine which section or part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to include collaborative games, but without clear grounding, the authors may struggle to apply it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments lack collaborative games and recommends exploring the behavior of evaluated methods in both collaborative and competitive settings. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiments by suggesting the inclusion of collaborative games. This feedback is valuable as it points out a specific aspect that could enhance the comprehensiveness and depth of the evaluation. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate collaborative games or what specific experiments should be conducted. While it offers a direction for improvement, the feedback could be more helpful if it included suggestions or examples of how to implement this suggestion. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, making it difficult for the authors to be convinced of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the missing experimental settings or what specific information should be included. Without concrete suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures 1 to 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue as the missing experimental settings for these figures, which are crucial for the results to be convincing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes the results difficult to be convincing. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the experimental settings are missing and how this impacts the results. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, which makes it difficult for the authors to be convinced of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their experimental settings. Without actionable feedback or specific suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it highlights a critical gap but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the rationale behind the work, suggesting that some parameter isolation methods are specifically tailored to leverage sparsity. However, it does not provide explicit guidance on how the proposed method avoids impeding the learning of new task knowledge. The comment implies that the authors should clarify this aspect, but it lacks concrete instructions on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically mentioning the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this observation is made or where the authors discuss the proposed method in detail. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in detailing the issue with current methods and the proposed solution, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some parameter isolation methods are specifically tailored to leverage sparsity, which contradicts the authors' suggestion that their method avoids impeding the learning of new task knowledge. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the rationale behind the work, specifically questioning how the proposed method avoids impeding the acquisition of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity, which contradicts the authors' claim. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or clarify their rationale. While it points out a potential weakness, it does not provide actionable steps or insights to improve the draft, making it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the regularization term, suggesting that it is ad-hoc and lacks theoretical support. It also proposes that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate these suggestions. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization term, suggesting it is ad-hoc and lacks theoretical support. It also proposes alternative statistics, such as the median, to replace the mean and standard deviation. However, the comment does not specify which part of the paper discusses the regularization term or where the authors can find more information about it. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of the regularization term, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the regularization term is ad-hoc and lacks theoretical support, suggesting that other statistics could be used instead of the mean and standard deviation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it offers a suggestion but lacks the necessary depth and support for the authors to fully understand and address the issue.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the regularization term, suggesting that it is ad-hoc and lacks theoretical support. It also proposes alternative statistics, such as the median, that could be used instead of the mean and standard deviation. However, the comment does not provide specific guidance on how the authors should address this issue or what steps they should take to incorporate these suggestions. While it offers a suggestion for improvement, the lack of detailed guidance or examples makes it somewhat helpful, as it gives the authors a direction but not a complete roadmap for enhancing their work. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear action for the authors to take, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This action is explicit and concrete, as it specifies exactly what needs to be done to enhance the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section, which is a specific part of the paper. It provides a clear action for the authors to take, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This action is fully grounded as it explicitly mentions the part of the paper where the comparison should be made, and it is specific in detailing what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not conducted comparisons with existing fairness algorithms in the experimental section, suggesting that integrating such comparisons would enhance the paper. However, the comment lacks specific examples or references to existing fairness algorithms, making it difficult for the authors to understand which algorithms to compare against or how to implement the suggested enhancement. Without detailed guidance or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth for the authors to effectively address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section by pointing out the absence of comparisons with existing fairness algorithms. It suggests that integrating benchmark comparisons against state-of-the-art fairness algorithms would enhance the paper by providing tangible evidence of the proposed method's performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is clear, actionable, and constructive, offering a specific direction for improvement. However, it could be more helpful if it provided more detailed guidance on which specific algorithms to compare against or how to conduct these comparisons effectively. Overall, the comment is mostly helpful, as it effectively highlights an important area for improvement and provides a clear path for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. This provides a clear and explicit action for the authors to take, as they need to address the computational budget and iteration cost of their method in relation to other methods. The comment is specific and concrete, giving the authors a clear direction on what needs to be included in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss iteration cost and compare it with related methods, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, the comment lacks specific details or references to support why this discussion is important or how it would benefit the paper. Without additional context or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks sufficient justification or examples to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to improve their draft by discussing the iteration cost of their proposed method and comparing it with related methods, including baseline methods. This feedback is specific and directly addresses a potential area for improvement, offering a clear direction for the authors to enhance the completeness and depth of their work. By highlighting the importance of computational budget and iteration cost, the comment empowers the authors to make a significant contribution to their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides several specific suggestions for improvement in the experimental section. It suggests that the authors should report average results over multiple runs to make the results more robust and easier to compare. It also asks for a discussion on why the decision boundaries look as they do in Section 3.1 and what information is present in Figure 9. These suggestions are explicit and provide clear guidance on what needs to be done, making the comment highly actionable. The feedback is detailed and actionable, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improvement in the experimental section, including the need to report average results over multiple runs, a discussion on decision boundaries, and clarification on the information presented in Figure 9. However, it does not explicitly mention which sections or parts of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as reporting averages and discussing decision boundaries. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of three parts, each providing specific suggestions for improvement in the experimental section. The first part suggests reporting average results over multiple runs, which is a standard practice in experimental evaluations. The second part recommends discussing the decision boundaries in Section 3.1, which would provide valuable insights into the model's behavior. The third part asks for clarification on the information presented in Figure 9, which is a request for additional detail. While the suggestions are logical and common, they lack specific examples or references, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific suggestions for improvement in the experimental section, such as reporting average results over multiple runs to enhance the robustness and comparability of the results. It also suggests discussing the decision boundaries in Section 3.1, which could offer valuable insights into the model's behavior. Additionally, the comment requests clarification on the information presented in Figure 9, which is a request for additional detail. These suggestions are clear and actionable, providing the authors with concrete guidance on how to improve their draft. However, the comment could be more helpful if it included more detailed explanations or examples of how to implement these suggestions. Overall, the feedback is mostly helpful, as it offers actionable insights but could be expanded for better guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might overcome this issue or suggest alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the model's applicability, but without clear references to the paper, the authors may find it challenging to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality. While this observation is accurate, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or improve the model's applicability. Without specific advice or suggestions, the authors may find it challenging to incorporate this feedback into their draft. Therefore, the comment is barely helpful, as it points out a weakness but does not provide substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the supervised pretraining approach based on the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to mitigate it. While the authors can infer that they should consider alternative pretraining methods or provide a more detailed explanation of their approach, the action is implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to supervised pretraining based on the homo-lumo gap, which is a particular aspect of the paper. It mentions the potential for negative transfer and provides an example of this issue with Transformer-M on the QM9 dataset. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue and providing an example, which helps the authors understand what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the homo-lumo gap may lead to negative transfer, as evidenced by the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This claim is somewhat verifiable as it provides a specific example of a potential issue, but it lacks detailed reasoning or references to support the claim fully. The authors could benefit from a more thorough explanation or additional evidence to strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the supervised pretraining approach based on the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This feedback is somewhat helpful as it highlights a specific area that needs attention and provides a clear example of a potential problem. However, the comment could be more helpful if it offered suggestions or guidance on how to address this issue or improve the model's performance. Overall, the comment provides a valuable insight but lacks depth and actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 80-82 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 80-82. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to clarify their reasoning. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and then determine how to address it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 80-82, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the use of the center correlation in Figure 4 A&B despite its stated lack of insight for discriminating model defenses. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the authors' reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 80-82 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 80-82. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the center correlation is useful in this context. This lack of detailed explanation or justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning and provide their own justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid question about the use of the center correlation in Figure 4 A&B, despite the authors' claim that it was not insightful for discriminating model defenses. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to reconsider their reasoning and provide a more detailed explanation of why they chose to use this metric. By identifying this inconsistency, the comment encourages the authors to clarify their methodology and improve the logical flow of their arguments. However, the comment could be more helpful if it provided specific guidance on how to address the issue or what additional evidence might be needed to support the use of the center correlation. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks detailed suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors would need to infer that they should reconsider the name or provide a more nuanced description of the phenomenon. The comment is somewhat actionable because it points out a specific issue but lacks concrete details on how to implement the suggested changes. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not specify which part of the paper discusses this phenomenon, making it weakly grounded. It is specific in detailing what the issue is and why the name might be problematic, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the name \"distributional generalization\" used to describe a phenomenon, suggesting that it might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. The comment provides a logical explanation for why the name might be too strong, but it lacks specific examples or references to support the claim. Without detailed examples or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. This feedback is somewhat helpful as it points out a specific area for improvement and provides a clear rationale for why the current name might be misleading. However, the comment could be more helpful if it offered suggestions for alternative names or ways to clarify the phenomenon's description. Overall, the comment provides a valuable insight that could guide the authors in refining their terminology and enhancing the clarity of their work. Therefore, it is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical contribution as \"ok\" but expresses concern about its strength, noting that it is \"weak, unpractical bound\" and that the proof lacks \"mathematical novelty.\" However, the comment does not provide explicit or implicit suggestions on how the authors might address these issues or improve the theoretical contribution. It lacks concrete guidance on what specific aspects of the theory need to be strengthened or how the authors can enhance the mathematical novelty of their work. Without actionable steps or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical contribution,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors find lacking, namely, the strength of the theoretical contribution, the unpracticality of the bound, and the lack of mathematical novelty in the proof. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok\" but not \"particularly strong,\" given existing results. It further criticizes the bound as \"weak, unpractical,\" and notes that the proof lacks \"mathematical novelty.\" However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism or how to address it. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the theoretical contribution, noting that it is \"ok\" but not particularly strong. It highlights the weakness of the bound as \"weak, unpractical,\" and points out the lack of \"mathematical novelty\" in the proof. While the comment provides some insight into the limitations of the theoretical contribution, it lacks actionable guidance or suggestions on how the authors might address these issues or strengthen their work. The feedback is somewhat helpful as it directs the authors' attention to areas that need improvement, but it does not offer detailed steps or strategies for enhancing the theoretical contribution. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the experimental evaluation, particularly regarding the ablation study and the comparison on the CIFAR dataset. It highlights that the paper claims a distinction in the \"picking\" step but does not ablate it, which is a clear and explicit action for the authors to address. Additionally, it points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. The comment is detailed and provides concrete guidance on how the authors can improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the ablation study, the comparison on CIFAR, and the concerns about the use of the DEN approach. The feedback is clear and provides specific guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study for the \"picking\" step, which is a specific aspect of the experimental evaluation. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of how the ablation study could be conducted or why it is necessary. Without specific justification or references, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific feedback on the experimental evaluation section, particularly regarding the ablation study and the comparison on the CIFAR dataset. It highlights that the paper claims a distinction in the \"picking\" step but does not include an ablation study to support this claim, which is a significant oversight. Additionally, the comment points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared and the lack of clarity in the use of the DEN approach. This feedback is detailed and actionable, providing clear guidance on how the authors can improve the rigor and clarity of their experimental evaluation. Therefore, the comment is highly helpful, as it offers constructive suggestions for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not provide explicit guidance on how the authors should implement this change or any other suggestions for improvement. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not specify which part of the paper this critique refers to, such as a particular figure or table. The comment is vague in its reference, making it difficult for the authors to identify the exact section being addressed. While it provides a specific suggestion for improvement, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. This feedback is specific and actionable, as it provides a clear suggestion for improving the clarity of the plot. However, it does not offer broader guidance or address other potential issues in the paper. While the comment is helpful in highlighting a specific aspect that could enhance the readability of the plot, it could be more comprehensive if it included additional suggestions or feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the phrase, but it lacks concrete details on what specific changes or additions are needed. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should clarify, namely the meaning of the phrase \"is sufficient\" in the context of the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide any specific examples, reasoning, or references to support the claim. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the comment and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the phrase \"is sufficient\" at lines 240 and 428. It suggests that the authors should clarify the meaning of this phrase in the context of the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. This feedback is clear and actionable, as it directs the authors to a specific area where clarification is needed. However, the comment could be more helpful if it provided additional context or examples to guide the authors in understanding the intended meaning of the phrase. Overall, the comment is mostly helpful as it highlights a crucial point that needs clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior task-optimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for non-linear RNN models that exhibit emergent behavior. The reviewer questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. However, the comment does not offer explicit guidance on how the authors might address these questions or improve their draft. The action is implicit, as the authors need to infer that they should clarify the scientific insight and provide more detailed explanations. While the action is somewhat vague, it is clear that the authors need to address the questions raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scientific insight gained from the model and formalism compared to prior task-optimized approaches, specifically asking for clarification on whether the model serves as a prototype approximation for non-linear RNN models with emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior task-optimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for non-linear RNN models that exhibit emergent behavior. The reviewer questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the model does not serve as a prototype approximation. This lack of evidence makes the claim somewhat verifiable, as the authors would need to provide additional justification or evidence to address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the scientific insight gained from the proposed model and formalism compared to prior task-optimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for non-linear RNN models that exhibit emergent behavior. The reviewer questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. This feedback is valuable as it prompts the authors to clarify the scientific contribution and provide a more detailed explanation of the model\\'s significance. However, the comment could be more helpful if it offered suggestions on how to address these questions or provide additional context. Overall, the comment is somewhat helpful, as it identifies a key area for improvement but lacks depth in its guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consistency of the output of the PPG model, specifically regarding the definition of O_{up} and the construction of ground truth labels. It questions whether O_{up} is trained to output offsets for all keypoints or only those within a certain distance from the center of the corresponding part. The comment also asks how the network parts responsible for each part predict all the keypoints of the pose. While the comment identifies a potential issue with the model's output and the training process, it does not provide explicit guidance on how to address these concerns or suggest specific actions to take. The action is implicit and somewhat vague, as the authors would need to infer the need to clarify the definition of O_{up} and the ground truth construction process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the PPG model\\'s output and the training process, particularly concerning the definition of O_{up} and the construction of ground truth labels. It mentions the discrepancy between the model\\'s output and the training data, questioning whether O_{up} is trained to output offsets for all keypoints or only those within a certain distance. The comment also asks how the network parts responsible for each part predict all the keypoints of the pose. However, the comment does not explicitly mention a specific section, table, or figure in the paper, making it weakly grounded. It is specific in detailing the issue with the model\\'s output and the training process, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the consistency of the PPG model\\'s output and the training process, specifically regarding the definition of O_{up} and the construction of ground truth labels. It questions whether O_{up} is trained to output offsets for all keypoints or only those within a certain distance from the center of the corresponding part. The comment also asks how the network parts responsible for each part predict all the keypoints of the pose. However, the comment does not provide any evidence, reasoning, or references to support the claim that the model is not consistently outputting all keypoints or that the network parts are not capable of predicting all keypoints. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the consistency of the PPG model\\'s output and the training process, particularly concerning the definition of O_{up} and the construction of ground truth labels. It highlights a potential discrepancy between the model\\'s output and the training data, questioning whether O_{up} is trained to output offsets for all keypoints or only those within a certain distance from the center of the corresponding part. The comment also asks how the network parts responsible for each part predict all the keypoints of the pose, which is a crucial question for understanding the model\\'s capabilities. While the comment identifies a potential issue with the model\\'s output, it does not provide detailed guidance or suggestions on how to address this concern. The feedback is somewhat helpful as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the small size and readability of the figures, the lack of clarity in the derivation of equation 5 from equation 4, the unclear introduction of \\\\(\\\\theta^{t+1/2}\\\\), the insufficient definition of \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\), and a cyclic definition of \\\\(S^{\\\\sim}\\\\) in Assumption 1. While the comment identifies multiple areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer the necessary actions, such as improving figure readability, clarifying the derivation, explaining the introduction of \\\\(\\\\theta^{t+1/2}\\\\), and providing proper definitions for \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\). The lack of explicit instructions makes the comment somewhat actionable, as it provides a clear indication of what needs to be addressed but lacks detailed guidance on how to implement these changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the readability of the figures, the clarity of the derivation of equation 5 from equation 4, the introduction of \\\\(\\\\theta^{t+1/2}\\\\), the definition of \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\), and a cyclic definition of \\\\(S^{\\\\sim}\\\\) in Assumption 1. However, the comment does not specify which parts of the paper these issues are related to, such as specific sections or figures. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in detailing the issues, the absence of explicit references to the paper's sections or figures makes it weakly grounded. Therefore, the comment is rated as 3: Weakly Grounded and Specific.', 'verifiability_rationale': 'The review point raises several concerns about the paper, including the readability of the figures, the clarity of the derivation of equation 5 from equation 4, the introduction of \\\\(\\\\theta^{t+1/2}\\\\), the definition of \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\), and a cyclic definition of \\\\(S^{\\\\sim}\\\\) in Assumption 1. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address these issues effectively. Therefore, the comment is rated as 1: Unverifiable.', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, including the readability of the figures, the clarity of the derivation of equation 5 from equation 4, the introduction of \\\\(\\\\theta^{t+1/2}\\\\), the definition of \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\), and a cyclic definition of \\\\(S^{\\\\sim}\\\\) in Assumption 1. While the comment provides specific examples of issues, it lacks detailed guidance on how to address these problems. The authors are left to infer the necessary changes, which limits the comment's helpfulness. The feedback is somewhat helpful as it points out areas for improvement, but it could be more comprehensive with explicit suggestions or detailed explanations. Therefore, the comment is rated as 3: Somewhat Helpful.'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are explicit and concrete, as they clearly indicate what changes need to be made to the paper. The authors can directly apply these actions to improve the visual presentation of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are fully grounded as they explicitly mention specific parts of the paper, such as legends, axis labels, captions, and figures. The comment is also specific as it details what needs to be addressed in these parts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are based on common sense and are easily verifiable by the authors. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. While the suggestions are logical and actionable, the lack of specific examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are clear and actionable, as they directly indicate what changes the authors should make to enhance the visual presentation of their work. However, the comment could be more helpful if it included additional guidance on why these changes are necessary or how they would improve the overall clarity of the paper. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments, specifically mentioning Figure 2 of [1] which demonstrates a larger effect of removing high-scoring images. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a comparison against Journey TRAK, particularly referencing Figure 2 of [1], which highlights a significant effect of removing high-scoring images. This provides clear guidance on what needs to be addressed in the counterfactual experiments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a comparison against Journey TRAK in the counterfactual experiments, referencing Figure 2 of [1] which shows a larger effect of removing high-scoring images. However, the comment lacks specific details on how this comparison should be implemented or what aspects of the comparison are crucial. It does not provide a clear rationale or examples to support the claim, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some basis for action but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the counterfactual experiments by suggesting a comparison against Journey TRAK, referencing Figure 2 of [1]. This provides a clear and actionable suggestion for the authors to enhance their analysis and potentially strengthen their results. By comparing against Journey TRAK, the authors can better understand the impact of removing high-scoring images, as demonstrated in the referenced figure. This feedback is mostly helpful as it offers a specific direction for improvement, but it could be more comprehensive if it included additional suggestions or guidance on how to implement the comparison effectively. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the experimental results, suggesting that replacing normal convolutions with adaptive convolutions is not always beneficial. It points out that the ACNN-v3 model, which uses adaptive convolutions across all layers, performed worse than ACNN-v2, which uses adaptive convolutions only in the last layer. The comment implies that the placement of adaptive convolutions is important but notes the absence of analysis or discussion on this aspect. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the impact of adaptive convolution placement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the ACNN-v3 model performed worse than ACNN-v2, suggesting that the placement of adaptive convolutions is important. However, the comment does not provide specific guidance on how the authors should analyze or address this issue. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, based on the experimental results presented in Table-3. It highlights that ACNN-v3, which uses adaptive convolutions across all layers, performed worse than ACNN-v2, which uses adaptive convolutions only in the last layer. This observation suggests that the placement of adaptive convolutions is important. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the authors can infer that the placement of adaptive convolutions is important, the lack of detailed explanation or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It points out that the ACNN-v3 model, which uses adaptive convolutions across all layers, performed worse than ACNN-v2, which uses adaptive convolutions only in the last layer. This observation suggests that the placement of adaptive convolutions is important, but the comment does not provide any analysis or discussion on this aspect. While the feedback highlights a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue. The comment is somewhat helpful as it points out a specific area that requires further analysis, but it could be more helpful with additional insights or suggestions. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the trade-off between computation time and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not provide explicit guidance on how the authors should address this issue or what actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or incorporate the feedback into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the trade-off between computation time and information loss when using ancestral graphs compared to DAGs, referencing a specific paper [10]. It questions the amount of information encoded in an ancestral graph, which is a specific aspect of the paper. The comment is fully grounded as it explicitly mentions the paper [10] and the specific issue being discussed. It is also specific because it clearly identifies the problem and asks a question about the information encoded in ancestral graphs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the trade-off between computation time and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. However, the comment does not provide any specific evidence, examples, or references to support the claim that this trade-off is significant or how it might impact the overall performance of the method. The lack of detailed reasoning or justification makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the trade-off between computation time and information loss when using ancestral graphs compared to DAGs. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in less information compared to the richer search space of DAGs. The comment questions how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant and insightful question for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate it into their work. While it identifies an important aspect of the method, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical discussions could be improved by providing sample complexity-type results for not returning NSF, such as the sufficient amount of training data points needed. However, it does not explicitly instruct the authors to include these results or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should add these results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexity-type results related to not returning NSF. However, it does not specify which part of the paper these discussions are in, making it weakly grounded. The comment is specific in its suggestion to include sample complexity results, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical discussions could be improved by providing sample complexity-type results for not returning NSF. However, it lacks specific examples or references to support this claim, making it difficult for the authors to understand how to implement the suggested improvements. The comment is somewhat verifiable as it provides a direction for improvement but lacks detailed justification or examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could be enhanced by providing sample complexity-type results for not returning NSF. This feedback is actionable, as it provides a clear direction for the authors to consider adding more detailed results. However, the comment could be more helpful if it offered specific guidance on how to derive or incorporate these results. Overall, the comment is mostly helpful, as it highlights an important aspect of the paper that could be strengthened with additional analysis.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' VAD (Visual Attention Descriptor) description, suggesting that it discards TF (Time-Frequency) bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it discards TF bins with zero magnitude, which could lead to division by zero. The comment implies that a VAD should look for the presence of speech (not just energy) and is typically defined over time, not frequency. However, the comment does not explicitly instruct the authors to revise their VAD description or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their VAD description and potentially address the issue of division by zero. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the VAD description, explaining that it discards TF bins with a magnitude less than epsilon, which could lead to division by zero. The comment further critiques the approach, suggesting that it does not align with the typical definition of a VAD, which is usually defined over time and looks for the presence of speech, not just energy. This provides clear guidance on what needs to be addressed in the VAD description. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' VAD description is puzzling and suggests that it discards TF bins with a magnitude less than epsilon, which could lead to division by zero. The reviewer argues that this approach is problematic because it does not align with the typical definition of a VAD, which is usually defined over time and looks for the presence of speech, not just energy. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the reasoning and provide their own justification to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a detailed critique of the authors' VAD (Visual Attention Descriptor) description, highlighting a specific issue where TF bins with a magnitude less than epsilon are discarded. The reviewer argues that this approach is problematic because it could lead to division by zero and does not align with the typical definition of a VAD, which is usually defined over time and looks for the presence of speech. This feedback is clear and actionable, as it identifies a specific flaw in the methodology and suggests that the authors reconsider their approach. However, it could be more helpful if it provided additional guidance on how to address the issue or alternative methods for handling low-magnitude TF bins. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for more comprehensive guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the discussion section could benefit from including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach as in Section 4.2. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is explicit and concrete, as it clearly indicates what additional discussion should be included and what specific aspects should be considered. The authors are given clear guidance on how to enhance the discussion section, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach, and provides specific examples of what to consider, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, it does not specify which part of the paper this discussion should be included in, leaving the authors to infer that it should be in the discussion section. The comment is specific in detailing what needs to be addressed, but it is weakly grounded as the authors cannot confidently determine the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach, and provides specific examples of what to consider, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals. However, the comment lacks detailed reasoning or references to support why this discussion is necessary or how it would enhance the paper. Without specific examples or evidence, the claim is somewhat verifiable, as it provides a suggestion but lacks depth and justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by suggesting that the discussion section could benefit from including a brief discussion on the empirical motivation for using time-varying Q^t and S_t, as opposed to a fixed approach. It also offers specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, as it guides the authors on what additional content to include in their discussion section. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the suggestion. Overall, the comment is mostly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction is not clear and that the methods might be similar, questioning the motivation behind the work. While the comment identifies a potential issue with the clarity of definitions, it does not provide explicit guidance on how the authors should address this concern or clarify the definitions. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the definitions in the paper. However, the lack of concrete suggestions or guidance on how to clarify the definitions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. It suggests that the distinction is not clear and that the methods might be similar, questioning the motivation behind the work. However, the comment does not specify which part of the paper contains these definitions or where the confusion arises. The authors cannot confidently determine which section or table is being addressed, making the comment weakly grounded. While it provides some specificity by questioning the definitions, the lack of explicit grounding limits the authors' ability to understand the exact issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction is not clear and that the methods might be similar, questioning the motivation behind the work. However, the comment lacks specific examples or references to support the claim that the distinction is not clear or that the methods are similar. Without detailed reasoning or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for questioning the definitions but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchor-based regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction is not clear and that the methods might be similar, questioning the motivation behind the work. This feedback highlights a potential area of confusion for the authors and points out a lack of clarity in the definitions. However, the comment does not provide specific suggestions or guidance on how the authors might clarify these definitions or address the concerns raised. While it identifies a potential issue, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the paper's readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not explicitly suggest any specific actions or provide guidance on how the authors might address these issues. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concerns about the paper's readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not specify which part of the paper is difficult to follow or lacks context. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment is somewhat specific in that it identifies the issues of lack of intuition and limited context, but without explicit references to specific sections or parts of the paper, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses concerns about the paper's readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not provide specific examples, reasoning, or references to support these claims. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's readability, noting that it lacks a clear intuition for how the pieces fit together and that the experiments have little context. This feedback is valuable as it highlights areas where the authors could improve the clarity and coherence of their presentation. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as suggesting alternative ways to structure the paper or provide more context for the experiments. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the student and refinement networks, which are trained simultaneously. It suggests that the comparison might be unfair and requests the authors to provide KID/FID metrics for their teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics to address the concern about fairness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the request for metrics, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, the comment does not provide any reasoning, examples, or references to support the claim that the comparison might be unfair. Without additional context or justification, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. This feedback is somewhat helpful as it identifies a potential issue with the experimental setup and suggests a specific metric to include, which could enhance the transparency and rigor of the evaluation. However, the comment lacks depth and does not provide detailed guidance on how to address the fairness concern or why the comparison might be unfair. The authors would need to infer that they should include the requested metrics to improve the clarity of their results. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to implement or explore this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider regarding the scaling of the refined region vector and suggests an alternative approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment provides a specific question and suggestion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the implications and potential benefits of the alternative approach, which could be more effective with additional explanation or evidence. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that could be improved by questioning the scaling of the refined region vector. It suggests an alternative approach by introducing a scaling variable before the attention weight, which could potentially enhance the model's performance. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, leaving the authors with a clear but incomplete direction for improvement. While it provides a valuable suggestion, the feedback could be more helpful if it included additional context or guidance on how to implement the alternative approach. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the model. It lacks concrete guidance on what actions the authors should take to mitigate this problem, such as proposing specific methods or experiments to enhance the model's ability to handle ambiguities. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to goal misspecification in the ALFRED benchmark, noting that failures occurred due to the LLM's inability to accurately recover the formal goal predicate, especially with ambiguities in human language. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the problem, it lacks grounding as it does not provide clear guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional evidence or context, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue related to goal misspecification in the ALFRED benchmark, noting that failures often occur due to the LLM's inability to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. While the comment highlights a potential weakness in the model's performance, it does not provide any suggestions or guidance on how to address this issue or improve the model. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a problem but lacks depth and constructive suggestions.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the small improvement of the proposed method over SOTA methods like IGEV and the question of whether there is a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. It also raises a concern about the difficulty of Sampling-Gaussian to significantly improve such frameworks. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or address the concern. The actions are implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two specific concerns about the improvement of the proposed method over SOTA methods like IGEV and questions the presence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. However, it does not explicitly mention which part of the paper these concerns relate to, making it weakly grounded. The comment is specific in detailing the concerns and suggesting an analysis of disparities, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions about the improvement of the proposed method over SOTA methods like IGEV and the presence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The first question suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. This implies a need for a detailed analysis, but it lacks specific examples or references to support the claim. The second part of the comment questions the difficulty of Sampling-Gaussian to significantly improve such frameworks, which is a logical deduction but lacks detailed reasoning or evidence. Overall, the comment is somewhat verifiable, as it provides some basis for the claims but lacks depth and specific examples to fully substantiate the concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important questions regarding the improvement of the proposed method over SOTA methods like IGEV and the presence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. It suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. This feedback is somewhat helpful as it points out a potential area for further analysis and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance or suggestions on how to conduct this analysis or address the concern about the difficulty of Sampling-Gaussian to significantly improve such frameworks. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should delve deeper into how specific models behave differently when ReGuide is applied, providing a more nuanced understanding of the conclusions. It gives an example of comparing false positive rates (FPR) between models with and without ReGuide. However, the comment does not explicitly instruct the authors to conduct this analysis or present the results in a specific way. While the action is implied, it lacks concrete guidance on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a deeper investigation into how specific models behave differently when ReGuide is applied, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this investigation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare false positive rates (FPR) between models with and without ReGuide, providing a clear direction for the authors to take. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide a deeper investigation into how specific models behave differently when ReGuide is applied, particularly focusing on false positive rates (FPR). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed guidance or evidence, the claim is considered borderline verifiable, as it provides a direction for improvement but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a specific example, such as comparing false positive rates (FPR) between models with and without ReGuide, which could enhance the nuance of the conclusions. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or presented preliminary results to illustrate the point. Overall, the feedback is somewhat helpful as it provides a clear direction for improvement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable suggestion that provides clear guidance on how the authors can improve their draft. By explicitly stating the need for clarification, the comment directs the authors to address a potential ambiguity in their presentation. The action is both explicit and concrete, as it clearly specifies what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. However, it does not specify which part of the paper this clarification is needed, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'No', 'helpfulness_rationale': 'The review comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable suggestion that could help improve the clarity and precision of the paper. By addressing this point, the authors can ensure that their presentation is unambiguous and easier to understand. However, the comment could be more helpful if it provided additional context or examples to illustrate the importance of this clarification. Overall, the comment is somewhat helpful as it identifies a specific area for improvement, but it lacks depth and could be more comprehensive.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct a specific error in the text, stating that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a concrete suggestion for improving the LaTeX formatting by placing the label after the caption. This direct and specific feedback allows the authors to easily identify the error and understand how to correct it. The comment is clear and actionable, providing both the correction and the method for implementation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, stating that \"it should be Fig. 1 instead of Fig. 5.1\" and provides a concrete suggestion for improvement regarding LaTeX formatting by recommending placing the label after the caption. This level of detail and specificity makes the comment highly actionable and informative for the authors. Therefore, this comment is rated as fully grounded and specific, corresponding to category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is an error in the text, specifically mentioning that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a suggestion for improving LaTeX formatting by placing the label after the caption. While the comment identifies a specific issue and offers a solution, it lacks detailed reasoning or references to support the claim about the error. The suggestion for LaTeX formatting is clear and actionable, but the claim about the figure number is not substantiated with evidence or references. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks depth and detail.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific error in the text, pointing out that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a clear suggestion for improving LaTeX formatting by recommending placing the label after the caption. This feedback is actionable and constructive, as it directly addresses a minor error and offers a practical solution for improving the presentation of the paper. However, the comment could be more helpful if it included additional suggestions or elaborated on the implications of the error. Overall, the comment is mostly helpful, as it provides clear guidance for improvement but could be expanded for greater depth and impact.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h, g$ and $\\delta$ are introduced without clear definitions of their input and output domains. While the comment identifies a specific issue with the clarity of the notations, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to clarify the notations, but the comment lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a clear area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. However, it does not specify which part of the paper these notations are introduced in, making it weakly grounded. The comment is specific in detailing the problem with the notations, but the lack of grounding makes it difficult for the authors to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. This is a clear and specific claim that requires the authors to clarify these notations for better understanding and consistency. The comment is mostly verifiable as it provides a clear and logical reason for the issue, but it could be strengthened by suggesting specific ways to address the lack of clarity, such as providing examples or definitions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. This is a clear and actionable feedback that helps the authors improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as defining the domains explicitly or providing examples. Overall, the comment is somewhat helpful as it highlights a significant area for improvement, but it lacks detailed guidance on how to implement the suggested changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify what aspects of the comparison need to be supplemented or what additional information would be beneficial. The comment lacks explicit guidance on how to enhance the comparison, making it vague and difficult for the authors to understand what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment does not provide specific guidance on what aspects of the comparison should be supplemented or what additional information would be beneficial. As a result, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not provide any specific reasoning, examples, or references to support why this comparison should be supplemented. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it lacks specific guidance on what aspects of the comparison need to be supplemented or what additional information would be beneficial. The comment is vague and does not provide actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it is unclear how much performance gain is attributed to the task formulation versus the use of pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these additional experiments or present the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and then decide how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"missing ablations,\" which allows the authors to accurately identify the part of the paper being addressed. It specifies what needs to be addressed by suggesting the inclusion of results using the GCPG model without pre-trained initializations. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is unclear how much performance gain is attributed to the task formulation versus the use of pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it is based on a logical inference but lacks sufficient justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by highlighting the lack of clarity regarding the source of performance gains. It specifically points out that it is unclear how much of the performance improvement is due to the task formulation versus the use of pre-trained language models. The suggestion to include results using the GCPG model without pre-trained initializations is a clear and actionable step that would help the authors address this ambiguity. By providing a concrete recommendation for additional experiments, the comment offers valuable guidance for improving the paper. However, it could be more helpful if it included more detailed reasoning or suggestions for how to conduct these experiments effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific suggestions for improvement. First, it recommends adding references next to baseline names in tables, such as placing a citation next to \"FF Positional\" if it refers to a paper method. This is an explicit action that the authors can directly implement. Second, it points out that the symbol $\\Omega$ is not explicitly defined in Corollary 1, though it can be inferred. While the authors can infer that they need to define $\\Omega$, the action is not as clear as it could be. The comment is mostly actionable, as it provides explicit guidance on one aspect and a clear suggestion for another, though the second part could be more detailed. Therefore, the comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Corollary 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the symbol $\\Omega$ is not explicitly defined in the corollary, which is a specific issue that needs to be addressed. This provides the authors with clear guidance on what part of the paper requires attention and what needs to be clarified. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains two claims: first, it suggests adding references next to baseline names in tables, and second, it points out that the symbol $\\Omega$ is not explicitly defined in Corollary 1. The first claim is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the recommendation. The second claim is fully verifiable as it clearly identifies a specific issue in the paper, allowing the authors to understand the need for clarification. Overall, the comment is mostly verifiable, as it provides some justification but could be strengthened with more detailed reasoning or references. Therefore, it aligns with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides two specific suggestions for improving the draft. First, it recommends adding references next to baseline names in tables, which is a clear and actionable piece of feedback. This would enhance the clarity and credibility of the paper. Second, the comment points out that the symbol $\\Omega$ is not explicitly defined in Corollary 1, which is a specific issue that needs to be addressed. While the comment is clear and identifies areas for improvement, it could be more helpful if it provided additional guidance on how to define $\\Omega$ or suggested alternative ways to present the information. Overall, the comment is mostly helpful, as it offers actionable feedback that the authors can use to enhance their draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a difficulty in understanding the axes of Figure 1, but it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on how to clarify the axes or improve the figure's clarity. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it points out a lack of clarity regarding the axes of the figure, which is a clear issue that needs to be addressed. However, without the specific section mentioned, the authors cannot confidently determine where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point states that it is \"hard to understand what the axes are for Figure 1,\" which is a subjective observation about the clarity of the figure. However, it does not provide any specific reasoning or examples to support why this is a problem or how it could be addressed. Without additional context or suggestions, the claim lacks sufficient justification and is therefore considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to improve the figure's clarity, which is a crucial aspect of effective communication in research papers. However, the comment could be more helpful if it provided suggestions on how to improve the figure's clarity, such as adding labels or explanations. Despite this, the comment is mostly helpful as it highlights a significant area for improvement that the authors can address to enhance the presentation of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific guidance or action on how to achieve this. The authors are left without a clear understanding of what steps they should take to enhance the results on ImageNet, making the comment somewhat vague and lacking in actionable details. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that results on ImageNet could be more convincing of the proposed method. However, it does not specify which part of the paper discusses the results on ImageNet or provide any details on how to improve the results. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting that the results could be more convincing, but it lacks detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results on ImageNet could be more convincing of the proposed method. While this feedback provides a direction for improvement, it lacks specific guidance or suggestions on how to enhance the results or what aspects of the ImageNet results might need attention. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not offer detailed actionable advice or examples, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of direct runtime comparisons with existing methods, suggesting that such comparisons are necessary to demonstrate the efficiency of the proposed approach. It implies that the authors should include these comparisons to provide a more comprehensive evaluation of their method. However, the comment does not specify which existing methods should be compared or how the comparisons should be conducted, leaving the action somewhat vague. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of missing direct runtime comparisons with existing methods, which is a specific aspect of the paper. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach. However, the comment does not specify which parts of the paper should be revised or what specific issues need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the need for runtime comparisons, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing, which is a valid concern. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach, as implicit differentiation usually requires additional computational costs. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for these comparisons based on the reasoning provided, but the lack of detailed evidence weakens the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. This is a crucial aspect for evaluating the efficiency and practicality of the proposed approach. By highlighting this omission, the comment provides a clear and actionable suggestion for the authors to enhance their draft. However, the comment could be more helpful if it offered specific guidance on which existing methods to compare with or how to conduct these comparisons effectively. Despite this, the feedback is mostly helpful as it directs the authors towards an important area of improvement, making it a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment claims that the proposed framework is a simple combination of meta-learning and federated learning and that it lacks any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment does not suggest how the authors might enhance the technical contribution of their framework or what specific aspects need to be improved. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what the authors should do to address the issue of the framework being a simple combination of meta-learning and federated learning. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning and that it lacks any technical contribution. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the proposed framework is a simple combination of meta-learning and federated learning, which may not constitute a significant technical contribution. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance the technical contribution of their framework. Without actionable feedback or guidance, the authors may find it challenging to improve their draft. Therefore, the comment is barely helpful, as it points out a concern but does not provide substantial assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the paper's contribution, suggesting that it primarily focuses on studying the connection between complementary and model robustness without providing further insights or solutions on how to leverage this connection to improve model robustness. The comment implies that the conclusion could be easily obtained and suggests that the paper lacks insightful findings or possible solutions. However, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the analysis and provide more insightful findings or solutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the paper's contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or analysis. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the contribution, the absence of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the paper's contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily and intuitively obtained, implying that the paper lacks insightful findings or possible solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains somewhat verifiable, as the authors may need to provide more detailed reasoning or examples to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the sufficiency of the paper's contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily and intuitively obtained, implying that the paper lacks insightful findings or possible solutions. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this concern. The feedback is somewhat helpful as it highlights a critical aspect of the paper's contribution, but it lacks actionable advice or detailed insights to guide the authors in enhancing their work. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\\'s motivation. While it raises a valid concern about the focus, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors would need to infer that they should consider the differences in representation between clusters. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\\'s motivation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the focus, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\\'s motivation. This is a subjective opinion or critique of the paper\\'s approach. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the focus of the paper, questioning why the authors chose to focus on which clusters are \"best\" rather than the differences in representation between them. This critique is based on the paper\\'s motivation, suggesting that the current focus might be misaligned with the intended goals. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what changes could be made to better align the focus with the motivation. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics\". This provides a clear and direct action for the authors to take, which is to correct the caption. The comment is specific and concrete, as it identifies the exact figure and the correct caption, allowing the authors to know exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption from \"Node Dynamics\" to \"Edge Dynamics'. This provides the authors with precise guidance on how to improve the figure caption. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a factual correction based on the content of the figure caption. However, the comment does not provide any reasoning or evidence to support why the caption is incorrect or why the suggested correction is appropriate. Without additional context or justification, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in the caption of Figure 7, which is a factual mistake. It provides a clear and actionable suggestion to correct the caption from \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is precise and directly addresses a minor but important detail that could improve the clarity and accuracy of the paper. By correcting the caption, the authors can enhance the presentation of their findings and ensure that the information is accurately represented. Therefore, the comment is mostly helpful, as it offers a clear and actionable improvement that the authors can easily implement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation. However, the comment does not explicitly instruct the authors to include these elements or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should add case studies and error studies to their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including case studies and error studies to enhance the paper\\'s effectiveness, providing an example of a case study in the context of graph pre-training for AMR parsing and generation. However, the comment does not specify which part of the paper should be addressed or how these studies should be integrated. The authors cannot confidently determine which sections or aspects of the paper would benefit from these additions. While the suggestion is specific about the type of study, the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including case studies and error studies would enhance the paper\\'s effectiveness by providing a more convincing demonstration of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed reasoning or references to support the claim that these studies would be particularly effective or necessary. The authors are left to infer the value of these studies, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that including case studies and error studies would enhance the paper's effectiveness by providing a more convincing demonstration of the proposed components. It offers an example of a case study in the context of graph pre-training for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed guidance on how to implement these studies or what specific aspects of the paper would benefit from them. While it provides a valuable suggestion, the feedback could be more helpful if it included more detailed instructions or examples of how to conduct and present these studies. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered. It provides examples of how the capacity of probing and latent size can affect the DCI evaluation. However, the comment does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve the draft. The action is implicit, as the authors need to infer that they should clarify the motivation for considering explicitness and size as extra evaluation. The lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and its consideration of explicitness (E) and size (S). It provides examples of how the capacity of probing and latent size can affect the DCI evaluation, suggesting that these aspects may already be considered. However, the comment does not specify which part of the paper discusses the DCI framework or where the authors should focus their attention. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper is being addressed. The comment is specific in detailing the concerns about explicitness and size, but without clear grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered. It provides examples of how the capacity of probing and latent size can affect the DCI evaluation, indicating that these factors are entangled. However, the comment lacks specific references or detailed reasoning to fully support the claim that the DCI framework may already be considered explicitness and size. While the reviewer provides some context, the absence of concrete evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the explicitness and size of the traditional DCI framework, suggesting that these aspects may already be considered. It provides examples of how the capacity of probing and latent size can affect the DCI evaluation, indicating that these factors are entangled. However, the comment does not offer specific guidance or suggestions on how the authors might address these concerns or improve their draft. While it identifies a potential issue, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should clarify the motivation for considering explicitness and size as extra evaluation, but the feedback is not comprehensive enough to fully assist them in improving their work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also suggests that the improvement brought by SoRA compared to the baseline might be due to random fluctuations. The comment implies that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are actual improvements due to SoRA. While the action is implicit, it is clear and concrete, as it directs the authors to address the missing standard deviation information and clarify the results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section of the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the lack of standard deviation information and the need to clarify which effects are within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This level of detail helps the authors understand exactly what revisions are necessary. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the standard deviation after multiple experiments is not provided, which may lead to the conclusion that the improvement brought by SoRA compared to the baseline is due to random fluctuations. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also suggests that the improvement brought by SoRA compared to the baseline might be due to random fluctuations, and recommends clarifying which effects fall within the range of standard deviation fluctuations and which are actual improvements. This feedback is clear and actionable, as it provides a direct suggestion for the authors to address a missing piece of information and improve the clarity of their results. However, it could be more helpful if it included additional guidance on how to present the data or interpret the results. Overall, the comment is mostly helpful, as it offers valuable insights and actionable feedback that the authors can use to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1 and Figure 2\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, explicitness of figures, and incorrect placement of Table 2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well organized and the layout is rushed, citing specific issues such as small font sizes in Figure 1 and 2, lack of explicitness in the figures, incorrect placement of Table 2, and incorrect formatting on page 6. While the comment provides specific examples of these issues, it lacks detailed reasoning or references to support the claim that these issues significantly impact the paper's organization or presentation. The authors are left to infer the significance of these observations, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment provides specific examples of these problems, it lacks detailed guidance on how the authors might address these issues or what specific changes would be beneficial. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable with additional suggestions or recommendations. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for real-world querying. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the interventions need to be evaluated for practicality and safety. The action is implicit and vague, as it leaves the authors to infer the necessary steps without clear direction. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for real-world querying. However, it does not specify which part of the paper discusses the types of interventions or where the authors should address the practicality and safety concerns. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is somewhat specific in that it highlights the importance of considering practicality and safety, but it lacks detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that while the types of interventions are reasonable computationally, they need to be considered for practicality and safety in real-world querying. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it offers a suggestion but lacks the necessary depth and support for the authors to fully understand and address the issue.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the practicality and safety of the interventions discussed in the paper. It suggests that while the computational types are reasonable, they need to be considered in terms of their real-world applicability and safety. However, the comment lacks specific guidance or suggestions on how the authors might address this concern, such as providing examples of real-world scenarios or discussing potential risks. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This feedback is explicit, as it directly points out a missing definition, providing the authors with a clear action to take: they should define the notation {\\cal P} with a subscript to ensure clarity and consistency in the paper. The action is also concrete, as it specifies exactly what needs to be done\u2014define the notation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"in the same section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the issue of using the notation {\\cal P} with a subscript multiple times without defining it, providing a clear and actionable suggestion for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an issue with the notation {\\cal P} with a subscript being used multiple times in the same section without being defined. This is a factual observation that requires no further explanation or justification to be understood. The comment is clear and specific, indicating a need for clarification or definition of the notation. Therefore, it is classified as \"3: Somewhat Verifiable\" as it is clear but lacks some depth in terms of providing examples or references to support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a specific issue in the paper, noting that the notation {\\cal P} with a subscript is used multiple times in the same section without being defined. This is a clear and actionable feedback that highlights a lack of clarity and consistency in the notation used. By pointing out this issue, the comment provides the authors with a specific area to address, encouraging them to define the notation to improve the readability and understanding of the paper. This feedback is mostly helpful as it directs the authors to a concrete improvement, though it could be more comprehensive if it suggested alternative notations or provided examples of where the notation is used. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the draft, such as correcting a spelling error (\"known\" instead of \"know\"), defining a symbol (\"\\\\gamma_0^{***}\"), and specifying the meaning of colors in a figure caption. These suggestions are explicit and concrete, allowing the authors to directly apply them to their draft. The feedback is detailed and actionable, providing clear guidance on how to address the identified issues. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the draft, such as correcting a spelling error (\"known\" instead of \"know\"), defining a symbol (\"\\\\gamma_0^{***}\"), and specifying the meaning of colors in a figure caption. However, it does not explicitly mention which part of the paper these suggestions relate to, such as a specific section or figure number. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the suggestions are specific, the lack of grounding makes it challenging for the authors to fully understand the scope of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of three separate suggestions for improving the draft. The first suggestion, correcting a spelling error (\"known\" instead of \"know\"), is a factual correction and does not require any claim or reasoning. The second suggestion, asking for a definition of \\\\gamma_0^{***}, is a request for clarification, which is a common request in peer reviews. The third suggestion, specifying the meaning of colors in a figure caption, is also a request for clarification. Overall, the comment is factual and does not contain any subjective claims or opinions, making it a \"No\" category.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft, such as correcting a spelling error (\"known\" instead of \"know\"), defining a symbol (\"\\\\gamma_0^{***}\"), and specifying the meaning of colors in a figure caption. These suggestions are actionable and directly address potential issues in the draft, offering clear guidance for the authors to enhance their work. However, the comment could be more helpful if it included additional feedback or suggestions for further improvements. Overall, the feedback is mostly helpful, as it provides valuable insights and actionable advice for the authors to consider.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the clarity and consistency of the paper. It questions the definition of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need to be explained better. Additionally, it points out that the variable 'p' is not explicitly defined, which is problematic given its extensive use throughout the paper. The comment implies that moving the definition of 'p' would improve the paper, but it does not provide specific guidance on how to address the issues with the \"upper faces\" or the projection \u03c0. While the authors can infer that they need to clarify these concepts, the lack of explicit instructions or detailed guidance makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises specific issues regarding the clarity of certain concepts in the paper, such as the \"upper faces\" of the convex hull and the variable 'p' in the context of decision boundaries of neural networks. It suggests that the dual subdivision and projection \u03c0 need to be explained better, and that the variable 'p' should be explicitly defined. However, the comment does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its suggestions, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises specific questions about the clarity of certain concepts in the paper, such as the \"upper faces\" of the convex hull and the variable 'p' in the context of decision boundaries of neural networks. It suggests that the dual subdivision and projection \u03c0 need to be explained better, and that the variable 'p' should be explicitly defined. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved, such as the clarity of the \"upper faces\" of the convex hull and the definition of the variable 'p'. It provides actionable feedback by suggesting that the authors should explain the dual subdivision and projection \u03c0 better and explicitly define the variable 'p'. However, the comment could be more helpful if it offered additional guidance on how to improve the clarity of these concepts or provided examples of how to better explain them. While the feedback is somewhat helpful, it lacks depth and could be expanded to provide more comprehensive suggestions. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes they should consider making to their draft. Without specific suggestions or instructions, the authors are left without a clear path forward, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this concern or what changes might be necessary. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the concern. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or what changes could be made to their draft. It lacks actionable feedback, leaving the authors without a clear path to improve their work. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the method separately on baseline detection and parsing techniques to better support their claim. While the comment identifies a specific issue and provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this evaluation or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method, which consists of two major components: a generative shape model and a word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain. The reviewer suggests evaluating the method separately on baseline detection and parsing techniques to better support the claim. However, the comment does not specify which part of the paper discusses the proposed method or the evaluation of the components. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of evaluating the components separately, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the method separately on baseline detection and parsing techniques to better support their claim. However, the comment does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would strengthen the claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, rendering the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key issue with the proposed method, specifically questioning the contribution of each component to the performance gain. It suggests that the authors should evaluate the method separately on baseline detection and parsing techniques to better support their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their analysis and strengthen their claims. However, the comment could be more helpful if it included additional guidance on how to conduct the evaluation or what specific metrics to use. Overall, the comment is mostly helpful, as it offers valuable insights and actionable suggestions for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should discuss the rationale behind the manual disentanglement and explore alternative approaches. The lack of concrete suggestions or detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of manual disentangling, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not provide any specific reasoning, examples, or references to support the claim that manual disentanglement is a significant issue or why it is necessary. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically questioning the manual disentangling process and suggesting that everything could be learned instead. It raises a valid point about the rationale behind the manual disentanglement and encourages the authors to explore alternative approaches. However, the comment lacks depth and specificity, as it does not provide detailed reasoning or suggestions for how the authors might address this issue. While it prompts the authors to consider alternative approaches, it does not offer concrete guidance or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method appears to simply adopt the self-attention mechanism from transformers and apply it to graphs. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen the connection. The comment lacks concrete suggestions or detailed instructions on how to improve the paper, leaving the authors uncertain about how to respond. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method seems to simply adopt the self-attention mechanism from transformers and apply it to graphs. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. It is also specific in that it highlights a lack of clarity regarding the connection between the theoretical analysis and the proposed method, but without grounding, the authors cannot confidently identify the relevant part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method appears to simply adopt the self-attention mechanism from transformers and apply it to graphs. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion that the proposed method does not enhance the generalization for distant nodes. As a result, the claim is not verifiable, and the comment does not provide the authors with a clear understanding of what needs to be addressed. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It suggests that the method might simply adopt the self-attention mechanism from transformers and apply it to graphs without providing a clear explanation of its enhancement. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the connection between the theoretical analysis and the proposed method. While it points out a potential area for improvement, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption. While it highlights a potential area of concern, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to clarify the method's behavior. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making it weakly grounded. However, the comment is specific in identifying a potential area of concern, as it questions the method's behavior without a key assumption. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not provide any specific reasoning, examples, or references to support why this is a concern. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the behavior of the method without the Lipschitz Hessian assumption, which is a critical aspect of the method's performance. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what steps they should take to clarify the method's behavior. While it identifies a potential area of concern, it lacks actionable advice or detailed insights that would help the authors improve their draft. Therefore, the comment is barely helpful, as it highlights a problem but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to improve the clarity of their presentation, but without specific instructions on how to do so, the action remains implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some pieces\" and \"equation (12),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies that the presentation of these methods is vague and requires checking the original paper for understanding. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it lacks specific examples or references to support the claim. The authors are left to infer that the presentation needs improvement, but without detailed guidance or evidence, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of certain pieces of the paper, noting that some methods are using existing approaches and that their presentation is vague, requiring the authors to consult the original paper to understand them. This feedback is clear and actionable, as it highlights a potential area for improvement in the clarity and organization of the paper. However, the comment could be more helpful if it provided suggestions on how the authors might improve the presentation or clarify the methods. Overall, the comment is mostly helpful as it directs the authors to address a specific issue, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind two specific design choices in Figure 1: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide explicit or implicit suggestions on how the authors should address these questions or provide further justification for their design choices. The comment lacks concrete guidance on what needs to be done or how the authors can improve their draft. As a result, the comment is unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the rationale behind two specific design choices: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. This provides clear guidance on what aspects of the paper require further explanation or justification. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While it identifies areas that could be clarified or better explained, it does not provide actionable feedback or suggestions on how the authors might address these questions or improve their draft. The comment lacks depth and specificity, making it somewhat helpful as it points out potential areas for improvement but does not offer concrete guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that Table 4 is incomplete and should include results for all four datasets. This provides a clear and direct action for the authors to take, which is to complete the table with the missing results. The comment is specific and concrete, as it clearly identifies the exact issue and what needs to be done to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely the results for all four datasets. This provides the authors with a clear understanding of what needs to be added to complete the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 4 is incomplete and should include results for all four datasets. While the comment identifies a specific issue with the table, it does not provide any reasoning or justification for why the table is incomplete or why it should include results for all four datasets. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct instruction on what needs to be addressed to improve the completeness of their results. By completing the table with the missing data, the authors can enhance the clarity and comprehensiveness of their findings, making the comment highly helpful. However, the comment could be more helpful if it provided additional guidance on how to present or analyze the results, but as it stands, it offers a clear and actionable suggestion.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on what aspects of the writing or presentation need improvement, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, it does not specify which part of the paper this issue is present in, such as a particular section, table, or figure. Without this specific reference, the authors cannot confidently identify the exact area that needs improvement. The comment is not grounded because it lacks a clear indication of the specific part of the paper being addressed. Additionally, it does not provide specific guidance on how to improve the writing or presentation, making it not specific either. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the writing and presentation of the paper, noting that it is \"jumbled at times.\" This is a subjective assessment and lacks specific examples or references to support the claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the writing and presentation of the paper, noting that it is \"jumbled at times.\" However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not specify which sections or aspects of the paper are jumbled, nor does it offer any guidance on how the authors might address this issue. Without concrete advice or examples, the authors are left without a clear understanding of how to enhance the clarity and coherence of their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the stability definition needs better justification, specifically pointing out that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). It proposes a more reasonable treatment by making the definition lower bounded. While the comment provides a clear action\u2014improving the justification of the stability definition\u2014it does not offer specific guidance on how to achieve this. The authors are left with a general direction but lack concrete steps to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the stability definition, suggesting that it needs better justification. It points out that the left side of the definition can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\), and proposes a more reasonable treatment by making the definition lower bounded. However, the comment does not specify which part of the paper discusses the stability definition, making it weakly grounded. It is specific in detailing the issue with the definition, but without explicit references, the authors may need to infer the section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the stability definition needs better justification, specifically noting that the left side can be arbitrarily small under some construction of \\\\(\\\\tilde{g}\\\\). The comment suggests a more reasonable treatment by making the definition lower bounded. However, the comment lacks specific examples or references to support the claim about the arbitrariness of the left side, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the suggestion for improvement is not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). It suggests a more reasonable treatment by making the definition lower bounded. This feedback is clear and actionable, providing the authors with a specific direction to improve their work. However, it could be more helpful if it included additional details or examples to illustrate the problem. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional context or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, particularly when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit, as the authors would need to infer that they should consider the impact of the annealing scheme and potentially explore alternative approaches or provide more detailed explanations to address the concern. The lack of concrete suggestions or guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, specifically when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not specify which part of the paper this refers to, making it difficult for the authors to pinpoint the exact section being addressed. While the authors can infer that it relates to the discussion of the annealing scheme, the lack of explicit grounding makes the comment weakly grounded. The comment is specific in its questioning about the potential bias introduced by the annealing scheme, but without clear grounding, the authors may struggle to understand which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of the annealing scheme in Section 4, particularly when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the importance of the annealing scheme described in the last paragraph of Section 4, particularly when $\\alpha$ is not decreased to 0. It suggests that this scheme might introduce a bias that could outweigh the bias reductions achieved by using IWAE. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve their draft. While it identifies a potential issue, it lacks actionable advice or detailed reasoning, making it somewhat helpful. The authors would need to infer that they should consider the impact of the annealing scheme and potentially explore alternative approaches or provide more detailed explanations to address the concern. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests considering the power demand on a mobile device. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should analyze or compare the computational complexity or how they should address the power demand on a mobile device. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emitting convolutions.\" It also suggests considering the power demand on a mobile device. However, the comment does not specify which part of the paper this question relates to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its request for comparison and consideration of power demand, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests considering the power demand on a mobile device. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the computational complexity could be a concern. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the computational complexity of the proposed method compared to other methods, specifically mentioning \"emerging convolutions.\" It also suggests considering the power demand on a mobile device, which is a relevant concern for practical applications. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. It does not offer any actionable steps or insights into how the computational complexity could be analyzed or compared. As a result, while the comment identifies a potential area for improvement, it does not provide sufficient detail or direction for the authors to effectively address the concern. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors' claim about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. It provides a specific correction, indicating that these heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. The comment is fully actionable because it provides a direct and concrete instruction for the authors to address the issue. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the base IOI circuit\" and the specific heads (\"Induction, Duplicate Token, and Previous Token heads\") being discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect in the authors' claim, pointing out that these heads are active at the S2 token but do not primarily attend to it. This provides a clear direction for the authors to correct their understanding and potentially revise their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' statement about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to external literature, which provides a basis for verification. However, the comment could be more verifiable by including a brief summary or explanation of the relevant section in Wang et al., 2023, to enhance clarity and understanding. Overall, the comment is mostly verifiable, as it provides a clear basis for the authors to address the issue.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the authors' claim regarding the primary attention of certain heads in the base IOI circuit. It points out that the authors incorrectly state that these heads primarily attend to the S2 token, while the referenced work suggests they are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their understanding and potentially revise their draft. By providing a specific correction and referencing external literature, the comment offers valuable guidance for improving the accuracy and clarity of the paper. Therefore, the comment is highly helpful, as it addresses a critical aspect of the draft and provides a clear path for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the work, suggesting that it is incremental and not impressive or novel. However, it does not specify which part of the paper this critique refers to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what specific issues need to be addressed. Additionally, the comment is somewhat specific in its critique of the pipeline, but without clear references, it remains challenging for the authors to fully grasp the feedback. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or comparisons to existing work, the authors may find it challenging to understand the basis of the critique. This makes the claim somewhat verifiable, as it is based on subjective assessment without strong supporting evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the technical contribution of the work, suggesting that it is incremental and not impressive or novel, consisting of a pack of tricks to improve defense evaluation. While the comment identifies a potential weakness in the paper's contribution, it lacks specific suggestions or guidance on how the authors might address this issue or enhance their work. The feedback is somewhat helpful as it points out a critical area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might develop a distributed version of the method or what specific steps they should consider to improve scalability. Without concrete suggestions or actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental setup. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific suggestions or guidance on how to address the scalability issue, such as proposing a distributed version of the method or alternative approaches. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the method, suggesting that it may not be feasible to run on a single instance due to the size of real-world datasets. This feedback highlights a critical limitation that could impact the practical applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this scalability issue, such as proposing a distributed version of the method or alternative approaches. While it points out a significant concern, the absence of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but does not offer detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the reason for the eta_ri term being a non-central chi-squared distribution. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify or justify this aspect of their work. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the reason for the eta_ri term being a non-central chi-squared distribution, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in questioning the rationale behind the distribution, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the reason for the eta_ri term being a non-central chi-squared distribution. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer the reasoning, making the comment unverifiable. Therefore, the comment is labeled as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind the eta_ri term being a non-central chi-squared distribution. While it identifies a potential area for clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks depth and actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the vagueness of the statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learning-agent analogy at L16-18, suggesting that it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. However, the comment does not offer explicit or implicit actions for the authors to take, such as how to revise the statement or address the analogy. The feedback is somewhat vague and lacks detailed guidance on how to implement the suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, such as the vagueness of the statement at L15 and the out-of-place analogy at L16-18. This provides clear guidance on how the authors should revise their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point includes a claim that the statement at L15 is too vague, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. The comment also critiques the reinforcement learning-agent analogy at L16-18, suggesting it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. However, the claim about the vagueness of the statement at L15 is somewhat verifiable as it provides a reference to support the claim, but it lacks specific examples or detailed reasoning. The critique of the analogy is also somewhat verifiable as it points out a potential issue with the analogy's placement. Overall, the comment is somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of a statement at L15, suggesting that certain RNNs work well for specific natural language reasoning tasks and providing a reference to support this claim. It also critiques the reinforcement learning-agent analogy at L16-18, suggesting that it is out-of-place and that generalization capabilities are better illustrated by examples later in the paper. While the comment identifies areas for improvement, it lacks detailed guidance on how the authors should revise these sections or address the analogy. The feedback is somewhat helpful as it highlights specific issues that need attention, but it could be more comprehensive with actionable suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: first, it notes that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not discuss this observation further. Second, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide a more detailed discussion of the observation and a theoretical justification for the algorithm. This lack of explicit action makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proposed sensitive-layer selection and the lack of mathematical or theoretical justification for Algorithm.1, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that the authors do not further discuss this observation. It also notes the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The authors are left to infer the significance of the observation and the need for theoretical justification, which could be challenging. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper. First, it points out that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not provide a detailed discussion of this observation. This feedback highlights a gap in the analysis and suggests that the authors should elaborate on the implications of their findings. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm.1, which is a critical aspect that needs to be addressed for the paper to be more robust and credible. By pointing out these specific areas, the comment provides clear guidance for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to strengthen the theoretical justification. Overall, the comment is mostly helpful as it identifies important areas for improvement and encourages the authors to expand their analysis and theoretical grounding.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuple-like structure instead of sets. This provides a specific and explicit action for the authors to take, as they can directly address this suggestion by revising the notation to better reflect the tuple structure. The comment is clear and concrete, offering a direct and actionable improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that triples denoted as $(e_1, r, e_2)$ should be represented to show their tuple-like structure instead of sets. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuple-like structure instead of sets. This is a specific and actionable suggestion that could improve the clarity of the paper. However, the comment does not provide any reasoning or examples to support why this change would be beneficial or how it would enhance the understanding of the triples. Without additional context or justification, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that triples denoted as $(e_1, r, e_2)$ would be clearer if they were represented to show their tuple-like structure instead of sets. This feedback is actionable and directly addresses a potential area for clarification in the paper. By suggesting a change in notation, the comment empowers the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it included additional context or examples to illustrate why this change would be beneficial. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting the absence of speed analysis and suggesting that comparisons of inference speed between the proposed network and prior work would be more interesting than reducing FLOPs. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to include such analysis. While the authors can infer that they need to conduct additional experiments to compare inference speed, the lack of concrete instructions or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks but noting the absence of comparisons of inference speed between the proposed network and prior work. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is specific in its critique of the lack of speed analysis but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a speed analysis, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. While the comment identifies a gap in the analysis, it does not provide specific examples or references to support the claim. The reasoning is somewhat vague, as it lacks detailed evidence or examples to substantiate the assertion. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of speed analysis, specifically mentioning the absence of comparisons of inference speed between the proposed network and prior work. It suggests that such comparisons would be more interesting than reducing FLOPs, which implies that the authors should consider including a more comprehensive analysis of inference speed. However, the comment does not provide specific guidance on how to conduct these comparisons or what metrics should be used. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the scalability of optimal quantization, suggesting that it is costly to both the number of data points (N) and the dimension (M). It also points out that the paper aims to speed up variational inference (VI) through fast convergence, but quantization is a bottleneck in this process, making the method less effective for big data and big model settings. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the method or what specific changes might be necessary. As a result, the authors are left without clear direction on how to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the scalability of optimal quantization, a topic mentioned in the abstract and introduction. It highlights the cost associated with both the number of data points (N) and the dimension (M), and suggests that quantization is a bottleneck for variational inference (VI) in big data and big model settings. However, the comment does not specify which part of the paper discusses the scalability of quantization or how it relates to the overall methodology. This makes it difficult for the authors to pinpoint the exact section or aspect that needs attention. While the comment is specific about the issue of scalability, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It argues that even with clustering, it is costly to both the number of data points (N) and the dimension (M). The paper aims to speed up variational inference (VI) through fast convergence, but the reviewer suggests that quantization is a bottleneck, making the method less effective for big data and big model settings. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide references or detailed explanations to support the assertion that quantization is a bottleneck for big data and big model settings. As a result, the claim is somewhat verifiable, as it provides a basis for the authors to consider but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the scalability of optimal quantization, which is a significant concern for the paper's claims about speeding up variational inference. It highlights that even with clustering, quantization remains costly in terms of both the number of data points (N) and the dimension (M). The reviewer also points out that this bottleneck limits the method's effectiveness for big data and big model settings, questioning the paper's aim to achieve fast convergence. However, the comment lacks specific suggestions or actionable advice on how the authors might address this issue or improve the scalability of their method. While it raises an important point, the feedback is somewhat helpful as it directs the authors to consider the scalability of their approach, but it does not provide detailed guidance on how to resolve the identified bottleneck. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment does not provide explicit guidance on how to compare the methods or what specific aspects of the notations need to be addressed. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the effectiveness of the proposed method against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment does not specify which part of the paper discusses the methodology or the issues mentioned above, making it weakly grounded. The comment is specific in suggesting comparisons and addressing notations issues, but without clear references, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment lacks specific details or references to support the claim about the effectiveness of the proposed method or the issues with notations. Without concrete examples or evidence, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment lacks specific guidance on how to compare the methods or what aspects of the notations need to be addressed. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the algorithm, specifically mentioning its reliance on the entire training dataset. It also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies areas that need improvement, such as the algorithm's performance with incomplete datasets and the comprehensiveness of the validation experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment provides some context and questions, it lacks specific examples or detailed reasoning to fully substantiate the claims. The feedback is somewhat verifiable, as it identifies areas for improvement but does not provide comprehensive evidence or detailed explanations. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important points regarding the algorithm's effectiveness, the comprehensiveness of the validation experiments, and the need for a clearer analysis of time complexity and efficiency. It also suggests that the authors should further elucidate the technical contribution rather than focusing solely on the form of the attack. While the comment identifies key areas for improvement, it lacks specific guidance on how the authors might address these issues or what changes could be made to enhance the paper. The feedback is somewhat helpful as it provides a general direction for improvement but does not offer detailed suggestions or actionable steps for the authors. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a counterexample, noting that RBF kernels have an infinite-dimensional RKHS, which would require an infinitely wide neural network to represent. The comment suggests that the limitation of neural networks in representing such kernels should be made clearer. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific sections to revise or examples to include. The action is implicit and somewhat vague, as the authors are left to infer how to improve the draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, line 104, allowing the authors to accurately identify the section being addressed. It also provides specific feedback by pointing out a counterexample to the claim that every kernel can be described by a feature space parameterized by a neural network, particularly for RBF kernels with infinite-dimensional RKHSs. This specificity helps the authors understand what needs to be addressed and how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is trivially not true, providing a counterexample with RBF kernels and their infinite-dimensional RKHSs. The comment suggests that this limitation should be made clearer. However, the reasoning is logical and provides a specific example to support the claim, making it mostly verifiable. The comment is clear and provides sufficient evidence for the reviewer to understand and address the issue. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with a claim made in the paper, noting that the assertion that every kernel can be described by a feature space parameterized by a neural network is not entirely accurate. It provides a counterexample using RBF kernels, which have an infinite-dimensional Reproducing Kernel Hilbert Space (RKHS), and explains that representing such kernels with neural networks would require an infinitely wide network. This critique highlights a potential misunderstanding or oversimplification in the paper, suggesting that the limitation of neural networks in representing certain kernels should be made clearer. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue, such as suggesting additional details or examples to include in the paper. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method is not well-positioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the positioning of their method in the literature. The action is implicit and vague, as it does not specify how the authors should conduct a thorough literature review or what specific aspects of their method need to be highlighted. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and suggests a thorough literature review, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. This provides clear guidance on what the authors should consider in their literature review. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. The comment provides specific examples of related work, which supports the claim and offers a clear rationale for why the method might not be as novel as initially presented. However, it could be more robust if it included a broader range of references or a more detailed explanation of how the proposed method differs from or builds upon these existing works. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and specific examples, but it could be strengthened with additional evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it is not well-positioned in the literature. It points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. This feedback is valuable as it highlights a potential gap in the authors' understanding of the existing literature and suggests that the method might not be as novel as claimed. However, the comment could be more helpful if it provided specific guidance on how the authors could address this issue, such as suggesting a more comprehensive literature review or highlighting the unique aspects of their method that differentiate it from existing approaches. Overall, the comment is somewhat helpful, as it identifies a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training and the limited use of tokens during inference. While it highlights a potential concern, it does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to clarify the handling of long token dimensions during inference, but the comment lacks concrete steps or detailed advice on how to implement this clarification. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide sufficient guidance for the authors to take action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training and the limited use of tokens during inference. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific in its inquiry about the handling of long token dimensions, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training and the limited use of tokens during inference. However, it does not provide any evidence, reasoning, or references to support the claim that this is a significant issue or a problem that needs to be addressed. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically concerning the use of long token dimensions during training and the limited use of tokens during inference. This question highlights a potential concern or area for improvement in the paper, as it questions the benefits of inference when only a limited number of tokens are used. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the handling of long token dimensions during inference. Without actionable feedback or specific suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and guidance for the authors to take action.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is explicit and provides a clear action for the authors to take, which is to include a gradient comparison between KL and PCC. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC)\" as key components of the paper. It also specifies the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, suggesting that the constraint strength should be defined by the gradient distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is mostly verifiable as it provides a logical reasoning and an example to support the claim, but it could be strengthened by including specific references or a more detailed explanation of the gradient comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence. It provides a logical argument based on the concept of constraint strength being defined by the gradient distribution, and it offers an example comparing KL divergence and MSE loss to illustrate the point. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim, which is a clear and actionable feedback for the authors. This feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a basis for further discussion. However, it could be more helpful if it included additional examples or suggestions for comparison. Overall, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the analysis presented in Figure 4. It asks whether GPI with noise added could reproduce the data similarly well, suggesting that additional measures should be considered to show that GPI cannot have as good a fit with behavioral data. The reviewer also suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the possibility of GPI with noise added reproducing the data similarly well and the need for additional measures to show that GPI cannot have as good a fit with behavioral data. Furthermore, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. This provides clear guidance on what aspects of the analysis need further exploration or discussion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the analysis presented in Figure 4, specifically regarding the reproducibility of data with GPI and noise, and suggests considering additional measures to show that GPI cannot have as good a fit with behavioral data. It also proposes discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors are left to interpret the suggestions, which may not be fully convincing or actionable. Therefore, the comment is considered borderline verifiable, as it provides some basis for questioning the analysis but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises several important points that could enhance the paper's analysis and discussion. It questions the reproducibility of data with GPI and noise, suggesting that additional measures should be considered to demonstrate that GPI cannot have as good a fit with behavioral data. The comment also proposes discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment lacks specific guidance on how to address these points or what additional analyses might be necessary. While it identifies areas for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples of how to strengthen the analysis. Therefore, the comment is somewhat helpful, as it offers insights but could be more comprehensive and actionable.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed approach with a \"small learning rate for attention parameters\" benchmark. However, it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should perform the comparison, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"small learning rate for attention parameters\" benchmark, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with the proposed approach, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification or comparison, rather than a claim that requires verification. It does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it should be classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it suggests a comparison with a specific benchmark, which could provide valuable insights for the authors. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what aspects to focus on. While it prompts the authors to consider an additional evaluation, it does not provide a comprehensive suggestion or detailed feedback, making it somewhat helpful rather than fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about aspects that were not understood. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about specific parts of the paper, such as lines 106 and 29, which suggests that the authors can identify the sections being addressed. However, it does not specify what needs to be addressed in these parts, such as why the distribution might have changed or how experiments disentangle changes in distribution from the removal of information. This makes the comment weakly grounded, as the authors can infer the parts being addressed but lack specific guidance on what to do. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. However, it does not provide any evidence, reasoning, or references to support these claims. The comment lacks specific examples or justifications, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about aspects that were not understood. While the comment identifies areas where the authors might need clarification or further explanation, it lacks actionable suggestions or detailed guidance on how to address these issues. The feedback is somewhat helpful as it points out specific areas of concern, but it does not provide concrete steps or insights for improvement. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that direct comparison using the numbers from the paper is unfair and recommends reproducing the results using the same setting, as most recent methods have their code released. This comment provides an explicit action for the authors to take, which is to reproduce the results using the same setting. However, it does not offer detailed guidance on how to implement this action, such as specifying which parts of the code to reproduce or which specific settings to use. Therefore, the comment is somewhat actionable, as it identifies an action but lacks concrete details on its execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of AdamW with cosine learning rate for training the proposed method, while comparing it with methods that use Adam with fixed learning rate. It suggests that direct comparison using the numbers from the paper is unfair and recommends reproducing the results using the same setting. However, the comment does not specify which part of the paper discusses the training methods or the comparison with other methods. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of different learning rates, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method uses AdamW with cosine learning rate, while comparing methods only use Adam with fixed learning rate. This observation is based on the comparison of training methods used in the paper. The reviewer suggests that direct comparison using the numbers from the paper is unfair and recommends reproducing the results using the same setting. However, the comment lacks specific examples or references to support the claim about the different learning rates used in the comparison. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that direct comparison using the numbers from the paper is unfair and recommends reproducing the results using the same setting, as most recent methods have their code released. This feedback is somewhat helpful as it highlights a potential flaw in the experimental setup and provides a suggestion for improvement. However, it could be more helpful if it included specific guidance on which parts of the code to reproduce or which settings to use. Overall, the comment provides a clear direction for the authors to enhance the fairness of their comparison, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area for further exploration, it does not provide explicit guidance on how the authors should address this question or incorporate it into their work. The comment lacks concrete actions or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its inquiry about the performance of a particular method, but it lacks detail on how this information could be integrated or utilized. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or evidence to substantiate the inquiry, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, which could be a valuable area for further exploration. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might approach this question or what aspects of their work could be improved. Without actionable feedback or detailed insights, the authors may find it challenging to address the comment effectively. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer substantial guidance or direction.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the quality of the plots, specifically mentioning that they are too small, have hard-to-distinguish colors, poorly labeled axes (e.g., \"error\"), and visually similar labels. The reviewer suggests that these issues are the reason for the sub-standard clarity. While the comment identifies specific issues with the plots, it does not provide explicit guidance on how to improve them. The authors are left to infer that they need to address these issues, but the lack of concrete suggestions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the plots,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their size, color distinguishability, poor labeling, and visually similar labels. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" and provides specific reasons for this assessment, such as being too small, having hard-to-distinguish colors, poorly labeled axes (e.g., \"error\"), and visually similar labels. These reasons are detailed and provide a clear basis for evaluating the claim. However, the comment lacks references or examples to support the claim further, which could make it somewhat verifiable. Overall, the comment is mostly verifiable as it provides a logical basis for the claim, but it could be strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific feedback on the quality of the plots, which are a crucial part of the paper. It identifies several issues, such as the small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels, all of which contribute to a lack of clarity. The comment also explains why these issues are problematic, as they are the reason for the sub-standard clarity. This feedback is actionable and provides clear guidance on how the authors can improve the presentation of their results. By addressing these issues, the authors can enhance the clarity and impact of their paper, making the comment highly valuable for their revision process. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% on most metrics. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the performance. The comment lacks concrete guidance on what actions the authors should take to enhance their results. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It only mentions the performance gains and the comparison between different approaches, without referencing any specific section, table, or figure. Therefore, the authors cannot confidently determine which part of the paper the comment pertains to, making it weakly grounded. Additionally, the comment is specific in that it highlights a concern about the performance gains being less than 1%, which could be useful for the authors to address. However, without grounding, the authors are left without a clear understanding of where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, as the difference between the baseline and the best approach is less than 1% on most metrics. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or comparisons to other works, the authors may find it difficult to assess the validity of the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% on most metrics. This observation highlights a concern that the authors may need to address to improve the significance of their results. However, the comment does not provide specific suggestions or guidance on how to enhance the performance or address this issue. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful. The authors would need to infer what steps to take to address the concern, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. While it prompts the authors to consider the value of this information, it does not provide explicit guidance on how to address this question or what actions should be taken. The comment is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. Additionally, it lacks specificity in detailing what information is being questioned or how it should be evaluated. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, lacking any assertion or guidance that would need to be substantiated. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. This question is relevant as it seeks to understand the value of the information provided in the feedback. However, the comment does not offer any suggestions or guidance on how to address this question or what actions the authors should take to improve their draft. While it identifies an area for improvement, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to make the submission stronger. However, it does not provide explicit instructions on how to add standard deviations to the table or how to make the experiments more extensive. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of standard deviations and the need for more extensive experiments. This provides clear guidance on how to improve the submission. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 does not show standard deviations and suggests that including them would make the submission stronger. However, the comment lacks specific examples or references to support the claim about the importance of standard deviations in strengthening the submission. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also suggests that the experiments should be more extensive to strengthen the submission. While the comment points out a clear area for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made to the experiments. The feedback is somewhat helpful as it highlights important aspects that need attention, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. While it identifies a potential issue with the current analysis, it does not provide explicit guidance on how to address this concern or what actions the authors should take. The comment is somewhat vague, as it leaves the authors to infer the need for further investigation or experimentation. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance boost due to additional parameters, referencing specific tables (Tab 1, 2, 3) and a baseline comparison with [14]. It questions whether a better Unary baseline might still yield a performance boost. However, the comment does not explicitly mention which part of the paper these tables or the baseline comparison are located in, making it weakly grounded. The comment is specific in detailing the issue with the performance boost and the comparison with the baseline, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references specific tables (Tab 1, 2, 3) and a baseline comparison with [14]. However, the comment lacks detailed reasoning or examples to fully support the claim that the performance boost is questionable. While it provides a basis for questioning the results, it does not offer a comprehensive explanation or evidence to substantiate the concern. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether a better Unary baseline might still yield a performance boost. It references specific tables (Tab 1, 2, 3) and a baseline comparison with [14], which suggests that the current analysis might be flawed. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what experiments could be conducted to clarify the performance boost. While it identifies a potential area for further investigation, it lacks actionable advice or specific recommendations, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is hard to follow and requires multiple reading passes for some sections. It recommends improving the structure, specifically the introduction, method, and experiments sections, and to put more focus on the IEM in Figure 3. Additionally, it suggests improving the visualization of Figures 7 and Figure (which is incomplete). However, the comment does not provide explicit guidance on how to improve the structure or the figures, leaving the authors to infer the necessary actions. The suggestions are somewhat vague and lack concrete details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is hard to follow and requires multiple reading passes for some sections, implying that the authors need to improve the structure. It recommends improving the structure, specifically mentioning the introduction, method, and experiments sections. However, it does not specify which parts of these sections need improvement or how to achieve this. The comment also suggests focusing more on the IEM in Figure 3, which is a specific part of the paper, but it does not provide detailed guidance on how to improve the visualization of Figures 7 and Figure. Therefore, the comment is weakly grounded as it does not fully identify the parts of the paper that need improvement, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper is hard to follow and requires multiple reading passes for some sections, implying that the structure could be improved. It recommends improving the structure, specifically mentioning the introduction, method, and experiments sections. However, the comment does not provide specific examples or detailed reasoning to support the claim that the structure needs improvement. Additionally, it suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure, but it lacks detailed guidance on how to achieve these improvements. Without concrete examples or detailed reasoning, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary depth to fully substantiate the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper's readability, noting that several sections require multiple reading passes. It suggests improving the structure, specifically mentioning the introduction, method, and experiments sections, and recommends focusing more attention on the IEM in Figure 3, which the authors consider the main figure. Additionally, the comment suggests improving the visualization of Figures 7 and Figure, but it lacks specific details on how to achieve these improvements. While the feedback points out areas for potential enhancement, it does not provide detailed guidance or suggestions for improvement, making it somewhat helpful. The comment offers a general direction but could be more actionable with additional details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. This comment provides an explicit action for the authors to take, which is to expand the related work section. However, it lacks specific guidance on how to achieve this, such as suggesting particular aspects to compare or discuss. The action is clear and direct, but it is somewhat vague in terms of implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this suggestion is intended for, making it weakly grounded. The comment is specific in its suggestion to enhance the related work section, but without clear guidance on which part of the paper it should be applied to, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. This feedback is somewhat helpful as it identifies a potential area for improvement, which is to enhance the depth and comprehensiveness of the related work section. However, the comment lacks specific guidance on how to achieve this, such as suggesting particular aspects to compare or discuss. Without more detailed suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be conducted on other architectures and classification tasks beyond neural networks and image classification. While it implies that the authors should consider expanding their experiments, it does not provide explicit guidance on which specific architectures or tasks to include. The action is implicit and somewhat vague, as the authors are left to infer the exact nature of the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be conducted on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which architectures or tasks should be included, nor does it provide any guidance on how to approach this expansion. The authors are left to infer the specific areas that need attention, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail the potential benefits or challenges of expanding the experiments. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the experiments should be conducted on other architectures and classification tasks beyond neural networks and image classification. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments should be conducted on a broader range of architectures and classification tasks beyond neural networks and image classification. This feedback is somewhat helpful as it identifies a potential area for expansion that could enhance the paper's scope and impact. However, the comment lacks specific guidance on which architectures or tasks to include, making it somewhat vague and incomplete. The authors would need to infer the exact nature of the suggested improvement, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the final learning rates used for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. It also notes that the authors only searched four different learning rates, suggesting that the optimal learning rate for the baseline might be outside the tested interval, potentially affecting the results. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the robustness of their results. The action is implicit and vague, as it does not specify how the authors should determine the final learning rates or how they should address the concern about the tested interval. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not detail what needs to be addressed regarding the learning rates or the potential impact of the tested interval. Without explicit references or detailed guidance, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the final learning rates used for the deep models, particularly CIFAR-10 and CIFAR-100. It notes that the authors only searched four different learning rates, which could potentially affect the results if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not provide any specific reasoning, examples, or references to support the claim that this could be a problem. Without additional context or evidence, the authors may find it challenging to understand and address the concern raised in the comment. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or supporting details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the final learning rates used for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. It notes that the authors only searched four different learning rates, which could potentially affect the results if the optimal learning rate for the baseline is outside the tested interval. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the robustness of their results. While it identifies a potential concern, it lacks actionable advice or detailed feedback, making it barely helpful. The authors would need to infer how to improve their draft based on this feedback, which limits its usefulness.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the authors' choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions in the context of limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in transformers is not a concern. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the model or data need to be clarified. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the suitability of using a transformer model without locality bias, questioning whether it is the best option given the nature of neighborhood interactions and limited information propagation. However, the comment does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the issue needs to be addressed. While the comment is specific in its critique of the model choice, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the authors' choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions and limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in transformers is not a concern. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that transformer models without locality bias are indeed the best option. Without additional context or evidence, the claim remains speculative and difficult to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the suitability of using a transformer model without locality bias, questioning whether it is the best choice given the nature of neighborhood interactions and limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in transformers is not a concern, which is a pertinent point for discussion. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what aspects of their model or data need clarification. While it identifies an important issue, the feedback could be more helpful if it provided actionable advice or examples to guide the authors in refining their approach. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer detailed guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the output of the algorithm depends on the order of data processing and suggests that this dependency should be clarified. While the comment explicitly states the issue and provides a clear action\u2014clarifying the dependency\u2014it does not offer specific guidance on how to clarify this dependency. The authors are left with the task of determining what aspects of the algorithm's output are affected by the data processing order and how to address this. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the output of the algorithm depends on the order in which the data are processed and recommends clarifying this dependency. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification, but without a reference to a specific section or part of the paper, the authors may find it challenging to locate the relevant section. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output of the algorithm depends on the order in which the data are processed and suggests that this dependency should be clarified. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this dependency is important or how it should be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the algorithm's output, specifically that it depends on the order of data processing. This observation is clear and highlights a potential area for clarification. However, the comment lacks specific guidance on how to address this issue or what aspects of the algorithm's output are affected by the data processing order. While it points out a potential area for improvement, it does not provide actionable steps or suggestions for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the model's overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify the impact of these strategies. The comment implies that the authors should consider the trade-off, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is not actionable, as it does not provide clear guidance on how to improve the draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the mitigation strategies aimed at reducing memorization and their potential impact on the model\\'s overall performance. However, it does not specify which part of the paper discusses these mitigation strategies or how they are implemented. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in that it highlights a potential trade-off between reducing memorization and maintaining performance, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the model\\'s overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it hints at a concern but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the impact of mitigation strategies on the model\\'s overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. It highlights that if these strategies significantly impair the model\\'s utility, it might deter their adoption. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments or analyses could be conducted to clarify the impact of the mitigation strategies. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, noting that other comparable papers did not employ it. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the reasoning behind their choice. The action is implicit, as the authors would need to infer that they should explain the rationale for using 6-fold cross-validation. The comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of 6-fold cross-validation, questioning its necessity and noting that other comparable papers did not use it. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the rationale behind the choice of cross-validation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, suggesting that other papers did not employ it. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the choice of cross-validation. Without detailed justification or evidence, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of explanation for the use of 6-fold cross-validation, particularly in comparison to other papers that did not employ it. This feedback highlights a potential gap in the paper's reasoning and could help the authors clarify their methodology. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as explaining the rationale behind the choice of cross-validation or comparing it to other methods. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the proposed approaches only outperform the baselines in one out of three setups, and there is no consistent trend in the results. It suggests that the results are insufficient to prove the benefits of the proposed methods and recommends additional experiments or more in-depth analysis. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments or perform more detailed analysis to strengthen the paper. The comment is concrete, as it specifies exactly what needs to be done to improve the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend, making the results insufficient to prove the benefits of the proposed methods. The comment suggests that additional experiments or more in-depth analysis are necessary to better justify the claims, providing clear guidance for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It provides specific evidence, such as the fact that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This detailed explanation supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional context or examples to further substantiate the claim. Overall, the feedback is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This observation is significant because it questions the sufficiency of the current results to support the claims made in the paper. The comment suggests that additional experiments or more in-depth analysis are necessary to better justify the benefits of the proposed methods. This feedback is clear, actionable, and provides a clear direction for the authors to improve their draft by conducting further experiments or analysis. Therefore, the comment is highly helpful, as it offers specific and constructive guidance for enhancing the paper\\'s claims and results.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the effectiveness of the proposed engineering method for ReC and notes the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. While the comment identifies an area for clarification, it does not provide explicit guidance on how to address this request or what specific aspects of the heuristic components need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the impact of these components. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Non-Ambiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for clarification regarding the impact of heuristic components, particularly the sophisticated filtering template used in this procedure. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. While the claim is based on the observation of the method's components, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the basis of the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the effectiveness of the proposed engineering method for ReC but highlights the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. This feedback is somewhat helpful as it identifies a specific area where the authors could provide more detail or explanation. However, the comment could be more helpful if it offered suggestions on how to address the request for clarification or provided examples of how these components impact the overall method. Without additional guidance, the authors may struggle to fully understand and address the feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the proposed method's ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. While the comment highlights a potential issue with the method's reliance on camera information, it does not provide explicit guidance on how to address this concern or suggest any specific actions the authors should take. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the proposed method's ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. It references a specific line (223) in the paper, which suggests that the authors can accurately identify the part of the paper being addressed. However, the comment does not specify what needs to be addressed in this part, such as suggesting alternative approaches or providing additional details. Therefore, the comment is weakly grounded but not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses doubt about the proposed method's ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. The comment highlights a potential issue with the method's reliance on camera information, but it does not provide any supporting evidence, examples, or references to substantiate the claim. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the proposed method's reliance on camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. This feedback highlights a potential limitation or area for improvement in the method's implementation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what alternative approaches could be considered. While it identifies a weakness, it does not provide actionable advice or detailed insights to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer comprehensive guidance for resolution.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not provide explicit guidance on how to achieve this detailed comparison or what specific aspects of the comparison should be emphasized. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be made or which sections of the related work are relevant. The comment is weakly grounded as it does not provide specific guidance on where to make the comparison, and it is specific in terms of the suggested improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically in terms of time complexity and competitiveness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand how to incorporate this comparison into their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. This feedback is somewhat helpful as it identifies a specific area for improvement, but it lacks depth and does not provide detailed guidance or suggestions on how to achieve this comparison. The authors would need to infer the necessary steps to incorporate this feedback into their draft, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, it does not provide explicit instructions or detailed guidance on how to implement this clarification. The action is implicit, as the authors need to infer that they should elaborate on the improvements of their method over ODA. While the comment is somewhat actionable, it lacks concrete details on how to achieve this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ODA,\" which is a specific method used in the context of solving the MOIP problem. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity on how the presented method improves performance and computation speed compared to using ODA. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs further explanation. However, the comment could be more helpful if it provided additional guidance on how to improve the clarity of this explanation or suggested specific areas where the authors could elaborate. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but lacks some depth in terms of actionable suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some figures are not self-explanatory, specifically mentioning Figure 4 where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. While the comment identifies a specific issue with the figures, it does not provide explicit guidance on how the authors should improve the figures to make them self-explanatory. The authors are left to infer that they need to add more detailed explanations or labels to the figures. This lack of explicit guidance makes the action somewhat vague and leaves the authors uncertain about the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the figure, noting that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This provides the authors with a clear understanding of what needs to be addressed to improve the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some figures are not self-explanatory, specifically mentioning Figure 4 where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. While the comment identifies a specific issue with the figures, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the exact nature of the problem and how it needs to be addressed. This makes the claim somewhat verifiable, as it provides a basis for improvement but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures, noting that some figures, such as Figure 4, are not self-explanatory. It provides a concrete example, stating that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback is actionable as it directs the authors to improve the clarity and self-explanatory nature of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the figures, such as adding more detailed labels or explanations. Overall, the comment provides a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of the sampling method for convergence to the optimum but notes that this aspect is not experimentally evaluated beyond a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to conduct a more thorough experimental evaluation or what specific aspects of the sampling method should be explored. The action is implicit and somewhat vague, as the authors are left to infer how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the importance of the sampling method for convergence to the optimum, noting that it is not experimentally evaluated carefully on the proposed benchmarks, except for Tab. 1 in the supplementary material, which compares it to sampling from a uniform distribution. However, the comment does not specify which part of the paper discusses the sampling method or the benchmarks used, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of sampling, it lacks grounding as it does not provide clear references to the relevant sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum but notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for Tab. 1 in the supplementary material, which compares it to sampling from a uniform distribution. The comment provides some evidence by mentioning the comparison to uniform sampling, but it lacks detailed reasoning or references to support the claim that the sampling method is crucial for convergence. Without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experimental evaluation of the sampling method, noting that it is not thoroughly evaluated beyond a comparison to sampling from a uniform distribution. This feedback is somewhat helpful as it highlights an area where the authors could strengthen their experimental design and analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct a more comprehensive evaluation of the sampling method's impact on convergence. Without detailed recommendations, the authors may struggle to address the feedback effectively, making the comment somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. The comment implies that the authors should provide a clearer explanation of the logic and comparisons, but it does not offer specific guidance on how to address these issues. The feedback is somewhat actionable as it identifies areas for improvement, but it lacks concrete suggestions or detailed guidance on how to implement the changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the logic and comparisons between the proposed method and specific references [9] and [16]. It also questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. However, the comment does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questioning of the rationale and comparisons, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. However, the comment does not provide any specific examples, reasoning, or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed explanation or evidence makes the claim somewhat verifiable, as the authors may need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to references [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with [9] while omitting [16]. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is a practical issue. While the comment identifies areas for improvement and raises concerns about the clarity and depth of the comparisons, it lacks specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it points out areas that need further clarification and discussion, but it does not provide detailed guidance on how to improve the paper's presentation or content. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. While the comment provides a clear direction for improvement, it does not specify which additional datasets should be used or how the experiments should be conducted. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. However, the comment does not specify which datasets should be used or how the experiments should be conducted, making it weakly grounded. The suggestion is specific in terms of the need for more comprehensive evaluation, but the lack of detail on the datasets or experimental setup makes it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. However, the comment lacks specific details or references to support why these additional experiments are necessary or how they would enhance the evaluation. The suggestion is somewhat vague and lacks depth, making it difficult for the authors to fully understand and implement the recommendation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of experimental results on more datasets. It suggests conducting additional experiments to provide a more comprehensive evaluation of the proposed method, which is a valuable and actionable piece of feedback. The comment also encourages conducting experiments on the full dataset instead of the low-resource regime, further enhancing the depth of the evaluation. However, the comment could be more helpful if it provided specific examples of additional datasets or guidance on how to conduct these experiments. Despite this, the feedback is mostly helpful as it directs the authors towards improving the comprehensiveness of their evaluation.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of clarity in how the generic argument task and the random argument task support the authors' claims, and the cumbersome nature of the dataset transformation and experimental setup. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the tasks or improve the experimental setup. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the clarity of the generic argument task and the random argument task in relation to the authors' claims, as well as the cumbersome nature of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the tasks and the experimental setup, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task did not clearly prove the authors' claims, and that the dataset transformation and experimental setup were cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the lack of clarity in how the generic argument task and the random argument task support the authors' claims, and the cumbersome nature of the dataset transformation and experimental setup. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need clarification, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide explicit guidance on how to address this question or what aspects of the comparison should be explored. The action is implicit, as the authors need to infer that they should compare their PL condition with the one mentioned in the reference. However, the lack of detailed guidance on how to conduct this comparison makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific reference, \"\u00e2\u0080\u009cGlobal Convergence of Arbitrary-Block Gradient Methods for Generalized Polyak-\u00c5\u0081ojasiewicz Functions\u00e2\u0080\u009d, arXiv:1709.03014,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for a comparison of the PL condition used in the paper with the PL conditions proposed in the mentioned reference, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide any specific reasoning, examples, or references to support the claim that such a comparison is necessary or beneficial. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the relevance of the comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. This question prompts the authors to consider the relevance and implications of their chosen PL condition in the context of existing work. However, the comment lacks detailed guidance or suggestions on how to approach this comparison or what aspects of the comparison are important. While it identifies a potential area for improvement, it does not provide actionable advice or insights that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it highlights a relevant area for consideration but does not offer comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of a discussion on the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline [31, 33, *]. However, the comment does not specify how the authors should conduct this analysis or what specific aspects of the computational effort need to be addressed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide this analysis for a fair comparison with the baseline, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a complete lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. This is a crucial aspect that needs to be addressed for a fair comparison with the baseline. However, the comment lacks specific guidance on how the authors should conduct this analysis or what specific aspects of the computational effort need to be considered. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the analysis and provide theoretical evidence. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, but it does not specify which part of the paper this analysis is discussed. The authors cannot confidently determine which section or figure this analysis is related to, making the comment weakly grounded. However, the comment is specific in detailing the issue of the lack of clarity in the analysis and the absence of theoretical evidence, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, noting that the trend is not clear across different model architectures and that no theoretical evidence is provided. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the paper, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It highlights that the analysis is underwhelming, noting that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. This feedback is valuable as it points out a gap in the analysis and suggests that the authors should consider expanding their analysis to include theoretical evidence and explore the correlation across different model architectures. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as recommending additional experiments or theoretical frameworks. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about a potential trap in the experiments conducted in Section 4.2, specifically regarding the use of AutoAugment. It questions whether the policy obtained by supervised training on ImageNet might lead to information leakage. The comment also poses questions about the implications of the authors' conclusion regarding pretraining datasets for linear classification and its relevance to self-supervised learning (SSL) algorithms. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses issues related to the experiments conducted in Section 4.2, specifically regarding the use of AutoAugment as a stronger augmentation strategy. It raises a concern about a potential trap where the policy obtained by supervised training on ImageNet might lead to information leakage. The comment also poses questions about the implications of the authors' conclusion regarding pretraining datasets for linear classification and its relevance to self-supervised learning (SSL) algorithms. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the areas needing attention, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about a potential trap in the experiments conducted in Section 4.2, specifically regarding the use of AutoAugment as a stronger augmentation strategy. It questions whether the policy obtained by supervised training on ImageNet might lead to information leakage. The comment also poses questions about the implications of the authors' conclusion regarding pretraining datasets for linear classification and its relevance to self-supervised learning (SSL) algorithms. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more context or evidence to address the concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about a potential trap in the experiments conducted in Section 4.2, specifically regarding the use of AutoAugment as a stronger augmentation strategy. It questions whether the policy obtained by supervised training on ImageNet might lead to information leakage, which is a critical issue for the validity of the experimental results. The comment also poses questions about the implications of the authors' conclusion regarding pretraining datasets for linear classification and its relevance to self-supervised learning (SSL) algorithms. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. While it identifies an important area for consideration, the feedback is somewhat vague and could be more helpful if it provided actionable advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore how their model works with tabular data, noting that it is another form of multi-modal data. However, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit, as the authors would need to infer that they should conduct experiments or analyses to understand the model's performance on tabular data. The lack of detailed guidance or specific steps makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the use of tabular data as another form of multi-modal data, which is an interesting idea. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore the model's performance on tabular data, but without a clear reference to a specific section or figure, the authors may find it challenging to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that tabular data is another form of multi-modal data and proposes exploring how the model works with it. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should explore how their model performs with tabular data, noting that it is another form of multi-modal data. While the comment identifies an interesting avenue for further investigation, it lacks specific guidance or suggestions on how to approach this exploration. The authors would need to infer that they should conduct additional experiments or analyses to understand the model's performance on tabular data, which limits the comment's helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from low-resourced languages with high-resourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. The action is somewhat vague, as it leaves the authors to infer the exact steps needed to implement the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from low-resourced languages with high-resourced ones. However, the comment does not specify which part of the paper discusses entity representations or where the analysis is lacking. This makes it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific about the type of analysis and the languages to consider, the lack of grounding makes it challenging to fully understand the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It suggests that the authors should add more analysis, visualizations, or case studies for different languages, including language families, and specifically mention the alignment of entities from low-resourced languages with high-resourced ones. However, the comment lacks specific examples or references to support the claim that the analysis is weak. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail or references to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the analysis of entity representations, particularly for language-agnostic characters. It suggests that the authors should provide more analysis, visualizations, or case studies to enhance the understanding of multilingual alignment. Additionally, the comment raises an interesting question about the alignment of entities from low-resourced languages with high-resourced ones, which could be valuable for the authors to explore. While the comment is clear and provides a direction for improvement, it could be more helpful if it included specific examples or suggested methods for analysis. Overall, the feedback is mostly helpful as it offers actionable insights and encourages further exploration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While it provides a direction for improvement, it does not explicitly instruct the authors to include specific details or examples. The action is implicit, as the authors need to infer that they should expand on the use of attention. However, the comment lacks concrete guidance on what aspects of attention should be detailed or how to present them in the appendix. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of more details, but it lacks concrete examples or guidance on what those details should include. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide concrete guidance on what aspects of attention should be detailed or how to present them. The comment is somewhat helpful as it points out a potential enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues or what actions the authors should take to address them. The comment is somewhat actionable as it directs the authors to specific areas of the references list that require attention, but it lacks concrete guidance on how to resolve the identified issues. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issues with the references list, namely the presence of duplicates and the absence of publication venues and years for many papers. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is rated as 5: Fully Grounded and Specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many papers are missing. However, the comment does not provide any specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to verify the accuracy of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it points out these problems, it does not provide any suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it highlights areas that need improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the theoretical analysis presented in Theorem 1, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare the theoretical results with other comparable methods. However, the comment does not provide explicit guidance on how to analyze or compare the results, nor does it offer concrete steps on what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other comparable methods. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare the theoretical results with other comparable methods. However, the comment lacks specific examples or references to support the claim about the lack of clarity or the need for comparison. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it included specific examples or guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to follow, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of the pseudo-code for the proposed method. While it prompts the authors to explain the performance difference, it does not provide explicit guidance on how to address the missing pseudo-code or what steps should be taken to include it. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide the pseudo-code. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, referencing specific works [1] and [2]. However, it does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in its request for clarification and the inclusion of the pseudo-code, but without clear references to the sections or figures, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of the pseudo-code for the proposed method. It references specific works [1] and [2] to support the claim about the performance difference. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the reasoning and provide additional context to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, referencing specific works [1] and [2]. It also points out the absence of the pseudo-code for the proposed method, which is a critical detail for understanding and replicating the research. However, the comment lacks depth and does not provide specific guidance on how the authors might address the performance difference or how to include the missing pseudo-code. While it identifies an important area for clarification, it does not offer actionable steps or suggestions for improvement, making it somewhat helpful. The authors would need to infer the need for additional context and guidance to fully benefit from this feedback.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the improvement of 0.8 in low-resource language translations is insignificant in a practical sense. It also mentions a missing reference, Aghajanyan et al. (2020), which discusses better fine-tuning by reducing representational collapse. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested reference. The action is implicit and vague, as the authors are left to infer that they need to discuss the practical significance of the improvement and include the missing reference. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the use of low-resource language pairs to fine-tune a multilingual model and mentions the method like R3F to maintain generalization ability. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment also highlights that the improvement of 0.8 in low-resource language translations is insignificant in a practical sense and points out a missing reference. This provides some specificity regarding the issue of practical significance and the need for a reference. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of 0.8 in low-resource language translations is insignificant in a practical sense. While the comment provides a specific example of a missing reference, it lacks detailed reasoning or examples to fully support the claim. The absence of a clear explanation or justification makes it difficult for the authors to understand the basis of the claim. Therefore, the comment is barely verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the use of low-resource language pairs in fine-tuning a multilingual model, noting that the improvement of 0.8 is insignificant in a practical sense. It also points out a missing reference, Aghajanyan et al. (2020), which discusses better fine-tuning by reducing representational collapse. While the comment highlights a potential area for improvement and provides a reference, it lacks detailed guidance on how the authors should address the issue or incorporate the missing reference. The feedback is somewhat helpful as it directs the authors to consider the practical significance of their results and to include relevant literature, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what additional experiments could be conducted. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its questioning of the experimental setup but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. However, it does not provide any specific reasoning or evidence to support this claim, leaving the authors without a clear understanding of why this limitation exists. The comment lacks detailed justification or examples, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. This feedback highlights a potential gap in the experimental validation and encourages the authors to provide a clearer explanation for their choice of noise type. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to strengthen the paper. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable value, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods. It implies that this visualization is crucial for supporting the research motivation of the paper. However, the comment does not provide explicit guidance on how to create the visualization or what specific aspects of the visualization should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods, which is important for supporting the research motivation of the paper. However, the comment does not specify which part of the paper this visualization should be included in, making it weakly grounded. It is specific in suggesting the need for visualization, but the lack of explicit mention of a particular section or figure makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. This is a logical assertion based on common knowledge in machine learning, where higher dimensionality can lead to increased complexity and potential performance degradation. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to provide evidence or references to substantiate this claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors' claim regarding the performance decline of PU learning methods with increasing data dimensionality. It suggests that visualizing this effect would be beneficial for supporting the research motivation of the paper. While the comment highlights an important aspect that could enhance the paper's impact, it lacks specific guidance on how to create the visualization or what aspects of the visualization should be included. This makes the feedback somewhat helpful, as it provides a direction for improvement but does not offer detailed actionable steps. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the empirical version of the objective (3) could be moved to the supplementary materials. This is an explicit action that the authors can take to improve their draft. The comment provides a clear and concrete instruction on where to place the objective, making it actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests moving the empirical version of the objective (3) to the supplementary materials. However, it does not specify which part of the paper this objective is located in, making it difficult for the authors to identify the exact section. While the comment is specific about the action to be taken, the lack of grounding makes it challenging for the authors to understand where to make the change. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be appropriate to put in the supplementary materials. This is a suggestion for improvement, but it lacks specific reasoning or justification for why this placement would be beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the empirical version of the objective (3) could be moved to the supplementary materials. This is a specific and actionable suggestion that could help the authors improve the organization and presentation of their work. By providing a clear direction for where to place the objective, the comment offers valuable guidance for the authors to enhance the clarity and structure of their paper. However, the comment could be more helpful if it included additional reasoning or examples to support the suggestion. Overall, the comment is mostly helpful as it provides a clear and actionable piece of feedback.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication and the importance of checking for meaningful communication. However, the comment does not provide explicit guidance on how to simplify the descriptions or what specific changes should be made. The suggestions are somewhat vague and lack concrete details, making it challenging for the authors to implement them effectively. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication and the importance of checking for meaningful communication. However, the comment does not specify which part of the paper contains these convoluted descriptions, making it difficult for the authors to pinpoint the exact areas that need improvement. While the suggestions are somewhat specific, the lack of grounding makes it challenging for the authors to understand which sections to focus on. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication and the importance of checking for meaningful communication. However, the comment lacks detailed reasoning or examples to fully support its claims, making it somewhat verifiable. The suggestions are somewhat vague and could benefit from more specific guidance or examples to enhance their verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It offers suggestions for improvement, such as referencing related work on speaker-listener communication and the importance of checking for meaningful communication. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to simplify the descriptions or what specific changes should be made. While it offers a starting point for improvement, the feedback could be more actionable and comprehensive to fully assist the authors in enhancing their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the definition of approximation error is ambiguous and could be better clarified by providing a mathematical characterization. While the comment implies that the authors should provide a mathematical characterization, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to add a mathematical characterization. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the definition of approximation error is ambiguous and could be better clarified by providing a mathematical characterization. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the need for a mathematical characterization, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the definition of approximation error is ambiguous and suggests that it would be better to provide a mathematical characterization. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the definition is ambiguous or how a mathematical characterization would address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous and could be clarified with a mathematical characterization. This feedback is specific and actionable, as it suggests a concrete way to improve the clarity and precision of the paper. By recommending a mathematical characterization, the authors are provided with a clear direction for enhancing the presentation of their work. However, the comment could be more helpful if it included examples or further elaboration on how to implement the mathematical characterization. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific claim about Corollary 10, stating that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is explicit and provides a clear action for the authors to consider, as they need to address the implications of this observation. However, the comment does not offer specific guidance on how to improve the draft or what aspects of the argument need to be revised. The action is clear and direct, but it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 180--182,\" which allows the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the claim that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what aspect of the paper requires attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This claim is based on a logical reasoning argument, as it highlights a specific aspect of the corollary that might be misinterpreted. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from a more detailed explanation or examples to clarify the reasoning behind the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Corollary 10, noting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is clear and actionable, as it highlights a potential misunderstanding or gap in the interpretation of the corollary. However, the comment could be more helpful if it provided additional context or suggestions for how the authors might address this issue. Overall, the comment is somewhat helpful, as it provides a clear point of improvement but lacks depth in its guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific issues with the proposed model, noting that it produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also points out that the model is simplistic, as it only changes edges with the average cluster size of one node. However, the comment does not provide explicit or implicit suggestions on how to address these issues or improve the model. The authors are left without guidance on how to enhance the model\\\\'s dynamics or complexity. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed model and its behavior, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue with the model\\\\'s dynamics, noting that it produces only one node changing cluster per time step due to a reassignment probability of 1/n. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also states that the model is simplistic because it only changes edges with the average cluster size of one node. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with the proposed model, noting that it produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also points out that the model is simplistic, as it only changes edges with the average cluster size of one node. While the comment highlights these weaknesses, it does not provide actionable suggestions or guidance on how to address these issues or improve the model\\\\'s complexity. The feedback is somewhat helpful as it points out areas for improvement, but it lacks depth and specific recommendations, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide details about the division of the dataset into training and testing sets, including the numbers used and the method of division. It specifies that the division should be explained, whether it was random or based on other considerations. This provides clear and concrete guidance on what information is missing and how it should be addressed. The authors know exactly what additional details they need to include to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for details about the division of the dataset into training and testing sets, which is a specific part of the paper. It specifies what information is missing, such as the numbers used and the method of division, which helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information regarding the division of the dataset into training and testing sets. It does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'No', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their draft by providing more details about the division of the dataset into training and testing sets. It requests information such as the numbers used and the method of division, which could be random or based on other considerations. This feedback is clear and actionable, as it directly points out a missing element that would enhance the transparency and reproducibility of the research. By addressing this comment, the authors can significantly improve the clarity and completeness of their paper. Therefore, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive if it suggested specific ways to present the information.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing guidance on how to address these issues. The feedback lacks concrete steps or suggestions, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique of the need for human labor and the scalability issue, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or detailed explanations, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific suggestions or actionable feedback on how to address these issues. While it identifies potential areas for improvement, it does not provide detailed guidance or examples for the authors to consider. As a result, the feedback is somewhat helpful, as it highlights important concerns but does not offer comprehensive advice for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the significance of the performance improvement of the proposed methods, specifically noting that the improvement in the bank dataset is only ~0.02. It also suggests that using tables to directly show key improvements would be more intuitive and detailed. While the comment identifies a potential issue with the presentation of results, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit, as the authors would need to infer that they should consider using tables to present the results more clearly. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the significance of the performance improvement and the suggestion to use tables for better presentation. This provides clear guidance on how the authors can improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance improvement of the proposed methods is not significant, as evidenced by the ~0.02 improvement in the bank dataset. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or supporting details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the significance of the performance improvement of the proposed methods, specifically noting that the improvement in the bank dataset is only ~0.02. It also suggests that using tables to directly show key improvements would be more intuitive and detailed. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to address the issue or what specific changes should be made to the draft. The suggestion to use tables is somewhat actionable, but the comment could be more helpful if it provided more detailed advice on how to present the results effectively. Overall, the comment is somewhat helpful, as it offers a clear direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the experimental validation, including the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their experimental validation or positioning, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental validation of the paper, specifically mentioning the limitation of considering only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific because it details the issues with the experimental validation and positioning. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental validation is not convincing, citing the limited depth of the networks considered (2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, specifically the consideration of layer redundancy in the context of network pruning, providing a specific example. The claim is somewhat verifiable as it provides some justification for the criticism, but it lacks detailed reasoning or references to support the specific issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the experimental validation of the paper, specifically noting the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. While the comment highlights these areas for improvement, it does not offer detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas for enhancement but lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or proof to support this claim. It also does not suggest any specific actions or improvements that the authors should take to address this issue. The comment lacks explicit guidance on how the authors might address the lack of theoretical results, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this work,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely the lack of new theoretical results. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or proof to support this claim. The comment lacks specific examples or references to substantiate the assertion that the work does not prove any new theoretical results. Without supporting evidence, the claim remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically that the use of a particular type of loss in a specific setting might be new, but the work does not provide any new theoretical results. This feedback highlights a gap in the paper's contribution and suggests that the authors should consider exploring or discussing the theoretical implications of their findings. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional theoretical analysis could be included. While it points out a potential area for improvement, it does not provide detailed actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the data and proposes that human test results might support it. However, it does not provide explicit guidance on how the authors should test this hypothesis or what evidence they should present to either prove or disprove it. The comment lacks concrete steps or detailed instructions on how to implement the suggested action, making it somewhat actionable. The authors are left with a vague idea of what to do but no clear direction on how to proceed. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not provide detailed guidance on what evidence should be presented to either prove or disprove the hypothesis. Without explicit references to sections or detailed instructions, the authors cannot confidently understand the scope of the feedback. Therefore, this comment is rated as 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data and suggests that human test results might support it. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to evaluate the claim independently, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data, suggesting that the \"trivial\" part might be highly consistent with the training set, while the \"impossible\" part might involve ambiguous labels or atypical object poses. The comment questions whether the authors could provide more evidence to either prove or disprove this hypothesis, which is a valuable suggestion for improving the paper. However, the comment lacks specific guidance on how to conduct this evidence collection or analysis, leaving the authors with a general idea of what to do but no detailed steps. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not provide comprehensive guidance. The score is 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning Task 1. While it implies that the model should be tested on other tasks, it does not provide explicit instructions or suggestions on how to conduct this additional testing. The action is implicit, as the authors need to infer that they should test the model on other tasks within the bAbI dataset. However, the comment lacks concrete guidance on which tasks to test or how to implement this additional testing. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"bAbI,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the testing of the model on only a single supporting fact dataset (Task 1 of bAbI) and asks about testing on other tasks. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning Task 1. It does not contain any subjective opinions, claims, or suggestions that require verification. The comment is purely factual and descriptive, aligning with the classification of \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning Task 1. While it identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how to test the model on other tasks or what those tasks might be. The comment lacks actionable advice, making it somewhat helpful as it highlights a potential area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that it is difficult for the authors to follow Section 3.2 and suggests that they may improve it by providing more illustrations and examples. While the comment explicitly suggests an action\u2014improving the section and providing additional illustrations and examples\u2014it does not specify how the authors should go about improving the section or what kind of illustrations and examples would be most helpful. The action is clear and direct, but the lack of detail on how to implement it makes it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it is difficult for the authors to follow Section 3.2 and recommends improving it by providing more illustrations and examples. However, it does not specify which part of Section 3.2 is particularly challenging to follow, nor does it provide any guidance on what kind of illustrations or examples would be most helpful. The comment lacks grounding as it does not allow the authors to pinpoint the specific section or part that needs improvement. It is also not specific because it does not offer detailed suggestions or examples for improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is difficult to follow Section 3.2 and suggests that the authors may improve it by providing more illustrations and examples. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the difficulty or how to address it. Without additional context or evidence, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that Section 3.2 is difficult to follow. It suggests that the authors may improve the section by providing more illustrations and examples. While the comment highlights a potential area for improvement, it lacks depth and specificity. It does not offer detailed guidance on what kind of illustrations or examples would be most beneficial, nor does it suggest alternative approaches to enhance clarity. As a result, the feedback is somewhat helpful, as it provides a general direction for improvement but does not fully address the authors' needs for enhancing the clarity of the section. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any specific suggestions or guidance on how the authors might address this limitation or enhance their work. The authors are left without a clear understanding of what needs to be done to improve the technical contribution of their paper. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the technical contribution are limited or how the authors might address this limitation. Without specific references or details, the authors cannot effectively respond to the comment. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, the comment lacks specific details or examples to support this claim. It does not provide any references or evidence to substantiate the assertion that the technical contribution is limited. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the lack of technical contribution and extension based on a typical model for the cross-domain recommendation setting. This feedback is clear and actionable, as it highlights a critical area where the authors could enhance their work. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this limitation or propose potential extensions. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement, allowing them to focus on enhancing the technical contribution of their paper. Therefore, the comment is rated as mostly helpful, corresponding to a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion by adding the baselines to the table. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be added to the table to improve understanding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to support the claim. The authors would need to infer the need for such baselines to enhance the understanding of the gap. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their draft by including additional baselines. By adding these baselines, the authors can gain a more comprehensive understanding of the performance differences between fully supervised and SSL approaches. This feedback is valuable and directly addresses a potential area for improvement in the paper, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as exploring alternative methods or optimizations. While the action is implied, it is vague and lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the time complexity of the proposed algorithm, specifically mentioning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, suggesting that it might make the algorithm impractical for such problems. However, the comment does not specify which part of the paper discusses the algorithm or the hypervolume calculation, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue of time complexity, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical for such problems. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the computation of hypervolume is time-consuming or impractical. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical for such problems. While the comment identifies a potential weakness in the algorithm's efficiency, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate such results. The action is implicit, as the authors can infer that they need to consider adding results on larger datasets, but the lack of concrete details makes the comment somewhat actionable. Therefore, this comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of the dataset used in the experiments being small, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to include results on medium or large datasets, such as ImageNet, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the dataset size is a concern or how it impacts the overall quality of the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the experiments, noting that they are all very small. It suggests that including results on medium or large datasets, such as ImageNet, would make the findings more convincing. While the comment highlights a valid concern, it does not provide specific guidance on how the authors might address this issue or what additional experiments could be conducted to strengthen their results. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only marginally helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should delve deeper into the limitations of evolutionary methods, specifically mentioning the importance of leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise when being critical. The comment further asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. While the comment provides several suggestions for improvement, it lacks explicit guidance on how to implement these suggestions or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should explore deeper aspects of evolutionary methods, such as leveraging state, reactiveness, and learning during an episode. It critiques the title as being too generic and suggests that the authors should be more precise when being critical. The comment also asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance on what aspects to explore but lacks detailed instructions on how to do so. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the paper for being too generic and vague, particularly in its title. It suggests that the authors should be more precise when being critical and provides examples of areas that could be explored further, such as the limitations of evolutionary methods and the adoption of DeepRL methods. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis for the critique, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the paper for being too generic and suggests that the authors should be more precise in their critical analysis. It provides specific examples, such as the need to explore deeper aspects of evolutionary methods, like leveraging state, reactiveness, and learning during an episode. The comment also suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago, which could provide valuable context. However, the feedback lacks detailed guidance on how to implement these suggestions or what specific actions the authors should take to address the identified weaknesses. While the comment offers some direction, it could be more helpful with additional actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. While the questions are explicit and direct, they do not provide concrete guidance on how the authors should address these issues. The authors are left with a clear understanding of what needs to be clarified or explained but lack specific instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on implementation. This aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. However, it does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the questions are specific about the methodology, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. These questions are factual and descriptive, as they seek clarification on specific aspects of the methodology. However, they do not contain subjective opinions or claims that require verification. Therefore, the comment is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. These questions are clear and direct, providing the authors with specific areas to clarify and improve their methodology. However, the comment lacks suggestions or guidance on how to address these issues or what improvements could be made. While it identifies areas for improvement, it does not offer detailed feedback or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not specify how this justification should be presented or what kind of empirical evidence would be most effective. While it implies a need for additional data or analysis, the action is not explicit or concrete, leaving the authors uncertain about how to implement the suggested improvement. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed guidance on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first claimed contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, suggesting that there should be empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical justification for the first claimed contribution, which is that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the lack of empirical justification for the first claimed contribution. It points out that the claim about the proposed algorithm not taking as many points or not needing apriori knowledge about dimensions of subspaces is not supported by empirical evidence. This feedback is valuable as it directs the authors to strengthen their claims by providing empirical validation. However, the comment could be more helpful if it suggested specific ways to conduct the empirical analysis or provided examples of how to present the evidence. Overall, the comment is somewhat helpful as it highlights an important area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the components of the approach are not novel, as they have been used in previous works. It mentions specific examples of weak predictors (MLP, Regression Tree, Random Forest) and sampling strategies that are similar to existing methods. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to enhance the novelty of their approach. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the approach by pointing out that the weak predictors used (MLP, Regression Tree, Random Forest) and the sampling strategy are similar to existing methods. It references specific works [2, 3, 7] and [5] to support the claim. However, the comment does not specify which part of the paper discusses the approach or the results in Table 2 of Appendix C. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak predictor components used in the approach are not novel, as they have been used in previous works [2, 3, 7]. It also notes that the sampling strategy is similar to epsilon-greedy and exactly the same as that in BRP-NAS [5]. The comment references specific works to support these claims, providing a basis for verification. However, the comment could be more robust by explicitly detailing how the components are similar to existing methods or by providing more specific examples of the overlap. Despite this, the claim is mostly verifiable as it is supported by references and logical reasoning, but it lacks some depth in explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the approach, specifically pointing out that the weak predictors used (MLP, Regression Tree, Random Forest) and the sampling strategy are similar to existing methods. It references specific works [2, 3, 7] and [5] to support these claims, providing a clear basis for the authors to understand the lack of novelty. However, the comment could be more helpful if it suggested specific ways the authors could differentiate their approach or enhance its novelty. While it highlights a critical area for improvement, the feedback is somewhat limited in its actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), which limits the novelty of the paper. It recommends that the authors provide a sufficient discussion on the comparison with RMED. However, the comment does not specify how the authors should address this similarity or what aspects of the comparison need to be elaborated upon. The action is implicit and vague, as it does not provide concrete guidance on how to improve the discussion or what specific comparisons should be made. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed S1DB-ED algorithm\" and \"RMED (Komiyama et al. 2015)\", allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of similarity between the two algorithms and recommends a sufficient discussion on the comparison. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), limiting the novelty of the paper. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed S1DB-ED algorithm, noting its similarity to RMED (Komiyama et al. 2015). This feedback is valuable as it highlights a need for a more thorough discussion of the comparison between the two algorithms. However, the comment lacks specific guidance on how the authors should address this similarity or what aspects of the comparison require further elaboration. While it points out a potential weakness, it does not provide actionable steps or detailed suggestions for improvement, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which aspects of the discussion are missing or what specific areas need to be addressed. The comment lacks explicit guidance on how the authors should expand their discussion or what specific details are missing. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the paper requires a more thorough discussion of prior work. This lack of specificity makes it difficult for the authors to address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the extent of the issue or how to address it. Without detailed examples or references, the claim is unverifiable, as the authors cannot determine the basis for the criticism. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the lack of a comprehensive discussion of previous work on the topic. This feedback is valuable as it highlights an area where the authors could enhance the depth and context of their research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending specific studies or methodologies to include. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the OT sample selection process in section 2.4.3, specifically regarding whether it runs once or iteratively with the EP module updates during training. It also asks about the iterative conduct of optimizing the loss of equation (10) and solving OT in equation (3). Additionally, the comment requests more details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment provides explicit questions and requests for clarification, it does not offer concrete suggestions on how to address these issues or improve the draft. The actions are implicit and somewhat vague, as the authors need to infer how to incorporate the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific questions about the OT sample selection process in section 2.4.3, which is fully grounded as it explicitly mentions the section. It also requests more details and a flow chart to clarify the process, which is specific to the topic of OT sample selection. However, the comment does not specify what is missing or needs to be addressed in detail, making it somewhat specific. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the OT sample selection process, specifically whether it runs once or iteratively with EP module updates during training. It also asks about the iterative conduct of optimizing the loss of equation (10) and solving OT in equation (3). Additionally, it requests more details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment provides specific questions and requests for clarification, it lacks detailed reasoning or references to support the claims made. The authors would need to infer the need for more information and a flow chart to fully understand the implications of the questions. Therefore, the comment is barely verifiable, as it provides some guidance but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several important questions about the OT sample selection process in section 2.4.3, specifically regarding whether it runs once or iteratively with the EP module updates during training. It also asks about the iterative conduct of optimizing the loss of equation (10) and solving OT in equation (3). Additionally, the comment requests more details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies a lack of clarity in the description of the OT process, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights areas where the authors could improve the clarity and comprehensiveness of their paper, but it lacks detailed actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the experimental evaluation of the proposed method, specifically noting that while the authors discuss how KG handles continuous tasks, there are no experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks why these are not included in the experiments. The comment requests a comparison of the empirical performance of these methods with ConBO. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to include experiments with continuous tasks and compare the performance of the entropy methods. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental evaluation of the proposed method, specifically noting the absence of experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks for a comparison of their empirical performance with ConBO. However, the comment does not specify which part of the paper discusses continuous tasks or entropy methods, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issue with the lack of experiments and requests additional comparisons. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the absence of experiments with continuous tasks and the lack of comparison of entropy methods for conditional optimization with ConBO. While the comment identifies a gap in the experimental evaluation, it does not provide specific examples or references to support the claim that these methods should be included. The reasoning is somewhat vague, as it lacks detailed justification or evidence for why these methods are important or how their inclusion would enhance the paper. Therefore, the claim is somewhat verifiable, as it is partially supported but lacks depth and clarity.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the experimental evaluation of the proposed method, specifically noting the absence of experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7, and asks for a comparison of their empirical performance with ConBO. This feedback is somewhat helpful as it highlights a specific area where the authors could enhance their work by including additional experiments and comparisons. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific metrics should be used for comparison. Overall, the comment offers valuable insights but lacks depth and actionable suggestions, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison into their work. However, the comment does not specify how to implement this comparison or what aspects of the comparison should be included, making it somewhat actionable. The minor point about the low jailbreaking percentage is not actionable as it does not provide guidance on how to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"other LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of a comparison of the approach with other LLMs, particularly in the context of crafting adversarial prompts and transferring them. The comment is specific in detailing the need for such a comparison, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This claim is somewhat verifiable as it suggests a logical extension of the work, but it lacks specific examples or references to support the idea of such a comparison. The comment does not provide detailed reasoning or evidence to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This provides a clear and actionable direction for the authors to enhance their work by expanding the scope of their analysis. However, the comment lacks specific guidance on how to implement this comparison or what aspects of the comparison should be included, which limits its helpfulness. While it offers a valuable suggestion, the lack of detailed guidance makes it somewhat helpful, as it provides a starting point for improvement but does not fully address the authors' needs. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment highlights a potential area of confusion for the authors, it does not provide explicit guidance on how to address this issue or what specific aspects need clarification. The action is implicit, as the authors are expected to infer that they need to provide a more detailed explanation of the difference between similarity and exit times. However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not provide any specific evidence, reasoning, or references to support the claim or the need for clarification. The comment lacks depth and does not offer a clear path for the authors to address the issue. As a result, the claim is unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the authors' claim regarding unsupervised feature selection from a diffusion perspective, specifically asking for clarification on the difference between similarity and exit times. While the comment identifies a potential area of confusion for the authors, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it highlights a specific point that needs clarification, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. It does not provide explicit instructions or suggestions on how the authors should address this question or what changes might be needed in their draft. The comment implies that the authors should consider discussing the limitations of their framework, but it lacks concrete guidance on how to do so. Therefore, the comment is not actionable, as it does not provide the authors with a clear path forward for improving their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its inquiry about the limitations of the framework, but the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not provide any specific reasoning, examples, or references to support the claim that the framework might not be applicable to these types of formulations. Without additional context or evidence, the authors may find it difficult to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. This question highlights a potential area for further exploration and clarification in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or what changes could be made to their framework. Without actionable feedback or suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and guidance.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made to the draft. The actions are implicit and somewhat vague, as the authors need to infer how to calculate the metrics and incorporate AUC results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density, and suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. However, the comment does not specify which part of the paper discusses the classification of breast density or where the AUC results are reported. This lack of grounding makes it difficult for the authors to identify the specific sections or parts of the paper that need attention. While the comment is specific in its suggestions, the absence of explicit references to the paper's sections or figures makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density and suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment provides a suggestion for improvement, it lacks specific examples or references to support the claim that this approach would be more informative. The authors would need to infer the reasoning behind this suggestion, which could be challenging. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks detailed justification or references.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the methodology used for calculating precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that reporting AUC with sensitivity and specificity at different operating points would be more informative for comparing model performance. While the comment identifies an area for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made to the draft. The feedback is somewhat helpful as it points out a potential area for clarification and improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner than the one created by the authors. However, it does not provide explicit guidance on how the authors should implement this suggestion or what specific actions they should take to utilize the Kialo dataset. The comment implies that the authors should consider using the Kialo dataset as an additional resource, but it lacks concrete steps or examples to guide them. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed guidance on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using the Kialo dataset as an alternative to the one created by the authors, noting its cleanliness and suitability for the study. However, it does not specify which part of the paper discusses the dataset creation or how the authors should incorporate the Kialo dataset. The comment lacks grounding as it does not provide explicit references to sections or figures, making it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while it provides a suggestion, it does not specify what needs to be done to implement this suggestion. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner than the one created by the authors. The comment provides a logical reasoning by highlighting the advantages of using the Kialo dataset, such as its cleanliness and suitability for the study. However, it lacks specific examples or references to support the claim fully. While the reasoning is clear, the absence of detailed examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner than the one created by the authors. It highlights the advantages of using the Kialo dataset, such as its cleanliness and suitability for the study. However, the comment does not provide specific guidance on how the authors should implement this suggestion or what additional steps they should take to utilize the Kialo dataset. While it offers a valuable insight, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction but lacks detailed guidance for the authors to improve their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that the authors' modification, particularly the cross-layer aspect, does not provide significant insight into machine learning. It also notes that the ablation study shows limited improvement from self-cross attention, questioning its significance. While the comment highlights areas for improvement, it does not provide explicit or implicit actions for the authors to take. The authors are left to infer that they should consider the novelty of their approach and the impact of their modifications, but without concrete guidance on how to address these issues, the feedback remains somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the Transformer in the field of NLP and vision, suggesting that it is no longer a novel contribution. It also points out that the authors' modification, particularly the cross-layer aspect, does not bring significant insight into machine learning. The comment further notes that the ablation study shows limited improvement from self-cross attention, questioning its significance. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. It is specific in detailing the issues with the novelty and the limited impact of the self-cross attention, but without clear references, the authors may struggle to identify the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer a novel contribution. It also notes that the authors' modification, particularly the cross-layer aspect, does not provide significant insight into machine learning. The comment further claims that the ablation study shows limited improvement from self-cross attention, questioning its significance. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, and the lack of detailed evidence weakens the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the Transformer in the context of NLP and vision tasks, suggesting that it is no longer a novel contribution. It also points out that the authors' modification, particularly the cross-layer aspect, does not provide significant insight into machine learning. The comment notes that the ablation study shows limited improvement from self-cross attention, questioning its significance. This feedback highlights areas where the authors' work may lack novelty and impact, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as suggesting alternative approaches or expanding the analysis. Overall, the comment is somewhat helpful as it identifies key areas for improvement but lacks detailed actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to their draft. While the authors can infer that they need to expand their experiments and provide sequential results, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses concerns about the limited number of tasks in the experiments and suggests including at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not specify which part of the paper discusses the experiments or tasks, making it weakly grounded. The comment is specific in detailing what the authors should address, such as expanding the number of tasks and providing sequential results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it relates to the paper's content. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. While the comment identifies a potential weakness in the experimental design, it lacks specific guidance on how the authors might address this issue or what changes they should make to their draft. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider conducting experiments on other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a clear and explicit action for the authors to take, which is to expand their experiments to include more types of sentence pair tasks. This guidance is concrete and specific, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitation in the experiments conducted by the authors, specifically noting that they only evaluate sentence similarity and open domain QA tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for additional experiments on other sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This provides a clear direction for the authors to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited, as the authors only conduct evaluations on sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE. While the comment identifies a limitation in the scope of the experiments, it lacks specific examples or references to support the claim that these additional tasks are common or necessary. The suggestion to include more tasks is logical and provides a direction for improvement, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to implement these additional experiments or provided examples of relevant datasets. Despite this, the comment offers valuable guidance and is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prompt should be included in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, it does not provide any explicit or implicit actions for the authors to take, such as where to include the prompt or how to access the supplement. The comment lacks concrete guidance on how to address this issue, making it unactionable. Therefore, the comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, it does not specify which part of the paper the prompt is intended for or how it relates to the content of the paper. The authors cannot confidently determine which section or figure the comment addresses, making it weakly grounded. Additionally, the comment does not provide specific guidance on what needs to be addressed or how to include the prompt effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests including the prompt in the appendix or supplement, noting that it might be in a supplement that the authors cannot access. However, the comment lacks specific guidance on how to include the prompt or what information should be included. It does not provide actionable advice or suggestions for improvement, leaving the authors with limited insight into how to address the issue. As a result, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment identifies a potential gap in the reasoning, it does not provide explicit guidance on how the authors should address this question or what additional analysis might be necessary. The action is implicit, as the authors need to infer that they should provide a clearer explanation for their analysis choice. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable. Therefore, the comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its question about the motivation, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. This is a valid question that could be addressed by providing a clearer explanation of the reasoning behind the analysis choice. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that the analysis is limited to the last layer. Without additional context or justification, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. This question highlights a potential gap in the reasoning or explanation provided in the paper, as it prompts the authors to clarify their analysis choices. By addressing this question, the authors can strengthen the rationale behind their methodology and provide a more comprehensive understanding of their approach. However, the comment could be more helpful if it offered suggestions or guidance on how to address this question or provide additional context. Overall, the comment is somewhat helpful as it identifies an area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the parameter S, suggesting that its setting is a problem. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps should be taken to resolve it. Without specific suggestions or instructions, the authors are left without a clear path forward, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the parameter S, suggesting that its setting is a problem. However, it does not specify which part of the paper discusses the parameter S or provide any context for the issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what needs to be addressed or how the issue can be resolved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the parameter S, suggesting that its setting is a problem. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why setting the parameter S is problematic. This lack of supporting evidence makes the comment unverifiable, as it does not provide a basis for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the parameter S, suggesting that its setting is a problem. However, it lacks specificity and does not provide any guidance or suggestions on how to address this issue. Without additional context or details, the authors are left without actionable feedback on how to improve their work. The comment is vague and does not offer a clear path for the authors to resolve the issue, making it barely helpful. Therefore, the comment is rated as 2: Barely Helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While it implies that human evaluation is a good idea, it does not provide explicit instructions or guidance on how to conduct such an evaluation. The authors are left to infer that they should perform a human evaluation, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. Additionally, the comment is specific in its suggestion to use human evaluation, but without grounding, the authors are left to make an educated guess about where to apply this feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While the comment implies that human evaluation is a better approach, it does not provide specific reasoning or examples to support this claim. The lack of detailed justification or references makes it difficult for the authors to understand why this suggestion is valid. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. This feedback is valuable as it highlights a potential limitation of the current evaluation approach and suggests an alternative method that could provide more reliable results. However, the comment lacks specific guidance on how to conduct a human evaluation or what criteria should be used. While it identifies an important area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers a clear direction but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback provides a clear and explicit action for the authors to consider, as it highlights a potential oversight in the introduction. The comment is specific in identifying the issue with the claim, making it highly actionable. Therefore, this comment aligns with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, the introduction. It is also specific because it clearly specifies what needs to be addressed, namely the potential oversight in the introduction regarding the choice of constraints as a hyperparameter. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is mostly verifiable as it provides a logical reasoning for why the claim might be an oversimplification, highlighting the potential need for tuning these constraints. However, it could be strengthened by providing specific examples or references to support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it identifies a potential oversight in the introduction and suggests that the authors should consider the choice of constraints as a hyperparameter that requires tuning. By highlighting this point, the comment provides the authors with a specific direction for improvement, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the triviality of the convergence proof, suggesting that it lacks substantial novelty and rigor. It provides a specific example of how the proof could be adapted by referencing a modification in the appendix. However, the comment does not explicitly instruct the authors to address this issue or provide detailed guidance on how to improve the proof. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising the proof to enhance its novelty and rigor. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Triviality of Convergence Proof\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, explaining that it lacks substantial novelty and rigor due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is non-i.i.d. The comment provides clear guidance on how the authors might address this issue by referencing a modification in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical proof for convergence is trivial, as it relies on the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is non-i.i.d. The comment provides a specific example of how the proof could be adapted by referencing a modification in the appendix, suggesting that previous theorems can be trivially adapted. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical proof of convergence, noting that it appears trivial due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is non-i.i.d. The comment provides a specific example of how the proof could be adapted by referencing a modification in the appendix, suggesting that previous theorems can be trivially adapted. This feedback is clear and actionable, as it directs the authors to address the lack of novelty and rigor in their convergence proof. However, the comment could be more helpful if it offered additional guidance on how to enhance the proof's depth or novelty. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for more comprehensive guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. The comment suggests that this should be mentioned clearly. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit, as the authors can infer that they need to clarify the experimental setup in the paper. The comment is somewhat actionable because it identifies a specific area that needs attention, but it lacks concrete details on how to implement the suggested change. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"The experimental setup borrowed from [2] is only semi-real,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that multi-node seed cascades are artificially created by merging single-node seed cascades. This provides clear guidance on how the authors should improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This claim is supported by the statement itself, which provides a clear explanation of the issue. However, the comment does not offer additional evidence or references to substantiate this claim, which could enhance its persuasiveness. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks some depth in terms of supporting evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This observation is clear and provides a specific point for the authors to address in their paper. By highlighting this detail, the comment offers a constructive suggestion for improving the transparency and rigor of the experimental setup description. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific ways to improve the clarity of the experimental setup. Overall, the comment is mostly helpful as it identifies a meaningful aspect of the paper that needs attention, but it could be more comprehensive with additional suggestions or guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several limitations in the paper, specifically regarding the limited scope of bias benchmarks and the absence of assessments on state-of-the-art generative models. It points out that the current benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are missing. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific steps they should take to expand their analysis. While the authors can infer that they need to include more diverse biases and datasets, as well as assessments on state-of-the-art generative models, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the bias benchmarks used in the paper, specifically noting that they only assess gender, race, and religion. It also points out the absence of assessments on state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper these limitations are discussed in, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the types of biases and models missing, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are missing. It also notes the absence of assessments on state-of-the-art generative models like GPT. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the feedback. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to conduct further research to confirm the extent of the limitations. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the limited scope of bias benchmarks. It points out that the current benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are missing. Additionally, it notes the absence of assessments on state-of-the-art generative models like GPT. This feedback is somewhat helpful as it highlights areas where the authors could enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these limitations, such as recommending additional datasets or models to include. Without concrete recommendations, the authors may find it challenging to fully utilize the feedback to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict in the paper regarding the performance of the multi-environment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this conflict or clarify the statements. The action is implicit, as the authors need to infer that they should clarify the conflicting claims. The action is vague because it does not specify how to clarify the statements or what aspects of the claims need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the conflicting claims made in the paper about the performance of the multi-environment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not specify which part of the paper these claims are made, making it weakly grounded. The comment is specific in identifying the conflicting claims, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point identifies a potential conflict in the paper regarding the performance of the multi-environment model. It highlights that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this conflict or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential conflict in the paper regarding the performance of the multi-environment model. It points out that the paper claims both an inevitable performance loss and outperformance due to knowledge sharing, which seems contradictory. While the comment highlights this inconsistency, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the conflicting claims. The feedback is somewhat helpful as it directs the authors to a critical area that needs attention, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method is sensitive to hyperparameters and recommends performing a careful hyperparameter search to find a proper $\\alpha$ for a new problem. This provides a clear and explicit action for the authors to take, as they need to conduct a hyperparameter search and adjust the $\\alpha$ value accordingly. The comment is specific in its suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method's sensitivity to hyperparameters, allowing the authors to identify the specific part of the paper being addressed. It also specifies the action needed, which is to perform a careful hyperparameter search to find a proper $\\alpha$ for a new problem. This provides clear guidance on how to apply the feedback, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, suggesting that careful hyperparameter search is necessary to find a proper $\\alpha$ for a new problem. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method's sensitivity to hyperparameters, suggesting that careful hyperparameter search is necessary to find a proper $\\alpha$ for a new problem. This feedback is clear and actionable, providing the authors with a specific direction to improve their method. However, the comment could be more helpful if it offered additional guidance on how to conduct the hyperparameter search or what strategies might be effective. Overall, the comment is mostly helpful as it highlights a critical aspect of the method that needs attention, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation of the metrics or citing the metrics. While the comment implies that the authors should include more details about the metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to expand the description of the metrics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific about the need for more detail on the metrics, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. However, the comment does not provide any specific reasoning, examples, or references to support why this is a desirable improvement. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that the authors should provide an explanation of the metrics or cite the metrics to enhance the clarity and comprehensiveness of the paper. While the comment highlights a potential weakness in the presentation of the metrics, it does not offer detailed guidance on how to improve the description or what specific aspects of the metrics should be elaborated upon. This feedback is somewhat helpful as it points out an area for improvement, but it lacks depth and actionable suggestions, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with Figure 3, such as the clarity of the workflow, captions, and the representation of communication modes. However, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to improve the clarity of the figure, but without specific suggestions or steps, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow, captions, and confusing representation of communication modes. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow, captions, and confusing representation of communication modes. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow, captions, and confusing representation of communication modes. While the comment highlights a clear area for improvement, it lacks actionable guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out a specific area that needs attention, but it does not provide detailed suggestions or steps for improvement, leaving the authors with limited direction on how to enhance the figure. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need clarification. The action is implicit, as the authors would need to infer that they should provide more details or examples to explain the concept. However, the comment lacks concrete instructions on how to implement this suggestion, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SSL pre-training stage of the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear: the meaning of \"learned [MASK] embedding.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely descriptive and does not offer any new information or reasoning that would help the authors understand or address the issue. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the context of the proposed method\\'s SSL pre-training stage. This feedback is clear and actionable, as it highlights a lack of clarity that could hinder the understanding of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the concept. While it points out a potential weakness, it lacks depth and does not offer constructive advice on how to improve the clarity of the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might address the derivative nature of their results or what steps they should take to make their work more original. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, the absence of grounding information limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or references to the specific literature the authors are building upon, the claim remains somewhat verifiable. The authors would need to provide more context or evidence to fully understand the basis of this claim, making it difficult to fully verify. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported results, suggesting that they are partially derivative, extending findings from standard networks to hyper-networks. While this observation is insightful, it lacks actionable guidance or suggestions for the authors to address this concern. The comment does not provide specific advice on how the authors might improve the originality or clarity of their results, leaving the authors without a clear path forward. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment identifies these areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to motivate the applications and consider using streaming datasets. This lack of explicit and detailed guidance makes the comment somewhat actionable, as the authors can deduce the necessary actions but do not have a clear roadmap for implementation. Therefore, the comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper's objective of designing fast label aggregation algorithms for a streaming setting, noting that it lacks motivation for the applications. It also points out that the empirical analysis uses static datasets, which limits the paper's usefulness. However, the comment does not specify which part of the paper discusses the motivation or the datasets used, making it weakly grounded. The comment is specific in identifying the issues with motivation and the use of static datasets, but without explicit references to sections or figures, the authors may need to infer the parts being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting and that the empirical analysis uses static datasets, limiting the paper's usefulness. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two key areas for improvement in the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, leaving the authors with a general idea of what to improve rather than a clear roadmap. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the scope of the study is under-specified, suggesting that the work focuses on injecting a CoT-based approach into small-scale Language Models. It also points out that additional relevant CoT baselines for in-context learning of Large Language Models are missing in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing relevant CoT baselines for in-context learning of Large Language Models, providing a clear direction for improvement. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach into small-scale Language Models. It also points out the absence of additional relevant CoT baselines for in-context learning of Large Language Models in Table 2 and 3, referencing a question for clarification. While the comment identifies a potential issue with the scope and suggests the inclusion of additional baselines, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for additional baselines and potentially revise the scope of the study. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scope of the study, suggesting that it focuses on injecting a CoT-based approach into small-scale Language Models. It also points out the absence of additional relevant CoT baselines for in-context learning of Large Language Models in Table 2 and 3, referencing a question for clarification. This feedback is somewhat helpful as it highlights a potential area for improvement and suggests the inclusion of additional baselines. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested additional relevant baselines. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Figure 3 is difficult to read, but it does not provide any specific guidance or suggestions on how to improve the figure's readability. The authors are left without any actionable steps to take to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 3 is located in, making it difficult for the authors to identify the issue. Additionally, the comment is specific in that it identifies the problem as the difficulty in reading the figure, but without grounding, the authors cannot pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that Figure 3 is \"very hard to read anything on the figure.\" However, it does not provide any specific reasoning or examples to support this claim. Without additional context or explanation, the authors may find it challenging to understand why the figure is difficult to read. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it lacks actionable suggestions or guidance on how the authors might improve the figure's readability. Without specific advice on what aspects of the figure need to be addressed or how to enhance its clarity, the authors are left without a clear path forward. This makes the comment barely helpful, as it points out a problem but does not provide sufficient assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit suggestions on how the authors might address this connection or incorporate it into their work. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the connection between the statement about the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any specific evidence, reasoning, or references to support the claim that this connection is relevant or important. Without additional context or justification, the authors may find it challenging to understand the basis of the comment and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. While the comment identifies a potential area for clarification or further discussion, it does not provide specific guidance or suggestions on how the authors might address this connection or incorporate it into their work. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. While the comment provides a general direction for improvement, it lacks specific guidance on which parts of the GAT training process need to be addressed or how the rewriting should be done. The authors are left with a broad understanding of what needs to be done but without concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"245,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences need rewriting for clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. However, the comment lacks specific details or references to support these claims. It does not provide any evidence or reasoning to justify why the GAT is trained with the whole model or why it needs to be reviewed by an English native speaker. Without this additional information, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the GAT training process, noting that it is trained with the whole model. It also suggests that the paper needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. While the comment points out a potential area for improvement, it lacks detailed guidance on how to address the issue or what specific changes might be necessary. The feedback is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable steps or detailed suggestions for the authors to follow. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific suggestions for the authors to consider: replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1 instead of the Adam default value. However, it does not explicitly instruct the authors on how to implement these changes or provide guidance on why these replacements or adjustments are necessary. The actions are implicit, as the authors need to infer that they should make these changes and understand the reasoning behind them. The lack of detailed guidance on how to apply these suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides two specific suggestions for the authors to consider, but it does not specify which part of the paper these suggestions relate to. The references to lines 119-121 and line 164 indicate that the authors can infer the sections being addressed, but the comment lacks explicit grounding. The suggestions are specific in terms of what needs to be considered, but without clear references, the authors may struggle to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two specific questions about the methodology and experimental choices in the paper. The first question pertains to the use of `n^2/(2*s^2)` and suggests replacing it with an arbitrary parameter `lambda`. The second question questions the justification for using a SGD learning rate of ~0.1, unlike the Adam default value. While the questions are clear and point to specific areas of concern, they do not provide detailed reasoning or references to support the claims. The authors would need to infer the reasoning behind these choices, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two specific suggestions for the authors to consider, which could potentially improve the clarity and robustness of their work. The first suggestion involves replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which could simplify the expression and make it more generalizable. The second suggestion questions the use of a SGD learning rate of ~0.1, unlike the Adam default value, and asks for justification. This feedback is actionable as it prompts the authors to consider alternative approaches and provide a rationale for their choices. However, the comment could be more helpful if it offered guidance on how to implement these suggestions or provided examples of how they might affect the results. Overall, the comment is mostly helpful, as it identifies areas for improvement and encourages the authors to reflect on their methodology.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model's performance under different scenarios. The comment also suggests that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, it does not explicitly instruct the authors on how to conduct the error analysis or what specific aspects of the model's performance should be analyzed. While the action is somewhat inferred, it lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues, and it encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. However, the comment does not specify which part of the paper should be addressed or how the error analysis should be conducted. This lack of grounding makes it difficult for the authors to understand which sections or aspects of the paper need improvement. Additionally, the comment is specific in its suggestion to conduct error analysis, but without grounding, it is challenging for the authors to apply this feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. However, the comment lacks specific examples or references to support the claim that error analysis is essential for guiding subsequent improvements. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general suggestion but lacks the depth needed for the authors to fully understand its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to enhance their paper by conducting error analysis. It emphasizes the importance of error analysis in evaluating model performance and identifying potential issues, which can guide subsequent improvements and expansions of the ERC research. The comment encourages the authors to provide detailed explanations of the model\\'s performance under different scenarios, which is a valuable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to conduct the error analysis or what aspects of the model should be analyzed. Despite this, the feedback is mostly helpful as it directs the authors towards a crucial improvement area, making it a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should analyze the domain gap between datasets and discuss how this gap might affect the adaption of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. While the comment provides explicit actions\u2014analyzing the domain gap and discussing its impact, as well as exploring fine-tuning on synthetic data\u2014the actions are somewhat vague. The authors are not given specific guidance on how to analyze the domain gap or what aspects to discuss. However, the comment does offer a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. However, the comment does not specify which part of the paper addresses the domain gap or synthetic data, making it weakly grounded. The comment is specific in its suggestions regarding the analysis and exploration of the domain gap and fine-tuning, but without explicit references to sections or figures, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The suggestions are somewhat vague and do not provide a clear path for the authors to address the issues. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or depth to fully substantiate the suggestions.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft by analyzing the domain gap between datasets and discussing its potential impact on the adaptation of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. While the comment offers actionable feedback, it could be more helpful if it provided more detailed guidance on how to analyze the domain gap or what aspects of the fine-tuning process to focus on. However, the suggestions are clear and provide a good starting point for the authors to improve their work, making the comment mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue and suggests a direction for improvement, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and discusses the performance of the method with an increasing number of identities, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance degradation and suggests a potential solution by presetting the capacity to a small number. The comment provides clear guidance on how the authors might address the scalability issue, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that performance degrades with an increasing number of identities. The reasoning is somewhat vague, as it does not provide detailed evidence or guidance on how to address the scalability issue. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It provides a specific example from Table 3 (a) to illustrate this issue, suggesting that the capacity should be preset to a small number, such as 10. The comment also questions whether the authors have considered how to scale up without compromising performance, prompting them to explore potential solutions. This feedback is clear and actionable, as it identifies a significant limitation and provides a direction for improvement. However, it could be more helpful if it offered specific suggestions or strategies for addressing the scalability issue. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and encourages the authors to consider it.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or details to support this claim, particularly regarding the NLP-specific aspects of their approach. While the comment implies that the authors should provide more evidence to substantiate their claim, it does not explicitly instruct them to do so or suggest what specific evidence is needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the NLP-specific aspects of their approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors\\' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made or which sections or figures might contain evidence to support it. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what aspects of the approach are NLP-specific, leaving the authors uncertain about how to address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the authors\\' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any specific evidence or reasoning to support this claim. The comment lacks detailed examples or references that would help the authors substantiate their claim. Without additional context or justification, the claim remains unverifiable, as the authors are left to question the validity of their assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the authors' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or details to support this claim, particularly regarding the NLP-specific aspects of their approach. This feedback is somewhat helpful as it highlights a potential gap in the authors' claim and encourages them to provide more evidence or details to substantiate it. However, the comment could be more helpful if it offered specific suggestions or guidance on how to strengthen the claim or address the lack of NLP-specific evidence. Overall, the comment provides a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. However, the comment does not provide explicit guidance on how to incorporate this method into the authors' draft or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors would need to infer that they should include a comparison with a NCE-based method and potentially discuss the findings of the referenced paper. The lack of concrete details makes the action somewhat vague, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. However, the comment does not specify which part of the paper this comparison should be made or where the authors should discuss the findings of the referenced paper. This makes it difficult for the authors to identify the specific section or aspect of the paper that needs improvement. The comment is not grounded as it does not provide clear guidance on which part of the paper to address. Therefore, it is rated as \"Not Grounded\".', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that at least one NCE-based method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. However, the comment lacks detailed reasoning or specific examples to support this claim. It does not provide a clear explanation of why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a relevant comparison. However, the comment lacks depth and does not provide specific guidance on how to incorporate this method or what aspects of the comparison should be highlighted. The authors would need to infer the need for this comparison and potentially discuss the findings of the referenced paper, which limits the comment's helpfulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment section could be improved by carrying out significance tests on the human evaluation results and comparing the proposed method with some recent LLMs. While the comment provides explicit actions\u2014carrying out significance tests and comparing with recent LLMs\u2014it does not specify how these actions should be implemented or what data should be used for the significance tests. The lack of detailed guidance on how to conduct these tests or select appropriate baselines makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically mentioning the need to carry out significance tests on human evaluation results and to compare the proposed method with recent LLMs. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the types of improvements needed, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by carrying out significance tests on the human evaluation results and comparing the proposed method with some recent LLMs. However, the comment lacks specific details or references to support these suggestions. It does not provide examples of how to conduct the significance tests or which recent LLMs should be used for comparison. Without these details, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary depth and specificity to fully guide the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the experiment section, such as the need to carry out significance tests on human evaluation results and to compare the proposed method with recent LLMs. This feedback is clear and actionable, providing the authors with concrete suggestions for enhancing the rigor and relevance of their work. However, the comment could be more helpful if it included specific examples of how to conduct the significance tests or which recent LLMs should be used for comparison. Despite this, the feedback is mostly helpful as it directs the authors towards important improvements that could strengthen their experimental evaluation. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, which is relevant to the topic of joint error in unsupervised domain adaptation (UDA). It also suggests that the authors should illustrate the relationship between this work and their proposed method and explain why their method is better. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is fully actionable, as it gives explicit guidance on what to include in the discussion and how to compare the proposed method with existing work. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of joint error in unsupervised domain adaptation (UDA), which is a well-defined part of the paper. It also specifies the need to discuss a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and to illustrate the relationship between this work and the proposed method. This provides clear guidance on what part of the paper needs attention and what specific issues need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' assertion about the lack of research on joint error in unsupervised domain adaptation (UDA) is inaccurate, as previous work has already addressed this issue. The comment provides a specific reference to \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, which supports the claim. However, the comment could be more robust by including a brief summary or explanation of the relevance of this work to the authors' proposed method. Despite this, the claim is mostly verifiable as it is supported by a specific reference, making it a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific gap in the authors' claim regarding the lack of research on joint error in unsupervised domain adaptation (UDA). It directs the authors to a relevant previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and suggests that they discuss this work in relation to their proposed method. By providing a specific reference and a clear direction for discussion, the comment offers actionable guidance on how the authors can strengthen their paper. This feedback is detailed and constructive, making it highly valuable for improving the draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure a fair comparison. While the authors can infer that they need to consider the dataset size in their analysis, the lack of concrete suggestions or actions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. It provides an example of a method, GEM, which employs only 20M unlabeled data. However, the comment does not specify which part of the paper discusses the comparison with SOTA methods or where the dataset sizes are mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of dataset size impacting accuracy, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of a method, GEM, which employs only 20M unlabeled data, suggesting that the superior performance of the proposed method might be attributed to the larger dataset size. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. It does not provide references or logical arguments to support the assertion that the dataset size significantly impacts accuracy. As a result, the claim is somewhat verifiable, as it is based on a logical argument but lacks sufficient evidence or references to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of a method, GEM, which employs only 20M unlabeled data, suggesting that the superior performance of the proposed method might be attributed to the larger dataset size. This observation highlights a potential issue with the experimental setup and the interpretation of results. However, the comment lacks specific guidance on how the authors should address this concern or what steps they should take to ensure a fair comparison. While it identifies a potential weakness, it does not offer actionable suggestions or detailed reasoning to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out an important issue but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that several curriculum learning methods have been discussed in Section 1, but it does not provide explicit guidance on how to address the need for designing a new curriculum learning method for text graphs. While the comment implies that the authors should justify the need for a new method, it lacks concrete suggestions or detailed instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on why existing methods cannot be applied. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that several curriculum learning methods have been discussed in Section 1 but does not provide a clear justification for why a new method is needed for text graphs. It highlights a research gap by noting that the paper does not discuss why existing methods cannot be applied. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the reasoning behind the need for a new method. The absence of detailed reasoning or examples makes the claim somewhat verifiable, as it provides a basis for discussion but lacks depth and clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that while several curriculum learning methods have been discussed, the need for designing a new method for text graphs is not justified. It highlights a research gap by noting that the paper does not discuss why existing methods cannot be applied. This feedback is somewhat helpful as it directs the authors to address a critical aspect of their work that needs further justification. However, the comment could be more helpful if it provided specific suggestions or guidance on how to justify the need for a new method or discuss the limitations of existing approaches. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive to fully assist the authors in enhancing their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest n-gram features. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, detailing which models to use and how to compare the transfer parts. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation in the NLP field\" and suggests using powerful pre-trained language models like BERT and XLNet as the base encoder. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on how the authors should improve their draft by comparing the efficacy of the transfer parts instead of using the simplest n-gram features. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using powerful pre-trained language models like BERT and XLNet as the base encoder can overcome the domain-shift problem, and suggests comparing the efficacy of the transfer parts instead of using the simplest n-gram features. While the claim is based on the understanding of domain adaptation in the NLP field, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to provide more evidence or examples to fully understand the basis of this suggestion. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of relying on simpler n-gram features. This feedback is actionable and offers a clear direction for the authors to enhance their draft by incorporating more advanced models and conducting a more thorough comparison. However, the comment could be more helpful if it included additional details or examples to guide the authors in implementing this suggestion effectively. Overall, the comment is mostly helpful as it provides a valuable insight into potential improvements, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a critical issue regarding the proposed method, which includes several complicated modules and more parameters than the baselines. It questions whether the main performance gain is due to a specific module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it does not offer any explicit or implicit guidance on how the authors might address this issue or what specific actions they should take to clarify the source of the performance gain. The lack of actionable advice leaves the authors without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It highlights a critical issue regarding the source of the main performance gain, questioning whether it originates from a particular module or is merely due to the increased number of parameters. The comment also notes that the current ablation study does not provide definitive answers to these questions. However, the comment does not specify which part of the paper discusses the proposed method or the ablation study, making it weakly grounded. The comment is specific in identifying the issue with the performance gain and the lack of clarity in the ablation study. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the source of the main performance gain in the proposed method, specifically questioning whether it originates from a particular module or is merely due to the increased number of parameters compared to baselines. The comment highlights that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support the claim that the ablation study is insufficient. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it points out a potential issue but does not provide a clear path for addressing it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the proposed method, specifically questioning the source of the main performance gain. It highlights that the method comprises several complicated modules and has more parameters than the baselines, making it unclear whether the performance improvement is due to a specific module or simply the increased number of parameters. The comment also notes that the current ablation study does not provide definitive answers to these questions. This feedback is valuable as it directs the authors to investigate the specific contributions of each module and the impact of the increased parameters on the performance gain. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation study or what specific analyses could be performed to clarify the source of the performance improvement. Overall, the comment is somewhat helpful, as it points out a critical issue but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for more explanation regarding why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. However, the comment does not provide specific guidance on how to address the request for more explanation or how to incorporate the suggestion about \"pure theory\" papers. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific section of the paper (lines 196-7), allowing the authors to accurately identify the part being addressed. It also specifies what needs to be addressed, namely, the requirement for more explanation regarding why two quantities are different and how this captures the difference in learning settings. The comment is specific in its request for clarification and suggests a leaning toward acceptance, which provides a clear direction for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the explanation of why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. However, the comment lacks specific examples or detailed reasoning to support the claim that the explanation is insufficient or unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some basis for understanding but lacks the depth needed for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that requires more explanation, specifically regarding why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address the issue or incorporate the suggestion about \"pure theory\" papers. The feedback is somewhat helpful as it points out a specific area for clarification but lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and explicit instruction that provides a direct action for the authors to take. It specifies what needs to be discussed, making the action concrete and actionable. The authors know exactly what aspect of the model they should address and how to do so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment requests the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for discussion, but the lack of grounding makes it difficult for the authors to know where to address this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a request for clarification and additional analysis, rather than a claim that requires verification. The comment does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is specific and actionable, as it directs the authors to address a particular aspect of their model that could impact its performance and reliability. By discussing the sensitivity of these parameters, the authors can provide valuable insights into the robustness and generalizability of their model. This feedback is clear and constructive, offering a direct path for improvement. Therefore, the comment is mostly helpful, as it provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. However, the comment does not provide explicit guidance on how to conduct this exploration or how to determine the number of random seeds. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its request for additional experiments and clarification on the number of random seeds, but without explicit references to sections or figures, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the number of random seeds used for learning the policies (DDPO and IPPG) in the experiment results. However, it does not provide any justification or reasoning for why this information is important or how it might impact the results. Without additional context or explanation, the claim is unverifiable, as the authors are left to infer the significance of the question. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG, and raises a question about the number of random seeds used for learning the policies. While the comment identifies an area for further investigation, it lacks specific guidance on how to conduct this exploration or how to determine the number of random seeds. The feedback is somewhat helpful as it points out a potential avenue for improvement, but it does not provide detailed instructions or suggestions for action. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. This provides a clear and explicit action for the authors to take, as they can directly apply this feedback by expanding their evaluation to include additional datasets and tasks. The comment is specific in its suggestion, detailing exactly what needs to be done to strengthen the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. However, it does not specify which parts of the paper are being addressed or how the evaluation is conducted. The authors cannot confidently determine which sections or figures are being referred to, making the comment weakly grounded. Additionally, while the comment is specific in suggesting the need for more datasets and tasks, it lacks detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary depth to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper's evaluation, noting that it is based on only one dataset and one task. This feedback is clear and actionable, as it suggests that expanding the evaluation to include more datasets and tasks would strengthen the results and conclusions. By providing a specific direction for improvement, the comment empowers the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered additional guidance on how to select or design the additional datasets and tasks. Despite this, the feedback is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting the definition of \"relevant\" auxiliary model weights in Definition 2.1. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how to improve the writing or suggest specific actions to take. The authors are left to infer that they need to clarify the definition, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of clarity in the definition of \"relevant\" auxiliary model weights, providing a clear indication of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting the definition of \"relevant\" auxiliary model weights in Definition 2.1. However, the comment does not provide any specific examples, reasoning, or references to support why this is a problem or how it could be improved. Without additional context or justification, the claim remains somewhat vague and lacks sufficient evidence to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the writing could be improved, namely the clarity of Definition 2.1. It points out that the term \"relevant\" auxiliary model weights is difficult to interpret, which suggests that the authors need to clarify this concept. While the comment is specific about the issue, it lacks broader guidance on how to improve the writing or what specific changes might be necessary. The feedback is actionable but could be more comprehensive, as it does not provide detailed suggestions or examples of how to enhance the clarity of the definition. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limitations of using MIA testing for evaluating unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It recommends using U-LiRA [1]. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate U-LiRA into their draft. The action is implicit and vague, as it does not specify how the authors should modify their paper to improve the robustness of their privacy guarantees. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of MIA testing for evaluating unlearning effectiveness, noting that the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees. It recommends using U-LiRA [1]. However, the comment does not specify which part of the paper discusses MIA testing or how it is used. The authors may infer that it relates to the methodology or experimental sections, but this is not explicitly stated. The comment is specific in its critique of the MIA testing approach but lacks grounding as it does not pinpoint the exact section or part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of MIA testing is not sufficiently robust for privacy guarantees and recommends using U-LiRA [1]. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why MIA testing is insufficient or how U-LiRA addresses this issue. Without additional context or evidence, the claim is difficult to verify, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of MIA (Membership Inference Attack) testing for evaluating unlearning effectiveness, noting that the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees. It recommends using U-LiRA [1] as an alternative. This feedback is somewhat helpful as it highlights a specific area for improvement and suggests a potential solution. However, the comment could be more helpful if it provided more detailed reasoning or examples of how the use of MIA testing might be insufficient, or if it suggested alternative methods for evaluating unlearning effectiveness beyond just recommending U-LiRA. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The comment is not grounded as the authors cannot confidently determine which part of the paper it addresses. It is also not specific because it does not provide detailed guidance on how to incorporate this suggestion into the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment identifies a potential area for expansion or clarification, it does not provide specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential avenue for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the quantitative evaluation results, noting that Figure 3 only reflects middle outputs and Figure 4 compares final results with a single data sample. The comment suggests that the current evaluations are not convincing enough to confirm ModelAngelo\u2019s superiority to competitors and asks if a quantitative comparison on the final outputs is possible. While the comment identifies a specific issue with the evaluation, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the evaluation process. The action is implicit, as the authors would need to infer that they should include a quantitative comparison of final outputs. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and lack comparison with final outputs. This provides clear guidance on what needs to be addressed to strengthen the evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the quantitative evaluation results, specifically questioning whether they reflect only middle outputs and if a comparison with final outputs is possible. While the comment identifies a potential issue with the evaluation, it does not provide any evidence or reasoning to support the claim that the current evaluations are insufficient or unconvincing. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the quantitative evaluation results, noting that Figure 3 only reflects middle outputs and Figure 4 compares final results with a single data sample. This observation raises concerns about the comprehensiveness and persuasiveness of the current evaluations in confirming ModelAngelo's superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be necessary to strengthen the evaluation. However, it does not provide specific guidance or suggestions on how to conduct this comparison or what aspects of the final outputs should be considered. While the comment highlights a critical area for improvement, it lacks detailed actionable advice, making it somewhat helpful. The authors would need to infer that they should include a quantitative comparison of final outputs, but the comment does not offer concrete steps or examples to facilitate this improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experiment-based evidence, confusing figures (e.g., \"sample count\" in Figure 2), and the lack of error bars or p-values in statistical inferences. While the comment identifies these areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they need to add more details, figures, and statistical measures, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with the qualitative nature of explanations and the lack of detail in simulation or experiment-based evidence, specifically mentioning figures and statistical inferences. However, it does not specify which parts of the paper these issues are present in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as adding more details to the figures and including error bars or p-values. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanations are qualitative and that procedures are described minimally or not at all, especially in simulation or experiment-based evidence. It also notes that some figures are confusing, such as the \"sample count\" in Figure 2, and that more details are needed to understand what was done in each simulation. Additionally, the comment suggests that statistical inferences should include error bars and/or p-values. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claims. Therefore, the claim is somewhat verifiable, as it offers some basis for improvement but could be strengthened with more detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experiment-based evidence, confusing figures, and the lack of error bars or p-values in statistical inferences. It provides specific examples, such as the confusion surrounding the 'sample count' in Figure 2, and suggests that adding more details and figures would enhance the paper's clarity and rigor. However, the comment could be more helpful if it offered concrete suggestions on how to improve these aspects, such as providing examples of how to add more detail or how to clarify confusing figures. Overall, the comment is somewhat helpful as it highlights important areas for improvement but lacks detailed guidance on implementation.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some claims in the paper might be inspired from existing studies and recommends adding supportive references. It provides an example of a section (Lines 55-64) where this issue is mentioned. However, the comment does not explicitly instruct the authors to add these references or provide specific guidance on which references to include. The action is implicit and somewhat vague, as the authors are left to infer that they need to add references to support the claims made in the specified section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Lines 55-64, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of claims that have been discussed in existing studies, suggesting that the authors should add supportive references. This feedback is detailed and provides a clear direction for improvement, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims in the paper are inspired from existing studies and suggests adding supportive references. It provides an example of a section (Lines 55-64) where this issue is mentioned. However, the comment lacks specific references or detailed reasoning to support the claim that the claims are inspired from existing studies. Without concrete examples or references, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue in the paper, noting that some claims might be inspired from existing studies. It suggests adding supportive references to these claims, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific examples of where these references should be added or suggested which studies might be relevant. Additionally, it could offer guidance on how to effectively integrate these references into the paper. While the feedback is somewhat helpful, it lacks depth and specificity, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also implies that providing a single review of the various advances in this area would be beneficial for the community. However, the comment does not specify which parts of the paper need to be revised or how the settings should be presented to align with prior work. The action is implicit and vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to provide a single review of the various advances in the area, but without a clear reference to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, the comment lacks specific details or examples of how this could be achieved, making it difficult for the authors to understand and implement the suggestion. Without additional context or guidance, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary depth or specificity to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. It also recommends providing a single review of the various advances in this area to benefit the community. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement these suggestions or what aspects of the algorithm need to be adjusted. The feedback is somewhat helpful as it points out a direction for improvement but does not provide detailed instructions or examples, leaving the authors with a general idea of what to work on but without a clear roadmap. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the generalizability of the specific examples of biases and prediction shifts presented in the paper. It points out that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not provide explicit guidance on how the authors should address this issue or what actions they should take to clarify the generalizability of their findings. The action is implicit and vague, as it does not specify how the authors can improve the clarity or provide more context on the generalizability of the examples. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the clarity of the paper, particularly regarding the generalizability of the examples of biases and prediction shifts presented in section 3.2 and Theorem 1. It highlights that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not specify which part of the paper these examples are located in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the generalizability of the examples, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the generalizability of the specific examples of biases and prediction shifts presented in the paper. It suggests that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the authors are unsure about the generalizability of these situations. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion in the paper, namely the generalizability of the examples of biases and prediction shifts presented in section 3.2 and Theorem 1. It points out that while the paper demonstrates these biases, it does not explain how common or general these situations are, leaving the authors uncertain about the scope of these findings. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or clarify the generalizability of their examples. Without specific advice on how to improve the clarity or provide more context, the feedback is somewhat helpful as it highlights an important area for improvement but does not offer detailed guidance. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would have appreciated more datasets, particularly for the cross-task transferability aspect. However, it does not provide explicit guidance on which datasets to include or how to incorporate them into the paper. The action is implicit, as the authors need to infer that they should add more datasets to address the cross-task transferability. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors would have appreciated more datasets, especially concerning the cross-task transferability aspect. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. The authors cannot confidently determine which part of the paper needs to be addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of more datasets for cross-task transferability, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors would have appreciated more datasets, particularly concerning the cross-task transferability aspect. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors would have appreciated more datasets, especially concerning the cross-task transferability aspect. While this feedback provides a clear direction for improvement, it lacks specific guidance on which datasets to include or how to incorporate them into the paper. The comment is somewhat helpful as it identifies a potential area for enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not provide explicit guidance on how to implement these unique tasks or what specific aspects of the dataset should be emphasized. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks performed on the dataset are somewhat standard, specifically mentioning figure captioning and matching figures/sub-figures to appropriate captions. It proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not specify which part of the paper these tasks are discussed or proposed for, making it weakly grounded. The comment is specific in detailing the suggestion for unique tasks, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment lacks specific examples or references to support the claim that the current tasks are standard or that the suggested tasks would effectively demonstrate the dataset's diversity. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. This feedback is somewhat helpful as it provides a direction for enhancing the tasks performed on the dataset, which could potentially enrich the paper\\'s contribution. However, the comment lacks specific guidance on how to implement these unique tasks or what aspects of the dataset should be emphasized. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors have made any additional novel effort in the Sec. 3.1 for 3D Gaussians generation, noting that it seems to follow the previous work, Luciddreamer. While the comment implies that the authors should clarify the novelty of their approach, it does not explicitly instruct them to provide evidence or details about any additional contributions. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the novelty of their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. However, it does not specify which part of the paper Sec. 3.1 corresponds to, making it weakly grounded. The comment is specific in its request for clarification regarding the novelty of the approach, but without explicit grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. While the comment implies that the authors should address the novelty of their approach, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of explicit evidence or justification makes the claim somewhat verifiable, as the authors are left to infer the need for clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the Sec. 3.1 for 3D Gaussians generation, noting that it appears to follow the previous work, Luciddreamer. While the comment identifies a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider the novelty of their approach, but it lacks actionable advice or detailed insights that would enhance the authors' understanding and ability to improve their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the tractability of MMD DRO or how to refine the upper bound. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. The lack of specific references or sections makes the comment weakly grounded. While it provides some specificity by mentioning the issues with the tractability of MMD DRO and the limitations of the upper bound, it does not offer detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient evidence to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It points out that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also notes that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it highlights that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the tractability of MMD DRO or the upper bound. While it identifies areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, as well as its applicability to binary classification scenarios where the true mean is known. It questions whether the framework remains relevant given the challenges of non-vanishing duality gaps and the difficulty of maximization over non-norm type constraints. Additionally, it asks whether the framework can provide intuitions on the risk upper bound. The comment also suggests exploring the use of covariance or other statistics to design a better defense. However, it does not provide explicit guidance on how the authors should address these questions or incorporate them into their draft. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require attention and how to address them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, specifically questioning its applicability given the challenges of non-vanishing duality gaps and the difficulty of maximization over non-norm type constraints. It also asks about the relevance of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the areas of concern, such as the challenges with non-convex losses and non-norm type defenses, and the applicability of the framework in binary classification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, specifically questioning whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant. It also asks about the applicability of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are open-ended and lack sufficient justification or evidence to guide the authors in addressing them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, as well as its applicability to binary classification scenarios where the true mean is known. It questions whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant, or if it could still provide some intuition on the risk upper bound. Additionally, it suggests exploring the use of covariance or other statistics to design a better defense. However, the comment lacks specific guidance or suggestions on how the authors might address these questions or incorporate them into their draft. While it identifies areas for improvement, it does not provide actionable steps or detailed reasoning, making it somewhat helpful. The feedback is valuable but could be more comprehensive to fully assist the authors in enhancing their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. However, the comment does not provide explicit guidance on how to implement this action or what specific steps the authors should take. While the suggestion is clear and concrete, the lack of explicit instructions on how to execute it leaves the authors with a general idea of what to do but no detailed guidance. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks specific implementation details.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an action to be taken with the baselines on the left-hand side of the figure, specifically proposing to sparsify the trained models to reduce the number of selected features and compare accuracy to the proposed model. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about an action that could be taken with the baselines in Figure 3, specifically suggesting sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, the comment does not provide any justification, reasoning, or references to support why this action is relevant or beneficial. Without additional context or explanation, the authors are left without guidance on how to address this suggestion or why it is important. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This feedback is actionable as it provides a clear direction for the authors to consider and potentially implement. However, the comment lacks depth and does not offer additional insights or suggestions on how to approach this action or what specific improvements might be expected. While it is somewhat helpful, it could be more beneficial with additional guidance or context. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks detail, making it difficult for the authors to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide explicit instructions or suggestions on how the authors should address these issues. While it identifies the areas needing more detail, it does not offer concrete guidance on how to improve the paper. Therefore, the comment is somewhat actionable, as it points out specific areas for improvement but lacks detailed guidance on how to implement these suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of detail in the techniques, making it difficult to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This allows the authors to accurately identify the parts of the paper that need improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights specific areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide any specific examples, references, or logical reasoning to support these claims. The authors are left to infer the need for more detail, which makes the feedback somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of detail regarding the techniques used, which makes it difficult for the authors to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve the paper. While it highlights the need for more detail, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Appendix H section should be reorganized to improve its readability. However, it does not provide specific guidance on how to reorganize the section or what aspects of the organization are problematic. The comment lacks concrete details, leaving the authors uncertain about the exact steps to take. As a result, the action is implicit and vague, making it difficult for the authors to apply the feedback effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the Appendix H section should be reorganized to improve its readability. However, it does not specify which part of the paper Appendix H refers to, making it difficult for the authors to identify the exact section that needs reorganization. Additionally, the comment lacks specificity in detailing what aspects of the section are difficult to follow, such as the structure, flow, or clarity of the content. Without these details, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the Appendix H section should be reorganized to improve its readability. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this reorganization is necessary or how it would benefit the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the organization of Appendix H, suggesting that it is difficult to follow. However, it lacks specific details or suggestions on how the authors might reorganize the section to improve its readability. Without actionable guidance or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it provides a general observation but no concrete steps for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the paper's clarity and reproducibility. It suggests that while the paper provides an intuitive understanding, it lacks the necessary technical details for reproduction, such as specifics about the RNN implementation. However, the comment does not explicitly instruct the authors to include these details or provide guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional details and how to address them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper and the issue of reproducibility, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the lack of technical details required for reproduction, such as specifics about the RNN implementation, and suggests that these details are missing from both the paper and the supplementary material. This provides clear guidance on what needs to be addressed to improve the paper\\'s reproducibility. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is written to provide an intuitive understanding but lacks sufficient details for reproduction, such as specifics about the RNN implementation. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper's clarity and reproducibility. It points out that while the paper provides an intuitive understanding of the work, it lacks the necessary technical details required for reproduction, such as specifics about the RNN implementation, including the number of units. This feedback is valuable as it highlights a significant gap in the paper's content, which could hinder the ability of other researchers to reproduce the results. However, the comment could be more helpful if it provided suggestions or guidance on what specific details should be included to enhance reproducibility. Overall, the comment is somewhat helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 would be stronger if it included error bars and more random trials to potentially eliminate random fluctuations in the results. While the comment provides explicit guidance on what should be added to the figure, it does not specify how to implement these changes or where to add them. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to Figure 1, specifically mentioning the need for error bars and more random trials to address potential random fluctuations. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed to enhance the figure, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Figure 1 would be stronger with error bars and more random trials to address potential random fluctuations. However, it does not provide any specific reasoning, examples, or references to support why these changes would be beneficial or how they would impact the results. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving Figure 1, such as adding error bars and conducting more random trials to address potential random fluctuations in the results. These suggestions are actionable and directly address a potential weakness in the figure's presentation. By offering concrete improvements, the comment empowers the authors to enhance the clarity and robustness of their results. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or why these changes are expected to improve the figure. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be further enhanced with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. It also points out that Figure 1 lacks clarity regarding the correspondence of points in the left and right graphs to different learning rates and steps, respectively. This feedback is clear and provides explicit guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. However, it does not specify which part of the related work section this introduction should be included in, making it weakly grounded. The comment also points out a lack of clarity in Figure 1, but it does not specify which part of the figure is unclear, making it weakly grounded. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. It also points out that Figure 1 lacks clarity regarding the correspondence of points in the left and right graphs to different learning rates and steps, respectively. However, the comment does not provide any references or detailed reasoning to support the claim that this suggestion is necessary or beneficial. The lack of justification makes the claim somewhat verifiable, as the authors may need to infer the importance of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft, such as adding a brief introduction to energy models in the related work section and clarifying the correspondence of points in Figure 1. These suggestions are actionable and directly address potential weaknesses in the paper, offering clear guidance for the authors to enhance their work. However, the comment could be more helpful if it included additional details or examples to further clarify the importance of these suggestions. Overall, the feedback is mostly helpful, as it provides a solid foundation for the authors to improve their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the FIITED approach, which relies on utility-based eviction decisions. It suggests that this approach might introduce biases, such as prematurely evicting valuable chunks due to their temporary high utility. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach. The action is implicit and vague, as it leaves the authors to infer the need for further analysis or modifications. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the FIITED approach, which is described as utility-based. It highlights a potential issue with this approach, suggesting that relying solely on utility scores for eviction decisions might introduce biases. However, the comment does not specify which part of the paper discusses the FIITED approach or where the utility-based approach is detailed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific in identifying the issue with the utility-based approach, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that relying solely on utility scores for eviction decisions in the FIITED approach might introduce biases. It provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed examples or evidence to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the FIITED approach, which relies on utility-based eviction decisions. It highlights that this approach might introduce biases, such as prematurely evicting valuable chunks due to their temporary high utility. While the comment points out a specific concern, it does not provide detailed guidance or suggestions on how to address this issue or improve the approach. The feedback is somewhat helpful as it raises a valid point about potential biases, but it lacks actionable advice or specific recommendations for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is devoted to a general introduction of DNNs and lacks any mention of drift. It suggests that this paragraph is not central to the paper's focus on detecting drift types and magnitude, and that it provides little valuable information. This feedback is clear and specific, as it identifies a specific part of the paper that needs revision and provides a clear rationale for why it is not relevant to the paper's core focus. The authors can directly infer that they should either remove or reframe this paragraph to align with the paper's main contribution. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the first paragraph of the Introduction, providing full grounding as the authors can accurately identify the section being addressed. It also specifies the issue with this paragraph, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\\'s focus. This level of detail allows the authors to understand exactly what part of the paper needs revision and what specific issue needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\\'s focus. The comment suggests that this paragraph provides little valuable information to readers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a basis for improvement but lacks the depth needed for full validation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction section, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\\'s focus. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of the DNN introduction to their core contribution. By highlighting this discrepancy, the comment provides a valuable insight into how the introduction could be improved to better align with the paper\\'s main focus. However, the comment could be more helpful if it suggested specific ways to reframe or remove the DNN introduction. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the performance and contribution of the framework. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It mentions that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment is fully grounded as it explicitly mentions the areas where the authors need to provide more clarity, such as the performance and contribution of different parts of the framework. It is also specific because it specifies what is missing in the current draft, including quantitative experiments, comparisons between algorithms, and detailed explanations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the experimental aspects of the paper, specifically regarding the performance and contribution of different parts of the framework. It notes that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the basis for the claim, which limits its verifiability.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by highlighting the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions, which is a crucial point for the authors to address. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might conduct these additional experiments or provide more detailed explanations. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks depth in terms of actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the model need to be clarified. The comment lacks concrete guidance on how the authors can improve the draft to address this concern. As a result, the authors are left without a clear understanding of what actions to take to enhance the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on how the authors might address this issue or what aspects of the model need clarification. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any specific evidence, reasoning, or references to support the claim that the model could generate novel knowledge or testable hypotheses. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, this comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. While it highlights a potential concern regarding the model's ability to produce novel insights, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft to address this concern. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer detailed or constructive advice. This aligns with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand on its own. This comment provides a clear and explicit action for the authors to take, which is to simplify Theorem 2. It also specifies how this action can be implemented by suggesting that it should be presented for the general audience. Therefore, the comment is highly actionable, as it provides a concrete and direct instruction for the authors to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a simplified version of Theorem 2 could be presented for the general audience, noting that it is currently difficult to understand on its own. This feedback is specific as it directly addresses the difficulty in understanding Theorem 2 and provides a concrete suggestion for improvement. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand on its own. This claim is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the difficulty in understanding the theorem. While the authors might infer that the comment is based on common knowledge about the complexity of theorems, the lack of detailed reasoning or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that needs improvement, namely the difficulty in understanding Theorem 2 and Definition 2. It suggests that a simplified version of Theorem 2 could be presented for the general audience, which is a valuable and actionable feedback. By providing a clear direction for improvement, the comment helps the authors enhance the accessibility and comprehensibility of their work. However, the comment could be more helpful if it offered additional suggestions or guidance on how to simplify the theorem or definition. Overall, the feedback is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments using a larger resolution than 224*224. While it implies an action, it does not provide explicit guidance on how to implement this suggestion, such as specifying which experiments should be conducted at a larger resolution or what the expected impact might be. The action is implicit and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with a larger resolution, which is a specific aspect of the methodology. However, it does not explicitly mention which part of the paper this relates to, such as a specific section or figure. The comment is specific in its suggestion but weakly grounded as the authors cannot confidently determine which part of the paper it addresses. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments with a larger resolution, which is a logical and interesting idea. However, it lacks specific details or references to support the claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it. Without additional context or evidence, the claim is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests conducting experiments with a larger resolution, which is an interesting and potentially valuable idea. However, the comment lacks specific guidance on how to implement this suggestion or what the expected impact might be. It does not provide actionable feedback or detailed reasoning, making it somewhat helpful. The authors would benefit from additional context or suggestions on how to approach this change, but the comment is incomplete and lacks depth. Therefore, it aligns with a score of 3, indicating that the feedback is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide explicit guidance on how the authors should revise their method or what specific changes to make. The action is implicit, as the authors need to infer that they should reconsider their approach and potentially implement the suggested alternative. While the action is somewhat concrete, it lacks detailed guidance on how to apply it, making the comment borderline actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section\" and the specific part of the section, \"What is the keypoint mask averaged feature vector?\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the approach used in calculating the averaged feature vector, suggesting that it might be incorrect and proposing an alternative method. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim that the current method is incorrect or why the alternative approach is better. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the KeyQN section, questioning the approach used to calculate the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors should revise their method or what specific changes to implement. While it points out a potential problem, it does not offer actionable steps or insights that would help the authors improve their work. Therefore, the comment is barely helpful, as it provides a starting point for improvement but lacks the necessary depth and guidance for the authors to effectively address the issue.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should make the different curves in Figure 2 more distinguishable by using styles like dashed lines or adding color. This provides a clear and explicit action for the authors to take, as they know exactly how to improve the figure. The comment is specific and concrete, giving detailed guidance on how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure by suggesting the use of styles like dashed lines or adding color. This feedback is detailed and actionable, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 2 right is difficult to distinguish between different curves and recommends using styles like dashed lines or adding color. This is a subjective observation and suggestion for improvement, but it lacks specific reasoning or examples to support why this is an issue or how it impacts the paper. Without additional context or evidence, the claim is difficult to verify, making it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between different curves. It provides a clear suggestion for improvement by recommending the use of styles like dashed lines or adding color to enhance the figure's clarity. This feedback is actionable and directly addresses a potential weakness in the presentation of the data, offering a concrete way for the authors to improve the figure. However, the comment could be more helpful if it included additional suggestions or considerations for other aspects of the figure or the overall presentation of the paper. Despite this, the comment is mostly helpful as it provides a clear and actionable direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. It recommends toning down the introduction and suggesting that the task is more accurately described as a feedback-driven QA in the form of a dialog. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to tone down the introduction or provide specific examples of what should be included. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claims made in the introduction, suggesting that they are not aligned with the tasks and models described. It recommends toning down the introduction and describing the task as a feedback-driven QA in the form of a dialog. However, the comment does not specify which part of the paper the introduction is located in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. The reviewer suggests that the task is more accurately described as a feedback-driven QA in the form of a dialog. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the claims made in the introduction, noting that they are not aligned with the tasks and models described. The authors are called to language learning, but the evaluation is based on question answering, which is a feedback-driven task. The comment suggests that the introduction should be toned down and that the task should be described more accurately as a feedback-driven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and accuracy of their introduction. However, the comment could be more helpful if it included examples of how to tone down the introduction or suggested specific changes to the description of the task. Overall, the comment is mostly helpful, as it offers valuable insights and actionable feedback that the authors can use to enhance their draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. It suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment does not offer any specific guidance or suggestions on how the authors might address this issue or strengthen their argument. The authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. However, it does not specify which part of the paper discusses this contribution or the issue of neural ODEs exhibiting inaccuracy while recomputing activations. The authors are left to infer that the comment pertains to the introduction or methodology sections, but without explicit references, the grounding is weak. The comment is specific in its critique of the analytical argument and empirical evidence provided, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the central contribution of the paper, specifically the modeling of weight evolution using ODEs, and raises concerns about the novelty of the problem it addresses. It claims that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the paper does not provide convincing evidence. This makes the claim somewhat verifiable, as it highlights a potential gap in the paper's argumentation but does not provide sufficient evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the central contribution of the paper, specifically the modeling of weight evolution using ODEs. It questions the novelty of the problem and suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy while recomputing activations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or strengthen their argument. While it highlights a critical area for improvement, the feedback is somewhat limited in its actionable value, making it somewhat helpful. The authors would need to infer the areas needing improvement, which could be challenging.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a specific and actionable suggestion, as it provides a clear instruction for the authors to include additional context or explanation in their draft. The comment is explicit and concrete, allowing the authors to directly apply the action by adding the necessary information. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L37,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a note about the algorithms following the sampled policy for a while, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a clear and actionable piece of feedback that could enhance the clarity and completeness of the paper. However, the comment lacks broader context or suggestions for other potential improvements, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it offers some guidance but could be more comprehensive.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper by suggesting that proving lower bounds for round complexity is a significant part of work in batched ranking problems. It then points out that the paper exploits an easy reduction from collaborative ranking, which makes the lower bound results a straightforward corollary of existing collaborative ranking results. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their work. It lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"proving lower bounds for round complexity\" and \"batched ranking problems,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper exploits an easy reduction from collaborative ranking, making the lower bound results a straightforward corollary. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a major part of work in batched ranking problems, but the paper exploits an easy reduction from collaborative ranking, making the lower bound results a straightforward corollary. This claim is somewhat verifiable as it provides a logical reasoning for why the lower bound results might be considered straightforward. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by suggesting that proving lower bounds for round complexity is a significant part of work in batched ranking problems. It then points out that the paper exploits an easy reduction from collaborative ranking, which makes the lower bound results a straightforward corollary of existing collaborative ranking results. This feedback highlights a potential gap in the paper's contribution and suggests that the authors should consider addressing this issue to enhance the novelty and impact of their work. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or what additional contributions they could make to address the identified gap. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not provide specific guidance on how to implement these suggestions or what aspects of the prompting technique need to be improved. The action is implicit and vague, as the authors are left to infer that they should explore more sophisticated prompting techniques. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or where the authors should focus their attention. This lack of grounding makes it difficult for the authors to understand which section or aspect of the paper needs improvement. Additionally, the comment is specific in suggesting that more sophisticated prompting techniques could be used, but without explicit references to the paper, it remains somewhat vague. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and does not fully leverage the capabilities of LLMs. It suggests that more sophisticated prompting techniques could yield better results in generating systematic reviews. However, the comment lacks specific guidance on how to implement these suggestions or what aspects of the prompting technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional experiments on larger datasets would be beneficial, but acknowledges that computational resources might be a constraint. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is explicit in suggesting additional experiments, which provides a clear action for the authors to take. However, it lacks specific guidance on which datasets or types of experiments to conduct, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests additional experiments on larger datasets, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper these experiments relate to, making it weakly grounded. The comment is specific in suggesting that maintaining probabilities might become an issue at large batch sizes, but it does not provide detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on larger datasets would be beneficial, but acknowledges the potential issue of computational resources. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is somewhat verifiable as it provides a rationale for the suggestion, but it lacks specific examples or references to support the claim about the potential issues with maintaining probabilities at large batch sizes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that additional experiments on larger datasets would be beneficial, which is a valuable piece of feedback for improving the paper. However, the comment also acknowledges the potential issue of computational resources, which is a practical consideration for the authors. The reviewer expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or guidance on how to conduct these additional experiments or address the computational concerns. Overall, the comment is somewhat helpful as it identifies an area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific examples of how the performance of the models in Table 4 is behind more recent models, citing GLaMM and UNINEXT. However, it does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of how the performance of the models in Table 4 is behind more recent models, citing specific models and their performance metrics. This level of detail helps the authors understand exactly what needs to be addressed and how to improve their results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of how these models perform compared to the current models. The claim is supported by the inclusion of references [ref1] and [ref2], which provide evidence for the performance of GLaMM and UNINEXT, respectively. This level of detail and support makes the claim fully verifiable, as it provides a clear basis for the authors to understand and address the issue. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the models in Table 4, noting that they are behind more recent models. It provides concrete examples of how these models perform, referencing GLaMM and UNINEXT, which achieve higher performance metrics. This feedback is valuable as it highlights a clear area for improvement and provides specific examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this performance gap or what steps they could take to improve their results. Despite this, the comment is mostly helpful as it directs the authors to areas that need attention and provides a basis for further discussion. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts. The comment implies that the current phrasing, \"evidence,\" is too strong and suggests a more specific term like \"Fig.\" However, it does not provide explicit guidance on how to revise the claim or what specific changes are needed. The action is implicit and somewhat vague, as the authors need to infer that they should replace \"evidence\" with a more precise term and potentially reference a figure. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts, recommending a more specific term like \"Fig.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should revise their claim about the evidence supporting the idea that some information is learned before the model can use the concepts. The comment implies that the current phrasing, \"evidence,\" is too strong and suggests a more specific term like \"Fig.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as it is based on an inference rather than a clear and substantiated argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the phrasing of a claim in the paper, suggesting that the term 'evidence' might be too strong and recommending a more specific term like 'Fig.' This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to revise the claim or what specific changes to make. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or enhance the novelty of their approach. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning that it relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in detailing the issue but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the innovation of the proposed video storyboarding approach is limited, as it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. The comment provides a specific example of a similar approach, suggesting that the novelty is limited. However, it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis of the claim, which makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. While the comment highlights this limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a weakness but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on few-shot classification using such a dataset. However, the comment does not provide explicit guidance on how the authors should address this weakness or what specific steps they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should conduct the comparison or what data they should use. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or figure that needs attention. Additionally, the comment does not provide specific guidance on how to address this issue or what changes should be made to the paper. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the weakness of the method being addressed might be more prominent in images with multiple objects or cluttered scenes. However, it does not provide any specific evidence, examples, or references to support this claim. Without further elaboration or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method, suggesting that it might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on few-shot classification using such a dataset. However, the comment lacks specific guidance on how the authors should address this issue or what steps they should take to improve their draft. While it provides a direction for further exploration, it does not offer actionable feedback or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, perhaps in the appendix. This provides a clear and explicit action for the authors to take, which is to expand the explanation of the bounds. The comment is specific in its suggestion, detailing what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, specifically mentioning the possibility of including this in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which section or part of the paper needs improvement. Additionally, while it suggests adding more explanation, it does not provide specific examples or guidance on how to do so. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. However, the comment does not provide any specific reasoning, examples, or references to support why this additional explanation would be beneficial. Without detailed justification or evidence, the claim remains somewhat verifiable, as the authors may need to infer the importance of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that additional context or explanation would enhance the paper's clarity and comprehensiveness. By recommending the inclusion of this information in the appendix, the comment offers a concrete direction for the authors to enhance their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to explain the bounds effectively. Overall, the feedback is mostly helpful, as it identifies a clear area for improvement and provides a specific suggestion for action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the implementation of kernels using OpenAI's Triton, rather than CUDA, is unnecessary due to well-known engineering improvements. However, it does not provide explicit guidance on how the authors should address this point or what changes might be needed in their draft. The action is implicit, as the authors would need to infer that they should consider the efficiency of their implementation or provide a rationale for their choice of framework. The comment lacks concrete details on how to implement or address this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Kernels are implemented with OpenAI's Triton, not CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains why the implementation choice is unnecessary due to engineering improvements. This provides the authors with a clear understanding of what needs to be addressed and why. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation of kernels using OpenAI's Triton, rather than CUDA, is unnecessary due to well-known engineering improvements. However, the comment does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how it applies to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific implementation detail regarding the use of OpenAI's Triton for kernels, noting that it is unnecessary due to well-known engineering improvements. While the comment highlights a potential area for clarification or justification in the paper, it does not provide detailed guidance on how the authors might address this point or what changes could be made to their draft. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only marginally helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the zero-shot nature of the experiment and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides examples of tasks that could be used to demonstrate the transferability. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the transferability and provide more information about the tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the zero-shot nature of the experiment and questions the transferability due to the difficulty of the source and target tasks. It provides examples of tasks, such as \"Walker-run\" being harder than \"walker-walk,\" and suggests that the manipulation scenario with rotations could provide sufficient information for policy transfer. However, the comment does not explicitly mention specific sections or parts of the paper that need to be addressed, making it weakly grounded. It is specific in detailing the issues with the transferability and the potential limitations, but without clear references, the authors may struggle to identify the exact areas to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the zero-shot nature of the experiment and the transferability of policies due to the difficulty of the source and target tasks. It provides examples, such as \"Walker-run\" being harder than \"walker-walk,\" and suggests that the manipulation scenario with rotations could provide sufficient information for policy transfer. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims, making it somewhat verifiable. The authors are left to infer the basis for these claims, which could be improved with more detailed explanations or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the zero-shot nature of the experiment and suggests that the transferability of policies might be limited due to the difficulty of the source and target tasks. It provides examples, such as 'Walker-run' being harder than 'walker-walk,' and suggests that the manipulation scenario with rotations could provide sufficient information for policy transfer. However, the comment does not offer specific guidance or suggestions on how to address these concerns or improve the paper's clarity on policy transferability. While it identifies a potential issue, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they need to clarify the transferability and provide more information about the tasks to address the feedback effectively.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the relative gains of the proposed method, suggesting that the improvement might be limited for most baselines and a small backbone like ResNet-50. It also raises a question about the potential effectiveness of the proposed method on larger backbone models like Swin-B or Swin-L. While the comment identifies a potential area for further investigation, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take. The suggestion to explore larger backbones is implicit but lacks concrete details on how to implement this exploration. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the relative gains of the proposed method across different frameworks and tasks, noting that the gains are not very strong. It specifically mentions that the proposed methods achieve only about 1% gain on a relatively small backbone ResNet-50. The comment also raises a question about whether the proposed method would still work well on larger backbone models like Swin-B or Swin-L. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issue with the relative gains and the question about larger backbones. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the relative gains of the proposed method are not very strong, particularly for most baselines and a small backbone like ResNet-50. It suggests that the proposed method might work better on larger backbone models like Swin-B or Swin-L due to the introduction of global pooling. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify the reasoning or understand the basis of the critique. The absence of detailed evidence or logical reasoning makes the claim somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific concern regarding the relative gains of the proposed method, noting that it is not very strong for most baselines and a small backbone like ResNet-50. It also raises a question about the potential effectiveness of the proposed method on larger backbone models like Swin-B or Swin-L, suggesting that the introduction of global pooling might make it easier to improve smaller backbones. While the comment highlights an area for further investigation, it does not provide detailed guidance or suggestions on how to address this issue or explore the performance on larger backbones. The feedback is somewhat helpful as it points out a potential limitation and encourages further exploration, but it lacks depth and actionable advice for the authors to improve their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analysis of neural networks, suggesting that it contributes less due to the triviality of extending from linear models to wide fully-connected neural networks, given the existing NTK theorem. It mentions specific sections of the paper (3.2 and 3.3) where this issue is discussed. However, the comment does not provide explicit guidance on how the authors might address this issue or improve their analysis. While the authors can infer that they need to strengthen their analysis or provide a more detailed discussion of the limitations of the current approach, the lack of concrete suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of the analysis of neural networks and the triviality of extending from linear models to wide fully-connected neural networks. This provides clear guidance on how the authors can improve their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of neural networks contributes less due to the triviality of extending from linear models to wide fully-connected neural networks, given the existing NTK theorem. The comment provides a specific example of how the extension is considered trivial, referencing sections 3.2 and 3.3. However, it lacks detailed reasoning or examples to fully substantiate the claim. While the authors can infer that the analysis might be insufficient, the comment does not offer a comprehensive explanation or evidence to support the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the analysis of neural networks contributes less, suggesting that the extension from linear models to wide fully-connected neural networks is trivial due to the existing NTK theorem. This feedback is somewhat helpful as it highlights a potential weakness in the analysis and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or expand their analysis to include more complex neural network architectures. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. It also mentions that the authors have provided an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the comment does not explicitly instruct the authors to add more datasets or provide additional details on their selection. While the suggestion is clear, it lacks concrete guidance on how to address the issue, such as proposing specific datasets or methods for evaluation. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of dataset size and the number of datasets used for the tasks, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the need for a more rigorous evaluation and suggests that the authors have addressed this concern by providing an addendum clarifying the novelty of the datasets and the motivations for their choice. This feedback is clear and specific, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. The authors provide an addendum clarifying the novelty of the datasets and the motivations for their choice, which supports the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the number of datasets used for the tasks, suggesting that it might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. The authors are informed that the datasets are substantially novel and that the motivations for their choice have been clarified. This feedback is helpful as it provides a specific concern and suggests that the authors have addressed it, which could improve the rigor of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct a more thorough evaluation or suggested specific datasets that could be included. Overall, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth in terms of actionable advice.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the results presented in the paper, noting that while there are good performance results with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback suggests that the authors should include results with larger models to provide a more comprehensive evaluation of their approach. However, the comment does not specify which part of the paper should be updated or how the results should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add results for larger models and potentially update the discussion section to reflect this addition. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"imageNet classification\" and the models used, \"ResNet50/34/18,\" and suggests the inclusion of results for \"larger models like ResNet101/152.\" This provides clear guidance on which part of the paper needs attention. However, the comment is somewhat specific as it does not provide detailed guidance on how to include these results or what aspects of the results should be highlighted. The authors can infer that they need to add results for larger models, but the lack of specific instructions makes it somewhat specific. Therefore, this comment is classified as fully grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results with larger models like ResNet101/152, despite good performance with ResNet50/34/18. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this observation is important or how it relates to the overall content of the paper. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a gap in the results presented in the paper, specifically noting the absence of performance results with larger models like ResNet101/152, despite the good performance with ResNet50/34/18. This feedback highlights an area where the authors could enhance their evaluation by including results with larger models. However, the comment lacks specific guidance on how to incorporate these results or what aspects of the results should be emphasized. While it identifies a potential improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed instructions or suggestions for addressing the issue. Therefore, the comment is rated as somewhat helpful, as it offers a clear direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multi-fidelity framework. It points out a discrepancy in the terminology used (\"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology used in these sections. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the multi-fidelity framework and sequential design for learning quantities of interest, referencing a specific paper (Stroh et al. 2017). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multi-fidelity framework, pointing out a discrepancy in terminology. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract and introduction use inconsistent terminology regarding the cost of the multi-fidelity framework, specifically mentioning \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. While the comment identifies a potential issue with clarity, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the inconsistency, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the clarity of the abstract and introduction regarding the cost of the multi-fidelity framework. It points out a discrepancy in terminology, noting that the abstract uses 'relatively inexpensive' while the introduction uses 'expensive to evaluate.' This feedback highlights a need for the authors to clarify their terminology to avoid confusion. However, the comment does not provide specific suggestions or guidance on how to address this issue, leaving the authors with a general idea of what to improve but lacking detailed actionable advice. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but does not fully guide the authors in making the necessary changes. This aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their method. The feedback is vague and lacks concrete steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how the proposed method addresses sparse reward problems, suggesting that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to identify the exact section being addressed. While the question is specific about the issue of sparse rewards, the lack of grounding makes it challenging for the authors to understand the context and respond effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the proposed method is similar to dense reward signals or that Qmix could solve sparse-reward tasks. Without clear evidence or references, the claim is difficult to verify, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their method. It does not provide actionable feedback or detailed insights into the areas where the method could be enhanced. As a result, the comment is barely helpful, as it identifies a potential issue but does not offer constructive feedback for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of the AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training, implying a need for a fair comparison. While the comment identifies an issue and suggests a potential area for clarification, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of the AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training, implying a need for a fair comparison. However, the comment does not specify which part of the paper discusses the dataset or the training process, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its request for clarification, the lack of grounding makes it challenging for the authors to fully understand the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training, implying a need for a fair comparison. However, the comment does not provide any evidence, reasoning, or references to support the claim that the dataset is not clearly indicated or that the comparison is unfair. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the clarity of the use of the AH36M dataset for training and questions whether other methods, such as HMR and SPIN, have access to this dataset during training. This is important for ensuring a fair comparison between different methods. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments could be conducted to clarify the situation. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights a critical aspect of the paper that needs clarification but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to correct the mistakes, discuss the work in detail, or provide new insights. Without specific suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need attention. The comment is not grounded as it does not provide specific references or sections to address. While it is somewhat specific in identifying the issues, the lack of grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks detailed discussion and comparison with previous work, and that it does not provide new insights in the field. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. While the comment points out these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it highlights areas that need attention, but it lacks actionable advice or detailed suggestions, leaving the authors with a general idea of what to work on but without a clear path forward. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. It also notes that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and that even pre-trained models are compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to clarify the motivation, ensure fair comparisons, or address the concerns about the model's size and the comparison methods. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. However, it does not specify which part of the paper these issues are related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. While the comment is specific in its critique of the motivation and experimental comparisons, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the motivation for using an adversarial network and the fairness of the experimental comparisons. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two main issues with the paper: the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental comparisons. It also points out that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and that even pre-trained models are compared with other models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation or the fairness of their comparisons. While it highlights areas for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment also suggests comparing the paper to other approaches that have been proposed since the initial work and have significantly improved the results. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the captioning experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the comparison of results on the official COOC leader board on the blind test set, referencing specific examples and related work. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should compare its results on the captioning experiment with official test sets or development sets, but it suggests comparing them on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. The comment provides specific references and examples to support its claim, making it mostly verifiable. However, it could be more robust with additional details or examples to fully substantiate the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the comparison of the captioning experiment. It recommends comparing the results on the official COOC leader board on the blind test set, referencing specific examples and related work that have achieved high scores on this challenge. Additionally, it suggests comparing the paper to other approaches that have been proposed since then and have significantly improved the results, providing a clear direction for improvement. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions or provided specific examples of how to compare the results. Overall, the feedback is mostly helpful as it offers actionable insights for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the reliability of the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to verify the results, what steps to take to improve the reliability of the findings, or how to address the discrepancy between MSE and MAE. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE, raising concerns about their validity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand why the results are considered unreliable or how to address the discrepancy between MSE and MAE. Therefore, the comment is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. This feedback is clear and actionable, as it highlights a potential problem with the experimental findings that the authors should investigate and address. However, the comment could be more helpful if it provided suggestions on how to verify the results or what steps to take to improve the reliability of the findings. Despite this, the comment offers valuable insight into a critical aspect of the paper, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the novelty of the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their methodology or what specific aspects need to be improved. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what aspects of the methodology lack novelty or how the proposed meta-algorithm is a direct extension of existing methods. Without specific guidance or examples, the authors cannot effectively address the feedback. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is not much novelty in the methodology and that the proposed meta-algorithm is a direct extension of existing methods. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or references to existing methods, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the methodology lacks novelty and is a direct extension of existing methods. While this feedback highlights an area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable advice, such as recommending specific enhancements or alternative approaches to increase the novelty of the methodology. Without detailed suggestions or examples, the authors may find it challenging to incorporate the feedback into their work. Therefore, the comment is rated as barely helpful, as it points out a concern but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the method, specifically the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific changes should be made to the draft. The comment identifies a gap in the methodology but lacks guidance on how to improve it. As a result, the authors are left without a clear understanding of what actions to take to address the identified issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. Without this context, the authors cannot confidently determine where the issue lies and how to address it. The comment is not grounded as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method, specifically the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any suggestions or guidance on how to address this issue or what specific changes should be made to the draft. The comment highlights a gap in the methodology but lacks actionable feedback, leaving the authors without a clear understanding of how to improve their work. As a result, the comment is barely helpful, as it points out a problem but does not offer any constructive advice or suggestions for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to clarify the terms. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding the meaning of \"wrong\" in the context of the paper. The comment requests clarification on what constitutes a good, bad, or wrong explanation, which is a clear and actionable request for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, specifically at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the use of \"wrong\" is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the use of the term \"wrong\" at line 248. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. This feedback is clear and actionable, as it provides a specific area for improvement and directs the authors to address a potential ambiguity in their writing. By clarifying the meaning of \"wrong,\" the authors can enhance the precision and clarity of their paper, making it easier for readers to understand their arguments. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It notes that the optimization process is performed on a sample-by-sample basis, raising questions about the potential variation in optimal hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as proposing specific methods for hyperparameter tuning or analyzing the impact of different hyperparameters. While the authors can infer that they need to clarify the robustness of their hyperparameter choices, the lack of concrete actions or suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It highlights that the optimization process is performed on a sample-by-sample basis, which raises questions about the potential variation in optimal hyperparameters. However, the comment does not specify which part of the paper discusses the hyperparameter tuning or optimization process, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment identifies a potential issue, it lacks specificity in terms of which part of the paper is being addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It notes that the optimization process is performed on a sample-by-sample basis, which raises questions about the potential variation in optimal hyperparameters. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the hyperparameter tuning process is not robust or that the variation in optimal hyperparameters could be significant. Without additional context or evidence, the claim remains somewhat verifiable, as the authors may need to infer the implications of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It highlights that the optimization process is performed on a sample-by-sample basis, raising concerns about the potential variation in optimal hyperparameters. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as proposing methods for hyperparameter tuning or analyzing the impact of different hyperparameters. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and guidance for the authors to improve their draft.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to others. It suggests that the authors should provide an analysis of the inferior results to align with the motivation of the paper. However, the comment does not specify which methods were used for comparison, nor does it provide guidance on how to analyze the inferior results. The action is implicit and vague, as the authors are left to infer that they need to address the comparison and analysis. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of limited comparisons and inconsistent performance, suggesting that the authors should provide an analysis of the inferior results to align with the paper\\'s motivation. However, it does not specify which methods were used for comparison or which parts of the paper need to be addressed. The lack of specific guidance on which sections or aspects of the paper require attention makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that the authors should provide an analysis of the inferior results to align with the motivation of the paper. However, the comment lacks specific examples or references to support the claim about the limited number of methods or the inconsistent performance. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to other methods. It highlights that the results do not align with the motivation of the paper, suggesting that the authors should provide an analysis of the inferior results to address this concern. While the comment points out a critical weakness, it does not offer specific guidance or suggestions on how to conduct this analysis or what aspects of the results need to be examined. The feedback is somewhat helpful as it directs the authors to an important area for improvement, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting that the paper only compares ELF (the author\\'s method) with a baseline without Mid Vision Feedback (MVF) but lacks a comparison with the image classification results of Mid Vision Feedback (MVF). This feedback suggests that the authors should include such a comparison to better demonstrate the contribution of their method. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors need to infer the need for a comparison and deduce the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of comparison with the image classification results of MVF, which is crucial for demonstrating the superiority of the schema searched by ELF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The comment suggests that this lack of comparison does not prove the superiority of the schema searched by ELF (the author\\'s method) over the schema in MVF. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains somewhat verifiable, as the authors may need to infer the reasoning behind the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the experimental demonstration of the paper's contribution points. It highlights the lack of comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for demonstrating the superiority of the schema searched by ELF (the author's method). This feedback is valuable as it directs the authors to include a more comprehensive experimental comparison, thereby strengthening the paper's claims. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects of the comparison should be included. Overall, the comment is mostly helpful, as it points out a critical area for improvement but lacks detailed suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially concerning occupant comfort and energy efficiency. While the comment identifies a specific area that needs more attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to expand on this aspect, but the comment lacks concrete suggestions or detailed instructions on how to do so. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what the authors should cover, namely the types of activities and their importance in smart homes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. This feedback is somewhat helpful as it highlights a specific area that needs improvement, but it lacks detailed guidance on how the authors might address this gap. The comment provides a clear direction for the authors to expand their discussion, but it does not offer specific suggestions or examples of how to incorporate this information into the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. It recommends using different notation to avoid this ambiguity. The comment is explicit in identifying the issue and provides a clear suggestion for improvement. However, it does not specify how the authors should implement this change, such as suggesting alternative notations or providing examples of how to use them. While the action is clear, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or element being addressed. The comment is specific in its suggestion to use different notation, but the lack of grounding makes it challenging for the authors to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this is a significant issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the symbol \"D\" in the paper, suggesting that it might be confusing as it represents both the dimensionality of points and the dilation factor. This feedback is clear and actionable, as it points out a specific area where clarity could be improved. However, the comment could be more helpful if it provided suggestions for alternative notations or examples of how to use them to avoid confusion. Overall, the comment is somewhat helpful as it highlights a potential issue that needs attention, but it lacks depth in terms of actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of the concept of \"state\" in the paper, suggesting that it is represented by the \"grid status\" (e.g., agent position) and obtained after applying an action of the trace. It also asks whether the term \"elements\" is equivalent to \"states\" or \"actions,\" implying that more elaboration is needed. While the comment identifies a potential area of confusion and suggests that the authors should clarify the concept, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should elaborate on the definition of \"state\" and its relationship to \"elements\" and \"actions.\" However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the clarity of the concept of \"state\" in the paper, specifically mentioning that it is represented by the \"grid status\" (e.g., agent position) and obtained after applying an action of the trace. It then asks whether the term \"elements\" is equivalent to \"states\" or \"actions,\" suggesting that more elaboration is needed. However, the comment does not specify which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the definition of \"state\" and its relationship to \"elements\" and \"actions,\" but without explicit references to the sections or figures, the authors may find it challenging to pinpoint the exact area that requires attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the concept of \"state\" in the paper, specifically asking whether the term \"elements\" is equivalent to \"states\" or \"actions.\" This is a subjective question that requires clarification and does not present a claim that needs verification. The comment does not provide any evidence, reasoning, or references to support the question, making it a factual statement rather than a claim. Therefore, it should be classified as \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential area of confusion regarding the concept of \"state\" in the paper, specifically questioning whether the term \"elements\" is equivalent to \"states\" or \"actions.\" This feedback is valuable as it highlights a need for clarification and suggests that the authors should elaborate on the definition of \"state\" and its relationship to other terms in the paper. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what additional information would be helpful. While it points out a potential area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a clear indication of an area that needs attention but lacks the depth and specificity required for full effectiveness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This comment provides a clear and explicit action for the authors to take, as they can directly compare the support of their proposed scheme with baseline methods using the suggested metric. The action is also concrete, as it specifies the exact method for comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. However, it does not specify which part of the paper this comparison should be made or which sections or figures might contain the necessary information. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while it provides a suggestion for comparison, it lacks specificity in terms of how this comparison should be conducted or what results are expected. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods using a Jaccard index. This is a suggestion for an additional analysis or comparison that could enhance the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is important or how it would be conducted. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the value of the suggestion without explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their work by including an additional comparison. By comparing the support of their proposed scheme with baseline methods, the authors can provide a more comprehensive evaluation of their approach. This feedback is mostly helpful as it offers a concrete suggestion for improvement, but it could be further enhanced by providing more details on the specific aspects of support to compare or the expected outcomes of the comparison. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue in Section 5.3, noting that a generator with a standard R-GCN discriminator tends to collapse, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paper. The action is implicit, as the authors need to infer that they should provide a detailed explanation of the mechanism behind the proposed module's stability. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue in that section, noting that a generator with a standard R-GCN discriminator tends to collapse, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones, implying that the authors should provide a detailed explanation of this mechanism. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a generator equipped with a standard R-GCN discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that the reason behind this difference is essential to demonstrate how the proposed method differs from previous ones. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or logical arguments to substantiate the assertion that the proposed module prevents collapse. Without additional evidence or explanation, the claim remains somewhat verifiable, as it lacks the necessary depth and support to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue in Section 5.3, noting that a generator with a standard R-GCN discriminator tends to collapse, while the proposed module does not. It highlights the importance of explaining the mechanism behind this difference to demonstrate how the proposed method differs from previous ones. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific improvements could be made to the paper. While it points out a potential area for enhancement, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should provide a detailed explanation of the mechanism behind the proposed module's stability, but the comment does not offer concrete steps or examples to facilitate this improvement. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or enhance the originality of their work. The action is implicit and vague, as it does not specify what steps the authors should take to differentiate their work or provide evidence of novelty. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is not grounded as it lacks specific references or sections, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the claim remains unverifiable, as the authors cannot confidently assess the validity of the concern. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic are similar to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. It lacks actionable advice, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete details on what needs to be clarified or improved. As a result, the authors are left without a clear understanding of how to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper discusses these comparisons, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment identifies a potential area for improvement but lacks actionable advice, leaving the authors without a clear path forward. As a result, the feedback is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model's comprehension of object presence. However, it does not provide explicit guidance on how the authors should address this issue or what alternative methods could be used. The comment implies that the authors should consider expanding their evaluation methods, but it lacks concrete suggestions or detailed instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not offer specific guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\\'s comprehension of object presence. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is not grounded as it does not provide specific references or sections of the paper that are relevant to the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\\'s comprehension of object presence. The comment implies that a yes response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks detailed evidence or references to substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a positive response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects in other tasks. This feedback is somewhat helpful as it identifies a potential limitation in the evaluation method, but it lacks detailed guidance on how the authors might address this issue or what alternative evaluation methods could be considered. The comment provides a starting point for improvement but does not offer comprehensive suggestions or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the very-long-term forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide context for the results. While the comment provides explicit guidance on what actions the authors should take\u2014namely, to conduct additional experiments and train models with the correct forecast horizon\u2014it does not specify how to implement these actions or what specific datasets or forecast horizons to use. The actions are concrete but lack detailed guidance, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the very-long-term forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to put the results in a proper context. However, the comment does not specify which part of the paper discusses the very-long-term forecasting task or which sections or figures need improvement. This lack of grounding makes it difficult for the authors to identify the specific areas that require attention. While the comment is specific about the need for additional experiments and training, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the very-long-term forecasting task is of limited practical significance and suggests improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the limited practical significance of the task. The suggestion to conduct experiments on more datasets and train models with the correct forecast horizon is clear and actionable, but the overall claim is somewhat verifiable due to the lack of detailed evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practical significance of the very-long-term forecasting task and suggests ways to improve the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is actionable and provides specific suggestions for enhancing the paper's content and context. However, it could be more helpful if it included additional guidance on which datasets or forecast horizons to use or how to effectively present the results. Despite this, the comment offers valuable insights that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific area of the experiments section, namely the missing components related to different queries used in spatio-temporal representation (spatial, temporal, and summary). It suggests that the authors should include experiments and explanations for these different queries, particularly in comparison to VideoChatGPT and other works. The comment implies that the authors should provide a detailed explanation of how these different queries are used and what the implications are. However, it does not explicitly instruct the authors to add these components or provide specific guidance on how to conduct the experiments. The action is implicit and somewhat vague, as the authors need to infer that they should include these components and provide explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments - Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing components, namely the experiments and explanation regarding the different queries used in spatio-temporal representation (spatial, temporal, and summary). The comment requests additional experiments and explanations, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments section is missing components regarding different queries used in spatio-temporal representation, specifically spatial, temporal, and summary queries. It suggests that the authors should include experiments and explanations for these different queries, particularly in comparison to VideoChatGPT and other works. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that these components are missing or critical. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the experiments section, noting the absence of components related to different queries used in spatio-temporal representation, such as spatial, temporal, and summary queries. It highlights the importance of these components, particularly in comparison to VideoChatGPT and other works, and raises questions about the implications of using only spatial, temporal, or summary queries. While the comment points out a specific area for improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors would need to infer that they should include experiments and explanations for these different queries to enhance the completeness and depth of their work. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not provide explicit guidance on how to detail the innovative aspects or what specific aspects need to be elaborated upon. The action is implicit and vague, as the authors are left to infer that they need to provide more details on the innovative aspects of the FRM. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not specify which part of the paper this comment is addressing, such as a specific section or figure. The comment is vague and does not provide any guidance on what needs to be detailed or how to elaborate on the innovative aspects. As a result, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Since the comment lacks specificity in detailing what needs to be addressed, it is not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the FRM is a simple combination of these attention mechanisms. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed FRM, suggesting that it is a simple combination of channel attention and spatial attention. It implies that the innovative aspects of the FRM should be detailed. However, the comment lacks specificity and does not provide concrete suggestions or guidance on how to elaborate on the innovative aspects. Without additional details or examples, the authors may struggle to understand what specific areas need to be expanded upon. Therefore, the comment is barely helpful, as it provides a general observation but lacks actionable feedback. The score of 2 aligns with this assessment.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors' claim about the lack of negative social impact, suggesting that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to incorporate these points into their draft. The action is implicit, as the authors need to infer that they should add a discussion on these aspects. However, the comment is somewhat actionable because it provides a concrete idea of what to include, making it easier for the authors to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Societal impact,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what the authors could include to address the issue of potential negative social impacts, such as mentioning the social impact of increased automation or the risks from the dual use of their method. This provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors' claim about the lack of negative social impact, suggesting that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. While the comment provides a suggestion for improvement, it does not offer specific examples or references to support the claim that the work has the potential for significant negative social impact. The reasoning is somewhat vague, as it lacks detailed justification or evidence. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides a basis for improvement but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the authors' claim regarding the lack of negative social impact of their work. It questions the authors' assertion and suggests that they should consider mentioning the social impact of increased automation or the risks associated with the dual use of their method. This feedback is somewhat helpful as it provides a direction for the authors to address a potential weakness in their work. However, the comment could be more helpful if it offered specific examples or guidance on how to incorporate these points into the draft. Overall, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. This provides clear and explicit guidance on how the authors should reorganize their paper to improve its structure and flow. The actions are concrete, as they specify exactly what needs to be done to achieve the desired outcome. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. However, the comment does not specify which parts of the sections are redundant or why they are redundant, making it difficult for the authors to identify the exact issues that need to be addressed. While the comment provides a general direction for improvement, it lacks specific details about what needs to be done to make the sections less redundant. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy. However, it does not provide any evidence or reasoning to support why these sections are redundant or how the suggested actions would effectively reduce the redundancy. Without specific examples or justifications, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential redundancy between Section 3 and Section 4, suggesting that the first paragraph of Section 4 could be moved to Section 3 and the remainder of Section 4 could be placed before Section 3. This feedback is specific and actionable, providing clear guidance on how the authors might reorganize their paper to improve its structure and flow. By addressing this redundancy, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it included additional suggestions or considerations for the reorganization, such as the specific content that should be moved or the rationale behind the proposed changes. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clear connection between two concepts: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" It suggests that the authors should clarify this connection, but it does not provide specific guidance on how to do so. The comment is explicit in identifying the issue but lacks detail on how to address it, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in identifying the need for clarification but lacks grounding as it does not provide explicit references to the paper sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the connection between two concepts: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" While it points out a lack of clarity, it does not provide specific suggestions or guidance on how to improve the connection or clarify the concepts. This feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the notation used in the paper, pointing out that the notation \\hat v^*_t is unusual and inconsistent with the standard use of \\hat for empirical estimates. While the comment highlights a potential inconsistency, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors would need to infer that they should clarify or correct the notation to align with standard conventions. However, the lack of concrete suggestions or guidance on how to implement this change makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, L434, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed, namely the unusual notation used for \\hat v^*_t, which is inconsistent with standard usage. This provides clear guidance on how the authors should revise the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the notation used in the paper, noting that the notation \\hat v^*_t is unusual and inconsistent with the standard use of \\hat for empirical estimates. While the comment highlights a potential inconsistency, it does not provide any supporting evidence or reasoning to justify why this inconsistency is problematic or how it affects the paper's conclusions. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, pointing out that the notation \\hat v^*_t is unusual and inconsistent with the standard use of \\hat for empirical estimates. This observation is clear and highlights a potential inconsistency that could affect the clarity and accuracy of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to improve the notation. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions in NAS, and why deterministic MLP predictors outperform robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, it does not provide explicit guidance on how to conduct these analyses or experiments, nor does it offer concrete steps for the authors to take. The comment is somewhat actionable as it identifies a potential area for improvement but lacks detailed instructions on how to implement it. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the areas where additional analysis could enhance the paper, specifically regarding the comparison of a simple greedy selection approach with more principled acquisition functions in NAS and the performance of deterministic MLP predictors compared to robust probabilistic predictors. This provides clear guidance on which parts of the paper need attention. The comment is also specific, as it suggests detailed analyses to explain the observed results, offering a clear direction for improvement. Therefore, this comment is classified as fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the potential for more novel and interesting contributions by suggesting that the paper could explore theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions in NAS and why deterministic MLP predictors outperform robust probabilistic predictors. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the claim and how it might be addressed. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions in NAS and why deterministic MLP predictors outperform robust probabilistic predictors. This feedback provides a clear direction for the authors to enhance the depth and impact of their work. However, the comment lacks specific guidance on how to conduct these analyses or experiments, which could limit its helpfulness. While it offers a valuable suggestion, the lack of detailed instructions makes it somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to provide a citation for the k-max problem, implying that it has been discussed elsewhere in the paper. However, it does not explicitly instruct the authors to include a citation or specify where the discussion can be found. The action is implicit and somewhat vague, as the authors need to infer that they should add a citation and then determine where to place it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks the authors to provide a citation for the k-max problem, implying that it has been discussed elsewhere in the paper. However, it does not specify which part of the paper the k-max problem is discussed in, making it weakly grounded. The comment is specific in its request for a citation, but the lack of grounding makes it difficult for the authors to know where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification or additional information regarding the k-max problem. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question that prompts the authors to provide a citation for the k-max problem, suggesting that it has been discussed elsewhere in the paper. While it identifies a potential area for improvement by requesting a citation, it does not offer specific guidance on how to address this issue or what information might be relevant. The comment is vague and lacks actionable suggestions, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it points out a missing detail, it does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify or improve the explanation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the estimation process and the model's reliability. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide any specific examples, references, or reasoning to support the claim that this information is missing or critical. The authors are left to infer the importance of this information, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is clear and actionable, as it directs the authors to provide additional details or clarification regarding the estimation process and the model's reliability. By addressing this issue, the authors can improve the transparency and robustness of their methodology, making the paper more comprehensive and understandable. The comment is mostly helpful as it provides a clear direction for improvement, though it could be more detailed by suggesting specific ways to enhance the explanation or provide additional context. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the applicability of the methods to real-world problems due to strong assumptions about camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might relax these assumptions or improve the methods to be more applicable to real-world scenarios. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods to real-world problems, specifically mentioning the strong assumptions made about camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper discusses these assumptions or how they impact the methods. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in identifying the issue with the assumptions, but without clear grounding, the authors may struggle to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the applicability of the methods to real-world problems is limited due to strong assumptions about camera parameters and object segmentation. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the applicability of the methods to real-world problems, specifically due to strong assumptions about camera parameters and object segmentation. This feedback is valuable as it highlights a potential area for improvement, suggesting that the authors should consider relaxing these assumptions to enhance the methods' applicability. However, the comment lacks specific guidance or suggestions on how to address these limitations, such as potential approaches or alternative methods that could be explored. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. The comment is explicit in identifying a specific issue with the text and provides a clear action for improvement by suggesting a more precise term. This allows the authors to directly address the inaccuracy and enhance the clarity of their writing. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L006\" in the main text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding \"on the subword level\" to clarify the use of \"thousands,\" providing a clear direction for improvement. This feedback is detailed and actionable, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the use of \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for improvement is clear, but the absence of additional context or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the text, noting that the use of \"thousands\" is not accurate and suggests adding \"on the subword level\" for clarity. This feedback is clear and actionable, providing the authors with a direct and constructive suggestion to improve the accuracy and precision of their writing. By addressing this issue, the authors can enhance the clarity and effectiveness of their paper. Therefore, the comment is mostly helpful, as it offers a clear and actionable improvement that would benefit the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises several points that could be actionable for the authors. First, it notes that certain hyperparameters, such as regularization, are not specified, which could be clarified by explicitly listing them. Second, it questions the y-value at x=0 in the latent path figures, asking if it is normalized and why. This suggests that the authors should provide more detail about the normalization process or clarify the behavior of the model at this point. Finally, the comment suggests that further analysis using interpolations would be interesting, implying that the authors should consider including this in their analysis. While the comment provides several potential areas for improvement, it lacks specific guidance on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to hyperparameters, latent path figures, and further analysis using interpolations. It explicitly mentions \"hyperparameters (e.g. regularization)\" and \"latent path figures (e.g. Fig 3),\" indicating that the authors can accurately identify the parts of the paper being addressed. The comment also suggests further analysis using interpolations, which is a specific request for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the inclusion of hyperparameters, the behavior of y-values at x=0 in latent path figures, and suggests further analysis using interpolations. While the comment identifies areas for clarification and potential improvement, it lacks specific reasoning or references to support the claims. The authors are left to infer the need for these clarifications and suggestions, which could be more effectively addressed with detailed explanations or references. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides several specific suggestions for improvement, such as clarifying the inclusion of hyperparameters, questioning the behavior of y-values at x=0 in latent path figures, and suggesting further analysis using interpolations. These points offer actionable feedback that could help the authors enhance the clarity and depth of their work. However, the comment could be more helpful if it provided more detailed guidance on how to address these issues or included examples of how to improve the analysis. Overall, the feedback is somewhat helpful, as it identifies areas for improvement but lacks comprehensive detail.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. While the comment explicitly mentions these issues, it does not provide specific guidance on how the authors should address them. The authors are left to infer that they need to clarify the forward referencing, provide more detailed explanations in the introduction, and ensure that the supporting material is moved to the main sections. This lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. Additionally, it points out that the material supporting the main contributions, including the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, which is not properly explained, and that the contributions are unclear in the introduction. It also notes that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. The comment provides specific examples of issues, such as Figure 1 and the introduction, and suggests that the authors should clarify the forward referencing and provide more detailed explanations of the contributions. However, it lacks detailed reasoning or references to support these claims, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is located in the appendix rather than the main sections. While the comment highlights these areas for improvement, it does not provide specific guidance on how the authors should address these issues or suggest alternative approaches. The feedback is somewhat helpful as it directs the authors to areas that need clarification and improvement, but it lacks depth and actionable suggestions, making it a 3 out of 5.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor, specifically in terms of epsilon. It asks for clarification on whether there is an error bound related to epsilon. While the comment identifies a specific area of uncertainty, it does not provide explicit guidance on how the authors should address this question or what steps they should take to clarify it. The action is implicit, as the authors need to infer that they should explore or explain the error bound. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the rounding of core tensors and the effect on approximation error in the full tensor. It mentions the use of clustering or error decision epsilon, which provides some grounding to the part of the paper being discussed. However, it does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in that it questions the effect of rounding on the approximation error and asks for clarification on whether there is an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It asks whether there is an error bound related to epsilon. While the comment identifies a specific area of concern, it does not provide any evidence, reasoning, or references to support the claim that the authors should explore this issue. The question is open-ended and lacks detailed guidance or justification, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It asks whether there is an error bound related to epsilon, which is a relevant concern for the authors to address. However, the comment lacks specific guidance or suggestions on how the authors might explore or clarify this issue. While it identifies a potential area for improvement, it does not provide actionable steps or insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out a potential area of concern but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the two test settings in visual dialog and the results presented in Table 1, which only shows the result for the discriminative setting. The reviewer questions the applicability of the discriminative setting to real-world applications and asks for the result on the generative setting. This comment implies that the authors should provide results for the generative setting to address the gap in the evaluation. However, it does not explicitly instruct the authors to include the generative setting results or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the generative setting results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings mentioned. It questions the applicability of the discriminative setting to real-world applications and asks for the results on the generative setting. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what is missing in the evaluation and what additional results are needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the applicability of the discriminative setting in real-world applications and asks for results on the generative setting. While it does not contain a subjective claim or opinion, it poses a logical question that requires the authors to consider the relevance of their results. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The comment is clear and logical, but it does not provide detailed reasoning or evidence to fully substantiate the question. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that Table 1 only presents results for the discriminative setting, while there are two test settings mentioned. It questions the applicability of the discriminative setting to real-world applications and asks for the results on the generative setting. This feedback is clear and actionable, as it directs the authors to provide additional results for the generative setting to address the gap in the evaluation. By highlighting this discrepancy, the comment helps the authors improve the comprehensiveness and relevance of their findings. However, it could be more helpful if it provided guidance on how to present or interpret the generative setting results. Overall, the comment is mostly helpful, as it effectively points out an area for improvement and encourages the authors to expand their evaluation.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what additional evidence or reasoning should be included, nor does it provide concrete guidance on how to achieve this. The comment is vague and lacks explicit instructions, making it difficult for the authors to understand what action to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is vague and lacks specificity, as it does not detail what evidence or reasoning should be included. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to address it. Without additional context or references, the claim remains vague and challenging to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specificity and does not offer detailed guidance or suggestions on how to achieve this. It is vague and does not provide actionable feedback, making it barely helpful. The authors are left without a clear understanding of what additional information or reasoning is needed to strengthen their claims. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed approach, noting that its effectiveness is not known for other language families. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or demonstrate the effectiveness of their approach across different language families. Without specific suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed approach, noting that its effectiveness is unknown for other language families. However, it does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to understand where the issue lies and how to address it. Additionally, the comment is specific in identifying the problem but lacks detail on how to address it. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed approach is unknown for other language families. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that the effectiveness of the proposed approach is unknown for other language families. This observation highlights a critical gap in the research, as it suggests that the findings may not be generalizable to other language families. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue. Without specific advice on how to investigate or demonstrate the effectiveness of the approach across different language families, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it points out a crucial limitation but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant gap in the paper, noting that the authors do not analyze the security of the proposed framework, specifically regarding the protection of privacy. While the comment identifies a clear area for improvement, it does not provide any specific guidance or suggestions on how the authors might address this issue. The authors are left with the task of independently determining how to analyze and discuss the security aspects of their framework, which makes the comment somewhat actionable. However, the lack of explicit guidance on what aspects to analyze or how to approach the analysis leaves the authors with limited direction. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the security aspect of the proposed framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue of privacy protection, which is a crucial aspect of security analysis. The comment provides a clear direction for the authors to address the lack of analysis in this area, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not analyze the security of the proposed framework, specifically regarding the protection of privacy. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the security of the proposed framework, particularly concerning privacy protection. This feedback is valuable as it highlights an area where the authors could enhance the robustness and reliability of their work. However, the comment could be more helpful if it provided some guidance on how the authors might approach this analysis or suggested specific aspects of security to consider. Without these additional details, the authors are left with a clear indication of a need for improvement but with limited direction on how to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This provides a clear and explicit action for the authors to take, as they need to either explicitly state the form of p or provide a reference to where it is discussed. The comment is specific and concrete, giving the authors a clear direction on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the form of p should be described near line 135, implying that the authors should provide more context or clarification regarding this aspect of their work. However, the comment does not specify which part of the paper line 135 refers to, making it weakly grounded. It is specific in suggesting that the form of p should be described, but without a clear reference to the section or table, the authors may find it challenging to locate the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This claim is somewhat verifiable as it points out a specific area where the paper could be improved by providing more context or clarification. However, it lacks detailed reasoning or examples to fully support the suggestion, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that the form of p should be described near line 135. It acknowledges that the authors assume p is a Gaussian distribution but do not explicitly state it, which could lead to confusion. By suggesting that the form of p should be described, the comment offers a clear and actionable direction for the authors to enhance the clarity and completeness of their paper. This feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive if it included additional suggestions or guidance. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which parts of the related work section need improvement or how the authors should address this issue. The comment lacks explicit guidance on what specific aspects of the related work need to be clarified or expanded upon, making it somewhat actionable. The authors know that they need to provide more detail on the differences between related works, but they are not given concrete steps on how to do so. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which part of the section this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to improve the description of differences, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the related work section, noting that while some related works are named, their differences are not adequately described. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the related work section by offering more detailed comparisons between the cited works. However, the comment could be more helpful if it suggested specific ways to improve the descriptions or provided examples of how to differentiate the related works. Despite this, the feedback is mostly helpful as it guides the authors towards a more comprehensive and detailed related work section.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the authors should clarify this point, but it does not provide specific guidance on how to do so. The comment is explicit in identifying a missing explanation but lacks detail on how to implement this action. Therefore, it is categorized as borderline actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for clarification, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. While the comment raises a valid point about the importance of reliable PPP metrics, it does not provide any specific evidence or reasoning to support why this explanation is missing or how it could be addressed. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the need for clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that while the authors mention the importance of reliable PPP metrics for understanding PPP effects, they do not explicitly explain what kind of understanding one reaches by examining the PPP maps. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the insights gained from the PPP maps. However, the comment could be more helpful if it suggested specific ways to clarify this point, such as providing examples or a brief discussion of the expected understanding. Overall, the comment is mostly helpful, as it highlights a crucial aspect that needs further elaboration in the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparison with state-of-the-art methods, such as SpanBERT, which could impact the credibility of the authors\\' work. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons they should include. The action is implicit, as the authors need to infer that they should compare their methods with state-of-the-art approaches to strengthen their credibility. While the action is clear, it lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with state-of-the-art methods, such as SpanBERT, which is a specific aspect of the paper. It specifies what needs to be addressed, namely the absence of such comparisons, which is crucial for credibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not compare their methods with other state-of-the-art methods for span-related tasks, such as SpanBERT, which could impact the credibility of their work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is somewhat verifiable, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with state-of-the-art methods, specifically mentioning SpanBERT. This is a crucial oversight as it affects the credibility and impact of the authors\\' work. By highlighting this issue, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific guidance on how the authors might compare their methods with SpanBERT or other relevant state-of-the-art approaches. Despite this, the comment is mostly helpful as it directs the authors to an important area for enhancement, allowing them to strengthen their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' discussion of regret, specifically regarding whether the prediction error over the entire horizon T can be sublinear. It points out a potential inconsistency in the authors' approach, where they discuss the impossibility of sublinear regret but then proceed to prove that their method achieves T^{1/2} regret. The comment implies that the authors need to clarify their discussion of regret and ensure consistency in their claims. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their discussion of regret. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 32-37 of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the discussion of regret, questioning whether the prediction error over the entire horizon T can be sublinear. This provides a clear direction for the authors to address the inconsistency in their claims. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' discussion of regret, specifically regarding whether the prediction error over the entire horizon T can be sublinear. It points out a potential inconsistency in the authors\\' approach, where they discuss the impossibility of sublinear regret but then proceed to prove that their method achieves T^{1/2} regret. The comment implies that the authors need to clarify their discussion of regret and ensure consistency in their claims. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for clarification and potentially seek additional context to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the authors\\' discussion of regret. It points out that while the authors discuss the impossibility of sublinear regret, they proceed to prove that their method achieves T^{1/2} regret, creating a potential confusion. The comment suggests that the authors need to clarify their discussion of regret to ensure consistency in their claims. This feedback is clear and actionable, as it provides a specific area for improvement and encourages the authors to address the inconsistency in their reasoning. However, it could be more helpful if it offered additional guidance on how to clarify the discussion or what specific aspects of the regret analysis need to be addressed. Overall, the comment is mostly helpful, as it effectively highlights a critical issue that needs attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of detailed explanation of the forward-prediction model and the poor schematic representation in Figure 2(b). It suggests that the figure should be redrawn and that the connection between the text, figure, and equations is unclear. While the comment provides explicit actions\u2014implying that the authors should improve the explanation, redraw the figure, and clarify the connection\u2014it does not offer concrete guidance on how to achieve these improvements. The actions are somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the forward-prediction model, the schematic representation in Figure 2(b), and the difficulty in connecting the text, figure, and equations. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details of the forward-prediction model are not well explained, and Figure 2(b) does not accurately represent the schematic of the model. It also notes that the connection between the text, figure, and equations is unclear. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate these claims. The authors are left to infer the exact nature of the issues, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper that needs improvement, namely the explanation of the forward-prediction model. It points out that the details are not well explained and that Figure 2(b) does not accurately represent the schematic of the model. Additionally, it notes that the connection between the text, figure, and equations is unclear, making it difficult for the authors to understand the model. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to improve the explanation or the figure. This feedback is somewhat helpful as it directs the authors to areas that require attention, but it lacks depth and actionable advice, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The suggestion to provide a stronger baseline is vague and lacks concrete details on how to implement it. Therefore, the comment is not actionable, as it does not offer clear and direct instructions for the authors to follow. This aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the training data, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment lacks specific examples or references to support the claim that such supervision is ignored. It does not provide detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered borderline verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone, and proposes that the authors should provide a stronger baseline to prove the usefulness of FP. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the training data. While it identifies a potential weakness, it does not provide actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to clarify the statement. The action is implicit, as the authors would need to infer that they should revise the statement to accurately reflect the operation of the RNNs. The lack of concrete suggestions or detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs revision. While the comment is specific in its critique of the multi-scale statement, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer provides a logical explanation for this claim, arguing that the sequentialization in the graph leads to logical time scales. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. While the comment raises a valid concern about the clarity and accuracy of the statement, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks actionable advice or detailed explanations, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the baseline methods used in the paper are weak and do not represent state-of-the-art approaches. It also notes the absence of a discussion on the limitations of the work. Additionally, the reviewer suggests that the conclusion could include a discussion of the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors need to infer how to improve their draft based on the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the weakness of the baseline methods used in the paper, suggesting that they are weak and not representative of state-of-the-art approaches. It also points out the absence of a discussion on the limitations of the work. However, the comment does not specify which part of the paper discusses the baseline methods or where the discussion of limitations is located. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues with the baseline methods and the lack of discussion on limitations, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the baseline methods are weak and not representative of state-of-the-art approaches, and that there is no discussion of limitations. It also suggests that the conclusion could include a discussion of the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. The reasoning is vague and does not provide detailed evidence or guidance on how to address the issues. Therefore, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that the baseline methods used are weak and do not represent state-of-the-art approaches. It also notes the absence of a discussion on the limitations of the work, which is a crucial aspect for a comprehensive evaluation. Additionally, the comment suggests that the conclusion could be enhanced by discussing the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. While the comment provides some direction for improvement, it lacks specific guidance on how to address these issues or what actions the authors should take to strengthen their work. The feedback is somewhat helpful as it highlights important areas for improvement, but it could be more detailed and actionable to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should clarify the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. It implies that the authors should make this distinction clearer upfront. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specific sections or examples where this clarification should be added. The action is implicit and somewhat vague, as the authors need to infer how to apply it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of expected performance under observation noise, suggesting that it is typically used because the decision-maker is interested in the true objective function and assumes noise. However, it points out that in the paper's formulation, the decision-maker does care about the noise, and the objective function of interest is a stochastic noisy function. This feedback is specific in its critique of the paper's formulation and suggests a clearer distinction should be made. However, it does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should clarify the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. This claim is somewhat verifiable as it provides a logical reasoning for why the distinction is important and suggests that it should be made clearer upfront. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper's evaluation methodology, suggesting that the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function, should be clarified upfront. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the paper's clarity and rigor. By highlighting this distinction, the comment offers a concrete suggestion for the authors to address, making it mostly helpful. However, it could be more helpful if it provided additional guidance on how to clarify this distinction or suggested specific sections where this clarification should be made. Overall, the comment is mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment does not explicitly instruct the authors to run the suggested experiment or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the doubly stochastic construction and the use of VGAE with a vamp prior, which are relevant to the paper. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. This provides clear guidance on what needs to be addressed in the paper, making it fully grounded. The comment is specific in its suggestions and requests for clarification, providing detailed guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific examples or references to support the claim that this approach would be effective or how it would impact the results. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestions. Therefore, the comment is rated as borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the potential use of VGAE with a vamp prior to better match the doubly stochastic construction in the work, suggesting that this could help determine whether the observed benefits are due to a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific guidance or suggestions on how to implement these ideas or what experiments to conduct to validate the claims. While it identifies areas for improvement, it does not provide detailed feedback or actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method, suggesting it is somewhat incremental. It also mentions that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the novelty or contribution of the method or how to better articulate the inspiration from prior work. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty and contribution of the method, noting that it is somewhat incremental and inspired by prior work. However, it does not specify which part of the paper this claim is based on, such as a particular section or table. The comment is vague in terms of what needs to be addressed to improve the novelty or contribution. Therefore, the comment is not grounded, as the authors cannot confidently determine which part of the paper it addresses, and it is also not specific, as it lacks detail on what needs to be improved. This aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty and contribution of the method are somewhat incremental, suggesting that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the assertion that the contribution is incremental. Without concrete examples or references, the claim remains somewhat verifiable, as the authors may need to infer the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically questioning the novelty and contribution of the method. It suggests that the method is somewhat incremental and that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it highlights an area for improvement, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to address the feedback, which limits the comment's usefulness. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of long-range dependencies for powerful predictors in the context of semantic segmentation. It suggests that the paper should discuss whether locality with respect to the 2D image space is encoded in the graph structure and how this might affect prediction. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper opens that learning long-range dependencies is important for powerful predictors,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of long-range dependencies in the context of semantic segmentation and suggests a discussion about the balance between locality and long-range dependencies. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of long-range dependencies in the context of semantic segmentation, suggesting that the paper should discuss the balance between locality and long-range dependencies. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered fully verifiable. Therefore, it is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a pertinent question about the necessity of long-range dependencies in the context of semantic segmentation, specifically questioning whether locality with respect to the 2D image space is encoded in the graph structure. This feedback highlights a potential gap in the paper's discussion and encourages the authors to explore the balance between locality and long-range dependencies. While the comment does not provide explicit suggestions for improvement, it identifies a critical area for further discussion, which could enhance the paper's depth and clarity. Therefore, the comment is somewhat helpful, as it offers a clear direction for the authors to consider but lacks detailed guidance on how to address the issue.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches or theoretical results. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks concrete guidance on how to address these issues, such as clarifying the meaning of $e_l$, providing additional context for the exponential dependence, or suggesting ways to improve the proposed approaches. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also mentions the potential weakness of the proposed approaches or theoretical results. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the potential weakness of the proposed approaches or theoretical results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies specific issues in the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also points out a potential weakness in the proposed approaches or theoretical results, suggesting that the performance may be more quickly getting worse than standard random features. However, the comment lacks actionable guidance or suggestions for the authors to address these issues. Without specific advice on how to clarify the term $e_l$, provide additional context for the exponential dependence, or improve the proposed approaches, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies areas for improvement but does not provide sufficient guidance for the authors to act upon.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the authors' explanation of the poor long-range modelling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The comment implies that the authors should consider discussing oversmoothing, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the poor long-range modelling ability of DGNs, specifically mentioning oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific paper to support the claim about oversmoothing. However, the comment does not explicitly mention which part of the paper it is addressing, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the part of the paper being discussed. The comment is specific in detailing the issue and suggesting an additional factor to consider, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modelling ability of DGNs could be due to oversmoothing, in addition to oversquashing and vanishing/exploding gradients. The comment references a specific paper to support the claim about oversmoothing. However, it does not provide detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from a more comprehensive explanation of how oversmoothing contributes to the observed performance issues, potentially with additional references or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors' explanation of the poor long-range modelling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. The comment references a specific paper to support the claim about oversmoothing, which could help the authors address this issue more comprehensively. However, the comment does not provide detailed guidance on how the authors should incorporate this additional factor into their discussion or analysis. While it offers a valuable insight, it lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the model collapsing less than other methods is a common occurrence and whether the authors have observed it in their experiments. While it prompts the authors to consider this aspect, it does not explicitly instruct them to provide evidence or address it in their draft. The action is implicit, as the authors need to infer that they should investigate and potentially include this information. However, the comment lacks concrete guidance on how to address this question or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it asks for clarification on whether this phenomenon is commonly encountered and whether the authors have observed it in their experiments. This provides a clear direction for the authors to address the question, but the lack of explicit grounding makes it challenging for them to pinpoint the exact section to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. However, it does not provide any evidence, reasoning, or references to support the claim that this phenomenon is commonly encountered or observed in the authors' experiments. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. It prompts the authors to consider whether this phenomenon is commonly encountered and whether they have observed it in their experiments. While the comment identifies an area that could be explored further, it lacks detailed guidance or suggestions on how to address this question or what specific aspects of the model's behavior to investigate. The feedback is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable steps or detailed insights to guide the authors in enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the problem formulation. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the paper these examples are located in, making it difficult for the authors to pinpoint the exact areas that need clarification. Additionally, the comment lacks specificity in terms of what aspects of the problem formulation are unclear, such as specific details or assumptions that need to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left without a clear understanding of why the problem formulation is unclear or how it might be improved. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the introduction and statement examples. However, it lacks specific details or suggestions on how the authors might address this issue. Without actionable guidance or examples of how to improve the clarity, the authors may find it challenging to make meaningful revisions to their draft. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and explicit action for the authors to take, as they can directly implement the suggestion by adding experiments with these models. The comment is specific in its recommendation, detailing which models should be used and how this would enhance the paper\\'s applicability and generalizability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental section. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks experiments on different LLM families and suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\\'s applicability and generalizability. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the paper lacks these experiments or how the suggested trials would enhance its applicability. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\\'s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly points out a specific area for improvement and provides concrete examples of models that could be used to enhance the paper\\'s comprehensiveness. By addressing this suggestion, the authors can significantly strengthen their work and provide a more robust evaluation of their method. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method described in the paper only works for generative models that can be fine-tuned as in/outpainting models. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing additional details. Without further guidance on how to address this limitation, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method described in the paper only works for generative models that can be fine-tuned as in/outpainting models. However, it does not specify which part of the paper this limitation is discussed or how it affects the overall methodology. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this limitation or improve the method. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method described in the paper only works for generative models that can be fine-tuned as in/outpainting models. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the scope and implications of the limitation. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a limitation in the method described in the paper, specifically that it only works for generative models that can be fine-tuned as in/outpainting models. While this observation highlights a potential constraint on the applicability of the method, it does not provide any suggestions or guidance on how to address this limitation or improve the method. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, the comment is barely helpful, as it identifies a problem but does not offer any constructive advice or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer suggests that the current presentation does not clearly explain how these two parts are related, which could make it difficult for readers to understand the overall narrative. However, the comment does not provide specific guidance on how the authors should improve the connection between these parts. It lacks concrete suggestions or actionable steps that the authors can take to address this issue. As a result, the comment is not actionable, as the authors are left without clear directions on how to improve their draft. Therefore, this comment aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. However, it does not specify which part of the paper this concern is directed towards, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the connection between the two parts, but it lacks grounding as it does not provide explicit references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the discrepancy between the initial understanding of the first part and the actual content, suggesting that the connection is not as clear as it could be. However, the comment lacks specific examples or references to support the claim that the connection is weak. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by pointing out a lack of clear connection between the first part, which discusses curve finding, and the second part, which focuses on FGE. The reviewer highlights a discrepancy between the initial understanding of the first part and the actual content, suggesting that the connection between the two parts is weak. This feedback is somewhat helpful as it provides a specific area for improvement, but it lacks detailed guidance or suggestions on how the authors might strengthen the connection. Without concrete advice or examples, the authors may struggle to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the performance of learning-based and heuristic-based solvers, noting that heuristic-based solvers, specifically the SOTA heuristic-solver (e.g., Concorde), usually perform better for single-objective TSP. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This provides a clear and explicit action for the authors to take, which is to include the results for linear scalarization + Concorde in their analysis. The action is concrete, as it specifies exactly what needs to be done to improve the comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"competitive baselines\" and \"heuristic-based solvers,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the performance of the SOTA heuristic-solver (e.g., Concorde) for single-objective TSP and suggests including results for linear scalarization + Concorde for a better comparison. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the learning-based solvers are much better than the heuristic-based solvers according to the experimental results. However, it highlights that for single-objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually performs better. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This claim is somewhat verifiable as it provides a logical reasoning for why the inclusion of linear scalarization + Concorde is necessary for a comprehensive comparison. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the learning-based solvers outperform heuristic-based solvers, but it highlights a potential gap in the comparison by suggesting the inclusion of results for linear scalarization with the SOTA heuristic-solver (e.g., Concorde). This feedback is actionable and provides a clear direction for the authors to improve their analysis by including additional comparisons. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their experimental evaluation. Therefore, the comment is mostly helpful, as it offers a specific and actionable suggestion for improvement, though it could be further detailed to provide more guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use long-term storage through pose graphs in SLAM, like those discussed in the appendix. However, the comment does not provide explicit guidance on how to incorporate this discussion into the paper or what specific aspects of the proposed method should be compared. The action is implicit and somewhat vague, as the authors are left to infer how to implement the suggested discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"general ideas\" and provides specific examples of methods that are already present in other approaches, such as topological reasoning using generalized Voronoi graphs or semantic maps, and long-term storage through pose graphs in SLAM. It also references the appendix section on graph-based SLAM, which provides context for the discussion. The comment is specific because it clearly specifies what needs to be addressed by discussing the proposed method in relation to these existing methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some general ideas are already present in other methods for exploration, specifically mentioning topological reasoning and long-term storage through pose graphs in SLAM. The comment provides specific examples of these methods, such as those using generalized Voronoi graphs or semantic maps, and references the appendix section on graph-based SLAM. This level of detail and specificity supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific methods, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the proposed method's grounding in neuroscience is not unique, as similar ideas have been explored in other methods for exploration, such as topological reasoning and long-term storage through pose graphs in SLAM. The comment suggests that the paper should discuss these existing methods to provide a more comprehensive context and differentiate the proposed approach. This feedback is mostly helpful as it highlights an important area for improvement and encourages the authors to expand the discussion of their method in relation to existing work. However, it could be more helpful if it provided specific examples or guidance on how to incorporate this discussion into the paper. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup, tasks, and other details, which are currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This provides explicit guidance on where the details should be located, making it clear what actions the authors should take. The suggestion is concrete, as it specifies which sections should be moved and where the background information should be placed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experimental setup, tasks, and other details, which are currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This provides clear guidance on which parts of the paper need adjustment, making it fully grounded. The comment is specific in detailing what needs to be moved and where, providing a clear understanding of the changes required. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental setup, tasks, and other details, currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This comment is based on a logical suggestion to improve the readability and interpretability of the paper. However, it lacks specific examples or references to support the claim that the current placement of these details hinders interpretation. While the reasoning is clear, the absence of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the organization of the paper, suggesting that the experimental setup, tasks, and other details, currently in the appendix, should be moved back into the main body to improve readability and interpretability. It also recommends moving some background information from Section 2 to the appendix. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the paper's clarity and coherence. By providing specific guidance on where to move certain sections, the comment empowers the authors to make informed decisions about restructuring their paper. Therefore, the comment is mostly helpful, as it offers clear and actionable advice that could significantly improve the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide glosses in Figure 2. This is a clear and explicit action that the authors can readily understand and implement. The comment is specific in its request, indicating exactly what needs to be done\u2014adding glosses to the figure. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing glosses in Figure 2, which is a specific part of the paper. However, it does not explicitly mention the section or figure number, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide glosses in Figure 2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with a classification of \"No.\" Therefore, the comment is labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors should provide glosses in Figure 2, which is a specific and actionable piece of feedback. By requesting glosses, the authors are given a clear direction for improving the clarity and completeness of their presentation. This feedback is specific and directly addresses a potential area of confusion or lack of detail, making it somewhat helpful. However, it could be more helpful if it provided additional guidance on how to create or integrate these glosses into the figure. Overall, the comment is moderately helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that \"Memb is apparently the previous state-of-the-art,\" but it does not provide any explicit or implicit suggestions on how to address this issue. The comment lacks guidance on whether the authors should include a reference or provide more context to support the claim. Without specific instructions on what needs to be done, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a specific section or table. It lacks grounding because the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is not specific because it does not provide details on what needs to be addressed or how the issue should be resolved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"Memb is apparently the previous state-of-the-art,\" but it does not provide any supporting evidence or references to substantiate this claim. Without any justification or references, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that \"Memb is apparently the previous state-of-the-art\" but does not provide any context or references to support this claim. It lacks actionable feedback, as it does not suggest how the authors might address this issue or provide evidence to support their claim. Without specific guidance or references, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific advice or suggestions, the authors are left without a clear path to respond to the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is vague and does not provide specific guidance on how to address the question or what changes might be necessary. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. However, it does not provide any claim, suggestion, or reasoning to support the question or offer any guidance on how to address it. The comment lacks any evidence or justification, making it unverifiable. Therefore, it is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization grouping, specifically questioning why finer grouping was not considered instead of per-tensor and per-channel approaches. This question highlights a potential area for improvement in the paper, as it suggests that the authors might be overlooking a more detailed approach to quantization. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to their work. Without specific advice or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks actionable feedback.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should study the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by conducting additional experiments or analyses. The comment is specific in its request for further investigation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes, specifically mentioning how performance varies with different ratios of unlabeled examples. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes the comment weakly grounded, as the authors may need to infer which part of the paper is being addressed. The comment is specific in its suggestion to study the impact of the ratio of unseen classes, but without clear grounding, it is difficult for the authors to know exactly where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This is a suggestion for further investigation and analysis, but it does not provide any specific reasoning, examples, or references to support why this study would be beneficial or how it could be conducted. The comment lacks detailed guidance or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This feedback is actionable and provides a clear direction for the authors to enhance their work by conducting additional experiments or analyses. By focusing on this aspect, the authors can gain a deeper understanding of the model's behavior and potentially improve its performance. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this study. Overall, the feedback is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part. It asks whether the combination of these two architectures is a reason for the improvements observed. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should provide a justification for their architectural choices. The comment is vague and lacks concrete details on how to implement the suggested action. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address the question or what changes might be necessary. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or explanation, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, which is a valid concern for understanding the architectural choices made in the paper. However, the comment does not provide any specific suggestions or guidance on how the authors might address this question or improve their work. It lacks depth and actionable feedback, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the definition of \"active vertices\" in line 135, which is a specific part of the paper. It implies that the authors need to clarify this term to ensure the reader understands the context. However, the comment does not provide explicit guidance on how to define \"active vertices\" or suggest alternative definitions. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the definition of \"active vertices.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definition of \"active vertices\" in line 135, which is a factual question about the paper's content. It does not contain a subjective claim, suggestion, or judgment that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the definition of \"active vertices\" in line 135. This is a clear and actionable piece of feedback that helps the authors clarify their terminology, ensuring that the reader understands the context. However, the comment could be more helpful if it provided additional context or suggested alternative definitions. Despite this, the feedback is somewhat helpful as it directs the authors to a specific area that needs clarification, allowing them to improve the clarity and precision of their writing. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the paper, noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. It also points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. Additionally, the comment suggests that the authors underestimate the widespread use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific sections to revise or how to elaborate on the negative impacts. The actions are somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue of the theory's inapplicability to the used model and the vagueness of \"structural assumptions,\" which are mentioned as being only in the appendix. Furthermore, the comment suggests elaborating on the potential negative societal impact of graph neural networks, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section, which is a valid observation. It also highlights the vagueness of \"structural assumptions\" mentioned only in the appendix, making the theoretical limitation difficult to understand. Additionally, the comment suggests that the authors underestimate the widespread use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several valuable insights that could help the authors improve their paper. It highlights a critical issue regarding the applicability of their theory to the used model, noting that this limitation is not adequately discussed in the paper. The comment also points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. Additionally, the reviewer suggests that the authors underestimate the widespread use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. This feedback is mostly helpful as it identifies specific areas for improvement and provides actionable suggestions, though it could be more comprehensive with additional details or examples. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide explicit guidance on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. The action is implicit and vague, as the authors are left to infer that they need to clarify the meaning of \"epsilon-greedy\" and potentially discuss its use in their strategy. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy\" in the context of the training process and suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It does not contain a subjective claim or suggestion that requires verification. The comment is factual and descriptive, as it seeks clarification on a specific term used in the paper. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide any guidance or suggestions on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. While it identifies an area that needs clarification, it lacks actionable feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow, with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific aspects of the method need to be improved. The action is implicit and vague, as it does not specify how the authors should enhance the technical contribution or what new elements they could incorporate. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow, with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment does not specify which part of the paper this critique refers to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to understand where the critique applies and what specific issues need to be addressed. Additionally, the comment is somewhat specific in its critique of the method's technical contribution, but without clear grounding, it remains challenging for the authors to act upon. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough, which provides a clear and actionable feedback for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might enhance the technical contribution or address the identified weakness. While it highlights an area for improvement, the feedback could be more helpful if it included concrete suggestions or examples of how to make the method more novel or impactful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the paper, noting that only the projection head (CNN layers) are affected, while the classification head (FCN layer) is not. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what changes could be made to the paper. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"projection head (CNN layers)\" and \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a particular aspect of the paper, noting that only the projection head is affected, while the classification head is not. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is factual and descriptive, stating that only the projection head (CNN layers) are affected but not the classification head (FCN layer). It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is factual and descriptive, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). While this observation is accurate, the comment does not provide any suggestions or insights on how this might impact the paper or what actions the authors could take to address this finding. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide explicit guidance on which parts are vital or how to address this issue. The comment implies that the authors should clarify the discussion, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment also suggests that the discussion is necessary but does not provide specific guidance on what needs to be discussed or how to distinguish the paper from related work. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the discussion is necessary. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient justification or examples to fully support the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific guidance or examples to help the authors address this issue. While the comment identifies a potential area for improvement, it lacks depth and actionable suggestions, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits its helpfulness. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It highlights that the decomposition and integration steps in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analogy need to be revised. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It highlights that the decomposition and integration steps introduced in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not specify which part of the paper discusses the analogy or the decomposition/integration steps, making it difficult for the authors to pinpoint the exact areas that need revision. While the comment is specific in its critique of the analogy, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It claims that the decomposition and integration steps introduced in the paper do not have a close connection with Fourier analysis as claimed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The reasoning is vague and does not provide sufficient evidence to validate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the analogy between HOI analysis and Harmonic analysis, pointing out that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. This feedback is somewhat helpful as it identifies a specific area of concern and suggests that the analogy might be overstated. However, the comment could be more helpful if it provided more detailed guidance on how the authors could address this issue or what specific aspects of the analogy need to be revised. Without concrete suggestions or examples, the authors may struggle to understand how to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bit-serial accelerators. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The comment implies that the authors should consider the limitations of their approach in the context of existing ML accelerators that use bit-parallel fixed-point numbers. While the authors can infer that they need to discuss the implications of their methodology in this context, the lack of concrete suggestions or guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of dynamic precision control during training, specifically mentioning bit-serial accelerators and the limitations of existing ML accelerators that use bit-parallel fixed-point numbers. However, it does not explicitly mention specific sections, tables, or figures of the paper that discuss these aspects. The authors can infer that the comment relates to the methodology or experimental setup, but without explicit references, the grounding is weak. The comment is specific in detailing the issue with dynamic precision control, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bit-serial accelerators. It then suggests that most existing ML accelerators use bit-parallel fixed-point numbers, which might restrict the implications of the proposed methodology. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence or examples weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the applicability of dynamic precision control during training, specifically questioning whether it might only show meaningful performance gains on bit-serial accelerators. It suggests that most existing ML accelerators use bit-parallel fixed-point numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential limitation or area for further discussion, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it highlights a potential area of concern, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the generalization of the model's performance across different focusing distances, specifically those not present in the training data. It suggests that the authors should consider including images with other focusing distances to assess the model's generalization ability. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific distances to include or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and generalize the findings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalization of the model's performance across different focusing distances, particularly those not included in the training data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalization of the model's performance across different focusing distances, specifically those not present in the training data. It does not contain a subjective claim or opinion but rather poses a question that requires the authors to consider additional experiments or analysis. The comment is factual and does not require external references or logical reasoning to be understood. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalization of the model's performance across different focusing distances, particularly those not included in the training data. It questions whether the model generalizes well beyond the distances present in the training set, which is a crucial aspect for evaluating the robustness of the model. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing additional experiments or analysis methods. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, particularly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a non-sequential model and its relation to \"movement dynamic.\" However, the comment does not provide explicit guidance on how to define content and style, nor does it offer concrete suggestions on how to address the ambiguity surrounding the meaning of \"style.\" The action is implicit and vague, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a non-sequential model and its relation to \"movement dynamic.\" However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. While the suggestion is specific about the need for broader definitions, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the definition of \"content\" and \"style\" in the context of the authors' specific neural application, referencing Gabbay & Hosehn (2018). It suggests that style should be instance-specific and that content includes information transferable among groups. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed explanation or references makes the claim somewhat verifiable, as it lacks sufficient evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the definitions of content and style in the context of the authors' specific neural application, referencing Gabbay & Hosehn (2018). It highlights the need for a broader understanding of these concepts, particularly in relation to instance-specific style and the transferability of content across groups. The comment also questions the meaning of 'style' in the context of a non-sequential model and its relation to 'movement dynamic,' which could help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided specific examples or suggestions for how to address these issues. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks detailed guidance, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific examples and comparisons to support the claim that the analysis of vit quantification could be explained in depth. It highlights discrepancies in the variance difference between the proposed approach and the baseline, and mentions that the quantization of MHSA introduces a large loss of precision, a finding already established in other models. However, the comment does not explicitly instruct the authors to provide a detailed explanation of the vit quantification analysis or to address the discrepancies and the loss of precision. While the authors can infer that they need to expand on the analysis, the action is somewhat vague and lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as Line 45 and Figures 1(b) and 5(b), allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, namely the depth of the analysis of vit quantification and the discrepancies in variance differences and the loss of precision in MHSA quantization. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of vit quantification could be explained in depth, providing specific examples and comparisons to support this claim. It highlights discrepancies in variance differences and the loss of precision in MHSA quantization, referencing findings in other models like Q-BERT and Q8BERT. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which could be improved with more explicit evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the paper's claims regarding vit quantification, offering specific examples and comparisons to support the argument that the analysis could be explained in depth. It highlights discrepancies in variance differences and the loss of precision in MHSA quantization, referencing findings in other models like Q-BERT and Q8BERT. This feedback is mostly helpful as it identifies areas where the paper could be improved by providing a more comprehensive explanation of the vit quantification analysis. However, it could be more helpful if it included suggestions for how the authors could address these issues or expand on the analysis. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It points out that the proposed X-transformation is similar to STN, applied locally, and notes that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions the absence of empirical or conceptual comparisons to STN, which is crucial for the work. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the paper. The feedback is somewhat vague and lacks concrete suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It highlights the similarity between the proposed X-transformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions the absence of empirical or conceptual comparisons to STN, which is important. However, the comment does not specify which part of the paper discusses the technical novelty or the comparison to STN, making it weakly grounded. The specificity of the comment is moderate as it identifies the issue but does not provide detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and that there are no empirical or conceptual comparisons to STN. The comment provides examples of existing works that have applied STN in local pixel neighborhoods, such as PointNet, which supports the claim. However, the comment could be more detailed by explicitly referencing specific sections or figures in the paper where these comparisons are missing. Despite this, the claim is mostly verifiable as it is supported by logical reasoning and examples, but it lacks some depth in terms of detailed references or specific comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN). It highlights the similarity between the proposed X-transformation and existing STN applications, noting that other works have explored applying STN in local pixel neighborhoods. The comment also points out the absence of empirical or conceptual comparisons to STN, which is crucial for establishing the novelty and contribution of the work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or what additional comparisons could be made to strengthen the paper. While it provides a clear direction for improvement, the feedback could be more helpful if it included concrete suggestions or examples of how to enhance the technical novelty. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the clarity of the paper by clarifying the notation used in equations L384 and L431. It explicitly mentions that the authors should clarify the notation |Y_t - Y_{t-1}| \\leq c_t almost surely and suggests that \\mu_t should be \\tilde \\mu_t. These suggestions are clear and direct, allowing the authors to understand exactly what needs to be addressed. The comment is explicit and provides concrete details on how to implement the changes, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (L384 and L431), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the clarity of the notation used in these sections, such as clarifying the meaning of |Y_t - Y_{t-1}| \\leq c_t almost surely and suggesting that \\mu_t should be \\tilde \\mu_t. This level of detail helps the authors understand exactly what needs to be addressed and how to do it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two specific suggestions for improving the clarity of the notation used in equations L384 and L431. It suggests that the authors should clarify the notation |Y_t - Y_{t-1}| \\leq c_t almost surely and that \\mu_t should be \\tilde \\mu_t. These suggestions are clear and actionable, providing the authors with specific guidance on how to improve the clarity of their notation. However, the comment does not provide any additional reasoning or references to support these suggestions, which could enhance the verifiability. Therefore, the comment is mostly verifiable, as it is well-supported but lacks some depth in terms of justification or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the clarity of the notation used in equations L384 and L431. It suggests that the authors should clarify the notation |Y_t - Y_{t-1}| \\leq c_t almost surely and that \\mu_t should be \\tilde \\mu_t. These suggestions are clear and actionable, as they directly address potential ambiguities in the notation, which could improve the readability and understanding of the paper. However, the comment could be more helpful if it provided additional context or explanation for why these changes are necessary or how they would impact the overall understanding of the paper. Despite this, the feedback is mostly helpful as it offers clear guidance for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the paper. The action is implicit, as the authors would need to infer that they should clarify the source of the reward and provide more detailed explanations of the network model. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvements, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not specify which part of the paper the authors should focus on, making it weakly grounded. The comment is specific in its request for clarification and suggestions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the current explanation is confusing or lacking. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely Eq. 12, where the source of the reward at each trial is unclear. It also suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment lacks detailed guidance on how to address these issues or what specific changes should be made to the paper. While it points out a potential area for improvement, it does not provide actionable steps or suggestions for clarification, making it somewhat helpful. The feedback is somewhat helpful as it highlights a specific area for improvement but does not offer comprehensive guidance for the authors to address the issue effectively.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to enhance the paper's clarity by attaching proof links to each theorem and corollary in the main paper. However, the comment does not explicitly instruct the authors to correct the figure reference or implement the proof link suggestion. While the actions are implied, they are vague and lack concrete details on how to execute them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure reference, suggesting that \"Fig.7\" should be \"Fig.12.\" Additionally, the comment provides a clear suggestion to enhance the paper's clarity by attaching proof links to each theorem and corollary in the main paper. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains a claim about the correctness of a figure reference (\"Fig.7\" should be \"Fig.12\") and suggests improving the paper's clarity by attaching proof links to theorems and corollaries. However, the comment lacks specific reasoning or examples to support the claim about the figure reference, making it difficult for the authors to verify the accuracy of the figure number. While the suggestion to improve clarity is logical, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on a potential error in the referencing of figures in the supplementary material, noting that 'Fig.7' should be 'Fig.12'. It also suggests enhancing the paper's clarity by attaching proof links to each theorem and corollary in the main paper. This feedback is actionable, as it directly points out a factual error and offers a concrete suggestion for improving the paper's organization and readability. However, the comment could be more helpful if it provided additional guidance on how to implement the proof link suggestion or elaborated on the specific concerns regarding motivation, methodology soundness, and experiment persuasion. Overall, the comment is mostly helpful, as it addresses key issues and provides actionable feedback, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about specific sections of the paper, such as the missing determiner in the definition above Section 3, the selection and tagging of action verbs, and the concept of \"action frames.\" While the comment explicitly asks for clarification on these points, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit, as the authors need to infer that they should clarify these aspects in their draft. However, the lack of concrete guidance on how to implement these clarifications makes the comment somewhat actionable. Therefore, it aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific sections of the paper, such as \"Above definition\" and \"Section 3,\" which allows the authors to accurately identify the parts being discussed. It also raises questions about the selection of action verbs and the concept of \"action frames,\" providing specific areas for clarification. This makes the comment fully grounded and specific, as it clearly identifies the parts of the paper that need attention and specifies what needs to be addressed. Therefore, the comment aligns with a score of 5: Fully Grounded and Specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about specific sections of the paper, such as the missing determiner in the definition above Section 3 and the selection of action verbs. It also asks about the concept of \"action frames\" and how they are picked. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is primarily factual and descriptive, aligning with a classification of \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the content of the paper, particularly regarding the missing determiner in a definition above Section 3, the selection of action verbs, and the concept of \"action frames.\" These questions are clear and point out areas where the authors may need to provide more detail or clarification. However, the comment does not offer suggestions or guidance on how to address these issues, leaving the authors with a clear understanding of what needs to be improved but without actionable steps to take. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is an explicit action that the authors can directly apply to improve the accuracy of the paper. The comment is clear and provides a specific instruction, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly points out a grammatical error that needs correction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically'. This is a factual correction and does not require any additional reasoning or references to be understood. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor grammatical error in the text, specifically pointing out that \"Empiically\" should be corrected to \"Empirically'. This is a clear and actionable suggestion that the authors can easily implement to improve the accuracy of their paper. While the comment is brief, it provides a specific and direct feedback that can enhance the quality of the draft. Therefore, it is rated as somewhat helpful, as it offers a clear improvement but lacks depth or breadth in addressing other potential issues.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, it does not provide explicit guidance on how to implement this improvement or what specific aspects of the feature selection should be considered. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed invariant learning module in Section 4.2, specifically mentioning mask selection and raw-level features. It also refers to the discussion about representation learning in the appendix, which suggests that the feature selection could be further improved. However, the comment does not specify which part of the paper the authors should focus on for improvement, making it weakly grounded. The comment is specific in suggesting that the feature selection could be improved by considering representation learning, but it lacks detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why considering representation learning would enhance the feature selection process or how it could be implemented. Without these details, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for improvement but lacks sufficient depth and clarity to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the feature selection presented in Section 4.2 could be further enhanced by considering representation learning, which is discussed in the appendix. This feedback is somewhat helpful as it points out a specific aspect that could be improved, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of representation learning should be considered. The comment provides a clear direction for improvement but does not offer comprehensive advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, it does not provide explicit instructions or suggestions on what specific details are missing or how the authors should address this issue. The comment implies that the authors should clarify the design of rewards, but it does not offer concrete guidance on what aspects need clarification or how to improve the explanation. Therefore, the comment is somewhat actionable, as it identifies a gap in the paper but lacks detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some details are missing\" and provides an example of \"how to design the rewards is not fully understandable.\" This allows the authors to accurately identify the part of the paper where the issue lies. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the design of rewards. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific issue being raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some details are missing and that the design of rewards is not fully understandable. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided additional guidance on how the authors might clarify the design of rewards or what specific aspects of the reward design are unclear. Despite this, the comment is mostly helpful as it directs the authors to a critical area for improvement, allowing them to enhance the clarity and completeness of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. It suggests that the number of entities is fixed, which is not clear. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to generalize the model. The action is implicit and vague, as it does not specify how the authors can modify their model or what additional experiments might be needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue and suggests that the number of entities is fixed, which is not clear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. However, it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. It highlights that the number of entities is fixed, which is not clear, and suggests that the authors should consider how to generalize the model to different numbers of entities. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what steps the authors should take to improve their model. While it points out a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not provide explicit guidance on how to address this issue or improve the novelty of the approach. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of novelty but lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the novelty of the incremental improvement to the K-NN based MT approach, suggesting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not provide specific examples or references to support the claim about the lack of novelty or the need for substantial engineering effort. This makes the claim somewhat verifiable, as it lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the incremental improvement to the K-NN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It acknowledges that the authors' execution is replicable and beats the idea in terms of novelty. However, the comment does not provide specific suggestions or guidance on how to address this issue or enhance the novelty of the approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The feedback is valuable but could be more impactful with detailed suggestions or constructive feedback on how to improve the novelty of the approach. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the computational efficiency of the Prithvi WxC model, suggesting that its runtime should be discussed as a limitation. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the draft. The comment implies that the authors should consider discussing the runtime, but it lacks concrete instructions or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational efficiency of the Prithvi WxC model, specifically mentioning its large parameter count and suggesting that its runtime should be discussed as a limitation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to discuss the runtime, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the computational efficiency of the Prithvi WxC model should be discussed as a limitation due to its large parameter count. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the argument. Without detailed reasoning or examples, the claim remains somewhat verifiable, as it is based on a logical deduction but lacks sufficient justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the computational efficiency of the Prithvi WxC model, specifically mentioning its large parameter count. It suggests that the runtime of this model should be discussed as a limitation for applications involving climate model parametrizations. While the comment highlights a relevant aspect of the model's performance, it does not provide specific guidance on how to address this issue or what actions the authors should take to improve their draft. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the idea is not enough and that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors might address these issues or improve the novelty of their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section being discussed. Additionally, the comment is not specific because it does not detail what aspects of the novelty or the new metric/method are considered straightforward, nor does it provide any suggestions for improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough and that both the new metric and method are relatively straightforward. However, the comment lacks specific details or examples to support this claim. It does not provide any references or logical reasoning to substantiate the assertion that the novelty is insufficient or that the new metric and method are straightforward. Without these elements, the claim is difficult for the authors to address or verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the idea and suggests that both the new metric and method are relatively straightforward. While this feedback highlights a concern that could impact the paper's contribution, it lacks specific guidance or suggestions on how the authors might address these issues or enhance the novelty of their work. The comment is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what changes could be made to the framing or how the contribution could be clarified. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper is being referred to, leaving the authors uncertain about the exact section or aspect that needs attention. The comment is vague and does not provide specific guidance on how to address the overselling or clarify the contribution. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the framing of the paper, suggesting that it oversells the method and makes the contribution less clear. However, the comment lacks specific details or actionable suggestions on how the authors might address this concern. Without concrete guidance or examples, the authors may find it difficult to understand the nature of the overselling or how to improve the clarity of their contribution. Therefore, the comment is barely helpful, as it provides a general observation but lacks depth and actionable advice.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps, which would enhance understanding. It also notes that the use of many symbols and a notation table could be better. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific examples of how to present the generative process in steps or how to create a more effective notation table. The action is implicit and somewhat vague, as the authors need to infer the exact actions to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the use of many symbols and a notation table. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the nature of the issue, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and by using a notation table. However, the comment does not provide specific examples, references, or detailed reasoning to support these suggestions. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies areas for improvement in the model description, specifically suggesting that presenting the generative process in separate steps could enhance understanding and that using a notation table could improve clarity. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to implement these suggestions or what specific changes would be beneficial. While it offers some actionable feedback, the lack of detailed examples or suggestions limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the quality of paraphrases used for training data generation. It points out that the difference between the paraphrases and the original sentences is unclear, which could impact the subsequent steps and the overall quality of the training data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paraphrases. The feedback is somewhat vague and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of generating paraphrases for training data, specifically noting that the difference between the paraphrases and the original sentences is unclear. This provides a clear indication of which part of the paper the comment is focused on, allowing the authors to accurately identify the section being discussed. However, the comment does not specify what needs to be addressed in terms of improving the paraphrases or how to ensure the quality of the training data. While the authors can infer that they need to clarify the differences between paraphrases and original sentences, the comment lacks specific guidance on how to achieve this. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases used for training data generation, specifically noting that the difference between the paraphrases and the original sentences is unclear. This is a valid concern as the quality of the training data is crucial for the model's performance. However, the comment does not provide specific examples or references to support the claim that the difference is unclear or how this impacts the subsequent steps. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the quality of paraphrases used for training data generation. It highlights that the difference between the paraphrases and the original sentences is unclear, which can significantly impact the subsequent steps and the overall quality of the training data. The comment provides a clear and actionable suggestion that the authors should clarify the differences between the paraphrases and the original sentences to ensure the quality of the training data. This feedback is valuable as it directs the authors to address a specific aspect of their methodology that could affect the effectiveness of their model. However, the comment could be more helpful if it provided additional guidance on how to improve the paraphrases or what specific steps should be taken to ensure the quality of the training data. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the clarity of the \"bold\" text in Figure 2, suggesting that it might be difficult to see. However, it does not provide explicit guidance on how to address this issue, such as recommending a different color or font size. The comment is somewhat vague and lacks concrete details on how to improve the figure. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the \"bold\" text being hard to see, suggesting improvements such as using another color or a bigger font. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that identifying rationales is not a simple problem, particularly for complex NLP tasks like machine translation. It also notes that the paper is well-organized and easy to follow, but points out that Figure 2 is cluttered and the \"bold\" text is difficult to see. While the comment provides some context, it lacks specific examples or references to support the claim about the difficulty of identifying rationales. The feedback is somewhat verifiable as it offers a general observation but could be strengthened with more detailed reasoning or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the \"bold\" text in Figure 2, which could hinder the reader's understanding of the human-identified rationales. While the comment acknowledges that the paper is well-organized and easy to follow, it points out a specific formatting issue that could be improved. However, the feedback lacks depth and does not provide actionable suggestions on how to address the problem, such as recommending alternative text styles or colors. The comment is somewhat helpful as it highlights a minor issue that could impact the clarity of the paper, but it could be more helpful with additional guidance on how to improve the presentation.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Flipped-QA framework, which is described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in non-LLM-based models like HiTeA and InternVideo. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take to address it. The action is implicit and vague, as it leaves the authors to infer the necessary steps, making it difficult to apply the feedback effectively. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the Flipped-QA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in non-LLM-based models like HiTeA and InternVideo. However, the comment does not specify which part of the paper discusses the Flipped-QA framework or the models it is applied to. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in its suggestion to verify the framework's effectiveness and universality, the absence of explicit references to the paper's sections or elements makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the Flipped-QA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in non-LLM-based models like HiTeA and InternVideo. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by suggesting that the Flipped-QA framework, described as general for various generative VideoQA models, should be further verified for its effectiveness and universality in non-LLM-based models like HiTeA and InternVideo. This feedback highlights an area where the authors could strengthen their analysis by expanding the scope of their evaluation. However, the comment lacks specific guidance on how to verify the framework's effectiveness or universality, or what additional experiments or analyses might be needed. While it points out a potential improvement, the lack of detailed suggestions or examples makes it somewhat helpful, as it provides a direction for the authors to consider but does not fully guide them in addressing the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, indicating that the writing could be improved. However, it does not provide any specific suggestions or actions for the authors to take to enhance their writing. The comment lacks explicit guidance on what aspects of the writing need improvement or how the authors can address these issues. As a result, the comment is unactionable because it does not offer concrete steps for the authors to follow. Therefore, it aligns with the label 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the writing, leaving the authors without actionable steps. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or evidence, the claim remains somewhat vague and challenging to address. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some indication of the issue but lacks sufficient detail for the authors to fully understand and address it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, indicating that the writing could be improved. However, the comment lacks specific suggestions or actionable feedback on how to enhance the clarity or coherence of the writing. Without detailed guidance or examples, the authors may struggle to address the issue effectively. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the proposed method primarily builds upon existing methods, such as Clopper-Pearson intervals and Gaussian elimination, and that it lacks significant theoretical novelty. The comment also expresses a willingness to improve the score if the authors address these concerns. However, it does not provide specific guidance on how to address these issues or what aspects of the method need to be improved to enhance its theoretical novelty. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of existing methods, such as Clopper-Pearson intervals and Gaussian elimination, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the concern regarding the lack of significant theoretical novelty, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how the method builds upon existing methods or why it lacks theoretical novelty. Without these elements, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a key weakness in the paper, noting that the proposed method primarily builds upon existing methods, such as Clopper-Pearson intervals and Gaussian elimination, and lacks significant theoretical novelty. This feedback is clear and actionable, as it highlights a specific area where the authors could improve their work. However, the comment could be more helpful if it provided suggestions on how to address the lack of theoretical novelty or how to differentiate the proposed method from existing approaches. Despite this, the comment is mostly helpful as it directs the authors to a critical area for improvement, allowing them to focus on enhancing the novelty and contribution of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should investigate and clarify the concatenation process. However, the comment lacks concrete details on how to implement this investigation or what specific aspects need clarification. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the text input is concatenated by four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or how to clarify the concatenation process. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether the text input is concatenated by four text elements of an object. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide any specific guidance or suggestions on how to address this question or what changes might be necessary. The comment lacks depth and does not offer actionable feedback that would help the authors improve their draft. Therefore, it is barely helpful, as it identifies a potential area for clarification but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not provide explicit guidance on how to motivate the \"why\" or what specific aspects of the paper need to be addressed to achieve this. The action is implicit, as the authors would need to infer that they should add a section or discussion motivating the importance of the research question. The comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not specify which part of the paper this motivation should be included in, making it weakly grounded. The comment is specific in its suggestion to motivate the \"why,\" but without a clear reference to a specific section or aspect of the paper, the authors may find it challenging to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by first motivating the \"why\" behind the research. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research, which is a valuable piece of feedback. It highlights a potential area for improvement by emphasizing the importance of clearly articulating the motivation and significance of the research question. However, the comment lacks specific guidance on how to motivate the \"why\" or what aspects of the paper need to be addressed to achieve this. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions on how to structure the motivation or examples of effective motivation strategies. Overall, the comment is somewhat helpful as it identifies a meaningful area for enhancement but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide specific guidance on how to make the sentence clearer or what aspects of the sentence need improvement. The authors are left with an implicit action to revise the sentence, but without concrete details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to make the sentence in lines 12-17 clearer. This feedback is actionable and provides a clear direction for improvement, making it a fully grounded and specific comment.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the sentence is cumbersome or how to make it clearer. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that the sentence describing the number of questions is cumbersome and could be clearer. This feedback is actionable as it provides a clear suggestion for improvement, guiding the authors to refine the sentence for better readability. However, the comment could be more helpful if it offered additional guidance on how to make the sentence clearer, such as suggesting specific ways to rephrase it or provide more context. Overall, the comment is mostly helpful as it highlights an area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the fairness of comparisons made in the experiments, specifically noting that the domain-specific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zero-shot single-image 3D reconstruction models might be unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experiments or comparisons. The action is implicit, as the authors need to infer that they should consider alternative datasets or methods to ensure fair comparisons. While the action is somewhat vague, it is clear that the authors need to address the issue of fairness in their comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pix3D\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons to zero-shot single-image 3D reconstruction models, highlighting the unfairness of the comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparisons to zero-shot single-image 3D reconstruction models are unfair because the domain-specific model and experiments are both conducted on Pix3D. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the comparisons are unfair. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of comparisons made in the experiments, specifically noting that the domain-specific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zero-shot single-image 3D reconstruction models might be unfair. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to ensure fair comparisons. While it highlights a concern, it lacks actionable advice or detailed insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer comprehensive guidance for resolution.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, as shown in \"3)\". It also points out that the trade-off between head and tail categories is not fully investigated for the baselines, suggesting that similar trade-offs could be explored by changing hyper-parameters in Decouple [Kang et al.]. The comment encourages the authors to continue this line of work for future submission. However, the comment does not provide specific guidance on how to address these issues or what changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies what needs to be addressed, namely the performance comparison with Decouple [Kang et al.] and the trade-off between head and tail categories. The comment also suggests that similar trade-offs could be explored by changing hyper-parameters in Decouple [Kang et al.], providing specific guidance on how to improve the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, as shown in \"3)\". It also notes that Table 5 demonstrates a trade-off between head and tail categories but does not fully investigate this trade-off for the baselines, suggesting that similar trade-offs could be explored by changing hyper-parameters in Decouple [Kang et al.]. This claim is somewhat verifiable as it provides a logical reasoning based on the performance comparison and suggests a potential area for further investigation. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights that the trade-off between head and tail categories is not fully investigated for the baselines, suggesting that similar trade-offs could be explored by adjusting hyper-parameters in Decouple [Kang et al.]. This feedback is valuable as it provides a clear direction for improvement, encouraging the authors to conduct further analysis and potentially enhance the paper's contribution. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as suggesting particular experiments or analyses to conduct. Overall, the comment is mostly helpful, as it identifies key areas for improvement and encourages further work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D (Contrastive 2D) approach. However, it does not specify which aspects of the C2D approach would benefit from these experiments or how the experiments should be conducted. The comment implies that the authors should consider adding such experiments, but it lacks concrete guidance on what specific experiments to perform or how to integrate them into the draft. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its suggestion regarding the type of experiments, but the lack of grounding makes it challenging for the authors to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific type of experiment that could enhance the paper's support for the C2D approach. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D approach would benefit from them. While it offers a direction for improvement, it does not fully address the authors' needs for comprehensive feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). While the comment prompts the authors to consider these aspects, it does not provide explicit guidance on how to address these questions or what changes might be necessary. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft based on these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). However, the comment does not specify which part of the paper these questions relate to, such as a specific section or equation. This makes it difficult for the authors to pinpoint the exact areas that need clarification or discussion. While the questions are specific about the content, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). However, the comment does not provide any evidence, reasoning, or references to support these claims. The questions are posed as inquiries for clarification, but without any substantiation, the authors are left to interpret the concerns independently. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the intuition behind the specific choice of $\\lambda_t$ in the E2W algorithm, particularly regarding exploration. It also questions the necessity of the exploration parameter $\\epsilon$ and the use of $\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\lambda_s$ in Equation (7). While the comment identifies areas where the authors might need to provide more context or justification, it lacks specific guidance on how to address these questions or what changes might be necessary. The feedback is somewhat helpful as it points out potential areas for clarification, but it does not offer detailed suggestions or actionable steps for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation is limited, primarily relying on 4 OCR QA datasets. It acknowledges that this evaluation may be unreliable, as the authors themselves admit in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. However, the comment does not provide explicit guidance on how the authors should incorporate these additional scenarios or how to conduct the ablation studies. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation, noting that it is limited to 4 OCR QA datasets and suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. This provides clear guidance on what additional scenarios should be included. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited, primarily relying on 4 OCR QA datasets, and suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the current evaluation is unreliable. The authors are expected to understand the reasoning and potentially address it, but the comment does not offer detailed evidence or guidance on how to do so. Therefore, the claim is somewhat verifiable, as it is supported by logical reasoning but lacks specific examples or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the paper, noting that it primarily relies on 4 OCR QA datasets. The authors themselves acknowledge this limitation in Figure 4(5), suggesting that the evaluation may be unreliable. The comment proposes that additional scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. This feedback is somewhat helpful as it highlights a specific area for improvement and suggests a potential enhancement to the evaluation process. However, it could be more helpful if it provided more detailed guidance on how to incorporate these additional scenarios or how to conduct the ablation studies. Overall, the comment offers a clear direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the notation and assumptions in the paper. It suggests clarifying the role of pi as a function from R^m to \\Delta^{K+1} and questions the dimensions of X pi(X) due to the removal of the no-op action. The comment implies that the authors should address these issues to improve the clarity and consistency of their paper. However, the action is implicit, as the authors need to infer that they should clarify the notation and address the dimensional mismatch. The comment is somewhat actionable because it provides specific areas for improvement, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the notation and assumptions in the paper, particularly concerning the function pi and the dimensions of X pi(X). It provides a clear explanation of the dimensional mismatch due to the removal of the no-op action. However, the comment does not explicitly mention the section or part of the paper where these issues are discussed, making it weakly grounded. The specificity of the comment is high as it clearly specifies what needs to be addressed regarding the notation and dimensions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the notation and assumptions in the paper, specifically regarding the function pi and the dimensions of X pi(X). It suggests that the authors should clarify the role of pi as a function from R^m to \\Delta^{K+1} and explain why the dimensions do not match after dropping the no-op action. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is somewhat verifiable as it provides a basis for improvement but requires more detailed explanation or evidence to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas for improvement in the paper, particularly concerning the notation and assumptions. It questions the role of pi as a function and the dimensional mismatch in equation (2) due to the removal of the no-op action. This feedback is clear and actionable, providing the authors with specific points to address and improve their work. However, the comment could be more helpful if it offered additional guidance on how to clarify the notation or address the dimensional mismatch. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to the tasks. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. However, the comment does not specify which part of the paper discusses these tasks, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the tasks, the lack of grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general concern but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. The comment provides a clear and actionable feedback, prompting the authors to consider the complexity and potential confusions of these tasks. However, it could be more helpful if it offered specific suggestions or guidance on how to simplify or clarify the tasks. Overall, the comment is mostly helpful as it identifies a significant issue and encourages the authors to address it, but it could be more comprehensive with additional suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly instruct the authors to address these issues or provide guidance on how to improve the realism of their evaluations. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision by suggesting that the realism of the evaluated tweets should be considered. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The specificity is moderate as it clearly specifies what needs to be addressed in the evaluation of weak supervision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that weak supervision could be better evaluated by considering the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the issue with the generation of authors being unrealistic. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides some justification but lacks depth and specific examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets. It provides specific examples, such as the requirement for 'all of the structured elements for perspectives to be present in the generated tweets' and the unrealistic generation of authors. However, the comment does not offer actionable suggestions or guidance on how to address these issues or improve the realism of the evaluation. While it highlights a concern, it lacks depth and constructive feedback, making it somewhat helpful. The authors would need to infer what needs to be done to improve the evaluation, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of visualization in the paper, specifically mentioning the absence of intermediate processes and comparisons. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. The comment lacks concrete guidance on what kind of visualizations would be beneficial or how to incorporate them into the draft. Without specific advice on what to visualize or how to compare, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which sections or figures are missing these visualizations. This lack of specific grounding makes it difficult for the authors to address the issue effectively. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons in the paper. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific areas where the visualization is lacking. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance the visual representation of their work. However, the comment could be more helpful if it provided suggestions on what kind of visualizations would be beneficial or how to effectively compare the intermediate processes. Despite this, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might correct the violation or what changes are necessary to align the counterfactual with the stated property. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1, providing a clear indication of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the expected counterfactual, noting that it violates $\\mathcal{P}_2$ as stated in Definition 1. While this feedback highlights a potential flaw in the paper, it lacks actionable guidance or suggestions on how the authors might address this issue. The comment does not provide any insight into how the authors could correct the violation or what changes might be necessary to align the counterfactual with the stated property. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a problem but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the importance of the result and questions the novelty of the findings, particularly in light of existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is vague and lacks actionable steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or theorem. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the result's importance and the dimension-free nature of the iteration complexity, it lacks grounding as it does not explicitly mention the relevant sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment lacks detailed reasoning or specific examples to substantiate these claims. It does not provide a clear explanation of why the findings are not surprising or how the iteration complexity issue impacts the overall significance of the paper. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment lacks detailed reasoning or specific examples to substantiate these claims, making it difficult for the authors to understand the significance of the concern or how to address it. The feedback is somewhat helpful as it identifies a potential weakness in the paper, but it does not provide actionable guidance or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that keypoint detection results should be included in the experiments section. This is a clear and explicit action that the authors can take to improve their draft. By including these results, the authors can provide a more comprehensive evaluation of their work, allowing readers to better understand the significance of their findings. The comment is specific and concrete, as it directly instructs the authors on what needs to be added to their experiments section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that keypoint detection results should be included in the experiments section. However, it does not specify which part of the experiments section this should be included in, making it weakly grounded. The comment is specific in its suggestion to include keypoint detection results, but the lack of grounding makes it difficult for the authors to know exactly where to add this information. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this is necessary or beneficial. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that keypoint detection results should be included in the experiments section. This is a specific and actionable piece of feedback that provides the authors with a clear direction for improving their draft. By including these results, the authors can enhance the comprehensiveness and depth of their experimental evaluation, allowing readers to better understand the significance of their findings. The comment is clear, concise, and directly addresses a specific area for improvement, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" However, the comment does not provide explicit guidance on how to conduct this comparison or what aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should perform the comparison, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" However, it does not specify which part of the paper this comparison should be made or how it relates to the overall content. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the type of comparison, it lacks specificity in terms of what aspects of the comparison should be included or how it should be conducted. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests comparing the proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This claim is somewhat verifiable as it provides a specific example of a comparison that could be made to strengthen the paper. However, it lacks detailed reasoning or references to support the suggestion comprehensively, which could make it difficult for the authors to fully understand and implement the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests comparing the proposed model with existing models that use answers as inputs, specifically mentioning 'Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).' This feedback is somewhat helpful as it identifies a potential area for comparison that could enhance the paper's contribution. However, the comment lacks depth and does not provide specific guidance on how to conduct the comparison or what aspects of the comparison should be highlighted. Without more detailed suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the grid search of the learning rate is conducted on the validation set. While it identifies a potential issue, it does not provide explicit instructions or suggestions on how to address this concern. The authors are left to infer that the comment implies a need to clarify the methodology used in the grid search. However, the action is implicit and somewhat vague, as it does not specify what needs to be done to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the grid search of the learning rate is conducted on the validation set. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is not grounded as it lacks specific references or context. Additionally, it does not provide detailed guidance on what needs to be addressed or how to approach the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether the grid search of the learning rate is conducted on the validation set. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the question or how it relates to the paper. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether the grid search of the learning rate is conducted on the validation set. While it identifies a potential issue in the methodology, it does not provide any suggestions or guidance on how to address this concern. The comment lacks depth and specificity, as it does not elaborate on the implications of this question or how it might affect the results. Without actionable feedback or detailed suggestions, the authors are left without clear direction on how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment implies that the authors should investigate the nature of these relations and consider whether they are appropriate for the dataset or if they should be categorized differently. While the action is implicit, it is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to \"Table A2\" and questions the presence of a large number of dobj relations, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not specify which part of the paper or section contains this table, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the relations but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. While the comment identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it points out a potential area for further investigation, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not provide explicit instructions or suggestions on how to address this issue, such as adding data or discussing the implications of the sample's diversity. The action is implicit, as the authors would need to infer that they should consider the diversity of their sample and its impact on generalizability. However, the comment lacks concrete guidance on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (L393), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the question about the diversity of the sample and its generalizability to other groups, especially marginalized groups. This provides clear guidance on what aspect of the paper requires attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not contain a subjective claim or suggestion but rather poses a question that could be addressed by the authors. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the diversity of the sample and its generalizability to other groups, especially marginalized ones. This is a critical aspect of ensuring the robustness and applicability of the research findings. However, the comment does not provide any suggestions or guidance on how to address this issue, such as adding data or discussing the implications of the sample's diversity. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}'"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the output quality of the paper is reasonable but still far from realistic, citing recent GAN works that achieve high-quality synthesized results. It implies that there is room for improvement in the result quality. However, the comment does not provide specific guidance or suggestions on how to enhance the output quality or address the issues of limited novelty, low resolution, and high hardware requirements. The authors are left with a general idea of what needs to be improved but lack concrete steps to take. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"output quality\" and \"recent GAN works,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the output quality is \"reasonable but still far from realistic\" and suggests that there is room for improvement. However, the comment does not provide specific details on which sections or figures of the paper need improvement, making it somewhat specific. Therefore, this comment is classified as fully grounded and somewhat specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the output quality is reasonable but still far from realistic, citing recent GAN works that achieve high-quality synthesized results. This claim is somewhat verifiable as it provides a general reference to recent advancements in GANs, which could be expanded with specific examples or citations to support the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but still far from realistic, especially considering recent advancements in GANs. It suggests that there is room for improvement in the result quality, which is a valuable insight for the authors to consider. However, the comment lacks specific guidance or suggestions on how to enhance the output quality or address the issues of limited novelty, low resolution, and high hardware requirements. While it provides a clear direction for improvement, the feedback could be more helpful if it included actionable steps or examples of how to achieve higher quality results. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not provide detailed guidance for the authors to follow.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of subpar hyperparameters, similar to those used in other works, and questions the clarity of the results presented in the leftmost plots. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The comment implies that the authors should consider using better hyperparameters or providing more clarity on the results, but it lacks concrete steps or detailed advice on how to implement these suggestions. As a result, the comment is somewhat actionable, as it identifies an area for improvement but does not offer specific guidance on how to achieve it. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the use of subpar hyperparameters, similar to those used in other works, and questions the clarity of the results presented in the leftmost plots. However, it does not specify which part of the paper these concerns relate to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its critique of the results, the absence of explicit references to the paper's sections or figures makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of subpar hyperparameters and questions the clarity of the results presented in the leftmost plots. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence or justification to substantiate the concerns, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the use of subpar hyperparameters, similar to those used in other works, and questions the clarity of the results presented in the leftmost plots. While it identifies a potential issue with the experimental setup, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This feedback is explicit, as it directly instructs the authors to include additional evaluations and specific elements in their draft. The action is also concrete, as it provides clear guidance on how to implement the suggestion by adding translations to Figure 6. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to add translations to Figure 6, which would help clarify the evaluation process for unseen words. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This claim is somewhat verifiable as it implies the need for additional evaluation, but it lacks specific examples or references to support the suggestion. The authors would need to infer the need for more detailed evaluation and the rationale behind it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. The reviewer recommends adding more evaluation, particularly on classifying unseen words, and suggests including translations in Figure 6 to aid understanding for those who do not speak Chinese. This feedback is actionable and provides clear guidance on how the authors can improve the presentation and clarity of their work. By addressing these suggestions, the authors can enhance the comprehensiveness and accessibility of their research, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While it identifies a potential issue with the dataset size, it does not provide explicit guidance on how to address this concern or suggest specific actions to take. The comment is somewhat vague, as it leaves the authors to infer that they need to consider the impact of the dataset size on the validity of their approach. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the VioT dataset, specifically mentioning the number of images in each category. It questions whether the number of images is sufficient to text the validity of the approach. However, the comment does not specify which part of the paper discusses the VioT dataset or the approach being questioned, making it weakly grounded. The comment is specific in identifying the issue with the dataset size, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While it raises a concern about the dataset size, it does not provide any specific reasoning, examples, or references to support the claim that the number of images is too small. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the reasoning or seek additional information to understand the issue fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of the number of images in the VioT dataset to text the validity of the approach. It questions whether the dataset size is adequate to support the claims made in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional data could be included to strengthen the validity of their approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer the implications of the comment and seek further guidance to improve their draft, which limits the comment's overall helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, it does not provide explicit guidance on how to conduct this study or what specific aspects of performance should be analyzed. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply this suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests an ablation study on the number of layers versus performance, which is a specific suggestion related to the methodology. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or table. The authors can infer that it relates to the experimental setup or results, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting an ablation study, but the lack of grounding makes it weakly grounded and specific. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, it does not provide any specific reasoning, examples, or references to support why this study would be beneficial or how it could be conducted. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, the comment lacks specific guidance on how to conduct this study or what aspects of performance should be analyzed. It does not provide any suggestions for improvement or actionable feedback on how the authors might address this issue. As a result, the comment is barely helpful, as it does not offer any meaningful insights or suggestions for the authors to consider.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including its difficulty to follow, the need for more intuitive explanations of mathematical derivations, and the lack of detailed explanations for figure captions. It suggests that the authors should provide additional explanations and legends for figures, such as explaining the colors in Fig. 2. However, the comment does not explicitly instruct the authors to add these explanations or legends, nor does it provide specific guidance on how to improve the clarity of the figures. While the authors can infer that they need to address these issues, the lack of concrete instructions makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper's difficulty to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not explicitly mention specific sections, figures, or tables, making it weakly grounded. It is specific in detailing what needs to be addressed, such as intuitive explanations and detailed figure captions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leading to a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically noting that it is hard to follow and lacks intuitive explanations for mathematical derivations. It also points out the absence of detailed explanations for figure captions, such as the need to explain the colors in Fig. 2. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is somewhat helpful as it directs the authors to areas needing improvement, but it lacks depth and actionable advice, making it a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a critical concern about the sensitivity of the empirical results to hyperparameter choices. It highlights the importance of this issue, noting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this concern, such as conducting additional experiments or providing a detailed analysis of the impact of different hyperparameter settings. The action is implicit, as the authors are left to infer that they need to investigate the robustness of their results to hyperparameter variations. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a crucial issue. However, it does not specify which part of the paper this concern pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its focus on hyperparameter sensitivity, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, suggesting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, noting that incorrect choices could potentially negate the benefits of the method. This is a significant issue that needs to be addressed to ensure the robustness and reliability of the findings. However, the comment lacks specific guidance or suggestions on how the authors might investigate or mitigate this concern. While it highlights an important area for improvement, the absence of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a crucial issue but does not provide detailed guidance on how to address it.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, given that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. However, the comment does not provide explicit guidance on how to claim the novelty or contribution, nor does it offer concrete steps on how to substantiate this claim. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"This work utilizes existing attack methods on a surrogate model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the similarity to using the transferability of adversarial examples directly and the need to further claim the novelty and contribution of the proposed method. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. While the comment highlights a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not provide any explicit or implicit suggestions on how to address these issues. The comment lacks actionable guidance, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses issues with the readability of text in Table 1 and the missing gradient symbol in Algorithm 1. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment does not provide specific guidance on how to improve the readability of the text or how to correct the missing gradient symbol. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two claims: that the text in Table 1 is too small and hard to read, and that the gradient symbol is missing in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without justification or examples, the authors may find it challenging to understand why these issues are significant or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the readability of the text in Table 1 and the missing gradient symbol in Algorithm 1. While it points out these weaknesses, it does not provide any suggestions or guidance on how to address them. The feedback is somewhat helpful as it highlights areas that need improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should render a citation more naturally using bracketed arguments in \\citep, referencing a specific figure. It also raises a question about the compatibility of this approach with hyperref. However, the comment does not provide explicit guidance on how to implement this suggestion or clarify the issue with hyperref. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Wright et al., 1934\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to render the citation more naturally using bracketed arguments in \\citep, providing clear guidance on what needs to be done. However, the comment does not specify how this approach interacts with hyperref, leaving a minor gap in specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should render a citation more naturally using bracketed arguments in \\citep, referencing a specific figure. It also raises a question about the compatibility of this approach with hyperref. However, the comment lacks specific examples or detailed reasoning to support the claim that this approach is not natural or how it might affect the rendering of the citation. Without additional context or justification, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests a specific way to render a citation more naturally using bracketed arguments in \\citep, referencing a specific figure. It also raises a question about the compatibility of this approach with hyperref, which could be a valuable point for clarification. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to implement the proposed change or address the compatibility issue with hyperref. While it identifies a potential improvement, the feedback is somewhat limited in its actionable value, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the discussion of computational aspects, noting that the authors do not provide a detailed analysis of how their proposed methods can be practically useful for high-dimensional data. It also points out that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for their experiments being conducted on small-scale datasets, which does not reflect the practical applicability of the methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer how to improve the discussion and experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and highlights the challenges associated with solving LPs in such settings. It also points out that the experiments are performed on small-scale datasets, which does not reflect the practical applicability of the methods. However, the comment does not specify which part of the paper discusses computational aspects or which sections are relevant to the issue of high-dimensional data. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss computational aspects, particularly in high dimensions, and that their algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for conducting experiments on small-scale datasets, which does not reflect the practical applicability of their methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. The reasoning is vague and does not provide detailed evidence or guidance on how to address the issues. Therefore, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion of computational aspects, particularly in high dimensions, which is a critical area for practical applicability. It highlights that the authors do not provide a detailed analysis of how their proposed methods can be practically useful for high-dimensional data, noting that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. Additionally, the comment points out that the experiments are conducted on small-scale datasets, which does not reflect the practical applicability of the methods. This feedback is valuable as it directs the authors to address the computational aspects and the limitations of their experimental setup. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the discussion or experiments. Overall, the comment is somewhat helpful, as it identifies important areas for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the equations in the paper, suggesting that the signs should be changed. It also mentions a minor comment about a specific line. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The actions are implicit and somewhat vague, as the authors need to infer that they should correct the signs in the equations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (Line 502, 503, and 504), allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear feedback on the equations, detailing the necessary corrections to the signs. This level of detail helps the authors understand exactly what needs to be changed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific feedback on the equations in the paper, suggesting that the signs should be changed. However, it lacks detailed reasoning or examples to support why these changes are necessary or how they impact the overall understanding of the paper. The feedback is somewhat verifiable as it points out specific errors, but it does not provide a comprehensive explanation or justification for the suggested changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the equations in the paper, pointing out inconsistencies in the signs used. It suggests that the \"+\" sign after \\\\nu_j should be a \"-\" sign, and similarly for other parts of the equations. This feedback is actionable and detailed, as it offers clear guidance on how the authors should correct the equations. However, the comment could be more helpful if it included a brief explanation of why these sign changes are necessary or how they affect the overall understanding of the paper. Despite this, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests that if the ResNet does not share parameters, a comparison to a deeper ResNet with parameter sharing could be an interesting baseline, potentially equivalent to an ODE net with a fixed time-step Euler integrator. However, the comment does not provide explicit guidance on how the authors should address this question or incorporate the suggested baseline into their experiments. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by questioning whether the ResNet shares parameters and proposing a comparison to a deeper ResNet with parameter sharing. This suggestion is relevant and actionable, as it guides the authors on how to enhance their experiments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks and suggests a comparison to a deeper ResNet with parameter sharing. While the comment provides a specific suggestion for improvement, it does not offer any evidence or reasoning to support why this comparison would be beneficial or how it might impact the results. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the comment. Therefore, the claim is barely verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests an interesting baseline for comparison by proposing a deeper ResNet with parameter sharing, which could potentially be equivalent to an ODE net with a fixed time-step Euler integrator. This feedback is somewhat helpful as it identifies a potential area for further exploration and provides a suggestion for an additional experiment. However, the comment lacks detailed guidance on how to implement this suggestion or how it might impact the results, leaving the authors with limited actionable insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation of the paper, suggesting that the cross-encoder architecture is not as effective as claimed. It highlights that the architecture attends to all candidates simultaneously, which may not be as fine-grained as expected. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the motivation of the paper, specifically questioning the effectiveness of the cross-encoder architecture. It mentions that the architecture is not \"ignoring cross-entity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its critique of the architecture, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the motivation of the paper, specifically questioning the effectiveness of the cross-encoder architecture. It claims that the architecture is not \"ignoring cross-entity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is vague and does not provide a clear explanation of why the architecture is not effective or how it might be improved. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the motivation of the paper, specifically questioning the effectiveness of the cross-encoder architecture. It points out that the architecture is not 'ignoring cross-entity comparison' and that it 'attends to all candidates at once' to obtain matching scores. While the comment identifies a potential issue with the motivation, it lacks specific guidance or suggestions on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it highlights a critical aspect of the paper's motivation, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the model or the question design. The comment lacks concrete guidance on how to implement or revise the approach, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what the authors should consider regarding the design choice of trimming questions, particularly in the context of a bag-of-words question model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. While the comment raises a valid concern about the efficiency of encoding longer sequences, it does not provide specific examples or references to support the claim that this design choice is \"odd.\" The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique and how it might impact their work. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific design choice in the paper, namely the decision to trim questions after the first 10, and questions its effectiveness, especially in the context of a bag-of-words question model. This is a valuable point as it highlights a potential inefficiency in the approach, suggesting that longer sequences might be necessary for encoding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what alternative approaches could be considered. While it raises a concern, the lack of actionable feedback limits its helpfulness to the authors. Therefore, the comment is rated as somewhat helpful, as it identifies a potential area for improvement but does not offer detailed guidance on how to implement it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the use of an \"antiquated GNN model and method\" and suggests that this impacts the performance of the framework. It also mentions that the baseline algorithms/methods are \"antiquated.\" However, the comment does not provide any specific guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes or improvements are needed to enhance the performance of the framework or the baseline methods. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions the use of an \"antiquated GNN model and method\" and suggests that this impacts the performance of the framework, but it does not provide specific details on which sections or parts of the paper are affected. Additionally, the comment is not specific because it does not detail what aspects of the model or methods are considered \"antiquated\" or how they impact performance. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an \"antiquated GNN model and method,\" which seriously impacts the performance of the framework. It also mentions that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of an \"antiquated GNN model and method,\" which could impact the performance of the framework. It also points out that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific details or suggestions on how the authors might address this issue or improve their work. While it highlights a potential weakness, it does not provide actionable guidance or insights into how the authors could enhance their approach or methodology. As a result, the comment is somewhat helpful, as it raises concerns but does not offer comprehensive advice for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically regarding the presence of the NO2 group. It suggests that additional post-analysis might be needed to extract shared motifs, implying that the analysis is not as straightforward as it could be. However, the comment does not provide explicit guidance on how to address this issue or what specific steps should be taken to improve the clarity of the explanation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation in Figure 1, questioning how the proposed method produces the explanation and suggesting that additional post-analysis might be necessary. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the proposed method produces the explanation in Figure 1, specifically regarding the presence of the NO2 group. It suggests that additional post-analysis might be necessary to extract shared motifs, implying that the analysis is not as straightforward as it could be. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it offers a suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that it is unclear how the proposed method produces the explanation regarding the presence of the NO2 group. The reviewer suggests that additional post-analysis might be necessary to extract shared motifs, implying that the analysis is not as straightforward as it could be. This feedback is somewhat helpful as it highlights a potential area for improvement in the clarity and comprehensiveness of the explanation. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested alternative approaches to enhance the clarity of the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take: first, to clarify the experiment and its implications, and second, to strengthen the experiment by considering additional factors. The first action is clear and concrete, as it instructs the authors to clarify the experiment and its implications. The second action is also explicit and provides a clear direction for improvement by suggesting considering additional factors. The comment is fully actionable as it provides specific guidance on how the authors can address the identified issues. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"one experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the use of pseudo feature importance and the reliance on Prop 3.2 and a large enough perturbation value. This provides clear guidance on how to improve the experiment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the limitations of the experiment due to the use of pseudo feature importance and the reliance on Prop 3.2 and a large perturbation value. It suggests that the experiment could be strengthened by considering additional factors. However, the comment lacks specific examples or references to support the claim about the difficulty in judging the trustworthiness of the experiment. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment, noting that it uses pseudo feature importance instead of true feature importance, which makes it difficult to assess the correctness of the results. The comment suggests that the experiment could be strengthened by considering additional factors, such as the number of perturbations and the reliance on Prop 3.2. This feedback is clear and actionable, providing the authors with specific areas to address and improve their work. However, the comment could be more helpful if it offered more detailed guidance on how to strengthen the experiment or suggested alternative approaches. Overall, the comment is mostly helpful, as it provides valuable insights and actionable feedback that can guide the authors in enhancing their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that non-convexity may not be an issue for SGD convergence if the function Z has certain properties. However, it does not provide any specific guidance or action for the authors to take in response to this observation. The comment lacks explicit instructions on how the authors might address this point or incorporate it into their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (ln. 182--184) of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear observation about the potential issue of non-convexity in the context of SGD convergence, suggesting that this may not be a problem if the function Z has good properties. This level of detail helps the authors understand what aspect of the paper needs attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that non-convexity may not be an issue for SGD convergence if the function Z has good properties. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue regarding the claim that non-convexity may not be an issue for SGD convergence if the function Z has good properties. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or incorporate it into their work. The comment lacks depth and actionable advice, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of comparison with models other than GPT2, confusion in certain sections, and missing citations and unreferenced notations. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how to compare models, clarify confusing sections, or correct the missing citations and unreferenced notations. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights several issues with the paper, including the lack of comparison with models other than GPT2, confusion in certain sections, and missing citations and unreferenced notations. However, it does not specify which sections or parts of the paper are confusing or where the missing citations and unreferenced notations are located. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment provides some specificity regarding the issues of missing comparisons and missing references, it lacks full grounding as it does not explicitly mention specific sections or parts of the paper. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point contains several claims that are not fully supported by evidence or reasoning. For instance, it claims that the authors did not compare any models other than GPT2, but it does not provide specific examples or references to support this claim. Similarly, it mentions confusion in certain sections and missing citations, but it lacks detailed explanations or references to substantiate these claims. The comment also points out missing references for the notation \\hat{D}(c), but it does not provide examples or detailed reasoning to support this claim. Overall, the lack of detailed evidence and reasoning makes the claims somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper, including the lack of comparison with models other than GPT2, confusion in certain sections, and missing citations and unreferenced notations. While the comment provides some specific feedback, it lacks detailed guidance on how the authors might address these issues. For instance, it does not suggest specific models to compare with or provide examples of how to clarify confusing sections. Additionally, it does not offer actionable steps for correcting the missing citations or unreferenced notations. As a result, the comment is somewhat helpful, as it highlights important areas for improvement but does not provide comprehensive or detailed guidance for the authors to follow.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the meaning of a specific term in Equation (2). While it does not explicitly instruct the authors to provide this clarification, it implies that they should explain the term to ensure the reader understands the equation. However, the action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the term. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a particular section or equation. It is also not specific because it does not provide any guidance or suggestions on how to address the question about the meaning of the term. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on a specific aspect of the paper, namely the meaning of a term in Equation (2). It does not contain a claim or assertion that requires verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific term in Equation (2), which could be helpful for the authors to clarify for better understanding. However, it does not provide any suggestions or guidance on how to address this issue or improve the clarity of the paper. The feedback is minimal and lacks actionable advice, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific instances where the text color should be changed from red to green in the Supplementary Material (SuppMat). It also specifies the exact lines and sections where these changes need to be made, including L502, L507, and L509. The comment provides clear and explicit instructions on how the authors should update the document, making it highly actionable. The feedback is detailed and specific, allowing the authors to understand exactly what needs to be done to improve the presentation of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and sections in the Supplementary Material (SuppMat) where changes need to be made, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear instructions on which lines should be changed from red to green, and it references specific line numbers (L502, L507, and L509) and sections (Algorithm 1 and Table 4). This level of detail ensures that the authors know exactly what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement, as it provides specific line numbers and sections in the Supplementary Material (SuppMat) where text color should be changed. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on formatting inconsistencies in the Supplementary Material. By identifying that certain lines and sections should be in green instead of red, and by specifying the exact line numbers and sections (L502, L507, and L509), the comment offers clear guidance on how the authors can improve the presentation of their work. This level of detail and specificity allows the authors to easily address the issue and enhance the clarity of their document. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not provide specific guidance on how to achieve this. The comment lacks explicit instructions or concrete details on what aspects of the analysis could be expanded or what data sources could be used. As a result, the authors are left without a clear understanding of how to apply this feedback to enhance their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not specify which part of the paper this analysis should be applied to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its suggestion to enhance the analysis, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a more comprehensive and data-intensive analysis would improve the paper, but it does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand how to implement this suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that a more comprehensive and data-intensive analysis would significantly improve the paper, but it does not provide specific guidance on how to achieve this. While it identifies a potential area for enhancement, it lacks actionable advice or detailed suggestions on what aspects of the analysis could be expanded or what data sources could be used. This feedback is somewhat helpful as it points out a direction for improvement, but it does not fully address the authors' needs for actionable guidance. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment identifies two separate issues, it does not explicitly instruct the authors to address these by providing detailed experimental settings and the code. The action is implicit and somewhat vague, as the authors need to infer that they should include these details to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. However, the comment does not specify which part of the paper discusses the experimental settings or where the code is mentioned. This makes it difficult for the authors to identify the exact sections that need improvement. While the comment is specific about the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly, which is critical for result reproducibility, and that the authors do not provide the code. However, the comment lacks specific details or examples to support these claims. Without additional information or references, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail or evidence to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment highlights these important aspects, it does not offer specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to areas that need improvement, but it lacks actionable advice or detailed suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. While the comment prompts the authors to address these questions, it does not provide explicit instructions on how to incorporate the suggested comparisons or clarify the reasoning behind the exclusion of online learning approaches. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract and other instances where the authors discuss the limitations of online learning formulations. It also specifies the need for a proper comparison against online learning approaches and RL, highlighting the importance of considering retraining costs and incremental updates. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. While the questions are logical and relevant, they do not provide specific evidence or references to support the claims made. The comment lacks detailed reasoning or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. This feedback is valuable as it prompts the authors to address the limitations of their current evaluation and consider a more comprehensive comparison. However, the comment could be more helpful if it provided specific suggestions or guidance on how to incorporate these comparisons into the paper. Overall, the comment is somewhat helpful, as it identifies a key area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cite and discuss works related to meta-learning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific sections or examples to include. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and discuss works related to meta-learning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not specify which part of the paper these works are relevant to, making it weakly grounded. The comment is specific in its suggestions regarding the need to cite and discuss these works, but without clear references to specific sections or parts of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should cite and discuss works related to meta-learning, particularly those that are relevant to continual learning, even if they do not directly target it. The comment also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand and address the feedback effectively. The claim is somewhat verifiable as it provides a general direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a detailed critique of the paper, suggesting that it should cite and discuss works related to meta-learning, particularly those that are relevant to continual learning, even if they do not directly target it. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment lacks specific guidance on which parts of the paper should be addressed or how the authors should incorporate these suggestions. While it offers a clear direction for improvement, the lack of detailed examples or actionable steps makes it somewhat helpful. Therefore, the comment aligns with a score of 3, as it provides some insight but could be more comprehensive and actionable.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different feedback. However, it does not provide explicit instructions or guidance on how to implement this suggestion. The action is implicit, as the authors need to infer that they should explore methods to increase the diversity of feedback. While the suggestion is concrete in terms of exploring different feedback types, the lack of explicit guidance on how to do so makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to explore different feedback types, but without a clear reference to the paper, it is difficult for the authors to understand where to apply this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might impact the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. This is a relevant point, as it could enhance the comprehensiveness and depth of the feedback provided. However, the comment lacks specific guidance or suggestions on how to implement this idea, such as exploring different methods for generating diverse feedback or providing examples of how to do so. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide explicit instructions on how to achieve this, such as specific sections or formatting to include. The action is implicit, as the authors need to infer that they should add a summary of the supplement experiments to the main text. This makes the comment somewhat actionable, as it provides a clear direction but lacks concrete guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the paper this clarification should be made, leaving the authors to infer that it should be in the main text. The comment is specific in its suggestion to clarify and summarize the experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification, making it difficult for the authors to understand why this clarification is necessary or how it would benefit their work. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it lacks specific guidance on how to achieve this, such as suggesting where in the text these experiments should be discussed or what kind of summary would be most effective. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide detailed actionable advice, leaving the authors with limited direction on how to address the issue. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. The comment provides a clear action for the authors to take, which is to address the missing references and conduct a comparison. However, it does not specify how to implement this action, such as which sections of the paper should be compared or what specific aspects of the comparison are needed. While the action is explicit, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, GFF[1] and EfficientFCN[2], which are relevant to the paper. It also specifies what needs to be addressed, namely a comprehensive comparison with these works. The comment is specific in detailing the need for a comparison and provides examples of relevant works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. However, the comment lacks specific examples or detailed reasoning to support the claim that these references are indeed important or missing. Without additional context or justification, the authors may find it challenging to understand why these references are crucial. Therefore, the claim is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or evidence to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works, which is a valuable suggestion for improving the paper's context and relevance. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what aspects of the comparison are essential. Despite this, the feedback is mostly helpful as it directs the authors towards a crucial area for improvement, enhancing the paper's comprehensiveness and scholarly value.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to strengthen their claims. The comment lacks concrete suggestions or detailed instructions on how to improve the experimental results or the claims made. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper these tables are located in, nor does it provide any guidance on how the authors might address this issue or strengthen their claims. The lack of specific references and detailed suggestions makes it difficult for the authors to understand the exact areas that need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. While the comment identifies a potential issue with the claim, it does not provide specific guidance or suggestions on how the authors might address this concern or strengthen their experimental results. The feedback is somewhat helpful as it highlights a critical point that needs attention, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation provides a clear and explicit action for the authors to take, as they can compare their results with these specific works to better understand their performance relative to existing methods. The comment is concrete, as it specifies exactly which papers to compare with, and it provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is fully grounded as it explicitly mentions the papers being compared, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies which papers to compare with, providing a clear direction for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is somewhat verifiable as it provides a clear suggestion for comparison, but it lacks specific details or examples of how the comparison should be conducted or what aspects of the performance should be analyzed. Without additional context or guidance, the authors may find it challenging to fully understand and implement the recommendation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation provides a clear and actionable direction for the authors to improve their draft by benchmarking their results against existing work. By comparing their performance with these specific papers, the authors can better understand the strengths and weaknesses of their approach and identify areas for further improvement. The comment is mostly helpful as it offers a concrete suggestion for comparison, but it could be more comprehensive if it included additional details or guidance on how to conduct the comparison effectively. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the Cycle FC method, noting that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests that there could be many different designs for this method and recommends exploring experiments or analysis with different sampling intervals and sample sizes. While the comment identifies an area for improvement and provides a direction for further exploration, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the Cycle FC method, specifically mentioning that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests exploring experiments or analysis with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC method or where the analysis is conducted. This makes it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue of insufficient analysis, it lacks grounding as it does not provide clear references to the relevant parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of the Cycle FC method is slightly insufficient and suggests exploring experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to justify why the analysis is insufficient or how the suggested experiments would address this issue. Without concrete examples or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the Cycle FC method, noting that it aligns features at different spatial locations to the same channel, but the analysis is slightly insufficient. It suggests exploring experiments or analysis with different sampling intervals and sample sizes as a way to address this issue. While the comment points out a specific area for improvement and provides a direction for further exploration, it lacks detailed guidance on how to conduct these experiments or what specific analyses would be beneficial. The feedback is somewhat helpful as it directs the authors towards potential enhancements, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically Algorithm 1, which uses a Vandermonde matrix known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\alpha$. The reviewer expresses concern that the algorithm may fail in practice even for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to conduct the experiments. While the action is implied, it is vague and lacks specific details on how to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern regarding the numerical instability of the algorithm, particularly for large $n$ and small $\\alpha$. The comment suggests that the paper would be more convincing if the authors provided experimental results, which is a clear and specific request for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically Algorithm 1, which uses a Vandermonde matrix known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\alpha$. The reviewer expresses concern that the algorithm may fail in practice even for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. However, the comment lacks specific examples or references to support the claim about the ill-conditioned nature of the Vandermonde matrix and its impact on the algorithm's performance. Without detailed reasoning or evidence, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical performance of the proposed algorithms, specifically Algorithm 1, which uses a Vandermonde matrix known to be ill-conditioned and numerically unstable. The reviewer provides a detailed explanation of the potential issues with the algorithm's performance, particularly for large $n$ and small $\\alpha$. The comment suggests that the paper would be more convincing if the authors provided experimental results to support their claims. This feedback is clear and actionable, as it directs the authors to address a specific concern and provide empirical evidence to strengthen their work. However, the comment could be more helpful if it offered guidance on how to conduct the experiments or suggested specific types of experiments that would be relevant. Overall, the comment is mostly helpful, as it identifies a significant area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the lack of standard deviations in the results, questioning the certainty of the best method's superiority. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or providing additional analysis to clarify the performance differences. The action is implicit and vague, as the authors are left to infer that they need to include standard deviations to address the concern. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of missing standard deviations in the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the problem, questioning the certainty of the best method's superiority due to the absence of standard deviations. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of standard deviations in the results makes it uncertain whether the best method is truly the best or if other RF configurations have performances close to it. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the lack of standard deviations in the results, which raises concerns about the certainty of the best method's superiority. While the comment highlights a critical gap in the analysis, it does not provide specific guidance or suggestions on how the authors might address this issue, such as including standard deviations or conducting additional analysis. The feedback is somewhat helpful as it points out a crucial area for improvement, but it lacks depth and actionable advice, making it only partially beneficial for the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests that the approach should be extended to more general settings. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to extend the approach or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific setting of the paper, including the requirements for the model and the episodic nature of the problem. It also specifies the need to extend the approach to more general settings, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being discussed and understand the specific issue being raised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific question about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. While the comment does not provide a claim or assertion, it raises a question that could be addressed by the authors. However, without further elaboration or justification, the comment lacks sufficient detail to be considered fully verifiable. Therefore, it is categorized as \"2: Borderline Verifiable.\"', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. This feedback is clear and actionable, as it provides a direction for improvement by identifying a potential area where the approach could be broadened. However, the comment could be more helpful if it offered specific guidance on how to extend the approach or what aspects of the current setting could be relaxed. Despite this, the feedback is mostly helpful as it directs the authors towards a meaningful enhancement of their work. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. While the comment identifies a specific detail that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this question. The action is implicit, as the authors need to infer that they should clarify the feature extractor used. However, the comment lacks concrete guidance on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it directly asks for clarification on the feature extractor used in relation to the dimensionality of each region. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This is a factual question that requires the authors to provide additional information or context. However, it does not contain a subjective claim or opinion that needs verification. Therefore, it is classified as \"No\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific detail in the paper, namely the dimensionality of each region being 512, and asks for clarification on which feature extractor is used. This is a clear and actionable question that prompts the authors to provide more context or detail about the feature extraction process. By addressing this question, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it suggested specific ways to clarify the feature extractor or provided examples of how this information could be presented. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks depth in its guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit, as the authors can infer that they need to add these details, but the lack of specificity makes it difficult to know exactly what to do. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in or how they should be presented. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of computation, algorithm, or implementation details would be beneficial. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not offer any specific reasoning, examples, or references to support why this suggestion is beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it lacks specificity and does not offer any guidance on how these details should be presented or what aspects of the paper would benefit from such information. While the comment identifies a potential area for improvement, it does not provide actionable feedback or suggestions for the authors to address this issue. Therefore, the comment is barely helpful, as it offers a vague suggestion without detailed guidance or examples. The score aligns with a rating of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of p < 0.4 in Algorithm 1, but it does not provide any guidance or suggestions on how the authors might have made this choice. The comment lacks explicit instructions or concrete advice on how to address the question or improve the algorithm. As a result, the authors are left without a clear understanding of what to do or how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the choice of p < 0.4 in Algorithm 1, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in questioning the choice of a particular value, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of p < 0.4 in Algorithm 1, but it does not provide any justification or reasoning for why this specific value was chosen. Without additional context or explanation, the authors are left without guidance on how to address this question or whether it is a valid choice. The comment lacks supporting evidence or logical reasoning, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of p < 0.4 in Algorithm 1, which is a specific aspect of the methodology. However, it does not provide any guidance or suggestions on how the authors might have made this choice or why it is appropriate. The comment lacks depth and does not offer actionable feedback that would help the authors improve their draft. As a result, it is barely helpful, as it identifies a potential issue but does not provide any constructive advice or direction for the authors to address it. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide explanations or analysis for the figures presented in Section 5, specifically mentioning the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and direct, allowing the authors to understand exactly what needs to be addressed. The action is explicit and concrete, as it specifies the exact sections and elements that require clarification. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5\" and the figures \"Figure 1, Figure 2, and Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of explanations or analysis for the figures, particularly the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors fail to provide explanations or analysis for the figures presented in Section 5, specifically mentioning the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of figures in Section 5, noting that the authors fail to provide explanations or analysis for Figures 1, 2, and 3. It highlights the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, as it directs the authors to specific areas where they need to improve their draft by adding explanations and analysis. However, the comment could be more helpful if it provided examples of how to explain or analyze the figures, such as suggesting specific types of analysis or questions to include. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify exactly what aspects of the motivation need clarification or how to demonstrate it more explicitly. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion to provide a clearer explanation, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left to infer the basis of the claim, making it difficult to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the motivation behind applying CMD in federated learning. It suggests that the authors could benefit from a more explicit demonstration or explanation of this motivation. However, the comment lacks specific guidance on how to address this issue or what aspects of the motivation need clarification. While it points out a potential area for improvement, it does not provide detailed suggestions or examples, making it somewhat helpful. The authors would need to infer the exact steps to take, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the analysis or what specific aspects of the methods should be examined. The suggestion to compare with other methods is clear, but the lack of detailed instructions on how to perform the analysis makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. However, it does not specify which part of the paper this analysis should be conducted or which sections of the paper discuss the methods being compared. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the type of analysis and comparison suggested, the lack of grounding makes it challenging for the authors to understand which parts of the paper are relevant. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. The comment provides specific references to support the suggestion, which helps the authors understand the basis for comparison. However, the claim about the lack of analysis is somewhat vague and lacks detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is mostly verifiable, as it provides some support but could be more robust with additional details or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, to clarify the unique advantages of the proposed method. The inclusion of references to specific works further supports the suggestion, providing a clear direction for the authors to enhance their analysis. This feedback is mostly helpful as it offers actionable insights and guidance on how to improve the paper's analysis and comparison, though it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study is needed to understand the effect of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly instruct the authors to conduct an ablation study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the need for an ablation study and the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for an ablation study in learning with MMD, suggesting alternative approaches such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion for improvement, as it provides concrete examples of alternative approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study is needed to understand the effect of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment lacks specific details or references to support the claim that an ablation study is necessary or how it would be conducted. The suggestion is somewhat vague and could benefit from more detailed guidance or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the learning with MMD approach, specifically noting the lack of an ablation study to understand the effect of each component. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is somewhat helpful as it highlights a potential area for improvement and offers some suggestions for further exploration. However, it could be more helpful if it provided more detailed guidance on how to conduct the ablation study or why it is necessary. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it raises a relevant question, it does not provide explicit guidance or suggestions on how the authors should address this issue or what actions they should take to improve their draft. The comment lacks concrete instructions or detailed feedback, leaving the authors uncertain about how to respond or what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity because it does not detail what the authors should do to address this question or how it relates to the overall content of the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any context, explanation, or justification for why this question is important or how it relates to the paper's content. Without additional information or reasoning, the authors are left without guidance on how to address this question or what it implies for their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of a model that assigns all negative samples to a distractor class. While this question is relevant to understanding the model's behavior, it does not provide specific guidance or suggestions on how the authors might address this issue or what improvements could be made to their draft. The comment lacks actionable feedback, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the performance of RLCD and RLAIF as the model size increases, noting that the advantage of RLCD diminishes from 7B to 30B. It raises a question about whether RLCD or RLCD-Rescore can scale to larger models that are better at differentiating responses near the decision boundary. While the comment identifies an area for further exploration and questions the scalability of RLCD, it does not provide explicit or implicit actions for the authors to take. The authors are left to infer that they should investigate the performance of RLCD and RLCD-Rescore on larger models, but the comment lacks concrete guidance on how to conduct this investigation or what specific aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of RLCD and RLAIF as the model size increases, specifically noting the shrinking advantage from 7B to 30B. It raises a question about whether RLCD or RLCD-Rescore can scale to larger models that are better at differentiating responses near the decision boundary. However, the comment does not specify which part of the paper this observation is based on, making it weakly grounded. It is specific in detailing the observation about the performance trend and the question about scalability, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, based on the data presented in Table 2. While the claim is supported by the data in the table, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the significance of this observation and its implications for the scalability of RLCD. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks depth and clarity in its reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a specific observation about the performance of RLCD and RLAIF as the model size increases, noting that the advantage of RLCD diminishes from 7B to 30B. It raises a question about whether RLCD or RLCD-Rescore can scale to larger models that are better at differentiating responses near the decision boundary. This feedback is somewhat helpful as it identifies a trend in the data and prompts the authors to consider the scalability of their model. However, it could be more helpful if it provided specific suggestions or guidance on how to investigate this further, such as suggesting additional experiments or analyses. Overall, the comment offers a valuable insight but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. While the comment highlights a potential limitation, it does not provide explicit guidance on how to address the scalability issue or suggest specific solutions. The action is implicit, as the authors need to infer that they should consider the scalability issue and explore potential solutions. However, the lack of concrete details makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not specify which part of the paper discusses the proposed NC measure or the scalability issue, making it difficult for the authors to identify the exact section to address. While the comment is specific about the issue of scalability, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim about the scalability issue. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be significantly reduced without addressing this issue. While the comment highlights a potential limitation, it does not provide specific suggestions or guidance on how to address the scalability issue or improve the method's applicability to large datasets. The feedback is somewhat helpful as it identifies a significant area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative analysis regarding computational gains, specifically mentioning the absence of measurements like GPU hours, memory usage, or training time. It suggests that such analysis would provide stronger evidence of efficiency improvements. The comment is explicit in identifying the missing information and provides concrete details on what kind of data would be needed to substantiate the claim. This allows the authors to directly address the issue by including the suggested quantitative analysis in their revised draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"computational gains\" and \"DQ V2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of quantitative analysis on computational gains, such as GPU hours, memory usage, or training time, which would provide stronger evidence of efficiency improvements. This detailed feedback helps the authors understand exactly what needs to be addressed to substantiate the claims of computational benefits.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks quantitative analysis on computational gains, specifically mentioning the absence of measurements like GPU hours, memory usage, or training time. It suggests that such analysis would provide stronger evidence of efficiency improvements. However, the comment does not provide any examples, references, or detailed reasoning to support the claim that these measurements are missing or critical. Without specific evidence or examples, the claim remains somewhat verifiable, as the authors would need to infer the need for such analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights that while the paper claims efficiency improvements through the use of a CNN-based data augmentation strategy, it does not provide specific measurements or comparisons to substantiate these claims. The suggestion to include quantitative data such as GPU hours, memory usage, or training time is clear and actionable, offering a concrete way for the authors to strengthen their claims and provide evidence of the efficiency improvements. This feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path for addressing it. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing, which implies that the method might be less efficient for these scenes. However, the comment does not provide explicit guidance on how to incorporate this information into the comparison or how to address the efficiency issue. The action is implicit and vague, as it does not specify what needs to be done to make the comparison more accurate or how to demonstrate the efficiency of the method. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"COLMAP\" and \"scene-by-scene fine-tuning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, noting that the time taken for these processes should be considered, making the method less efficient. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing, rendering the method less efficient for these scenes. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of COLMAP and scene-by-scene fine-tuning, suggesting that the time taken for these processes should be considered to accurately assess the method's efficiency. However, the comment lacks specific guidance or suggestions on how to address this issue or what data should be included in the comparison. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an important aspect that needs attention but does not offer comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. While the comment highlights areas that need further discussion and analysis, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. However, the comment does not specify which part of the paper discusses the FMN, making it difficult for the authors to pinpoint the exact section that needs attention. While the questions are specific, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are open-ended and lack depth, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several important questions and concerns about the discussion and analysis of the 'filter manifold network' (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. These questions highlight areas where the authors could provide more detailed analysis and discussion. However, the comment lacks specific suggestions or guidance on how to address these issues, making it somewhat helpful. The feedback provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the contribution of the CoNO model, specifically whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable and provides references to support the claim. While the comment implies that the authors should compare their model to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to UNets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed CoNO model and questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This comment is fully grounded as it explicitly mentions the CoNO model and the specific parts of the paper being discussed. It is also specific because it provides clear guidance on what comparisons should be made, namely comparisons to UNets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the contribution of the CoNO model, specifically whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, referencing works by Raonic et al. and Gupta et al. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, the comment could be more robust if it included a detailed explanation of why these comparisons are necessary or how they would impact the evaluation of the model. Overall, the claim is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical question about the contribution of the CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, as evidenced by references to works by Raonic et al. and Gupta et al. This feedback is valuable as it prompts the authors to provide a more detailed analysis of their model's performance and to include comparisons with relevant baselines. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects of the model's performance should be compared. Overall, the comment is mostly helpful, as it identifies a significant area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It points out that the comparison of computational complexity is expected in the experiment part. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the method. The action is implicit, as the authors need to infer that they should compare the computational complexity of their method with the baselines. While the action is somewhat vague, it is clear that the authors need to address the computational complexity issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational complexity of the proposed PSA method, specifically mentioning that it requires more computation than baselines. It also notes that the comparison of computational complexity is expected in the experiment part. However, the comment does not specify which part of the paper discusses the algorithm or the experimental setup, making it weakly grounded. The comment is specific in identifying the issue with the computational complexity of the PSA method, but without explicit references to sections or figures, the authors may need to infer which parts to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically noting that it involves calculating all previous layer outputs in the current layer. The comment suggests that a comparison of computational complexity is expected in the experiment part. However, the comment lacks specific details or references to support this claim, such as examples of how the computation is performed or comparisons with other methods. Without these details, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient evidence or references to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It highlights a potential gap in the comparison of computational complexity, which is expected in the experiment part. While the comment points out a valid concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the method. The feedback is somewhat helpful as it directs the authors to consider the computational complexity of their method, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them to conduct specific experiments or analyses to demonstrate the contribution of each factor. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. However, the comment does not specify which part of the paper discusses the model or the factors, making it weakly grounded. It is specific in suggesting an analysis of the individual contributions of noise and exponential moving average, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. However, the comment lacks specific examples or references to support the claim that the \\Pi model captures only the noise part. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and enhance their model. However, the comment could be more helpful if it included suggestions for how to conduct the analysis or what specific experiments to perform. Overall, the comment is mostly helpful, as it offers valuable insights and guidance for the authors to improve their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides several specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggesting that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are explicit and provide clear guidance on how the authors should improve their draft, making the comment highly actionable. The comment is fully grounded as it explicitly mentions specific parts of the paper that need improvement, and it is specific because it provides detailed suggestions for each part. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are specific and provide clear guidance on how the authors should improve their draft, making the comment fully verifiable. The comment is detailed and offers actionable advice, allowing the authors to understand exactly what needs to be addressed. Therefore, it is classified as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other state-of-the-art Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. These suggestions are detailed and actionable, providing clear guidance on how the authors can improve their draft. However, the comment could be more helpful if it included specific examples or detailed instructions on how to implement these suggestions. Overall, the feedback is mostly helpful, as it offers valuable insights and actionable advice for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reporting of results, suggesting that the paper only shows results after a significant amount of training. It also speculates about the potential impact of the CNN's performance with less data, questioning whether the model is able to perform reasonably well with less data. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting how to include results during training or how to address the speculation about the CNN's performance. The feedback lacks concrete guidance on how to address these issues, making it difficult for the authors to know what steps to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the reporting of results, suggesting that the paper only shows results after a significant amount of training. It speculates about the potential impact of the CNN's performance with less data, questioning whether the model is able to perform reasonably well with less data. However, the comment does not specify which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of results being reported after training, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reporting of results in the paper, specifically noting that results are only reported after a significant amount of training. It speculates on the potential impact of the CNN's performance with less data, questioning whether the model is able to perform reasonably well with less data. However, the comment does not provide any specific evidence, examples, or references to support the claim that the results are only reported after training. This lack of substantiation makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent concern about the reporting of results in the paper, specifically noting that results are only reported after a significant amount of training. This is a valid point, as in reinforcement learning, understanding the agent's behavior during the learning process is crucial. The comment suggests that the authors might be interested in exploring how the CNN performs with less data, which is a reasonable speculation. However, the comment lacks specific guidance or suggestions on how to address this issue or what experiments could be conducted to investigate the CNN's performance with less data. While it identifies an area for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to rewrite a specific sentence in the paper, indicating that the original phrasing is unclear. This provides a clear and direct action for the authors to take, making the comment highly actionable. The comment also specifies the location of the sentence, further enhancing its clarity and utility. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the location of the sentence in the paper (P. 5, p. 3, l.), allowing the authors to accurately identify the part being addressed. It is also specific because it requests a rewrite of the sentence, which is clear and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding a specific sentence in the paper, rather than a claim that requires verification. It does not contain any subjective opinions, logical reasoning, or references. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it directly identifies a specific issue with the clarity of a sentence in the paper. By requesting a rewrite, the authors are given a clear and actionable direction to improve the readability and understanding of the text. This feedback is specific and provides a concrete step for the authors to take, making it highly beneficial for enhancing the quality of their draft. Therefore, the comment is rated as 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions. It suggests that the authors should consider these aspects and provide details on how they are addressed in the manuscript. While the comment implies that the authors should include this information, it does not explicitly instruct them to add it or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include details about these aspects in their manuscript. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DocRED\" and \"multiple entity mentions,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with how the authors handle documents as an entire sentence and how they deal with multiple entity mentions, which are important aspects of the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are specific concerns related to the methodology or experimental setup. However, it does not provide any claims or suggestions that require verification or justification. The comment is factual and descriptive, lacking any subjective opinions or assertions. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are important aspects of the manuscript. It highlights a potential gap in the current manuscript by noting that these details are missing. However, the comment does not provide any suggestions or guidance on how the authors might address these issues or improve their manuscript. While it identifies an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. It further recommends adding another stream for low-resolution, which might not be a major contribution for a top-tier venue like ICLR. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes might be necessary to enhance the contribution. The action is implicit and vague, as it does not specify how the authors should demonstrate the novelty or significance of their contribution or how they might address the concern about the low-resolution stream. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"a top-tier venue like ICLR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear opinion on the marginality of the contribution and suggests adding another stream for low-resolution, which is a specific aspect of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. It recommends adding another stream for low-resolution, which might not be a major contribution for a top-tier venue like ICLR. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the contribution is marginal or that adding a low-resolution stream would not be a major contribution. As a result, the claim is unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. It recommends adding another stream for low-resolution, which might not be a major contribution for a top-tier venue like ICLR. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance the contribution. It does not provide actionable advice or detailed feedback on what aspects of the paper could be improved to make the contribution more significant. As a result, the comment is barely helpful, as it does not offer substantial insights or constructive feedback to the authors. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of the main contribution, suggesting that the performance gain is primarily due to PBSD. It also asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment implies that the authors should clarify the main contribution and provide additional motivations for PBSD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer what needs to be addressed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the clarity of the main contribution and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the content being questioned, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the main contribution and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment does not provide any specific evidence, reasoning, or references to support its claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the main contribution, specifically questioning whether it is somewhat unclear. It suggests that the performance gain is primarily due to PBSD, as indicated by the ablation study, and asks for clarification on the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it prompts the authors to consider additional motivations for PBSD, but it lacks depth and actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It asks for clarification on how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0, but d_K(\u03c0_0, \u03c0) is large. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on what needs to be done or how to address the question. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It asks for clarification on how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0, but d_K(\u03c0_0, \u03c0) is large. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It asks for clarification on how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0, but d_K(\u03c0_0, \u03c0) is large. However, the comment does not provide any evidence, reasoning, or references to support the claim that the reviewer is questioning the implications of the provided tester. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the implications of providing a tester for the spread parameter, specifically whether it also yields an (\u03f5, \u03b4)-identity tester. It asks for clarification on how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0, but d_K(\u03c0_0, \u03c0) is large. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a specific area that needs further explanation, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. While the comment highlights a potential issue with the authors' engagement with the appendix, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The feedback is implicit and lacks concrete suggestions, making it difficult for the authors to understand how to enhance their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. However, the comment does not specify which part of the Appendix or the paper the authors should focus on, nor does it provide any guidance on how to address this issue. The lack of specific information about the sections or experiments mentioned makes it difficult for the authors to understand the exact areas that need attention. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern about the authors not carefully reading the additional experiments described in the Appendix, such as the Brusselator, due to time constraints. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to explain why the authors might not have read the appendix thoroughly. Without additional context or reasoning, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. While the comment highlights a potential issue with the authors' engagement with the appendix, it does not provide specific suggestions or guidance on how to address this concern. The feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it difficult for the authors to fully understand how to enhance their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This question implies that the authors should clarify the distinction between the two methods to avoid misleading readers. While the comment is explicit in its request for clarification, it lacks concrete guidance on how to address the issue or what specific aspects of the method need to be clarified. The authors are aware of the need to provide more detail but are not given explicit steps on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors\\' claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This question is clear and specific, as it directly addresses the method used in the paper. However, it does not provide explicit references to specific sections or parts of the paper, making it weakly grounded. The comment is specific in its request for clarification, as it asks for a comparison between the \"active learning pipeline\" and traditional active learning. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about using active learning in step 2, specifically asking whether the \"active learning pipeline\" is the same as traditional active learning. This is a subjective claim that requires the authors to clarify their methodology and ensure that their description is accurate and consistent with established practices. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to address this question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the authors\\' claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" is the same as traditional active learning, which could potentially mislead readers. This feedback is clear and identifies a specific area that needs clarification. However, it lacks detailed guidance on how the authors should address this issue or what specific aspects of their method need to be clarified. While the comment is somewhat helpful, it could be more impactful with additional suggestions or examples to guide the authors in improving their description. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the dataset distribution. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the detailed distribution of the proposed dataset. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is specific in that it points out a lack of clarity in the dataset distribution, but without grounding, the authors are left to guess which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the detailed distribution of the proposed dataset is unclear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of why the dataset distribution is unclear or how it might be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the detailed distribution of the proposed dataset is unclear. However, it does not provide any suggestions or guidance on how the authors might address this lack of clarity. Without actionable feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a problem but does not offer any constructive advice or direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a self-supervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how to implement or address this issue. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration of self-supervised methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method's reliance on annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of supervised training. This makes it difficult for the authors to pinpoint the exact section or aspect that needs attention. While the comment is specific about the issue of annotated labels and suggests an alternative approach, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method necessitates annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it is based on a logical deduction but lacks sufficient substantiation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed method, specifically that it requires annotated labels for learning semantic tokens, which restricts its applicability to supervised training. It suggests that a self-supervised pretraining approach without annotations could be more appealing. This feedback is somewhat helpful as it highlights a potential area for improvement and offers an alternative approach. However, the comment could be more helpful if it provided specific guidance on how to implement or explore the self-supervised approach. Overall, the comment offers valuable insights but lacks detailed actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides a clear and explicit action for the authors to take, as they need to expand their experiments to include these more complex tasks. The comment is specific in its suggestion and offers concrete guidance on how to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"continuous control experiments\" and provides examples of tasks like \"cartpole or mountain car\" and \"locomotion of ants or humanoids.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need to demonstrate LFF's effectiveness on more challenging DRL tasks with higher input dimensionality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car, and suggests that it is important to demonstrate LFF's effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is somewhat verifiable as it provides a logical reasoning for why the authors should consider more complex tasks to showcase the scalability of LFF. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of LFF, the authors should show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, providing the authors with a specific direction to enhance their work. By addressing this suggestion, the authors can strengthen the paper's claims about the scalability of LFF and provide a more comprehensive evaluation of its capabilities. Therefore, the comment is highly helpful, as it offers constructive guidance for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests specific changes to the abstract, recommending a more detailed description of expressivity and the inclusion of learning curves for all experiments, potentially in an appendix. While the comment provides explicit guidance on what should be included in the abstract, it does not specify how the authors should implement these changes or what steps they should take to generate the learning curves. The action is somewhat vague, as it lacks concrete instructions on how to produce the learning curves or how to present the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, providing a clear reference point for the authors to understand where the feedback is being applied. It also specifies what the authors should include in the abstract, such as a more detailed description of expressivity and the inclusion of learning curves for all experiments. This level of detail allows the authors to accurately identify the part of the paper that needs revision. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract should include a more detailed description of expressivity, specifically mentioning the change in linear regions in output space after a citation. It also recommends including learning curves for all experiments, potentially in an appendix. While the suggestion is logical and provides a specific example, it lacks detailed reasoning or references to support why these additions would be beneficial. The comment is somewhat verifiable as it offers a clear direction for improvement but could be strengthened with additional justification or examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the abstract by adding more detail about expressivity and including learning curves for all experiments. It suggests that the abstract should mention the change in linear regions in output space after a specific citation, which would provide a more detailed and informative description of the paper's contributions. Additionally, the comment recommends including learning curves for all experiments, potentially in an appendix, which would enhance the paper's comprehensiveness and allow for a more thorough evaluation of the results. These suggestions are clear and actionable, offering the authors a clear path to improve their draft. However, the comment could be more helpful if it provided additional guidance on how to generate or present the learning curves effectively. Overall, the feedback is mostly helpful, as it addresses specific areas for improvement and provides a solid foundation for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the paper's motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. While the comment implies that the authors should provide more context and examples to clarify the motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the motivation and provide examples of domain adaptation tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the paper's motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not specify which part of the paper discusses the motivation or the application of the proposed method, making it weakly grounded. It is specific in detailing what needs to be addressed, such as clarifying the motivation and providing examples of domain adaptation tasks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the lack of clarity in the paper's motivation and the absence of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors are left to infer the need for clarification and examples, which could be addressed with additional evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by questioning the clarity of the motivation and the lack of a clear application for the proposed method. It highlights the absence of a clear demonstration of how the domain adaptation technique would be useful in practical scenarios, such as adapting a model trained on a synthetic dataset to a real dataset. The comment suggests that including examples of such applications would significantly enhance the paper's impact and relevance. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or tasks that would illustrate the practical utility of the proposed method. Overall, the comment is mostly helpful as it directs the authors to address a critical aspect of their work, but it could be further improved with more detailed guidance.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for considering only one deep learning-based baseline, MULT, which was proposed in 2019 and is no longer considered state-of-the-art. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how the authors might update their baseline comparisons or justify their choice of baselines. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a list of references related to multimodal sentiment analysis and emotion recognition, but it does not specify which part of the paper these references are relevant to. The authors cannot confidently determine which sections or aspects of their work are being addressed by the critique. Additionally, the comment does not specify what needs to be addressed in these references or how they relate to the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper regards MISA as the only deep learning-based baseline that considers cross-sensory interaction but notes that MISA was proposed in 2020, making it somewhat out of fashion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by suggesting that the baseline used, MISA, is outdated and no longer considered state-of-the-art. It points out that MISA was proposed in 2020, which may make it less relevant for current research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as considering more recent baselines or justifying their choice of MISA. Without actionable advice or suggestions, the comment is somewhat helpful as it highlights a potential area for improvement but lacks depth and direction. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should compare the tensor completion results for all models, including TW, TT, and TR, while ensuring that they have the same number of model parameters. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue of unclear comparisons. The comment is fully actionable because it specifies the exact steps required to improve the fairness of the comparison. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a comparison against other models in the experiments, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on how to address the issue, including the omission of model ranks and the requirement to compare tensor completion results with the same number of model parameters. This level of detail ensures that the authors understand exactly what needs to be done to improve the fairness of the comparison. Therefore, this comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison against other models in the experiments is unclear and that the omission of model ranks makes it difficult to ensure a fair comparison. The comment suggests that the authors should compare tensor completion results for all models, including TW, TT, and TR, while having the same number of model parameters. This claim is somewhat verifiable as it provides a logical reasoning for why the comparison is unclear and suggests a specific action to take. However, it lacks detailed examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a significant issue with the experimental comparison, specifically the lack of clarity and the omission of model ranks. It provides clear guidance on how to address this issue by suggesting that the authors should compare tensor completion results for all models, including TW, TT, and TR, while ensuring that they have the same number of model parameters. This detailed feedback is actionable and constructive, as it helps the authors improve the fairness and rigor of their experiments. The comment is comprehensive and provides a clear path for the authors to enhance their draft, making it highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it was shown to be better than \"FP\" in Table 1. This provides a clear and explicit action for the authors to take, which is to include \"ATA\" in the comparison. The comment is specific and concrete, as it directly instructs the authors on what needs to be done to strengthen the comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific setting \"leave one out,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of the proposed method to \"ATA\" in the context of the \"leave one out\" setting. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as \"ATA\" was shown to be better than \"FP\" in Table 1. This claim is somewhat verifiable as it provides a logical reasoning based on the results in Table 1 to justify the suggestion. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that the proposed method should be compared to \"ATA\" in Table 2. This is based on the observation that \"ATA\" was shown to be better than \"FP\" in Table 1. The comment provides a clear and actionable suggestion for the authors to enhance the comparison and strengthen the results section. By including \"ATA\" in the comparison, the authors can provide a more comprehensive and convincing evaluation of their method. This feedback is mostly helpful as it offers a specific and constructive suggestion for improvement, though it could be further elaborated to provide additional context or rationale. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential inconsistency in the normalization module between two versions of the paper, suggesting that the text might be misleading. It also points out the need for standardization in the pictograms used in the figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/5.0 to 2.5/4.0 MAE range. Additionally, the reviewer notes minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not provide explicit or implicit actions for the authors to take, such as how to address the inconsistency in the normalization module or how to standardize the pictograms. The lack of actionable guidance makes it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the normalization module, suggesting that it appears different in two versions despite the text implying consistency. It also recommends standardizing pictograms in figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/50 to 2.5/4.0 MAE range. Additionally, it points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing the issues with the normalization module and the need for standardization in the pictograms, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the normalization module, suggesting that it appears different in two versions despite the text implying consistency. It also recommends standardizing pictograms in figures, specifically mentioning Figure 4, which is confusing due to overlapping symbols in the 0/50 to 2.5/4.0 MAE range. Additionally, it points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the comment lacks detailed reasoning or specific examples to fully substantiate these claims. While it provides some context, it does not offer a comprehensive explanation or evidence to support the claims, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the normalization module between two versions of the paper, which could lead to confusion for readers. It also suggests the need for standardization in the pictograms used in the figures, particularly noting that Figure 4 is confusing due to overlapping symbols in the 0/50 to 2.5/4.0 MAE range. Additionally, the comment points out minor issues with the text, such as a specific point on page 4 after equation 2. However, the feedback lacks detailed guidance or suggestions on how to address these issues, making it somewhat helpful. The authors would benefit from a clearer understanding of the inconsistencies and the need for standardization, but the comment could be more actionable with specific recommendations or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. The comment implies that the authors should clarify the algorithm's details and address the computational cost. However, it does not explicitly instruct the authors to provide these details or address the cost, making the action implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the authors' claim regarding the utility of subdivision splines and the computational cost of the proposed algorithm. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in that it questions the details of the algorithm and its computational cost, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. The comment implies that the authors should clarify the algorithm\\'s details and address the computational cost. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is barely verifiable, as it provides some context but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the utility of subdivision splines and the computational cost of their proposed algorithm. It questions the lack of detail in the theoretical part of the paper regarding how the algorithm removes subdivision splines and whether it incurs extra computational costs. This feedback is somewhat helpful as it points out a gap in the paper's explanation and raises a valid concern about the algorithm's efficiency. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues. Overall, the comment offers some insight but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While it suggests that these terms likely denote the Encoder and Decoder networks, the comment does not provide explicit guidance on how the authors should define these terms or where they should be defined. The action is implicit, as the authors need to infer that they should define W and V, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear indication of what needs to be addressed but does not offer specific guidance on how to implement the action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper (p.3, A4, eq.3 and eq.4) where the terms W and V are not defined. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies that the terms W and V are not defined in these sections, and it suggests that these terms likely denote the Encoder and Decoder networks. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While the comment identifies a potential issue with the clarity of the paper, it does not provide any specific examples or references to support the claim. The authors are left to infer that the terms are likely undefined, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the terms W and V are not defined in equations 3 and 4. This is a clear and actionable feedback that highlights a lack of clarity in the paper. By pointing out the missing definitions, the comment provides the authors with a direct instruction to improve the readability and understanding of their work. However, the comment could be more helpful if it suggested where these terms should be defined or provided examples of how they are used. Overall, the feedback is somewhat helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparison with some baselines is unfair because these baselines lack prior knowledge of users or language embedding computation. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the comparison. The action is implicit, as the authors need to infer that they should consider a more fair comparison by incorporating prior knowledge or language embedding computation into the baselines. While the action is clear, the lack of concrete details on how to implement this change makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that need revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the proposed method with some baselines, specifically noting that these baselines lack prior knowledge of users or language embedding computation. This observation raises concerns about the fairness of the comparison. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. While it highlights a potential weakness, it lacks actionable advice or detailed recommendations, making it somewhat helpful. The authors would need to infer that they should consider incorporating prior knowledge or language embedding computation into the baselines to ensure a fairer comparison. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, including why the output-side layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixel-shuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies several areas that need clarification or improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about specific aspects of the paper, including the benefits of output-side layers, the clarity of Figure 4, the details of the Pixel-shuffle operation, and the dimensionality of upsampling in Figure 2. However, it does not explicitly mention which sections or parts of the paper these issues relate to, making it difficult for the authors to pinpoint the exact areas needing attention. While the comment specifies the nature of the issues, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, including the benefits of output-side layers, the clarity of Figure 4, the details of the Pixel-shuffle operation, and the dimensionality of upsampling in Figure 2. However, it does not provide any specific evidence, reasoning, or references to support these claims. The questions are open-ended and lack detailed explanations or justifications, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions and concerns about the paper, including the benefits of output-side layers, the clarity of Figure 4, the details of the Pixel-shuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies areas that need clarification or improvement, it lacks specific guidance on how the authors should address these issues. The feedback is somewhat helpful as it points out areas for improvement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also asks whether alternating between generating negative chips and training the network could potentially improve performance. While the comment poses a question that could guide the authors to consider certain aspects of their methodology, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also asks whether alternating between generating negative chips and training the network could help improve performance. However, the comment does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification or further discussion. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the fixed nature of negative chips and whether they will be updated during the training process. It also asks whether alternating between generating negative chips and training the network could improve performance. However, the comment does not provide any evidence, reasoning, or references to support these claims or questions. The authors are left to interpret the questions as potential areas for further exploration or improvement, but without any guidance or justification, the claims remain speculative. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fixed nature of negative chips after being generated from the lightweight RPN and whether they will be updated during the training process. It also inquires whether alternating between generating negative chips and training the network could potentially improve performance. While the comment identifies a potential area for clarification or further exploration, it does not provide specific suggestions or guidance on how the authors might address these questions or incorporate them into their work. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide explicit guidance on how to conduct this evaluation or what specific aspects of the approach should be considered. The action is implicit, as the authors need to infer that they should perform this evaluation, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion to evaluate the approach on new and old patients, the absence of grounding information makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would impact the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. This feedback highlights a potential area for further analysis and could guide the authors in refining their methodology or experimental design. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of the approach should be considered. While it identifies a relevant area for improvement, the lack of detailed suggestions or examples limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the experimental methodology, specifically questioning whether the 300W-LP dataset is used in all experiments or just some. It highlights a potential unfair advantage for the proposed method if the dataset is used in all experiments. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the use of the 300W-LP dataset in their experiments. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the concern about the experimental methodology is raised, specifically mentioning the use of 300W-LP. It is also specific because it clearly identifies the issue: the discrepancy in the use of the 300W-LP dataset between the proposed method and the baselines, questioning whether it is used in all experiments or just some. This allows the authors to understand exactly what part of the paper needs clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the experimental methodology, specifically regarding the use of the 300W-LP dataset. It claims that the same procedure is used as for baselines, but most baselines do not use this dataset. The comment questions whether 300W-LP is used in all experiments or just some, suggesting a potential unfair advantage for the proposed method. However, the comment lacks specific examples or references to support the claim about the baselines not using the dataset. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a basis for questioning the methodology but does not fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the experimental methodology, specifically questioning the use of the 300W-LP dataset. It highlights a potential unfair advantage for the proposed method if the dataset is used in all experiments, which is a significant concern. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what changes could be made to ensure a fair comparison. While it points out a potential problem, it does not provide actionable steps or specific advice on how to resolve it, making it somewhat helpful. The feedback is valuable but could be more impactful with additional guidance on how to improve the experimental design or methodology.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the algorithm need to be revised. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not specify which part of the paper these techniques are discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its critique of the novelty of the techniques but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, the comment lacks specific evidence or references to support this claim. Without detailed examples or citations, the authors may find it challenging to understand the basis of the critique or how to address it. The comment is somewhat verifiable as it provides a general observation but lacks detailed justification or examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of some techniques used in the algorithm, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" While it points out a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or population-weighted average, and notes that disease incident data are often available in count or rate per the number of residents. While the comment identifies a potential inconsistency in the formulation, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1)\" and refers to specific works, [Law et al., NeurIPS'18] and [4], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support $v$, while the data might be aggregated by other procedures, such as simple summation or population-weighted average. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the formulation introduced by the authors assumes that observations are obtained by averaging over the support $v$, but it suggests that the data might be aggregated by other procedures, such as simple summation or population-weighted average. The reviewer provides examples of how disease incident data are often available in count or rate per the number of residents, which supports the claim. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or population-weighted average, and notes that disease incident data are often available in count or rate per the number of residents. This feedback highlights a potential gap in the paper's methodology and suggests that the authors should consider alternative aggregation methods or provide a more detailed explanation of the data aggregation process. While the comment is somewhat helpful as it identifies a potential issue and suggests an area for improvement, it could be more helpful if it provided specific guidance on how to address the issue or alternative methods to consider. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. While the comment implies that the authors should conduct a more detailed analysis, it does not explicitly instruct them to do so or provide specific guidance on how to analyze the training dynamics. The action is implicit and somewhat vague, as the authors need to infer that they should perform a more thorough analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute. It implies that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its suggestion to provide an analysis, but the lack of grounding makes it difficult for the authors to know exactly where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute, and suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper: the lack of in-depth analysis regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to strengthen the paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work. However, the comment could be more helpful if it provided some guidance on how to conduct this analysis or suggested specific areas of investigation. Despite this, the comment is mostly helpful as it highlights a critical aspect of the paper that needs attention, providing the authors with a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the lack of mathematical definition for architectural details, specifically mentioning multi-head attention. It questions the use of split arrows in Figure 2 and asks for clarification on whether the same vectors are used for keys and values. While the comment explicitly suggests that a formal definition would help readers understand the architecture, it does not provide specific guidance on how to implement this suggestion, such as suggesting a particular notation or explanation. The action is clear but somewhat vague in terms of implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses architectural details, specifically mentioning multi-head attention and questioning the use of split arrows in Figure 2. It also asks for clarification on whether the same vectors are used for keys and values. However, the comment does not explicitly mention which part of the paper these details are discussed, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the mathematical definition of multi-head attention and the clarification of the split arrow in Figure 2. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the lack of mathematical definition for architectural details, specifically multi-head attention, and seeks clarification on the use of split arrows in Figure 2. It also asks for clarification on whether the same vectors are used for keys and values. While the comment identifies areas that require clarification and suggests a formal definition, it does not provide specific examples or references to support these claims. The reasoning is somewhat logical, but the lack of detailed examples or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas where the paper could be improved, particularly in the lack of mathematical definitions for architectural details like multi-head attention. It also raises questions about the clarity of Figure 2, specifically the use of split arrows and the vectors used for keys and values. The comment provides actionable suggestions for improvement, such as adding a formal definition of multi-head attention and clarifying the elements in Figure 2. However, the feedback could be more comprehensive by offering specific examples or detailed explanations of how to address these issues. Overall, the comment is mostly helpful as it highlights important areas for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that each individual's data is independently and identically distributed (iid) drawn from the same distribution. The reviewer questions the validity of this assumption, particularly in the context of the \\sqrt{m} argument in the beginning of Section 5.1 and its application in proving Theorem 6 to Theorem 7. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary in the draft. The authors are left without guidance on how to resolve this concern or improve the paper. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that each individual's data is iid drawn from the same distribution, questioning its validity in the context of the \\sqrt{m} argument in Section 5.1 and its application in proving Theorem 6 to Theorem 7. However, the comment does not specify which part of the paper this issue is discussed or how it relates to the overall content. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue with the iid assumption, but it lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that each individual's data is independently and identically distributed (iid) drawn from the same distribution. The reviewer questions the validity of this assumption, particularly in the context of the \\(\\sqrt{m}\\) argument in the beginning of Section 5.1 and its application in proving Theorem 6 to Theorem 7. The comment suggests that this assumption is unjustifiable because in practice, each user's preferred set of \"emojis\" are very different. However, the comment does not provide specific examples or references to support the claim that the iid assumption is problematic or how it affects the validity of the results. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the assumption that each individual's data is independently and identically distributed (iid) drawn from the same distribution. It questions the validity of this assumption, particularly in the context of the \\(\\sqrt{m}\\) argument in the beginning of Section 5.1 and its application in proving Theorem 6 to Theorem 7. The reviewer provides a logical argument, suggesting that this assumption is unjustifiable because in practice, each user's preferred set of \"emojis\" are very different. However, the comment does not offer any suggestions or guidance on how to address this issue or what changes might be necessary to improve the paper. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful as it points out an area for improvement but does not provide a clear path forward for the authors to address the concern.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider making the policy non-fixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement this suggestion, such as which specific aspects of the policy to modify or which reinforcement learning algorithms to compare against. The action is somewhat vague, as it leaves the authors to infer the exact steps needed to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider making the policy non-fixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment applies. While the comment is specific in its suggestion, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider making the policy non-fixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, the comment lacks specific details or references to support this suggestion, making it difficult for the authors to understand the basis of the claim or how to implement it. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on a logical extension of the current work but lacks concrete guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should consider making the policy non-fixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. This feedback provides a clear direction for improving the paper by expanding the scope of the tasks and enhancing the comparison with existing methods. However, the comment lacks specific details or suggestions on how to implement this change, such as which aspects of the policy to modify or which reinforcement learning algorithms to compare against. While it offers a valuable insight, the lack of actionable guidance limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the comprehensiveness of the experiments, noting that the analyses of the method itself and the experimental outcomes are not sufficiently detailed. It also questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific aspects of the analysis need to be expanded. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comprehensiveness of the experiments, specifically noting that the analyses of the method itself and the experimental outcomes are not comprehensive enough. It also questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issue of comprehensiveness, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analyses of the method itself and the experimental outcomes are not comprehensive enough, and that the performance improvement attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level is questionable. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the comprehensiveness of the experiments, noting that the analyses of the method itself and the experimental outcomes are not detailed enough. It also questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. This feedback is somewhat helpful as it highlights a critical area for improvement, prompting the authors to expand their analysis and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it offered specific suggestions or guidance on how to enhance the analysis. Overall, the comment provides a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the paper, noting that its focus on explaining multi-task models restricts its applicability. However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or improve the applicability of their work. The comment lacks concrete guidance on what changes could be made to broaden the paper's scope or relevance. As a result, the authors are left without a clear understanding of how to proceed to enhance the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs improvement. It is also not specific because it does not detail what aspects of the paper are limited in terms of applicability. Without specific guidance or references, the authors cannot effectively address the feedback. Therefore, this comment is rated as 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper \"mainly focuses on explaining multi-task models, which somehow limits the applicability.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or context to allow the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable, and the comment does not offer actionable guidance for improvement. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the paper, noting that its focus on explaining multi-task models restricts its applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance the paper's applicability. Without actionable feedback or detailed suggestions, the authors are left without a clear understanding of how to improve their work. Therefore, the comment is barely helpful, as it points out a weakness but does not provide substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the literature review should include several papers that seem relevant, specifically mentioning [1] and [2]. It also notes that VR-MARINA and DASHA-MVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the literature review should include several papers that seem relevant, specifically mentioning [1] and [2]. It also notes that VR-MARINA and DASHA-MVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not specify which section of the paper the literature review is located, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the inclusion of relevant papers and the comparison with QSGD. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VR-MARINA and DASHA-MVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issue. The absence of references or detailed explanations weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the literature review, noting that it may be overlooking several relevant papers. It provides specific examples, such as [1] and [2], which seem to satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks detailed guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. While it points out a potential gap in the literature review, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in following the presentation of the paper but does not provide any specific guidance or suggestions on how the authors might improve the clarity or organization of their work. Without explicit instructions or concrete advice, the authors are left without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the presentation of the paper but does not specify which part of the paper is hard to follow. It lacks grounding as the authors cannot confidently determine which section or aspect of the paper is being referred to. Additionally, the comment does not provide specific details about what makes the presentation hard to follow, such as unclear explanations, confusing terminology, or lack of structure. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses difficulty in following the presentation of the paper, but it does not provide any specific claims, opinions, or suggestions for improvement. It lacks detailed reasoning, examples, or references to support the claim. As a result, the comment is classified as \"No\" because it does not contain a claim that requires verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses difficulty in following the presentation of the paper, which is a valid concern for authors. However, it lacks specificity and actionable advice on how the authors might improve the clarity or organization of their work. Without detailed suggestions or guidance, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not provide explicit instructions or guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete details, leaving the authors uncertain about how to respond or incorporate the suggestions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestions but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. This feedback is somewhat helpful as it identifies an area where the authors could provide additional insights or evidence to strengthen their claims. However, the comment lacks specificity and does not offer detailed guidance on how the authors might address these questions or what additional experiments or analyses could be conducted. The feedback is incomplete and could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the level of detail provided about the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the time-dependent LGSSM parameters gamma. While the comment implies that the authors should elaborate on these aspects, it does not explicitly instruct them to add more details or clarify the computation requirements. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the computation requirements of the models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a more detailed presentation of the compared models, specifically DMM, DVBF, and KVAE. It also references Table 1, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the computation requirements of the three methods compared in Table 1. This provides the authors with a clear understanding of what additional information is needed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the level of detail provided regarding the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the time-dependent LGSSM parameters gamma. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that the current presentation lacks detail. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer's concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by questioning the level of detail provided about the compared models, particularly DMM, DVBF, and KVAE. It highlights the need for more information on the computation requirements of these models, specifically mentioning the time-dependent LGSSM parameters gamma. This feedback is somewhat helpful as it directs the authors to consider adding more detail to their presentation of the models and their computational aspects. However, the comment could be more helpful if it provided specific suggestions or examples of how to enhance the presentation of these models. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to perform these experiments or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their experiments to include these models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. However, it does not specify which part of the paper these experiments are intended to address, making it weakly grounded. The comment is specific in its suggestion to include more experiments, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas where these experiments should be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. However, the comment lacks specific reasoning or examples to support why these additional experiments are necessary or how they would enhance the paper. Without detailed justification or references, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis for the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. This feedback is somewhat helpful as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on how to conduct these additional experiments or what specific aspects of the models should be explored. Without detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it does not describe the hyperparameters used by each defense or how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate the amount of clean data required to remove the attack. This feedback provides a clear and explicit action for the authors to take, as they need to include details about the hyperparameters used and their derivation. The comment is also concrete, as it specifies exactly what information is missing and how it should be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of description regarding hyperparameters used by each defense and how those hyperparameters are derived. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not describe the hyperparameters used by each defense or how they are derived. It suggests that a maximally charitable evaluation would optimize hyperparameters against the attack and demonstrate the amount of clean data required to remove the attack. However, the comment lacks specific examples or references to support the claim that the paper does not provide this information. Without detailed examples or references, the authors may find it challenging to understand the exact nature of the missing information. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of information regarding the hyperparameters used by each defense and how they are derived. It suggests that a more comprehensive evaluation would involve optimizing these hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it included examples of how to optimize hyperparameters or suggested specific techniques for deriving them. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear path for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the practical implications of the theoretical results, suggesting that the paper could benefit from providing more take-away points for practitioners. It also notes that the main take-away point, which is to query a cluster proportionally to the square root of its size, is unclear whether it is a novel finding in the paper. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to the draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the practical implications of the theoretical results, suggesting that the paper could benefit from providing more take-away points for practitioners. However, it does not specify which part of the paper discusses the theoretical results or where the take-away points are mentioned. This makes it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the issue of practical implications, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper would benefit from providing more take-away points for practitioners. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for more practical takeaways, but the lack of detailed reasoning or examples weakens the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out that the theoretical results lack immediate practical implications. It suggests that the paper would benefit from providing more take-away points for practitioners, which is a valuable insight for improving the paper's relevance and impact. However, the comment could be more helpful if it offered specific guidance on how to develop these take-away points or suggestions for additional experiments or analyses that could enhance the practical relevance of the findings. While the comment provides a clear direction for improvement, it lacks depth and specificity, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of introducing separators in section 4, asking for clarification on their purpose beyond T/I/O. While it prompts the authors to explain the role of separators, it does not provide explicit guidance on how to address this issue or what specific changes might be needed. The action is implicit, as the authors need to infer that they should clarify the purpose of separators. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of introducing separators and asks for clarification on their purpose beyond T/I/O, providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of introducing separators in section 4, specifically asking for clarification on their purpose beyond T/I/O. While it does not contain a subjective claim or opinion, it prompts the authors to consider the rationale behind the introduction of separators. However, it lacks specific examples or detailed reasoning to fully substantiate the question, making it somewhat verifiable. The comment is mostly verifiable as it provides a clear direction for the authors to address the issue, but it could be more robust with additional examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a question about the necessity of introducing separators in section 4, specifically asking for clarification on their purpose beyond T/I/O. This feedback is somewhat helpful as it prompts the authors to consider the rationale behind the introduction of separators and to provide additional context or justification for their inclusion. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the issue, which limits its overall impact. Therefore, it aligns with a score of 3, as it provides some insight but could be more comprehensive and actionable.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide explicit guidance on which alternative strategies to explore or how to implement them. The action is implicit, as the authors need to infer that they should consider other pooling methods and potentially explore them. While the comment is somewhat actionable, it lacks concrete details on how to proceed with the exploration or implementation of alternative pooling strategies. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L235), allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the choice of mean pooling and suggesting alternative strategies, such as other pooling methods. This provides clear guidance on what needs to be considered or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide any specific reasoning, examples, or references to support why mean pooling is chosen or why other strategies might be better. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. This feedback is somewhat helpful as it prompts the authors to consider alternative approaches, which could potentially improve the robustness or effectiveness of their method. However, the comment lacks depth and does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how to implement them. As a result, while it offers a starting point for improvement, it does not fully empower the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This provides a clear and explicit action for the authors to take, as they know exactly what additional information to include in their table. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete improvement by comparing the real search cost in terms of GPU days, which provides clear guidance on what needs to be added to the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This is a specific and actionable suggestion that provides a clear direction for improvement. However, the comment does not offer any reasoning or justification for why this comparison is important or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is somewhat verifiable, as it provides a specific action but lacks detailed reasoning or references to support its importance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This feedback is actionable and directly addresses a potential area for enhancing the clarity and comprehensiveness of the paper. By offering a concrete suggestion, the comment empowers the authors to make a meaningful improvement to their draft, making it mostly helpful. However, it could be more helpful if it included additional context or reasoning for why this comparison is important. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to include them in the draft. The action is implicit, as the authors can infer that they need to add this information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in that it identifies a missing detail that needs clarification, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a factual question that requires the authors to provide specific details about their training process. However, the comment does not offer any additional context, reasoning, or references to support the need for this information. As a result, the claim is somewhat verifiable, as it is based on a logical request for clarification but lacks sufficient justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about the training details of the VQGAN, asking whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This question highlights a potential gap in the authors' explanation of their methodology, as it is crucial to provide these details for reproducibility and understanding. However, the comment does not offer any suggestions or guidance on how the authors might address this issue, such as providing additional information or clarifying the training process. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a specific area that needs clarification but does not provide comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work should include and compare to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment does not provide explicit guidance on how to incorporate these comparisons or discussions into the paper. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), which are mentioned by name. This provides clear grounding as the authors can accurately identify the sections or parts of the paper where these works are discussed. The comment also recommends a discussion on how the work differs from other chatbox research works, which is specific and provides guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment lacks specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the paper. The absence of detailed justification or references makes it difficult for the authors to understand the basis for the claim, leading to a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies the need to include and compare the current work with specific related studies, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also suggests a discussion on how the work differs from other chatbox research works. However, the comment lacks specific guidance on how to incorporate these comparisons or discussions into the paper, leaving the authors with a general idea but no detailed instructions. This makes the comment somewhat helpful, as it provides a direction for improvement but could be more comprehensive with additional details or examples. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, particularly in the MSVD task, where performance shows minor improvements. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the methods. It lacks concrete guidance on what changes could be made to enhance the generality of the methods or to achieve more significant improvements in performance. Without specific actions or suggestions, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by pointing out that these methods are not generic on some cross-model retrieval tasks, particularly noting the performance in MSVD (Table 3) showing minor improvements. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, specifically noting that the performance in MSVD (Table 3) shows minor improvements. However, the comment lacks specific evidence or references to support this claim. Without detailed analysis or examples, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, particularly in the MSVD task, where performance shows minor improvements. While the comment highlights a potential area for improvement, it does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the generality of their methods. The feedback is somewhat helpful as it points out a limitation, but it lacks depth and specificity, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the experimental strengths of the proposed approach, suggesting that running the algorithm on 40 different networks from the training phase might be unnecessary. It proposes an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their experimental setup. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the experimental setup and suggesting an alternative approach, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the proposed approach is unnecessary or that the suggested alternative is more effective. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or improve their experimental setup. While it identifies a potential issue, it lacks actionable advice or detailed reasoning to help the authors enhance their work. Therefore, the comment is barely helpful, as it offers a point of consideration but does not provide substantial feedback for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might establish this relationship, leaving them without a clear path forward. As a result, the comment is unactionable, as it does not offer any concrete steps or suggestions for improvement. Therefore, it aligns with the lowest score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact issue. It mentions \"incomplete study\" and \"the relationship between the top selected patches and the disease is not yet established,\" but without specific references to sections, tables, or figures, the authors cannot pinpoint the exact area of concern. The comment is also not specific because it does not detail what aspects of the study are incomplete or how the relationship between patches and disease should be established. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment lacks specific details or references to support this claim. It does not provide examples of how the relationship is missing or why it is important. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. This feedback is valuable as it highlights a critical gap in the research, suggesting that the authors need to provide more evidence or analysis to support their claims. However, the comment lacks specific guidance on how the authors might address this issue or what additional data or analysis could be included to establish the relationship. While it points out a crucial area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct a typographical error in the phrase \"for 'in-between' uncertainty,\" specifically mentioning that the first quotation mark should be a forward mark rather than a backward mark. This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be corrected and how to implement the suggestion. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"for 'in-between' uncertainty\" and provides a specific instruction regarding the typographical error in the quotation mark. It clearly specifies what needs to be addressed, making it fully grounded. The comment is also specific as it provides a clear and actionable suggestion for correcting the typographical error. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding a typographical error in the phrase \"for 'in-between' uncertainty.\" It specifies that the first quotation mark should be a forward mark rather than a backward mark. While the comment is accurate, it does not provide any additional reasoning, references, or context to support the claim. However, it is clear and specific, making it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion for correcting a typographical error in the phrase \"for 'in-between' uncertainty.\" It clearly identifies the issue, which is a minor but important detail that affects the clarity and accuracy of the paper. By specifying the correct typographical mark, the comment guides the authors on how to improve the draft. This level of detail and specificity is valuable for the authors to address the feedback effectively. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme is mainly about FedSP. However, it does not provide explicit guidance on what needs to be improved or how the authors should address this issue. The comment implies that the authors should consider revising their draft to better reflect the performance of FedSP, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the performance of FedSP is not the best in these tables on some datasets. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or data, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the performance of FedSP in Table 1 and Table 2 on some datasets, noting that it is not the best. This feedback is clear and actionable, as it highlights a potential area for improvement in the draft. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it offers a starting point for improvement, the comment could be more helpful if it included recommendations or suggestions for enhancing the performance of FedSP or discussing the reasons for its suboptimal performance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the clarity and specificity of the paper. It asks the authors to clarify the meaning of \"Omega\" in line 178, to specify that OMD is a family of algorithms, and to provide more detail about the link function and the specific theorem in reference [32] related to the regret guarantee. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how to address these points. The authors are left with a general idea of what needs to be clarified but without specific steps on how to implement the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific questions and suggestions related to the content of the paper, particularly around line 178. It asks for clarification on the meaning of \"Omega,\" the nature of OMD as a family of algorithms, the link function, and the specific theorem in reference [32] related to the regret guarantee. However, the comment does not explicitly mention the section or part of the paper where these questions are relevant, making it weakly grounded. The questions are specific and provide clear guidance on what needs to be addressed, making the comment fully specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and suggestions regarding the clarity and specificity of the paper, particularly around line 178. It asks the authors to clarify the meaning of \"Omega,\" specify that OMD is a family of algorithms, and provide more detail about the link function and the specific theorem in reference [32] related to the regret guarantee. While the questions are logical and seek clarification, they do not provide specific examples or references to support the claims, making the comment somewhat verifiable. The authors would need to infer the need for clarification and provide additional context to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several specific questions and suggestions that could help the authors improve their draft. It asks for clarification on the meaning of 'Omega' in line 178, suggests that OMD is a family of algorithms, and requests more detail about the link function and the specific theorem in reference [32] related to the regret guarantee. While the comment is clear and identifies areas for improvement, it lacks depth and could be more helpful if it provided additional guidance or examples. Therefore, the comment is somewhat helpful, as it offers actionable feedback but could be expanded to be more comprehensive.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. While it points out a potential issue with the approach, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors would need to infer that they should consider incorporating a Markovian state into their models or provide a rationale for why this approach was taken. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the models are learned directly from pixels without a Markovian state,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular aspect of the models that needs consideration, suggesting the inclusion of a Markovian state. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the models being learned directly from pixels without a Markovian state. This is a clear and actionable point that highlights a potential issue with the approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. While it points out a potential area for improvement, it does not offer detailed advice or examples, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before. It suggests that the authors should point out some references to support this claim. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so or specify which parts of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they should add references to support the claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the Hamming distance over entire parts of the sequence, questioning its common practice and contrasting it with node-wise Hamming loss. This provides a clear direction for the authors to address the concern. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before. It suggests that the authors should point out some references to support this claim. While the comment raises a valid concern about the novelty of the approach, it lacks specific references or detailed reasoning to substantiate the claim. The authors would need to conduct further research to find relevant literature to support the claim, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific concern regarding the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF. It questions the novelty of this approach, noting that the authors have not seen it before and are only aware of works reporting node-wise Hamming loss. The comment suggests that the authors should point out some references to support this claim, which provides a clear direction for the authors to address the concern. However, the comment could be more helpful if it provided specific references or examples of works that use node-wise Hamming loss, making it easier for the authors to understand and address the issue. Overall, the comment is somewhat helpful as it highlights an important point for clarification and provides a basis for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the name of the \"Evaluation\" element can be changed to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This comment provides explicit guidance on how to improve the paper by changing the name and adjusting the presentation of the evaluation section. The actions are concrete and detailed, allowing the authors to understand exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it provides clear guidance on how to improve the presentation of the evaluation section by suggesting a more precise name and adjusting the content. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the name of the \"Evaluation\" element can be changed to \"Metrics\" to avoid ambiguity, as \"evaluation\" has a broader meaning. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This feedback is mostly verifiable as it provides a clear rationale for the suggestion, explaining why changing the name would improve clarity and consistency. However, it could be more robust if it included specific examples of how the metrics are currently presented or why they are well-known. Overall, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the naming of the \"Evaluation\" element, suggesting that it could be changed to \"Metrics\" to avoid ambiguity. It also recommends removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are well-known and standard practice. This feedback is clear and actionable, offering concrete suggestions for improving the clarity and presentation of the paper. By addressing the potential ambiguity in the term \"evaluation\" and suggesting a more precise and consistent approach to presenting metrics, the comment empowers the authors to enhance the quality and readability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific guidance or suggestions on how the authors might explore the dataset further. The comment lacks explicit instructions or concrete details on what aspects of the dataset should be investigated or how it could be integrated into the paper. As a result, the authors are left without a clear understanding of how to address this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should occur, leaving the authors uncertain about the exact location or scope of the suggestion. Additionally, the comment lacks specificity in terms of what aspects of the dataset should be explored or how it could be integrated into the paper. Without these details, the authors cannot confidently address the feedback. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why this suggestion is important or how it could be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specific guidance or suggestions on how the authors might explore the dataset further or what aspects of the dataset should be investigated. The comment is vague and does not provide actionable feedback, leaving the authors with limited insight into how to address the feedback. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement, noting that the improvement is evident but difficult to characterize as remarkable. It implies that the authors should consider using more precise language to describe the results. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specific examples of more objective terms or how to revise the text to achieve this. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section number [218], allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of more objective terms instead of \"remarkable\" to describe the accuracy improvement. This provides clear guidance on how to revise the text, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement, noting that the improvement is evident but difficult to characterize as remarkable. This claim is somewhat verifiable as it provides a specific suggestion for improvement but lacks detailed reasoning or examples to fully support the claim. The authors would need to infer the reasoning behind the suggestion, which could be improved with additional explanation or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the paper, suggesting that the term \"remarkable\" should be replaced with more objective terms to describe the accuracy improvement. It also points out that the improvement is evident but difficult to characterize as remarkable, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific examples of more objective terms or guidance on how to revise the text to achieve this. Despite this, the feedback is mostly helpful as it directs the authors to improve the clarity and objectivity of their language, which is a valuable piece of advice. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using longer video sequences (e.g., by running the LSTM over many time steps) to address the issue of inconsistent motion, changing color, or object disappearing over time in the synthesized results for UCF-101. It also acknowledges that the paper has an interesting idea and extensive experiments, but the results are not perfect and seem to handle subtle motion. The comment provides a clear and explicit action for the authors to take, which is to explore the use of longer video sequences. This action is concrete, as it specifies the exact change to be made, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"short video sequences\" and provides examples, such as \"e.g., 16 frames,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of longer video sequences to improve the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has an interesting idea and extensive experiments, but the results are not perfect and seem to handle subtle motion. It suggests that the authors should consider using longer video sequences to address issues such as inconsistent motion, changing color, or object disappearing over time. However, the comment lacks specific examples or references to support the claim about the results not being perfect or handling subtle motion. While the suggestion to use longer video sequences is logical, the overall claim is not fully verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on the paper's content, particularly regarding the use of short video sequences and the results presented for the UCF-101 dataset. It highlights issues such as inconsistent motion, changing color, and object disappearing over time, suggesting that the authors could improve their results by using longer video sequences. The comment also acknowledges the paper's interesting idea and extensive experiments, but points out that the results are not perfect and seem to handle subtle motion. This feedback is clear and actionable, offering a concrete suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to implement the suggestion or explored other potential areas for enhancement. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and provides a clear direction for the authors to follow.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that it is not yet possible to realize efficiency gains on GPU, which is a common observation in the field of pruning. However, it does not provide any specific guidance or suggestions for how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a general statement about the difficulty of realizing efficiency gains on GPU, which is a common observation in the field of pruning. However, it does not provide specific guidance or suggestions for how the authors might address this issue or improve their work. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is not yet possible to realize efficiency gains on GPU, as with most work on pruning. However, the comment lacks specific evidence or references to support this claim. It does not provide any logical reasoning or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that it is not yet possible to realize efficiency gains on GPU, which is a common observation in the field of pruning. However, it does not provide any specific suggestions or insights on how the authors might address this issue or improve their work. The comment lacks actionable guidance and does not offer any constructive feedback that could help the authors enhance their draft. Therefore, it is barely helpful, as it identifies a limitation but does not provide a clear path for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the numerical evaluation: the use of synthetic data and the fairness of the comparison with [5]. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their evaluation or ensure a fair comparison. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the numerical evaluation of the paper, specifically mentioning the use of synthetic data and the comparison with [5]. However, it does not specify which part of the paper discusses the numerical evaluation, making it weakly grounded. The comment is specific in identifying the issues with the evaluation, such as the use of synthetic data and the fairness of the comparison with [5]. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data, and the comparison with [5] is not fair due to the difference in problem complexity. However, the comment does not provide specific examples or detailed reasoning to support these claims. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key issues with the numerical evaluation of the paper. First, it points out that the method is only evaluated on synthetic data, which may not accurately reflect real-world scenarios. Second, it notes that the comparison with [5] is not entirely fair because [5] is designed for a more complex problem, specifically lacking knowledge of camera pose parameters. These observations are clear and highlight potential limitations in the evaluation, but they do not provide specific suggestions or guidance on how to address these issues. While the feedback is somewhat helpful in identifying areas for improvement, it lacks actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment implies that the authors should consider the relevance of this experiment, it does not provide explicit guidance on how to address this question or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion about the experiment's relevance, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. However, the comment lacks specific evidence or reasoning to support the claim that the experiment is unnecessary or how it might strengthen the paper. The authors are left to infer the relevance of the experiment, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments could be conducted to strengthen their claims. The feedback is somewhat helpful as it points out a potential area for further exploration, but it does not provide detailed actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the cost of insurance after the method is applied, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what changes could be made to the paper to address this concern. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the cost of insurance after the method is applied, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what changes might be needed in the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the cost of insurance after the method is applied, but it does not contain any claims, opinions, or suggestions that require verification. It is a factual question that does not challenge the authors to make any judgments or provide evidence. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the cost of insurance after the method is applied, which could be relevant for understanding the practical implications of the proposed approach. However, the comment does not provide any suggestions or insights on how to address this question or what changes might be needed in the paper to clarify this aspect. Without actionable guidance or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not explicitly instruct the authors on how to clarify this difference or what specific aspects of the paper need to be addressed. While the suggestion is clear, the lack of detailed guidance on implementation makes it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not specify which part of the paper discusses meta solvers or centralized RL, making it difficult for the authors to pinpoint the exact section that needs clarification. While the suggestion is specific about the content to be clarified, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights, and provides a specific example by citing Foester et al. This claim is somewhat verifiable as it offers a suggestion for improvement and includes a reference to support the claim. However, the comment lacks detailed reasoning or explanation of why this clarification is necessary or how it would benefit the paper. The authors would need to infer the importance of this clarification, which could be improved with more context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity in their paper. However, the comment could be more helpful if it offered additional guidance on how to clarify this difference or what specific aspects of the paper need to be addressed. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for greater depth and actionable suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper's categorization method, noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the practice of posting papers on arXiv earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their categorization method. The action is implicit, as the authors would need to infer that they should consider the arXiv publication dates when categorizing the papers. The lack of concrete instructions or suggestions makes the action vague and difficult to implement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the categorization of papers based on publication years on the ACL anthology, noting that many papers are posted on arXiv earlier. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique, the lack of grounding makes it challenging for the authors to fully understand and address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's categorization method, which splits papers based on publication years on the ACL anthology, is inaccurate because many papers are posted on arXiv earlier. The reviewer provides an example, such as the BERT paper being available on arXiv before the ACL anthology publication. However, the comment lacks detailed reasoning or references to support the claim comprehensively. While the example provides some context, it does not fully substantiate the claim, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's categorization method, specifically noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the practice of posting papers on arXiv earlier. The reviewer provides an example, such as the BERT paper being available on arXiv before the ACL anthology publication, which highlights the inconsistency in the categorization. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their categorization method. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should consider the arXiv publication dates when categorizing the papers, but the comment does not provide detailed steps or examples to facilitate this improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the definition of M_T on page 3 could be clearer by providing examples. While the comment implies that the authors should consider adding examples to improve the understanding of M_T, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the definition of M_T, suggesting that the notation is not making it difficult to understand the concept and recommending the inclusion of examples to clarify it. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of M_T on page 3 could be clearer by providing examples. However, it does not offer any specific reasoning or evidence to support why this clarification is necessary or how it would improve the understanding of the concept. The comment lacks detailed justification or examples, making it difficult for the authors to fully grasp the need for the suggested improvement. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the definition of M_T on page 3, suggesting that the notation could be more easily understood with the inclusion of examples. This feedback is specific and actionable, as it provides a clear direction for improvement by recommending that the authors consider adding examples to enhance the understanding of the concept. However, the comment could be more helpful if it offered additional guidance on how to create these examples or suggested specific areas where examples would be most beneficial. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two distinct points regarding the relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. For the first point, the comment questions the rationale behind not using importance sampling and suggests that the authors should clarify why they chose to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q. This provides a clear and explicit action for the authors to take, as they need to explain their reasoning and potentially provide examples to support their choice. For the second point, the comment highlights a lack of clarity in the differences between QRS and RS, specifically questioning how the algorithm behaves differently for certain values of u. This is also an explicit action, as the authors need to clarify the distinction between these two methods. Both points are concrete and provide clear guidance on how the authors can improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses two distinct points regarding the relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. However, it does not specify which sections or parts of the paper these points relate to, making it weakly grounded. The comment is specific in detailing the issues with the relaxation of rejection sampling and the lack of clarity in the differences between QRS and RS. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions about the methodology and algorithm presented in the paper. The first question asks why the authors did not directly use importance sampling instead of relaxing rejection sampling with an arbitrary parameter \u03b2. The second question questions the differences between QRS and RS in Algorithm 1, specifically asking for a value of u where they behave differently. While the questions are clear and specific, they do not provide any supporting evidence or reasoning to justify the authors' choices or to address the reviewer's concerns. The lack of detailed explanation or references makes it difficult for the authors to address these questions effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two distinct points that could be helpful for the authors to address. First, it questions the rationale behind using an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q in the relaxation of rejection sampling. This raises a valid concern that could be addressed by providing a clear explanation of why the authors chose this approach and how it impacts the results. Second, the comment points out a lack of clarity in the differences between QRS and RS in Algorithm 1, specifically questioning how the algorithm behaves differently for certain values of u. This feedback is valuable as it highlights a potential area for improvement in the paper. However, the comment could be more helpful if it provided specific examples or guidance on how the authors could address these issues. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and detail in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks specific guidance on how to refine the performance or what aspects of the future work need improvement. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment is somewhat specific in that it suggests future refinement, but without detailed guidance on what aspects to focus on, it remains vague. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the observed performance enhancements are modest, suggesting room for further refinement in the future. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or detailed reasoning to substantiate the assertion that the enhancements are modest. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it lacks specific details or actionable feedback on how the authors might address this issue or what aspects of the future work could be improved. While it identifies a potential area for improvement, the comment does not provide concrete guidance or suggestions, making it somewhat helpful. The authors would need to infer additional steps to address the feedback, which limits the comment's impact. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230-234 and 234-235. It also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. These instructions are clear and direct, allowing the authors to know exactly what needs to be addressed. The comment is fully actionable as it provides specific guidance on where to add references and clarify terminology. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230-234 and 234-235,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed: providing references for two passages and clarifying the term \"MLP\" in Figure 2. This level of detail ensures that the authors understand exactly what revisions are required. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point contains claims that require specific references to support the statements about the encoder and decoder in sequence-to-sequence machine translation (MT) models and the application of this framework to summarization generation tasks. The comment also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. However, the comment lacks specific references or detailed reasoning to substantiate these claims, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on two areas of the paper, namely Section 3.2 and Figure 2. It requests references for two passages related to sequence-to-sequence machine translation (MT) models and the application of this framework to summarization generation tasks. Additionally, it points out that the term 'MLP' is not described in the paper, specifically in Figure 2. This feedback is clear and actionable, as it directs the authors to specific areas where they need to provide additional context or clarification. By addressing these points, the authors can improve the completeness and accuracy of their paper. Therefore, the comment is rated as highly helpful, as it offers detailed guidance on how to enhance the draft.\", 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experimental setup. The action is implicit, as the authors are left to infer that they need to investigate the reasons for the similar performance and potentially enhance their experiments. The lack of concrete steps or detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not specify which part of the paper these datasets are associated with, making it weakly grounded. The comment is specific in identifying the issue with the experimental results, but without explicit references to the datasets or sections, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it difficult to understand why the results are not convincing or how the performance similarity to IRM impacts the effectiveness of the proposed method. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern regarding the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their experimental setup. While it points out a potential weakness, it does not provide actionable steps or detailed insights to help the authors enhance their work. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not offer comprehensive guidance. The score of 3 aligns with this assessment.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long entity is known. However, it does not provide explicit instructions or suggestions on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should consider the question and provide a detailed explanation. The comment lacks concrete guidance on how to implement this suggestion, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the rationale behind detecting both entities, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. This is a question that requires the authors to clarify their reasoning and provide additional context or explanation. However, the comment does not offer any specific examples, references, or detailed reasoning to support the question. As a result, the claim is somewhat verifiable, as it lacks sufficient evidence or justification for the authors to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind detecting both entities in Figure 2 and asks for a comparison with a scenario where only the long entity is known. This question prompts the authors to clarify their reasoning and provide additional context, which could help them improve the clarity and depth of their explanation. However, the comment lacks specific guidance on how the authors should address this question or incorporate it into their draft. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of empirical validation in the paper and suggests that the authors would like to see experiments where the bounds are validated. However, it does not provide explicit instructions on how to conduct these experiments or what specific aspects of the bounds need validation. The action is implicit, as the authors can infer that they need to add empirical validation, but the lack of concrete guidance on how to do so makes the comment somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical validation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors would like to see experiments where the bounds are validated, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical validation and suggests that the authors would like to see experiments where the bounds are validated. However, the comment does not provide any specific examples, references, or reasoning to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper: the lack of empirical validation. It suggests that the authors would benefit from seeing experiments where the bounds are validated, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects of the bounds need validation. Despite this, the feedback is mostly helpful as it directs the authors towards a crucial improvement that would strengthen the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still considered sequential information. While the comment identifies a specific point of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the meaning of \"chunks\" in the context of the paper. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it directly questions the clarity of the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still considered sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still considered sequential information. This is a subjective question that requires the authors to provide their understanding of the term. While the comment is clear and specific, it does not provide any evidence or reasoning to support the claim, making it difficult for the authors to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks,\" asking for clarification on whether chunks are still considered sequential information. This feedback is clear and actionable, as it prompts the authors to revisit and clarify a particular aspect of their paper. By addressing this question, the authors can improve the clarity and precision of their writing, ensuring that their terminology is consistent and understandable. However, the comment could be more helpful if it provided additional context or suggested specific ways to clarify the concept. Overall, the comment is somewhat helpful, as it identifies a need for clarification but lacks depth in its guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output is indeed a masked version, Figure 1 might be misleading. The comment also proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not explicitly instruct the authors to address this discrepancy or provide specific guidance on how to correct it. While the action is somewhat inferred, it lacks concrete details on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output is a masked version, Figure 1 might be misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not specify which part of the paper contains the equation or figure, making it weakly grounded. It is specific in detailing the issue and suggesting improvements, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output is a masked version, Figure 1 might be misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment lacks specific examples or detailed reasoning to support the claim that the output patches are indeed masked versions of the input image. Without further elaboration or evidence, the claim remains somewhat verifiable, as it is based on an interpretation of the content rather than direct observation or logical deduction. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output is indeed a masked version, Figure 1 might be misleading. The comment also proposes that zooming on the region of interest using bilinear sampling could provide better results. While the comment highlights a potential issue and offers a suggestion for improvement, it lacks detailed guidance on how to address the discrepancy or implement the proposed solution. The feedback is somewhat helpful as it points out a specific area for clarification and improvement, but it could be more actionable with additional details. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. While the reviewer identifies a potential issue with the theorem, the comment does not provide explicit guidance on how to address this concern or what changes might be necessary. The action is implicit, as the authors would need to infer that they should investigate the assumption and potentially revise the theorem or its explanation. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about a specific aspect of Theorem 1, focusing on the assumption of a separate node with 0 neighbors. However, it does not explicitly mention which part of the paper this refers to, making it weakly grounded. The comment is specific in that it identifies a potential issue with the theorem's assumption, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the validity of Theorem 1, specifically regarding a node with 0 neighbors. The reviewer questions the assumption that this leads to an upper bound of 0, which is not necessarily true. However, the comment does not provide any evidence, reasoning, or references to support this claim or question. Without additional context or justification, the reviewer's concern remains unverified, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about a potential issue with Theorem 1, particularly concerning the assumption of a separate node with 0 neighbors. The reviewer questions the validity of the upper bound in this scenario, which is a critical point that needs clarification. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or revise the theorem. While it identifies a potential weakness, it does not provide detailed feedback or constructive advice, making it somewhat helpful. The authors would need to infer that they should investigate the assumption and potentially revise the theorem or its explanation, but the comment does not offer explicit steps or guidance to achieve this. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited technical novelty of the paper, suggesting that it is similar to previous works that focus on graph-based approaches, co-attention mechanisms, and architectures. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the paper could be improved to enhance its novelty. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to respond or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b) that the authors should compare with, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of limited technical novelty and the similarity of the idea, co-attention mechanism, and architecture to previous works. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has limited technical novelty, as it is similar to previous works that focus on graph-based approaches, co-attention mechanisms, and architectures. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed comparisons that would help the authors understand the extent of the similarity and how it impacts the novelty of their work. Without concrete evidence or examples, the claim is difficult to verify, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the limited technical novelty compared to previous works that focus on graph-based approaches, co-attention mechanisms, and architectures. While the comment highlights this concern, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks actionable advice or detailed suggestions, making it difficult for the authors to fully address the concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the discussion of training time reduction compared to parameter reduction. It notes that the discussion section does not address this point, suggesting that the authors should either revisit the discussion or remove the comment. However, the comment does not provide explicit guidance on how to revise the discussion or what specific aspects need to be addressed. The action is implicit, as the authors can infer that they need to revisit the discussion section to include the mentioned point. The action is somewhat vague, as it lacks detailed instructions on how to incorporate the information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that the discussion section does not revisit the point about training time reduction being less drastic than parameter reduction. This provides clear guidance on what part of the paper requires revision. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion section does not revisit the point about training time reduction being less drastic than parameter reduction. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify or address the issue effectively. The feedback is somewhat verifiable as it points out a potential oversight but does not provide detailed evidence or guidance on how to correct it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the discussion section of the paper, noting that the point about training time reduction being less drastic than parameter reduction is not revisited. This feedback is clear and actionable, as it directs the authors to a specific area that needs attention. However, it could be more helpful if it provided suggestions on how to address this issue or what aspects of the discussion could be expanded upon. Overall, the comment is mostly helpful as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address it or what changes might be necessary. The action is implicit, as the authors need to infer that they should explore the broader applicability of their work. However, the comment lacks concrete details on how to implement this exploration, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it lacks specific references or context. Additionally, it does not provide detailed guidance on how to address the question or what changes might be necessary. Therefore, this comment is not grounded and not specific, aligning with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the issue. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. This question prompts the authors to consider the broader context and potential applications of their work. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this question or what changes might be necessary. While it identifies an area for improvement, it does not offer actionable feedback that would empower the authors to enhance their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while it mentions the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment suggests that the paper should explore why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not offer specific guidance on how to address this issue or what kind of analysis or solutions could be proposed. The action is implicit, as the authors need to infer that they should provide a deeper analysis of the difficulty in detecting GPT-generated rumors. The action is vague because it lacks concrete details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the handling of rumors generated by GPT, specifically noting that the paper mentions the challenges of detecting such rumors but lacks further analysis or solutions. It questions why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in that it identifies a gap in the analysis and suggests a need for further exploration, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difficulty of detecting GPT-generated rumors compared to natural rumors, suggesting that the paper does not provide a clear analysis or explanation for this phenomenon. It implies that the experimental results might be misleading, as artificial rumors, being written by humans, should be about as difficult to detect as natural rumors. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the paper does not adequately address this issue. Without additional evidence or analysis, the authors may find it challenging to fully understand and address the concern raised. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that while it acknowledges the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions to address this issue. The comment questions why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. This raises a valid concern that the paper does not adequately explain or justify the experimental results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional analysis could be conducted to provide a more comprehensive understanding. While it highlights an important area for improvement, the feedback could be more helpful if it offered concrete suggestions or directions for further exploration. Therefore, the comment is somewhat helpful, as it identifies a meaningful gap but does not provide detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. While the comment identifies a potential issue with the technical contribution, it does not provide explicit guidance on how the authors should address this limitation or what specific aspects of the section need improvement. The action is implicit, as the authors would need to infer that they should consider a more formal and principled approach to enhance the technical contribution. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This claim is somewhat verifiable as it provides a specific example of a limitation in the technical contribution, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis for this claim, which could be improved by providing more context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical contribution of the paper, specifically pointing out that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This feedback is clear and actionable, as it highlights a specific area where the authors could improve the depth and rigor of their work. By emphasizing the need for a more formal and principled approach, the comment provides a clear direction for enhancing the paper. However, it could be more helpful if it suggested specific ways to address this limitation or provided examples of how to incorporate a more formal approach. Overall, the comment is mostly helpful, as it offers valuable feedback that the authors can use to improve their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the font size in Figure 6 is small, which could be a minor issue. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the font size or what specific changes are needed. Without actionable steps, the authors are left without a clear path to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the font size in Figure 6, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the font size in Figure 6 is small. While this is a factual observation, the comment does not provide any reasoning or justification for why this is an issue or how it affects the paper. Without additional context or explanation, the authors may find it difficult to understand the significance of this observation or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor issue with the font size in Figure 6, which could affect the readability of the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the figure. Without actionable advice or examples, the comment is somewhat helpful as it highlights a potential area for improvement, but it does not provide the authors with a clear path forward. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'}'"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a regret about the limited exploration of the probability mass function in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the case of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to incorporate different probability mass functions into their experiments. The suggestion is vague and lacks concrete details, making it difficult for the authors to understand how to implement the proposed improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MixBoost\" and \"probability mass function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is practically unexploited and suggests considering various distributions to add depth to the experimental setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a regret about the limited exploration of the probability mass function in the paper, specifically mentioning that it is practically unexploited. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the case of Boosted Decision Trees (BDT) of different depths. However, the comment lacks specific examples or references to support the claim that the quasi-uniform distribution is well-suited or why exploring other distributions would be beneficial. Without detailed reasoning or evidence, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by pointing out that the probability mass function is practically unexploited in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the case of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide specific guidance on how the authors might explore different probability mass functions or what specific experiments could be conducted to address this issue. While it offers a direction for improvement, the lack of detailed suggestions or examples makes it somewhat helpful. The authors would need to infer how to implement the suggested changes, which limits the comment's full impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the comparison. The comment lacks concrete guidance on how to improve the draft or what specific actions the authors should take. As a result, the comment is unactionable, as it does not provide the authors with any direction or steps to follow to improve their work.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not specify which part of the paper this comparison is made or which models are being compared. The lack of specific grounding makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. Additionally, the comment does not provide any guidance or suggestions on how to address the issue of fairness in the comparison. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the concern, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. This is a pertinent issue that could affect the validity of the comparisons made in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to ensure a fair comparison. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to conduct further analysis or seek additional feedback to fully address the concern. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include missing references, specifically mentioning a relevant work [a] that discusses supervised learning in QBF solving. It also provides a brief explanation of the relevance of this work, stating that it generalizes SMT. The comment is clear and direct, providing the authors with a specific action to take: include the suggested reference and discuss its connections to their work. This level of detail makes the comment highly actionable, as it clearly outlines what needs to be done and how to implement it. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"relevant references\" and provides a specific example of a work [a] that is relevant to the topic. It also instructs the authors to \"please discuss connections with [a],\" which clearly specifies what needs to be addressed. This provides the authors with a clear understanding of the part of the paper that requires attention and the specific action to be taken. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references below are relevant to the topic, especially [a], which discusses supervised learning in QBF solving. It provides a brief explanation of the relevance of this work, stating that it generalizes SMT. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the authors are given a direction to explore, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic. It provides a clear example of a relevant work [a] that discusses supervised learning in QBF solving, which generalizes SMT. The comment instructs the authors to include these references and discuss their connections to their work. This feedback is actionable and provides a concrete direction for the authors to enhance their draft by incorporating additional relevant literature. However, the comment could be more helpful if it offered specific guidance on how to integrate or discuss the suggested references. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the mono tonic relationship imposed between the degree of a single-task predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. However, the comment does not provide explicit guidance on how the authors should address this question or what specific aspects of the relationship need to be explored. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper by questioning the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that the ensemble engenders a subspace that explicitly encodes tradeoffs and results in a continuous parameterization of the Pareto Front. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be explained. Therefore, this comment is labeled as fully grounded and specific, corresponding to category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss, suggesting that it might be replaced by other relationships. The comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss, suggesting that it might be replaced by other relationships. It also recommends explaining this point, which could provide valuable insights into the continuous parameterization of the Pareto Front. However, the comment lacks specific guidance on how the authors should explore or address this issue, making it somewhat helpful. The feedback is clear but could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the draft to include such a comparison. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison is intended for or how it relates to the content of the draft. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the comparison or what aspects of the paper need to be revised. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the comparison of computation cost or running time, but it does not provide any specific claims, opinions, or suggestions. It is a factual question that does not require verification or justification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect for evaluating the efficiency and practicality of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or incorporate such a comparison into their draft. Without specific advice or suggestions, the authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the paper's goal in the introduction and suggests that the examples provided do not effectively convey the need for inter-process communication. It also offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms like Hogwild. While the comment provides a clear action\u2014improving the clarity of the introduction and suggesting specific areas for focus\u2014it does not offer detailed guidance on how to achieve this. The suggestion is concrete but lacks specific steps or examples, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the introduction by suggesting that the examples chosen do not effectively convey the need for inter-process communication. The authors are given specific advice on focusing on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms like Hogwild. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the lack of clarity in the paper's goal in the introduction and suggests that the examples provided do not effectively convey the need for inter-process communication. The reviewer offers specific examples, such as sampling-based Bayesian methods, to illustrate this point. However, the comment lacks detailed reasoning or references to support the claim that the examples are not convincing. While the suggestion for improvement is clear, the absence of supporting evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment is mostly helpful as it identifies a lack of clarity in the paper's goal in the introduction and suggests specific areas for improvement. The reviewer provides examples, such as sampling-based Bayesian methods, to illustrate the issue and offers a constructive suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms like Hogwild. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, it could be more helpful if it included additional guidance on how to effectively convey the paper's goal or more detailed examples of the suggested problems. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. While it prompts the authors to consider the privacy implications of their approach, it does not provide explicit guidance on how to address these concerns or suggest specific actions to improve the draft. The comment is somewhat vague, as it leaves the authors to infer the need for further discussion and clarification. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. However, it does not specify which part of the paper these questions are related to, making it difficult for the authors to pinpoint the exact section or aspect being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. It is also not specific because it does not detail what needs to be addressed or how the questions should be answered. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. While it prompts the authors to consider the privacy implications of their approach, it does not provide specific evidence or references to support the claim that the approach is more privacy-preserving than others. The questions raised are logical but lack detailed reasoning or examples, making the comment somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. It suggests that one might think this is a bad example of an application of federated learning, which could provide valuable insights for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these concerns or improve the draft. While it identifies an area for improvement, it does not provide actionable feedback or detailed reasoning, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of fair comparison between CPEF and PMEF, noting that PMEF lacks a pre-training module, which is a key aspect of CPEF. It recommends comparing CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of CPEF\u2019s innovative pre-training module design. This comment provides a clear and explicit action for the authors to take, which is to include a comparison with ExpertBert. The action is concrete, as it specifies exactly what needs to be done to ensure a fair comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and the comparison between CPEF and PMEF, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of a lack of fair comparison and recommends a concrete solution by comparing CPEF with another pre-trained model, ExpertBert. This provides clear guidance on what needs to be addressed and how to do it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair because PMEF lacks a pre-training module, which is a key aspect of CPEF. The comment suggests that to ensure fairness, CPEF should be compared with another pre-trained model, such as ExpertBert. However, the comment does not provide specific examples or references to support the claim that PMEF lacks a pre-training module or why this makes the comparison unfair. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It highlights that PMEF lacks a pre-training module, which is a key aspect of CPEF, making the comparison unfair. The comment provides a clear and actionable suggestion to address this issue by recommending a comparison with another pre-trained model, such as ExpertBert. This feedback is highly helpful as it directly points out a significant weakness in the experimental setup and offers a concrete solution to improve the fairness of the comparison. By addressing this issue, the authors can strengthen the validity of their claims and enhance the overall quality of their work. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the hyperlinks for footnote 3 and 4 are not working. This is a clear and explicit action that the authors can take to address the issue. The comment provides specific information about which parts of the paper need correction, making it concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the hyperlink functionality, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the hyperlink functionality in the paper. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a specific issue with the hyperlink functionality in the paper, noting that the hyperlinks for footnote 3 and 4 do not seem to work. This is a clear and actionable feedback that the authors can easily address by ensuring the hyperlinks are functional. The comment is specific and provides a direct action for the authors to take, making it highly helpful in improving the draft. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests revising the discussion, particularly in the modeling section, as it is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment implies that the authors should revise the discussion to address these points, but it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests revising the discussion, especially in the modeling section, which is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. However, the comment does not explicitly mention which part of the paper this refers to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of clarity in the modeling section and the need for a better formalization. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment implies that the authors should revise the discussion to address these points, but it does not provide explicit reasoning or references to support the claim that the discussion is unclear or needs improvement. The feedback is somewhat verifiable as it points out areas for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the clarity and organization of the discussion, particularly in the modeling section. It suggests that the discussion is not clear enough and offers concrete examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment also points out that the figure is misleading, which could lead to confusion. By highlighting these specific areas for improvement, the comment offers actionable guidance for the authors to enhance the clarity and coherence of their draft. However, the feedback could be more comprehensive if it included additional suggestions or examples of how to improve the discussion. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be more detailed to fully assist the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the description of the neural network is hard to understand, but it also indicates that the final paragraph of the section clarifies it. The comment implies that the authors should consider starting the section with this clearer explanation. However, the action is implicit, as the authors need to infer that they should start the section with the final paragraph. The action is also somewhat vague, as it does not provide specific guidance on how to integrate the clearer explanation into the section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section of the paper (line 528), allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the description of the neural network by suggesting that the final paragraph of the section should be used as the starting point. This provides a clear direction for the authors to enhance the readability of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network is hard to understand, suggesting that the final paragraph of the section clarifies it. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the description is unclear. As a result, the claim is somewhat verifiable, as it is based on an observation without sufficient justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network, noting that the final paragraph of the section clarifies it. It suggests that the authors consider starting the section with this clearer explanation. This feedback is actionable and provides a clear direction for improvement, as it guides the authors on how to enhance the readability and coherence of their paper. By addressing this suggestion, the authors can significantly improve the clarity of their presentation, making it easier for readers to understand the neural network description. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the model should be addressed. The action is implicit, as the authors would need to infer that they should consider adding attention-based enc-dec training to their model. However, the lack of concrete details or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. Additionally, it lacks specificity in detailing what aspects of the model should be trained towards attention-based enc-dec training. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is relevant or beneficial. The comment lacks depth and does not offer a clear justification for the proposed change, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this idea. The comment does not provide any actionable advice or examples that would help the authors understand how to address the limitation or incorporate attention-based enc-dec training. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance or suggestions for implementation. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While the comment implies that the current division might be redundant or unnecessary, it does not provide explicit guidance on how the authors should revise the tables or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the need for a change and how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252)\" and specifies the issue regarding the division of tables. It clearly identifies the part of the paper being addressed, allowing the authors to accurately pinpoint the section. The comment is also specific because it questions the necessity of dividing tables into three types, suggesting that one type (the column header) might suffice. This provides a clear direction for the authors to consider and potentially revise their table structure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While the comment does not contain a subjective claim or suggestion, it implies that the current division might be redundant or unnecessary. However, without further explanation or justification, the claim is not fully verifiable. The comment lacks specific reasoning or examples to support the assertion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While it does not provide a direct suggestion or solution, it highlights a potential area for improvement in the presentation of the data. By identifying this issue, the comment offers a clear point for the authors to consider and potentially address in their draft. However, the feedback could be more helpful if it included suggestions or guidance on how to revise the table structure. Overall, the comment is somewhat helpful as it points out a specific area for improvement, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. However, it does not provide explicit guidance on which other methods should be considered or how they might impact the results. The comment implies that the authors should explore additional attack methods, but it lacks concrete suggestions or detailed instructions on how to do so. As a result, the authors are left with a vague idea of what to improve, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not specify which other methods should be explored or why the current methods are insufficient. The comment lacks grounding as it does not mention specific sections or parts of the paper that need improvement. It is also not specific because it does not provide detailed guidance on which methods to consider or how they might impact the results. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the paper for using only two attack methods, suggesting that other classical attack methods in NLP could be considered. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the critique. The comment lacks detailed justification or evidence, which hinders the authors' ability to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. While the comment identifies a potential area for improvement, it lacks specific guidance on which other methods should be considered or how they might impact the results. The suggestion to explore additional attack methods is somewhat helpful as it provides a direction for the authors to consider, but it does not offer detailed advice or examples, which could further enhance its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the mitigation methods or how they could ensure that the image generation capabilities are not compromised. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It mentions \"mitigation methods affect the image generation capabilities of diffusion models,\" but it does not provide context or references to specific sections, tables, or figures. The comment is also not specific because it does not detail what needs to be addressed or how the authors should approach the issue. Therefore, this comment is not grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The comment lacks actionable advice, leaving the authors without a clear path to enhance their work. As a result, the feedback is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure fair comparisons. The action is implicit and vague, as it does not specify how the authors can mitigate the risk of information leakage or how they should adjust their comparisons to account for this concern. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the comparisons with existing SSL methods. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in identifying the issue, the absence of explicit references to the paper's sections or content makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the incorporation of prior knowledge could lead to unfair comparisons. Without concrete evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk that the pretrained visual model and target dataset might leak additional information, skewing results and leading to unfair comparisons. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure fair comparisons. While it identifies a critical concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and actionable suggestions.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit suggestions for improvement or clarification. The authors are left without guidance on how to address this observation or what might be causing it. As a result, the comment lacks actionable feedback, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the reviewer is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is surprising or how the dominance of function words over content words might be addressed. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, followed by a question about the reviewer's understanding. While the observation is based on a specific example, the comment lacks detailed reasoning or evidence to support the claim. The authors may find it challenging to understand the basis of the observation without further explanation or context. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which the reviewer finds surprising. However, it does not provide any specific suggestions or insights on how this observation might be addressed or what implications it has for the paper. The comment lacks actionable guidance and does not offer any constructive feedback that would help the authors improve their work. Therefore, it is barely helpful, as it does not provide any meaningful direction for the authors to follow.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using the minimal k-means objective over multiple seeds as a baseline is more reasonable than the average of k-means objectives with multiple seeds. It provides specific references to support this claim, making it explicit and concrete. The authors know exactly what needs to be changed and how to implement it, as the suggestion is clear and detailed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the average of k-means objectives with multiple seeds should be replaced with the minimal k-means objective over multiple seeds as a baseline. It provides specific references to support this claim, making it fully grounded as it explicitly mentions the part of the paper being addressed. The comment is also specific as it clearly specifies what needs to be addressed, suggesting a change in the baseline used for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the average of k-means objectives with multiple seeds should be replaced with the minimal k-means objective over multiple seeds as a baseline. It provides specific references to support this claim, such as [1] Jin, Chi, et al. \"Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.\" Advances in neural information processing systems 29 (2016): 4116-4124, and [2] Fr\u00e4nti, Pasi, and Sami Sieranoja. \"K-means properties on six clustering benchmark datasets.\" Applied Intelligence 48.12 (2018): 4743-4759. These references provide logical reasoning and evidence to support the claim, making it fully verifiable. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a minor suggestion to improve the baseline used for comparison in the paper. It recommends using the minimal k-means objective over multiple seeds instead of the average of k-means objectives with multiple seeds. The comment also includes references to support the suggestion, providing a clear rationale for why this change might be beneficial. This feedback is actionable and constructive, as it offers a specific and logical improvement that the authors can implement to enhance their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences against Argument Mining/Discussion Summarization. While the comment implies an action\u2014namely, to clarify the differences\u2014the authors are left to infer the exact steps needed to implement this suggestion. The action is explicit but somewhat vague, as it does not provide specific guidance on how to clarify the differences. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences against Argument Mining/Discussion Summarization. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the task might be closer to Argument Mining than Summarization and recommends that the paper further clarify the differences against Argument Mining/Discussion Summarization. This feedback is somewhat helpful as it points out a potential area for clarification and suggests a direction for improvement. However, it lacks specific guidance on how to address the differences or what aspects of the paper need to be clarified. The comment provides a starting point for the authors to consider, but it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions (2.a and 2.b) that the authors need to address. Question 2.a asks for clarification on the relationship between temperature calibration and uncertainty calibration, particularly regarding the training regularization term H. Question 2.b critiques the motivation for calibrating networks given that they are already over-confident. These questions provide clear and explicit actions for the authors to take, making the comment highly actionable. The feedback is detailed and specific, guiding the authors to clarify and address the confusion and critique. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 155-160\" and \"lines 133-136,\" allowing the authors to accurately identify the sections of the paper being addressed. It is also specific because it details the confusion regarding the relationship between temperature calibration and uncertainty calibration, and it critiques the motivation for calibrating networks given their over-confidence. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific questions about the relationship between temperature calibration and uncertainty calibration, particularly concerning the training regularization term H. It also critiques the motivation for calibrating networks given their over-confidence. While the questions are clear and logical, the comment lacks detailed reasoning or references to support the claims made, such as why the regularization term H requires temperature calibration or how this aligns with the paper's motivation. The feedback is somewhat verifiable as it provides a basis for the authors to address the confusion and critique, but it could be more robust with additional evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment is highly helpful as it identifies specific areas of confusion and provides detailed questions for the authors to address. It highlights a potential inconsistency in the paper's approach to temperature and uncertainty calibration, particularly regarding the training regularization term H. The critique of the motivation for calibrating networks given their over-confidence is also insightful. By raising these points, the comment guides the authors to clarify and address these issues, which are crucial for improving the paper's coherence and alignment with its motivation. The detailed feedback is actionable and constructive, making it a valuable contribution to the authors' work.\", 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment does not provide explicit guidance on how to incorporate this discussion or where to add it. The action is implicit, as the authors need to infer that they should include a discussion of the missing reference and its relevance to their work. The comment is somewhat actionable because it identifies a specific area for improvement but lacks concrete details on how to implement it. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"unrolling\" and provides a link to a specific paper, \"Lista,\" which is relevant to the topic. It also specifies what needs to be addressed by discussing the similarities and differences between the proposed work and Lista, placing the paper in the appropriate context. This provides clear guidance on which part of the paper should be addressed and what specific issues need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is closely related to the idea of unrolling and that the omission of this reference is significant. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out a missing reference that is closely related to the proposed work. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista,\" as detailed in the paper \"Lista\" by Yann Lecun. This feedback is valuable as it directs the authors to a relevant piece of literature that could enhance the context and positioning of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate the discussion of \"Lista\" into the paper or suggested where to add this discussion. Despite this, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the linear program in Theorem 3 should be explained intuitively to help readers understand it better. It implies that the authors should provide an explanation of the objective and constraints in the linear program. However, the comment does not specify how to explain the objective and constraints or what kind of explanation would be most effective. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the intuitive explanation of the linear program, including the objective and constraints. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the linear program in Theorem 3 should be explained intuitively to aid reader understanding. However, the comment lacks specific details or examples to support this claim. It does not provide any reasoning or references to justify why an intuitive explanation would be beneficial or how it could be implemented. As a result, the claim is not verifiable, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the linear program in Theorem 3 should be explained intuitively to aid reader understanding. It points out that while the theorem is understood, an intuitive explanation of the objective and constraints would be beneficial. However, the comment lacks detailed guidance on how to provide this explanation or what aspects of the explanation would be most effective. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions on the type of explanation or examples to include. Therefore, the comment is somewhat helpful, as it offers a clear area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is explicit and provides a clear action for the authors to take, which is to define the FLOT cost matrix in the paper. The comment is concrete, as it specifies exactly what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of definition for the FLOT cost matrix in Algorithm 1. This provides the authors with a clear understanding of what needs to be addressed to improve the paper.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is clear and actionable, as it directly points out a missing element that needs to be addressed for the paper to be complete and understandable. By defining the FLOT cost matrix, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define the cost matrix effectively. Overall, the comment is somewhat helpful as it highlights a crucial aspect that needs attention, but it lacks depth in terms of guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the convergence of a bound in Theorem 2, specifically concerning the second term in Eq. (30). It notes that a similar bound in [Grunewalder et al, 2010], Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment suggests that the authors prove this, but it does not provide explicit guidance on how to approach the proof or what specific steps to take. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27)\" from [Grunewalder et al, 2010], allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the bound in Theorem 2, Eq. (30), particularly regarding the convergence of the second term as T approaches infinity. The comment requests proof of this convergence, providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the convergence of a bound in Theorem 2, specifically concerning the second term in Eq. (30). It notes that a similar bound in [Grunewalder et al, 2010], Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment suggests that the authors prove this, but it does not provide specific examples or references to support the claim that the second term does not converge to 0. While the reasoning is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the convergence of a bound in Theorem 2, Eq. (30), particularly concerning the second term. It notes that a similar bound in [Grunewalder et al, 2010], Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment requests that the authors prove this, which provides a clear direction for addressing a potential weakness in the paper. However, the comment could be more helpful if it offered additional guidance or suggestions on how to approach the proof or what specific aspects of the proof might be challenging. Overall, the comment is mostly helpful as it identifies a specific area for improvement and encourages the authors to address it, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the clarity of Algorithm 2, specifically regarding the computation of 'avg' and the use of variables j' and i''. It suggests that the authors should clarify these aspects to improve the understanding of the algorithm. However, the comment does not provide explicit guidance on how to update the algorithm or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. However, it does not specify which part of the paper Algorithm 2 is located in, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the content of the algorithm, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. However, it does not provide any supporting evidence or reasoning to justify why these aspects are unclear or problematic. The comment lacks specific examples or references that would help the authors understand the issues being raised. As a result, the claim is unverifiable, as it does not offer a clear basis for addressing the concerns.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the use of variables j\\' and i\\'. It also suggests that the authors should clarify these aspects to improve the understanding of the algorithm. While the comment identifies a potential area for improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is somewhat helpful as it points out areas that need clarification, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific definition of the sparsity of the residual term, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment explicitly asks for clarification and suggests specific actions, such as providing evidence and comparisons, it does not offer detailed guidance on how to implement these actions. The authors are left to infer the exact steps needed to address the issue, making the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specific definition of the sparsity of the residual term in the paper, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. However, the comment does not specify which part of the paper discusses the sparsity of the residual term, making it weakly grounded. While it provides some specificity by asking for clarification and evidence, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the specific definition of the sparsity of the residual term and suggests providing evidence to support the assumption across various noisy cases. It also implies a need to compare the advantages of the proposed method with existing methods. However, the comment lacks detailed reasoning or references to substantiate these claims, making it difficult for the authors to fully understand and address the issues. The feedback is somewhat verifiable as it provides some direction but lacks depth and specific examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the definition of the sparsity of the residual term in the paper. It questions whether the term implies the inclusion of many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, the comment implies a need to compare the advantages of the proposed method with existing methods. While the feedback is clear and points out a potential area for clarification, it could be more helpful if it provided specific examples or guidance on how to demonstrate the advantages of the proposed method. Overall, the comment is somewhat helpful as it highlights important aspects that need attention but lacks detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of the term \"connectivity\" in the paper, arguing that it is misleading because it does not reflect the structural connections between the brain and body. However, the comment does not provide any specific guidance or suggestions on how the authors should revise or clarify the use of the term. It lacks explicit instructions on what changes should be made or how the authors can address this issue. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of the term \"connectivity\" in the paper, arguing that it is misleading because it does not reflect the structural connections between the brain and body. However, the comment does not specify which part of the paper uses the term \"connectivity\" or provide any guidance on how the authors should revise or clarify its use. This makes it difficult for the authors to identify the specific section or aspect of the paper that needs attention. As a result, the comment is not grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is specific in its critique of the term \"connectivity,\" but without grounding, it lacks actionable guidance. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not reflect the structural connections between the brain and body. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"connectivity\" in the paper, suggesting that it is misleading because it does not reflect the structural connections between the brain and body. While the comment highlights a specific concern, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction on how to revise their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It also directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that the authors should address these issues in that section. However, the comment does not provide explicit guidance on what specific aspects of the paper need improvement or how to address the issues mentioned. The action is implicit and somewhat vague, as the authors are left to infer the exact areas that require attention. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which provides some grounding by indicating where the issues might be discussed. However, the comment does not specify which parts of the paper are missing details or require improvement, making it weakly grounded. The comment is specific in identifying the areas that need attention, such as related work, experiments, and writing, but it lacks detailed guidance on what specific issues need to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that the authors should address these issues in that section. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not polished or lacks clarity. Without concrete examples or references, the authors may find it challenging to understand the specific areas that need improvement. Therefore, the claim is barely verifiable, as it lacks sufficient evidence or justification to guide the authors effectively.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is not polished and lacks polish, with missing details in related work, experiments, and writing. The comment directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that the authors should address these issues in that section. However, the comment lacks specific guidance on what aspects of the paper need improvement or how to address the identified weaknesses. While it provides a general direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but could be more comprehensive and detailed to be fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the methodology, suggesting that the authors should study the importance of orthogonal matrix weights in their model. It implies that the current approach might be unnecessary and that a deeper analysis is needed to justify the use of orthogonal matrices. However, the comment does not provide explicit guidance on how to conduct this study or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the methodology of the paper, specifically mentioning the use of orthogonal matrix weights and the potential redundancy of steps 2 and 3. It suggests that the authors should study the importance of orthogonal matrix weights, implying that the current approach might be unnecessary. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact area of concern. The comment is specific in its suggestion to study the importance of orthogonal matrix weights, but without clear grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the potential redundancy of steps 2 and 3 in the methodology, suggesting that the importance of orthogonal matrix weights might be overstated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the current approach might be unnecessary. Without concrete evidence or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the methodology, specifically suggesting that steps 2 and 3 might be redundant and that the importance of orthogonal matrix weights could be overstated. It implies that the authors should study the necessity of orthogonal matrix weights to validate their use. However, the comment lacks specific guidance on how to conduct this study or what aspects of the model should be examined. While it points out a potential area for improvement, the feedback is somewhat vague and could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically around 4-5. It suggests that the authors might be experiencing overfitting. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to investigate the cause of the accuracy drop and consider whether overfitting is a potential factor. While the action is implicit, it is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why accuracy starts to drop after a certain order and suggests that it might be due to overfitting. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically around 4-5, and suggests that it might be due to overfitting. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation and the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically around 4-5, and suggests that it might be due to overfitting. While the comment identifies a potential issue with the results presented in the figure, it does not provide any specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for further investigation, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the toy-like nature of the models and datasets used in the paper, suggesting that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small should be considered. It also questions the feasibility of experimenting on language tasks. While the comment implies that the authors should address these issues, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should include more complex models and datasets or discuss the challenges of language tasks. However, the comment lacks concrete details on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also raises questions about the feasibility of experimenting on language tasks. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The specificity of the comment is moderate as it provides clear suggestions for improvement, but it lacks detailed guidance on how to address these suggestions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small. While the comment provides specific examples of datasets that could be used, it lacks detailed reasoning or references to support the claim that these datasets would be more appropriate. The suggestion to experiment on language tasks is also vague and lacks specific guidance. Therefore, the claim is somewhat verifiable, as it provides some basis for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that the models and datasets used are too simplistic, specifically mentioning the need for more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also raises questions about the feasibility of experimenting on language tasks, which is a relevant concern. While the comment provides some direction for improvement, it lacks detailed guidance on how to address these issues or what specific experiments could be conducted. The feedback is somewhat helpful as it highlights areas for enhancement but could be more comprehensive with additional suggestions or detailed reasoning. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of natural ablation studies, specifically mentioning the importance of including a baseline where scratchGAN is pretrained. It suggests that this baseline is crucial for supporting the central argument against pretraining. However, the comment does not provide explicit guidance on how to conduct these ablations or what specific results should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"natural ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for a baseline where scratchGAN is pretrained, providing clear guidance on what needs to be addressed. However, the comment does not provide specific details on which sections or parts of the paper should be revised to include these ablations. This makes the comment fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that some natural ablation studies are missing, specifically mentioning the importance of including a baseline where scratchGAN is pretrained. This claim is somewhat verifiable as it highlights a specific area where additional analysis could strengthen the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the missing baselines and understand their relevance to the central argument against pretraining.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where additional analysis is needed, namely the inclusion of natural ablation studies. It provides a clear example of a crucial baseline that is missing, which is the performance of scratchGAN when pretrained. This feedback is valuable as it highlights a significant gap in the paper and suggests a way to strengthen the argument against pretraining. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these ablations or what specific results should be included. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to state how they handle comparisons between episodes with different lengths, providing a clear and concrete action to take. It also highlights a specific issue with the lack of a normalization factor in the distance calculation, which could bias the results towards longer trajectories. The comment is fully grounded as it directly references the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. The action is explicit and concrete, providing detailed guidance on how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with how comparisons between episodes with different lengths are handled, including the method used (padding) and the potential bias introduced by the lack of a normalization factor. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should state how they handle comparisons between episodes with different lengths, specifically mentioning that the authors pad shorter sequences by replicating their last state. It also highlights a potential issue with the lack of a normalization factor of 1/T, which could bias the results towards longer trajectories. The comment provides specific details about the method used and the potential bias, making it mostly verifiable. However, it could be strengthened by including examples or references to support the claim about the bias. Overall, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on a critical aspect of the paper. It identifies a potential issue with how comparisons between episodes with different lengths are handled, noting that the authors pad shorter sequences by replicating their last state. The comment also points out a potential bias introduced by the lack of a normalization factor of 1/T, which could favor longer trajectories. This feedback is valuable as it directs the authors to clarify their methodology and address a potential flaw in their approach. By providing concrete suggestions and highlighting specific areas for improvement, the comment empowers the authors to enhance the clarity and robustness of their work. Therefore, this comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the absence of consideration for Vision Transformer in the experiment and the uncertainty of its effectiveness on larger datasets like ImageNet. It also questions whether the pruning strategy might differ in self-attention layers. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take. The suggestions are implicit and lack concrete details, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also inquires about the potential differences in pruning strategies in self-attention layers. However, the comment does not specify which part of the paper discusses the experimental setup or the results related to image classification, making it difficult for the authors to pinpoint the exact areas that need attention. The lack of specific guidance on what aspects to address further reduces the comment\\'s grounding specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also asks whether the pruning strategy might differ in self-attention layers. However, the comment does not provide any specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the claims remain unsubstantiated, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental evaluation by pointing out the absence of consideration for Vision Transformer, a state-of-the-art model in image classification. It also raises questions about the effectiveness of the proposed technique on larger datasets like ImageNet and the potential differences in pruning strategies in self-attention layers. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to consider additional experiments and analyses, but it could be more comprehensive with detailed recommendations or examples. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant gap in the paper by noting the absence of a comparison against baselines. It points out that the functionality similarity comparison study only reports accuracy across optimization levels of binaries, without considering any baselines. The comment suggests that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to include or how to conduct the comparison. While the action is implied, it is vague and lacks concrete details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of comparison against baselines in the functionality similarity comparison study, specifically mentioning that the study only reports accuracy across optimization levels of binaries without considering baselines. It also notes that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing and suggesting what could be included, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines in the functionality similarity comparison study, specifically noting that the study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch. However, the comment does not provide specific examples or references to support the claim that the paper is widely understood or that many papers have developed similar approaches. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as it relies on the authors' interpretation of the existing literature. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against baselines in the functionality similarity comparison study. It highlights that the study only reports accuracy across optimization levels of binaries without considering baselines, which is a widely-understood binary analysis application. The comment suggests that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch, indicating that the paper could benefit from including such comparisons. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting particular baselines to include or how to conduct the comparison. While it identifies an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention a specific detail in Section SI 6.5 regarding the evaluation process, noting that it differs from the evaluation in Mnih et al. [7] due to the absence of human starts. This comment provides an explicit action for the authors to take, which is to include this detail in their manuscript. The action is concrete as it specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be mentioned in that section, namely the difference in evaluation due to the absence of human starts. This provides the authors with a clear understanding of what to address, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should mention a specific detail in Section SI 6.5 regarding the evaluation process, noting that it differs from the evaluation in Mnih et al. [7] due to the absence of human starts. This claim is somewhat verifiable as it provides a clear reason for the authors to include this detail, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional context or examples to strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to include in Section SI 6.5. It highlights a detail that is important for the evaluation process, noting that the evaluation differs from that in Mnih et al. [7] due to the absence of human starts. This feedback is clear and directly addresses a potential area of confusion or omission in the manuscript. By suggesting this addition, the comment empowers the authors to improve the clarity and completeness of their work. Therefore, the comment is mostly helpful, as it offers a clear and actionable piece of feedback that would enhance the manuscript.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the figures, including their readability, the clarity of the text, the explanation of inputs and outputs, and the self-contained nature of the captions. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the figures, such as suggesting specific changes or providing examples of how to enhance readability. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses issues with figures 1 to 3, but it does not specify which parts of the paper these figures are located in, making it weakly grounded. It also lacks specificity in detailing what needs to be addressed, such as suggestions for improving readability, clarity, or self-containment of the captions. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that Figures 1 to 3 are difficult to parse due to small text, lack of clear explanation of inputs and outputs, and unself-contained captions. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the figures, such as their readability, the clarity of the text, the explanation of inputs and outputs, and the self-contained nature of the captions. It highlights that the figures are difficult to parse and suggests that the texts in the figures are too small. However, the comment does not provide actionable feedback or suggestions on how the authors might improve the figures. While it points out areas for improvement, it lacks depth and guidance, making it somewhat helpful. The authors would need to infer how to address these issues, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. The comment implies that the authors should include such metrics to substantiate their claims of efficiency. However, the action is implicit, as the authors need to infer that they should report metrics to demonstrate efficiency. The action is also somewhat vague, as it does not specify which metrics should be reported or how they should be presented. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the advantages of their proposed method over previous work in terms of efficiency. This allows the authors to accurately identify the section being addressed. The comment is also specific because it points out a lack of reporting of metrics that would demonstrate the efficiency of the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not report any metric that shows the proposed method is more efficient to train compared to previous work. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to substantiate these claims. This feedback is valuable as it highlights a critical area where the paper lacks empirical support. However, the comment could be more helpful if it suggested specific metrics or methods for evaluating efficiency, such as training time or computational resources. Without these details, the authors may struggle to address the feedback effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern that the contribution of the paper is not substantial enough, specifically regarding the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or enhance their contribution. It lacks concrete guidance on what specific aspects of the paper could be improved to increase its impact. As a result, the authors are left without a clear understanding of how to proceed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the contribution of the paper, specifically addressing the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. This allows the authors to accurately identify the part of the paper being discussed. The comment is also specific because it clearly specifies the issue with the contribution, noting that it is important but still limited. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the paper is not enough, specifically regarding the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, the comment lacks specific details or examples to substantiate this claim. It does not provide any evidence or reasoning to support the assertion that the contribution is insufficient. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper's contribution, specifically noting that the paper addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or enhance their contribution. It lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is not particularly helpful in guiding the authors towards enhancing their work. Therefore, it aligns with a score of 1, indicating that it is not helpful at all.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests the authors to provide more details about the state-space, actions, and the space of theta. While the authors can infer that they need to clarify these aspects, the comment does not explicitly instruct them to do so. The request for more details is clear, but the action of providing these details is implicit, making the comment somewhat actionable. The lack of explicit instructions or guidance on how to provide the additional details makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, L81, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the details about the state-space, actions, and the space of theta. The request for more details is clear and specific, providing the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more details about specific aspects of the paper, such as the state-space, actions, and the space of theta. While the request is clear and specific, it does not provide any additional context, reasoning, or references to support why these details are important or how they impact the paper. The authors are left to infer the importance of these details, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies specific areas where the authors need to provide more details, such as the nature of the state-space (finite or continuous), the actions involved, and the space of theta. By requesting these details, the comment encourages the authors to clarify critical aspects of their work, which could enhance the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or guidance on why these details are important or how they might impact the overall understanding of the paper. Overall, the feedback is clear and actionable, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the method's performance on general reasoning tasks or what changes could be made to enhance its effectiveness. Without explicit or implicit actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its critique of the method's performance but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method's performance on general reasoning tasks compared to mathematical reasoning. While it highlights an area for improvement, it lacks specific details or suggestions on how the authors might address this issue. The comment is somewhat helpful as it points out a gap in the method's effectiveness, but it does not provide actionable guidance or examples of how the authors could enhance their approach. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The authors acknowledge this in Section 3, where they mention the inapplicability of Theorem 1 due to normalization. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to the proof technique. While the authors are informed about the problem, they are left without a clear path to resolve it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the reliance on a special case where a contradiction arises as matrix norms approach infinity. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors are informed about the issue but are not given a clear path to address it, which limits the comment's helpfulness. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention the inapplicability of Theorem 1 due to normalization. While the comment highlights a potential weakness in the proof, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the proof technique. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks actionable advice, making it a 3: Somewhat Helpful comment.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that GDSS, despite not explicitly presenting a conditional framework, proposes a conditional molecule generation framework using classifier guidance, which could serve as a baseline. However, the comment does not provide explicit guidance on how to implement this suggestion or compare the models in Table 3. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. The comment further provides context by mentioning that GDSS, despite not explicitly presenting a conditional framework, proposes a conditional molecule generation framework using classifier guidance, which could be used as a baseline. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the continuous diffusion model, as evidenced by its performance in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that while GDSS does not explicitly present a conditional framework, recent work proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. The claim is somewhat verifiable as it provides a logical reasoning based on the performance in Table 2 and references recent work, but it lacks specific examples or detailed explanations of how the comparison should be conducted. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential improvement to the paper by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that while GDSS does not explicitly present a conditional framework, recent work proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. This feedback is somewhat helpful as it provides a clear direction for improvement by suggesting a relevant comparison and offering context through references to recent work. However, it could be more helpful if it included specific guidance on how to implement this comparison or compare the models in Table 3. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment does not provide explicit guidance on how the authors should implement these suggestions or what specific changes need to be made to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream tasks or the evaluation metrics used, making it difficult for the authors to pinpoint the exact areas that need revision. While the comment provides some specificity regarding the choice of tasks and metrics, it lacks full grounding as it does not explicitly mention sections or figures. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the choice of downstream tasks and pre-training methods, suggesting that LiDAR-based segmentation might be a better choice than object detection for benchmarks using IoU-based metrics like KITTI and Waymo. It also questions the effectiveness of colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the critique. The feedback is somewhat verifiable as it provides a general rationale but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the choice of downstream tasks and pre-training methods, suggesting that LiDAR-based segmentation might be a better fit for benchmarks using IoU-based metrics like KITTI and Waymo. It also questions the effectiveness of colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. While the comment provides some insight into potential improvements, it lacks specific guidance on how the authors should address these issues or what changes might be necessary in their draft. The feedback is somewhat helpful as it identifies areas for improvement but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential contradiction between the objective of Eq (12) and the IPO (Iterative Proportional Fitting) method. However, it does not provide explicit guidance or suggestions on how the authors should address this contradiction. The comment lacks concrete steps or actionable advice, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable, as it does not offer any specific direction or guidance on how to resolve the issue. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Eq (12)\" and \"IPO,\" which are specific elements of the paper. However, it does not explicitly state which part of the paper contains the discussion or analysis of these elements, making it weakly grounded. The comment is specific in identifying a potential contradiction between the objective of Eq (12) and the IPO method, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the objective of Eq (12) seems to be in contradiction with IPO. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the assertion of a contradiction. Without further elaboration or supporting evidence, the claim remains unverifiable. Therefore, the comment aligns with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the objective of Eq (12) and the IPO method, which is a specific area of concern for the authors. However, the comment lacks depth and actionable guidance on how the authors might address this issue. It does not provide suggestions for resolving the contradiction or offer insights into how the authors could clarify or align their objective with the IPO method. As a result, while the comment highlights a potential problem, it does not provide sufficient assistance for the authors to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also expresses a concern that allowing \"t\" to be arbitrary does not add value. While the comment provides a specific suggestion for improvement, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity, indicating a specific part of the paper that needs attention. However, it does not explicitly mention which section or part of the paper this refers to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. While the comment provides a specific suggestion, it lacks detailed reasoning or examples to support why this change would improve clarity. The authors are left to infer the benefit of the suggestion, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. This feedback is actionable and directly addresses a potential area of confusion for the authors. However, the comment could be more helpful if it provided additional context or examples of how this change would enhance clarity. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder might struggle to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or what specific aspects of their model could be improved. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the model's ability to handle semantic concepts, but without clear grounding, the authors may struggle to understand the context and relevance of the question. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder might struggle to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder might struggle to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of their model could be improved. While it identifies a potential area for concern, it lacks actionable insights or detailed feedback, making it somewhat helpful. The authors may gain some understanding of the issue but would need to seek further clarification or guidance to improve their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This provides a clear and explicit action for the authors to take, as they need to add this comparison to their draft. The suggestion is concrete, as it specifies which loss functions to include and provides examples, making it easy for the authors to understand and implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be made or which sections or figures would benefit from this addition. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. While the suggestion is specific in terms of the loss functions to include, the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This claim is somewhat verifiable as it provides specific examples of loss functions that could be included, but it lacks detailed reasoning or references to support why these comparisons are necessary or beneficial. The authors would need to infer the importance of these comparisons, which could be improved with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This feedback is specific and actionable, as it provides clear examples of loss functions that could enhance the paper's relevance and depth. By adding this comparison, the authors can strengthen their work and provide a more comprehensive evaluation of their approach. However, the comment could be more helpful if it included additional reasoning or context on why these comparisons are important. Overall, the feedback is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides several specific suggestions for improvements, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific numerical corrections in Table 3. Additionally, it points out an issue with the DOI number and the link in the paper. These suggestions are explicit and concrete, allowing the authors to directly apply them to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improvements, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific numerical corrections in Table 3. It also points out an issue with the DOI number and the link in the paper. The comment is fully grounded as it explicitly mentions specific sections and lines of the paper, allowing the authors to accurately identify the parts being addressed. The specificity is high as it provides clear guidance on what needs to be corrected or clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several specific suggestions for improving the paper, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific numerical corrections in Table 3. Additionally, it points out an issue with the DOI number and the link in the paper. These suggestions are clear and actionable, providing the authors with direct guidance on how to improve their draft. However, the comment lacks detailed reasoning or references to support the suggestions, which could enhance its verifiability. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides several specific and actionable suggestions for improving the draft, such as clarifying the use of \"D2 transcription norms\" and \"EF,\" correcting a typo in line 029, suggesting a change in the abbreviation from \"PLN\" to \"NLP,\" correcting a repeated word in line 264, and providing specific numerical corrections in Table 3. Additionally, it points out an issue with the DOI number and the link in the paper. These suggestions are clear and detailed, offering the authors a clear path to enhance the quality and accuracy of their work. However, the comment could be more helpful if it included additional guidance on how to address the identified issues or why these changes are necessary. Overall, the feedback is mostly helpful, as it provides a solid foundation for the authors to improve their draft, but it could be more comprehensive with additional reasoning or context.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including confusion due to the use of undefined notation (M and N), suggesting that the authors spell out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be cross-referenced. While the comment provides explicit suggestions for improvement, such as defining notation and improving figure clarity, it lacks concrete guidance on how to implement these suggestions. For instance, the authors are not told to provide specific definitions for M and N or to suggest alternative ways to improve figure readability. The action is somewhat vague, as it does not offer detailed steps or examples for how to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with notation in the paper, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be cross-referenced. However, the comment does not specify which parts of the paper these issues are present, making it weakly grounded. The suggestions are specific in terms of what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the notation is confusing, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4 and noting that the text in Figure 1 is too small to see. The comment provides specific suggestions for improvement, such as defining notation and enhancing figure clarity, which are logical and verifiable. However, it lacks detailed reasoning or references to support the claim about the confusion caused by the notation. While the suggestions are actionable, the lack of comprehensive justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper, including the confusion caused by undefined notation (M and N) and suggestions for enhancing the clarity of figures. It provides specific recommendations, such as spelling out F.L.T.R in Figure 4 and noting that the text in Figure 1 is too small to see. Additionally, it suggests that notation and figures be cross-referenced, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided more detailed guidance on how to implement these suggestions or addressed other potential issues in the paper. Overall, the feedback is mostly helpful as it offers actionable insights for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue, such as suggesting alternative notations or clarifying the usage of $p$. The action is implicit and vague, as the authors are left to infer that they need to make the notation clearer. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using $p$ to denote both the phase mixing probability and a dummy variable in Algorithm 1 could be confusing. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion might arise or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. While the comment highlights a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable advice, making it incomplete. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding of the approach. It also critiques the figure, noting that it is too abstract and confusing, and that it does not align with the paper's main contribution, which is improvements on the WiC task. The comment implies that the authors should consider adding a mathematical formulation and improving the figure's clarity and relevance. However, it does not provide explicit instructions on how to implement these suggestions, such as which specific aspects of the mathematical formulation to include or how to improve the figure's clarity. The action is somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the high-level description and the figure, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as adding a more detailed mathematical formulation and improving the figure's clarity and relevance to the WiC task. This provides clear guidance on how to enhance the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the high-level description as intuitive but suggests that a more detailed mathematical formulation, potentially in the appendix, would be beneficial. It also critiques the figure, noting that it is too abstract and confusing, and that it does not align with the paper's main contribution, which is improvements on the WiC task. The comment provides specific suggestions for improvement, such as adding a mathematical formulation and improving the figure's clarity and relevance. However, it lacks detailed reasoning or references to support these claims, making the feedback somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on areas where the paper could be improved. It suggests that a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding of the approach. Additionally, it critiques the figure, noting that it is too abstract and confusing, and that it does not align with the paper's main contribution, which is improvements on the WiC task. The comment offers suggestions for improvement, such as adding a mathematical formulation and improving the figure's clarity and relevance. However, the feedback could be more comprehensive by providing specific examples or guidance on how to implement these suggestions. Overall, the comment is mostly helpful as it identifies areas for improvement and offers actionable feedback, but it could be more detailed to fully assist the authors in enhancing their draft.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include additional benchmarking tasks outside of AitW. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors on which tasks to include or how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the specific tasks that would enhance the benchmarking. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which tasks or provide any guidance on how to implement this suggestion. The authors cannot confidently determine which part of the paper this comment addresses, as it is a general recommendation for improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should include additional benchmarking tasks outside of AitW. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should include additional benchmarking tasks outside of AitW, which could enhance the comprehensiveness and robustness of their evaluation. However, the comment lacks specificity and does not provide any guidance on which tasks to include or how to implement this suggestion. While it offers a general direction for improvement, it does not offer detailed feedback or actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for additional information regarding the experiments conducted. It asks for the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iteration-wise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST-2. While the comment explicitly asks for these details, it does not provide explicit guidance on how to incorporate them into the draft or suggest specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address these requests. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments\" and \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the pre-training experiment part, such as the lack of steps vs ppl for linformer with YOSO and the comparison of YOSO with linformer on iteration-wise convergence. Additionally, it raises a question about the better accuracy of linformer in downstream tasks like SST-2, which requires further explanation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the experimental setup and results, specifically regarding the steps vs ppl of linformer with YOSO in Figure 4 and the comparison of YOSO with linformer on iteration-wise convergence. It also questions the better accuracy of linformer in downstream tasks like SST-2 and asks for an explanation. While the comment identifies areas where the paper could be improved, it lacks specific examples or detailed reasoning to fully substantiate the claims. The questions are clear and logical, but the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas where the paper could be improved, particularly in the experimental section. It points out the lack of steps vs ppl for linformer with YOSO in Figure 4 and questions the comparison result of YOSO with linformer on iteration-wise convergence. Additionally, it raises a question about the better accuracy of linformer in downstream tasks like SST-2, suggesting a need for further explanation. While the comment is clear and identifies areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it provides a clear direction for the authors to enhance their draft, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. However, it does not provide any explicit or implicit actions for the authors to take. The comment points out a potential issue but does not guide the authors on how to address it or what changes are needed. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a clear discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. This provides the authors with a clear understanding of what needs to be corrected or clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract incorrectly states that the proposal distribution must upper bound the target everywhere, which is not true as the authors clarify in the text. This claim is supported by the fact that the authors themselves acknowledge the discrepancy in the text, providing a clear justification for the comment. However, the comment could be more robust by explicitly referencing the specific section of the text where the clarification is provided, enhancing its verifiability. Overall, the comment is mostly verifiable, as it is supported by logical reasoning and clear evidence, but it could be strengthened with more specific references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue in the abstract, noting that it incorrectly states that the proposal distribution must upper bound the target everywhere, which is not true as the authors clarify in the text. This feedback is clear and actionable, as it directs the authors to correct the abstract to align with the content in the text. However, the comment could be more helpful if it provided guidance on how to revise the abstract or suggested specific changes to make it more accurate. Despite this, the comment is mostly helpful as it highlights a critical error that needs addressing, providing the authors with a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. It suggests that the authors should clarify the use of the name or provide a different label. However, the comment does not specify how the authors should address this issue or what changes they should make to the paper. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the naming of \"PointNet\" in the referenced paper, which is not present in the current paper. The comment provides a clear suggestion to clarify the use of the name or provide a different label, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. The comment provides a specific reference to the paper \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi et al. This reference supports the claim that the name \"PointNet\" is confusing and potentially misleading. However, the comment could be more verifiable by providing additional context or examples of how this confusion might affect the paper's clarity or impact. Overall, the comment is mostly verifiable, as it is supported by a specific reference but lacks some depth in explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the naming of \"PointNet\" in Figure 1, noting that the name is confusing because it does not appear in the current paper and is shared with another paper. The comment provides a clear reference to the paper \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi et al., which helps the authors understand the context and the potential confusion. However, the comment could be more helpful by suggesting specific ways the authors could address this issue, such as clarifying the use of the name or providing a different label. While it offers a valuable insight, it lacks actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This suggests that the authors should clarify the relationship between the equations. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects need clarification. While it implies that the authors should clarify the equations, the action is not concrete, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This part of the comment is fully grounded as it explicitly mentions the equations, allowing the authors to accurately identify the section being addressed. However, the comment does not specify what needs to be addressed in this part, such as clarifying the relationship between the equations or providing additional context. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This is a subjective opinion or critique of the paper's content, as it expresses a concern about the clarity and correctness of the equations. However, the comment does not provide any specific evidence, reasoning, or references to support this claim, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, specifically questioning if the convergence leads to the optimal solution for Eq. 5. This feedback highlights a potential area of confusion or lack of clarity in the paper, suggesting that the authors should clarify the relationship between the equations. However, the comment does not provide specific guidance or suggestions on how to address this issue, leaving the authors with limited actionable feedback. The minor comment about the unnecessary use of \"on\" in Line 78 is also noted but lacks depth. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but does not offer detailed guidance or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the assumption of the general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what changes might be necessary. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm, suggesting that it might be possible to assume the latter. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the distribution assumption, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain a claim that requires verification or justification. The comment is factual and descriptive, asking for clarification or a discussion of the difference between these assumptions. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It prompts the authors to consider whether it is possible to assume the latter and asks for clarification on the difference between the two assumptions. While the comment identifies a potential area for clarification and exploration, it does not provide specific guidance or suggestions on how the authors might address this question or what changes could be made to the algorithm. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide explicit guidance on how to implement this discussion or what specific aspects of the partitioning strategy should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors discuss the limitations of freezing the partitioning in the first iteration. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology, specifically the assumption of coverage in the first iteration of partitioning. It suggests that this choice might be risky and recommends that the authors discuss the limitations of this approach. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. However, the comment could be more helpful if it offered additional guidance on how to discuss the limitations or what aspects of the partitioning strategy should be considered. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit suggestions on how the authors should address this question or what changes might be needed. Without further guidance or clarification, the authors are left without a clear understanding of what action to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the section or figure being referred to. Additionally, the comment is not specific because it does not provide any details on what is intended or how it should be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the intent of Section 5.2 but does not provide any claim, suggestion, or critique that requires verification. It is a factual question that does not offer any guidance or insight into how the authors should improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, which could be helpful for the authors to clarify their writing or improve the flow of the paper. However, it does not provide any specific suggestions or guidance on how to address this question or what changes might be needed. The comment lacks actionable feedback, making it barely helpful as it does not offer any actionable steps for the authors to take. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that many aspects of the approach need clarification and that the paper quickly delves into technical details without clearly explaining the overall approach or its rationale. However, it does not provide explicit instructions or suggestions on how the authors should clarify these aspects or address the concern about the paper's flow. The action is implicit, as the authors are expected to infer that they need to clarify the approach and provide a clearer explanation of the paper's overall structure and rationale. The action is somewhat vague, as it lacks concrete guidance on what specific aspects need clarification or how to address the concern about the paper's flow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many aspects of the approach need to be clarified,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies what needs to be clarified, particularly regarding the interaction between knowledge about objects and verbs to overcome reporting bias. However, the comment does not provide specific examples or detailed guidance on what aspects need clarification, making it somewhat specific. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the approach and the paper's flow, specifically questioning how the approach makes knowledge about objects interact with knowledge about verbs to overcome reporting bias. However, the comment lacks specific examples, detailed explanations, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically highlights the concern regarding how the approach makes knowledge about objects interact with knowledge about verbs to overcome reporting bias, which is a critical point for understanding the paper's contribution. However, the comment lacks detailed suggestions or guidance on how the authors might address these issues or improve the clarity of their approach. While it points out a crucial area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide specific steps or examples for the authors to follow. Therefore, the comment is rated as somewhat helpful, as it provides a clear direction for improvement but could be more comprehensive with detailed guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. It also recommends including this information in a dedicated section to enhance clarity. The comment provides a clear and explicit action for the authors to take, which is to define the threat model more explicitly and include it in a dedicated section. This action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. It also recommends including this information in a dedicated section to enhance clarity. However, the comment does not specify which part of the paper discusses the threat model, making it weakly grounded. While it provides specific guidance on what needs to be addressed, the lack of explicit mention of the section or part of the paper makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. It recommends including this information in a dedicated section to enhance clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the threat model is unclear or lacks explicit definition. While the suggestion is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of the threat model. It suggests that the authors should define the threat model more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their work. By recommending the inclusion of this information in a dedicated section, the comment offers a concrete suggestion that can significantly improve the paper. Therefore, the comment is highly helpful, as it provides detailed guidance on how to address a specific weakness and enhance the overall quality of the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment implies that the authors should provide a justification for their choice, it does not explicitly instruct them to do so or offer specific guidance on how to implement this change. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain their decision. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the section of the paper being addressed. It is also specific because it clearly specifies the issue: the decision to use early stopping only by link prediction accuracy and questions why it was not averaged with type accuracy. This provides a clear direction for the authors to address the concern. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind using early stopping based solely on link prediction accuracy, suggesting that averaging with type accuracy might be a more comprehensive approach. However, the comment does not provide any specific reasoning, examples, or references to support why this decision was made or why it might be improved. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of concern regarding the decision to use early stopping based solely on link prediction accuracy. It questions the rationale behind this choice, suggesting that averaging with type accuracy might be a more comprehensive approach. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential weakness in the methodology, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to set a reasonable class-imbalanced task in the context of few-shot learning. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete details or examples to guide the authors. The comment implies that the authors should clarify this aspect, but it lacks specific guidance on how to do so. Therefore, the comment is not actionable, as it does not provide the authors with a clear path to improve their draft. The comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the phrase \"sampling class-imbalanced tasks\" in the context of few-shot learning, specifically asking how to set a reasonable class-imbalanced task. However, it does not specify which part of the paper this phrase appears in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of class imbalance in few-shot learning, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how to set a reasonable class-imbalanced task in the context of few-shot learning. It does not contain a subjective claim or suggestion but rather poses a question that requires clarification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"sampling class-imbalanced tasks\" in the context of few-shot learning, specifically asking how to set a reasonable class-imbalanced task. This question highlights a potential area of confusion or lack of clarity in the paper, which could be addressed by providing more detailed explanations or examples. However, the comment does not offer any suggestions or guidance on how to improve the clarity or address the issue, making it somewhat helpful as it identifies a specific area for improvement but lacks actionable feedback. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the chat-GPT baseline is rudimentary and that few-shot approaches should be tested. It also recommends including discourse relation information in the prompts, possibly using a Chain-of-Thought style, to potentially improve the results. However, the comment does not provide explicit guidance on how to implement these suggestions or actions. The feedback is somewhat vague, as it lacks detailed instructions on how to test the few-shot approach or how to incorporate the discourse relation information into the prompts. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide concrete steps for the authors to take. This aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the chat-GPT baseline, noting that it is rudimentary and that few-shot approaches are not tested. It also suggests including discourse relation information in the prompts, potentially using a Chain-of-Thought style, to improve results. However, the comment does not specify which part of the paper discusses the baseline or the prompts, making it weakly grounded. It is specific in detailing what needs to be addressed, such as testing few-shot approaches and incorporating discourse relation information. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-GPT baseline is rudimentary and that few-shot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, might yield good results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a weakness in the paper by pointing out that the chat-GPT baseline is rudimentary and that few-shot approaches are not tested. It also suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, could improve the results. However, the comment does not provide specific guidance on how to implement these suggestions or how to test the few-shot approach. While it offers some direction for improvement, the feedback lacks depth and actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was performed. This feedback is explicit, as it directly instructs the authors to include more information about the pruning process. However, the action is somewhat vague because it does not specify exactly what details need to be added or how the pruning process should be described. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 238-239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the lack of detail in explaining how the ground truth of sensitivity is achieved, specifically mentioning the absence of information on the pruning process. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically noting that lines 238-239 mention estimating sensitivity by pruning but lack details on the actual pruning process. This claim is somewhat verifiable as it identifies a gap in the explanation, but it does not provide specific examples or references to support the assertion. The authors would need to infer the missing details themselves, which limits the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors lack detail, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide sufficient information on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more details about the methodology used to determine the ground truth of sensitivity. By addressing this feedback, the authors can improve the clarity and completeness of their paper, making the comment mostly helpful. However, it could be more helpful if it suggested specific ways to include the details or examples of how the pruning process was conducted. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some parts of the text could be written more clearly, specifically mentioning lines 97, 105-106, and the concept of a proper rotation matrix and the issue of a non-positive semidefinite matrix. However, it does not provide explicit instructions or suggestions on how the authors should improve the clarity of these sections. The feedback is somewhat vague, as it implies that the authors should clarify these points but does not offer concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some parts of the text could be written more clearly, specifically mentioning lines 97, 105-106, and the concept of a proper rotation matrix and the issue of a non-positive semidefinite matrix. However, it does not provide explicit references to sections, tables, or figures, making it difficult for the authors to pinpoint the exact parts of the paper being addressed. While the comment is specific about the issues needing clarification, the lack of grounding makes it challenging for the authors to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some parts of the text could be written more clearly, specifically mentioning lines 97, 105-106, and the concept of a proper rotation matrix and the issue of a non-positive semidefinite matrix. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies areas where the text could be written more clearly, specifically mentioning lines 97, 105-106, and the concepts of a proper rotation matrix and a non-positive semidefinite matrix. It provides specific examples of where the text is unclear, such as the need for explicit explanation of these concepts. However, the comment lacks broader context or suggestions on how the authors might improve the clarity of these sections. While it offers some actionable feedback, it could be more helpful if it provided more detailed guidance or examples of how to revise the text. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This comment provides a specific suggestion for improvement, indicating that the authors should consider a different term for the function. The action is explicit and concrete, as it clearly directs the authors to make a change to the terminology. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, suggesting that the function g might be better described as a binary operator, similar to the approach in Cohen and Shashua, 2016. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This comment provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to support why this change would be beneficial. While the reference to Cohen and Shashua, 2016, provides some context, the comment does not fully explain the rationale behind the suggestion or how it aligns with the paper's goals. Therefore, the claim is somewhat verifiable, as it offers a suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by suggesting that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This feedback is actionable and offers a clear direction for enhancing the clarity and consistency of the paper. By aligning the terminology with existing literature, the authors can improve the readability and understanding of their work. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful as it offers a clear and actionable piece of feedback, but it could be further enhanced with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors' content and recommends shrinking the captions to provide more space for the methods or related work sections. This feedback is explicit and provides a clear action for the authors to take, which is to adjust the captions. The comment is specific in its suggestion, detailing what needs to be done to improve the layout and presentation of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, namely, to shrink the captions to leave more space for the methods or related work sections. This feedback is detailed and actionable, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors' content, recommending that the captions be shrunk to provide more space for the methods or related work sections. This claim is somewhat verifiable as it provides a clear suggestion for improvement but lacks specific examples or references to support the claim. The authors would need to independently verify the extent of the overlap and the effectiveness of shrinking the captions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the captions of Figure 1 and Figure 2, noting that they have large overlaps with the authors' content. It provides a clear suggestion to shrink the captions to make space for the methods or related work sections. This feedback is actionable and directly addresses a potential issue with the layout and presentation of the paper. By offering a specific and constructive suggestion, the comment empowers the authors to improve the clarity and readability of their work. However, the comment could be more helpful if it included additional guidance on how to effectively shrink the captions or suggested alternative layout options. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. It implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to include or exclude the dataset. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work and why it is not used as a potential benchmark for evaluation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment lacks specific reasoning or examples to support the claim that Vidgen et al., 2021, is similar to the dataset or why it should be considered as a benchmark. Without detailed justification or references, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a pertinent question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or why the dataset should or should not be included. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights a relevant concern but does not offer concrete steps for the authors to take.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10), ideally with error-bars. It also points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and that the models are small, making it an excuse for not providing statistics. The comment provides clear guidance on how the authors should present their results, including specific actions such as calculating means over multiple runs and including error bars. This explicit and detailed feedback allows the authors to directly address the issue and improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how the results should be presented, including the need to present them as a mean over many runs (at least 10) with error bars, and highlights the issue with the plotted curves being from single runs. This detailed feedback helps the authors understand what needs to be addressed and how to improve their presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error bars, as the current presentation based on single runs might be subject to significant fluctuations. The comment provides a logical reasoning by explaining why presenting results as a mean with error bars is important for accuracy and reliability. However, it lacks specific examples or references to support the claim, which could make it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the presentation of results, suggesting that the comparison between standard and evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error bars. This is a clear and actionable suggestion that addresses a potential issue with the current presentation of results, which might be subject to significant fluctuations due to single runs. By providing this guidance, the comment helps the authors improve the accuracy and reliability of their findings. However, the comment could be more helpful if it included additional suggestions or considerations for the analysis. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide explicit or implicit suggestions on how the authors might address these issues or improve their approach. The feedback lacks concrete guidance on potential modifications or strategies to enhance the proposed method, leaving the authors without clear direction on how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section being addressed. While the critique provides some specificity regarding the issues raised, the lack of explicit grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims, making it somewhat verifiable. The authors may find it challenging to fully understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve their approach. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it offers some insight but lacks the depth needed for comprehensive improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detail about the experimental environment, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. While the comment explicitly suggests what information should be included, it does not provide specific guidance on how to describe the environment or what aspects to focus on. The action is clear and explicit, but it lacks concrete details on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also highlights that different versions of the environment can impact training and inference speeds. However, the comment does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. While the authors can infer that this relates to the experimental setup, the lack of explicit mention makes the comment weakly grounded. The comment is specific in its suggestion to include more detail about the experimental environment, but the lack of grounding makes it less helpful. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this information is important or how it impacts the results. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide more detail about the experimental environment, including the CUDA and PyTorch versions. It also highlights the importance of this information, noting that different versions can impact training and inference speeds. While the comment is clear in its suggestion, it lacks specific guidance on how to describe the environment or what aspects to focus on. This provides the authors with a general direction for improvement but could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, as it offers a clear area for enhancement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. It also acknowledges the authors' judgment that there is no immediate societal impact. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the draft or what specific changes might be necessary. As a result, the authors are left without a clear understanding of how to respond or improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is vague in its reference, making it difficult for the authors to pinpoint the exact area that needs attention. Additionally, it does not provide specific guidance on how to address this concern or what changes might be necessary. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. This feedback highlights a potential limitation in the methodology or experimental design, which could impact the robustness and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the clarity of a paragraph (L156-166) and suggests that the authors should clarify the use of bandit algorithms and the explanation of the Gittins strategy. It also points out that the figure is hard to understand and that the explanation of dashed lines is vague. While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to clarify these sections or provide concrete guidance on what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section of the paper (L156-166), allowing the authors to accurately identify the part being addressed. It also provides specific feedback on the clarity of the paragraph, the use of bandit algorithms, the explanation of the Gittins strategy, and the difficulty in understanding the figure. The comment is specific in detailing what needs to be clarified or improved, such as the explanation of bandit algorithms and the vagueness of the figure's explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paragraph is barely understandable, despite the reviewer's expectation that they understand what is being said. It also critiques the use of bandit algorithms, specifically mentioning the Gittins strategy and the Markov chain nature of posterior evolution. The comment highlights the difficulty in understanding the figure, noting that the explanation of dashed lines is vague. However, the comment lacks specific examples or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the basis for the critique, which limits the verifiability of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the clarity of a paragraph (L156-166), noting that it is barely understandable despite the reviewer's expectation of understanding. It critiques the use of bandit algorithms, specifically mentioning the Gittins strategy and the Markov chain nature of posterior evolution. The comment also highlights the difficulty in understanding the figure, noting that the explanation of dashed lines is vague. While the feedback is somewhat helpful in identifying areas for improvement, it lacks detailed guidance on how to clarify the paragraph or improve the explanation of the figure. The authors would need to infer the necessary steps to address these issues, making the comment mostly helpful but not fully so.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention the evaluation metric used in the paper to improve clarity and understanding of the results. It provides a specific example of where this information is missing, namely lines 078-079 and line 08. However, the comment does not explicitly instruct the authors on how to incorporate this information or what specific metric should be mentioned. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (078-079 and line 08), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of the evaluation metric for clarity and comparability. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric should be mentioned for clarity and comparability, providing a specific example of where this information is missing. However, the comment lacks detailed reasoning or examples to fully support the claim. It does not provide references or logical reasoning to justify why mentioning the evaluation metric is crucial for understanding the results. As a result, the claim is somewhat verifiable, as it is partially supported but lacks depth and clarity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the evaluation metric should be mentioned in the paper to enhance clarity and comparability. It provides a concrete example of where this information is missing, specifically in lines 078-079 and line 08. By highlighting the importance of including the evaluation metric, the comment offers actionable feedback that could help the authors improve the presentation and understanding of their results. However, the comment could be more helpful if it provided additional guidance on how to choose the appropriate metric or why it is important for the study. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear rationale for doing so.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the standard deviation of the noise in the simulation study is not as high as it could be, based on the observations compared to the true trajectories. It recommends studying the behavior of the model under higher noise. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specifying which aspects of the model should be studied or how to increase the noise level. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simulation study\" part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion to study the behavior of the model under higher noise, based on the observation that the current noise level is not as high as it could be. This guidance is detailed and actionable, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the standard deviation of the noise in the simulation study is not as high as it could be, based on the observations compared to the true trajectories. However, the comment lacks specific evidence or examples to support this claim. It does not provide a detailed explanation of why the current noise level is insufficient or how the model would behave under higher noise. Without this additional information, the claim remains somewhat verifiable, as the authors may need to infer the reasoning or seek further clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the simulation study, noting that the standard deviation of the noise is not as high as it could be based on the observations compared to the true trajectories. It suggests studying the behavior of the model under higher noise, which is a valuable and actionable piece of feedback. However, the comment could be more helpful by providing specific guidance on how to increase the noise level or what aspects of the model should be studied under higher noise. Despite this, the feedback is mostly helpful as it directs the authors to an important area for improvement, allowing them to enhance the robustness of their simulation study. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the bounds of the approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to resolve the concern, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the bounds of the approach, specifically mentioning that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the bounds, the absence of explicit grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounds of the approach have o(1) terms and improve over previous results for arbitrarily long inputs, but it does not provide any specific evidence or reasoning to support this claim. Without detailed justification or examples, the authors may find it difficult to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the bounds of the approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide any suggestions or guidance on how to address this concern or how it might limit the applications of the approach. The comment lacks actionable advice or insights that could help the authors improve their draft. As a result, it is barely helpful, as it only points out a potential problem without offering any constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting question about the performance of DVP on video with varying lengths. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises an interesting question about the performance of DVP on video with different lengths, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what needs to be improved in the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of DVP on video with different lengths, which could be a valuable point for discussion or further exploration. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this question or what improvements could be made to their draft. Without actionable insights or constructive feedback, the comment is not particularly helpful in guiding the authors to enhance their work. Therefore, it aligns with a score of 1, indicating that it is barely helpful.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion or clarify the distinction in their draft. The action is implicit, as the authors would need to infer that they should clarify the target queries in the introduction or methodology sections. However, the lack of specific guidance on how to clarify the distinction makes the action vague and less actionable. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment expresses confusion about whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until reading the conclusion. However, it does not specify which part of the paper this confusion pertains to, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the type of cloze queries targeted, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until reading the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support why this distinction is important or how it affects the paper's content. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights a potential confusion regarding the paper's focus on single-token or multi-token cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions, leaving the authors with limited guidance on how to improve their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should evaluate the approximation error of the proposed training objective by calculating the actual KL-divergence and checking whether it approaches zero. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue. The comment is fully actionable because it specifies the exact steps required to implement the suggested improvement. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.3,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed training objective has ignored the KL-divergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. This level of detail makes the comment specific, as it clearly identifies what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the proposed training objective in Section 3.3, noting that it has ignored the KL-divergence term in equation (3). The comment suggests evaluating the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim that the approximation error is significant or needs evaluation. Without additional context or justification, the authors may find it challenging to understand the basis for this critique. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 3.3, where the proposed training objective has ignored the KL-divergence term in equation (3). It suggests that the authors evaluate the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the identified gap in their analysis. However, the comment could be more helpful if it included additional guidance on how to calculate the KL-divergence or suggested specific experiments to validate the approximation error. Despite this, the comment offers valuable insights that can significantly enhance the authors' work, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work [1]. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to strengthen the connection between Section 2 and the methodology section and expand the theoretical analysis to include more depth and novelty. The lack of specific actions or concrete suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2\" and \"the methodology section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the limited connection between these sections and the simplicity of the theoretical analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work [1]. While the comment provides a general assessment of the connection and the complexity of the theoretical analysis, it lacks specific examples or detailed reasoning to support these claims. The absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for understanding but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the authors should strengthen this link. It also points out that the theoretical analysis is somewhat simplistic and closely related to a specific work [1], implying that the authors should expand or enhance the theoretical analysis to address this concern. While the comment provides some direction for improvement, it lacks specific guidance on how to strengthen the connection or expand the theoretical analysis. The feedback is somewhat helpful as it highlights areas for improvement but could be more detailed and actionable to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. While the comment implies an action, it does not explicitly instruct the authors to provide a detailed discussion or analysis of these situations. The action is somewhat vague, as it leaves the authors to infer that they need to expand on the discussion of the losses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests further discussion or exploration of which situations the losses help, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its focus on the relationship between losses and specular areas, but without clear guidance on where to include this discussion, it is weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. This feedback is somewhat helpful as it points out a potential area for additional discussion that could enhance the paper's depth and clarity. However, the comment lacks specificity and does not provide detailed guidance on how to expand the discussion or what aspects to focus on. As a result, the feedback is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the paper's strength for ICLR but does not provide any specific suggestions or actions for the authors to take to improve their draft. It lacks concrete guidance on what aspects of the paper need to be addressed or how the authors can enhance its quality. Without explicit or implicit actions, the authors are left without a clear path to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses doubt about the paper's strength for ICLR but does not specify which part of the paper is being questioned or what aspects need improvement. It lacks grounding as the authors cannot determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific, as it does not provide any details on what needs to be improved or how the authors can enhance the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses doubt about the paper's strength for ICLR but does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed justification or examples to substantiate the authors' concerns. Without such support, the claim remains unsubstantiated and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses doubt about the paper's strength for ICLR but does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. It lacks actionable guidance, such as identifying specific weaknesses or areas for improvement, making it difficult for the authors to address the feedback effectively. As a result, the comment is barely helpful, as it does not offer any meaningful insights or direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the major contributions of the paper and criticizes the approach of analyzing previous work as a contribution. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment suggests that the authors should clarify their contributions, but it does not offer specific guidance on how to do so. Without concrete suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is unclear regarding its major contributions or critique the approach of analyzing previous work as a contribution. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific because it does not provide detailed guidance on how to clarify the contributions or critique the approach. Therefore, this comment is not grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unclear what the major contributions of the paper are and criticizes the approach of analyzing previous work as a contribution. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the major contributions. It also critiques the approach of analyzing previous work as a contribution, which is a valuable point for the authors to consider. However, the comment lacks depth and actionable suggestions. While it highlights a critical area for improvement, it does not provide specific guidance on how the authors might address this issue or what changes could be made to clarify the contributions. As a result, the comment is somewhat helpful, as it points out a crucial weakness but does not offer comprehensive feedback for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. While the comment identifies these areas, it does not provide explicit guidance on how to address them or suggest concrete actions for the authors to take. The authors are left to infer that they need to clarify these aspects, but the lack of detailed instructions or examples makes the action vague and difficult to execute. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses issues with Algorithm 2 and line 225, providing specific examples of what needs clarification. It mentions the lack of explanation on how to determine n_t and the ambiguity of the term \"appropriate number.\" This allows the authors to accurately identify the parts of the paper being discussed, making the comment fully grounded. The specificity is also high as it clearly specifies the issues with the algorithm and the term in question, providing detailed feedback on what needs to be addressed. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific questions about the paper: how to determine n_t in Algorithm 2 and the meaning of \"appropriate number\" in line 225. While the questions are clear and point to specific areas needing clarification, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper: the lack of explanation on how to determine n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. While the comment points out these areas, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the feedback lacks depth and actionable advice. Therefore, the comment is barely helpful, as it provides some insight but does not fully assist the authors in improving their draft.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reproducibility of the results, questioning whether the code will be publicly available. While it identifies a potential issue, it does not provide any explicit or implicit suggestions on how the authors might address this concern. The comment lacks concrete guidance on what steps the authors should take to ensure reproducibility, such as providing detailed instructions or guidelines for sharing the code. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the reproducibility issue, such as proposing alternative methods for sharing the code or providing detailed instructions. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific details or examples that would help the authors understand the issue or how to address it. Without additional context or justification, the claim remains unverifiable, making the comment unsuitable for guiding the authors to improve their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. This is a critical issue for scientific research, as reproducibility is essential for validating findings. However, the comment lacks actionable guidance or suggestions on how the authors might address this concern. It does not provide any specific steps or recommendations that could help the authors improve their draft, such as proposing alternative methods for sharing the code or providing detailed instructions. As a result, the comment is barely helpful, as it identifies a significant issue but does not offer any concrete solutions or guidance for the authors to improve their work. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the claim that \"in practice the mixing time is even better\" and argues that this claim is not sufficiently supported by the experiments. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or strengthen their evidence. The comment lacks explicit instructions on what actions the authors should take to improve their draft, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about \"mixing time\" and its support by experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, stating that the evidence provided is insufficient. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional evidence or context, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. This feedback is clear and actionable, as it highlights a gap in the evidence provided to practitioners. However, the comment could be more helpful if it suggested specific ways the authors could strengthen their evidence or provide additional experimental results. Despite this, the comment offers valuable guidance for improving the paper, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. It implies that the authors should consider this extension, but it does not explicitly instruct them to do so or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should extend the feature and understand the implications of such an extension. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not offer any justification or reasoning for why this extension is necessary or beneficial. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. This feedback is specific and actionable, as it offers a clear direction for the authors to consider in their work. However, it lacks depth and does not provide detailed reasoning or guidance on why this extension is necessary or beneficial. While it offers a starting point for improvement, the comment could be more helpful if it included additional context or elaborated on the implications of such an extension. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the clarity and detail of the paper. It explicitly mentions the need to denote the vector representations of words in the equation and asks for clarification on whether these vectors are L2-normalized. Additionally, it requests information on the method used for computing nearest neighbor examples, specifically whether cosine or dot-product is used. These suggestions are clear and actionable, providing the authors with concrete steps to take to enhance the paper. The comment is fully actionable as it directly instructs the authors on what needs to be addressed and how to do so. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as denoting vector representations, clarifying normalization, and specifying the method for computing nearest neighbor examples. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of specific questions and suggestions for the authors to address, such as denoting vector representations, clarifying normalization, and specifying the method for computing nearest neighbor examples. These requests are actionable and provide clear guidance on how the authors can improve their paper. However, the comment does not include any logical reasoning, common knowledge, or external references to support the suggestions. While the suggestions are clear and actionable, the lack of supporting evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable suggestions for improving the clarity and detail of the paper. It requests the authors to clarify the vector representations used in the equation, whether these vectors are L2-normalized, and the method used for computing nearest neighbor examples (cosine or dot-product). These suggestions are clear and directly address potential ambiguities or missing details in the paper, offering the authors concrete steps to take for improvement. The feedback is detailed and constructive, making it highly helpful for the authors to enhance their draft. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It suggests that experiments should be run multiple times and that reporting statistics is essential. The comment provides a clear action for the authors to take, which is to address the reproducibility issue by running multiple experiments and reporting statistics. This explicit guidance makes the comment highly actionable, as it provides a direct path for improvement. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It suggests that experiments should be run multiple times and that reporting statistics is essential. The comment is fully grounded as it explicitly mentions the topic of deep RL experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, such as running multiple experiments and reporting statistics. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a longstanding issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It references a recent suggestion for a community effort towards reproducibility, citing a specific paper. The comment provides a logical reasoning by explaining the importance of reproducibility in deep RL and suggests that the authors should address this issue by running multiple experiments and reporting statistics. However, the comment lacks specific examples or detailed guidance on how to implement these suggestions, which could make it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It highlights a longstanding problem and suggests that the authors should address this issue by running multiple experiments and reporting statistics. The comment references a recent suggestion for a community effort towards reproducibility, providing a clear context for the importance of the issue. By emphasizing the need for reproducibility, the comment offers actionable guidance for the authors to improve the reliability and significance of their experiments. However, the comment could be more helpful if it provided specific examples or detailed instructions on how to implement the suggestions. Overall, the feedback is mostly helpful as it directs the authors towards a crucial improvement in their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the formatting of equations in the paper, noting that some end with a period while others end with a comma. It provides explicit instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. This feedback is clear and actionable, as it directly instructs the authors on what needs to be corrected. The comment is specific in its instructions, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figure 2, Line 433, and Line 468, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue with the formatting of equations, noting that some end with a period while others end with a comma. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the inconsistency in punctuation marks used at the end of equations in specific parts of the paper (Figure 2, Line 433, and Line 468). It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor issue with the formatting of equations in the paper, specifically noting that some equations end with a period while others end with a comma. This feedback is clear and actionable, as it provides specific instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. By addressing this issue, the authors can improve the clarity and professionalism of their paper. However, the comment could be more helpful if it suggested alternative punctuation marks or provided guidance on why consistency is important. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical contribution or what specific aspects need to be revised. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, it does not specify which part of the paper this comparison is made or where the similarity is discussed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying a potential issue with the technical contribution, but it lacks detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the technical contribution of the paper, noting the similarity between $kNN-ECD$ and $kNN-MT$. This observation raises concerns about the novelty and impact of the work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without actionable feedback or detailed advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is barely helpful, as it points out a potential weakness but does not provide substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the figures in Figure 1 are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon occurring in these figures. This feedback provides a clear and explicit action for the authors to take, namely to verify the nature of the figures and potentially conduct additional experiments. The comment is specific in its request for clarification and suggests a concrete way to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors should determine if the figures are generated by real experiments or artificially and, if artificially generated, conduct real-world experiments to support the phenomenon. This provides a clear direction for the authors to address the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon occurring in these figures. This feedback is somewhat verifiable as it provides a clear question and a suggestion for further investigation, but it lacks specific examples or references to support the claim. The authors would need to conduct additional research or experiments to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon occurring in these figures. This feedback is valuable as it prompts the authors to verify the authenticity of their figures and potentially strengthen their claims with empirical evidence. By addressing this concern, the authors can enhance the credibility and robustness of their work. The comment is clear, actionable, and provides a specific direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the authors were unclear about the number of parameters used in each approach, as mentioned in Section B.3. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on what specific steps the authors should take to clarify the number of parameters or how to present this information effectively. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a lack of clarity regarding the number of parameters used in each approach, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the clarity of the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a specific issue in the paper, namely the lack of clarity regarding the number of parameters used in each approach, as mentioned in Section B.3. While it identifies a potential area for improvement, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is clear and highlights a specific aspect of the paper that needs attention, but it lacks actionable advice or suggestions for improvement. Therefore, the comment is somewhat helpful, as it provides a clear indication of a problem but does not offer comprehensive guidance for resolution.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. While the comment implies that these elements are necessary for clarity, it does not explicitly instruct the authors to include them or provide guidance on how to create them. The action is implicit, as the authors can infer that they need to add an example and a figure to improve the explanation. However, the comment lacks concrete details on what specific aspects of the definition should be illustrated or how the figure should be designed. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this explanation is intended for, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion to include an example and a figure, but it lacks grounding as it does not pinpoint the specific part of the paper that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning, examples, or references to support why these elements are necessary or how they would enhance the explanation. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. While this feedback is relevant and provides a clear direction for improvement, it lacks specificity and does not offer detailed guidance on how to create or integrate these elements into the paper. The comment is somewhat helpful as it identifies a potential area for enhancement, but it does not provide actionable steps or suggestions for implementation. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the novelty of their method or what specific aspects need to be clarified or differentiated from existing methods. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, it does not specify which part of the paper this concern relates to, such as a particular section or method description. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the method's novelty, the absence of grounding information limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or examples, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, prompting the authors to consider how their method differentiates itself from existing techniques. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their method. Without actionable advice or detailed examples, the feedback is limited in its impact on the authors, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. It also highlights the importance of optimization and theoretical property analysis, noting that some conclusions or insights can be gained from this analysis. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific changes or improvements to address the issue. The authors are left without clear guidance on how to address the concern about the assumption or enhance the manuscript. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the assumption among classes, suggesting it is not practical. However, it does not specify which part of the manuscript discusses this assumption, making it difficult for the authors to identify the exact section or content being addressed. The comment is specific in its critique of the assumption but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence or justification to be considered verifiable. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption among classes, suggesting that it is not practical. It also notes that the formulation or definition in the manuscript is somewhat trivial, but highlights the importance of optimization and theoretical property analysis, which can provide valuable insights. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the manuscript. While it points out a potential area for enhancement, it does not provide actionable steps or detailed feedback that would be helpful for the authors to make meaningful improvements. Therefore, the comment is somewhat helpful, as it offers some insight but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the statistical significance of the evaluation results reported in Table 1, noting that the results are based on only three trials per case, which is not statistically significant. The comment suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the statistical significance of their results. The action is implicit and vague, as the authors are left to infer that they need to increase the number of trials or reconsider their claims. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statistical significance of the results, explaining why the reported deviations are not meaningful and why the claims made are not valid. The comment provides clear guidance on how the authors should address this issue, such as increasing the number of trials or reconsidering their claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation results in Table 1 are based on only three trials, which is not statistically significant. It argues that this lack of significance makes the reported deviations and claims about performance not meaningful. The comment provides a logical reasoning for why the results are not significant and suggests that the authors should reconsider their claims. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the statistical significance of the evaluation results reported in Table 1. It points out that the results are based on only three trials per case, which is not statistically significant, making the reported deviations and claims about performance not meaningful. The comment provides a clear rationale for why the results are not significant and suggests that the authors reconsider their claims. However, it does not offer specific guidance on how the authors might address this issue or what steps they should take to improve the statistical significance of their results. While the comment highlights a significant concern, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should include these two relevant papers in their comparison, but it does not specify how to do so or what aspects of the comparison should be addressed. Without concrete guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the issue of a shallow comparison, it lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the feature comparison section, noting that it is shallow and lacks two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing references in their comparison. However, the comment could be more helpful if it provided suggestions on how to integrate these references or what aspects of the comparison should be addressed. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, allowing the authors to enhance the depth and comprehensiveness of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This comment provides an explicit action for the authors to take, which is to reconsider their usage of the word and ensure that it is appropriate and verifiable. The action is concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the usage of the word \"equivalent\" is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word, especially if the equivalence is not verified. This provides clear guidance on what needs to be addressed in those specific parts of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should be more cautious in their usage of the word \"equivalent,\" especially if the equivalence is not verified. This comment is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the claim. While it implies that the authors should reconsider their usage, it does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their usage, especially if the equivalence is not verified. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. By recommending a more cautious approach, the comment helps the authors improve the accuracy and precision of their language, which is crucial for the clarity and credibility of their work. Therefore, the comment is highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the multi-view clustering approach, specifically questioning why other views are useful if the paraphrase similarity view performs significantly better. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a detailed analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis, but without clear references to specific sections or figures, it is difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment lacks specific examples or references to support the claim that the other views are not useful. It does not provide a clear rationale or evidence to justify the need for a detailed analysis of the differences between the views. As a result, the claim is somewhat verifiable, as it lacks sufficient evidence to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It highlights a gap in the analysis by noting that while the paraphrase similarity view performs significantly better, the other views do not provide additional insights. The comment suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. This feedback is somewhat helpful as it identifies a specific area for improvement and encourages a deeper analysis of the clustering techniques. However, it could be more helpful if it provided specific guidance on how to conduct this analysis or suggested additional empirical examples to support the claim. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors need to provide a more detailed explanation of the architecture within the paper to make it self-contained. However, the comment does not specify exactly what aspects of the architecture need clarification or how the authors should elaborate on it. While the action is implied, it is vague and lacks concrete guidance on what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of clarity in the explanation of the architecture used for the experiments, which is a specific part of the paper. It also points out that the authors refer to Jiang et al. (2019) for details, implying that the paper is not self-contained. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the architecture used for the experiments is not clearly explained in the paper, as the authors refer to Jiang et al. (2019) for details. This claim is somewhat verifiable because it highlights a lack of clarity in the explanation, but it does not provide specific examples or references to support the claim beyond the mention of Jiang et al. (2019). The authors would need to elaborate on what aspects of the architecture are unclear to address the comment effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained, and the authors rely on Jiang et al. (2019) for details. This makes the paper not self-contained, as readers may not have access to the cited work. The comment is clear and actionable, as it directs the authors to provide a more detailed explanation of the architecture within the paper. However, it could be more helpful if it suggested specific areas where the explanation could be expanded or provided with examples. Overall, the comment is mostly helpful as it highlights a critical issue and provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights an inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that maintaining consistency would be beneficial. While the comment identifies a specific issue, it does not provide explicit guidance on how to achieve consistency or what steps the authors should take to address this. The action is implicit, as the authors would need to infer that they should ensure consistent formatting of these terms. However, the lack of concrete instructions on how to implement this consistency makes the comment somewhat actionable. Therefore, this comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue of inconsistent typesetting, which is clear and specific. The comment provides a clear and actionable suggestion for improvement, making it fully grounded and specific. Therefore, this comment aligns with a score of 5: Fully Grounded and Specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the typesetting of BertScore and BLEURT throughout the paper, noting that they are inconsistently typeset as Bertscore or Bleurt. This observation is clear and actionable, as it points out a minor but noticeable inconsistency that could affect the readability and professionalism of the paper. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a specific formatting style or providing examples of consistent usage. While the feedback is somewhat helpful in identifying a minor issue, it lacks depth and actionable suggestions, making it a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests the scaling law applies to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia regarding model size. However, the comment does not explicitly instruct the authors to provide these results or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests the scaling law applies to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia regarding model size. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in its suggestion to provide detailed results, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests the scaling law applies to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia regarding model size. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to infer the need for more detailed results, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests the scaling law applies to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia regarding model size. While the comment identifies a potential issue with the experimental setup, it does not offer specific guidance on how to address this concern or what additional experiments might be necessary. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies several specific issues with the presentation quality of the paper, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the presentation. The actions are implicit and vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 1&2,\" \"tables with a \\\"-\\\" for the method,\" \"the \\\"Dataset\\\" columns in the tables,\" \"the management of Fig 3 and Table 2,\" and a \"*\" in Table 1. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details several issues with the presentation quality, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some aspects of the presentation quality in the paper are weaknesses for a high-quality publication, such as NeurIPS. It provides specific examples of issues, including the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. However, the claim lacks detailed reasoning or references to support why these issues are significant or how they impact the paper's quality. The comment is somewhat verifiable as it provides some justification but lacks depth and specific examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific weaknesses in the presentation quality of the paper, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. While the comment provides a clear overview of these issues, it lacks detailed guidance on how the authors might address them or what specific improvements could be made. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper uses analysis to justify the use of the information axis as a tool. It also points out that the conclusion mentions the need for related experiments to demonstrate the tool's effectiveness. However, the comment does not provide explicit guidance on how the authors should conduct these experiments or what specific aspects of the information axis tool need to be explored. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper uses much analysis to justify the use of the information axis as a tool. It also mentions that the conclusion points out the need for related experiments to demonstrate the tool's effectiveness. However, the comment does not specify which part of the paper this analysis or justification is located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, while the comment implies the need for related experiments, it does not provide specific guidance on what those experiments should entail or how they should be conducted. This lack of specificity and grounding makes the comment weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper uses much analysis to justify the use of the information axis as a tool. It also mentions that the conclusion points out the need for related experiments to demonstrate the tool's effectiveness. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the criticism. Without clear reasoning or references, the claim is considered borderline verifiable, as it provides some context but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could benefit from additional experiments to demonstrate the effectiveness of the information axis tool. It points out that the conclusion mentions the need for related experiments, which implies that the current analysis might not be sufficient to fully justify the use of the tool. However, the comment lacks specific guidance on what kind of experiments would be beneficial or how the authors should approach them. While it provides a direction for improvement, the feedback is somewhat vague and could be more helpful if it included suggestions for specific experiments or analyses. Therefore, the comment is rated as somewhat helpful, as it offers a clear direction but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question relates to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it does not provide explicit references or context. Additionally, it does not specify what the authors should do to address this question or how it relates to the paper's content. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how it relates to their work. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific feedback, suggestions, or insights on how the authors might address this question or what steps they should consider. The comment lacks actionable guidance or depth, leaving the authors with limited information to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the text in lines 293-295 is unclear and difficult for readers to understand and evaluate. It suggests that the authors should clarify this section by providing more context or explanation. However, the comment does not specify how the authors should clarify the text or what specific aspects need to be addressed. The action is implicit and vague, as it requires the authors to infer the need for clarification and then decide how to implement it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 293-295, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the text in these lines is unclear and difficult for readers to understand and evaluate, suggesting that the authors should clarify the section by providing more context or explanation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 is unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the text is unclear or how to improve its clarity. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text in lines 293-295, noting that it is unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should clarify this section by providing more context or explanation. While the feedback is specific about the problematic text, it lacks detailed guidance on how to improve the clarity or what specific aspects of the text need clarification. This makes the comment somewhat helpful, as it provides a clear area for improvement but could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the organization and clarity of the proofs in the paper, noting that many proofs lack clean logic and are difficult to follow. It provides a specific example, asking whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. While the comment identifies a clear area for improvement, it does not provide explicit guidance on how the authors should reorganize the proofs or address the lack of clarity. The action is implicit, as the authors would need to infer that they should improve the organization and logic of the proofs. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the organization and clarity of the proofs, providing a clear example of what needs to be addressed. The comment specifies that the proofs lack clean logic and are hard to follow, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is \"extremely not well organized\" and that many proofs lack \"clean logic and are very hard to follow,\" making it difficult to rigorously check the correctness of the proof. The comment provides a specific example, asking whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. However, the claim lacks detailed reasoning or examples to fully substantiate the assertion about the organization and clarity of the proofs. While the comment provides a basis for improvement, it does not offer a comprehensive explanation or evidence to support the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proofs in the paper, noting that many proofs lack clean logic and are difficult to follow, which hinders the rigorous checking of their correctness. The comment provides a specific example, asking whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$, which highlights a potential area of confusion or lack of clarity. While the comment points out a critical issue, it does not offer detailed guidance or suggestions on how the authors might improve the organization or logic of the proofs. This feedback is somewhat helpful as it directs the authors to areas needing attention, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by incorporating experiments on real-world datasets. The comment is specific in its recommendation, detailing what kind of experiments would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. However, it does not specify which part of the paper discusses the experiments or the out-of-distribution setting, making it difficult for the authors to identify the exact section or part that needs revision. While the comment is specific about the type of experiments, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This claim is somewhat verifiable as it provides a logical reasoning for why real-world datasets might be more appropriate for evaluating the paper's claims. However, it lacks specific examples or references to support the suggestion, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This feedback is valuable as it highlights a potential gap in the paper's evaluation methodology. By recommending the use of real-world datasets, the authors can better assess the practical applicability and robustness of their proposed approach. However, the comment could be more helpful if it provided specific examples of real-world datasets or guidance on how to conduct these experiments. Overall, the comment is somewhat helpful as it identifies an important area for improvement but lacks detailed suggestions or examples, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207-210) on the single image case. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to clarify the explanation or what specific aspects need to be improved. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. Additionally, the comment is vague and does not provide specific guidance on what needs to be addressed or improved. Therefore, it is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207-210) on the single image case. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the explanation is vague or how it could be improved. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of some explanations, specifically mentioning the last paragraph of Section 3 (lines 207-210) on the single image case. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the clarity of these explanations. Without additional details or constructive feedback, the authors are left without a clear path to address the identified issue. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. While the comment implies that this extension would be more interesting and practical, it does not provide explicit guidance on how to implement this extension or what specific aspects of the current study need to be addressed to make this extension feasible. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion to extend the study, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical suggestion that aligns with the idea of making the study more interesting and practical. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains somewhat verifiable, as it is based on logical reasoning but lacks detailed backing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical and interesting suggestion that could enhance the practicality and relevance of the study. However, the comment does not provide specific guidance on how to extend the study or what aspects of the current work need to be addressed to make this extension feasible. While it offers a potential direction for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their approach or what specific aspects need to be improved. Without concrete suggestions or actions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. The comment is specific in its critique of novelty but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. This claim is somewhat verifiable as it provides a basis for comparison with a well-known approach, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors could benefit from additional context or references to support the assertion of limited novelty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the proposed approach to pretraining, noting that it closely resembles the strategies used in ELECTRA. While the comment highlights a specific concern, it does not provide detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the motivation for the Newton algorithm in section 4 is lacking, noting that it is essentially a 1-dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm's runtime and suggests that experiments could help motivate the need for the analysis/algorithm. While the comment implies that the authors should consider adding experiments to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct experiments to strengthen the motivation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation for the Newton algorithm in section 4, which is a specific part of the paper. It provides a detailed critique of the motivation, suggesting that it is lacking and that the algorithm is essentially a 1-dimensional line search on a convex function. The comment also questions the impact of this on the algorithm's runtime and suggests that experiments could help motivate the need for the analysis/algorithm. This provides clear guidance on what needs to be addressed in section 4, making the comment fully grounded. Additionally, it specifies the issue with the motivation and suggests a way to improve it, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation for the Newton algorithm in section 4 is lacking, suggesting that it is essentially a 1-dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm's runtime and suggests that experiments could help motivate the need for the analysis/algorithm. However, the comment lacks specific examples or references to support the claim that the motivation is lacking or that the algorithm is a simple line search. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper, section 4, where the motivation for the Newton algorithm is lacking. It critiques the algorithm as essentially a 1-dimensional line search on a convex function, which converges linearly, and questions the impact of this on the algorithm's runtime. The reviewer suggests that experiments could help motivate the need for the analysis and algorithm. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a way to address the identified weakness. However, it could be more helpful if it included more detailed guidance on how to conduct the suggested experiments or what specific experiments would be most effective. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary to make the results more idiom-specific. The action is implicit and vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed upweighing and KNN methods, specifically mentioning the results presented in Figure 3. It critiques the similarity of the impact of these methods on idiomatic vs. random data, suggesting that the results may not be specific to idiomatic translations. However, the comment does not explicitly mention which part of the paper Figure 3 is located in, making it weakly grounded. The comment is specific in detailing the issue with the methods and the interpretation of the results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. The comment provides a logical reasoning by pointing out the similarity in impact across different language and score combinations, as illustrated in Figure 3. However, it lacks specific examples or references to support the claim that the results are not idiom-specific. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a basis for further investigation but does not fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. The comment provides a logical reasoning by pointing out the similarity in impact across different language and score combinations, as illustrated in Figure 3. However, the feedback lacks specific suggestions or guidance on how the authors might address this issue or improve the results to be more idiom-specific. While the comment identifies a potential weakness in the methodology, it does not offer actionable steps or detailed insights for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it provides some insight but could be more comprehensive and actionable.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the consistency of the number of biases across different parts of the paper, specifically noting that the authors mention having C biases in section 3.4 but only find one hyper-parameter for the feed-forward models. This feedback is explicit and provides a clear action for the authors to take: they should clarify the discrepancy in the number of biases and ensure consistency throughout the paper. The comment is specific and actionable, as it directly points out a potential issue and suggests a concrete step for the authors to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 77,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the number of biases, which is a clear and specific concern. The comment provides a clear direction for the authors to address the confusion regarding the number of biases, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the consistency of the number of biases across different parts of the paper, specifically questioning why the authors mention having C biases in section 3.4 but only find one hyper-parameter for the feed-forward models described in section 3.4. The comment is somewhat verifiable as it provides a specific observation about the inconsistency in the number of biases, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the consistency of the number of biases across different parts of the paper. It points out that while the authors mention having C biases in section 3.4, they only find one hyper-parameter for the feed-forward models described in the same section. This inconsistency creates confusion and suggests that the authors need to clarify their approach to handling biases. The comment is clear and actionable, providing a direct suggestion for the authors to address the discrepancy. However, it could be more helpful if it offered additional guidance on how to resolve the issue or suggested specific ways to ensure consistency throughout the paper. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that subtracting dynamic factors from dynamic information in Equation 8 might lead to the loss of some dynamic information, which could hinder the LSTM module's ability to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the equation. The action is implicit, as the authors would need to infer that they should consider alternative approaches or modifications to the equation to mitigate the potential loss of dynamic information. The lack of concrete suggestions or detailed guidance makes the action somewhat vague and challenging to implement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to Equation 8, which is a part of the paper. It highlights a potential problem with subtracting dynamic factors from dynamic information, suggesting that it might lead to the loss of some dynamic information, thereby affecting the LSTM module's ability to capture complete dynamic changes. This provides clear grounding as the authors can easily identify the part of the paper being addressed. The comment is also specific, as it details the issue with Equation 8 and suggests a potential consequence. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that subtracting dynamic factors from dynamic information in Equation 8 might result in the loss of some dynamic information, which could hinder the LSTM module's ability to capture complete dynamic changes. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically suggesting that subtracting dynamic factors from dynamic information might lead to the loss of some dynamic information, which could affect the LSTM module's ability to capture complete dynamic changes. While the comment highlights a specific area that requires attention, it does not provide detailed guidance or suggestions on how to address this issue. The authors would need to infer that they should consider alternative approaches or modifications to the equation to mitigate the potential loss of dynamic information. The feedback is somewhat helpful as it points out a potential problem, but it lacks depth and actionable advice, making it only partially beneficial for the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how to address these questions or what experiments to conduct to explore these effects. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insights that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it identifies areas that could be explored further, it does not provide specific guidance or suggestions on how to address these questions or what experiments to conduct. The feedback is somewhat helpful as it points out potential areas for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests showing smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any explicit or implicit guidance on how to implement this suggestion, such as which specific elements of the figures should be highlighted or how the smoothing process should be visualized. The action is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5, which provides some grounding as it mentions specific figures. However, it does not specify which parts of the figures should be highlighted or how the smoothing process should be visualized, making the comment specific but lacking in detail. The authors can infer that the issue is related to the clarity of the figures but cannot fully understand the scope of the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the understanding of the reconstruction quality. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. While this feedback is relevant and could improve the clarity of the paper, it lacks depth and specificity. The comment does not provide detailed guidance on how to present the smoothed shapes or why they are important for understanding the reconstruction quality. Without additional context or suggestions, the authors may struggle to fully address the feedback. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the evaluation of the proposed approach by noting the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it does not provide explicit guidance on how to conduct a direct comparison of test accuracy. The action is implicit, as the authors are expected to infer that they need to include a direct comparison of test accuracy to demonstrate the improvement of the proposed approach over the baseline. However, the lack of concrete instructions on how to perform this comparison makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of direct comparisons with the prior approach PRANC in both language and vision tasks, and the lack of a direct comparison of test accuracy. This provides the authors with a clear understanding of what needs to be addressed to strengthen the evaluation of the proposed approach. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no direct comparisons with the prior approach PRANC in either the language or vision tasks used to evaluate the proposed approach. It mentions comparisons of training loss and the rank of possible solutions but notes that without a direct comparison of test accuracy, it is unclear if the approach is an improvement over the baseline. The claim is somewhat verifiable as it provides some evidence of comparisons but lacks detailed examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment acknowledges comparisons of training loss and the rank of possible solutions, it highlights the critical issue of test accuracy, which is essential for demonstrating the improvement of the proposed approach over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or suggested additional metrics for evaluation. Overall, the comment is mostly helpful, as it effectively guides the authors to address a key weakness in their work.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It points out that the paper mentions selecting 21 event types from Freebase but does not explain how these were chosen or what the coverage is on the 33 event types in the ACE data. While the comment identifies a potential issue and asks for clarification, it does not provide explicit guidance on how the authors should address these concerns or what steps they should take to improve the draft. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It specifically mentions Section 2 line 262, which discusses the selection of 21 event types from Freebase, and asks about the coverage on the 33 event types in the ACE data. This provides full grounding as the authors can accurately identify the section and line being addressed. The comment is also specific, as it clearly specifies what needs to be addressed regarding the selection and coverage of event types. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It specifically mentions Section 2 line 262, which discusses the selection of 21 event types from Freebase, and asks about the coverage on the 33 event types in the ACE data. However, the comment does not provide any justification or reasoning for why these concerns are valid or how they might be addressed. Without additional context or explanation, the authors are left to interpret the concern and its implications, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It points out that the paper mentions selecting 21 event types from Freebase but does not explain how these were chosen or what the coverage is on the 33 event types in the ACE data. This feedback highlights a potential gap in the paper's discussion and suggests that the authors should provide more details to address these concerns. However, the comment lacks specific guidance on how the authors might improve their draft to address these issues, making it somewhat helpful. The authors are left to infer the necessary steps, which limits the comment's impact. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments on generation tasks that are more likely to require a well-performing language model, such as language modeling, machine translation, or text summarization. It also points out that the current experiments on word similarity and SquAD do not adequately reflect the language modeling capability. The comment provides clear guidance on what additional experiments the authors should include to strengthen the paper. This feedback is explicit and concrete, as it directly instructs the authors on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments conducted in section 5.3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, suggesting that the authors should include tasks like language modeling, machine translation, or text summarization to better reflect the language modeling capability of pre-trained models. This provides clear guidance on what additional experiments would strengthen the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments conducted in section 5.3 do not adequately reflect the language modeling capability of pre-trained models, suggesting that additional experiments on tasks like language modeling, machine translation, or text summarization would be more appropriate. While the comment provides a rationale for why these additional tasks are relevant, it lacks specific examples or references to support the claim. The reasoning is logical but could be strengthened with more detailed justification or evidence. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the experiments conducted do not fully reflect the importance of language modeling capability in pre-trained models. It suggests that the authors should include additional experiments on tasks such as language modeling, machine translation, or text summarization to better demonstrate the relevance of their findings. This feedback is clear and actionable, providing the authors with specific directions for improving their draft. However, the comment could be more helpful if it included examples of how these additional experiments would be conducted or why they are crucial for validating the paper's claims. Overall, the comment is mostly helpful, as it offers valuable insights and guidance for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the mixed use of notations $\\hat{Y}$ and $Y$ in Section 2. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks concrete guidance on what needs to be done to ensure consistency in notation usage. Without specific instructions or examples, the authors are left without a clear path to resolve the problem. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out an issue with the mixed use of notations $\\hat{Y}$ and $Y$ in Section 2. However, it does not specify which part of Section 2 is affected, making it difficult for the authors to pinpoint the exact issue. The comment is weakly grounded as it does not provide enough context for the authors to accurately identify the section being addressed. Additionally, it lacks specificity in detailing what needs to be addressed regarding the inconsistent notation usage. Therefore, this comment is weakly grounded and not specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the notations of $\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, the comment does not provide any specific examples or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mixed use of notations $\\hat{Y}$ and $Y$ in Section 2. While it points out a specific area that needs attention, it lacks detailed guidance or suggestions on how the authors might address this inconsistency. The comment is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable steps or examples to help the authors resolve the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks important references for domain adaptation. It suggests that the authors should cite and discuss these references in the revised manuscript. This feedback is explicit and provides a clear action for the authors to take, which is to include and discuss relevant references. The comment is specific in its suggestion, guiding the authors on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation,\" allowing the authors to accurately identify the part of the paper that needs improvement. It is also specific because it clearly specifies the issue, which is the lack of important references for domain adaptation. The authors know exactly what needs to be addressed in the revised manuscript, making this comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation. However, it does not provide any specific examples or references to support this claim. Without additional context or references, the authors may find it challenging to understand the specific areas where the paper is lacking. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the lack of important references for domain adaptation. It provides a clear and actionable suggestion for improvement by recommending that the authors cite and discuss these references in the revised manuscript. This feedback is specific and directly addresses a critical aspect of the paper, making it highly helpful for the authors to enhance their work. The comment is clear, concise, and provides a direct path for improvement, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of EMA-weighting in other baseline models, specifically \"Supervised\" and \\Pi, and suggests that it would be beneficial to know if all models being compared utilize EMA benefits for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or detailed guidance on how to implement this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should check and clarify the use of EMA-weighting in the baseline models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the use of EMA-weighting in other baseline models and the need for a fair comparison. The comment requests clarification on whether EMA-weighting is used for models like \"Supervised\" and \\Pi, and suggests that this information should be included to ensure a fair comparison. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of EMA-weighting in baseline models, specifically \"Supervised\" and \\Pi, and suggests that it would be beneficial to know if all models being compared utilize EMA benefits for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not provide any specific examples, references, or detailed reasoning to support the claim that this information is necessary. The lack of explicit justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the use of EMA-weighting in baseline models, such as \"Supervised\" and \\Pi, and suggests that it would be beneficial to know if all models being compared utilize EMA benefits for a fair comparison. This feedback is clear and actionable, as it points out a potential area for clarification that could enhance the fairness and rigor of the comparison. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific ways to ensure a fair comparison. Overall, the comment is mostly helpful, as it identifies a meaningful aspect of the draft that needs attention and provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the suspicious performance of the SCNN model on domain pricing, suggesting that it might be due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to investigate or resolve the concern. The suggestion for presentation is vague and lacks concrete details. Therefore, the comment is not actionable, as it does not provide clear instructions or guidance on how the authors can improve their draft. The comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the SCNN model's performance on domain pricing, suggesting that it might be \"lucky\" and questioning the chosen hyperparameters. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is vague and does not provide detailed guidance on what needs to be addressed. Therefore, the comment is not grounded, as the authors cannot confidently determine which part of the paper it addresses, and it is also not specific, as it lacks detailed information about the issue. This aligns with a score of 1: Not Grounded and Not Specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the suspicious performance of the SCNN model on domain pricing, suggesting that it might be due to hyperparameter tuning. However, the comment lacks specific evidence or references to support the claim that the chosen hyperparameters are at the end of the searched range or that the distance to the next best model is suspiciously large. Without detailed reasoning or examples, the claim remains speculative and difficult to verify. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the suspicious performance of the SCNN model on domain pricing, suggesting that it might be due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they should take to investigate or resolve the concern. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or how the authors should address these issues. The comment lacks concrete actions or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which parts of the paper these issues relate to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific about the nature of the issues, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what specific issues need to be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity and motivation of the experimental setup, specifically mentioning corpora and datasets. However, it lacks detailed guidance or suggestions on how to address these issues. The comment is vague and does not provide specific examples or actionable steps for the authors to take, making it somewhat helpful. While it highlights an area for improvement, it does not offer a comprehensive or constructive response, leaving the authors with limited actionable feedback. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern that the proposed method's improvement over existing RL methods is not impressive. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks concrete guidance on how the authors might enhance their method or present it more effectively to demonstrate its superiority. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the improvement are not impressive or how the authors might address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, the comment lacks specific details or evidence to support this claim. It does not provide any examples, references, or logical reasoning to substantiate the assertion that the improvement is not impressive. Without further context or justification, the authors are left without a clear understanding of why this claim is made or how it might be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concern about the improvement of the proposed method over existing RL methods, suggesting that it is not impressive. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance their method. It does not provide actionable feedback or guidance on what aspects of the method could be improved to demonstrate its superiority. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It also notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is explicit and provides a clear action for the authors to take: they should provide more detailed information about the size of each hourglass module. However, the comment lacks specific guidance on how to measure or compare the size of the model, making it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This provides a clear reference to a specific part of the paper, allowing the authors to identify the relevant section. However, the comment does not specify what needs to be addressed in this part, such as how the model size compares to competing approaches or how the size of each module was determined. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This feedback is clear and provides a specific question that the authors should address to improve the clarity and completeness of their paper. However, it does not offer any additional context or justification for why this information is important or how it relates to the overall work. Therefore, the comment is somewhat verifiable, as it provides a clear question but lacks depth in terms of supporting evidence or reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, particularly noting that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the model's architecture, which is crucial for understanding and replicating their work. However, the comment could be more helpful if it suggested specific ways to measure or compare the model size with competing approaches. Despite this, the feedback is mostly helpful as it directs the authors to a critical aspect of their draft that needs clarification and detail.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the dimensions of the projection matrices in Section 1.2, suggesting that the current dimensions might be incorrect. The reviewer provides a potential correction, indicating that the dimensions should be $A_i \\in \\mathbb{R}^{d_i \\times m_i}$ to allow projection of a tensor $T \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots d_p}$. However, the comment does not explicitly instruct the authors to make this change or provide further guidance on how to verify the correctness of the dimensions. While the action is implied, it is vague and lacks detailed instructions on how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dimensions of the projection matrices, suggesting a potential correction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the dimensions of the projection matrices in Section 1.2, suggesting that the current dimensions might be incorrect. The reviewer provides a potential correction, indicating that the dimensions should be $A_i \\in \\mathbb{R}^{d_i \\times m_i}$ to allow projection of a tensor $T \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots d_p}$. However, the comment lacks detailed reasoning or examples to support the claim that the current dimensions are indeed incorrect or why the suggested dimensions are necessary. Without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the dimensions of the projection matrices in Section 1.2, suggesting that the current dimensions might be incorrect. It provides a potential correction, indicating that the dimensions should be $A_i \\in \\mathbb{R}^{d_i \\times m_i}$ to allow projection of a tensor $T \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\ldots d_p}$. However, the comment does not offer detailed reasoning or examples to support the claim that the current dimensions are indeed incorrect or why the suggested dimensions are necessary. While it provides a clear direction for improvement, the lack of detailed justification or guidance makes it somewhat helpful. The authors would need to infer the reasoning behind the suggestion, which could be improved with additional explanation. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that the proposed method, PACE, addresses a gap by treating climate emulation as a diagnostic-type prediction. It points out that prior work, such as ClimateBench or ClimateSet, has already explored this area. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the distinction between their work and existing research. The action is implicit, as the authors need to infer that they should either clarify the novelty of their approach or acknowledge the prior work. The comment is vague in its suggestion, as it does not provide concrete steps on how to address the issue or what specific aspects of the prior work need to be discussed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim being made in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is misleading about the claim, pointing out that prior work, such as ClimateBench or ClimateSet, has already addressed the same gap. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper's claim about addressing a gap by proposing PACE as a diagnostic-type prediction is misleading because prior work, such as ClimateBench or ClimateSet, has already done this. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how the prior work differs from the proposed method. Without this additional information, the claim remains somewhat verifiable, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the claim made in the paper, specifically questioning the novelty of the proposed method, PACE, in addressing a gap in climate emulation. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts. This feedback is somewhat helpful as it highlights a potential area of overlap or lack of novelty that the authors should consider. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or clarify the distinction between their work and existing research. Without actionable advice, the authors may struggle to fully understand how to improve their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the metric learning theory in the paper, suggesting that it is not novel or better than existing theoretical results. It implies that the authors should consider how to improve the metric learning aspect of their work. However, the comment does not provide specific guidance on what changes or improvements could be made to address the identified issue. The action is implicit and vague, as the authors are left to infer that they need to enhance the metric learning section. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the metric learning theory in the paper, referencing the generalization theory of neural networks and suggesting that the proposed metric perspective analysis does not offer better results compared to previous theoretical findings. It implies that the part of metric learning in the paper does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in its critique of the metric learning theory but lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is not novel or better than existing theoretical results, citing the generalization theory of neural networks. It suggests that the proposed metric perspective analysis does not yield better results compared to previous findings. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of references or detailed explanations weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the metric learning theory in the paper, noting that it is not novel or better than existing theoretical results. It suggests that the proposed metric perspective analysis does not yield better results compared to previous findings, implying that the part of metric learning in the paper does not seem to work. While the comment identifies a potential weakness in the paper's theoretical contribution, it lacks specific guidance or suggestions on how the authors might address this issue or improve the metric learning aspect. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a key experiment. It also recommends condensing the current figures to make space for these visual results. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on which figures to move or how to condense them. The action is somewhat vague, as the authors need to infer which figures to move and how to condense them to effectively utilize the space. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a key experiment. It also recommends condensing the current figures to make space for these visual results. However, the comment does not specify which figures are being referred to or how they should be condensed, making it weakly grounded. The suggestion is specific in terms of addressing the lack of visual results on crowd density estimation, but the lack of detail on which figures to move or how to condense them makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a key experiment. It also recommends condensing the current figures to make space for these visual results. While the comment provides a clear rationale for the suggestion, it lacks specific examples or references to support the claim that the main paper lacks visual results on crowd density estimation. The suggestion is logical and well-reasoned, but the absence of detailed examples or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the organization of the paper, suggesting that visual results from the supplementary material should be moved to the main paper. It highlights the lack of visual results on crowd density estimation, a key experiment, and recommends condensing the current figures to make space for these visual results. This feedback is actionable and constructive, as it guides the authors on how to improve the presentation of their results and enhance the clarity of their main paper. However, the comment could be more helpful if it provided more detailed guidance on which figures to move or how to condense them. Overall, the comment is mostly helpful, as it offers clear suggestions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential confusion in the notation used in the paper, specifically mentioning the use of 'r' to denote both the risk for minimization problems and primal risk for minimax problems. While the comment highlights a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out a specific issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the notation used in the paper, mentioning the potential confusion with the use of 'r' to denote both the risk for minimization problems and primal risk for minimax problems. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the notation section. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using 'r' to denote both the risk for minimization problems and primal risk for minimax problems is confusing. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this confusion arises or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation used in the paper, specifically the use of 'r' to denote both the risk for minimization problems and primal risk for minimax problems. This observation highlights a potential source of confusion for the readers, as it could lead to misunderstandings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their notation. While it points out a specific area for attention, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should clarify the notation, but without further guidance, the feedback is limited in its impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of test examples and suggests exploring whether differences in the corpus (e.g., British vs. American) could affect the results. However, it does not provide explicit guidance on how to address this issue or what actions the authors should take to investigate it. The comment is vague and lacks concrete suggestions, making it difficult for the authors to understand how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of test examples and suggests exploring whether differences in the corpus (e.g., British vs. American) could affect the results. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors may infer that it relates to the discussion of test examples or the analysis of corpus residual value, but the lack of explicit mention makes it weakly grounded. The comment is specific in its question about the impact of corpus differences, but without clear grounding, it is difficult for the authors to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of test examples and suggests exploring whether differences in the corpus (e.g., British vs. American) could affect the results. However, it does not provide any specific reasoning, examples, or references to support the claim that this is a crucial issue. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the importance of test examples and suggests exploring whether differences in the corpus could affect the results. It specifically mentions an example involving a 'British' patient and an 'American corpus,' which highlights a potential issue with the generalizability of the findings. However, the comment does not provide any guidance or suggestions on how to address this concern or what actions the authors should take to investigate it. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful. The authors would need to infer the need for further analysis and exploration, which limits the comment's overall impact.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not explicitly instruct the authors to change the dataset or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the suggested dataset and understand the reasoning behind it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not specify which part of the paper discusses the choice of the testbed dataset, making it difficult for the authors to identify the exact section being addressed. While the suggestion is specific, the lack of grounding makes it challenging for the authors to understand the context and apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. The reasoning provided is that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions is more intuitive or straightforward for weak supervision tasks. Without detailed justification or evidence, the claim is somewhat verifiable, as it provides a rationale but lacks depth and clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of the testbed dataset, suggesting that the authors consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. The rationale provided explains that WebQuestions is more intuitive and straightforward for weak supervision tasks, which would facilitate direct comparison with mainstream QA research. This feedback is clear and actionable, as it provides a specific suggestion for improvement and offers a rationale for why the change might be beneficial. However, the comment could be more helpful if it included additional guidance on how to implement the change or why WebQuestionsSP was initially chosen. Overall, the comment is mostly helpful, as it provides valuable insights and actionable feedback that can guide the authors in enhancing their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It also implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it does not specify how to demonstrate the benefits of sparsity or how to make the claims more convincing. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not specify which part of the paper discusses sparsity or training, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of sparsity and its relevance, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for questioning the claims but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific guidance or suggestions on how to address this issue or what additional evidence might be needed to support the claims. While it raises a valid point about the need for demonstration, it lacks actionable advice or detailed feedback on how to improve the draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer substantial guidance for the authors to enhance their work.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not provide any specific suggestions or actions for the authors to take to address this issue or enhance the novelty of their work. The comment lacks explicit guidance on how the authors might improve their design or what specific aspects need to be revised to make it more novel. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not specify which part of the paper this claim is related to, such as the introduction, methodology, or results sections. Without this context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the novelty of the design. Therefore, the comment is not grounded and lacks specificity, making it ungrounded and not specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, the comment does not provide any specific evidence or references to support this claim, such as examples of similar work or detailed explanations of how the design aligns with existing approaches. Without this additional context, the authors may find it difficult to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the design, suggesting that it is based on the use of attention for motion learning, which has been widely used in video understanding. This feedback highlights a concern that the authors may need to address to enhance the originality of their work. However, the comment lacks specific suggestions or guidance on how the authors might improve the novelty of their design or address the identified limitation. Without actionable advice or detailed examples, the authors may find it challenging to understand how to respond to this feedback effectively. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet-1k, and ImageNet-100. It implies that these results should ideally be presented in the main paper. However, the comment does not provide explicit guidance on how to conduct this analysis or present the results, leaving the authors to infer the necessary steps. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include an analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet-1k, and ImageNet-100. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its suggestion to include results on these datasets, but the lack of explicit mention of the paper section makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks analysis or results on other datasets, specifically mentioning ImageNet derivatives, ImageNet-1k, and ImageNet-100. While the comment suggests that these results should ideally be presented in the main paper, it does not provide specific examples or references to support the claim that the current analysis is insufficient. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the need for additional analysis based on the provided information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should include an analysis or results on other datasets, such as ImageNet derivatives, ImageNet-1k, and ImageNet-100. This feedback is valuable as it highlights a gap in the current analysis and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or presented examples of how such results might be presented. Despite this, the comment provides actionable feedback that encourages the authors to expand their analysis, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the model design and learning details, noting that they are fragmented or missing. It suggests that the authors could provide a model illustration plot, pseudo-code table, or code repository to address this issue. The comment is explicit in identifying the need for additional details and provides concrete suggestions on how to improve the clarity of the model design. By offering specific examples of what could be included, the authors are given clear guidance on how to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of unclear model design and learning details, suggesting that the authors could provide a model illustration plot, pseudo-code table, or code repository. However, it does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing visual aids or detailed descriptions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model architecture and learning details are fragmented or missing, suggesting that the authors could provide a model illustration plot, pseudo-code table, or code repository. While the comment provides some guidance on what could be included, it lacks specific examples or references to support the claim that these details are indeed missing or fragmented. The suggestion to provide additional details is logical and helpful, but the lack of concrete evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design and learning details, noting that they are fragmented or missing. It provides specific suggestions for improvement, such as including a model illustration plot, pseudo-code table, or code repository. This feedback is actionable and constructive, as it guides the authors on what additional information is needed to enhance the clarity and reproducibility of their work. By offering concrete examples of what could be included, the comment empowers the authors to address the identified weakness effectively. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the initial mention of BigFive and MBTI as models in the Abstract and Introduction sections and their subsequent use as datasets in the Experiments section. It suggests that the authors should either extend their explanation for using these as models or state them as datasets throughout the paper. While the comment identifies a specific issue and provides a clear direction for addressing it, it does not offer detailed guidance on how to extend the explanation or what specific aspects of the models should be discussed. The action is explicit but somewhat vague, as it leaves the authors with a general idea of what needs to be done but lacks concrete steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Abstract and Introduction sections where BigFive and MBTI are initially presented as models, and the Experiments section where they are used as datasets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue: the discrepancy between the initial mention of BigFive and MBTI as models and their use as datasets in the experiments. It suggests that the authors should either extend their explanation or state them as datasets throughout the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that BigFive and MBTI are initially presented as models in the Abstract and Introduction sections but are used as datasets in the Experiments section. This observation is based on a direct comparison of the content in these sections. The comment suggests that the authors should either extend their explanation or state them as datasets throughout the paper. While the claim is based on factual observation, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the authors to address the issue but does not offer comprehensive support or detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant discrepancy in the paper, noting that Big Five and MBTI are initially presented as models in the Abstract and Introduction but are later used as datasets in the Experiments section. This observation highlights a potential inconsistency in the paper's presentation and suggests that the authors should either provide a more detailed explanation of why these tools are treated as models initially or consistently use them as datasets throughout the paper. The comment is clear and actionable, offering a specific direction for the authors to address the issue. However, it could be more helpful if it provided additional guidance on how to extend the explanation or what specific aspects of the models should be discussed. Overall, the comment is mostly helpful as it effectively points out a critical issue and provides a clear path for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. While the comment provides a clear action\u2014either to include rejection rates or to consider misclassifications as rejections\u2014it does not specify how to implement this action. The authors are left with a general direction but lack concrete guidance on how to incorporate rejection rates into their results or how to justify viewing misclassifications as rejections. Therefore, the comment is somewhat actionable, as it provides an explicit action but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. However, it does not specify which part of the paper this issue pertains to, such as the results section or a specific table. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment is specific in its suggestion to include rejection rates or view misclassifications as rejections, but without a clear reference to the relevant section, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the rejection rate is not shown in any experiments and suggests that it could be viewed as misclassifications. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification for why rejection rates are not included or why misclassifications should be considered as rejections. Without this additional context, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that misclassifications could be viewed as rejections, which is a valuable insight for the authors to consider. However, the comment lacks actionable guidance on how to include rejection rates or how to justify viewing misclassifications as rejections. While it points out a potential area for improvement, it does not provide detailed steps or suggestions for addressing the issue, making it somewhat helpful. The authors would need to infer how to incorporate this feedback into their work, which limits the comment's overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the generalization to specific TSP instances, particularly the fine-tuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalization to specific TSP instances, particularly the fine-tuning step in DIMES. It suggests that the authors should clarify the differences between DIMES and other methods, especially in the context of TSP100 in-distribution testing performance with and without meta-learning. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what needs to be addressed, such as clarifying the generalization and comparing DIMES with other methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the need to clarify the generalization to specific TSP instances, particularly the fine-tuning step in DIMES. It suggests that the authors should compare DIMES with other methods on TSP100, both with and without meta-learning. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, as it does not provide detailed guidance on how to address the issue or what specific aspects of the comparison should be highlighted. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claim but lacks sufficient detail and support.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by suggesting that the authors clarify the generalization to specific TSP instances, particularly the fine-tuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning, which could provide valuable insights. However, the comment lacks detailed guidance on how to implement these suggestions or what specific aspects of the comparison should be emphasized. While it provides a clear direction for improvement, the feedback could be more helpful if it included specific examples or detailed instructions on how to conduct the comparison. Therefore, the comment is somewhat helpful, as it offers a clear idea of what needs to be addressed but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on which thresholds or hyperparameters to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on the final thresholds used and suggests sharing the full set of hyperparameters for reproducibility. This provides clear guidance on what needs to be addressed and why. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification and additional information regarding the thresholds used in the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by asking for clarification on the final thresholds used in the results and suggesting that sharing the full set of hyperparameters would enhance reproducibility. While it does not provide detailed guidance on how to determine the thresholds or which hyperparameters to include, it does offer a clear direction for the authors to improve the transparency and reproducibility of their work. However, the comment could be more helpful if it provided additional suggestions or examples of how to address these issues. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential nuance in the original claim, it does not provide explicit guidance on how the authors should address this issue or what specific features they should consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of different features on question difficulty. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. While the comment provides some specificity by mentioning the potential influence of features, it lacks full grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. The comment provides a specific example of a potential factor that could affect the conclusion, offering a clear rationale for why the original claim might be incomplete or misleading. This level of detail and specificity makes the claim mostly verifiable, as it provides a logical basis for the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. This feedback is somewhat helpful as it identifies a potential nuance in the original claim and provides a specific example of a factor that could affect the conclusion. However, the comment could be more helpful if it offered additional guidance on how the authors might explore or address this issue in their analysis. Overall, the comment provides a clear point of improvement but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 could be optimized to use less whitespace. This is a specific and actionable suggestion, as it provides a clear direction for improvement. The authors know exactly what aspect of the figure needs attention and how to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests optimizing Figure 1 to use less whitespace, but it does not specify which part of the paper Figure 1 corresponds to or provide any context for why this optimization is necessary. Without this information, the authors cannot confidently determine which section of the paper needs revision. The comment is specific in its suggestion but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this optimization is necessary or how it would impact the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that Figure 1 could be optimized to use less whitespace. While this feedback is specific and actionable, it lacks broader context or suggestions for improvement beyond optimizing the figure. The comment provides a clear direction for the authors to consider, but it does not offer a comprehensive set of recommendations or address other potential areas for enhancement. As a result, the feedback is somewhat helpful, as it gives the authors a specific area to focus on but does not provide a full picture of how to improve the draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space used in the study. It suggests that the authors should provide evidence or analysis to support the claim that the space is meaningful, such as examining whether the addition of morphological variants results in semantically coherent outcomes. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide evidence or analysis to support the claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaningfulness of the geometry of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors should provide evidence or analysis to support this claim. It also provides an example, such as examining whether \"looking\" - \"look\" + \"walk\" = \"walking\", to illustrate the concept. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies what needs to be addressed regarding the meaningfulness of the space. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors should provide evidence or analysis to support this claim. The comment provides an example, such as examining whether \"looking\" - \"look\" + \"walk\" = \"walking\", to illustrate the concept. However, it lacks detailed reasoning or references to support the claim that the current space is meaningful. The authors are left to infer the need for such analysis, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the meaningfulness of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors should provide evidence or analysis to support this claim. It provides an example, such as examining whether \"looking\" - \"look\" + \"walk\" = \"walking\", to illustrate the concept. However, the comment lacks detailed guidance or suggestions on how to conduct this analysis or what specific evidence would be compelling. While it identifies an important area for improvement, the feedback is somewhat vague and could be more helpful if it provided more specific advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how to improve the writing quality or address the issue of missing related work. The authors are left to infer that they need to revise the explanation of basic memory networks and the forward model to be more concise and that they should include more reinforcement learning tasks in the related work section. This lack of explicit and detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing quality or the related work section require improvement makes the comment weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the writing quality of the paper should be improved, specifically noting that the authors spend the same space on explaining basic memory networks and the forward model. It also mentions that the related work section has missing pieces on more reinforcement learning tasks. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the writing quality of the paper and the completeness of the related work section. It points out that the authors spend the same space explaining basic memory networks and the forward model, suggesting that the explanation could be more concise. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is somewhat helpful as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of replacing the first column of Qo with vo, which affects the reachability of the first state. It suggests that this change might impact the validity of Assumption 1, which concerns the finite length of an option. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of this change on their assumptions and potentially revise their approach. The lack of concrete instructions makes the action somewhat vague, aligning with a score of 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the implications of replacing the first column of Qo with vo and its impact on the reachability of the first state and Assumption 1. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implications of a specific change in the paper, namely the replacement of the first column of Qo with vo, and its impact on the reachability of the first state and Assumption 1. While the comment highlights a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, pointing out a potential problem with the replacement of the first column of Qo with vo, which affects the reachability of the first state and potentially impacts Assumption 1. While the comment highlights a potential area of concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or what changes could be made to the paper. The feedback is somewhat helpful as it directs the authors to a specific part of the paper that requires attention, but it lacks depth and actionable advice. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not explicitly instruct the authors on how to implement this suggestion or what specific aspects to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a suggestion for the authors to consider if they did not see improvements in FLOPs or inference time, suggesting they should look for improvements in accuracy or specific properties. While the comment offers a potential direction for exploration, it lacks specific guidance on which aspects to focus on or how to approach this analysis. The suggestion is somewhat helpful as it prompts the authors to consider alternative metrics or properties, but it does not provide detailed instructions or examples, which could limit its effectiveness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should have tested this assumption, the comment does not explicitly instruct or suggest how to conduct the test. The action is implicit, as the authors need to infer that they should test the assumption. However, the comment lacks concrete guidance on how to perform the test or what specific aspects to consider. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not specify which part of the paper this assumption is made or where it is discussed. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the testing of the assumption, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the assumption made regarding the use of d_e as replacements for entity embeddings. It questions whether this assumption has been tested, which is a crucial aspect of ensuring the validity of the research. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific tests could be conducted. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should test the assumption, but the comment does not offer detailed steps or examples to facilitate this process. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. While it acknowledges that the information is unclear, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to clarify the process. The comment is vague and lacks concrete suggestions, making it difficult for the authors to know how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide any specific examples, reasoning, or references to support these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. This feedback is valuable as it highlights a potential issue with the transparency and reproducibility of the methodology. However, the comment lacks actionable guidance on how the authors might address this issue, such as suggesting specific steps or providing additional context. While it points out a weakness, it does not offer detailed advice on how to improve the clarity or transparency of the scoring function, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that making the factors in a table does not help convey more messages than pure text, implying that the table does not add any additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to revise the table or what specific changes could be made to improve its effectiveness in conveying messages. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"factors in a table,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that making the factors in a table does not help convey more messages than pure text, suggesting that the table does not add any additional information. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that making factors in a table does not help convey more messages than pure text, suggesting that the table does not add any additional information. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of information in a table, suggesting that it does not effectively convey more messages than pure text. This feedback is somewhat helpful as it highlights a specific area for improvement, but it lacks depth and actionable guidance. The authors are left without a clear understanding of how to revise the table to enhance its effectiveness in conveying messages. While the comment points out a potential problem, it does not provide specific suggestions or examples for improvement, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not provide any guidance or suggestions on how to address this question or what aspects of the simulation might benefit from such an analysis. The comment lacks explicit instructions or concrete advice, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. Without this context, the authors cannot confidently determine where to address the question or what aspects of the paper need clarification. The comment is not grounded, as it lacks specific references, and it is also not specific because it does not provide detailed guidance on how to answer the question or what information is needed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, aligning with the classification of \"No.\" Therefore, it is labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the number of different kinds of physical interactions that can be included in a simulation. While it highlights an area that might require further exploration or clarification, it does not provide any specific guidance or suggestions on how to address this question or what aspects of the paper might benefit from such an analysis. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is barely helpful, as it identifies a potential area for improvement but does not offer detailed or constructive advice. This aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of one-hot encoding for the categorical dataset, which could negatively impact model performance. While the comment identifies specific issues with the dataset selection and suggests that the authors should consider the importance of categorical features and one-hot encoding, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the model comparison section. It provides detailed feedback on the dataset selection, noting that only one dataset contains categorical features while the others are exclusively numerical. This feedback is specific, as it clearly specifies what needs to be addressed in the model comparison section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of one-hot encoding for the categorical dataset, which could negatively impact model performance. The comment provides a clear and logical explanation of why the dataset selection is inadequate and suggests that the authors should consider the importance of categorical features and one-hot encoding. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the model comparison section, highlighting a significant limitation in the dataset selection. It points out that only one dataset contains categorical features, while the others are exclusively numerical, which may affect the generalizability of the conclusions. Additionally, the comment notes the absence of one-hot encoding for the categorical dataset, which could negatively impact model performance. This feedback is clear and actionable, as it identifies specific areas where the authors need to improve their draft. However, it could be more helpful if it suggested specific ways to address these issues, such as recommending the inclusion of additional datasets with categorical features or the use of one-hot encoding. Overall, the comment is mostly helpful, as it provides valuable insights for improvement but could be more comprehensive with detailed suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the choice of IoT datasets, specifically FlatCam Face [26] and Head-pose detection [11], is unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. While the comment identifies a potential issue with the dataset selection, it does not provide explicit guidance on how the authors should address this concern or what specific datasets they should consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative datasets and potentially re-evaluate their benchmarking results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the choice of IoT datasets, namely that they are unpopular and outdated, and suggests better options for benchmarking. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of IoT datasets, specifically FlatCam Face [26] and Head-pose detection [11], is unpopular and outdated, making the benchmarking results difficult to sense and evaluate. The comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. However, the comment lacks specific examples or references to support the claim about the datasets being unpopular or outdated. While the reasoning is somewhat logical, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the choice of IoT datasets used in the paper, noting that the selected datasets, FlatCam Face [26] and Head-pose detection [11], are unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. This feedback is somewhat helpful as it highlights a potential weakness in the dataset selection and provides suggestions for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct a more comprehensive benchmarking or suggested alternative datasets in detail. Overall, the comment provides a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the pruning strategy, suggesting that it might not be effective for large networks due to the lack of consideration for global top Q values of the metric over the average of gradients. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider this aspect, but it lacks concrete steps or suggestions on how to implement it. Therefore, the comment is somewhat actionable, as it identifies a potential problem but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning strategies, particularly in the context of large networks and distributed training. It highlights a potential problem with the current approach, suggesting that majorly works with large networks but does not mention the necessity of finding global top Q values of the metric over the average of gradients. This provides a clear indication of what part of the paper the comment is addressing, making it fully grounded. The comment is also specific as it specifies the potential issue with pruning strategies and suggests that this consideration could break acceleration techniques like quantization and sparsification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks, which are usually trained in distributed settings, but does not mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is somewhat verifiable as it highlights a potential issue with the pruning strategy but lacks specific examples or references to support the claim. The authors would need to provide more context or evidence to fully understand the implications of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the pruning strategy, specifically noting that it might not be effective for large networks due to the lack of consideration for global top Q values of the metric over the average of gradients. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate the necessary considerations into their work. While it points out a critical aspect that needs attention, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear observation but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this concern, making the comment unactionable. Therefore, this comment aligns with the lowest score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not specify which subfigures are in question or provide any details about the potential issue. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what needs to be addressed or how the issue might be resolved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any evidence, reasoning, or references to support this claim. Without specific details or examples, the authors are left without guidance on how to address the issue or verify its existence. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about potential errors in the subfigures of Figs 1 and 2, questioning whether they have been swapped by mistake. However, it does not provide any specific details or suggestions on how to address this issue. The comment lacks actionable guidance or insight into what might have caused the error or how the authors could verify the accuracy of the figures. Without further elaboration or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the dropout probe improves sensitivity and identifies a potential concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dropout probe improving sensitivity and highlights a concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in identifying the concern about false positives, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dropout probe improves sensitivity but also raises a concern about the increased risk of false positives. The comment suggests that this issue should be a substantial part of the discussion. However, the comment lacks specific examples or detailed reasoning to substantiate the claim about the increased risk of false positives. It does not provide references or logical arguments to support the assertion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the increased risk of false positives when using the dropout probe, which improves sensitivity. It suggests that this issue should be a substantial part of the discussion. While the comment highlights a specific area that needs attention, it does not provide detailed guidance on how to address this concern or what aspects of the discussion should be expanded. The feedback is somewhat helpful as it points out a potential issue that could impact the validity of the results, but it lacks depth and actionable suggestions for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors' claim about the placement of the regret bound and the reviewer's inability to find it in the supplementary material. While the comment points out a potential issue with the authors' claim, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should double-check the placement of the regret bound and ensure it is correctly referenced. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about the placement of the regret bound in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors did not find the regret bound for the mini-batch estimator in the supplementary material, and it references a specific paper [1] that might contain the relevant information. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' claim about the regret bound being cast to the appendix is not supported by the supplementary material. However, the comment does not provide any specific evidence or references to substantiate this claim. Without additional information or examples, the reviewer's assertion remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors' claim regarding the placement of the regret bound in the appendix. It points out that the authors did not find the regret bound for the mini-batch estimator in the supplementary material, referencing a specific paper [1] that might contain the relevant information. This feedback is clear and actionable, as it directs the authors to double-check the placement of the regret bound and ensure it is correctly referenced. However, the comment could be more helpful if it provided additional guidance on how to verify the claim or suggested alternative approaches to address the issue. Overall, the comment is mostly helpful as it highlights a critical oversight and encourages the authors to take corrective action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly mentions that the paper formatting does not follow the NeurIPS style, specifically noting issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and provides specific actions for the authors to take, such as revising the formatting and restructuring the paper. The comment is explicit and concrete, allowing the authors to understand exactly what needs to be addressed and how to do it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically noting that it does not follow the NeurIPS style. It details the problems with the abstract font size and bottom page margins, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper formatting does not follow the NeurIPS style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the issues or understand how to address them effectively. The reasoning is logical but lacks detailed evidence, which could be improved with references or examples. Therefore, the comment is rated as borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper formatting, noting that it does not adhere to the NeurIPS style. It highlights particular problems, such as the abstract font being too large and the bottom page margins being altered. The comment suggests that by addressing these formatting issues, the authors could gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with specific areas to focus on and potential improvements to consider. However, the comment could be more helpful if it offered additional guidance on how to address the formatting issues or suggested specific changes to the paper structure. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, it does not provide explicit guidance on how the authors should address this issue or what specific methods they should include in their discussion. The action is implicit and vague, as it leaves the authors to infer that they need to incorporate a more comprehensive discussion of exploration methods. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it highlights the lack of discussion and comparison of exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed examples or references, the claim is not fully verifiable, as it does not provide a clear understanding of the specific issues that need to be addressed. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the absence of discussion and comparison of exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis of related work. However, the comment could be more helpful if it suggested specific methods or approaches that the authors should consider discussing or comparing. While it provides a clear direction for improvement, the lack of detailed guidance limits its impact on the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a clear and explicit action that the authors can easily understand and implement. The comment provides a specific and concrete instruction on how to improve the figure, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the annotations in Figure 4 can be further enlarged for better visibility. However, it does not specify which part of the paper Figure 4 is located in, nor does it provide any context or explanation for why this is necessary. The authors may infer that it refers to a specific section or figure, but the lack of explicit mention makes it difficult to pinpoint the exact area. The comment is specific in its suggestion but weakly grounded as it does not provide clear guidance on which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a factual observation about the presentation of the figure, but it does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is descriptive and does not provide any reasoning or evidence to support the claim. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a specific and actionable piece of feedback that directly addresses a potential issue with the presentation of the figure. By recommending the enlargement of annotations, the reviewer provides a clear and constructive suggestion that the authors can easily implement to improve the clarity and readability of their work. This feedback is valuable and directly actionable, making it a helpful comment for the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment raises a concern about the scope of the claim but does not offer guidance on how to address it or what changes might be necessary. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific part of the paper by referencing lines 26-27, which provides full grounding. It also specifies the issue by pointing out that the claim about multiple entities existing in both sentences and documents is not limited to document-level relation extraction but applies to broader contexts like joint entity and relation extraction. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" This claim is based on a general observation about the nature of entities in text, which is a common understanding in the field. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors could infer that the comment is based on common knowledge, but additional evidence or references would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the claim about multiple entities existing in both sentences and documents is not limited to document-level relation extraction but applies to broader contexts like joint entity and relation extraction. This feedback is clear and actionable, as it directs the authors to consider the scope of their claims and potentially expand their discussion to include these broader contexts. By addressing this comment, the authors can improve the accuracy and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific suggestions or examples of how to incorporate these broader contexts into the discussion. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse\". This is a specific and actionable suggestion that the authors can easily address by revising the label. The comment provides clear guidance on what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that one of the labels on the color bar should be \"worse,\" providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse.\" This is a specific observation that requires the authors to verify the accuracy of the label. However, the comment does not provide any additional context, reasoning, or references to support why this correction is necessary or beneficial. Without further explanation or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a specific issue with Figure 4, suggesting that one of the labels on the color bar should be \"worse.\" This is a clear and actionable feedback that the authors can easily address by revising the label. The comment is specific and provides a clear direction for improvement, making it highly helpful. It helps the authors identify a minor but important detail that needs correction, which can enhance the clarity and accuracy of their presentation. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue in the text, pointing out that the phrase \"training/validation/test\" should be \"training/validation/test sets\". This is an explicit action that the authors can take to correct the text. The comment is clear and provides a concrete instruction on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the correction needed, which is to change \"training/validation/test\" to \"training/validation/test sets'. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction, stating that the phrase \"training/validation/test\" should be \"training/validation/test sets\" in the specified location. This is a straightforward factual correction and does not require any additional reasoning or references to be considered verifiable. Therefore, it is classified as \"3: Somewhat Verifiable\" as it provides a clear correction but lacks depth or additional context.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is specific and actionable, pointing out a minor error in the text where the phrase \"training/validation/test\" should be corrected to \"training/validation/test sets\". This feedback is clear and provides a direct instruction for the authors to make the necessary correction. While the comment is concise, it effectively guides the authors in improving the accuracy of their writing. Therefore, it is rated as mostly helpful, as it offers a clear and actionable suggestion that is essential for enhancing the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit, as the authors would need to infer how to provide the requested information or improve the writing. Therefore, the comment is somewhat actionable, as it provides some guidance but lacks concrete steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about specific aspects of the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment does not explicitly mention specific sections or parts of the paper that need attention, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, such as the coefficient and hyperparameter details. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The questions raised are open-ended and do not provide clear guidance or evidence for the authors to address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several important questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies areas that need clarification or improvement, it lacks specific guidance on how to address these issues or provide additional details. The feedback is somewhat helpful as it points out potential weaknesses and areas for improvement, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets around the term or defining the bracketed term separately. These suggestions are explicit and provide concrete guidance on how the authors might address the issue. The comment is clear and actionable, allowing the authors to directly implement the proposed changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides concrete suggestions for improving the clarity of the definition by adding extra brackets or defining the bracketed term separately. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets or defining the bracketed term separately. While the comment provides a suggestion for improvement, it does not offer any specific reasoning or examples to support why the current definition might be confusing. The lack of detailed explanation or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some suggestion but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the definition of the quantile, suggesting that adding extra brackets or defining the bracketed term separately could improve understanding. This feedback is specific and actionable, providing the authors with clear guidance on how to enhance the clarity of their paper. By addressing this suggestion, the authors can make their work more accessible and easier to follow. The comment is mostly helpful as it offers a concrete and actionable improvement, though it could be further expanded to include additional suggestions or examples. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. This provides a clear and explicit action for the authors to take, as they can directly implement this suggestion by updating their model reference. The comment is specific in its recommendation, guiding the authors on what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to replace the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. This guidance is clear and actionable, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. While the suggestion is based on the reviewer's opinion that the model is no longer state-of-the-art, it lacks specific evidence or references to support this claim. The comment does not provide detailed reasoning or examples to justify the suggestion, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to replace the model by Dozat and Manning (2016) with a \"very high performing model\" or something similar. This feedback is actionable and directly addresses a potential issue with the model used in the paper. By offering a clear alternative, the comment empowers the authors to improve the accuracy and relevance of their work. However, the comment could be more helpful if it provided additional context or justification for why this replacement is necessary or beneficial. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion, but it could be further enhanced with additional reasoning or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation identifies a key weakness of the method. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the method. The authors are left without guidance on what steps to take to enhance their work. Therefore, the comment is unactionable as it lacks any direction for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed compression\" and \"PQ,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed compression performs worse than PQ when a small code length is allowed, which is a clear and specific critique. This provides the authors with a clear understanding of the problem and how it needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed compression performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation highlights a critical limitation of the method, which is important for the authors to address in order to improve their work. However, the comment lacks actionable suggestions or guidance on how to resolve this issue or enhance the method. While it points out a significant area for improvement, it does not provide the authors with a clear path forward, making it somewhat helpful. The feedback is valuable but could be more impactful with additional suggestions or guidance on potential solutions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies several areas where the paper could be improved, such as the inclusion of subjective statements, the need for proofs and references to support claims, and the lack of detailed explanation for certain statements. It also suggests that the paper should provide a detailed explanation to verify these claims. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with subjective statements and the need for proofs and references to support claims. It also mentions specific areas, such as the labor-intensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with subjective statements and the need for additional evidence, but without explicit references, it is challenging for the authors to pinpoint the exact parts of the paper that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about subjective statements and the need for proofs and references to support claims. It provides specific examples, such as the labor-intensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, the comment lacks detailed reasoning or references to substantiate these claims, making it somewhat verifiable. The authors would need to infer the need for additional evidence and detailed explanations to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, such as the inclusion of subjective statements and the need for proofs and references to support claims. It also highlights specific issues, such as the labor-intensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment suggests that the paper should provide a detailed explanation to verify these statements, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is mostly helpful as it directs the authors to areas for improvement and encourages them to provide more detailed explanations.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about how the proposed method compares with prior art. While it prompts the authors to consider this comparison, it does not provide explicit instructions or suggestions on how to address this comparison. The authors are left to infer that they should include a comparison with prior work, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks a question about how the proposed method compares with prior art. However, it does not specify which part of the paper this comparison should be made or what aspects of the comparison are relevant. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its request for a comparison, but without grounding, the authors are left to make an educated guess about where to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the proposed method compares with prior art. However, it does not provide any specific details, examples, or references to support this claim. Without additional context or evidence, the authors are left to make their own judgments about the relevance and importance of this comparison. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how the proposed method compares with prior art, which is a relevant and important aspect for evaluating the novelty and contribution of the work. However, the comment lacks specific guidance or suggestions on how to address this comparison. It does not provide any insights into what kind of comparison would be beneficial or how the authors might approach it. Without actionable advice or examples, the comment is somewhat helpful as it identifies an important area for improvement but does not provide sufficient direction for the authors to address it effectively. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not explicitly instruct the authors to add more detailed analyses or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for more detailed analysis and the specific areas where it should be expanded. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the type of analysis that could be more detailed, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment lacks specific examples or references to support the claim that the current analysis is lacking in detail. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment lacks specific guidance on how to enhance the analysis or what additional insights could be derived from the data. While it identifies a potential area for improvement, it does not offer actionable steps or detailed suggestions for the authors to follow. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there are other properties of features that could be used in the approach design. While it suggests that exploring additional properties might be beneficial, it does not provide explicit guidance on how to identify or utilize these properties. The comment is somewhat vague, as it lacks specific examples or actionable steps for the authors to take. Therefore, the comment is somewhat actionable, as it provides a direction but not a detailed path for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide context or references to specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. This feedback is somewhat helpful as it prompts the authors to consider expanding their approach and potentially enhancing its effectiveness. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to identify or utilize these additional properties. Without concrete examples or actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment does not explicitly instruct the authors to address these questions or provide guidance on how to do so. The action is implicit, as the authors need to infer that they should investigate and potentially illustrate the conservation of properties. While the action is somewhat concrete, it lacks explicit instructions on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many solvers' algorithms\" and provides examples of symplectic integrators and Hamiltonian systems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether learning F^\\\\dagger behaves in a way that preserves nice mathematical properties, such as conservation of mass or charge, and suggests illustrating this numerically. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment does not offer any specific reasoning, references, or evidence to support the claim that such conservation properties are not being addressed or how the proposed illustrations would demonstrate this. The lack of detailed explanation or justification makes the claim somewhat verifiable, as the authors would need to infer the basis for the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an important question about the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and suggests illustrating this numerically. However, the comment does not provide specific guidance or suggestions on how to address this issue or what kind of numerical illustrations would be most effective. While it identifies a potential area for improvement, it lacks actionable advice or detailed examples, making it somewhat helpful. The authors would need to infer that they should investigate and potentially illustrate the conservation of properties, which limits the comment's helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a weakness in the method, noting that it is mostly constructed on top of previous methods without significant network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes to make. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies weaknesses in the method, specifically noting that it is mostly constructed on top of previous methods without significant network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issue with the network architecture but lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of using two SIRENs for f and d, suggesting that d might be a simpler network. However, it does not provide any specific reasoning or evidence to support this claim, such as logical arguments or references to existing literature. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the method, noting that it is mostly constructed on top of previous methods without significant network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. This feedback provides a clear area for improvement, prompting the authors to consider simplifying the network architecture. However, the comment lacks detailed guidance on how to address this issue or what specific changes might be beneficial. While it highlights a potential area for refinement, the feedback could be more helpful with additional suggestions or examples. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested analysis. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the redundancy of RQ1 and suggests an interesting point for analysis related to the percentage of explicit hate information in the dataset and its effect on implicit hate speech detection performance. However, it does not specify which part of the paper discusses RQ1 or where the dataset analysis is mentioned. The comment is weakly grounded as it does not provide explicit references to sections or figures, but it is specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also suggests an interesting point for analysis regarding the percentage of explicit hate information in the dataset and its effect on implicit hate speech detection performance. However, the comment lacks specific examples or references to support the claim about the redundancy of RQ1. While it provides a suggestion for improvement, the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the RQ1 mentioned in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. However, the comment lacks specific guidance on how the authors should address this issue or incorporate the suggested analysis into their draft. While it provides a direction for improvement, the feedback is somewhat limited in its actionable nature, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a variety of tasks beyond link prediction where the proposed method (PE) is important. However, it does not provide any specific guidance or suggestions on how to achieve this, such as which tasks to include or how to demonstrate the importance of PE in those tasks. The comment lacks explicit instructions or concrete details, making it difficult for the authors to understand what actions they should take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not specify which tasks or sections of the paper need to be addressed to achieve this. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity in detailing what tasks should be included or how they should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to incorporate it into their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. While this feedback provides a direction for improvement, it lacks specific guidance or examples on how to achieve this. The authors may find it challenging to understand the exact nature of the tasks that should be included or how to demonstrate the importance of PE in those tasks. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide detailed actionable feedback. The score of 3 aligns with this assessment.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between the authors' work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it prompts the authors to elaborate on these differences, it does not provide explicit guidance on how to address this question or what specific aspects need to be clarified. The action is implicit, as the authors need to infer that they should compare their work with the mentioned papers and explain the differences. However, the comment lacks concrete details on how to implement this comparison or what specific aspects to focus on, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"other works focusing on the semantic face editing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests elaboration on the differences between the authors' work and these papers, particularly regarding continuous control over attributes. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the differences between the authors' work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. While it does not contain a direct claim, it prompts the authors to elaborate on these differences, which could be considered a suggestion for improvement. However, the comment lacks specific examples or detailed reasoning to support the request, making it somewhat verifiable. The authors would need to infer the need for elaboration and may require additional guidance to fully understand the request. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the differences between the authors' work and other works focusing on semantic face editing, particularly those that achieve continuous control over attributes. This is a relevant point as it highlights a potential gap in the authors' work and encourages them to elaborate on how their approach differs from existing methods. However, the comment lacks specific guidance on what aspects of the comparison should be addressed or how the authors might approach this elaboration. While it provides a clear direction for improvement, the lack of detailed suggestions or examples makes it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_{test}. It suggests that the current approach of using summation might be misleading because it could select a subset of policies that are good for the majority of MDPs but bad for the remaining ones. The reviewer proposes using the minimum over S_{test} instead, arguing that this would provide a more accurate representation of the policy's performance. However, the comment does not provide explicit guidance on how the authors should implement this suggestion or what specific changes they should make to their evaluation process. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the intuitive goal of finding a set of policies that contains an optimal policy for every test MDP in S_test. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear rationale for why the current evaluation method might be misleading and suggests an alternative approach using the minimum over S_test. This detailed explanation helps the authors understand the issue and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_test. It suggests that the current approach of using summation might be misleading because it could select a subset of policies that are good for the majority of MDPs but bad for the remaining ones. The reviewer proposes using the minimum over S_test instead, arguing that this would provide a more accurate representation of the policy's performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the summation approach is misleading. This lack of evidence makes the claim somewhat verifiable, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_test. It suggests that the current approach of using summation might be misleading because it could select a subset of policies that are good for the majority of MDPs but bad for the remaining ones. The reviewer proposes using the minimum over S_test instead, arguing that this would provide a more accurate representation of the policy's performance. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, it could be more helpful if it included additional details or examples to further clarify the issue. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that footnotes are used excessively, making the paper distracting, and recommends moving important content into the main body and details about parameter settings into the appendix. While the comment provides explicit guidance on how to improve the paper by suggesting specific actions, such as moving content to the main body and appendix, it lacks detailed instructions on which parts of the paper should be moved and how to ensure the content is appropriately integrated. The action is somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that footnotes are used excessively, making the paper distracting, and recommends moving important content into the main body and details about parameter settings into the appendix. However, it does not specify which parts of the paper are being referred to, making it weakly grounded. The comment is specific in its suggestion to move content to the main body and appendix, but without explicit references, the authors may struggle to identify the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that footnotes are used excessively, making the paper distracting, and suggests moving important content to the main body and details about parameter settings to the appendix. While the comment provides a general rationale for the suggestion, it lacks specific examples or references to support the claim about excessive use of footnotes. The authors would need to infer the basis for this claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the excessive use of footnotes, which can make the paper distracting. It provides actionable suggestions for improvement, such as moving important content to the main body and details about parameter settings to the appendix. This feedback is clear and constructive, offering specific guidance on how to enhance the paper's readability and flow. However, the comment could be more helpful if it included additional suggestions or considerations, such as specific examples of content that could be moved or how to ensure the main body remains coherent after the restructuring. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for greater depth and guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inclusion of few-shot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific demonstrations to include or how to integrate them into the paper. The comment is somewhat vague, as it leaves the authors to infer the exact action needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the inclusion of few-shot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. While it is specific in suggesting the inclusion of few-shot demonstrations, the lack of grounding makes it difficult for the authors to understand where to apply the suggestion. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. The comment does not provide specific examples or references to support the claim that the inclusion of zero-shot results is necessary or beneficial. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what additional experiments might be relevant. The comment is somewhat helpful as it points out a potential area for enhancement, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a minor issue regarding Figure 3, noting that \"OAA\" is not referenced in the body text and that there might be additional content in the appendix that is missing or the caption is out of date. While the comment identifies a potential issue with the figure, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to check the figure and its caption for consistency and completeness, but the action is not clearly defined. Therefore, the comment is somewhat actionable, as it highlights a specific area that needs attention but lacks detailed instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific issue regarding Figure 3, noting that \"OAA\" is not referenced in the body text and that there might be additional content in the appendix that is missing or the caption is out of date. This provides clear guidance on what needs to be addressed in the figure, making the comment specific. However, it does not explicitly mention which part of the paper Figure 3 is located in, which could make it slightly challenging for the authors to pinpoint the exact issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a specific issue regarding Figure 3, noting that \"OAA\" is not referenced in the body text and that there might be additional content in the appendix that is missing or the caption is out of date. While the comment identifies a potential issue with the figure, it lacks detailed reasoning or references to support the claim that \"OAA\" is not referenced or that the caption is out of date. The authors are left to infer the validity of the claim, which makes the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that \"OAA\" is not referenced in the body text and that there might be additional content in the appendix that is missing or the caption is out of date. This feedback is clear and actionable, as it directs the authors to check the figure and its caption for consistency and completeness. However, the comment could be more helpful if it provided suggestions on how to address the issue, such as suggesting where the additional content might be located or how to update the caption. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the nature of their proposed solution in the introduction, stating that it is a \"fix\" of [12] rather than a new PIC approach. It provides a specific example of where this clarification is needed, in lines 29-30. The comment is clear and direct, providing a concrete action for the authors to take. It instructs them to mention the prior work [12] to avoid confusion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section where the clarification is needed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors must clarify the nature of their proposed solution as a \"fix\" of [12] rather than a new PIC approach, and it provides a specific example of where this clarification is needed in lines 29-30. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors must be more clear in the introduction about the nature of their proposed solution, specifically that it is a \"fix\" of [12] rather than a new PIC approach. The comment provides a specific example of where this clarification is needed, in lines 29-30, and suggests that the authors should mention the prior work [12] to avoid confusion. This claim is mostly verifiable as it provides a clear reasoning and specific examples, but it could be strengthened with additional references or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a clear and specific suggestion for improvement. It instructs the authors to clarify the nature of their proposed solution in the introduction, emphasizing that it is a \"fix\" of [12] rather than a new PIC approach. This feedback is actionable and constructive, as it directs the authors to address a potential point of confusion and ensure that their work is accurately represented. By providing a specific example of where this clarification is needed, the comment helps the authors improve the clarity and accuracy of their paper. Therefore, this comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference [2]. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions or detailed guidance on how to conduct the analysis or present the findings. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that this can be computed from a reference [2]. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may need to infer that it relates to the methodology or experimental results sections. The comment is specific in its request for clarification but lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference [2]. However, it does not provide any specific reasoning or evidence to support the claim that the effective receptive field is indeed improved. The comment lacks detailed explanation or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that this can be computed from a reference [2]. While it identifies an area for further investigation, it does not provide detailed guidance or suggestions on how to conduct this analysis or present the findings. The comment is somewhat helpful as it points out a potential area for improvement and encourages the authors to explore it, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the objective for the LSTM part is the same for pre-training and fine-tuning, specifically mentioning the probabilities of actions. It also proposes that the authors may add another head to the network to compute value functions for states during the fine-tuning stage. This comment provides explicit guidance on what the authors should consider and how they might improve their draft by adding another head to the network. The action is clear and concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides a specific suggestion for improving the LSTM part of the paper, focusing on the objective for pre-training and fine-tuning. It suggests that the authors may add another head to the network to compute value functions for states during the fine-tuning stage. This comment is fully grounded as it explicitly mentions the LSTM part, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear and actionable suggestion for improvement. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the objective for the LSTM part is the same for pre-training and fine-tuning, specifically mentioning the probabilities of actions. It proposes that the authors may add another head to the network to compute value functions for the states during the fine-tuning stage. This comment is mostly verifiable as it provides a clear and logical suggestion for improvement, aligning with the reasoning and common knowledge that additional heads can be used to compute value functions. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the LSTM part of the paper, noting that the objective for pre-training and fine-tuning is the same, specifically mentioning the probabilities of actions. It suggests that the authors may add another head to the network to compute value functions for the states during the fine-tuning stage. This feedback is clear and actionable, offering a concrete improvement that the authors can implement to enhance their draft. By providing a specific suggestion, the comment helps the authors address a potential area for improvement in their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. While it prompts the authors to provide a justification for this combination, it does not explicitly instruct them to do so or offer guidance on how to address this question. The action is implicit, as the authors need to infer that they should provide a rationale for the combination. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the exact part of the paper being addressed. While the comment is specific in its inquiry, the lack of grounding makes it difficult for the authors to fully understand and address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. This is a question that seeks clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRAC-G4RL) and whether G4RL requires HRAC's regularization in the latent space. This question prompts the authors to provide a justification for their approach, which could help them clarify their methodology and improve the clarity of their work. However, the comment lacks specific guidance or suggestions on how to address this question or what aspects of the combination might need further explanation. While it identifies an area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a potential area for clarification but does not offer comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge some of the older works in the related works section. While the comment implies that the authors should include these older works, it does not provide specific guidance on which works to acknowledge or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging \"older works\" in the context of supervised, multilingual systems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge some of the older works in the related works section. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which works should be acknowledged. Without additional context or references, the claim is somewhat verifiable, as it lacks sufficient detail to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should acknowledge some of the older works in the related works section. This feedback is clear and actionable, as it provides a specific direction for improvement. By acknowledging older works, the authors can provide a more comprehensive overview of the field and demonstrate a deeper understanding of its history. However, the comment could be more helpful if it offered specific examples or guidance on which older works to include. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides a basis for action, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear-/exponential-decay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing predicted architectures could lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, questioning the underperformance of linear-/exponential-decay sampling compared to uniform sampling and suggesting an alternative approach based on the authors' argument about the predictor's accuracy on the good subregion. This provides a clear direction for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear-/exponential-decay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing predicted architectures could lead to better performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the results are confusing or that the suggested alternative approach is valid. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the results presented in Table 2, specifically regarding the underperformance of linear-/exponential-decay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing predicted architectures could lead to better performance. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable advice or detailed reasoning, making it somewhat helpful. The authors would need to infer the necessary steps to address the concern, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights potential issues with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment does not provide explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how to improve the method or what specific changes might be necessary to reduce the time complexity. Without actionable suggestions or concrete steps, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization-based methods. However, it does not specify which part of the paper these issues are discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in detailing the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity of the proposed method is high, citing the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment lacks specific evidence or references to support these claims. Without detailed reasoning or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies potential issues with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization-based methods. While the comment highlights these concerns, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the efficiency of their method. Without actionable advice or detailed recommendations, the authors may find it challenging to make meaningful improvements based on this feedback. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. This comment provides a clear and explicit action for the authors to take, which is to label the figures more precisely. The suggestion is concrete, as it specifies exactly what needs to be done to improve the clarity of the figures. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, it does not explicitly mention which figures are being referred to, making it weakly grounded. The comment is specific in its suggestion to improve the clarity of the figures by providing more detailed labels. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification or examples to fully substantiate the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the figures, suggesting that labeling them as \"pre-trained solution encoders & solution decoders\" would improve their readability. This feedback is clear and actionable, providing the authors with a direct and specific direction for enhancing the presentation of their figures. By addressing this suggestion, the authors can significantly improve the clarity and understanding of their work. Therefore, the comment is highly helpful, as it offers a clear and constructive improvement that directly addresses a specific aspect of the paper.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also suggests that the relevance of the occlusion experiment is unclear, as the method does not seem to propose anything specific to occlusion. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific comparisons or clarifying the relevance of the occlusion experiment. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific comparisons with NeRF-based methods, such as \"Zero-1-to-3\" and \"point-e,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the relevance of the occlusion experiment, questioning its significance in the context of the method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of comparison with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also questions the relevance of the occlusion experiment, suggesting that it does not align with the method's specific contributions. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or justifications weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with NeRF-based methods, specifically mentioning 'Zero-1-to-3' and 'point-e.' This feedback is valuable as it highlights the need for the authors to contextualize their work within the existing literature. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it does not align with the method's specific contributions. However, the comment lacks detailed guidance on how the authors should address these issues, such as providing specific comparisons or clarifying the relevance of the occlusion experiment. While the feedback is somewhat helpful in identifying areas for improvement, it could be more actionable with additional suggestions or guidance. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multi-aspect\" and a question about the subscripts in Figure 1. While the comment explicitly suggests that a brief explanation of \"multi-aspect\" would be helpful, it does not provide guidance on how to implement this suggestion, such as what kind of explanation would be beneficial or how to integrate it into the paper. Similarly, the question about the subscripts in Figure 1 is specific but lacks guidance on how to address it. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to achieve them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed: a brief explanation of \"multi-aspect\" and a question about the subscripts in Figure 1. This level of detail provides clear guidance on what the authors should do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for a brief explanation of \"multi-aspect\" and a question about the subscripts in Figure 1. The first part is a suggestion for improvement, but it lacks specific guidance on how to provide the explanation or what aspects to cover. The second part is a question that requires clarification but does not provide any evidence or reasoning to support it. Therefore, the comment is mostly verifiable, as it provides some basis for improvement but lacks detailed justification or references. The score of 4 aligns with this assessment.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multi-aspect\" and a question about the subscripts in Figure 1. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues. For instance, it does not suggest specific ways to clarify the \"multi-aspect\" concept or provide examples to enhance understanding. Similarly, the question about the subscripts in Figure 1 is open-ended and does not offer actionable advice on how to resolve it. Therefore, the comment is somewhat helpful, as it highlights important areas for improvement but does not provide comprehensive or detailed guidance for the authors to follow. The feedback is clear but could be more actionable to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment explicitly asks for clarification and suggests a more detailed analysis, it does not provide explicit instructions on how to conduct the analysis or what specific aspects need to be detailed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the extraction process and its impact on the experiment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how parts of sentences and documents are extracted and whether the extraction rules have an effect on the experiment, along with a request for a more detailed analysis. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. However, the comment does not provide any evidence, reasoning, or references to support the need for such clarification or detailed analysis. Without specific examples or references, the authors may find it challenging to understand the basis for the request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment identifies a potential area for clarification and suggests a more thorough analysis, it lacks specific guidance or examples on how to conduct this analysis or what aspects of the extraction process need further exploration. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for information about the computational requirements of the experiments, specifically the time taken and the hardware used. While it prompts the authors to provide this information, it does not explicitly instruct them to include it in the paper or suggest where to add it. The action is implicit, as the authors can infer that they need to provide this information, but it lacks concrete guidance on how to present or discuss it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for information about the computational requirements of the experiments, including the time taken and the hardware used. This allows the authors to accurately identify the part of the paper where this information should be addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the computation required for the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the computational requirements of the experiments, specifically the time taken and the hardware used. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it prompts the authors to provide information about the computational requirements of their experiments, specifically the time taken and the hardware used. This feedback is valuable as it highlights an important aspect of the experimental setup that could enhance the reproducibility and transparency of the work. However, the comment lacks depth and does not provide specific guidance on how to present or discuss this information, making it somewhat helpful rather than fully helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. While it prompts the authors to provide more discussion, it does not explicitly instruct them to do so or offer concrete guidance on how to address this concern. The action is implicit, as the authors need to infer that they should discuss the application of the meta sampler and the specific epoch it is applied. However, the lack of detailed guidance on how to implement this discussion makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its request for more discussion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not provide any evidence, reasoning, or references to support the claim that the authors only apply the meta sampler in a decoupled way or when specific epochs are used. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. This is a valid concern that could impact the understanding and interpretation of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for clarification, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should discuss the application of the meta sampler and the specific epoch it is applied, but without further guidance, the feedback is limited in its usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper. However, the comment does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the necessary actions and may require additional guidance to execute them effectively. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using fairness-aware metrics like Equality odds (EO) and conducting more experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper. However, the comment does not specify which part of the paper discusses the use of metrics or the experimental setup, making it difficult for the authors to identify the exact sections that need revision. While the suggestion to use specific metrics and datasets is clear, the lack of explicit grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Comsumption, referencing a cited AAAI paper. This claim is somewhat verifiable as it provides a clear direction for improvement by suggesting specific metrics and datasets to enhance the fairness of the experiments. However, it lacks detailed reasoning or examples to fully support the claim, which could make it challenging for the authors to understand and implement the suggested changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific suggestions for improvement, such as using fairness-aware metrics like Equality odds (EO) and conducting additional experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper, which could be helpful in understanding how to implement these suggestions. However, the comment lacks detailed guidance on how to integrate these changes into the draft or what specific aspects of the experiments need to be addressed. While it offers a clear direction for improvement, the feedback could be more helpful if it included more detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the content on lines 107-114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment highly actionable. The explicit suggestion to either rephrase, include in a discussion, or remove the content gives the authors a direct path to improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the content on lines 107-114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment highly actionable. However, the comment does not specify which part of the paper this refers to, leaving the authors to infer that it is the content on lines 107-114. Therefore, the comment is fully grounded but lacks specificity, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the content on lines 107-114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. While the comment provides a clear recommendation, it lacks specific examples or references to support the claim that the content is speculative or overly opinionated. This makes the claim somewhat verifiable, as the authors would need to independently assess the content to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (lines 107-114) as being speculative or overly opinionated, suggesting that it should be rephrased, included in a discussion section, or removed. This feedback is clear and actionable, providing the authors with a direct path to improve the clarity and objectivity of their work. By offering specific suggestions for how to address the issue, the comment is mostly helpful, as it guides the authors in making necessary revisions. However, it could be more helpful if it provided additional context or examples to support the claim about the content being speculative or opinionated.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement achieved by the changes suggested in the paper. While the comment implies that these baselines should be included, it does not explicitly instruct the authors to add them or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate these baselines into their evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include these baselines, but without clear grounding, the authors may struggle to identify the exact section or part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, the comment lacks specific examples or references to support the claim that these baselines are necessary or would provide additional insights. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered borderline verifiable, as it provides some indication of the need for additional baselines but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. This feedback is somewhat helpful as it identifies a potential area for further validation and provides a specific suggestion for improvement. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why these baselines are particularly relevant. The authors may find it challenging to fully understand and address the feedback without additional context or explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two key issues that need addressing: the lack of analysis regarding the value of the neighborhood size h and its influence on the model's performance, and the inconsistent use of hyperparameter sets across different datasets. The comment suggests that providing readers with intuitive knowledge of the value of h to use and demonstrating the robustness of the method with respect to varying neighborhood sizes is essential. It also questions whether the authors can provide insights into how performance varies with a constant set of parameters. While the comment identifies the areas that need improvement, it does not explicitly instruct the authors on how to conduct this analysis or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the missing element of the value of neighborhood size h and its influence on the model\\'s performance, which is a key parameter of the proposed strategy. It also mentions the inconsistent use of hyperparameter sets across different datasets, which is not ideal. However, the comment does not specify which part of the paper discusses the neighborhood size or the hyperparameter sets, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its suggestions regarding the analysis of the neighborhood size and the use of consistent hyperparameters, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the missing analysis of the neighborhood size h and its influence on the model\\'s performance, as well as the inconsistent use of hyperparameter sets across different datasets. The comment suggests that providing readers with intuitive knowledge of the value of h to use and demonstrating the robustness of the method with respect to varying neighborhood sizes is essential. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. While the authors might infer that the lack of analysis and inconsistent hyperparameter usage are significant issues, the lack of explicit evidence or detailed explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper: the lack of analysis regarding the value of the neighborhood size h and its influence on the model\\'s performance, and the inconsistent use of hyperparameter sets across different datasets. It highlights the importance of providing readers with intuitive knowledge of the value of h to use and demonstrating the robustness of the method with respect to varying neighborhood sizes. Additionally, it questions whether the authors can provide insights into how performance varies with a constant set of parameters. While the comment points out these issues, it does not offer specific guidance or suggestions on how to address them, such as proposing additional experiments or analyses. The feedback is somewhat helpful as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. While the comment prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the paper. The action is implicit, as the authors need to infer that they should discuss the model's robustness to imperfect data and potential strategies for handling missing modalities. However, the lack of concrete guidance on how to implement these suggestions makes the comment somewhat actionable. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not specify which part of the paper addresses this issue, making it weakly grounded. The comment is specific in its inquiry about the model's behavior and potential strategies for handling missing data, but without explicit references to sections or figures, the authors may struggle to identify the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not provide any specific evidence, reasoning, or references to support the claims made. It lacks detailed explanations or examples to substantiate the concerns, making it difficult for the authors to understand and address the issue. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It prompts the authors to consider the impact of such data imperfections on the model and whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it highlights a potential area for improvement and encourages the authors to explore the robustness of their model under different data conditions. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as potential strategies for handling missing data or additional experiments to validate the model's performance. Overall, the comment is somewhat helpful, as it identifies a relevant area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment suggests an analysis, it does not provide explicit guidance on how to conduct this analysis or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset and provide statistics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"General Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear question and suggestion for analysis, asking the authors to show the statistics of how negation or intensity words affect the dataset. This guidance is detailed and specific, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment does not contain a subjective claim, it suggests an analysis that could be beneficial for the paper. However, it lacks specific examples or references to support the suggestion, making it somewhat verifiable. The authors would need to infer the need for this analysis, which limits the verifiability of the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. This feedback is somewhat helpful as it identifies a potential area for further analysis that could enhance the understanding of the dataset's characteristics. However, the comment lacks detailed guidance or suggestions on how to conduct this analysis, which limits its impact on the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the authors\\' draft, noting that they do not verify the stability of the OGE-Aug model on OOD benchmarks like DrugOOD, where SPE [2] is validated. This feedback is explicit and provides a clear action for the authors to take, which is to verify the stability of their model on these benchmarks. The comment is specific in its suggestion, guiding the authors to address a particular aspect of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the stability of the OGE-Aug on OOD benchmarks such as DrugOOD,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of verification of the model\\'s stability on these benchmarks. The comment provides a clear direction for the authors to take, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not verify the stability of the OGE-Aug model on OOD benchmarks such as DrugOOD, where SPE [2] is validated. This claim is somewhat verifiable as it points out a specific issue related to the evaluation of the model\\'s stability on OOD datasets. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the issue raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' draft, noting that they do not verify the stability of the OGE-Aug model on OOD benchmarks such as DrugOOD, where SPE [2] is validated. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs verification. By highlighting this omission, the comment provides a concrete suggestion for improvement, which can help the authors enhance the robustness and reliability of their model. Therefore, the comment is mostly helpful, as it offers a clear and actionable direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider additional methods for parameter-efficient fine-tuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. While the comment implies that these methods could provide a valuable basis for experimental comparison, it does not explicitly instruct the authors to implement or explore these methods. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to apply these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional methods for parameter-efficient fine-tuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore alternative methods for parameter-efficient fine-tuning, which could enhance the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering additional methods for parameter-efficient fine-tuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. While the suggestion is logical and aligns with common practices in the field, it lacks specific examples or references to support the claim. The comment provides a general direction for improvement but does not offer detailed reasoning or evidence to fully substantiate the suggestion. Therefore, the claim is somewhat verifiable, as it is based on logical reasoning but lacks sufficient detail or references to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a suggestion for improvement by suggesting that the authors consider additional methods for parameter-efficient fine-tuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. This feedback is somewhat helpful as it identifies a potential area for further exploration and experimentation that could enhance the paper. However, the comment lacks specific guidance on how to implement or explore these methods, which limits its actionable value. The suggestion is clear and relevant, but it could be more helpful if it provided more detailed guidance or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide specific guidance on which baselines to include or how to structure the comparison. The action is implicit, as the authors need to infer that they should expand the related work section and compare their work to baselines using coordinates. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not specify which baselines are relevant or how the comparison should be structured. The authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a specific section or element. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide specific examples of these baselines or explain why such a comparison is necessary or beneficial. Without detailed reasoning or references, the claim lacks sufficient support, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some indication of the need for comparison but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a more comprehensive comparison with existing baselines. However, the comment lacks specific guidance on which baselines to include or how to structure the comparison, which limits its actionable value. The authors would benefit from additional details on the selection of baselines and the expected structure of the comparison. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments in the paper are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment implies that multiple seed experiments would provide a more robust evaluation. However, it does not explicitly instruct the authors to conduct multiple seed experiments or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should perform multiple seed experiments to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the experiments being conducted on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. However, the comment does not specify which part of the paper discusses the experiments or the results related to the single seed experiments. This lack of grounding makes it challenging for the authors to identify the exact section or part of the paper that needs improvement. While the comment is specific in its suggestion to use multiple seed experiments, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to training on a single seed, making it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed guidance on how to conduct multiple seed experiments or why this would be beneficial. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the experimental setup, noting that the experiments are conducted using a single seed, which makes it challenging to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that using multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, it could be more helpful if it included additional guidance on how to conduct these experiments or why multiple seeds are necessary. Overall, the comment is mostly helpful, as it offers a clear direction for enhancing the robustness of the experimental evaluation.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it highlights a lack of clarity in the motivation, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the motivation behind their choice of distributions. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in questioning the motivation, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. Without additional context or justification, the claim lacks verifiability, as the authors are left to interpret the reasoning themselves. Therefore, this comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of clarity in the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically regarding the explanation of the chosen distributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative distributions or providing a more detailed rationale. Without actionable advice, the authors may find it challenging to fully address the feedback, making the comment somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the accessibility of the proposed method due to the requirement of a multi-GPU setup for optimizations. It suggests that this requirement might limit the potential users who can access or implement the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific guidance on how to make the method more accessible or how to justify the need for a multi-GPU setup. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"optimizations in the proposed method\" and the \"requirement of a multi-GPU setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains the issue of accessibility due to the need for a multi-GPU setup, which could limit potential users. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the requirement of a multi-GPU setup for the proposed method makes it inaccessible to many potential users. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the accessibility of the proposed method due to the requirement of a multi-GPU setup for optimizations. This is a valid concern that could limit the potential users who can access or implement the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a missing citation for the public skip-gram data set mentioned in line 425. While it points out the omission, it does not provide any explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include the citation, but the comment lacks detail on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the section of the paper where the issue lies. It is also specific because it clearly identifies the missing citation for the public skip-gram data set, providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing citation for the public skip-gram data set in L425. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, namely the missing citation for the public skip-gram data set mentioned in line 425. This is a clear and actionable piece of feedback that directly points out a deficiency in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as where to find the missing citation or how to incorporate it into the paper. While it highlights a critical oversight, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the current system captures semantics through RNN-based models and recommends comparing it with another system that also captures semantics. It also suggests using Ref-[2] as a strong baseline for comparison. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific aspects of the comparison should be highlighted or how the performance of the current system should be evaluated against the baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the current system with another system that captures semantics, implying a need for comparison. However, it does not specify which part of the paper this comparison should be made or which sections are relevant. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting a comparison with Ref-[2] as a strong baseline, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system with another system that captures semantics, recommending Ref-[2] as a strong baseline. However, it lacks specific details or references to support the claim that Ref-[2] is a strong baseline. The comment does not provide a clear rationale or evidence for why this comparison is necessary or beneficial. As a result, the claim is not verifiable, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the current system with another system that captures semantics, recommending Ref-[2] as a strong baseline for comparison. While it identifies a potential area for improvement by highlighting the need for a comparative analysis, the comment lacks specific guidance on how to conduct this comparison or what aspects of the performance should be evaluated. The suggestion to use Ref-[2] as a baseline is a good starting point, but the comment does not provide detailed instructions or examples to help the authors implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. While the comment identifies a lack of clarity, it does not provide explicit guidance on what actions the authors should take to address this issue. The authors are left to infer that they need to clarify these details in their draft, but the comment lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it points out a specific area needing clarification but does not provide detailed guidance on how to implement the suggestion.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for details, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. This is a factual question that requires the authors to provide additional information to ensure the reproducibility and transparency of their results. However, the comment does not offer any suggestions or reasoning to address this issue, making it a normal statement rather than a claim. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by questioning the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validation, and testing. This feedback is valuable as it highlights a lack of transparency and reproducibility in the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or clarifications. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a significant issue but does not offer concrete solutions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their model. The comment lacks concrete suggestions or detailed instructions on how to diagnose and resolve the problem. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is vague and lacks specificity, as it does not provide detailed guidance on what needs to be addressed or how to diagnose the problem. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left without a clear understanding of how to address the issue or what steps might be necessary. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they should take to improve their model. It does not provide actionable advice or insights that would help the authors enhance their work. As a result, the comment is barely helpful, as it identifies a potential problem but does not offer constructive feedback or direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more context on why and how it manages to achieve these results. It also mentions that the authors could consider increasing the rating based on their response. However, the comment does not explicitly instruct the authors to provide specific details or actions to address the question. While it implies that the authors should elaborate on the benefits of the SE framework, the lack of explicit guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the SE framework can help improve the paper, suggesting that the authors should provide more context on why and how it manages to achieve these results. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification and additional context, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more context on why and how it manages to achieve these results. It also references a specific paper [1] by Luo et al. to support the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the connection between the referenced paper and the current work, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more context on why and how it manages to achieve these results. It also references a specific paper to support the claim, which could be helpful for the authors to understand the context better. However, the comment lacks detailed guidance on how to improve the paper or what specific aspects need clarification. While it identifies an area for improvement, it does not provide actionable steps or suggestions for the authors to address the issue. Therefore, the comment is somewhat helpful, as it offers a starting point for the authors to enhance their draft but lacks depth and specificity.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what changes could be made to the approach. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the limitation of the approach, but it lacks detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the system should be able to generalize to more views without difficulty. As a result, the claim is considered unverifiable, as it lacks sufficient support for the authors to understand or address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitation of the approach to two views and suggests that it should be able to generalize to more views. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or what changes could be made to the approach. The comment is somewhat helpful as it points out a potential issue, but it does not provide actionable feedback or detailed insights to help the authors improve their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or non-existent. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics. The comment implies that the authors should consider the limitations of their current metrics and explore alternative evaluation methods, but it lacks concrete steps or suggestions for implementation. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or non-existent. However, the comment does not specify which part of the paper discusses these metrics or the datasets used, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the nature of the critique, it lacks grounding as it does not provide clear references to the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or non-existent. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the metrics used for evaluating continual learning, specifically noting that these metrics are not suitable for settings where task boundaries are unknown or non-existent. This critique is valuable as it highlights a limitation in the current evaluation approach, which could affect the paper's claims and conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative metrics. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it offers insight but lacks detailed guidance for the authors to enhance their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. While it prompts the authors to consider this choice, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the reasoning behind this choice. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its question, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any specific reasoning, examples, or references to support why this choice was made. Without additional context or justification, the claim is unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. This question highlights a potential area for clarification in the methodology section. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential area for improvement, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the discussion regarding the hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback provides a clear and explicit action for the authors to take, which is to include a detailed discussion on how to set the hyperparameter in practice and to analyze its sensitivity. The comment is concrete, as it specifies exactly what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the discussion on arbitrary hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in detailing what is missing, such as guidance on setting the hyperparameter and sensitivity analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the discussion on the hyperparameter \u03b3 is missing, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This claim is somewhat verifiable as it highlights a gap in the paper but does not provide specific examples or references to support the claim. The authors would need to infer the missing information, which limits the verifiability of the comment. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the hyperparameter \u03b3, specifically regarding how to set it in practice for a given graph and the lack of sensitivity analysis. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the importance of this hyperparameter and its impact on the results, the comment guides the authors to include a detailed discussion that would enhance the clarity and reproducibility of their work. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could explain the difference in ICL performance when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations in the model, should be considered. However, the comment does not provide explicit guidance on how to implement this controlled baseline or what specific experiments should be conducted to address this issue. The action is implicit and somewhat vague, as the authors need to infer the need for a controlled baseline and deduce the specific steps to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the different locations of induction heads and FV heads within the model, which could be a confounding factor in the analysis of ICL performance. It suggests that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment does not explicitly mention which part of the paper discusses the ablation of induction heads or FV heads, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its suggestion, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the different locations of induction heads and FV heads within the model could be a confounding factor contributing to the difference in ICL performance when ablating these heads. The comment suggests that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could explain the difference in ICL performance when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations in the model, should be considered. This feedback is somewhat helpful as it points out a specific area that needs further investigation and provides a suggestion for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to implement the controlled baseline or what specific experiments should be conducted to address this issue. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that a section on synonym identification is missing under the similarity measurement section, which describes how the multiple-choice task is approached. This provides a clear and direct action for the authors to take, namely to include this section in their draft. The comment is explicit and concrete, as it specifies exactly what is missing and where it should be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"similarity measurement\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing section, \"a section on synonym identification,\" which describes how the multiple-choice task is approached. This provides the authors with a clear understanding of what is missing and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under the similarity measurement section, which describes how the multiple-choice task is approached. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this section is missing or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the absence of a section on synonym identification under the similarity measurement section. This is a clear and actionable piece of feedback that would help the authors improve their draft by ensuring all relevant aspects are addressed. The comment is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific issues with the Methodology section, such as the difficulty in following the model architecture description and the use of inconsistent notation. It provides concrete examples, like the introduction of $v^p_{t-1}$ in Section 2.2 without corresponding equations, and the confusion caused by the notation for labels ($l_0$, $l_{t-1}$). The comment suggests that these issues make the section hard to follow, but it does not offer explicit guidance on how to improve the clarity or consistency of the description. While the authors can infer that they need to address these inconsistencies and improve the clarity of the model architecture description, the action is somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the Methodology section, which is a specific part of the paper. It provides detailed feedback on the clarity and consistency of the model architecture description, including specific examples of confusing notation and inconsistencies. The authors can confidently identify the part of the paper being addressed, and the comment specifies what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Methodology section is hard to follow due to confusing model architecture descriptions and inconsistent notation. It provides specific examples, such as the introduction of $v^p_{t-1}$ in Section 2.2 without corresponding equations and the confusion caused by the notation for labels ($l_0$, $l_{t-1}$). However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors can infer that the issues are valid, but the lack of explicit justification weakens the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the Methodology section, such as the difficulty in following the model architecture description and the use of inconsistent notation. It provides concrete examples, like the introduction of $v^p_{t-1}$ in Section 2.2 without corresponding equations and the confusion caused by the notation for labels ($l_0$, $l_{t-1}$). This feedback is clear and actionable, as it directs the authors to improve the clarity and consistency of their model architecture description. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing a more detailed explanation of the notation or restructuring the description for better clarity. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific guidance on how to create this overview or what aspects should be included. The comment is vague and lacks concrete instructions, leaving the authors uncertain about how to implement the suggested improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not specify which part of the paper this overview should be included in or how it should be structured. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include an overview, but it lacks details on what aspects of the workflow and model should be covered. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. While this feedback is relevant and could help the authors improve the clarity and accessibility of their paper, it lacks specific guidance on how to create such an overview or what aspects should be included. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment implies that this issue should be discussed in the paper, but it does not provide explicit guidance on how to address it or what specific aspects of the paper need revision. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the issue of bias in the sketch. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not specify which part of the paper discusses the sketch or the ridge regression problem, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of bias, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It claims that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It points out that this cannot be computed accurately without a significant runtime, which could lead to bias that defeats the purpose of the approach. The comment suggests that this issue should be discussed in the paper, but it does not provide specific guidance on how to address it or what aspects of the paper need revision. While the feedback highlights a potential weakness, it lacks detailed suggestions or actionable steps for the authors to take, making it somewhat helpful. The comment is clear and identifies an important area for improvement, but it could be more helpful with additional guidance on how to address the issue.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should redefine Figure 3 to show scalar values instead of vectors. This is a clear and explicit action that provides specific guidance on how the authors should modify their draft. The comment is concrete, as it specifies exactly what needs to be changed and how to do it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure-3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be done: redefine the figure to show scalar values instead of vectors. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should redefine Figure 3 to show scalar values instead of vectors. This is a specific and actionable suggestion that directly addresses a potential issue with the presentation of the figure. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would improve the clarity or accuracy of the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered borderline verifiable, as it is somewhat supported but lacks sufficient detail to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the expected quantities are scalars but are shown as vectors. This feedback is clear and actionable, providing the authors with a direct instruction on how to correct the figure. By redefining the figure to accurately represent the scalar values, the authors can improve the clarity and accuracy of their presentation. This feedback is specific and provides a clear path for improvement, making it mostly helpful. However, it could be more helpful if it included additional suggestions or considerations for the authors to keep in mind while making the change.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific guidance or suggestions on how the authors should improve the experiment setup or address these questions. The comment lacks explicit actions or concrete details, leaving the authors uncertain about what changes to make. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concerns about the ablations in the paper, noting that they raise many questions. However, it does not specify which part of the paper the ablations are discussed in, nor does it provide any guidance on how to address these questions or improve the experiment setup. The lack of specific grounding makes it difficult for the authors to understand which section or aspect of the paper needs attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses concerns about the ablations in the paper, noting that they raise many questions. However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concerns about the ablations in the paper, noting that they raise many questions. However, it lacks specificity and actionable suggestions, making it difficult for the authors to understand the issues or how to address them. The comment does not provide any guidance on how to improve the experiment setup or clarify the questions that arise from the ablations. As a result, the feedback is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further, implying that additional empirical testing could strengthen the argument. However, the comment does not provide specific guidance on how to conduct this testing or what data or experiments would be most effective. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, noting that a reasonable argument is made about the usefulness of the proposed models for learning representations for low-frequency words. However, it does not explicitly mention which part of the paper this argument is made, leaving the authors to infer that it relates to the discussion of the models or their applications. The comment is specific in detailing the issue of the lack of empirical evidence and the suggestion to explore this aspect further. However, the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evidence to support the argument that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. The lack of supporting evidence or detailed explanation makes the claim somewhat verifiable, as the authors would need to infer the basis for the claim and potentially seek additional evidence to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further, which is a valuable piece of feedback. However, the comment could be more helpful by providing specific guidance on how to conduct this exploration or what types of empirical evidence would be most relevant. While it highlights an important gap in the paper, the suggestion lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the resolution of the 3D voxel and its impact on computational cost. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the study of global features and specifically mentions methods like PiFu that avoid voxel-like features due to computational and memory costs. It questions the resolution of the 3D voxel and whether it introduces unnecessary overhead. The comment suggests studying the importance of global features in Section 4.2 by comparing different resolutions of voxel features, noting that a 1x1x1 resolution is equivalent to using a single global feature. This provides clear guidance on what needs to be addressed in the paper, making it fully grounded. The comment is also specific as it details the issue and suggests a concrete approach to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxel-like features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that different resolutions of voxel features could offer valuable insights. The authors would need to infer the basis for this suggestion, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific question regarding the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxel-like features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. This feedback is clear and actionable, as it directs the authors to explore the impact of voxel resolution on computational cost and the importance of global features. However, it could be more helpful if it provided additional guidance on how to conduct this comparison or what specific metrics to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth and actionable guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the error analysis on the movie dataset, noting that it is missing. It suggests that the authors should provide information on the cases where the model fails to help other researchers continue with the task. However, the comment does not offer explicit guidance on how to address this issue or what specific information should be included in the error analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a detailed error analysis section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing error analysis, and suggests that the authors should provide information on the cases where the model fails to help other researchers continue with the task. This provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any reasoning or evidence to support why this is a significant issue or how it impacts the paper. Without additional context or explanation, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or supporting details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the error analysis on the movie dataset is missing. It highlights the importance of this analysis for other researchers to continue with the task. However, the comment lacks actionable guidance on how the authors might address this issue or what specific information should be included in the error analysis. While it points out a critical gap, it does not provide detailed suggestions or examples, making it somewhat helpful. The authors would need to infer that they should add a detailed error analysis section to address the issue, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that the authors would find it interesting to explore development set trends with respect to hyper-parameters. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve the clarity of the table or the analysis of the trends. The suggestion is somewhat vague and lacks concrete details on how to implement the proposed exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the table, namely the difficulty in discerning trends and suggests exploring development set trends with respect to hyper-parameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a suggestion for improvement rather than a claim that requires verification. It proposes exploring development set trends with respect to hyper-parameters, which is a suggestion for further analysis but does not contain any subjective opinions or logical reasoning that would need to be supported. Therefore, the comment is classified as \"No\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly regarding the behavior of PM+CL compared to PM or CL alone. It suggests exploring development set trends with respect to hyper-parameters, which is a valuable and actionable feedback for the authors. By highlighting this issue, the comment provides a clear direction for improving the clarity and depth of the analysis presented in the paper. However, the comment could be more helpful if it offered additional guidance on how to explore these trends or suggested specific methods for analysis. Overall, the feedback is mostly helpful as it points out a significant area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a difficulty in understanding Figure 5 due to overlapping lines, suggesting that the authors could report additional metrics such as FLOPs or model size to make the figure more concrete. While the comment provides a clear action\u2014improving the clarity of Figure 5 by adding more metrics\u2014it does not specify how to implement this action, such as which metrics to include or how to present them. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue with the figure, namely the difficulty in understanding due to overlapping lines, and suggests a concrete improvement by reporting additional metrics like FLOPs or model size. This provides clear guidance on what needs to be addressed to enhance the clarity and comprehensiveness of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is difficult to understand Figure 5 due to overlapping lines, and suggests that reporting additional metrics like FLOPs or model size would make the figure more concrete. While the comment identifies a specific issue with the figure's clarity, it lacks detailed reasoning or examples to fully support the claim. The suggestion to include additional metrics is logical but could be more robust with specific examples or references to similar practices in the field. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could enhance the figure's clarity by reporting additional metrics such as FLOPs or model size. This feedback is actionable and provides a clear direction for improvement, as it guides the authors on what additional information to include to make the figure more informative and easier to interpret. However, the comment could be more helpful if it offered specific examples of how to present these additional metrics or suggested alternative ways to visualize the data. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on what those details should include. The authors are left without a clear understanding of what information is needed to address the issue, making the comment somewhat vague and difficult to act upon. Therefore, this comment is rated as 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which part of the paper contains these missing details, making it difficult for the authors to identify the exact section or part that needs attention. Additionally, the comment lacks specificity, as it does not detail what information is missing or how it impacts the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details or how they impact the paper. Without additional context or evidence, the claim remains unverifiable. Therefore, this comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how to address this issue. The feedback is vague and lacks actionable suggestions, leaving the authors without a clear understanding of what information is needed to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the paper being too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It suggests simplifying the description and explaining the architecture and computations better. Additionally, it recommends reducing the content of Figure 7, Section 8, and lines 39-64 to gain more space. While the comment provides explicit suggestions for improvement, such as simplifying the description and explaining the architecture and computations better, it lacks concrete guidance on how to achieve these changes. The authors are left with a general idea of what needs to be done but without specific steps or examples, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on how to improve the paper, such as simplifying the description and explaining the architecture and computations better. The suggestion to reduce the content of lines 39-64 further emphasizes the need for conciseness. This level of detail and specificity makes the comment highly actionable and grounded, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It suggests simplifying the description and explaining the architecture and computations better, and recommends reducing the content of Figure 7, Section 8, and lines 39-64 to gain more space. While the comment provides a general suggestion for improvement, it lacks specific examples or references to support the claim about the paper being too dense. The authors would need to infer the basis for this claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The authors are advised to simplify the description and explain the architecture and computations better, which is a constructive suggestion for improving the clarity and accessibility of the paper. Additionally, the comment recommends reducing the content of Figure 7, Section 8, and lines 39-64 to gain more space, which is a practical piece of advice. While the comment is clear and actionable, it could be more helpful if it provided specific examples or detailed guidance on how to simplify the description or explain the architecture and computations. However, it is mostly helpful as it offers valuable feedback for improving the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the performance of EIGNN with respect to over-smoothing on real-world datasets, particularly in comparison to variants like GCNII. However, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects of the evaluation should be considered. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"evaluation on over-smoothing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating EIGNN's performance on real-world datasets, especially in comparison to variants like GCNII, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests evaluating the performance of EIGNN with respect to over-smoothing on real-world datasets, particularly in comparison to variants like GCNII. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is important or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests evaluating the performance of EIGNN with respect to over-smoothing on real-world datasets, particularly in comparison to variants like GCNII. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a direction for further evaluation. However, it lacks detailed guidance on how to conduct this evaluation or what specific aspects of the evaluation should be considered. The comment could be more helpful if it included suggestions on the methodology or metrics for the evaluation. Overall, the feedback is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of a separate part or subsection dedicated to introducing the inference strategy. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit, as the authors can infer that they need to add a section or subsection explaining the inference strategy, but the comment lacks concrete details on how to implement this addition. Therefore, the comment is somewhat actionable, as it provides a clear indication of what is missing but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of a separate part or subsection to introduce the inference strategy, particularly how multiple prompts are used in the test stage. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that lacks clarity, namely the introduction of the inference strategy. It points out that the paper does not provide a separate part or subsection explaining how multiple prompts are used in the test stage. This feedback is clear and actionable, as it directs the authors to a specific area where they need to improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided suggestions on how to introduce the inference strategy or examples of how to implement it. Overall, the comment is mostly helpful as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Figure 4 is confusing and that the columns are not explained in the text or caption. While the comment highlights a specific issue with the figure, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the meaning of the columns in the figure, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Figure 4, namely that the columns are not explained in the text or caption. This provides the authors with a clear understanding of what needs to be addressed to improve the clarity of the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 is confusing because it is not clear what the columns mean, as this is not explained in the text or caption. This claim is somewhat verifiable as it provides a specific issue with the figure but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer that they need to clarify the meaning of the columns in the figure, but the comment does not offer a clear path for how to do so. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the columns are not explained in the text or caption, making the figure confusing. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the figure, such as suggesting specific ways to label the columns or provide additional context. Overall, the comment is somewhat helpful as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the real-world applications of the new problem setting are not clear, specifically mentioning sorting and ranking. The comment questions the complexity of the procedure to find upper bounds on gaps and its implications for solving a ranking problem. However, the comment does not provide explicit guidance on how to improve the discussion of the results or how to clarify the real-world applications. The suggestions are somewhat vague and lack concrete details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the real-world applications of the new problem setting are not clear, specifically mentioning sorting and ranking. However, the comment does not specify which part of the paper these discussions or applications are related to, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding as it does not provide clear references to the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also questions the real-world applications of the new problem setting, specifically mentioning sorting and ranking, and raises concerns about the computational complexity of the procedure to find upper bounds on gaps. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The suggestions are somewhat vague and do not provide a clear path for the authors to address the issues. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some direction but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies areas for improvement in the paper, specifically suggesting that the discussion of experiment results could be more detailed and providing an example of how to conclude from the Streetview experiment. It also raises concerns about the clarity of real-world applications and questions the computational complexity of the procedure to find upper bounds on gaps, particularly in the context of solving a ranking problem. While the comment provides some actionable feedback, it lacks depth and specificity, as it does not offer detailed guidance on how to enhance the discussion or address the concerns about real-world applications and computational complexity. The feedback is somewhat helpful, as it points out areas for improvement but could be more comprehensive to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or improve their results, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. The lack of specific referencing makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, it is not grounded because it does not provide clear guidance on which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. While the comment identifies a potential issue with the experimental setup or results, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps or detailed explanations to help the authors enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to include an ablation study. The comment identifies a gap in the analysis but does not offer guidance on how to fill that gap, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of a small performance gain. However, it does not specify which part of the paper lacks ablation analysis or provide any guidance on how to address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the need for ablation analysis but lacks detailed suggestions on how to implement it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis in the main paper makes it difficult to determine the source of a small performance gain. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. This feedback is clear and actionable, as it highlights a critical gap in the analysis that could impact the paper's conclusions. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as suggesting specific ablation studies or analyses that could be included. Overall, the comment is mostly helpful as it points out a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). It also mentions that the authors use a threshold (Th.) in their experiments. However, the comment does not provide explicit guidance or suggestions on how the authors should address this observation or incorporate the threshold into their work. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific section or part of the paper. This allows the authors to accurately identify the section being addressed. The comment is also specific because it provides a clear observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8), and it mentions the use of a threshold (Th.) in the experiments. This level of detail helps the authors understand what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"2 shows that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. And the authors use Th.\" However, the comment lacks specific details or references to support this claim. It does not provide any evidence, examples, or logical reasoning to substantiate the observation about the noise rate of similarity labels. Without additional context or justification, the claim is difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). It highlights a potential issue that the authors might be facing, which could be relevant to the accuracy of their experimental results. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or incorporate it into their work. While it identifies a potential area for improvement, it does not provide detailed feedback or constructive advice, making it somewhat helpful. The authors would need to infer what steps to take, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the verification of the hypothesis through the designed experiment. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. The comment suggests that it would be better to compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to conduct an additional experiment to strengthen the motivation of the work. The action is concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the comparison between models trained on the original dataset and the mixture of the original and adversarial examples to better verify the hypothesis. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the hypothesis is not well verified by the designed experiment, specifically noting a discrepancy in how models are trained in conventional methods versus the base model. The comment suggests an additional experiment to compare models trained on the original dataset versus the mixture of the original and adversarial examples. This claim is somewhat verifiable as it provides a logical reasoning for why the experiment might not be sufficient, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the verification of the hypothesis through the designed experiment. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. This discrepancy makes it difficult to assess the impact of the augmented adversarial examples. The comment suggests a crucial experiment to compare the model trained on the original dataset with that trained on the mixture, which would help highlight the impact of the augmented adversarial examples. This feedback is clear, actionable, and provides a specific direction for the authors to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the CNN experiments are not fully convincing but does not provide any specific details or suggestions on how to improve them. The comment lacks explicit guidance on what aspects of the experiments need to be addressed or how the authors should enhance the results. Without concrete actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the CNN experiments are discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is not specific because it does not provide details on what aspects of the experiments are not convincing or how the authors might address this issue. Without specific guidance or examples, the authors cannot effectively respond to the comment. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the CNN experiments are not fully convincing, but it does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors are left without a clear understanding of why the experiments are not convincing or how they might address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concern about the CNN experiments, stating they are not fully convincing. However, it lacks specific details or suggestions on how the authors might address this issue. Without actionable feedback or guidance on improving the experiments, the authors are left without a clear path to enhance their draft. The comment is vague and does not provide any constructive advice, making it barely helpful. Therefore, the comment is rated as 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention that the results for model (3) in Table 1 were computed by themselves, as they are not reported in the original paper. This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be added to their draft to address this issue. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results for model (3) (Chung et al. 2016) for Cs-En were not reported in the original paper and suggests that the authors should mention this if they computed the results themselves. This provides a clear and detailed instruction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for model (3) in Table 1 were not reported in the original paper and suggests that the authors should mention this if they computed the results themselves. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to verify the accuracy of the information. Without additional context or evidence, the claim remains somewhat unverifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the results for model (3) in Table 1 were not reported in the original paper and were computed by the authors themselves. This feedback is clear and actionable, as it directs the authors to explicitly mention this in their draft. By doing so, the authors can ensure that their work is transparent and accurate, enhancing the credibility of their research. The comment provides a direct and constructive suggestion for improvement, making it highly helpful for the authors. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should place more emphasis on prompt design, noting that different prompts can lead to varying performance outcomes. It implies that the authors should discuss effective prompt design strategies. However, the comment does not provide specific guidance on how to implement this suggestion, such as which aspects of prompt design should be emphasized or what techniques should be discussed. The action is implicit and somewhat vague, as the authors need to infer the specific areas where more emphasis is needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that the feedback pertains to the discussion of prompt design, the lack of explicit mention or clear reference to specific sections or figures makes the comment weakly grounded. The comment is specific in its suggestion to discuss effective prompt design strategies, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment lacks specific examples or references to support the claim that the paper does not adequately address prompt design. Without detailed examples or references, the authors may find it challenging to understand the specific areas where the paper needs improvement. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks the necessary depth and specificity to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. While the comment identifies a specific area for improvement, it lacks detailed guidance on how to address this issue or what specific aspects of prompt design should be discussed. The feedback is somewhat helpful as it points out a crucial area for the authors to consider, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXplain models as an example. This provides a clear and explicit action for the authors to take, as they can compare their results with these models to better understand their performance relative to existing state-of-the-art methods. The comment is specific in its suggestion and provides a concrete direction for improvement, allowing the authors to enhance the context and relevance of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXplain models as an example. However, it does not specify which part of the paper this comparison should be made or where the results are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs to be addressed. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the authors' results with SoTA approaches, specifically mentioning HateXplain models as an example. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or beneficial. Without additional context or justification, the claim lacks sufficient evidence to be fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides a suggestion but lacks detailed support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests comparing the authors\\' results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models as an example. This feedback is somewhat helpful as it provides a clear direction for the authors to enhance the context and relevance of their work by comparing their results with existing state-of-the-art methods. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to perform the comparison or what aspects of the results should be compared. While it offers a starting point for improvement, the feedback could be more comprehensive and actionable to fully benefit the authors. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. While the comment implies that the use of freezing is not well-justified, it does not explicitly instruct the authors to remove or modify the use of freezing. The action is implicit, as the authors would need to infer that they should provide a clearer explanation for their choice of using freezing. However, the comment lacks concrete guidance on how to address this issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. However, it does not specify which part of the paper discusses the use of freezing or provide any context for why this question is important. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the choice of methods but does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. However, the comment does not provide any specific reasoning, examples, or references to support why freezing is used or why adaptive methods might be preferred. This lack of justification makes the claim somewhat verifiable, as the authors would need to provide more context or evidence to address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid question about the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. This feedback is somewhat helpful as it prompts the authors to clarify their choice of methods and provide a justification for their decision. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the issue. The authors would need to conduct further research or provide additional context to fully address the reviewer\\'s concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. While the comment implies an action, it does not explicitly instruct the authors to include a detailed plan or specify how to address the limitations. The action is somewhat vague, as it lacks concrete guidance on what constitutes a detailed plan or how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which part of the paper discusses the limitations, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion to provide a detailed plan, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment lacks specific details or examples of how this detailed plan might be structured or what actions should be taken. Without additional information or guidance, the authors may find it challenging to understand the exact nature of the plan they need to develop. Therefore, the comment is considered borderline verifiable, as it provides some suggestion but lacks sufficient detail or examples to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is somewhat helpful as it identifies a specific area for improvement\u2014developing a detailed plan to address limitations. However, the comment lacks depth and specificity, as it does not provide guidance on what constitutes a detailed plan or how the authors might approach this task. Without additional details or suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It also proposes an interesting idea for the authors to perform a similar analysis on their proposed model. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in suggesting an analysis that could be performed on the proposed model, but without clear guidance on how to implement it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. However, the comment does not offer a detailed explanation or justification for why this analysis is important or how it would enhance the paper. The lack of specific reasoning or examples makes it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. The comment also proposes an interesting idea for the authors to perform a similar analysis on their proposed model, which could enhance its robustness. However, the comment lacks detailed guidance on how to conduct this analysis or what specific aspects of the model should be examined. While it offers a valuable suggestion, the feedback could be more helpful if it included concrete steps or examples. Therefore, the comment is somewhat helpful, as it provides some insight but requires further elaboration to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement. It points out a potential inconsistency in the use of notation in Equation 3, specifically noting the use of p m in the numerator and p c in the denominator. The authors are asked to clarify the reason for this inconsistency. Additionally, the comment suggests that the variance could be considered for further improvement in Algorithm 2, where only the mean \u03bc f is used for the fusion prototype. The reviewer also suggests using \u03bc g instead of \u03bc f to maintain consistency with Equation 3. While the comment provides specific areas for clarification and potential improvement, it does not explicitly instruct the authors on how to address these issues. The suggestions are somewhat concrete, but the lack of explicit guidance on how to implement them makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues in Equation 3 and Algorithm 2, specifically regarding the use of notation and the consideration of variance. However, it does not explicitly mention which part of the paper these issues are located in, such as specific sections or equations. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its suggestions regarding notation and variance, the lack of grounding makes it challenging for the authors to fully understand and address the issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of notation in Equation 3 and suggests considering the variance in Algorithm 2. However, it does not provide any specific reasoning or justification for why the notation is confusing or why variance should be considered. The comment lacks detailed explanations or references to support the claims, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies specific areas for improvement in the paper, such as clarifying the notation used in Equation 3 and suggesting the inclusion of variance in Algorithm 2. It also points out a potential inconsistency in the use of notation and suggests a more consistent notation. While the comment provides some actionable feedback, it lacks depth and could be more helpful if it offered more detailed guidance or suggestions for improvement. The feedback is somewhat helpful as it directs the authors to specific areas that need attention, but it could be more comprehensive to fully assist them in enhancing their draft. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in certain settings. While the comment implies that the authors should provide a more comprehensive discussion of computational complexity, it does not explicitly instruct them to do so or offer specific guidance on how to address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of computational complexity. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment does not specify which part of the paper discusses the computational cost or where the authors should provide a more comprehensive discussion. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its critique of the computational cost, the absence of explicit references to the paper's sections or content makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the computational cost of the proposed approach, suggesting that the paper does not adequately explain why the additional cost did not result in significant delays. It also questions whether the approach might become prohibitive in some settings. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the computational cost of the proposed approach. It points out that while the paper mentions the additional cost not leading to significant delays, it does not provide a clear explanation or justification for this claim. The reviewer also questions whether the approach might become prohibitive in certain settings, which is a valid concern that could impact the practical applicability of the work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or provide a more comprehensive discussion of the computational complexity. While it highlights an important area for improvement, the feedback could be more helpful if it included actionable steps or examples of how to enhance the discussion of computational cost. Therefore, the comment is somewhat helpful, as it identifies a relevant area for improvement but does not provide detailed guidance for the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider explaining more about how novel values in the test set are handled. This is a clear and explicit action that the authors can readily follow. The comment provides a specific instruction on what needs to be addressed, making it highly actionable. The authors know exactly what aspect of the paper requires further explanation, which is the handling of novel values in the test set. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it suggests that the authors should consider explaining how novel values in the test set are handled, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is a suggestion for improvement, but it does not provide any specific reasoning, examples, or references to support why this clarification is necessary or beneficial. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks sufficient evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that the authors should consider explaining how novel values in the test set are handled for clarity. This feedback is actionable and directly addresses a potential area of confusion or lack of understanding in the paper. By suggesting a more detailed explanation, the comment helps the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this explanation might be implemented. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point mentions that similar methods have been proposed for multi-task learning but does not discuss them in the paper, referencing a specific work [1]. While it implicitly suggests that the authors should discuss these methods, the action is not explicit, and the authors are left to infer that they need to address this gap. The comment lacks concrete guidance on how to incorporate or discuss these methods, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"multi-task learning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that similar methods have been proposed but are not discussed in the paper, referencing a specific work [1]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the label is 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar methods have been proposed for multi-task learning but are not discussed in the paper, referencing a specific work [1]. This claim is somewhat verifiable as it provides a reference to support the assertion that similar methods exist. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a gap in the paper by pointing out that similar methods have been proposed for multi-task learning but are not discussed. This feedback is valuable as it highlights an area where the authors could enhance their work by providing a more comprehensive discussion of related methods. However, the comment could be more helpful if it offered suggestions on how to incorporate or discuss these methods, such as specific references or examples. Overall, the comment is somewhat helpful as it identifies a relevant area for improvement but lacks depth in its guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not provide explicit instructions or suggestions on how the authors should conduct this comparison or what specific aspects of the computation should be considered. The action is implicit, as the authors need to infer that they should compare the computational cost, but it lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not specify which part of the paper this comparison should be made or which methods are being referred to. The lack of specific grounding makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. Additionally, the comment does not provide any guidance on how to conduct the comparison or what specific aspects of the computation should be considered. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. While it identifies a potential area for further analysis, it does not provide specific guidance or suggestions on how the authors might approach this comparison or what aspects of the computation should be considered. The comment lacks depth and actionable advice, making it somewhat helpful as it highlights a potential area for improvement but does not offer detailed guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a generic external knowledge base to avoid issues with points 1 and 2, as demonstrated in Figure 3. However, it does not provide explicit guidance on how to implement this suggestion or clarify the confusion regarding the writing. The action is implicit, as the authors need to infer that they should use a generic external knowledge base and understand the confusion in the writing. The comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using a generic external knowledge base to avoid issues with points 1 and 2, referencing Figure 3. However, it does not specify which part of the paper these points are located in, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base to address the confusion in the writing, but without clear guidance on how to implement this suggestion, it is somewhat specific. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is too confusing, making it difficult for the authors to understand if the suggested solution is valid. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it is somewhat supported but lacks sufficient detail or examples to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the writing, specifically mentioning that points 1 and 2 could be avoided by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment does not provide specific guidance or suggestions on how to improve the writing or address the confusion. While it highlights a potential improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not offer detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment provides explicit questions and suggestions, it does not offer concrete guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not specify which part of the paper these questions or suggestions relate to, making it difficult for the authors to identify the exact sections or elements being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. While it provides some specificity by mentioning the choice of 0.6 and other loss functions, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises questions about the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not provide any specific reasoning, examples, or references to support these claims. The questions are open-ended and lack detailed justification, making it difficult for the authors to understand the basis of the concerns. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment identifies areas for improvement, it lacks specific guidance or detailed feedback on how the authors might address these issues. The questions are open-ended and do not provide actionable steps or suggestions for the authors to take. As a result, the comment is somewhat helpful, as it offers some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of in-depth analysis of the experimental results. It provides a specific example, asking for an explanation of why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is explicit and concrete, as it directly points out the need for a more detailed analysis and provides a clear direction for the authors to address this issue. The authors can infer that they should include a more thorough discussion of the experimental results, explaining the observed differences in model performance across different datasets. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for in-depth analysis of the experimental results, specifically questioning why the improvements are limited on the offense detection dataset and significant on the coarse stereotype set. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it provides a clear example of what needs to be addressed, prompting the authors to delve deeper into the analysis of their experimental results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a gap in the paper by noting the absence of in-depth analysis of the experimental results. It provides a specific example, asking for an explanation of why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any reasoning, examples, or references to support why this observation is important or how it impacts the overall findings. Without additional context or justification, the authors may find it challenging to understand the significance of the feedback and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of in-depth analysis of the experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is valuable as it directs the authors to explore the reasons behind these discrepancies, which could provide deeper insights into the effectiveness of their models. However, the comment could be more helpful if it provided suggestions or guidance on how to conduct this analysis or what aspects to consider. Overall, the comment is somewhat helpful as it highlights an important area for improvement, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the method of training on labeled data, including incorporating input mask explanation annotations for a few examples and using modern backbone baselines like ResNet50 or DenseNet121. It also expresses skepticism about the effectiveness of the proposed method, noting that many similar interventions have failed. However, the comment does not offer concrete guidance on how to implement these suggestions or address the skepticism. The authors are left with a vague idea of potential improvements but lack clear steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the method of training on labeled data, including incorporating input mask explanation annotations for a few examples and using modern backbone baselines like ResNet50 or DenseNet121. It also expresses skepticism about the effectiveness of the proposed method, noting that many similar interventions have failed. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance on potential improvements but lacks detailed instructions on how to implement them. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the proposed method, suggesting that many similar interventions have failed. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the skepticism. The comment lacks detailed reasoning or evidence to substantiate the claim, leaving the authors uncertain about the validity of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment provides specific suggestions for improving the method of training on labeled data, such as incorporating input mask explanation annotations for a few examples and using modern backbone baselines like ResNet50 or DenseNet121. It also expresses skepticism about the effectiveness of the proposed method, noting that many similar interventions have failed. However, the comment lacks detailed guidance on how to implement these suggestions or address the skepticism, leaving the authors with a vague idea of potential improvements. While the feedback offers some direction, it could be more helpful with additional actionable steps or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search. It recommends ensuring that the baseline is fully tuned with similar resources to the proposed method for a fair comparison. However, the comment does not provide explicit guidance on how to conduct this tuning or what specific steps should be taken. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, recommending that the baseline be fully tuned with similar resources for a fair comparison. However, the comment does not specify which part of the paper discusses the hyperparameters or the baseline comparison, making it weakly grounded. It is specific in suggesting the need for a fair comparison, but without explicit references to sections or figures, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, recommending that the baseline be fully tuned with similar resources for a fair comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on logical reasoning but lacks sufficient detail to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by pointing out that it introduces multiple hyperparameters and conducts an extensive hyperparameter search. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method would be important for a fair comparison. This feedback is somewhat helpful as it highlights a potential area for improvement in the experimental setup. However, it lacks specific guidance on how to conduct this tuning or what specific steps should be taken to ensure a fair comparison. The comment provides a clear direction but could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the definition of perplexity provided in the paper, specifically mentioning that it is not accurate and that Equation 1 does not represent perplexity but rather cross-entropy. While the comment identifies a specific issue with the definition and provides a clear explanation of the discrepancy, it does not offer any suggestions or guidance on how the authors might address this issue. The action is explicit but lacks concrete steps or detailed advice on how to correct the definition or improve the explanation. Therefore, the comment is somewhat actionable, as it highlights a specific error but does not provide actionable guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the definition of perplexity provided in the paper, specifically mentioning that it is not accurate and that Equation 1 does not represent perplexity but rather cross-entropy. However, the comment does not specify which part of the paper this critique refers to, such as a particular section or equation number. This lack of specificity makes it difficult for the authors to pinpoint the exact issue and address it effectively. The comment is fully grounded in terms of identifying the part of the paper being addressed, but it is not specific in detailing what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the definition of perplexity provided in the paper is incorrect, specifically stating that it is not what perplexity is and that Equation 1 does not represent perplexity but rather cross-entropy. The comment provides a clear explanation of the discrepancy, making it somewhat verifiable. However, it lacks specific examples or references to support the claim, which could enhance its persuasiveness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the definition of perplexity in the paper, pointing out that the provided definition is inaccurate and that Equation 1 does not represent perplexity but rather cross-entropy. This feedback is clear and actionable, as it highlights a factual error that needs correction. However, the comment could be more helpful if it provided guidance on how the authors might revise their definition or Equation 1 to accurately represent perplexity. Despite this, the comment offers valuable insight into a critical aspect of the paper, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the condition \\eta \\ge C_0 in Proposition 6.1 is strong and that it should be compared with the condition in Section 4. While the comment implies that the authors should clarify this condition, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should provide more context or explanation for the condition. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Proposition 6.1\" and \"Section 4,\" providing clear grounding for the authors to identify the specific parts of the paper being addressed. It also specifies the issue with the condition \\eta \\ge C_0, suggesting that the authors should clarify this condition and compare it with the one in Section 4. This level of detail allows the authors to understand exactly what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition \\eta \\ge C_0 in Proposition 6.1 is strong, suggesting that it should be compared with the condition in Section 4. While the comment provides a rationale for why the condition might be strong, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the basis for the claim, which could be challenging. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Proposition 6.1, noting that the condition \\eta \\ge C_0 is strong and typically small values of \\eta are expected. It suggests that the authors should clarify this condition and compare it with the condition in Section 4. This feedback is actionable and provides a clear direction for the authors to improve the clarity and consistency of their paper. By addressing this issue, the authors can enhance the understanding and applicability of their work. Therefore, the comment is rated as 4: Mostly Helpful, as it offers a clear and constructive suggestion for improvement, though it could be further expanded to provide more detailed guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more baselines for graph contrastive learning, specifically mentioning MVGRL and gpt-gnn, and test them on common datasets. This provides a clear and explicit action for the authors to take, as they know exactly which baselines to add and where to test them. The comment is concrete, as it specifies the exact baselines and datasets to consider, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"graph classification task\" and suggests adding more baselines for graph contrastive learning, such as MVGRL and gpt-gnn. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies which baselines are missing and suggests testing them on common datasets, providing detailed guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the compared baseline in the graph classification task is insufficient, specifically mentioning the absence of MVGRL and gpt-gnn. However, the comment does not provide any reasoning or justification for why these baselines are missing or why their inclusion is necessary. Without additional context or explanation, the authors may find it challenging to understand the basis for this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the baselines used in the graph classification task, noting that MVGRL and gpt-gnn are missing. It provides a clear suggestion to include these baselines and test them on common datasets, which is a valuable piece of feedback for improving the comprehensiveness of the study. However, the comment could be more helpful if it offered additional guidance on how to select or compare these baselines or suggested specific datasets for testing. Despite this, the feedback is mostly helpful as it directs the authors to areas for improvement and provides actionable suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It highlights that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and actionable suggestion for the authors to enhance their evaluation process, ensuring that their defense strategies are robust against more sophisticated attacks. By addressing this concern, the authors can significantly improve the reliability and effectiveness of their proposed methods. Therefore, the comment is highly helpful, as it offers a specific and constructive direction for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve the clarity of the table legends. The action is concrete, as it specifies the exact changes required, such as expanding the legends and clarifying the meaning of the numbers. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified in the legends, namely whether the numbers represent % errors or % correct, and specifies the context of MNIST and CIFAR. This level of detail helps the authors understand exactly what revisions are needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This claim is somewhat verifiable as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim. The authors would need to infer the need for clarification based on the feedback, which could be improved by providing more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the legends of Table 1, 2, and 3, suggesting that they should be longer and clarify whether the numbers represent % errors or % correct. This feedback is clear and actionable, providing the authors with a direct path to improve the clarity and accuracy of their presentation. By addressing this issue, the authors can enhance the readability and understanding of their results. The comment is mostly helpful as it offers a specific and constructive suggestion, though it could be further enhanced by providing additional context or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, making it difficult to assess the significance of the results. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as including standard deviations in future experiments or analyses. Without concrete guidance on how to improve the results, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of standard deviations, which makes it difficult to judge the significance of the results. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the results lack standard deviations or how this affects their interpretation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to judge the significance of the results. This feedback is clear and actionable, as it highlights a critical aspect of the experimental analysis that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how the authors might include standard deviations or discuss their implications. Despite this, the comment offers valuable guidance for improving the clarity and rigor of the experimental results, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the theoretical foundation of the paper, specifically questioning the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization. However, it does not provide explicit instructions or suggestions on how the authors might address these issues. The comment implies that the authors should consider providing these details, but it lacks concrete guidance on how to do so. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the theoretical foundation of the paper, specifically mentioning the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization. It implies that the authors should provide these details, but it does not explicitly mention which part of the paper these issues are discussed in. This makes it weakly grounded, as the authors may need to infer the specific section or part of the paper being addressed. However, the comment is specific in detailing what needs to be addressed, such as the existence and smoothness of the solution and the guarantees of the discretization. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis is weak due to the lack of discussion on the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the theoretical foundation of the paper, specifically regarding the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization. It suggests that these aspects are not adequately addressed, which could impact the robustness and reliability of the analysis. However, the comment lacks specific guidance or suggestions on how the authors might strengthen their analysis or address these issues. While it points out an area for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful. The authors would need to infer what aspects to focus on, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the realism of their generated images, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paper\" and \"supplemental material,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quality of generated images by the proposed method is limited, noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This feedback is clear and actionable, as it highlights a key area for improvement in the paper. However, it could be more helpful if it provided suggestions on how to enhance the realism of the generated images or suggested specific techniques that could be employed. Despite this, the comment offers valuable guidance for the authors to address the identified weakness, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific questions and suggestions for improvement regarding the description of the graph G in Section 3.3. It asks for clarification on how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be added or clarified in their draft. The comment is fully actionable, as it provides clear guidance on how to improve the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the size and elements of G, and adding the dimensions of G, X, and W to enhance understanding of the DGCN model. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity and completeness of the description of the graph G in Section 3.3. It suggests that the authors should provide more details about the size and elements of G, as well as the dimensions of G, X, and W to better understand the DGCN model. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claims. The suggestions are logical and based on common practices in describing models, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the clarity and completeness of the description of the graph G in Section 3.3. It suggests that the authors should clarify how G is built using the human skeleton and provide more details about the size and elements of G, as well as the dimensions of G, X, and W. These suggestions are actionable and constructive, as they guide the authors on what aspects of their paper need improvement. By addressing these points, the authors can enhance the understanding of their model and improve the overall clarity of their work. Therefore, the comment is highly helpful, as it offers clear and actionable feedback that empowers the authors to significantly improve their draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counter-argument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any explicit or implicit suggestions on how the authors should revise their draft to address this issue. It lacks concrete guidance on what changes are needed or how to implement the correction. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (559-560) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear critique of the claim made in those lines, suggesting that the statement is not entirely accurate and offering a counter-argument. This feedback is detailed and provides a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement on lines 559-560 is not entirely true, specifically regarding the Cycle Consistency loss. It provides a counter-argument, suggesting that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify the accuracy of the critique or understand the basis of the counter-argument. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on a logical assertion without sufficient substantiation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counter-argument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment lacks actionable guidance or suggestions on how the authors might revise their draft to address this issue. It does not provide specific examples or detailed feedback on what changes could be made to clarify or correct the inaccurate statement. As a result, while the comment highlights a potential area for improvement, it does not offer sufficient direction for the authors to effectively address the feedback. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"hyper-spectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or improve the clarity of their terminology. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"hyper-spectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear definition of hyperspectral imaging, which helps the authors understand the confusion and how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that calling \"hyper-spectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any additional evidence or reasoning to support this claim. The comment lacks specific examples or references that would help the authors understand why the term is confusing or how it could be clarified. As a result, the claim is unverifiable, making the comment unsuitable for improving the paper.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"hyper-spectral.\" It suggests that this term might be confusing and provides a definition of hyperspectral imaging. However, the comment does not offer any actionable advice or suggestions on how the authors might address this confusion or improve the clarity of their terminology. While it points out a potential area for improvement, it lacks depth and does not provide guidance on how to implement the suggested changes. Therefore, the comment is barely helpful, as it identifies a problem but does not offer substantial assistance for the authors to improve their draft.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the concept of energy, which is introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment provides specific suggestions for improvement, such as refreshing the concept of energy and providing hints on how to interpret it, as well as clarifying the concept of peak in the figure. However, it does not explicitly instruct the authors to implement these suggestions, leaving the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Section 3.1 and Section 5.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the explanation of the concept of energy, suggesting that it could be refreshed in Section 5.2 and providing hints on how to interpret it. Additionally, the comment points out that the concept of peak in Figure 5 is not described, which is a specific issue that needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also notes that the concept of peak in Figure 5 is not described. The comment provides specific suggestions for improvement, such as refreshing the concept of energy and providing hints on how to interpret it, as well as clarifying the concept of peak in the figure. However, it lacks detailed reasoning or references to support these suggestions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the clarity and completeness of the paper. It highlights that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. Additionally, it points out that the concept of peak in Figure 5 is not described, which is a significant oversight. The feedback is actionable and constructive, as it directs the authors to specific areas where improvements are needed. However, the comment could be more helpful if it provided additional guidance on how to implement these suggestions or included examples of how to interpret the energy concept. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. It mentions specific examples, such as the combination of Linformer and window attention in Big Bird, to illustrate the need for such details. However, the comment does not explicitly instruct the authors to include these explanations or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detailed explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of each component to the final performance improvements, with an example provided. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, with an example given. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The claim is somewhat verifiable as it provides a general direction for improvement but lacks detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed explanations of how each component contributes to the final performance improvements. It offers a concrete example, such as the combination of Linformer and window attention in Big Bird, to illustrate the need for such detailed explanations. This feedback is actionable and provides a clear direction for the authors to enhance their draft by adding more context and depth to their analysis. However, the comment could be more helpful if it included additional suggestions or guidance on how to present these explanations effectively. Overall, the comment is mostly helpful as it directs the authors towards a specific area of improvement with a clear example, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific areas where details are missing in the paper, particularly regarding the grammar over kernels and the probabilities associated with it. It also questions the clarity of how inference is performed. While the comment identifies the need for more detailed explanations, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The feedback is somewhat vague, as it leaves the authors to infer the necessary steps to improve the draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the models and grammars used in the paper, particularly the lack of detail regarding the grammar over kernels and the probabilities associated with it. It also questions the clarity of how inference is performed. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is high as it clearly identifies the areas needing more detail and clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of detail regarding the grammar over kernels and the probabilities associated with it, questioning the clarity of how inference is performed. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The feedback is vague and lacks sufficient evidence to allow the authors to understand the issues fully or address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail, particularly regarding the grammar over kernels and the probabilities associated with it. It questions the clarity of how inference is performed, which is a crucial aspect for understanding the practical application of the approach. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is somewhat helpful as it points out areas needing improvement, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete advice on how to improve the paper, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the role of visual information in the paper, specifically mentioning the ablation study and the performance of the w/o perception module and w perception. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the ablation study and the questionable nature of the experimental results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the role of visual information, the lack of explicit verification in the ablation study, and questions about the significance of the experimental results. It provides specific examples, such as the similar performance of w/o perception and w perception modules and the questioning of the results due to the sample size. However, the comment lacks detailed reasoning or references to support the claims, making it somewhat verifiable. The authors would need to infer the basis for the concerns, which could be improved with more explicit justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue regarding the role of visual information in the paper, noting that the ablation study does not explicitly verify its effectiveness. It also questions the significance of the experimental results, suggesting that the improvements might not be statistically significant given the sample size. This feedback is valuable as it highlights a gap in the paper's analysis and encourages the authors to provide more robust evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as additional experiments or analyses. Overall, the comment is somewhat helpful, as it points out important areas for improvement but lacks depth in its suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. It also points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work by including citations and comparisons. The comment is fully grounded as it specifies the section and the issue, and it is concrete as it provides a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"the end of Sec. 4.2,\" providing clear grounding for the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out that previous works on Lasso screening are not cited or compared, such as Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 2992-3006. This feedback is fully grounded and specific, as it clearly identifies the section and the issue, providing a detailed direction for improvement. Therefore, this comment is rated as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 2992-3006. This claim is somewhat verifiable as it provides a specific example of a missing citation, which allows the authors to understand the issue and potentially address it. However, the comment lacks a broader explanation or reasoning for why this omission is significant, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening but fails to cite or compare previous works on Lasso screening. The comment provides a specific example of a missing citation, which is helpful for the authors to understand the gap in their literature review. However, the comment could be more helpful if it suggested how the authors might address this issue, such as by including the suggested citation or discussing the relevance of previous works. Overall, the feedback is somewhat helpful as it highlights a critical omission that needs attention, but it lacks depth in suggesting specific actions to take.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the model has several components with hyperparameters that are not fully provided, requiring the authors to trace them in the source code. This feedback is explicit, as it clearly states what information is missing and what action the authors should take to address it. The action is also concrete, as it specifies exactly what needs to be done: trace the hyperparameters in the source code. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that the model has many components whose hyperparameters are not fully provided, requiring the authors to trace them in the source code. This provides a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model has many components whose hyperparameters are not fully provided, requiring the authors to trace them in the source code. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the model has several components with hyperparameters that are not fully provided, requiring the authors to trace them in the source code. This feedback is clear and actionable, as it highlights a potential area for improvement in the paper. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or suggested specific steps they could take to ensure the reproducibility of their results. Despite this, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the notation used for results, specifically questioning the meaning of the percentage improvement claim for CIFAR-10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to clarify the notation. The action is implicit, as the authors need to infer that they should clarify the notation and explain the meaning of the percentage improvement. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the notation used for results, particularly the unclear meaning of the percentage improvement claim for CIFAR-10. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity in the notation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the notation for results is unclear and that the paper does not specify what the percentage improvement claim for CIFAR-10 means. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of unclear notation or references to specific sections where the issue is discussed. Without additional context or justification, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of notation used in the results section, pointing out that the paper claims a 3% improvement for CIFAR-10 but does not specify what the %p stands for. This feedback is clear and actionable, as it directs the authors to clarify the notation and provide a definition for the percentage improvement. By addressing this issue, the authors can improve the readability and understanding of their results, making the paper more accessible and impactful. The comment is mostly helpful as it provides a clear direction for improvement, though it could be more comprehensive if it suggested specific ways to clarify the notation or provide examples of how to do so.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but are okay with the proposed method. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it lacks specific guidance on how to present these qualitative results or what specific aspects of the failure cases should be analyzed. The action is explicit but somewhat vague, as it does not detail the exact steps or format for presenting the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, zoomed-in views, and analysis of failure cases, which are relevant to the paper. However, it does not specify which part of the paper these elements should be included in, making it weakly grounded. The comment is specific in its suggestions for improvement, such as showing qualitative results and analyzing limitations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results, zoomed-in views, and analysis of failure cases, which are valuable additions to the paper. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand how to implement these improvements. The feedback is somewhat verifiable as it provides a general direction for improvement but does not offer detailed guidance or evidence to support the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including qualitative results, zoomed-in views, and analysis of failure cases, which are valuable additions to the paper. By providing these types of results, the authors can offer a more comprehensive and inspiring perspective on their work. The comment is clear and actionable, as it directs the authors to specific areas where they can enhance their paper. However, it could be more helpful if it provided more detailed guidance on how to present these qualitative results or what specific aspects of the failure cases should be analyzed. Overall, the comment is mostly helpful, as it offers clear suggestions for improvement that would benefit the authors.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This provides a clear and explicit action for the authors to take, as they can directly address the ambiguity in the title. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the clarity of the title. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. However, it does not provide specific guidance on which part of the paper this issue is related to, such as a particular section or figure. The authors may need to infer that the title is ambiguous based on the context of the paper, but the comment lacks full grounding. It is specific in its suggestion to clarify the title, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This claim is somewhat verifiable as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim fully. The authors would need to infer the relevance of this suggestion to the specific content of the paper, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. By addressing this ambiguity, the authors can enhance the clarity and precision of their paper, making it easier for readers to understand the focus of their work. Therefore, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific claim made in the paper on line 238, which is that the Central Limit Theorem (CLT) implies that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer points out that this statement is incorrect, as the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment provides a clear and explicit action for the authors to take, which is to correct this inaccurate claim. It also specifies exactly what needs to be addressed, making the action concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly details the incorrect assertion made about the Central Limit Theorem (CLT) and provides a detailed explanation of why the claim is incorrect, including the limitations of the CLT in non-asymptotic regimes and its applicability to finite linear combinations of arbitrary random variables. This level of detail helps the authors understand exactly what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' statement on line 238, \"According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables,\" is incorrect. The reviewer provides a detailed explanation of why this claim is incorrect, citing the limitations of the CLT in non-asymptotic regimes and its applicability to finite linear combinations of arbitrary random variables. This detailed reasoning and explanation support the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific and incorrect claim made in the paper regarding the Central Limit Theorem (CLT). It provides a clear and detailed explanation of why the authors' statement is inaccurate, highlighting the limitations of the CLT in non-asymptotic regimes and its applicability to finite linear combinations of arbitrary random variables. This feedback is actionable and constructive, guiding the authors to correct the inaccurate claim and improve the accuracy of their paper. The comment is detailed and provides a clear path for improvement, making it highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly instructs the authors to analyze the time complexity of the proposed policies mentioned in that section. This provides a clear and precise direction for improvement, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement, as it requires the authors to analyze the time complexity of the proposed policies mentioned in Section 4. There is no claim or suggestion made, and the comment does not require any verification or justification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, instructing the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This provides a clear and actionable direction for the authors to improve their draft by addressing a specific aspect of their work. The feedback is concise and directly helpful, making it a valuable piece of guidance. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. While the comment identifies a potential issue with the evaluation methodology, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider using a human metric instead of an automatic one. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper discusses the human evaluation or the use of TSS. This makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific about the issue of using an automatic metric, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support why an automatic metric might be less convincing or why a human metric is preferable. Without additional justification or evidence, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of an automatic metric TSS for human evaluation, questioning its effectiveness compared to a human metric. This feedback highlights a potential weakness in the evaluation methodology, which could impact the convincingness of the human evaluation results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative metrics could be considered. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. While the comment implies that the current experiments are sufficient to prove the point, it does not explicitly instruct the authors to include experiments across more diverse domains. The action is implicit and somewhat vague, as the authors are not given specific guidance on which domains to include or how to conduct these experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. However, it does not specify which part of the paper the experiments are currently located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion to include experiments across more diverse domains, but the lack of grounding makes it challenging for the authors to understand where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. However, it does not provide any specific reasoning, examples, or references to support why this expansion would strengthen the paper. The claim is somewhat verifiable as it implies a logical extension to the current experiments, but without detailed justification or evidence, it lacks robustness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. This feedback is somewhat helpful as it identifies a potential area for improvement that could strengthen the paper. However, the comment lacks specificity and does not provide detailed guidance on how to conduct these additional experiments or what specific domains should be included. Without more detailed suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the authors' draft: the lack of confidence intervals for their results and the limited evaluation on only two datasets. While the comment identifies these areas as needing improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to include confidence intervals and expand their evaluation to more datasets. This lack of explicit action makes the comment somewhat actionable, as the authors can deduce the necessary steps but do not have a clear roadmap for implementation. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of confidence intervals for the results and the limited evaluation on only two datasets, which are standard datasets in the RNP community. This provides the authors with clear guidance on what aspects of their work need improvement. However, the comment does not specify what needs to be addressed in terms of confidence intervals or expanding the evaluation, making it somewhat specific. Therefore, the comment is classified as fully grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment provides references to relevant works that have evaluated on similar datasets, suggesting that the authors should consider expanding their evaluation. However, the claim lacks detailed reasoning or specific examples to fully support the assertion that the evaluation is limited to only two datasets. The references provided are relevant but do not fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the authors' draft: the lack of confidence intervals for their results, which makes it difficult to assess the statistical significance of performance gains. It also points out that the evaluation is limited to only two datasets, which may not be sufficient to generalize the findings. The comment provides references to relevant works that have evaluated on similar datasets, suggesting that the authors should consider expanding their evaluation to include more datasets. This feedback is clear and actionable, as it directs the authors to address the lack of statistical rigor and broaden their evaluation. However, it could be more helpful if it suggested specific methods for calculating confidence intervals or provided guidance on selecting additional datasets. Overall, the comment is mostly helpful, as it offers valuable insights and actionable suggestions for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to evaluate the interpretability tax. Without concrete guidance or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper does not evaluate the magnitude of the interpretability tax associated with the method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors need to address, which is the evaluation of the interpretability tax. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without detailed reasoning or evidence, the claim is unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This feedback is clear and actionable, as it provides a specific area for the authors to address in their draft. However, the comment could be more helpful if it suggested potential methods or approaches for evaluating the interpretability tax. Despite this, the comment offers valuable guidance for the authors to enhance the comprehensiveness of their work. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's main contribution lies in demonstrating the effectiveness of combining existing techniques rather than proposing novel ones. However, it does not provide explicit guidance on how the authors should address this point or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to enhance the paper, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the approaches in Sec. 5 are straightforward and standard, and that the main contribution is demonstrating the effectiveness of combining existing techniques. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LUQ design is straightforward once the goal is clear, and the approaches in Section 5 are standard and explored in previous literature. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the validity of the assertion. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on general observations without strong justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critique of the paper's main contribution, suggesting that it primarily demonstrates the effectiveness of combining existing techniques rather than proposing novel ones. While this feedback offers a perspective on the paper's contribution, it lacks actionable suggestions or detailed guidance on how the authors might address this critique. The comment does not provide specific advice on how to enhance the paper's novelty or impact, leaving the authors with limited insights on how to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not offer comprehensive guidance. The score aligns with a rating of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to include the training losses or what specific information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or experimental setup, but without explicit mention, the comment is weakly grounded. The comment is specific in that it identifies a potential issue with the training process and suggests including training losses, which is a clear and actionable request. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not provide any reasoning, examples, or references to support why this is a concern or how the inclusion of training losses would address the issue. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While the comment identifies a potential issue with the training process, it lacks specificity and does not provide detailed guidance on how to address the concern or what kind of training losses would be relevant. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not offer actionable advice or suggestions for specific changes. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide explicit guidance on how the authors should address this overclaiming or what specific aspects need to be revised. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the overclaiming of the BC loss and provides a clear explanation of why the different aspects are considered the same concept. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential overclaiming of the proposed BC loss in the theoretical analysis section, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are essentially the same concept from different viewpoints. This feedback is somewhat helpful as it points out a potential issue with the paper's claims, but it lacks specific guidance on how the authors might address this concern or what changes could be made to clarify the distinction. The comment provides a clear direction for improvement but does not offer detailed suggestions or actionable steps, which limits its overall impact on the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors' motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arena-based evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or make changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the relevance of the proposed method to the authors' motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It also critiques the use of arena-based evaluation systems like Chatbot Arena for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current score-based evaluation systems. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in detailing the issues with the proposed method and the limitations of arena-based evaluation systems, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors' motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arena-based evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current score-based evaluation systems. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable, as it provides a general critique but lacks detailed evidence or reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the relevance of the proposed method to the authors' motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arena-based evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current score-based evaluation systems. While the comment identifies a potential issue with the proposed method, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out a potential limitation but does not provide detailed actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are questioned about the fairness of this comparison. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the training process. While it identifies a potential problem, it lacks concrete suggestions or actions for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the training of RegMixup, specifically mentioning that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the training process, but without clear references to the relevant sections, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, leading to a slower running speed compared to other methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the claim remains unverifiable, as the authors cannot independently verify the accuracy or significance of the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, specifically noting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are questioned about the fairness of this comparison, which is a valid concern. However, the comment lacks actionable suggestions or detailed guidance on how to address this issue or improve the comparison. While it highlights a potential problem, it does not provide specific steps or recommendations for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the notation used in an unnumbered equation, specifically questioning whether the expression should be t_R^m or t_R^{m-1}. It also requests a definition of t_R^m, as this term is used subsequently and its meaning is unclear. This feedback is clear and provides a direct action for the authors to take, which is to clarify the notation and provide a definition. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l81-82,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation in the unnumbered equation, asking for clarification on whether it should be t_R^m or t_R^{m-1} and requesting a definition of t_R^m. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the notation used in an unnumbered equation, specifically whether it should be t_R^m or t_R^{m-1}. It also requests a definition of t_R^m, as this term is used subsequently and its meaning is unclear. While the comment identifies a potential issue with the notation, it does not provide any logical reasoning, examples, or references to support the claim that the notation is incorrect or unclear. The authors are left to infer the need for clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific feedback on a potential issue with the notation used in an unnumbered equation. It explicitly asks the authors to clarify whether the expression should be t_R^m or t_R^{m-1} and requests a definition of t_R^m, as this term is used subsequently and its meaning is unclear. This feedback is clear, actionable, and directly addresses a specific concern, allowing the authors to improve the clarity and consistency of their paper. The comment is detailed and provides a clear path for the authors to address the issue, making it highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using focal loss in regression tasks, specifically focusing on the potential issue of lower gradients for easy samples leading to inaccurate predictions. It suggests that the authors might be aiming for a unified approach without considering the differences between classification and regression tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for further clarification or discussion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the use of focal loss in regression tasks, specifically questioning its application in the context of IoU regression. It highlights the difference between focal loss's effectiveness in classification tasks, where it handles class imbalance, and its potential issues in regression, where lower gradients for easy samples might lead to inaccurate predictions. However, the comment does not specify which part of the paper discusses the use of focal loss or the IoU regression, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of focal loss in regression, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind using focal loss in regression tasks, specifically focusing on the potential issue of lower gradients for easy samples leading to inaccurate predictions. It highlights the difference between focal loss's effectiveness in classification tasks and its potential issues in regression, particularly in the context of IoU regression. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of detailed explanation or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the use of focal loss in regression tasks, specifically questioning its effectiveness in IoU regression. It points out that while focal loss is effective for class imbalance in classification, its lower gradients for easy samples might lead to inaccurate predictions in regression tasks. This observation suggests that the authors might be aiming for a unified approach without considering the differences between classification and regression tasks. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer the need for further clarification or discussion, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any explicit or implicit actions for the authors to take to address this question. The comment lacks guidance on how the authors might investigate or address the scalability issue, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the question needs to be addressed. Additionally, the comment does not provide specific guidance or suggestions on how to investigate or address the scalability issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this issue. Without actionable advice or insights, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the statistical significance of the improvements of the proposed model over the RL without feedback model, based on the data presented in row 3 and row 4 of Table 6. It suggests that the authors should verify if the improvements are statistically significant. However, the comment does not provide explicit guidance on how to conduct this verification or what specific statistical tests should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform statistical significance tests. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the improvements of the proposed model over the RL without feedback model, particularly noting that the BLEU-1 score is worse. This provides a clear direction for the authors to address the concern. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the improvements of the proposed model over the RL without feedback model, based on the data presented in row 3 and row 4 of Table 6. While the comment identifies a potential issue with the BLEU-1 score, it does not provide any specific reasoning, examples, or references to support the claim that the improvements are not statistically significant. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the statistical significance of the improvements of the proposed model over the RL without feedback model, as indicated in Table 6. It points out that the BLEU-1 score is worse, which raises concerns about the robustness of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what statistical tests could be used to verify the significance of the improvements. While it highlights a potential area for concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as somewhat helpful, as it identifies a problem but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"continuation to the above remark,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the possibility of relaxing the need to visit all ball-action pairs with each iteration and exploring the impact of partially covering them. This provides clear guidance on what the authors should consider and how they might approach the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide any specific reasoning, examples, or references to support why this modification might be beneficial or how it could be implemented. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs and asks what would happen in such a scenario. This feedback is somewhat helpful as it identifies a potential area for improvement and prompts the authors to consider alternative approaches. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement these changes or what impact they might have. The authors are left with a general idea but without actionable steps, making the comment somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors should use a better encoder, such as RoBERTa-base, instead of BERT to improve the results. While it suggests an alternative model, it does not provide explicit guidance on how to implement this change or what specific improvements might be observed. The action is implicit and somewhat vague, as the authors need to infer that they should experiment with a different encoder and potentially report the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether a better encoder, such as RoBERTa-base, could improve the results compared to using BERT. However, it does not specify which part of the paper this question pertains to, such as the methodology or experimental setup. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting an alternative model but does not provide detailed guidance on how to implement or evaluate this change. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether a better encoder, such as RoBERTa-base, could improve the results compared to using BERT. While it suggests an alternative model, it does not provide specific evidence or reasoning to support this claim. The comment lacks detailed justification or examples to substantiate the assertion that a better encoder would lead to improved results. Therefore, the claim is considered borderline verifiable, as it is somewhat supported but lacks sufficient detail or references to back it up.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the potential benefits of using a better encoder, such as RoBERTa-base, instead of BERT. It suggests that the authors should consider experimenting with a more advanced model to potentially improve their results. However, the comment lacks specific guidance on how to implement this change or what kind of improvements might be expected. While it provides a direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a potential area for enhancement but does not fully support the authors in making the necessary adjustments. The score aligns with a rating of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific datasets to include or how to analyze the results. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with different levels of reasoning requirements. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more datasets, but without clear references to the paper, the authors may struggle to identify the exact areas where these datasets should be added or discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with different levels of reasoning requirements. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it effectively. Without detailed justification or examples, the claim is considered borderline verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is somewhat helpful as it points out a potential area for improvement in terms of the breadth of the evaluation. However, the comment lacks specific guidance on which datasets to include or how to analyze the results, making it somewhat incomplete. The authors would benefit from additional details on how to incorporate these datasets and what specific analyses would be necessary to demonstrate the generalizability of their technique. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like Ref-NeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to compare the methods. The action is implicit and somewhat vague, as the authors need to infer that they should add these comparisons to their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the choice of baseline methods, specifically mentioning Ref-NeRF and MipNerf for comparison in the appearance decomposition and larger outdoor scene evaluations, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need revision. While the comment is specific about the suggested baselines, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like Ref-NeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. However, the comment does not provide specific reasoning or examples to support why these methods are suitable or how they would improve the evaluation. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how it should be addressed. Therefore, the comment is considered borderline verifiable, as it provides some suggestion but lacks sufficient evidence or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential improvement in the choice of baseline methods, specifically suggesting the inclusion of Ref-NeRF for appearance decomposition and MipNerf for larger outdoor scenes. This feedback is actionable as it provides specific examples of alternative methods that could enhance the evaluation of the paper. However, the comment could be more helpful if it offered additional guidance on how to compare these methods or why they are suitable. Overall, the comment is mostly helpful as it directs the authors towards improving their baseline selection, but it could be more comprehensive with additional suggestions or explanations.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without significantly impacting the performance of predictive models. This provides a clear and explicit action for the authors to take, as they need to show the practical application of their method in achieving fair policy learning while maintaining predictive performance. The comment is specific in its request for demonstration and provides a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without \"severely damaging the performance of predictive model.\" This feedback is specific in its request for a demonstration of the method's application in achieving fair policy learning while maintaining predictive performance. However, it does not explicitly mention which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its suggestion, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without \"severely damaging the performance of predictive model.\" This claim is somewhat verifiable as it provides a clear direction for the authors to address a specific aspect of their work. However, it lacks detailed examples or references to support the claim, which could make it challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors demonstrate how their proposed method can achieve fair policy learning without significantly impacting the predictive model performance. This feedback is actionable and offers a clear direction for the authors to enhance their work. By focusing on the practical application of their method, the comment helps the authors address a critical aspect of their research, making it mostly helpful. However, it could be more helpful if it provided additional guidance or examples on how to achieve this demonstration. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant concern regarding the lack of implementation details for the proposed methods, which the authors should address in Section 4.1. While the comment explicitly suggests that the authors should include these details, it does not provide specific guidance on what aspects of the implementation should be included or how to present them effectively. The action is clear and explicit, but it lacks concrete details on how to implement the suggested changes. Therefore, the comment is somewhat actionable, as it provides a clear direction but requires further elaboration to be fully actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a clear and specific issue. However, it does not specify which part of the paper should address these details, making it weakly grounded. The comment is specific in detailing the need for implementation details, but the lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a concern about the lack of implementation details for the proposed methods, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples, references, or reasoning to support why this is a significant issue or how it impacts the paper. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks detailed justification or examples to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for understanding and evaluating the paper. By pointing out this issue, the comment provides a clear direction for the authors to improve their draft by including detailed implementation descriptions in Section 4.1. This feedback is actionable and constructive, as it directs the authors to a specific area where they can enhance their work. However, the comment could be more helpful if it provided additional guidance on what specific implementation details should be included or how to present them effectively. Overall, the comment is mostly helpful, as it effectively highlights a crucial area for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting the absence of empirical evaluation and comparison with other methods. It also questions the practical value of the contribution, suggesting that even theoretical papers should provide some justification for their significance. However, the comment does not offer any specific guidance or suggestions on how the authors might address these issues, such as proposing additional experiments, comparisons, or theoretical arguments. Without concrete actions or recommendations, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, which are specific aspects of the paper. It also questions the practical value of the contribution, which is a clear and specific issue. However, the comment does not provide detailed guidance on how to address these issues, such as suggesting specific experiments or comparisons. Therefore, the comment is fully grounded and specific, but it lacks actionable guidance, making it somewhat actionable.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation and comparison with other methods, questioning the practical value of the contribution. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of empirical evidence and comparison makes it difficult for the authors to understand the basis of the criticism. Therefore, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It questions the practical value of the contribution, suggesting that even theoretical papers should provide some justification for their significance. However, the comment does not offer any specific suggestions or guidance on how the authors might address these issues, such as proposing additional experiments, comparisons, or theoretical arguments. While it highlights a significant gap in the paper, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a crucial area for improvement but does not provide detailed guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion in the manuscript regarding the use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the usage of P in the manuscript, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out a specific issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. It provides examples, such as equations (3) and (4) and line 44 in the appendix, where this confusion arises. This allows the authors to accurately pinpoint the part of the paper that needs clarification. The comment is specific in detailing what needs to be addressed, as it highlights the inconsistency and suggests that the authors should clarify the usage of P. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. The comment provides examples, such as equations (3) and (4) and line 44 in the appendix, where this confusion arises. However, it does not offer any additional reasoning, references, or examples to support the claim that this inconsistency leads to confusion. While the authors can infer that the comment is valid, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the manuscript, noting that the symbol P is used inconsistently, sometimes representing a probability and other times a cumulative distribution function. This inconsistency can lead to confusion for readers. While the comment highlights the problem, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is clear and identifies a potential area for improvement, but it lacks actionable advice on how to resolve the confusion. Therefore, the comment is somewhat helpful, as it points out a specific problem but does not offer detailed guidance on how to improve the manuscript.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the understanding of how neural networks learn natural rare spurious correlations. It also points out that most analysis and ablation studies use artificial patterns instead of natural spurious correlations, and that duplicating artificial patterns is different from natural spurious features. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to incorporate natural spurious correlations into their analysis or how to differentiate between artificial and natural patterns. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of how neural networks learn natural rare spurious correlations, which is a specific aspect of the paper. It highlights that the community is unaware of this, and that most analysis uses artificial patterns instead of natural ones. The comment also clarifies the difference between duplicating artificial patterns and natural spurious features. However, it does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and the distinction between artificial and natural patterns, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the community is unaware of how neural networks learn natural rare spurious correlations, and that most analysis uses artificial patterns instead of natural ones. The comment provides a logical reasoning by explaining the difference between duplicating artificial patterns and natural spurious features, which are complex and different in every example. However, it lacks specific examples or references to support the claim about the community's unawareness. While the reasoning is clear, the absence of supporting evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the understanding of how neural networks learn natural rare spurious correlations. It highlights that the community is unaware of this, and that most analysis and ablation studies use artificial patterns instead of natural ones. The comment also clarifies the difference between duplicating artificial patterns and natural spurious features, which are complex and different in every example. This feedback is valuable as it points out a critical area for improvement, suggesting that the authors should consider incorporating natural spurious correlations into their analysis and differentiating between artificial and natural patterns. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested additional experiments to explore the topic. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL and asks if the algorithms can be applied in more general tasks. While the comment identifies a potential area for expansion, it does not provide explicit guidance on how to address this limitation or explore the application of the algorithms in more general tasks. The action is implicit and somewhat vague, as the authors are left to infer how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the method being discussed in the paper, specifically noting that it is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL, suggesting that the authors might consider applying such algorithms in more general tasks. However, the comment does not explicitly mention which part of the paper discusses the method or navigation problems, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of generalizability, it lacks full grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL, suggesting that the authors might consider applying such algorithms in more general tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the method is limited to navigation problems or that the combination of RL and planning has already been discussed in PRM-RL. Without additional context or references, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that the method discussed can be applied in general MDP but is limited in navigation problems. It also points out that combining RL and planning has been discussed in PRM-RL, suggesting that the authors might consider applying such algorithms in more general tasks. This feedback highlights an area for potential expansion and exploration, providing the authors with a direction for future work. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address the limitations or explore the application of the algorithms in more general tasks. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the suitability of feature spaces for 1-NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion that individual standardization of feature dimensions could avoid this issue. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the suitability of their feature spaces and potentially standardize them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely whether all feature spaces are well-suited for 1-NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment further provides a suggestion that individual standardization of feature dimensions could avoid this issue. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the suitability of feature spaces for 1-NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion that individual standardization of feature dimensions could avoid this issue. However, the comment lacks specific examples or references to support the claim that feature spaces not close to a spherical Gaussian may perform poorly. Without additional evidence or references, the claim is difficult to verify, making the comment borderline verifiable. Therefore, the label is 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the suitability of feature spaces for 1-NN, specifically questioning whether all feature spaces are well-suited for this task. It also provides a suggestion that if a feature space is not close to a spherical Gaussian, it may perform poorly, and that individual standardization of feature dimensions could potentially avoid this issue. While the comment identifies a potential area for improvement and offers a specific suggestion, it lacks detailed guidance on how to implement this suggestion or what specific steps the authors should take to address the issue. The feedback is somewhat helpful as it points out a potential problem and offers a possible solution, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the definition of the \"contrastive gap,\" which is a core concept of the work. It points out that while an intuitive example is provided, the setting of this example is less convincing, and a clear, formal definition is still missing. However, the comment does not provide explicit guidance on how the authors should define the contrastive gap or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear and formal definition. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific part of the paper being addressed. It provides a clear and specific explanation of the issue, noting that the concept has not been defined clearly and lacks a formal definition. The comment also suggests that the setting of the example is less convincing, indicating a need for improvement in the example's presentation. This level of detail allows the authors to understand exactly what part of the paper needs attention and what specific issues need to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"contrastive gap\" has not been defined clearly, which is a subjective opinion. It suggests that the setting of the example is less convincing and that a clear, formal definition is still lacking. However, the comment does not provide specific examples or references to support the claim that the definition is unclear or lacking. Without additional evidence or reasoning, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is labeled as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper by pointing out that the \"contrastive gap\" is not clearly defined. This is a crucial oversight that could hinder the understanding and impact of the work. The comment suggests that while an intuitive example is provided, the setting of this example is less convincing, and a clear, formal definition is still lacking. This feedback is valuable as it highlights a specific area where the authors need to improve the clarity and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to define the contrastive gap or examples of how to make the setting of the example more convincing. Overall, the comment is somewhat helpful as it identifies a critical issue but lacks depth in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two aspects of the paper: the description of state changes and environment giving a reward in section 3.1, line 143, and the clarity of the action description in line 154. It explicitly points out that the statement is not true of standard MDP formulations, suggesting that the authors may be misrepresenting the reward structure. Additionally, it notes that the description of each action being a single feature or the power set is unclear, recommending that the authors make the description more precise. While the comment provides clear guidance on what needs to be addressed, it does not offer concrete steps on how to implement these changes. Therefore, the comment is mostly actionable, as it identifies specific issues but lacks detailed instructions for resolution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the incorrect statement about rewards in standard MDP formulations and the lack of clarity regarding the action description. This provides clear guidance on how the authors should revise their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in section 3.1, line 143, \"Then the state changes and environment gives a reward,\" is not true of standard MDP formulations. This claim is supported by the reasoning that rewards are typically associated with transitions between states, not state changes and environment. The comment also points out that it is unclear whether each action is a single feature or the power set, suggesting that the description needs to be more precise. While the reasoning is logical and provides a basis for the claim, it lacks specific examples or references to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on two key areas of the paper. It highlights an issue with the description of state changes and environment giving a reward in section 3.1, line 143, noting that this is not consistent with standard MDP formulations. This feedback is valuable as it points out a potential misrepresentation in the paper. Additionally, the comment addresses the clarity of the action description in line 154, suggesting that the authors should clarify whether each action is a single feature or the power set. This feedback is actionable and constructive, as it provides clear guidance on how the authors can improve the accuracy and clarity of their descriptions. However, the comment could be more helpful if it offered specific suggestions on how to revise the descriptions or provide examples to enhance clarity. Overall, the comment is mostly helpful, as it identifies important areas for improvement and encourages the authors to address these issues.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns in a response, leading to an increase in the score. However, the comment does not provide explicit guidance on how to incorporate these additional baselines or how to test beforehand whether they are suitable. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work [29, 5, 6]\" and \"other works discussed in related work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should include other baselines, such as those discussed in the related work section, and suggests that this would be beneficial. However, the comment does not provide specific guidance on what aspects of the baselines should be included or how they should be tested. This makes the comment fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that other baselines should be included, referencing specific works in the related work section. It suggests that the authors should consider adding these baselines to the final version of the paper. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors are encouraged to address this suggestion, but the lack of detailed justification or examples weakens the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by suggesting the inclusion of additional baselines, referencing specific works in the related work section. It also acknowledges that the authors have addressed their concerns in a response, which led to an increase in the score. However, the comment lacks detailed guidance on how to incorporate these additional baselines or how to test them beforehand. While it provides a clear direction for improvement, the feedback could be more comprehensive and actionable if it included specific suggestions or examples. Therefore, the comment is somewhat helpful, as it offers a clear area for improvement but lacks depth and detail.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about the meaning of \\delta in the statement of Lemma 5. While it prompts the authors to clarify the term, it does not provide explicit instructions or suggestions on how to address this issue. The authors are left to infer that they need to provide a definition or explanation for \\delta, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment asks a question about the meaning of \\delta in the statement of Lemma 5. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it does not provide explicit references or guidance on where to find the relevant information. Additionally, the comment is specific in that it identifies a particular term that needs clarification, but the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \\delta in the statement of Lemma 5. However, it does not provide any context, explanation, or justification for why this question is important or how it relates to the paper's content. Without additional information or reasoning, the authors are left to interpret the significance of the question, making it difficult to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \\delta in the statement of Lemma 5. While it points out a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is vague and lacks actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, as it does not offer any meaningful feedback or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue in the paper, noting that the authors set \\alpha_m uniformly to 1/M, implying that contributions from all modalities are the same. It then references works in multimodal fusion that suggest dynamically weighting modalities is important. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider dynamic weighting of modalities. While the suggestion is concrete, the lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is, noting that the authors set \\u03b1_m uniformly to 1/M, implying that contributions from all modalities are the same, and references works in multimodal fusion that suggest dynamically weighting modalities is important. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that setting \\u03b1_m uniformly to 1/M implies that contributions from all modalities are the same, which is a subjective interpretation. However, it references works in multimodal fusion that suggest dynamically weighting modalities is important, providing a basis for the claim. The comment is somewhat verifiable as it offers a logical reasoning and reference to external work, but it could be more robust with additional examples or detailed explanations. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors set \\u03b1_m uniformly to 1/M, which implies that contributions from all modalities are the same. It references works in multimodal fusion that suggest dynamically weighting modalities is important, highlighting a potential area for improvement. However, the comment does not provide specific guidance on how the authors might address this issue or what changes they should make to their draft. While it points out a potential area for enhancement, it lacks actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. While the comment identifies a problem with the language, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The authors are left without a clear understanding of what changes are needed to improve the clarity of the text. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is problematic, namely the difficulty in understanding the use of \"to meet\". Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"to meet\" in the paper is pervasive and difficult to understand. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. While the comment highlights a potential area for improvement in the clarity of the writing, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a specific area that needs attention, but it lacks actionable advice or examples of how to improve the clarity of the text. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the notation used in the text (L_task) and the notation used in Figure 1 (L_class). This suggests that the authors should ensure consistency in their notation throughout the paper. However, the comment does not provide explicit guidance on how to address this inconsistency or what specific changes need to be made to the text or figures. The action is implicit, as the authors can infer that they need to correct the inconsistency, but the lack of detailed instructions makes the action vague and challenging to execute. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment points out a discrepancy in the notation used for the task loss, specifically noting that it is called L_task in the text but L_class in Figure 1. This provides a clear and specific reference to the part of the paper where the inconsistency occurs, allowing the authors to accurately identify the issue. The comment is fully grounded as it explicitly mentions the sections or figures where the discrepancy is noted. It is also specific because it clearly specifies what needs to be addressed, which is the inconsistency in the notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and requires no further verification or reasoning to be understood. The comment is a normal statement, as it describes a factual observation without making any claims or suggestions. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and highlights a potential area of confusion for the reader. However, the comment does not provide any suggestions or guidance on how the authors might address this inconsistency or improve the clarity of their presentation. While it points out a minor issue, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should ensure consistency in their notation, but the comment does not offer detailed steps or examples to facilitate this process. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these limitations or what specific aspects of the method need to be improved. Without clear instructions or suggestions, the authors are left without a clear path to respond to the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it lacks specific references or context. Additionally, it does not provide detailed guidance on what needs to be addressed or how the authors should respond. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples to substantiate the assertion about the method\\'s limitations. Without additional context or evidence, the authors may find it challenging to understand or address the concerns raised in the comment. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as 'pretty shallow.' However, it does not provide any specific suggestions or guidance on how the authors might address these limitations or improve their method. The comment lacks actionable feedback, leaving the authors without a clear understanding of what changes are needed or how to proceed. As a result, the comment is not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It implies that the current evaluation, which only includes answer generation and summarization, is limited because these tasks are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment provides a clear action for the authors to take, which is to expand the evaluation to include machine translation. This action is explicit and concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It highlights that the current evaluation, which only includes answer generation and summarization, is close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment implies that expanding the evaluation to include machine translation would strengthen the paper. However, it does not specify which part of the paper discusses the evaluation methodology or where the suggestion to include machine translation evaluation should be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper it addresses. The comment is specific in suggesting an additional evaluation method, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work only uses answer generation and summarization to evaluate the proposed method, which are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation would provide a more convincing evaluation due to the lower uncertainties per word. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The claim is somewhat verifiable as it provides a logical argument but lacks detailed evidence or references to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation methodology of the proposed method, noting that it only uses answer generation and summarization, which are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment suggests that including machine translation in the evaluation would provide a more convincing assessment due to the lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the paper's evaluation. However, it could be more helpful if it included additional details or examples of how machine translation could be integrated into the evaluation process. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is explicit in its request for clarification, it does not provide any guidance or suggestions on how the authors might address these questions or improve their draft. The action is implicit, as the authors need to infer that they should clarify these details in their paper. However, the lack of concrete guidance on how to implement or address these questions makes the comment somewhat actionable. Therefore, it aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and refers to the \"response letter,\" which should be clear to the authors. It is also specific because it asks for clarification on the \"dropping rate\" and the \"number of masks generated,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. This is a factual question that requires the authors to provide additional information or clarification in their paper. However, the comment does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the implementation details of the dropout mechanism, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it prompts the authors to provide additional information or clarification in their paper. However, the comment could be more helpful if it suggested ways to address these questions or provided guidance on how to improve the clarity of the explanation. Overall, the comment is somewhat helpful, as it identifies a specific area for improvement but lacks depth in terms of actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for further justification of the effectiveness of the proposed two-stage optimization approach. It suggests that the authors should include comparisons with other single-stage attacks and provide proper benchmarks and comparisons with state-of-the-art algorithms to substantiate the effectiveness of the technical contributions. While the comment explicitly suggests what needs to be done, it lacks specific guidance on how to conduct these comparisons or what benchmarks to use. The action is clear but somewhat vague, as it does not provide detailed instructions on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the proposed two-stage optimization approach, suggesting that it needs further justification. It mentions the need for comparisons with other single-stage attacks and proper benchmarks and comparisons with state-of-the-art algorithms. However, the comment does not specify which part of the paper discusses the proposed approach or where these comparisons should be made. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the need for additional comparisons, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that the authors should include comparisons with other single-stage attacks and provide benchmarks and comparisons with state-of-the-art algorithms to substantiate the effectiveness of the technical contributions. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the claim is considered borderline verifiable, as it provides some basis for the suggestion but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by highlighting the need for further justification of the effectiveness of the proposed two-stage optimization approach. It suggests that the authors should include comparisons with other single-stage attacks and provide benchmarks and comparisons with state-of-the-art algorithms to substantiate the technical contributions. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on how to strengthen the paper. However, the comment could be more helpful if it included suggestions on which specific benchmarks or comparisons would be most effective. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance the rigor and persuasiveness of their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that it does not provide information about the type of GPUs used and the inference time during testing. While the comment identifies a gap in the paper's content, it does not offer any explicit or implicit suggestions on how the authors might address this issue. The authors are left without guidance on what additional information to include or how to improve the paper to address this concern. Therefore, the comment is unactionable, as it lacks any direction or advice on how to resolve the identified issue.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing information regarding the type of GPUs and inference time when testing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide information about the type of GPUs used and the inference time during testing. However, the comment lacks any supporting evidence or reasoning to substantiate this claim. Without specific examples or references, the authors are left without guidance on how to address this issue or what additional information might be relevant. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the absence of information regarding the type of GPUs used and the inference time during testing. This feedback is clear and actionable, as it directs the authors to include this information to enhance the completeness and transparency of their work. By addressing this issue, the authors can provide a more comprehensive understanding of their experimental setup and results, which is crucial for the reproducibility and credibility of their research. However, the comment could be more helpful if it suggested specific ways to include this information or examples of how to present it effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the performance of RS-D4PG monotonically increasing with respect to \u03bb values and suggests exploring what happens when \u03bb is even smaller. It also points out missing variables (\u03c4 and \u03b7) in the bracket on Page 3, Line 2, and missing variables (\u03c4 and \u03b7) in the equation on Page 3, Line 4. While the comment identifies specific areas that need clarification or further exploration, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and specific locations on \"Page 3, Line 2\" and \"Page 3, Line 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as the performance of RS-D4PG with respect to \u03bb values and the missing variables in the equations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the performance of RS-D4PG with respect to \u03bb values and points out missing variables in equations. While the questions are specific and require the authors to investigate further, the comment lacks detailed reasoning or references to support the claims. The authors are left to infer the need for additional analysis or clarification, making the comment somewhat verifiable. Therefore, it aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises specific questions about the performance of RS-D4PG with respect to \u03bb values and points out missing variables in equations. It suggests exploring the behavior of the model with even smaller \u03bb values, which could provide valuable insights into the model's performance. Additionally, it identifies missing variables in the equations, indicating areas where clarification or correction is needed. While the comment is somewhat vague in terms of providing detailed guidance on how to address these issues, it does offer actionable feedback that could help the authors improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment provides a specific action for the authors to take, indicating that they should adjust the connections in the figure to accurately represent the data. The action is explicit and concrete, as it clearly specifies what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement regarding the connections in the Perceptual Metric, specifying which images should be connected and which should not. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment is specific and provides a clear suggestion for improvement, indicating a potential error or misrepresentation in the figure. However, it does not offer any additional context, reasoning, or references to support the claim. While the suggestion is logical and based on the description, the lack of detailed explanation or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, suggesting that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific direction to improve the accuracy and clarity of their figure. By addressing this suggestion, the authors can enhance the presentation of their results and ensure that the figure accurately reflects the data. The comment is mostly helpful as it offers a clear and direct improvement, though it could be more comprehensive if it included additional suggestions or context. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific sentence in the paper that is confusing and requires clarification. It suggests that the authors should re-read the sentence and the subsequent sentences to understand it better. However, the comment does not provide explicit guidance on how to clarify the sentence or what specific changes should be made. The action is implicit and vague, as it does not specify what needs to be done to make the sentence clearer. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the sentence at lines 93-95. This allows the authors to accurately identify the section being discussed. The comment is also specific because it clearly identifies the issue with the sentence, which is its confusion and lack of clarity. The authors are informed about what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a specific sentence in the paper is confusing and requires clarification. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors cannot determine why the sentence is confusing or how it could be clarified. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with a sentence in the paper, noting that it is confusing and requires clarification. While the comment highlights a potential area for improvement, it does not provide detailed suggestions or guidance on how to clarify the sentence. The feedback is somewhat helpful as it points out a need for better clarity, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific instances where the authors need to address certain claims or statements in their paper. It explicitly mentions that the claims on lines 78-79, 129-130, 156-158, and 217-218 require citations or evidence. However, the comment does not provide any guidance on how the authors should go about finding or providing these citations or evidence. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment provides specific line numbers (78-79, 129-130, 156-158, and 217-218) where the authors need to address certain claims or statements. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. Additionally, the comment specifies what needs to be addressed in each instance, such as the need for citations or evidence. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific claims in the paper that require citations or evidence. It provides line numbers (78-79, 129-130, 156-158, and 217-218) where these claims are made, allowing the authors to accurately pinpoint the sections that need attention. However, the comment does not provide any examples, detailed reasoning, or references to support these claims, making it somewhat verifiable. The authors are informed about the need for citations or evidence but are not given specific guidance on how to obtain or present them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific instances in the paper where claims are made without sufficient evidence or citations. It points out that the authors need to provide citations for the claims on lines 78-79, 129-130, 156-158, and 217-218. This feedback is clear and actionable, as it directs the authors to specific areas where they need to enhance their work by providing evidence or citations. However, the comment could be more helpful if it offered guidance on how to find or present the evidence or citations. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoder-decoder for multiple tasks, while Figure 2 shows one encoder-decoder per auxiliary task. This observation is clear and explicit, providing a direct action for the authors to take: they should ensure consistency between the figures. The comment is specific in identifying the issue and suggests a concrete action to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the number of encoder-decoders shown in the two figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoder-decoder for multiple tasks, while Figure 2 shows one encoder-decoder per auxiliary task. This observation is factual and based on a direct comparison of the figures. However, the comment does not provide any additional reasoning, examples, or references to support the claim that this inconsistency is problematic or needs correction. While the authors can infer that the inconsistency might be an issue, the lack of detailed explanation or justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoder-decoder for multiple tasks, while Figure 2 shows one encoder-decoder per auxiliary task. This observation is clear and actionable, providing the authors with a direct point of comparison and highlighting a potential issue with the consistency of their figures. By pointing out this discrepancy, the comment helps the authors ensure that their figures accurately represent the data and maintain consistency throughout the paper. However, the comment could be more helpful if it suggested specific ways to address the inconsistency or provided guidance on how to improve the clarity of the figures. Overall, the comment is mostly helpful as it identifies a clear issue that needs attention.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether each node can attend to its own lower-level representation, based on the description of equation 2 and the concept of neighboring nodes. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct the authors to provide a response or make changes to their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the discrepancy between the description and the equation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether each node can attend to its own lower-level representation, based on the description of equation 2 and the concept of neighboring nodes. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on how to address the issue, leaving the authors without clear direction. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether each node can attend to its own lower-level representation, based on the description of equation 2 and the concept of neighboring nodes. However, the comment does not provide any specific reasoning, examples, or references to support the claim that only neighboring nodes are attended to. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the representation of nodes in the paper, particularly concerning whether each node can attend to its own lower-level representation. It points out a potential discrepancy between the description of equation 2 and the concept of neighboring nodes, which could lead to confusion. While the comment identifies an area that needs clarification, it does not provide detailed guidance or suggestions on how to address the issue. The feedback is somewhat helpful as it highlights a potential area of confusion, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions how the inequality after line 433 follows from Lemma 7, suggesting that it might be a combination of previous inequalities. The comment implies that the authors should clarify the connection between Lemma 7 and the inequality, but it does not provide explicit guidance on how to do so. While the action is implicit, it is vague and lacks concrete details on how the authors should facilitate the reading or clarify the connection. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the connection between the inequality after line 433 and Lemma 7. The comment requests clarification on how the inequality follows from the lemma, which is a specific and actionable request. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the logical connection between an inequality and Lemma 7, specifically asking how the inequality after line 433 follows from the lemma. While the comment implies that the authors should clarify this connection, it does not provide any evidence or reasoning to support the claim that the inequality follows from the lemma. The lack of detailed explanation or justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion regarding the derivation of an inequality from Lemma 7, which is a crucial aspect of the paper. It requests clarification on how the inequality after line 433 follows from the lemma, suggesting that it might be a combination of previous inequalities. This feedback is actionable as it directs the authors to a specific area where they need to provide more detail or explanation. However, the comment could be more helpful if it offered suggestions on how to clarify the connection or provide additional context. Overall, the comment is mostly helpful as it highlights a need for improvement in the clarity and coherence of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the unclear main contribution, the overstated novelty claims, and the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and vague, as the authors are left to infer what needs to be done to clarify these aspects. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, noting that it is unclear and that the novelty claims are overstated or not well-supported. It also points out the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not specify which part of the paper discusses the main contribution, making it weakly grounded. The specificity of the comment is moderate as it identifies areas that need clarification, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear and that the novelty claims are overstated or not well-supported. It also notes the lack of clarity in how the proposed method copes with dynamic large-scale multitasking and how automation is achieved. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leading to a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, specifically focusing on the clarity of the main contribution, the novelty claims, and the explanation of how the proposed method handles dynamic large-scale multitasking and automation. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. This lack of actionable feedback makes the comment somewhat helpful, as it points out areas for improvement but does not offer detailed advice or examples. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the results of the bottom-up method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\\' method on the standard MS COCO dataset, particularly in easy (non-occluded) settings. While the comment provides explicit guidance on what data to include and how to evaluate performance, it lacks specific instructions on how to implement these suggestions, such as which columns or metrics to focus on. The action is somewhat vague, as it does not provide detailed steps or examples for inclusion and evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the bottom-up method [9]\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what data to include in the table and how to evaluate the performance of the authors\\' method on the MS COCO dataset, particularly in easy (non-occluded) settings. This level of detail helps the authors understand exactly what needs to be addressed and how to do it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including the results of the bottom-up method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\\' method on the standard MS COCO dataset, particularly in easy (non-occluded) settings. While the comment provides a clear suggestion for improvement, it lacks specific reasoning or references to support why this inclusion would be beneficial. The authors are left to infer the value of this suggestion, which could be helpful but is not fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft by including the results of the bottom-up method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\\' method on the standard MS COCO dataset, particularly in easy (non-occluded) settings. This feedback is actionable and constructive, as it guides the authors on what additional data to include and how to assess the performance of their method. However, the comment could be more helpful if it provided more detailed guidance on how to evaluate the performance or what specific metrics to focus on. Overall, the comment is mostly helpful, as it offers clear directions for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their approach. It lacks concrete guidance on what changes could be made to align the paper with the depth of true guideline understanding. As a result, the authors are left without actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the paper only considers label names, descriptions, and few-shot examples, while annotation guidelines in the IE domain are complex and curated by linguists. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. This provides a clear and logical basis for the critique, making the claim mostly verifiable. However, the comment could be strengthened by including more detailed references or examples to further substantiate the claim. Overall, the feedback is mostly verifiable, as it offers a reasonable basis for the critique but lacks some depth in supporting evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the claim of using \"annotation guideline\" in the paper, suggesting that it may be an overstatement. It provides specific examples from the TACRED slot filling guidelines, such as the rule for city of birth, to illustrate the complexity of annotation guidelines in the Information Extraction (IE) domain. This critique offers a clear and actionable feedback, highlighting a potential gap in the paper's approach. However, the comment could be more helpful if it suggested specific ways the authors could address this issue or improve their approach to align with the depth of true guideline understanding. Overall, the comment is somewhat helpful as it identifies a meaningful area for improvement but lacks detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment comparison is weak because the authors only compare their method to the BERT-baseline. It recommends comparing the method to token pruning and token combination baselines. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct these additional comparisons. The authors are left to infer that they need to add these comparisons to their experimental setup. This lack of explicit guidance makes the action somewhat vague and leaves the authors with limited direction on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment comparison is weak, specifically mentioning that the authors only compare their method to the BERT-baseline. It recommends comparing the method to token pruning and token combination baselines. However, the comment does not specify which part of the paper this comparison is intended for, such as a specific section or table. This makes it difficult for the authors to accurately identify the section being addressed, resulting in weak grounding. The comment is specific in suggesting additional comparisons, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment comparison is weak, as the authors only compare their method to the BERT-baseline. It suggests that the authors should compare their method to token pruning and token combination baselines. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general suggestion but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental comparison, noting that the authors only compare their method to the BERT-baseline. It suggests that the authors should include comparisons to token pruning and token combination baselines to provide a more comprehensive evaluation of their method. This feedback is clear and actionable, as it directs the authors to specific areas where they can enhance their experimental setup. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or why these baselines are particularly relevant. Overall, the comment is mostly helpful, as it offers valuable suggestions for improvement but could be more detailed in its guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental section should include a comparison to coordinate-aware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to add this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these methods in their experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental section should include a comparison to coordinate-aware methods like TFN or SchNet. However, it does not specify which part of the paper this comparison should be made or which section of the paper is being addressed. The authors cannot confidently determine which part of the paper is being discussed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of certain methods, but without explicit references to the experimental section, it remains weakly grounded and specific. Therefore, this comment aligns with category 3: Weakly Grounded and Specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental section should include a comparison to coordinate-aware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not provide specific reasoning or examples to support why such a comparison is important or how it would enhance the paper. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors may need to infer the importance of the suggested comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section by suggesting the inclusion of comparisons to coordinate-aware methods like TFN or SchNet. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper's experimental evaluation. By comparing against methods that are aware of point coordinates, the authors can better demonstrate the effectiveness of their approach. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or why these methods are particularly relevant. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential weakness in the paper by stating that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might identify or discuss these weaknesses, leaving the authors without a clear path forward. As a result, the comment is unactionable, as it does not offer any actionable steps or suggestions for improvement. Therefore, it aligns with the lowest score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the authors did not show the possible weaknesses of the proposed model. It lacks any reference to a specific section, table, or figure, making it difficult for the authors to identify the exact area that needs improvement. Additionally, the comment is not specific because it does not provide any details on what aspects of the model's weaknesses are not addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors did not show the possible weaknesses of the proposed model. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples of how to demonstrate the weaknesses, the authors may struggle to improve their draft. The comment is somewhat helpful as it highlights an area for improvement, but it does not provide sufficient detail or direction for the authors to effectively address the concern. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It suggests that the paper lacks a related work section and does not experiment with other extract-then-generate methodologies. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It suggests that the paper lacks a related work section and does not experiment with other extract-then-generate methodologies. However, the comment does not specify which part of the paper addresses these issues, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific in its questioning of the novelty and contribution, the lack of grounding makes it challenging for the authors to understand the exact areas that require improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It suggests that the paper lacks a related work section and does not experiment with other extract-then-generate methodologies. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the novelty and contribution of the proposed idea in the context of long document summarization. It points out the lack of a related work section and the absence of experiments with other extract-then-generate methodologies, which are crucial for understanding the paper's position and potential impact. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or what additional experiments could be conducted to strengthen their work. While it identifies a significant gap in the paper, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but requires more detailed guidance for the authors to improve their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes alternative directions for dealing with churn, such as using unlabeled data or applying constraints. However, the comment does not provide explicit guidance on how the authors should address the computational cost or explore the suggested alternatives. The action is implicit and vague, as it leaves the authors to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes alternative directions for dealing with churn, such as using unlabeled data or applying constraints. However, the comment does not specify which part of the paper this issue relates to, making it difficult for the authors to identify the exact section or figure being addressed. While the comment is specific about the concerns raised, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes alternative directions for dealing with churn, such as using unlabeled data or applying constraints. However, the comment lacks specific examples or references to support the claim about the computational cost or the effectiveness of the proposed alternatives. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes alternative directions for dealing with churn, such as using unlabeled data or applying constraints. While the comment identifies a potential issue with the approach, it does not provide specific guidance or suggestions on how to address the computational cost or explore the proposed alternatives. The feedback is somewhat helpful as it highlights an area for improvement but lacks depth and actionable advice, leaving the authors with limited insights to enhance their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from B-GLN. While the comment implies that the authors should include more related work, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on which additional works to include or how to compare their method with B-GLN. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from B-GLN. However, the comment does not specify which part of the paper the introduction of related work is located, making it weakly grounded. It is specific in suggesting the need for more work on GLN and the comparison with B-GLN, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of related work is insufficient and suggests providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from B-GLN. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not fully verifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the introduction of related work, noting that it is insufficient and recommending the inclusion of more work on GLN to reflect the advantages or differences of the proposed method, particularly in comparison to B-GLN. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft. However, it could be more helpful if it included suggestions on which specific works to include or how to effectively compare the proposed method with B-GLN. Overall, the comment is mostly helpful as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using only one dropout rate for Moon\\'s approach, while suggesting that Variational dropout and recurrent dropout parameters are used. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider using multiple dropout rates for Moon\\'s approach to align with the other methods. While the suggestion is concrete, the lack of explicit guidance on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of a single dropout rate for Moon\\'s approach, contrasting it with the use of input-output and recurrent dropout parameters in Variational dropout. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the dropout rate usage, the absence of explicit grounding reduces the comment\\'s effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind using only one dropout rate for Moon\\'s approach, while suggesting that Variational dropout and recurrent dropout parameters are used. However, the comment does not provide any specific reasoning or evidence to support why this choice was made or how it might affect the results. It lacks detailed explanations or references to relevant literature that could help the authors understand the implications of this choice. As a result, the claim is not verifiable, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the rationale behind using only one dropout rate for Moon\\'s approach, while suggesting that Variational dropout and recurrent dropout parameters are used. This feedback is somewhat helpful as it points out a potential inconsistency in the methodology and prompts the authors to consider alternative approaches. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors might address this issue or what changes could be made to their approach. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the absence of larger-scale experiments, specifically mentioning the lack of experiments with larger state-action spaces and non-trivial dynamics, such as grid-worlds with walls or other non-trivial tiles. It suggests that the absence of these experiments might be due to a lack of time or scalability issues. The comment also provides examples of alternative experimental domains, such as simple video-game domains, which could be used to assess the method. However, the comment does not explicitly instruct the authors to include these experiments or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should add larger-scale experiments and consider specific examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for larger-scale experiments, which allows the authors to accurately identify the part of the paper being addressed. It specifies the type of experiments that would be beneficial, such as those with larger state-action spaces and non-trivial dynamics, including examples like grid-worlds with walls and other non-trivial tiles. The comment also suggests alternative experimental domains, such as simple video-game domains, which further clarifies the need for additional experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the absence of larger-scale experiments, specifically mentioning the lack of experiments with larger state-action spaces and non-trivial dynamics. It suggests that the absence of these experiments might be due to a lack of time or scalability issues. The comment provides examples of alternative experimental domains, such as simple video-game domains, which could be used to assess the method. However, it does not offer specific references or detailed reasoning to support the claim that these experiments are necessary or would significantly improve the paper. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of larger-scale experiments, particularly those with larger state-action spaces and non-trivial dynamics. It questions the reason for this omission, suggesting that it might be due to a lack of time or scalability issues. The comment provides specific examples of alternative experimental domains, such as simple video-game domains, which could be used to assess the method. This feedback is valuable as it directs the authors to consider expanding their experimental evaluation to include more complex scenarios, which would help in better judging the method's performance and scalability. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these additional experiments or suggested specific types of analyses that would be beneficial. Overall, the comment is mostly helpful, as it offers clear suggestions for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the authors\\' draft, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. While the comment identifies a gap in the authors\\' work, it does not provide explicit guidance on how the authors should address this issue or what specific measurements they could consider. The action is implicit, as the authors need to infer that they should include a quantitative analysis to address the identified gap. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of quantitative measurement regarding occupation bias relative to real distributions in society, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing aspect, which is the lack of quantitative measurement for occupation bias. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This is a specific claim that highlights a gap in the authors\\' work. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of missing measurements or references to similar studies. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the authors\\' work, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This feedback is clear and actionable, as it highlights a critical area for improvement that could enhance the rigor and depth of the paper. By pointing out the absence of quantitative analysis, the comment encourages the authors to consider and implement such measurements, which would strengthen their argument and provide a more comprehensive understanding of the issue. However, the comment could be more helpful if it suggested specific types of quantitative measurements or provided examples of how to conduct such analysis. Overall, the comment is mostly helpful as it directs the authors towards an important improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or incorporate it into their work. The action is implicit, as the authors would need to infer that they should consider the impact of adaptive gradient methods on their findings and potentially explore this aspect in their analysis or experiments. The comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the impact of adaptive gradient methods, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, the comment does not provide any specific reasoning, examples, or references to support the claim that adaptive gradient methods could affect the findings or amplify updates. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of adaptive gradient methods instead of SGD, suggesting that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. This feedback is somewhat helpful as it identifies a potential area for consideration and prompts the authors to think critically about the implications of their choice of optimization method. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or incorporate it into their work. The feedback is incomplete and could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the experiments: the limited types of teacher architectures and the age of the compared methods. While it identifies these areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in their comparisons. This lack of explicit and detailed guidance makes the comment somewhat actionable, as the authors can understand the need for improvement but may struggle to implement it effectively. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the experiments, such as the limited types of teacher architectures and the age of the compared methods, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are not sufficient enough, specifically noting the limited types of teacher architectures and the age of the compared methods. While the comment identifies these issues, it lacks detailed reasoning or references to support why these limitations are significant or how they impact the paper's conclusions. The authors are left to infer the importance of these points, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the experiments: the limited types of teacher architectures and the age of the compared methods. It provides specific feedback by suggesting that the authors should include more diverse teacher architectures and compare their methods with more recent studies. This feedback is clear and actionable, offering the authors a clear direction for enhancing the comprehensiveness and relevance of their experiments. However, the comment could be more helpful if it provided additional guidance on how to select or implement the suggested improvements. Overall, the comment is mostly helpful as it effectively highlights important areas for improvement and directs the authors towards specific actions, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might incorporate information from 2-hop neighbors or clarify the effectiveness of their method. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is not grounded as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide any specific evidence, reasoning, or references to support these claims. Without detailed justification or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper, specifically the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide any suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is vague and lacks actionable advice, making it difficult for the authors to understand how to enhance their work. As a result, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, it does not provide explicit instructions or detailed guidance on how to implement these suggestions, such as which specific parts of the paper need to be revised or what specific analyses should be conducted. The actions are implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without clear steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, the comment does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs revision. While the comment provides some specificity by mentioning the type of image and dataset, it lacks full grounding as it does not explicitly reference a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, the comment lacks specific reasoning or evidence to support why these changes are necessary or beneficial. It does not provide detailed explanations or references to justify the recommendation, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the experimental setup by recommending the use of DICOM images instead of PNG images and suggesting the FastMRI challenge dataset. It also mentions the importance of comparing inference speeds between different methods. However, the comment lacks detailed guidance on how to implement these suggestions, such as which specific sections of the paper need to be revised or what specific analyses should be conducted. While it offers valuable insights, the lack of actionable steps limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While it implies that the authors should consider optimizing and validating their approach, the comment does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed for optimization and validation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ProtPainter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the binder design, noting that ProtPainter only provides an empirical conformation estimation and requires further optimization and validation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While the comment suggests that further optimization and validation are required, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. This feedback is clear and actionable, as it directs the authors to consider enhancing the optimization and validation of their approach. However, the comment could be more helpful if it provided specific suggestions or guidance on how to achieve this optimization and validation. Despite this, the comment offers a valuable insight that can guide the authors in improving their work, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model's time scale of adaptation. While the comment provides some context and suggests a potential area for further exploration, it does not explicitly instruct the authors to provide this information or clarify it in their draft. The action is implicit, as the authors need to infer that they should provide more details about the training process and the impact of cycle duration. However, the comment lacks concrete guidance on how to address this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model's time scale of adaptation. However, the comment does not specify which part of the paper Figure 7 is located in, making it weakly grounded. It is specific in detailing what needs to be clarified regarding the training process and the impact of cycle duration. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point requests clarification on how the model in Figure 7 was trained and suggests considering the impact of changing the cycle duration on the model's time scale of adaptation, referencing Smirnakis et al. Nature 1997. While the comment provides a specific reference to external work, it does not offer detailed reasoning or examples to support the claim that the model cannot handle longer time scales. The lack of explicit justification or detailed explanation makes the claim somewhat verifiable, as the authors would need to provide more context to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model's time scale of adaptation. It references Smirnakis et al. Nature 1997, which provides context for the discussion. However, the comment lacks specific guidance on what information the authors should include to address this request, making it somewhat helpful. While it identifies an area for clarification, it does not provide detailed suggestions or examples to enhance the authors' understanding or improve the draft. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it raises an interesting point, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this scenario or what changes could be made to their draft to account for it. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. Additionally, it does not specify what needs to be addressed or how the authors might approach this scenario. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the issue. Therefore, it is classified as \"No\" because it lacks any claim or assertion that needs to be verified.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it prompts the authors to consider this scenario, it does not provide any guidance or suggestions on how to address it or what changes might be necessary in their draft. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of how to improve their work. Therefore, the comment is barely helpful, as it identifies a potential area for consideration but does not offer substantial assistance in addressing it. This aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more evaluation would be beneficial, particularly for CIFAR-10 in full label and lower label scenarios. However, it does not provide explicit guidance on what specific evaluations should be conducted or how the authors should approach this additional evaluation. The action is implicit, as the authors need to infer that they should add more evaluations, but it lacks concrete details on what to evaluate or how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evaluation would be beneficial, especially for CIFAR-10 in full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be conducted in or how it should be integrated. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while it suggests the need for more evaluation, it does not provide specific details on what kind of evaluation is required or how it should be conducted, making it specific but not fully specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evaluation would be beneficial, particularly for CIFAR-10 in full label and lower label scenarios. However, it does not provide any specific reasoning, examples, or references to support why this additional evaluation is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more evaluation would be beneficial, especially for CIFAR-10 in full label and lower label scenarios. However, it lacks specificity and does not provide detailed guidance on what kind of additional evaluation is needed or how it should be conducted. While it points out a potential area for improvement, the comment does not offer actionable advice or suggestions for enhancing the paper's evaluation, making it somewhat helpful. The authors would need to infer that they should add more evaluations, but the comment does not provide enough detail to guide them effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H->N and H->B using less data than H->N+B, and H->N->H and H->N->H using less data than H->N+B->H. While the comment identifies a potential issue with the comparability of the results, it does not explicitly instruct the authors to address this concern or provide guidance on how to ensure fair comparisons. The action is implicit and somewhat vague, as the authors need to infer that they should consider the data usage in their comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons in Table 2, particularly regarding the use of different amounts of data in the comparisons. The authors are informed about the specific comparisons that use less data, such as H->N and H->B compared to H->N+B, and H->N->H compared to H->N+B->H. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H->N and H->B compared to H->N+B, and H->N->H compared to H->N+B->H. However, the comment does not offer any justification or reasoning for why this comparability issue is significant or how it might affect the results. Without additional context or explanation, the authors may find it challenging to understand the implications of the data usage differences. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H->N and H->B compared to H->N+B, and H->N->H compared to H->N+B->H. This feedback is clear and actionable, as it highlights a specific area where the authors should consider ensuring fair comparisons. However, the comment could be more helpful if it suggested ways to address the issue or provided guidance on how to ensure that the comparisons are fair. Overall, the comment is somewhat helpful as it points out a potential problem that needs attention, but it lacks depth in terms of actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting that it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several issues, it does not provide explicit guidance on how to address them or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact areas that need attention. The lack of specific guidance on how to address these issues further reduces the comment's effectiveness. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the issues and address them effectively. The lack of detailed justification or references makes the claim somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several concerns about the placement of an addition, the clarity of the iterative algorithm application, and the lack of references to Laplacian eigenmaps. It questions the counterintuitive placement of the addition, suggesting it might be more logical to be placed elsewhere. The comment also points out a lack of clarity regarding the iterative algorithm's application, specifically whether it is applied with one or two iterations, and what happens for larger iterations. Additionally, it notes the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies several areas for improvement, it lacks specific guidance on how to address these issues or what actions the authors should take. The feedback is somewhat helpful as it highlights important aspects that need attention, but it could be more comprehensive and actionable to fully assist the authors in improving their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment does not explicitly instruct the authors to remove or reorganize the section, nor does it provide specific guidance on how to better integrate the description of the proposed methodology with the model choice or how to use the time spent on ResNet architecture more effectively. The action is implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in its critique of the inclusion and relevance of Section 2.1 and the description of the proposed methodology, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides a general critique but lacks detailed justification or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the inclusion of Section 2.1, specifically questioning the relevance of Batch Normalization in the context of the proposed Conditional Batch Normalization (CBN). It suggests that the description of the methodology is independent of the model choice and that the time spent on describing the ResNet architecture could be better utilized to provide motivation and intuition for the CBN approach. While the comment highlights areas for potential improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is somewhat helpful as it points out areas for clarification and improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It highlights a potential inconsistency in the reasoning, suggesting that multiplying by a nicely-conditioned matrix might not result in a sparse matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for clarification or correction. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue raised in the paper at line 122, where the authors assume a dense projection matrix multiplication leads to a sparse matrix. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly explains the inconsistency in the reasoning and questions the assumption of sparsity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It points out a potential inconsistency in the reasoning, suggesting that multiplying by a nicely-conditioned matrix might not result in a sparse matrix. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper regarding the assumption made in equation (1) about the sparsity of the resulting matrix after multiplication by a dense projection matrix. It questions the reasoning behind this assumption, suggesting that multiplying by a nicely-conditioned matrix might not result in a sparse matrix. This feedback is somewhat helpful as it highlights a potential inconsistency in the paper's logic, prompting the authors to reconsider their assumptions. However, the comment could be more helpful if it provided guidance on how the authors might address this issue or what changes could be made to clarify the reasoning. Overall, the comment offers a clear point of improvement but lacks depth in its suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors need to provide a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This action is clear and concrete, as it specifies exactly what needs to be done to strengthen the paper. The authors know precisely how to address the feedback by including the requested figure, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first question being addressed, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it provides a clear and actionable suggestion for the authors to include a figure demonstrating the decline in accuracy of a predictor over time in different settings. This guidance is detailed and helps the authors understand exactly what needs to be added to their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evidence of the motivation is not direct and suggests that the authors need to plot a figure to support their claim. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or references to existing literature that could strengthen the argument. The comment is somewhat verifiable as it offers a reasonable suggestion but could benefit from additional context or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the evidence for the motivation is not direct. It suggests that the authors should include a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim. This feedback is clear and actionable, providing the authors with a concrete direction for improving the paper. However, the comment could be more helpful if it included additional suggestions or examples of how to effectively present this evidence. Overall, the comment is mostly helpful as it offers a clear and actionable improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It asks the authors to explain how excessive risk is defined in line 103 and how it is calculated in practice, particularly concerning expectation. The comment also questions why excessive risk is a good representation for fairness, given that the optimal solution \u03b8* is not the optimal solution for the loss function with respect to data of group a, potentially leading to negative values. The reviewer observes that all excessive risk values in Figure 3 and Figure 7 are positive and asks if these values are comparable across different groups. These questions and requests for clarification provide explicit guidance on what the authors should address, making the comment highly actionable. The authors know exactly what aspects of the paper need further explanation or clarification, which helps them improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, including the definition of excessive risk, its calculation, and its comparability across different groups. This level of detail provides clear guidance on how the authors should respond, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It does not contain any subjective opinions or claims that require verification. The questions are logical and seek to understand the methodology and its implications, making the comment primarily factual and descriptive. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides detailed questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It specifically asks the authors to explain how excessive risk is defined in line 103, how it is calculated in practice, and why it is a good representation for fairness. The reviewer also points out a potential issue with the values in Figure 3 and Figure 7, noting that they are all positive despite the theoretical possibility of negative values. This feedback is clear and actionable, as it directs the authors to specific areas where they need to provide more detailed explanations or justifications. However, the comment could be more helpful if it included suggestions for how to address the issue of positive values despite the theoretical possibility of negative values. Overall, the comment is mostly helpful, as it provides a good starting point for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It also provides a reference to support the claim that initialization should play a role, such as pre-training. However, the comment does not explicitly instruct the authors to revise the statement or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the statement to be more precise. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Initialization\" and its role in the context of NGD and NGF, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the need for a more careful statement regarding the role of initialization. However, the comment does not provide specific examples or detailed guidance on how to revise the statement, making it somewhat specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It provides a reference to support this claim, which is a common practice in academic writing. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from additional context or examples to fully understand the implications of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It provides a reference to support the claim, which is a common practice in academic writing. However, the comment could be more helpful if it offered specific guidance on how to revise the statement or what aspects of the statement need clarification. While it provides a clear direction for improvement, the feedback is somewhat limited in its depth and actionable nature, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to improve readability. While the comment explicitly mentions the need for clarification regarding the extraction process, it does not provide specific guidance on how to achieve this. The suggestion to improve readability through proofreading is also vague and lacks detail. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide concrete steps for the authors to take. The comment is rated as 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for clarification regarding the extraction of named entities from the datasets, allowing the authors to accurately identify the part of the paper being addressed. It also suggests that English proofreading would improve readability, which is a specific and actionable suggestion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is not clear how named entities were extracted from the datasets and suggests that English proofreading would improve readability. While the suggestion to improve readability is logical and common practice, the claim about the lack of clarity in named entity extraction is not substantiated with specific examples or references. This makes the claim somewhat verifiable, as it lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to enhance readability. While the comment highlights these issues, it does not provide specific guidance or suggestions on how to address them. The feedback is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, making it only slightly beneficial for the authors. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific instances where the authors' draft could be improved. It highlights a potential issue with the phrasing at line 200, suggesting that the term \"for every arm a\" might imply a single optimistic parameter, which is not necessarily the case. Additionally, it questions the choice of T_0 = m Sqrt(T) and suggests an alternative formulation that could improve the condition. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to implement the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L200 and L303) in the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific feedback on the phrasing at line 200, questioning the implication of \"for every arm a\" and suggesting an alternative formulation. Additionally, it offers a specific suggestion regarding the choice of T_0 = m Sqrt(T) and proposes an alternative condition that could improve the paper. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts, both of which are factual statements. The first part questions the phrasing at line 200, suggesting that it might imply a single optimistic parameter, which is not necessarily the case. The second part questions the choice of T_0 = m Sqrt(T) and suggests an alternative formulation that could improve the condition. While the claims are based on logical reasoning and common knowledge, they lack specific examples or references to support the claims fully. Therefore, the comment is somewhat verifiable, as it provides some justification but could be strengthened with more detailed reasoning or references. The label aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on two distinct points in the paper, offering detailed suggestions for improvement. It questions the phrasing at line 200, suggesting that it might imply a single optimistic parameter, which is not necessarily the case. This feedback is actionable, as it prompts the authors to reconsider the wording and ensure clarity. Additionally, the comment questions the choice of T_0 = m Sqrt(T) and suggests an alternative formulation that could improve the condition, providing a clear direction for the authors to enhance their work. While the feedback is somewhat detailed, it could be more comprehensive with additional suggestions or examples. Overall, the comment is mostly helpful, as it offers valuable insights and actionable feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the definition of variables L and E in the paper. It points out that these variables are not defined in the immediate vicinity, which could hinder the reader's understanding. Additionally, the comment notes inconsistencies in the italicization of L and E, which could affect the clarity and consistency of the paper. While the comment identifies a clear issue and suggests a specific area for improvement, it does not provide explicit guidance on how to define L and E or how to ensure consistent italicization. The action is somewhat vague, as the authors need to infer that they should define the variables and maintain consistent formatting. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the variables L and E are not defined in the immediate vicinity and that there are inconsistencies in their italicization. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue regarding the definition of variables L and E in the paper, noting that they are not defined in the immediate vicinity and that there are inconsistencies in their italicization. While the comment identifies a factual observation about the paper's formatting and clarity, it does not provide any logical reasoning, common knowledge, or external references to support the claim. The authors are left to infer the need for clarification or correction, which limits the verifiability of the comment. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the variables L and E are not defined in the immediate vicinity and that there are inconsistencies in their italicization. This feedback is clear and actionable, as it points out a lack of clarity and consistency in the presentation of the variables. By highlighting these issues, the comment provides the authors with a direct path to improve the readability and consistency of their paper. However, the comment could be more helpful if it suggested specific ways to define the variables or ensure consistent formatting. Overall, the comment is mostly helpful as it identifies a clear area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which aspects of the experimental section are weak or what additional experiments would be beneficial. The comment lacks concrete guidance on how to improve the experimental section, leaving the authors with a general idea but no specific direction to follow. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which part of the paper the experimental section is located in, nor does it provide any details on what aspects of the experiments are weak or what additional experiments could be beneficial. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any guidance on how to improve the experimental section or what kind of additional experiments would be helpful. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental section is weak and suggests that more experiments are required. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer the nature of the weakness and the need for more experiments, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental section, suggesting that more experiments are needed. However, it lacks specificity and does not provide any guidance on what additional experiments might be beneficial or how they could address the identified weakness. This feedback is vague and does not offer actionable advice, leaving the authors with limited insight into how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. While the comment implies that the authors should consider including these comparisons, it does not explicitly instruct them to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to include more comparisons, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameter-efficient fine-tuning techniques beyond LoRA and SPP. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for more comprehensive comparisons. However, the comment lacks specific guidance or suggestions on which models or techniques should be included, making it somewhat vague and incomplete. The authors would need to infer that they should expand their comparisons, which could be challenging without further direction. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the use of \"Despite of\" and \"to a even deeper,\" and to correct the grammatical error on line 265. These instructions are clear and direct, allowing the authors to understand exactly what changes are needed. However, the comment does not provide additional guidance on how to implement these changes or what specific aspects of the writing should be improved. Therefore, the comment is mostly actionable, as it provides explicit instructions but lacks detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper, focusing on lines 2, 56, and 158. It suggests removing specific phrases like \"Despite of\" and \"to a even deeper\" and correcting a grammatical error on line 265. While the comment does not explicitly mention sections, it implies that these lines are part of the paper, allowing the authors to infer the specific parts being addressed. The comment is specific in detailing what needs to be corrected, such as the use of specific phrases and the grammatical error. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of four claims, each suggesting specific changes to the writing style and clarity of certain sentences in the paper. The claims are specific and provide clear guidance on how the authors should revise the text. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. While the suggestions are logical and actionable, the absence of additional justification or evidence makes the claims somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It instructs the authors to revise the sentences on lines 2, 56, and 158 to remove specific phrases and correct a grammatical error on line 265. While the feedback is clear and actionable, it lacks depth and does not offer broader guidance on how these changes might impact the overall understanding or significance of the paper. The comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional suggestions or context. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This suggests that the authors should clarify the distinction between these two concepts and correct any errors in the equations. However, the comment does not provide explicit guidance on how to address the issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the concepts and correct the equations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This allows the authors to accurately identify the part of the paper being addressed, providing full grounding. The comment is specific in its request for clarification and correction, as it points out potential errors in the equations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This is a factual question that requires the authors to clarify the distinction between these two concepts and correct any errors in the equations. However, the comment does not provide any additional context, reasoning, or references to support the claim. As a result, the authors are left to interpret the question and address it independently, making the comment unverifiable. Therefore, the comment is labeled as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This feedback is somewhat helpful as it points out a potential area of confusion or error in the equations. However, it lacks detailed guidance or suggestions on how the authors might address this issue or what specific changes are needed. The comment is clear in identifying a potential problem, but it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the novelty or significance of their work. Without specific suggestions or feedback on how to enhance the model or the paper's contribution, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment lacks specificity in detailing what aspects of the model or the paper are considered straightforward extensions. As a result, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, the comment lacks specific details or examples to support this claim. It does not provide any references or evidence to substantiate the assertion that the model is a straightforward extension of the GAN. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. While this feedback provides a general critique of the paper's novelty, it lacks specific details or actionable suggestions for improvement. The authors are left without a clear understanding of how to address the perceived lack of innovation or how to enhance the paper's contribution. Without more detailed feedback or guidance, the comment is somewhat helpful but does not provide substantial support for the authors to make meaningful improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational design. However, it does not provide explicit or implicit actions for the authors to take, such as conducting the comparison or providing feedback on the results. The comment lacks concrete guidance on how the authors should address this suggestion, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational design. However, it does not specify which part of the paper this question relates to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity because it does not detail what aspects of the comparison should be considered or how the authors should approach it. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational design. However, it does not provide any specific evidence, reasoning, or references to support the claim that the method performs better in pure combinational logic. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of the proposed method in pure combinational logic and suggests a comparison between sequential and combinational design. This feedback is somewhat helpful as it prompts the authors to consider an additional aspect of their work and could potentially lead to further exploration or refinement of their method. However, the comment lacks depth and does not provide specific guidance or suggestions on how to approach this comparison or what aspects of the design might be relevant. As a result, the feedback is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it suggests that the authors should provide this information, it does not explicitly instruct them to include it in the draft or specify how to calculate or present the results. The action is implicit, as the authors need to infer that they should add this information to the experiment section. However, the lack of detailed guidance on how to implement this suggestion makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment section where the authors have designed a baseline combining LDA and LSTM. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it requests the performance of this baseline in terms of the topic switch percent metric, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. However, it does not provide any evidence, reasoning, or references to support why this metric is important or how it should be evaluated. The comment lacks specific details or justification, making it difficult for the authors to understand the basis for the request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the experiment section, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. It questions the authors' understanding of this baseline and requests additional information on its performance. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. While it highlights a potential area for clarification, it lacks actionable advice or constructive feedback that would empower the authors to enhance their work. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but does not offer comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies areas where the authors could provide more clarity, it does not explicitly instruct the authors on how to address these issues or what specific actions they should take. The actions are implicit and somewhat vague, as the authors need to infer how to improve the draft based on the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not specify which part of the paper addresses these issues, making it weakly grounded. The questions are specific and provide clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the relevant sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not provide any specific examples, reasoning, or references to support these claims. The questions are logical and inferable, but without detailed justification or evidence, they are considered borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important questions about the motivation of the task, particularly concerning the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also inquires about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies a key area for clarification, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider the practical implications and potential applications of their work, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action that the authors can directly implement by adding experiments with GPT-3.5. The comment is specific in its suggestion, providing a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. This makes it difficult for the authors to identify the exact section that needs revision. While the suggestion is specific in its recommendation, the lack of grounding makes it challenging for the authors to apply it effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is logical and aligns with the understanding of cost-effectiveness, it lacks specific examples or references to support the claim. The authors would need to infer the reasoning behind this suggestion, which could be improved by providing more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it is based on a reasonable argument but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly addresses a potential limitation in the current evaluation by suggesting an alternative, more cost-effective option. By incorporating experiments with GPT-3.5, the authors can strengthen the robustness and comprehensiveness of their evaluation, which would be beneficial for the paper. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects of the approach should be evaluated with GPT-3.5. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4, specifically mentioning the BLEU score for WMT17-WIKT. This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be done to improve their draft, which aligns with the definition of a highly actionable comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, namely the inclusion of bold numbers for the baselines of previous work, particularly for WMT17-WIKT, where the best BLEU result is in the baselines. This level of detail helps the authors understand exactly what changes are required. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement that requests the inclusion of bold numbers for the baselines of previous work in Table 4, specifically mentioning the BLEU score for WMT17-WIKT. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it provides clear guidance on what needs to be improved in the paper. It requests the inclusion of bold numbers for the baselines of previous work in Table 4, particularly for WMT17-WIKT, where the best BLEU score is in the baselines. This feedback is valuable as it directs the authors to a specific area for improvement, enhancing the clarity and completeness of their work. However, the comment could be more helpful if it suggested alternative ways to present this information or provided examples of how to format the numbers. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for examples of \"unreliable neighbors,\" which implies that the authors should provide specific instances to clarify the concept. However, it does not explicitly instruct the authors to include these examples in their draft or suggest where they should be added. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and understand the context of \"unreliable neighbors.\" Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests examples of \"unreliable neighbors,\" which directly points out what needs clarification or further explanation in that section. This provides clear guidance on what the authors should address to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point asks for examples of \"unreliable neighbors,\" which is a request for clarification and does not contain a subjective claim or suggestion that requires verification. It is a factual request for information, making it a \"No\" category.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment requests examples of \"unreliable neighbors,\" which is a specific and actionable suggestion for the authors to clarify a concept in their paper. By asking for examples, the reviewer provides a clear direction for improving the draft, making it somewhat helpful. However, the comment could be more helpful if it offered additional guidance on how to define or categorize these neighbors or suggested where these examples should be included in the paper. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study, as it is crucial for understanding these synergies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to include the TD3GA algorithm and its comparison. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the claim about the synergies between DQD and PPO, specifically noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study. However, the comment does not specify which part of the paper discusses the synergies or the comparison to TD3GA, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main paper does not mention the TD3GA algorithm, which is crucial for understanding the synergies between DQD and PPO. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the assertion. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the insufficient backing of the claim about the synergies between DQD and PPO. It points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the study, highlighting a key area that needs attention. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue, such as suggesting additional experiments or analyses to include the TD3GA algorithm. Overall, the comment is somewhat helpful as it identifies a significant weakness but lacks detailed actionable feedback, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the surprising performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance. It prompts the authors to explain why this occurs, suggesting that they should provide a detailed explanation of the results. However, the comment does not specify how the authors should address this question or what aspects of the results need clarification. The action is implicit and vague, as it requires the authors to infer the need for an explanation and then decide how to provide it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Sections 6.1 and 6.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the surprising performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance and asks for an explanation. This provides a clear direction for the authors to address the concern. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the surprising performance of the tree-sliced Wasserstein distance compared to the original optimal transport distance. While it prompts the authors to explain this phenomenon, it does not provide any specific evidence, reasoning, or references to support the claim. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the observation and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a surprising result in the paper, specifically the outperformance of the tree-sliced Wasserstein distance over the original optimal transport distance, and prompts the authors to explain why this occurs. This feedback is valuable as it highlights a potential area of confusion or a need for further clarification in the results section. However, the comment lacks specific guidance on how the authors might approach explaining this result or what aspects of the results require further discussion. While it points out an important observation, it does not provide detailed suggestions or actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the term \"confident\" in the context of ceterus paribus convexity, questioning whether it refers to model confidence or human interpretability. While the comment identifies a potential point of confusion for the authors, it does not provide explicit guidance on how to address this issue or suggest specific actions to clarify the term. The action is implicit, as the authors need to infer that they should rephrase the sentence to avoid ambiguity. However, the comment lacks concrete details on how to rephrase the sentence or what specific aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not provide details on what needs to be addressed or how the authors should approach the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about the term \"confident\" in the context of ceterus paribus convexity, questioning whether it refers to model confidence or human interpretability. The comment suggests that the authors should rephrase the sentence to avoid ambiguity. However, the comment lacks specific examples or references to clarify the issue, making it difficult for the authors to fully understand and address the concern. As a result, the claim is somewhat verifiable, as it provides a general suggestion but lacks detailed support or guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential point of confusion for the authors regarding the term 'confident' in the context of ceterus paribus convexity. It suggests that the authors might be unsure whether 'confident' refers to model confidence or human interpretability. While the comment highlights a potential ambiguity, it does not provide specific guidance or suggestions on how to clarify the term or rephrase the sentence. The feedback is somewhat helpful as it points out a potential issue that could affect the clarity of the paper, but it lacks actionable advice on how to address it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the paper, noting that the use of known causal relationships might not be feasible in practice due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve the practicality of their work. The action is implicit and vague, as it does not offer concrete steps or advice on how to make the paper more practical. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, it does not specify which part of the paper this concern pertains to, such as a particular section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. This is a valid point that highlights a potential limitation of the proposed approach. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the practicality of their work. While it identifies a concern, it does not provide specific steps or advice for improvement, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the figures and empirical results, such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the figures and empirical results. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of polishing of figures and empirical results, which impedes clarity and confidence in the findings. It also specifies the issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of polishing of figures and empirical results, which impedes clarity and confidence in the findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, the comment does not offer any logical reasoning, references, or examples to support these claims. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, specifically focusing on the figures and empirical results. It highlights issues such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These observations provide the authors with specific feedback on what needs to be addressed to enhance the clarity and confidence in their empirical findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures or empirical results, such as providing guidance on polishing techniques or suggesting alternative experimental designs. Overall, the comment is somewhat helpful as it points out areas for improvement but lacks detailed guidance on how to implement these suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the work is limited, pointing out that tighter confidence intervals (CIs) with fine-tuning are expected outcomes. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might enhance the novelty of their work or what specific aspects need to be improved to make the findings more impactful. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the work is limited, pointing out that tighter confidence intervals (CIs) with fine-tuning are expected outcomes. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is not grounded as it does not provide specific guidance on what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the work is limited, suggesting that tighter confidence intervals (CIs) with fine-tuning are expected outcomes. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the work, suggesting that the findings might be expected outcomes of task-specific fine-tuning. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps or detailed insights to help the authors make meaningful changes. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be stronger if it reported the numbers observed in a label noise experiment on ImageNet with 1000 classes, particularly focusing on non-tail classes. This provides a clear and explicit action for the authors to take, as they can directly incorporate these additional results into their draft. The comment is specific in its suggestion and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on non-tail classes. This provides a clear and specific direction for the authors to enhance their analysis. However, the comment does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what additional data would strengthen the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, particularly focusing on non-tail classes. This claim is somewhat verifiable as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of this additional data to understand the full context of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would be strengthened by reporting additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on non-tail classes. This feedback is actionable and provides a clear direction for the authors to enhance their analysis and potentially strengthen their conjecture. By including these additional results, the authors can further stress-test their conjecture and provide a more comprehensive evaluation. However, the comment could be more helpful if it offered specific guidance on how to present or interpret these additional results. Overall, the comment is mostly helpful as it identifies a valuable area for improvement and provides a clear suggestion for action.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. It suggests that the authors should provide additional feedback to improve the paper. However, the comment does not explicitly instruct the authors on how to address this question or what specific feedback to provide. The action is implicit, as the authors need to infer that they should explain their reasoning for choosing the metric and provide additional feedback. The action is somewhat vague, as it lacks concrete guidance on how to improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in questioning the metric choice, the absence of explicit grounding makes it challenging for the authors to understand the context. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. However, it does not provide any justification or reasoning to support this claim. The comment lacks specific examples or references to substantiate the assertion, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. It prompts the authors to provide additional feedback to improve the paper. However, the comment lacks specificity and does not offer detailed guidance or suggestions on how to address the question or what kind of feedback would be beneficial. The authors are left without clear direction on how to improve their draft, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this question or what aspects of their work could be improved to clarify this point. As a result, the authors are left without any actionable feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. Additionally, it does not specify what needs to be addressed in this context, leaving the authors with no clear direction for improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any claim, suggestion, or judgment that requires verification or justification. The comment is purely descriptive and does not offer any insight or reasoning that would help the authors understand or address the question. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. This question highlights a potential gap in the paper's discussion of the practical implications of the proposed method. However, the comment does not provide any suggestions or insights on how the authors might address this gap or improve the paper's relevance. Without actionable feedback or guidance, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and direction.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the evaluation section, including the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of in-content examples used, and the lack of exploration of the effects of varying the number of in-context examples. It also notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the evaluation section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of in-content examples used, and the lack of exploration of the effects of varying the number of in-context examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of mention of the number of different sets of in-content examples used in the experiments and the lack of exploration of the effects of varying the number of in-context examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. These claims are supported by logical reasoning and specific examples, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims about the limitations of the evaluation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically regarding the comprehensiveness and transparency of the evaluation. It points out the lack of detail in the experiment setup, such as the absence of information on the number of different sets of in-content examples used. Additionally, it notes that the paper does not explore the effects of varying the number of in-context examples, which is a significant oversight. The comment also highlights the limitation of relying solely on one dataset, which may affect the generalizability of the results. While the feedback is clear and actionable, it could be more helpful if it provided specific suggestions on how to address these issues, such as suggesting additional datasets or methods for exploring the impact of varying in-context examples. Overall, the comment is mostly helpful as it provides valuable insights into areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the contrastive learning framework used in the paper, suggesting that it is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their framework. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without any supporting information, the authors are left without a basis to verify or address the issue. This lack of substantiation makes the claim unverifiable, as the authors cannot confidently determine the validity of the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which is a specific and well-known framework. This observation highlights a potential issue with the novelty or differentiation of the proposed approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes they could consider to differentiate their work. Without actionable feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential problem but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is explicit and provides a clear action for the authors to take, namely to add these experiments to better showcase the unique advantages or potential shortcomings of the proposed method. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides a clear direction for the authors to improve the paper by including these additional experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is somewhat verifiable as it suggests a specific area for improvement, but it does not provide detailed reasoning or examples to support why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the need for such comparisons to fully understand the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by adding additional experiments that could showcase the unique advantages or potential shortcomings of the proposed method. By including these comparisons, the authors can provide a broader context for their work and enhance its impact. Therefore, the comment is highly helpful, as it offers a clear and constructive direction for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the related work should be considered. The action is implicit, as the authors need to infer that they should expand their discussion of related work to include these references. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, it does not specify which part of the paper this issue pertains to, such as the introduction, related work section, or discussion. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in suggesting the need for additional related work, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, the comment lacks specific details or reasoning to support why these references are particularly relevant or how they would enhance the paper. Without additional context or explanation, the claim is difficult to verify, making it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as [1], [2], and [3]. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or what aspects of related work should be considered. Without concrete suggestions or examples, the feedback is vague and does not offer actionable advice for the authors. As a result, the comment is barely helpful, as it does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of comparisons against existing text GANs, particularly those with open-source implementations. It also points out that while SeqGAN is mentioned, it is not tested with a pretrained version. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific comparisons or additional experiments. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these comparisons and tests. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"text GANs\" and \"SeqGAN,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by highlighting the lack of comparison against existing text GANs, including those with open-source implementations, and notes that SeqGAN is mentioned but not tested with a pretrained version. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is no comparison against existing text GANs, particularly those with open-source implementations, and that SeqGAN is not tested with a pretrained version. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is considered borderline verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against existing text GANs, especially those with open-source implementations. It also notes that while SeqGAN is mentioned, it is not tested with a pretrained version. This feedback is valuable as it highlights an area where the authors could strengthen their evaluation and provide a more comprehensive comparison. However, the comment could be more helpful if it suggested specific comparisons or additional experiments that the authors could conduct to address this gap. Overall, the comment is somewhat helpful as it provides a clear direction for improvement but lacks detailed guidance on how to implement it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific aspects of the algorithmic focus they should consider. The comment implies that the authors should expand on the algorithmic aspects, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is specific in its suggestion regarding the focus on algorithmic aspects, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should have focused on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or examples, the claim remains somewhat verifiable, as it is based on a logical argument but lacks sufficient evidence to fully substantiate the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper should have focused more on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner. This feedback is somewhat helpful as it highlights a specific area that could enhance the paper's contribution and novelty. However, the comment lacks depth and does not provide detailed guidance on how the authors might address this suggestion or what specific aspects of the algorithmic focus they should consider. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful rather than fully helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. It provides a specific example of how the tables could be reorganized, suggesting that the 8 SFII columns and the 8 SPDI columns should be separated. This feedback is explicit and concrete, as it directly instructs the authors on how to improve the readability of the tables. The action is clear and actionable, providing a specific and detailed suggestion for the authors to implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, one for the 8 SFII columns and another for the 8 SPDI columns. This detailed feedback helps the authors understand exactly what needs to be done to enhance the clarity of the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. While the suggestion is logical and could improve readability, it lacks specific examples or references to support why this change would be beneficial. The comment does not provide detailed reasoning or evidence to justify the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, one for the 8 SFII columns and another for the 8 SPDI columns. This feedback is actionable and directly addresses a potential issue with the presentation of the data. By offering a clear and concise suggestion, the comment empowers the authors to enhance the clarity and organization of their tables, making it easier for readers to understand the information. However, the comment could be more helpful if it included additional suggestions or considerations for further improvements. Overall, the comment is mostly helpful as it provides a clear and actionable piece of feedback, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a clear and explicit action that the authors can readily understand and implement. The comment provides a specific request for clarification, which is actionable and concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between \"valid\" and \"orig'. This provides the authors with a clear understanding of what revisions are necessary. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a request for clarification and does not contain a subjective opinion or claim that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'No', 'helpfulness_rationale': 'The review comment is helpful as it provides a specific request for clarification regarding the terms \"valid\" and \"orig\" in Figure 5. By asking the authors to specify the difference between these terms, the comment directs them to a critical area that needs clarification in their paper. This feedback is actionable and constructive, as it helps the authors improve the clarity and precision of their presentation. However, the comment could be more helpful if it provided additional guidance on how to clarify these terms or suggested specific ways to improve the figure. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making the comparisons between the methods more systematic, specifically by comparing the best performance of each. However, it does not provide explicit guidance on how to achieve this, such as suggesting specific metrics or methods for comparison. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper by Zemel et al. (2013) and the comparison with the present paper. It also specifies the need to make the comparisons more systematic with respect to the tuning of each method, particularly by comparing the best performance of each. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons more systematic, specifically by comparing the best performance of each method. However, the comment lacks specific details or examples of how this comparison could be implemented or what metrics would be used. Without additional information or guidance, the claim is difficult to verify, making it borderline verifiable. The authors would need to infer the exact steps to take, which limits the verifiability of the comment.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with the most closely related work of Zemel et al. (2013) could be more systematic, particularly by comparing the best performance of each method. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper's analysis and comparisons. However, the comment could be more helpful if it included suggestions on how to achieve this systematic comparison, such as specifying metrics or methods for evaluating performance. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. However, it does not provide explicit guidance on which methods to compare or how to adapt them for language tasks. The action is implicit, as the authors need to infer that they should consider comparing to specific methods mentioned in the computer vision setting. The comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a comparison to methods mentioned in the computer vision setting, which implies that the authors should focus on this aspect. However, it does not specify which methods are being referred to or provide details on how to adapt them for language tasks. The comment is weakly grounded as it does not explicitly mention sections or parts of the paper, but it is specific in its suggestion to compare to certain methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that comparing to methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The comment lacks detailed justification or evidence, which limits its verifiability. Therefore, it is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that including a comparison to methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. While the comment provides a rationale for this suggestion, it lacks specific examples or detailed guidance on which methods to compare or how to adapt them for language tasks. This feedback is somewhat helpful as it offers a direction for improvement but does not fully address the authors' needs for comprehensive comparisons. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This provides a clear and explicit action for the authors to take, as they need to estimate the time complexity to support the claim about scalability. The comment is specific in its suggestion, detailing what needs to be done to substantiate the claim. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This claim is somewhat verifiable as it provides a logical reasoning for why the estimation of time complexity is important for demonstrating scalability. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This feedback is clear and actionable, as it provides a specific and concrete suggestion for the authors to improve their draft. By estimating the time complexity, the authors can better substantiate their claims about the scalability of their learning algorithm. This feedback is detailed and directly addresses a potential weakness in the paper, making it highly helpful for the authors to enhance their work. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, specifically referencing Chapter 4 of Steinwart and Christmann. While it prompts the authors to explore this connection, it does not provide explicit guidance on how to address it or what specific aspects of the connection should be investigated. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the connection further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the connection between the third point and the properties of universal kernels, referencing a specific chapter in a relevant work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing Chapter 4 of Steinwart and Christmann. While the comment provides a specific reference to a relevant work, it does not offer a detailed explanation or justification for why this connection is important or how it relates to the paper's content. The lack of detailed reasoning or examples makes it somewhat verifiable, as the authors would need to infer the relevance of the reference. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the connection between the third point of definition one and the properties of universal kernels, referencing a relevant work by Steinwart and Christmann. This feedback is somewhat helpful as it prompts the authors to explore the connection further, which could enhance the depth and rigor of their analysis. However, the comment lacks detailed guidance on how to approach this exploration or what specific aspects of the connection should be investigated. While it provides a direction for improvement, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'}'"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the discussion around equation (10) is terse and not clearly explained. While it suggests that the authors should improve the clarity of this discussion, it does not provide specific guidance on how to achieve this. The action is implicit, as the authors need to infer that they should enhance the explanation of the discussion around equation (10). However, the comment lacks concrete details on what aspects of the discussion need to be clarified or expanded. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out that the discussion around this equation is terse and not well-explained, providing a clear indication of what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is terse and not clearly explained. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is actionable as it provides a clear area for improvement, suggesting that the authors should enhance the clarity and depth of their discussion. However, the comment lacks specific guidance on how to improve the explanation or what aspects of the discussion need clarification. While it offers a valuable suggestion, it could be more helpful if it provided more detailed guidance or examples of how to improve the explanation. Therefore, the comment is mostly helpful, as it directs the authors to an area of improvement but does not fully address the need for actionable feedback.', 'helpfulness_label': '4'} "}
